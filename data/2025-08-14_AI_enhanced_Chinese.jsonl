{"id": "2508.09238", "pdf": "https://arxiv.org/pdf/2508.09238", "abs": "https://arxiv.org/abs/2508.09238", "authors": ["Hyunsung Kim", "Hoyoung Choi", "Sangwoo Seo", "Tom Boomstra", "Jinsung Yoon", "Chanyoung Park"], "title": "ELASTIC: Event-Tracking Data Synchronization in Soccer Without Annotated Event Locations", "categories": ["cs.DB"], "comment": "Accepted at ECML PKDD 2025 Workshop on Machine Learning and Data\n  Mining for Sports Analytics (MLSA 2025)", "summary": "The integration of event and tracking data has become essential for advanced\nanalysis in soccer. However, synchronizing these two modalities remains a\nsignificant challenge due to temporal and spatial inaccuracies in manually\nrecorded event timestamps. Existing synchronizers typically rely on annotated\nevent locations, which themselves are prone to spatial errors and thus can\ndistort synchronization results. To address this issue, we propose ELASTIC\n(Event-Location-AgnoSTIC synchronizer), a synchronization framework that only\nuses features derived from tracking data. ELASTIC also explicitly detects the\nend times of pass-like events and separates the detection of major and minor\nevents, which improves the completeness of the synchronized output and reduces\nerror cascade across events. We annotated the ground truth timestamps of 2,134\nevents from three Eredivisie matches to measure the synchronization accuracy,\nand the experimental results demonstrate that ELASTIC outperforms existing\nsynchronizers by a large margin.", "AI": {"tldr": "ELASTIC\u662f\u4e00\u79cd\u4ec5\u4f7f\u7528\u8ddf\u8e2a\u6570\u636e\u7279\u5f81\u7684\u540c\u6b65\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u8db3\u7403\u4e8b\u4ef6\u4e0e\u8ddf\u8e2a\u6570\u636e\u540c\u6b65\u7684\u6311\u6218\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8db3\u7403\u4e2d\u4e8b\u4ef6\u4e0e\u8ddf\u8e2a\u6570\u636e\u7684\u540c\u6b65\u56e0\u624b\u52a8\u8bb0\u5f55\u7684\u65f6\u95f4\u6233\u4e0d\u51c6\u786e\u800c\u56f0\u96be\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u6613\u51fa\u9519\u7684\u4e8b\u4ef6\u4f4d\u7f6e\u6807\u6ce8\u3002", "method": "\u63d0\u51faELASTIC\u6846\u67b6\uff0c\u4ec5\u5229\u7528\u8ddf\u8e2a\u6570\u636e\u7279\u5f81\uff0c\u660e\u786e\u68c0\u6d4b\u4f20\u7403\u7c7b\u4e8b\u4ef6\u7684\u7ed3\u675f\u65f6\u95f4\uff0c\u5e76\u533a\u5206\u4e3b\u6b21\u8981\u4e8b\u4ef6\u3002", "result": "\u5728\u4e09\u4e2aEredivisie\u6bd4\u8d5b\u76842134\u4e2a\u4e8b\u4ef6\u4e0a\u6d4b\u8bd5\uff0cELASTIC\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u540c\u6b65\u5668\u3002", "conclusion": "ELASTIC\u901a\u8fc7\u51cf\u5c11\u8bef\u5dee\u4f20\u9012\u548c\u63d0\u5347\u540c\u6b65\u5b8c\u6574\u6027\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6570\u636e\u540c\u6b65\u95ee\u9898\u3002"}}
{"id": "2508.09594", "pdf": "https://arxiv.org/pdf/2508.09594", "abs": "https://arxiv.org/abs/2508.09594", "authors": ["Fei Teng", "Haoyang Li", "Lei Chen"], "title": "LLMLog: Advanced Log Template Generation via LLM-driven Multi-Round Annotation", "categories": ["cs.DB"], "comment": "Accepted in VLDB 2025", "summary": "Modern computing systems, such as HDFS and Spark, produce vast quantities of\nlogs that developers use for tasks like anomaly detection and error analysis.\nTo simplify log analysis, template generation methods have been proposed to\nstandardize log formats, transforming unstructured data into structured\ntemplates. Existing heuristic-based methods and neural network-based methods\nsuffer from low accuracy problems due to the reliance on handcrafted heuristics\nor specific log patterns in training sets. Recently, large language models\n(LLMs) have shown great potential in log template generation. However, they\noften struggle with ambiguous, complex, or highly specific log content, which\ncan lead to errors in generating accurate templates. To address these\nchallenges, we propose LLMLog, a multi-round annotation framework with adaptive\nin-context learning. We first propose an edit-distance-based similarity metric\nto evaluate log similarity. Then, we introduce a method to select the most\ninformative $k$ unlabeled logs for annotation by considering both the\nrepresentativeness of the logs and the confidence of LLM predictions.\nAdditionally, we design an adaptive context selection strategy that adaptively\nselects labeled logs to ensure comprehensive keyword coverage for unlabeled\nlogs. These labeled logs serve as the context for LLMs to better understand the\nunlabeled logs, thereby enhancing the accuracy of template generation.\nExtensive experiments on sixteen datasets demonstrate that LLMLog outperforms\nthe state-of-the-art approaches.", "AI": {"tldr": "LLMLog\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u8f6e\u6807\u6ce8\u548c\u81ea\u9002\u5e94\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u9ad8\u65e5\u5fd7\u6a21\u677f\u751f\u6210\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65e5\u5fd7\u6a21\u677f\u751f\u6210\u65b9\u6cd5\u56e0\u4f9d\u8d56\u624b\u5de5\u89c4\u5219\u6216\u7279\u5b9a\u8bad\u7ec3\u96c6\u6a21\u5f0f\u800c\u51c6\u786e\u6027\u4f4e\uff0cLLMs\u5728\u5904\u7406\u590d\u6742\u65e5\u5fd7\u65f6\u4e5f\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7f16\u8f91\u8ddd\u79bb\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\uff0c\u9009\u62e9\u6700\u5177\u4ee3\u8868\u6027\u7684\u672a\u6807\u6ce8\u65e5\u5fd7\u8fdb\u884c\u6807\u6ce8\uff0c\u5e76\u8bbe\u8ba1\u81ea\u9002\u5e94\u4e0a\u4e0b\u6587\u9009\u62e9\u7b56\u7565\u3002", "result": "\u572816\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLLMLog\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "LLMLog\u901a\u8fc7\u591a\u8f6e\u6807\u6ce8\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u663e\u8457\u63d0\u5347\u4e86\u65e5\u5fd7\u6a21\u677f\u751f\u6210\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2508.09602", "pdf": "https://arxiv.org/pdf/2508.09602", "abs": "https://arxiv.org/abs/2508.09602", "authors": ["Yaoyu Zhu", "Jintao Zhang", "Guoliang Li", "Jianhua Feng"], "title": "A Lightweight Learned Cardinality Estimation Model", "categories": ["cs.DB", "cs.AI", "cs.LG"], "comment": "IEEE Transactions on Knowledge and Data Engineering (TKDE), 2025", "summary": "Cardinality estimation is a fundamental task in database management systems,\naiming to predict query results accurately without executing the queries.\nHowever, existing techniques either achieve low estimation accuracy or incur\nhigh inference latency. Simultaneously achieving high speed and accuracy\nbecomes critical for the cardinality estimation problem. In this paper, we\npropose a novel data-driven approach called CoDe (Covering with Decompositions)\nto address this problem. CoDe employs the concept of covering design, which\ndivides the table into multiple smaller, overlapping segments. For each\nsegment, CoDe utilizes tensor decomposition to accurately model its data\ndistribution. Moreover, CoDe introduces innovative algorithms to select the\nbest-fitting distributions for each query, combining them to estimate the final\nresult. By employing multiple models to approximate distributions, CoDe excels\nin effectively modeling discrete distributions and ensuring computational\nefficiency. Notably, experimental results show that our method represents a\nsignificant advancement in cardinality estimation, achieving state-of-the-art\nlevels of both estimation accuracy and inference efficiency. Across various\ndatasets, CoDe achieves absolute accuracy in estimating more than half of the\nqueries.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCoDe\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8986\u76d6\u8bbe\u8ba1\u548c\u5f20\u91cf\u5206\u89e3\u6280\u672f\uff0c\u9ad8\u6548\u4e14\u51c6\u786e\u5730\u89e3\u51b3\u4e86\u57fa\u6570\u4f30\u8ba1\u95ee\u9898\u3002", "motivation": "\u57fa\u6570\u4f30\u8ba1\u662f\u6570\u636e\u5e93\u7ba1\u7406\u4e2d\u7684\u5173\u952e\u4efb\u52a1\uff0c\u4f46\u73b0\u6709\u6280\u672f\u8981\u4e48\u7cbe\u5ea6\u4f4e\uff0c\u8981\u4e48\u5ef6\u8fdf\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u540c\u65f6\u5b9e\u73b0\u9ad8\u901f\u5ea6\u548c\u51c6\u786e\u6027\u3002", "method": "CoDe\u5229\u7528\u8986\u76d6\u8bbe\u8ba1\u5c06\u8868\u5212\u5206\u4e3a\u591a\u4e2a\u91cd\u53e0\u7684\u5c0f\u6bb5\uff0c\u5e76\u901a\u8fc7\u5f20\u91cf\u5206\u89e3\u5efa\u6a21\u6570\u636e\u5206\u5e03\uff0c\u7ed3\u5408\u521b\u65b0\u7b97\u6cd5\u9009\u62e9\u6700\u4f73\u5206\u5e03\u7ec4\u5408\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCoDe\u5728\u57fa\u6570\u4f30\u8ba1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u534a\u6570\u4ee5\u4e0a\u67e5\u8be2\u8fbe\u5230\u7edd\u5bf9\u51c6\u786e\u3002", "conclusion": "CoDe\u901a\u8fc7\u591a\u6a21\u578b\u8fd1\u4f3c\u5206\u5e03\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u6570\u4f30\u8ba1\u7684\u6027\u80fd\uff0c\u4e3a\u6570\u636e\u5e93\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09631", "pdf": "https://arxiv.org/pdf/2508.09631", "abs": "https://arxiv.org/abs/2508.09631", "authors": ["Yuchen Tian", "Kaixin Li", "Hao Chen", "Ziyang Luo", "Hongzhan Lin", "Sebastian Schelter", "Lun Du", "Jing Ma"], "title": "AmbiGraph-Eval: Can LLMs Effectively Handle Ambiguous Graph Queries?", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have recently demonstrated strong capabilities\nin translating natural language into database queries, especially when dealing\nwith complex graph-structured data. However, real-world queries often contain\ninherent ambiguities, and the interconnected nature of graph structures can\namplify these challenges, leading to unintended or incorrect query results. To\nsystematically evaluate LLMs on this front, we propose a taxonomy of\ngraph-query ambiguities, comprising three primary types: Attribute Ambiguity,\nRelationship Ambiguity, and Attribute-Relationship Ambiguity, each subdivided\ninto Same-Entity and Cross-Entity scenarios. We introduce AmbiGraph-Eval, a\nnovel benchmark of real-world ambiguous queries paired with expert-verified\ngraph query answers. Evaluating 9 representative LLMs shows that even top\nmodels struggle with ambiguous graph queries. Our findings reveal a critical\ngap in ambiguity handling and motivate future work on specialized resolution\ntechniques.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u56fe\u67e5\u8be2\u6b67\u4e49\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u5f15\u5165AmbiGraph-Eval\u57fa\u51c6\u8bc4\u4f30LLMs\u5904\u7406\u6b67\u4e49\u67e5\u8be2\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u7684\u56fe\u67e5\u8be2\u5e38\u5b58\u5728\u6b67\u4e49\uff0c\u800cLLMs\u5728\u5904\u7406\u8fd9\u7c7b\u95ee\u9898\u65f6\u8868\u73b0\u4e0d\u8db3\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u548c\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u5305\u542b\u4e09\u79cd\u4e3b\u8981\u7c7b\u578b\u7684\u56fe\u67e5\u8be2\u6b67\u4e49\u5206\u7c7b\u6cd5\uff0c\u5e76\u5f00\u53d1AmbiGraph-Eval\u57fa\u51c6\uff0c\u8bc4\u4f309\u79cd\u4ee3\u8868\u6027LLMs\u3002", "result": "\u5373\u4f7f\u9876\u7ea7LLMs\u5728\u5904\u7406\u6b67\u4e49\u56fe\u67e5\u8be2\u65f6\u4e5f\u8868\u73b0\u4e0d\u4f73\uff0c\u63ed\u793a\u4e86\u6b67\u4e49\u5904\u7406\u7684\u5173\u952e\u7f3a\u53e3\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u6b67\u4e49\u5904\u7406\u7684\u91cd\u8981\u6027\uff0c\u5e76\u547c\u5401\u672a\u6765\u5f00\u53d1\u4e13\u95e8\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09332", "pdf": "https://arxiv.org/pdf/2508.09332", "abs": "https://arxiv.org/abs/2508.09332", "authors": ["Anshul Khairnar", "Aarya Rajoju", "Edward F. Gehringer"], "title": "Teaching Code Refactoring Using LLMs", "categories": ["cs.SE", "cs.LG"], "comment": "Accepted for presentation at the Frontiers in Education Conference,\n  Nashville, Tennessee, USA, 2-5 November 2025", "summary": "This Innovative Practice full paper explores how Large Language Models (LLMs)\ncan enhance the teaching of code refactoring in software engineering courses\nthrough real-time, context-aware feedback. Refactoring improves code quality\nbut is difficult to teach, especially with complex, real-world codebases.\nTraditional methods like code reviews and static analysis tools offer limited,\ninconsistent feedback. Our approach integrates LLM-assisted refactoring into a\ncourse project using structured prompts to help students identify and address\ncode smells such as long methods and low cohesion. Implemented in Spring 2025\nin a long-lived OSS project, the intervention is evaluated through student\nfeedback and planned analysis of code quality improvements. Findings suggest\nthat LLMs can bridge theoretical and practical learning, supporting a deeper\nunderstanding of maintainability and refactoring principles.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5982\u4f55\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u901a\u8fc7\u5b9e\u65f6\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u53cd\u9988\u63d0\u5347\u8f6f\u4ef6\u5de5\u7a0b\u8bfe\u7a0b\u4e2d\u7684\u4ee3\u7801\u91cd\u6784\u6559\u5b66\u3002", "motivation": "\u4ee3\u7801\u91cd\u6784\u80fd\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\uff0c\u4f46\u5728\u590d\u6742\u771f\u5b9e\u4ee3\u7801\u5e93\u4e2d\u6559\u5b66\u56f0\u96be\uff0c\u4f20\u7edf\u65b9\u6cd5\u53cd\u9988\u6709\u9650\u4e14\u4e0d\u4e00\u81f4\u3002", "method": "\u5c06LLM\u8f85\u52a9\u91cd\u6784\u6574\u5408\u5230\u8bfe\u7a0b\u9879\u76ee\u4e2d\uff0c\u4f7f\u7528\u7ed3\u6784\u5316\u63d0\u793a\u5e2e\u52a9\u5b66\u751f\u8bc6\u522b\u548c\u89e3\u51b3\u4ee3\u7801\u5f02\u5473\uff08\u5982\u957f\u65b9\u6cd5\u3001\u4f4e\u5185\u805a\uff09\u3002", "result": "\u901a\u8fc7\u5b66\u751f\u53cd\u9988\u548c\u4ee3\u7801\u8d28\u91cf\u6539\u8fdb\u5206\u6790\u8bc4\u4f30\uff0c\u53d1\u73b0LLMs\u80fd\u5f25\u5408\u7406\u8bba\u4e0e\u5b9e\u8df5\u5b66\u4e60\u7684\u5dee\u8ddd\u3002", "conclusion": "LLMs\u6709\u52a9\u4e8e\u5b66\u751f\u66f4\u6df1\u5165\u7406\u89e3\u53ef\u7ef4\u62a4\u6027\u548c\u91cd\u6784\u539f\u5219\u3002"}}
{"id": "2508.09361", "pdf": "https://arxiv.org/pdf/2508.09361", "abs": "https://arxiv.org/abs/2508.09361", "authors": ["Mingyang Gong", "Guohui Lin", "Brendan Mumey"], "title": "An improved local search based algorithm for $k^-$-star partition", "categories": ["cs.DS", "F.2.2"], "comment": null, "summary": "We study the $k^-$-star partition problem that aims to find a minimum\ncollection of vertex-disjoint stars, each having at most $k$ vertices to cover\nall vertices in a simple undirected graph $G = (V, E)$. Our main contribution\nis an improved $O(|V|^3)$-time $(\\frac k2 - \\frac {k-2}{8k-14})$-approximation\nalgorithm.\n  Our algorithm starts with a $k^-$-star partition with the least $1$-stars and\na key idea is to distinguish critical vertices, each of which is either in a\n$2$-star or is the center of a $3$-star in the current solution. Our algorithm\niteratively updates the solution by three local search operations so that the\nvertices in each star in the final solution produced cannot be adjacent to too\nmany critical vertices. We present an amortization scheme to prove the\napproximation ratio in which the critical vertices are allowed to receive more\ntokens from the optimal solution.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3$k^-$-star\u5212\u5206\u95ee\u9898\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a$O(|V|^3)$\uff0c\u8fd1\u4f3c\u6bd4\u4e3a$\\frac k2 - \\frac {k-2}{8k-14}$\u3002", "motivation": "\u7814\u7a76$k^-$-star\u5212\u5206\u95ee\u9898\uff0c\u65e8\u5728\u627e\u5230\u8986\u76d6\u56fe\u4e2d\u6240\u6709\u9876\u70b9\u7684\u6700\u5c0f\u9876\u70b9\u4e0d\u76f8\u4ea4\u661f\u96c6\uff0c\u6bcf\u4e2a\u661f\u6700\u591a\u5305\u542b$k$\u4e2a\u9876\u70b9\u3002", "method": "\u7b97\u6cd5\u4ece\u5177\u6709\u6700\u5c111-\u661f\u7684\u5212\u5206\u5f00\u59cb\uff0c\u901a\u8fc7\u8bc6\u522b\u5173\u952e\u9876\u70b9\uff0c\u5e76\u8fed\u4ee3\u5e94\u7528\u4e09\u79cd\u5c40\u90e8\u641c\u7d22\u64cd\u4f5c\u6765\u4f18\u5316\u89e3\u3002", "result": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u65f6\u95f4\u590d\u6742\u5ea6$O(|V|^3)$\u5185\u5b9e\u73b0\u4e86\u6539\u8fdb\u7684\u8fd1\u4f3c\u6bd4\u3002", "conclusion": "\u901a\u8fc7\u5173\u952e\u9876\u70b9\u548c\u5c40\u90e8\u641c\u7d22\u64cd\u4f5c\u7684\u7ed3\u5408\uff0c\u7b97\u6cd5\u5728\u4fdd\u8bc1\u6548\u7387\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u8fd1\u4f3c\u6027\u80fd\u3002"}}
{"id": "2508.09144", "pdf": "https://arxiv.org/pdf/2508.09144", "abs": "https://arxiv.org/abs/2508.09144", "authors": ["Liping Huang", "Yicheng Zhang", "Yifang Yin", "Sheng Zhang", "Yi Zhang"], "title": "Efficient Real-Time Aircraft ETA Prediction via Feature Tokenization Transformer", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 9 figures, published in the confernce \"US-Europe Air\n  Transportation Research & Development Symposium 2025\"", "summary": "Estimated time of arrival (ETA) for airborne aircraft in real-time is crucial\nfor arrival management in aviation, particularly for runway sequencing. Given\nthe rapidly changing airspace context, the ETA prediction efficiency is as\nimportant as its accuracy in a real-time arrival aircraft management system. In\nthis study, we utilize a feature tokenization-based Transformer model to\nefficiently predict aircraft ETA. Feature tokenization projects raw inputs to\nlatent spaces, while the multi-head self-attention mechanism in the Transformer\ncaptures important aspects of the projections, alleviating the need for complex\nfeature engineering. Moreover, the Transformer's parallel computation\ncapability allows it to handle ETA requests at a high frequency, i.e., 1HZ,\nwhich is essential for a real-time arrival management system. The model inputs\ninclude raw data, such as aircraft latitude, longitude, ground speed, theta\ndegree for the airport, day and hour from track data, the weather context, and\naircraft wake turbulence category. With a data sampling rate of 1HZ, the ETA\nprediction is updated every second. We apply the proposed aircraft ETA\nprediction approach to Singapore Changi Airport (ICAO Code: WSSS) using\none-month Automatic Dependent Surveillance-Broadcast (ADS-B) data from October\n1 to October 31, 2022. In the experimental evaluation, the ETA modeling covers\nall aircraft within a range of 10NM to 300NM from WSSS. The results show that\nour proposed method method outperforms the commonly used boosting tree based\nmodel, improving accuracy by 7\\% compared to XGBoost, while requiring only 39\\%\nof its computing time. Experimental results also indicate that, with 40\naircraft in the airspace at a given timestamp, the ETA inference time is only\n51.7 microseconds, making it promising for real-time arrival management\nsystems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7279\u5f81\u6807\u8bb0\u5316\u7684Transformer\u6a21\u578b\uff0c\u7528\u4e8e\u5b9e\u65f6\u9884\u6d4b\u98de\u673a\u5230\u8fbe\u65f6\u95f4\uff08ETA\uff09\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5b9e\u65f6ETA\u9884\u6d4b\u5bf9\u822a\u7a7a\u5230\u8fbe\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u8dd1\u9053\u6392\u5e8f\u4e2d\uff0c\u9700\u8981\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u5229\u7528\u7279\u5f81\u6807\u8bb0\u5316\u5c06\u539f\u59cb\u8f93\u5165\u6620\u5c04\u5230\u6f5c\u5728\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7Transformer\u7684\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u5173\u952e\u4fe1\u606f\uff0c\u907f\u514d\u4e86\u590d\u6742\u7684\u7279\u5f81\u5de5\u7a0b\u3002\u6a21\u578b\u652f\u6301\u5e76\u884c\u8ba1\u7b97\uff0c\u6bcf\u79d2\u66f4\u65b0\u4e00\u6b21ETA\u9884\u6d4b\u3002", "result": "\u5728\u65b0\u52a0\u5761\u6a1f\u5b9c\u673a\u573a\u7684\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6bd4XGBoost\u6a21\u578b\u51c6\u786e\u7387\u63d0\u9ad87%\uff0c\u8ba1\u7b97\u65f6\u95f4\u4ec5\u970039%\uff0c\u4e14\u5355\u6b21\u63a8\u7406\u65f6\u95f4\u4ec551.7\u5fae\u79d2\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9ad8\u6548\u4e14\u51c6\u786e\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u5230\u8fbe\u7ba1\u7406\u7cfb\u7edf\u3002"}}
{"id": "2508.09505", "pdf": "https://arxiv.org/pdf/2508.09505", "abs": "https://arxiv.org/abs/2508.09505", "authors": ["Zhanghan Wang", "Ding Ding", "Hang Zhu", "Haibin Lin", "Aurojit Panda"], "title": "Verify Distributed Deep Learning Model Implementation Refinement with Iterative Relation Inference", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Distributed machine learning training and inference is common today because\ntoday's large models require more memory and compute than can be provided by a\nsingle GPU. Distributed models are generally produced by programmers who take a\nsequential model specification and apply several distribution strategies to\ndistribute state and computation across GPUs. Unfortunately, bugs can be\nintroduced in the process, and a distributed model implementation's outputs\nmight differ from the sequential model's outputs. In this paper, we describe an\napproach to statically identify such bugs by checking model refinement, that\nis, can the sequential model's outputs be reconstructed from the distributed\nmodel's outputs? Our approach, implemented in GraphGuard, uses iterative\nrewriting to prove model refinement. Our approach can scale to today's large\nmodels and deployments: we evaluate it using GPT and Llama-3. Further, it\nprovides actionable output that aids in bug localization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9759\u6001\u68c0\u6d4b\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u9519\u8bef\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u67e5\u6a21\u578b\u7ec6\u5316\uff08\u5373\u80fd\u5426\u4ece\u5206\u5e03\u5f0f\u6a21\u578b\u7684\u8f93\u51fa\u91cd\u5efa\u987a\u5e8f\u6a21\u578b\u7684\u8f93\u51fa\uff09\uff0c\u5e76\u5728GraphGuard\u4e2d\u5b9e\u73b0\u3002", "motivation": "\u7531\u4e8e\u5927\u578b\u6a21\u578b\u9700\u8981\u591aGPU\u5206\u5e03\u5f0f\u8bad\u7ec3\uff0c\u7a0b\u5e8f\u5458\u5728\u5c06\u987a\u5e8f\u6a21\u578b\u8f6c\u6362\u4e3a\u5206\u5e03\u5f0f\u6a21\u578b\u65f6\u53ef\u80fd\u5f15\u5165\u9519\u8bef\uff0c\u5bfc\u81f4\u8f93\u51fa\u4e0d\u4e00\u81f4\u3002", "method": "\u4f7f\u7528\u8fed\u4ee3\u91cd\u5199\u6280\u672f\u8bc1\u660e\u6a21\u578b\u7ec6\u5316\uff0c\u5e76\u5728GraphGuard\u4e2d\u5b9e\u73b0\u8be5\u65b9\u6cd5\u3002", "result": "\u65b9\u6cd5\u53ef\u6269\u5c55\u5230GPT\u548cLlama-3\u7b49\u5927\u578b\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u9519\u8bef\u5b9a\u4f4d\u8f93\u51fa\u3002", "conclusion": "GraphGuard\u80fd\u6709\u6548\u8bc6\u522b\u5206\u5e03\u5f0f\u6a21\u578b\u4e2d\u7684\u9519\u8bef\uff0c\u5e76\u5e2e\u52a9\u5b9a\u4f4d\u95ee\u9898\u3002"}}
{"id": "2508.09160", "pdf": "https://arxiv.org/pdf/2508.09160", "abs": "https://arxiv.org/abs/2508.09160", "authors": ["Beyza Cinar", "Maria Maleshkova"], "title": "Presenting DiaData for Research on Type 1 Diabetes", "categories": ["cs.LG", "cs.DB", "q-bio.QM"], "comment": "11 pages, 7 figures, 3 tables", "summary": "Type 1 diabetes (T1D) is an autoimmune disorder that leads to the destruction\nof insulin-producing cells, resulting in insulin deficiency, as to why the\naffected individuals depend on external insulin injections. However, insulin\ncan decrease blood glucose levels and can cause hypoglycemia. Hypoglycemia is a\nsevere event of low blood glucose levels ($\\le$70 mg/dL) with dangerous side\neffects of dizziness, coma, or death. Data analysis can significantly enhance\ndiabetes care by identifying personal patterns and trends leading to adverse\nevents. Especially, machine learning (ML) models can predict glucose levels and\nprovide early alarms. However, diabetes and hypoglycemia research is limited by\nthe unavailability of large datasets. Thus, this work systematically integrates\n15 datasets to provide a large database of 2510 subjects with glucose\nmeasurements recorded every 5 minutes. In total, 149 million measurements are\nincluded, of which 4% represent values in the hypoglycemic range. Moreover, two\nsub-databases are extracted. Sub-database I includes demographics, and\nsub-database II includes heart rate data. The integrated dataset provides an\nequal distribution of sex and different age levels. As a further contribution,\ndata quality is assessed, revealing that data imbalance and missing values\npresent a significant challenge. Moreover, a correlation study on glucose\nlevels and heart rate data is conducted, showing a relation between 15 and 55\nminutes before hypoglycemia.", "AI": {"tldr": "\u672c\u6587\u6574\u5408\u4e8615\u4e2a\u6570\u636e\u96c6\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b2510\u540d\u53d7\u8bd5\u8005\u7684\u5927\u578b\u7cd6\u5c3f\u75c5\u6570\u636e\u5e93\uff0c\u7528\u4e8e\u7814\u7a76\u4f4e\u8840\u7cd6\u4e8b\u4ef6\uff0c\u5e76\u5206\u6790\u4e86\u6570\u636e\u8d28\u91cf\u4e0e\u8840\u7cd6\u4e0e\u5fc3\u7387\u7684\u5173\u7cfb\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u89e3\u51b3\u7cd6\u5c3f\u75c5\u7814\u7a76\u4e2d\u5927\u578b\u6570\u636e\u96c6\u7f3a\u4e4f\u7684\u95ee\u9898\uff0c\u4ee5\u63d0\u5347\u4f4e\u8840\u7cd6\u9884\u6d4b\u548c\u7ba1\u7406\u7684\u51c6\u786e\u6027\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u7cfb\u7edf\u6574\u540815\u4e2a\u6570\u636e\u96c6\uff0c\u6784\u5efa\u4e24\u4e2a\u5b50\u6570\u636e\u5e93\uff08\u4eba\u53e3\u7edf\u8ba1\u6570\u636e\u548c\u5fc3\u7387\u6570\u636e\uff09\uff0c\u5e76\u8fdb\u884c\u6570\u636e\u8d28\u91cf\u8bc4\u4f30\u4e0e\u76f8\u5173\u6027\u5206\u6790\u3002", "result": "\u7ed3\u679c\u5305\u62ec\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b149\u767e\u4e07\u6b21\u6d4b\u91cf\u7684\u6570\u636e\u5e93\uff0c\u53d1\u73b0\u6570\u636e\u4e0d\u5e73\u8861\u548c\u7f3a\u5931\u503c\u662f\u4e3b\u8981\u6311\u6218\uff0c\u5e76\u63ed\u793a\u4e86\u8840\u7cd6\u4e0e\u5fc3\u7387\u5728\u4f4e\u8840\u7cd6\u524d15\u81f355\u5206\u949f\u7684\u76f8\u5173\u6027\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8be5\u6570\u636e\u5e93\u4e3a\u7cd6\u5c3f\u75c5\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u540c\u65f6\u6570\u636e\u8d28\u91cf\u548c\u76f8\u5173\u6027\u5206\u6790\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2508.09366", "pdf": "https://arxiv.org/pdf/2508.09366", "abs": "https://arxiv.org/abs/2508.09366", "authors": ["Qiaolin Qin", "Xingfang Wu", "Heng Li", "Ettore Merlo"], "title": "Plug it and Play on Logs: A Configuration-Free Statistic-Based Log Parser", "categories": ["cs.SE", "D.2.5"], "comment": null, "summary": "Log parsing is an essential task in log analysis, and many tools have been\ndesigned to accomplish it. Existing log parsers can be categorized into\nstatistic-based and semantic-based approaches. In comparison to semantic-based\nparsers, existing statistic-based parsers tend to be more efficient, require\nlower computational costs, and be more privacy-preserving thanks to on-premise\ndeployment, but often fall short in their accuracy (e.g., grouping or parsing\naccuracy) and generalizability. Therefore, it became a common belief that\nstatistic-based parsers cannot be as effective as semantic-based parsers since\nthe latter could take advantage of external knowledge supported by pretrained\nlanguage models. Our work, however, challenges this belief with a novel\nstatistic-based parser, PIPLUP. PIPLUP eliminates the pre-assumption of the\nposition of constant tokens for log grouping and relies on data-insensitive\nparameters to overcome the generalizability challenge, allowing \"plug and play\"\non given log files. According to our experiments on an open-sourced large log\ndataset, PIPLUP shows promising accuracy and generalizability with the\ndata-insensitive default parameter set. PIPLUP not only outperforms the\nstate-of-the-art statistic-based log parsers, Drain and its variants, but also\nobtains a competitive performance compared to the best unsupervised\nsemantic-based log parser (i.e., LUNAR). Further, PIPLUP exhibits low time\nconsumption without GPU acceleration and external API usage; our simple,\nefficient, and effective approach makes it more practical in real-world\nadoptions, especially when costs and privacy are of major concerns.", "AI": {"tldr": "PIPLUP\u662f\u4e00\u79cd\u65b0\u578b\u7684\u7edf\u8ba1\u578b\u65e5\u5fd7\u89e3\u6790\u5668\uff0c\u6311\u6218\u4e86\u8bed\u4e49\u578b\u89e3\u6790\u5668\u66f4\u4f18\u7684\u666e\u904d\u89c2\u70b9\uff0c\u901a\u8fc7\u6570\u636e\u4e0d\u654f\u611f\u53c2\u6570\u5b9e\u73b0\u9ad8\u51c6\u786e\u6027\u548c\u901a\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u7edf\u8ba1\u578b\u65e5\u5fd7\u89e3\u6790\u5668\u5728\u51c6\u786e\u6027\u548c\u901a\u7528\u6027\u4e0a\u4e0d\u8db3\uff0c\u800c\u8bed\u4e49\u578b\u89e3\u6790\u5668\u4f9d\u8d56\u5916\u90e8\u77e5\u8bc6\uff0c\u6210\u672c\u9ad8\u4e14\u9690\u79c1\u6027\u5dee\u3002PIPLUP\u65e8\u5728\u63d0\u4f9b\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u4e14\u9690\u79c1\u53cb\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "PIPLUP\u6d88\u9664\u4e86\u5bf9\u5e38\u91cf\u4ee4\u724c\u4f4d\u7f6e\u7684\u9884\u8bbe\uff0c\u91c7\u7528\u6570\u636e\u4e0d\u654f\u611f\u53c2\u6570\uff0c\u5b9e\u73b0\u201c\u5373\u63d2\u5373\u7528\u201d\u7684\u65e5\u5fd7\u89e3\u6790\u3002", "result": "PIPLUP\u5728\u5927\u578b\u5f00\u6e90\u65e5\u5fd7\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u7edf\u8ba1\u578b\u89e3\u6790\u5668Drain\u53ca\u5176\u53d8\u4f53\uff0c\u5e76\u4e0e\u6700\u4f73\u65e0\u76d1\u7763\u8bed\u4e49\u578b\u89e3\u6790\u5668LUNAR\u7ade\u4e89\u3002", "conclusion": "PIPLUP\u662f\u4e00\u79cd\u7b80\u5355\u3001\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u65e5\u5fd7\u89e3\u6790\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6210\u672c\u4e0e\u9690\u79c1\u654f\u611f\u7684\u573a\u666f\u3002"}}
{"id": "2508.09422", "pdf": "https://arxiv.org/pdf/2508.09422", "abs": "https://arxiv.org/abs/2508.09422", "authors": ["Meghal Gupta", "William He", "Ryan O'Donnell", "Noah G. Singer"], "title": "A Classical Quadratic Speedup for Planted $k$XOR", "categories": ["cs.DS"], "comment": "22 pages", "summary": "A recent work of Schmidhuber et al (QIP, SODA, & Phys. Rev. X 2025) exhibited\na quantum algorithm for the noisy planted $k$XOR problem running quartically\nfaster than all known classical algorithms. In this work, we design a new\nclassical algorithm that is quadratically faster than the best previous one, in\nthe case of large constant $k$. Thus for such $k$, the quantum speedup of\nSchmidhuber et al. becomes only quadratic (though it retains a space\nadvantage). Our algorithm, which also works in the semirandom case, combines\ntools from sublinear-time algorithms (essentially, the birthday paradox) and\npolynomial anticoncentration.", "AI": {"tldr": "\u672c\u6587\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u7ecf\u5178\u7b97\u6cd5\uff0c\u5728\u5927\u578b\u5e38\u6570k\u7684\u60c5\u51b5\u4e0b\uff0c\u6bd4\u4e4b\u524d\u7684\u6700\u4f73\u7b97\u6cd5\u5feb\u4e8c\u6b21\u65b9\uff0c\u4ece\u800c\u5c06\u91cf\u5b50\u52a0\u901f\u4ece\u56db\u6b21\u65b9\u964d\u4f4e\u5230\u4e8c\u6b21\u65b9\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u7b97\u6cd5\u5728\u566a\u58f0\u79cd\u690dkXOR\u95ee\u9898\u4e0a\u7684\u4f18\u52bf\uff0c\u5e76\u63a2\u7d22\u7ecf\u5178\u7b97\u6cd5\u662f\u5426\u80fd\u7f29\u5c0f\u4e0e\u91cf\u5b50\u7b97\u6cd5\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "method": "\u7ed3\u5408\u4e9a\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\uff08\u751f\u65e5\u6096\u8bba\uff09\u548c\u591a\u9879\u5f0f\u53cd\u96c6\u4e2d\u5de5\u5177\uff0c\u8bbe\u8ba1\u65b0\u7b97\u6cd5\u3002", "result": "\u65b0\u7b97\u6cd5\u5728\u5927\u578b\u5e38\u6570k\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u4e8c\u6b21\u52a0\u901f\uff0c\u4e14\u9002\u7528\u4e8e\u534a\u968f\u673a\u60c5\u51b5\u3002", "conclusion": "\u7ecf\u5178\u7b97\u6cd5\u53ef\u4ee5\u663e\u8457\u7f29\u5c0f\u4e0e\u91cf\u5b50\u7b97\u6cd5\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u4f46\u4ecd\u4fdd\u7559\u91cf\u5b50\u7b97\u6cd5\u7684\u7a7a\u95f4\u4f18\u52bf\u3002"}}
{"id": "2508.09145", "pdf": "https://arxiv.org/pdf/2508.09145", "abs": "https://arxiv.org/abs/2508.09145", "authors": ["Xingle Xu", "Yongkang Liu", "Dexian Cai", "Shi Feng", "Xiaocui Yang", "Daling Wang", "Yifei Zhang"], "title": "MoLAN: A Unified Modality-Aware Noise Dynamic Editing Framework for Multimodal Sentiment Analysis", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": null, "summary": "Multimodal Sentiment Analysis aims to integrate information from various\nmodalities, such as audio, visual, and text, to make complementary predictions.\nHowever, it often struggles with irrelevant or misleading visual and auditory\ninformation. Most existing approaches typically treat the entire modality\ninformation (e.g., a whole image, audio segment, or text paragraph) as an\nindependent unit for feature enhancement or denoising. They often suppress the\nredundant and noise information at the risk of losing critical information. To\naddress this challenge, we propose MoLAN, a unified ModaLity-aware noise\ndynAmic editiNg framework. Specifically, MoLAN performs modality-aware blocking\nby dividing the features of each modality into multiple blocks. Each block is\nthen dynamically assigned a distinct denoising strength based on its noise\nlevel and semantic relevance, enabling fine-grained noise suppression while\npreserving essential multimodal information. Notably, MoLAN is a unified and\nflexible framework that can be seamlessly integrated into a wide range of\nmultimodal models. Building upon this framework, we further introduce MoLAN+, a\nnew multimodal sentiment analysis approach. Experiments across five models and\nfour datasets demonstrate the broad effectiveness of the MoLAN framework.\nExtensive evaluations show that MoLAN+ achieves the state-of-the-art\nperformance. The code is publicly available at\nhttps://github.com/betterfly123/MoLAN-Framework.", "AI": {"tldr": "MoLAN\u6846\u67b6\u901a\u8fc7\u6a21\u6001\u611f\u77e5\u7684\u52a8\u6001\u566a\u58f0\u7f16\u8f91\uff0c\u7ec6\u7c92\u5ea6\u5730\u6291\u5236\u566a\u58f0\u5e76\u4fdd\u7559\u5173\u952e\u4fe1\u606f\uff0cMoLAN+\u5728\u60c5\u611f\u5206\u6790\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\u56e0\u65e0\u5173\u6216\u8bef\u5bfc\u6027\u4fe1\u606f\u5bfc\u81f4\u7684\u95ee\u9898\uff0c\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u56e0\u5168\u5c40\u5904\u7406\u800c\u4e22\u5931\u5173\u952e\u4fe1\u606f\u3002", "method": "\u63d0\u51faMoLAN\u6846\u67b6\uff0c\u5c06\u6a21\u6001\u7279\u5f81\u5206\u5757\u5e76\u52a8\u6001\u5206\u914d\u53bb\u566a\u5f3a\u5ea6\uff0cMoLAN+\u57fa\u4e8e\u6b64\u6846\u67b6\u5b9e\u73b0\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86MoLAN\u7684\u5e7f\u6cdb\u6709\u6548\u6027\uff0cMoLAN+\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "MoLAN\u6846\u67b6\u7075\u6d3b\u4e14\u9ad8\u6548\uff0cMoLAN+\u5728\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\u8868\u73b0\u5353\u8d8a\u3002"}}
{"id": "2508.09591", "pdf": "https://arxiv.org/pdf/2508.09591", "abs": "https://arxiv.org/abs/2508.09591", "authors": ["Wenxiang Lin", "Xinglin Pan", "Lin Zhang", "Shaohuai Shi", "Xuan Wang", "Xiaowen Chu"], "title": "HierMoE: Accelerating MoE Training with Hierarchical Token Deduplication and Expert Swap", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "The sparsely activated mixture-of-experts (MoE) transformer has become a\ncommon architecture for large language models (LLMs) due to its sparsity, which\nrequires fewer computational demands while easily scaling the model size. In\nMoE models, each MoE layer requires to dynamically choose tokens to activate\nparticular experts for computation while the activated experts may not be\nlocated in the same device or GPU as the token. However, this leads to\nsubstantial communication and load imbalances across all GPUs, which obstructs\nthe scalability of distributed systems within a GPU cluster. To this end, we\nintroduce HierMoE to accelerate the training of MoE models by two\ntopology-aware techniques: 1) token deduplication to reduce the communication\ntraffic, and 2) expert swap to balance the workloads among all GPUs. To enable\nthe above two proposed approaches to be more general, we build theoretical\nmodels aimed at achieving the best token duplication and expert swap strategy\nunder different model configurations and hardware environments. We implement\nour prototype HierMoE system atop Megatron-LM and conduct experiments on a\n32-GPU cluster with DeepSeek-V3 and Qwen3-30B-A3B models. Experimental results\nshow that our HierMoE achieves $1.55\\times$ to $3.32\\times$ faster\ncommunication and delivers $1.18\\times$ to $1.27\\times$ faster end-to-end\ntraining compared to state-of-the-art MoE training systems, Tutel-2DH,\nSmartMoE, and Megatron-LM.", "AI": {"tldr": "HierMoE\u901a\u8fc7\u62d3\u6251\u611f\u77e5\u6280\u672f\uff08\u4ee4\u724c\u53bb\u91cd\u548c\u4e13\u5bb6\u4ea4\u6362\uff09\u4f18\u5316MoE\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u901a\u4fe1\u6548\u7387\u548c\u8d1f\u8f7d\u5747\u8861\u3002", "motivation": "MoE\u6a21\u578b\u5728\u5206\u5e03\u5f0fGPU\u96c6\u7fa4\u4e2d\u5b58\u5728\u901a\u4fe1\u548c\u8d1f\u8f7d\u4e0d\u5747\u8861\u95ee\u9898\uff0c\u963b\u788d\u4e86\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51faHierMoE\u7cfb\u7edf\uff0c\u91c7\u7528\u4ee4\u724c\u53bb\u91cd\u51cf\u5c11\u901a\u4fe1\u6d41\u91cf\uff0c\u4e13\u5bb6\u4ea4\u6362\u5e73\u8861GPU\u8d1f\u8f7d\uff0c\u5e76\u5efa\u7acb\u7406\u8bba\u6a21\u578b\u4f18\u5316\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cHierMoE\u5728\u901a\u4fe1\u548c\u7aef\u5230\u7aef\u8bad\u7ec3\u901f\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "conclusion": "HierMoE\u6709\u6548\u89e3\u51b3\u4e86MoE\u6a21\u578b\u7684\u6269\u5c55\u6027\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2508.09232", "pdf": "https://arxiv.org/pdf/2508.09232", "abs": "https://arxiv.org/abs/2508.09232", "authors": ["Nick Oh", "Giorgos D. Vrakas", "Si\u00e2n J. M. Brooke", "Sasha Morini\u00e8re", "Toju Duke"], "title": "PETLP: A Privacy-by-Design Pipeline for Social Media Data in AI Research", "categories": ["cs.MM", "cs.AI", "cs.DB"], "comment": null, "summary": "Social media data presents AI researchers with overlapping obligations under\nthe GDPR, copyright law, and platform terms -- yet existing frameworks fail to\nintegrate these regulatory domains, leaving researchers without unified\nguidance. We introduce PETLP (Privacy-by-design Extract, Transform, Load, and\nPresent), a compliance framework that embeds legal safeguards directly into\nextended ETL pipelines. Central to PETLP is treating Data Protection Impact\nAssessments as living documents that evolve from pre-registration through\ndissemination. Through systematic Reddit analysis, we demonstrate how\nextraction rights fundamentally differ between qualifying research\norganisations (who can invoke DSM Article 3 to override platform restrictions)\nand commercial entities (bound by terms of service), whilst GDPR obligations\napply universally. We reveal why true anonymisation remains unachievable for\nsocial media data and expose the legal gap between permitted dataset creation\nand uncertain model distribution. By structuring compliance decisions into\npractical workflows and simplifying institutional data management plans, PETLP\nenables researchers to navigate regulatory complexity with confidence, bridging\nthe gap between legal requirements and research practice.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86PETLP\u6846\u67b6\uff0c\u6574\u5408GDPR\u3001\u7248\u6743\u6cd5\u548c\u5e73\u53f0\u6761\u6b3e\uff0c\u4e3a\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u7814\u7a76\u63d0\u4f9b\u7edf\u4e00\u5408\u89c4\u6307\u5bfc\u3002", "motivation": "\u73b0\u6709\u6846\u67b6\u672a\u80fd\u6574\u5408\u4e0d\u540c\u6cd5\u89c4\u9886\u57df\uff0c\u5bfc\u81f4\u7814\u7a76\u4eba\u5458\u7f3a\u4e4f\u7edf\u4e00\u6307\u5bfc\u3002", "method": "\u5f15\u5165PETLP\u6846\u67b6\uff0c\u5c06\u6cd5\u5f8b\u4fdd\u969c\u5d4c\u5165ETL\u6d41\u7a0b\uff0c\u52a8\u6001\u66f4\u65b0\u6570\u636e\u4fdd\u62a4\u5f71\u54cd\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7Reddit\u5206\u6790\uff0c\u63ed\u793a\u7814\u7a76\u673a\u6784\u4e0e\u5546\u4e1a\u5b9e\u4f53\u5728\u6570\u636e\u63d0\u53d6\u6743\u5229\u4e0a\u7684\u5dee\u5f02\uff0c\u4ee5\u53caGDPR\u7684\u666e\u904d\u9002\u7528\u6027\u3002", "conclusion": "PETLP\u901a\u8fc7\u7ed3\u6784\u5316\u5408\u89c4\u51b3\u7b56\u548c\u7b80\u5316\u6570\u636e\u7ba1\u7406\u8ba1\u5212\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u5e94\u5bf9\u6cd5\u89c4\u590d\u6742\u6027\u3002"}}
{"id": "2508.09537", "pdf": "https://arxiv.org/pdf/2508.09537", "abs": "https://arxiv.org/abs/2508.09537", "authors": ["Yanzhou Li", "Tianlin Li", "Yiran Zhang", "Shangqing Liu", "Aishan Liu", "Yang Liu"], "title": "Your Coding Intent is Secretly in the Context and You Should Deliberately Infer It Before Completion", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly used for function completion in\nrepository-scale codebases. Prior studies demonstrate that when explicit\ninstructions--such as docstrings--are provided, these models can generate\nhighly accurate implementations. However, in real-world repositories, such\nannotations are frequently absent, and performance drops substantially without\nthem. To address this gap, we frame the task as a three-stage process. The\nfirst stage focuses on intent inference, where the model analyzes the code\npreceding the target function to uncover cues about the desired functionality.\nSuch preceding context often encodes subtle but critical information, and we\ndesign a reasoning-based prompting framework to guide the LLM through\nstep-by-step extraction and synthesis of these signals before any code is\ngenerated. The second stage introduces an optional interactive refinement\nmechanism to handle cases where preceding context alone is insufficient for\nintent recovery. In this stage, the model proposes a small set of candidate\nintentions, enabling the developer to select or edit them so that the inferred\nintent closely matches the actual requirement. Finally, in the third stage, the\nLLM generates the target function conditioned on the finalized intent. To\nsupport this pipeline, we curate a dataset of 40,000 examples annotated with\nintermediate reasoning traces and corresponding docstrings. Extensive\nexperiments on DevEval and ComplexCodeEval show that our approach consistently\nboosts multiple LLMs, achieving over 20\\% relative gains in both\nreference-based and execution-based metrics, with the interactive refinement\nstage delivering additional improvements beyond these gains.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e09\u9636\u6bb5\u65b9\u6cd5\uff0c\u901a\u8fc7\u610f\u56fe\u63a8\u65ad\u548c\u4ea4\u4e92\u5f0f\u4f18\u5316\u63d0\u5347LLM\u5728\u65e0\u6ce8\u91ca\u4ee3\u7801\u5e93\u4e2d\u7684\u51fd\u6570\u751f\u6210\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u4ee3\u7801\u5e93\u4e2d\u5e38\u7f3a\u5c11\u663e\u5f0f\u6ce8\u91ca\uff0c\u5bfc\u81f4LLM\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u89e3\u51b3\u65e0\u6ce8\u91ca\u65f6\u7684\u529f\u80fd\u63a8\u65ad\u95ee\u9898\u3002", "method": "\u5206\u4e09\u9636\u6bb5\uff1a1) \u610f\u56fe\u63a8\u65ad\uff0c\u5206\u6790\u4ee3\u7801\u4e0a\u4e0b\u6587\uff1b2) \u4ea4\u4e92\u5f0f\u4f18\u5316\uff0c\u5f00\u53d1\u8005\u53c2\u4e0e\u610f\u56fe\u4fee\u6b63\uff1b3) \u751f\u6210\u76ee\u6807\u51fd\u6570\u3002", "result": "\u5728DevEval\u548cComplexCodeEval\u4e0a\uff0c\u65b9\u6cd5\u663e\u8457\u63d0\u5347LLM\u6027\u80fd\uff0c\u76f8\u5bf9\u589e\u76ca\u8d8520%\u3002", "conclusion": "\u4e09\u9636\u6bb5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u6ce8\u91ca\u4ee3\u7801\u7684\u610f\u56fe\u63a8\u65ad\u95ee\u9898\uff0c\u4ea4\u4e92\u4f18\u5316\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u751f\u6210\u51c6\u786e\u6027\u3002"}}
{"id": "2508.09892", "pdf": "https://arxiv.org/pdf/2508.09892", "abs": "https://arxiv.org/abs/2508.09892", "authors": ["Lucas Castro", "Rosiane de Freitas"], "title": "Retroactive Monotonic Priority Queues via Range Searching", "categories": ["cs.DS", "cs.CG", "E.1; F.2"], "comment": "13 pages, 4 figures", "summary": "The best known fully retroactive priority queue costs $O(\\log^2 m \\log \\log\nm)$ time per operation, where $m$ is the number of operations performed on the\ndata structure. In contrast, standard (non-retroactive) and partially\nretroactive priority queues cost $O(\\log m)$ time per operation. So far, it is\nunknown whether this $O(\\log m)$ bound can be achieved for fully retroactive\npriority queues.\n  In this work, we study a restricted variant of priority queues known as\nmonotonic priority queues. We show that finding the minimum in a retroactive\nmonotonic priority queue is a special case of the range-searching problem. We\ndesign a fully retroactive monotonic priority queue with a cost of $O(\\log m +\nT(m))$ time per operation, where $T(m)$ is the maximum between the query and\nthe update time of a specific range-searching data structure with $m$ elements.\nFinally, we design a fully retroactive monotonic priority queue that costs\n$O(\\log m \\log \\log m)$ time per operation.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5355\u8c03\u4f18\u5148\u961f\u5217\u7684\u9650\u5236\u53d8\u4f53\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u56de\u6eaf\u7684\u5355\u8c03\u4f18\u5148\u961f\u5217\uff0c\u5176\u64cd\u4f5c\u65f6\u95f4\u4e3aO(log m + T(m))\uff0c\u5e76\u8fdb\u4e00\u6b65\u8bbe\u8ba1\u4e86\u4e00\u79cd\u64cd\u4f5c\u65f6\u95f4\u4e3aO(log m log log m)\u7684\u961f\u5217\u3002", "motivation": "\u76ee\u524d\u5b8c\u5168\u56de\u6eaf\u4f18\u5148\u961f\u5217\u7684\u64cd\u4f5c\u65f6\u95f4\u8f83\u9ad8\uff08O(log\u00b2 m log log m)\uff09\uff0c\u800c\u6807\u51c6\u548c\u975e\u5b8c\u5168\u56de\u6eaf\u961f\u5217\u4ec5\u4e3aO(log m)\uff0c\u56e0\u6b64\u63a2\u7d22\u662f\u5426\u80fd\u5b9e\u73b0O(log m)\u7684\u5b8c\u5168\u56de\u6eaf\u961f\u5217\u3002", "method": "\u5c06\u5355\u8c03\u4f18\u5148\u961f\u5217\u7684\u6700\u5c0f\u503c\u67e5\u627e\u95ee\u9898\u8f6c\u5316\u4e3a\u8303\u56f4\u641c\u7d22\u95ee\u9898\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8e\u7279\u5b9a\u8303\u56f4\u641c\u7d22\u6570\u636e\u7ed3\u6784\u7684\u5b8c\u5168\u56de\u6eaf\u5355\u8c03\u4f18\u5148\u961f\u5217\u3002", "result": "\u63d0\u51fa\u4e86\u4e24\u79cd\u5b8c\u5168\u56de\u6eaf\u5355\u8c03\u4f18\u5148\u961f\u5217\uff0c\u64cd\u4f5c\u65f6\u95f4\u5206\u522b\u4e3aO(log m + T(m))\u548cO(log m log log m)\u3002", "conclusion": "\u901a\u8fc7\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u8303\u56f4\u641c\u7d22\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u5b8c\u5168\u56de\u6eaf\u5355\u8c03\u4f18\u5148\u961f\u5217\uff0c\u4f46\u4ecd\u672a\u8fbe\u5230O(log m)\u7684\u76ee\u6807\u3002"}}
{"id": "2508.09146", "pdf": "https://arxiv.org/pdf/2508.09146", "abs": "https://arxiv.org/abs/2508.09146", "authors": ["Shugang Hao", "Hongbo Li", "Lingjie Duan"], "title": "To Theoretically Understand Transformer-Based In-Context Learning for Optimizing CSMA", "categories": ["cs.LG", "cs.AI", "cs.NI"], "comment": null, "summary": "The binary exponential backoff scheme is widely used in WiFi 7 and still\nincurs poor throughput performance under dynamic channel environments. Recent\nmodel-based approaches (e.g., non-persistent and $p$-persistent CSMA) simply\noptimize backoff strategies under a known and fixed node density, still leading\nto a large throughput loss due to inaccurate node density estimation. This\npaper is the first to propose LLM transformer-based in-context learning (ICL)\ntheory for optimizing channel access. We design a transformer-based ICL\noptimizer to pre-collect collision-threshold data examples and a query\ncollision case. They are constructed as a prompt as the input for the\ntransformer to learn the pattern, which then generates a predicted contention\nwindow threshold (CWT). To train the transformer for effective ICL, we develop\nan efficient algorithm and guarantee a near-optimal CWT prediction within\nlimited training steps. As it may be hard to gather perfect data examples for\nICL in practice, we further extend to allow erroneous data input in the prompt.\nWe prove that our optimizer maintains minimal prediction and throughput\ndeviations from the optimal values. Experimental results on NS-3 further\ndemonstrate our approach's fast convergence and near-optimal throughput over\nexisting model-based and DRL-based approaches under unknown node densities.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM transformer\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u7406\u8bba\uff0c\u7528\u4e8e\u4f18\u5316WiFi 7\u4e2d\u7684\u4fe1\u9053\u8bbf\u95ee\u3002\u901a\u8fc7\u9884\u6536\u96c6\u78b0\u649e\u9608\u503c\u6570\u636e\u793a\u4f8b\u548c\u67e5\u8be2\u78b0\u649e\u6848\u4f8b\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2atransformer-based ICL\u4f18\u5316\u5668\uff0c\u751f\u6210\u9884\u6d4b\u7684\u7ade\u4e89\u7a97\u53e3\u9608\u503c\uff08CWT\uff09\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u672a\u77e5\u8282\u70b9\u5bc6\u5ea6\u4e0b\u5177\u6709\u5feb\u901f\u6536\u655b\u548c\u63a5\u8fd1\u6700\u4f18\u7684\u541e\u5410\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u4e8c\u8fdb\u5236\u6307\u6570\u9000\u907f\u65b9\u6848\u5728\u52a8\u6001\u4fe1\u9053\u73af\u5883\u4e0b\u6027\u80fd\u8f83\u5dee\uff0c\u800c\u57fa\u4e8e\u6a21\u578b\u7684\u4f18\u5316\u65b9\u6cd5\u56e0\u8282\u70b9\u5bc6\u5ea6\u4f30\u8ba1\u4e0d\u51c6\u786e\u5bfc\u81f4\u541e\u5410\u91cf\u635f\u5931\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2atransformer-based ICL\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u9884\u6536\u96c6\u78b0\u649e\u9608\u503c\u6570\u636e\u793a\u4f8b\u548c\u67e5\u8be2\u78b0\u649e\u6848\u4f8b\u4f5c\u4e3a\u8f93\u5165\u63d0\u793a\uff0c\u751f\u6210\u9884\u6d4b\u7684CWT\u3002\u5e76\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u8bad\u7ec3\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u672a\u77e5\u8282\u70b9\u5bc6\u5ea6\u4e0b\u80fd\u5feb\u901f\u6536\u655b\uff0c\u4e14\u541e\u5410\u91cf\u63a5\u8fd1\u6700\u4f18\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u6a21\u578b\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684transformer-based ICL\u4f18\u5316\u5668\u5728\u52a8\u6001\u4fe1\u9053\u73af\u5883\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u541e\u5410\u91cf\u6027\u80fd\uff0c\u4e14\u5bf9\u8f93\u5165\u6570\u636e\u7684\u5bb9\u9519\u6027\u5f3a\u3002"}}
{"id": "2508.09663", "pdf": "https://arxiv.org/pdf/2508.09663", "abs": "https://arxiv.org/abs/2508.09663", "authors": ["Philipp A. Friese", "Ahmed Eleliemy", "Utz-Uwe Haus", "Martin Schulz"], "title": "Closing the HPC-Cloud Convergence Gap: Multi-Tenant Slingshot RDMA for Kubernetes", "categories": ["cs.DC", "cs.NI"], "comment": "10 pages, 12 figures, 1 table, 3 listings, to be published in IEEE\n  Cluster 2025", "summary": "Converged HPC-Cloud computing is an emerging computing paradigm that aims to\nsupport increasingly complex and multi-tenant scientific workflows. These\nsystems require reconciliation of the isolation requirements of native cloud\nworkloads and the performance demands of HPC applications. In this context,\nnetworking hardware is a critical boundary component: it is the conduit for\nhigh-throughput, low-latency communication and enables isolation across\ntenants. HPE Slingshot is a high-speed network interconnect that provides up to\n200 Gbps of throughput per port and targets high-performance computing (HPC)\nsystems. The Slingshot host software, including hardware drivers and network\nmiddleware libraries, is designed to meet HPC deployments, which predominantly\nuse single-tenant access modes. Hence, the Slingshot stack is not suited for\nsecure use in multi-tenant deployments, such as converged HPC-Cloud\ndeployments. In this paper, we design and implement an extension to the\nSlingshot stack targeting converged deployments on the basis of Kubernetes. Our\nintegration provides secure, container-granular, and multi-tenant access to\nSlingshot RDMA networking capabilities at minimal overhead.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9HPE Slingshot\u7f51\u7edc\u7684\u6269\u5c55\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u591a\u79df\u6237\u7684HPC-Cloud\u878d\u5408\u90e8\u7f72\uff0c\u57fa\u4e8eKubernetes\u5b9e\u73b0\u5b89\u5168\u3001\u4f4e\u5f00\u9500\u7684\u5bb9\u5668\u7ea7\u8bbf\u95ee\u3002", "motivation": "HPC-Cloud\u878d\u5408\u8ba1\u7b97\u9700\u8981\u6ee1\u8db3\u591a\u79df\u6237\u9694\u79bb\u548c\u9ad8\u6027\u80fd\u9700\u6c42\uff0c\u4f46\u73b0\u6709Slingshot\u8f6f\u4ef6\u6808\u4ec5\u652f\u6301\u5355\u79df\u6237\u6a21\u5f0f\uff0c\u65e0\u6cd5\u9002\u5e94\u878d\u5408\u90e8\u7f72\u7684\u5b89\u5168\u9700\u6c42\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8eKubernetes\u7684Slingshot\u6269\u5c55\uff0c\u63d0\u4f9b\u5bb9\u5668\u7ea7\u3001\u591a\u79df\u6237\u7684RDMA\u7f51\u7edc\u8bbf\u95ee\u80fd\u529b\u3002", "result": "\u6269\u5c55\u5b9e\u73b0\u4e86\u5b89\u5168\u7684\u591a\u79df\u6237\u8bbf\u95ee\uff0c\u4e14\u6027\u80fd\u5f00\u9500\u6781\u4f4e\u3002", "conclusion": "\u8be5\u6269\u5c55\u6210\u529f\u89e3\u51b3\u4e86Slingshot\u5728\u591a\u79df\u6237\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\u95ee\u9898\uff0c\u4e3aHPC-Cloud\u878d\u5408\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.09147", "pdf": "https://arxiv.org/pdf/2508.09147", "abs": "https://arxiv.org/abs/2508.09147", "authors": ["Alaa Saleh", "Roberto Morabito", "Sasu Tarkoma", "Anders Lindgren", "Susanna Pirttikangas", "Lauri Lov\u00e9n"], "title": "Agentic TinyML for Intent-aware Handover in 6G Wireless Networks", "categories": ["cs.NI", "cs.AI", "cs.DC", "cs.LG", "cs.MA"], "comment": null, "summary": "As 6G networks evolve into increasingly AI-driven, user-centric ecosystems,\ntraditional reactive handover mechanisms demonstrate limitations, especially in\nmobile edge computing and autonomous agent-based service scenarios. This\nmanuscript introduces WAAN, a cross-layer framework that enables intent-aware\nand proactive handovers by embedding lightweight TinyML agents as autonomous,\nnegotiation-capable entities across heterogeneous edge nodes that contribute to\nintent propagation and network adaptation. To ensure continuity across\nmobility-induced disruptions, WAAN incorporates semi-stable rendezvous points\nthat serve as coordination anchors for context transfer and state preservation.\nThe framework's operational capabilities are demonstrated through a multimodal\nenvironmental control case study, highlighting its effectiveness in maintaining\nuser experience under mobility. Finally, the article discusses key challenges\nand future opportunities associated with the deployment and evolution of WAAN.", "AI": {"tldr": "WAAN\u6846\u67b6\u901a\u8fc7\u5d4c\u5165\u8f7b\u91cf\u7ea7TinyML\u4ee3\u7406\uff0c\u5b9e\u73b0\u610f\u56fe\u611f\u77e5\u548c\u4e3b\u52a8\u5207\u6362\uff0c\u89e3\u51b3\u4e866G\u7f51\u7edc\u4e2d\u4f20\u7edf\u5207\u6362\u673a\u5236\u7684\u5c40\u9650\u6027\u3002", "motivation": "6G\u7f51\u7edc\u4e2d\u4f20\u7edf\u53cd\u5e94\u5f0f\u5207\u6362\u673a\u5236\u5728\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u548c\u81ea\u4e3b\u4ee3\u7406\u670d\u52a1\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u8db3\u3002", "method": "WAAN\u6846\u67b6\u5229\u7528TinyML\u4ee3\u7406\u4f5c\u4e3a\u81ea\u4e3b\u534f\u5546\u5b9e\u4f53\uff0c\u8de8\u5f02\u6784\u8fb9\u7f18\u8282\u70b9\u5b9e\u73b0\u610f\u56fe\u4f20\u64ad\u548c\u7f51\u7edc\u9002\u914d\uff0c\u5e76\u5f15\u5165\u534a\u7a33\u5b9a\u4f1a\u5408\u70b9\u786e\u4fdd\u8fde\u7eed\u6027\u3002", "result": "\u901a\u8fc7\u591a\u6a21\u6001\u73af\u5883\u63a7\u5236\u6848\u4f8b\u7814\u7a76\uff0c\u8bc1\u660e\u4e86WAAN\u5728\u79fb\u52a8\u6027\u4e0b\u7ef4\u6301\u7528\u6237\u4f53\u9a8c\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6587\u7ae0\u8ba8\u8bba\u4e86WAAN\u90e8\u7f72\u548c\u6f14\u8fdb\u4e2d\u7684\u5173\u952e\u6311\u6218\u4e0e\u672a\u6765\u673a\u9047\u3002"}}
{"id": "2508.09403", "pdf": "https://arxiv.org/pdf/2508.09403", "abs": "https://arxiv.org/abs/2508.09403", "authors": ["Ting Cai", "Stephen Sheen", "AnHai Doan"], "title": "Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models", "categories": ["cs.CL", "cs.DB"], "comment": null, "summary": "Expanding the abbreviated column names of tables, such as ``esal'' to\n``employee salary'', is critical for numerous downstream data tasks. This\nproblem arises in enterprises, domain sciences, government agencies, and more.\nIn this paper we make three contributions that significantly advances the state\nof the art. First, we show that synthetic public data used by prior work has\nmajor limitations, and we introduce 4 new datasets in enterprise/science\ndomains, with real-world abbreviations. Second, we show that accuracy measures\nused by prior work seriously undercount correct expansions, and we propose new\nsynonym-aware measures that capture accuracy much more accurately. Finally, we\ndevelop Columbo, a powerful LLM-based solution that exploits context, rules,\nchain-of-thought reasoning, and token-level analysis. Extensive experiments\nshow that Columbo significantly outperforms NameGuess, the current most\nadvanced solution, by 4-29\\%, over 5 datasets. Columbo has been used in\nproduction on EDI, a major data portal for environmental sciences.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faColumbo\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u8868\u683c\u5217\u540d\u7f29\u5199\u6269\u5c55\u7684\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u65b9\u6cd54-29%\u3002", "motivation": "\u89e3\u51b3\u8868\u683c\u5217\u540d\u7f29\u5199\u6269\u5c55\u95ee\u9898\uff0c\u56e0\u73b0\u6709\u65b9\u6cd5\u5728\u5408\u6210\u6570\u636e\u548c\u51c6\u786e\u6027\u8bc4\u4f30\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5f15\u51654\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u65b0\u51c6\u786e\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5f00\u53d1\u57fa\u4e8eLLM\u7684Columbo\u89e3\u51b3\u65b9\u6848\u3002", "result": "Columbo\u57285\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u65b9\u6cd5NameGuess\u3002", "conclusion": "Columbo\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5df2\u5728\u73af\u5883\u79d1\u5b66\u6570\u636e\u95e8\u6237EDI\u4e2d\u6295\u5165\u4f7f\u7528\u3002"}}
{"id": "2508.09648", "pdf": "https://arxiv.org/pdf/2508.09648", "abs": "https://arxiv.org/abs/2508.09648", "authors": ["Taohong Zhu", "Lucas C. Cordeiro", "Youcheng Sun"], "title": "ReqInOne: A Large Language Model-Based Agent for Software Requirements Specification Generation", "categories": ["cs.SE"], "comment": null, "summary": "Software Requirements Specification (SRS) is one of the most important\ndocuments in software projects, but writing it manually is time-consuming and\noften leads to ambiguity. Existing automated methods rely heavily on manual\nanalysis, while recent Large Language Model (LLM)-based approaches suffer from\nhallucinations and limited controllability. In this paper, we propose ReqInOne,\nan LLM-based agent that follows the common steps taken by human requirements\nengineers when writing an SRS to convert natural language into a structured\nSRS. ReqInOne adopts a modular architecture by decomposing SRS generation into\nthree tasks: summary, requirement extraction, and requirement classification,\neach supported by tailored prompt templates to improve the quality and\nconsistency of LLM outputs.\n  We evaluate ReqInOne using GPT-4o, LLaMA 3, and DeepSeek-R1, and compare the\ngenerated SRSs against those produced by the holistic GPT-4-based method from\nprior work as well as by entry-level requirements engineers. Expert evaluations\nshow that ReqInOne produces more accurate and well-structured SRS documents.\nThe performance advantage of ReqInOne benefits from its modular design, and\nexperimental results further demonstrate that its requirement classification\ncomponent achieves comparable or even better results than the state-of-the-art\nrequirement classification model.", "AI": {"tldr": "ReqInOne\u662f\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u4ee3\u7406\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u5c06\u81ea\u7136\u8bed\u8a00\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316SRS\uff0c\u751f\u6210\u66f4\u51c6\u786e\u548c\u7ed3\u6784\u5316\u7684\u6587\u6863\u3002", "motivation": "\u624b\u52a8\u7f16\u5199SRS\u8017\u65f6\u4e14\u6613\u4ea7\u751f\u6b67\u4e49\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u5206\u6790\uff0cLLM\u65b9\u6cd5\u5b58\u5728\u5e7b\u89c9\u548c\u53ef\u63a7\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "ReqInOne\u5c06SRS\u751f\u6210\u5206\u89e3\u4e3a\u6458\u8981\u3001\u9700\u6c42\u63d0\u53d6\u548c\u9700\u6c42\u5206\u7c7b\u4e09\u4e2a\u4efb\u52a1\uff0c\u6bcf\u4e2a\u4efb\u52a1\u4f7f\u7528\u5b9a\u5236\u63d0\u793a\u6a21\u677f\u3002", "result": "ReqInOne\u751f\u6210\u7684SRS\u6bd4GPT-4\u65b9\u6cd5\u548c\u521d\u7ea7\u5de5\u7a0b\u5e08\u66f4\u51c6\u786e\u548c\u7ed3\u6784\u5316\uff0c\u9700\u6c42\u5206\u7c7b\u7ec4\u4ef6\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "\u6a21\u5757\u5316\u8bbe\u8ba1\u4f7fReqInOne\u5728SRS\u751f\u6210\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u9700\u6c42\u5206\u7c7b\u7ec4\u4ef6\u8fbe\u5230\u6216\u8d85\u8d8a\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2508.09592", "pdf": "https://arxiv.org/pdf/2508.09592", "abs": "https://arxiv.org/abs/2508.09592", "authors": ["Licheng Liu", "Mingda Qiao"], "title": "Online Prediction with Limited Selectivity", "categories": ["cs.LG", "cs.DS"], "comment": null, "summary": "Selective prediction [Dru13, QV19] models the scenario where a forecaster\nfreely decides on the prediction window that their forecast spans. Many data\nstatistics can be predicted to a non-trivial error rate without any\ndistributional assumptions or expert advice, yet these results rely on that the\nforecaster may predict at any time. We introduce a model of Prediction with\nLimited Selectivity (PLS) where the forecaster can start the prediction only on\na subset of the time horizon. We study the optimal prediction error both on an\ninstance-by-instance basis and via an average-case analysis. We introduce a\ncomplexity measure that gives instance-dependent bounds on the optimal error.\nFor a randomly-generated PLS instance, these bounds match with high\nprobability.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u9650\u9009\u62e9\u6027\u9884\u6d4b\u6a21\u578b\uff08PLS\uff09\uff0c\u7814\u7a76\u9884\u6d4b\u8bef\u5dee\u7684\u6700\u4f18\u89e3\uff0c\u5e76\u5f15\u5165\u590d\u6742\u5ea6\u5ea6\u91cf\u6765\u63d0\u4f9b\u5b9e\u4f8b\u4f9d\u8d56\u7684\u8bef\u5dee\u754c\u9650\u3002", "motivation": "\u7814\u7a76\u5728\u9884\u6d4b\u7a97\u53e3\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u4f18\u5316\u9884\u6d4b\u8bef\u5dee\uff0c\u5f25\u8865\u73b0\u6709\u65b9\u6cd5\u5bf9\u4efb\u610f\u65f6\u95f4\u9884\u6d4b\u7684\u4f9d\u8d56\u3002", "method": "\u63d0\u51faPLS\u6a21\u578b\uff0c\u901a\u8fc7\u5b9e\u4f8b\u5206\u6790\u548c\u5e73\u5747\u6848\u4f8b\u5206\u6790\u7814\u7a76\u6700\u4f18\u9884\u6d4b\u8bef\u5dee\uff0c\u5e76\u5f15\u5165\u590d\u6742\u5ea6\u5ea6\u91cf\u3002", "result": "\u590d\u6742\u5ea6\u5ea6\u91cf\u63d0\u4f9b\u4e86\u5b9e\u4f8b\u4f9d\u8d56\u7684\u8bef\u5dee\u754c\u9650\uff0c\u4e14\u5728\u968f\u673a\u751f\u6210\u7684PLS\u5b9e\u4f8b\u4e2d\u9ad8\u6982\u7387\u5339\u914d\u3002", "conclusion": "PLS\u6a21\u578b\u4e3a\u6709\u9650\u9009\u62e9\u6027\u9884\u6d4b\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u590d\u6742\u5ea6\u5ea6\u91cf\u662f\u6709\u6548\u7684\u5de5\u5177\u3002"}}
{"id": "2508.09148", "pdf": "https://arxiv.org/pdf/2508.09148", "abs": "https://arxiv.org/abs/2508.09148", "authors": ["Junghwan Lim", "Sungmin Lee", "Dongseok Kim", "Eunhwan Park", "Hyunbyung Park", "Junhyeok Lee", "Wai Ting Cheung", "Dahye Choi", "Jaeheui Her", "Jaeyeon Huh", "Hanbin Jung", "Changjin Kang", "Beomgyu Kim", "Jihwan Kim", "Minjae Kim", "Taehwan Kim", "Youngrok Kim", "Haesol Lee", "Jeesoo Lee", "Kungyu Lee", "Dongpin Oh", "Yeongjae Park", "Bokki Ryu", "Daewon Suh", "Dongjoo Weon"], "title": "Motif 2.6B Technical Report", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have revolutionized\nartificial intelligence, yet developing an effective foundational LLM that\nbalances high performance with computational efficiency remains challenging,\nespecially for emerging research groups. To address this gap, we introduce\nMotif-2.6B, a 2.6-billion-parameter foundation model designed to democratize\nadvanced LLM capabilities. Motif-2.6B incorporates several innovative\narchitectural enhancements, including Differential Attention and PolyNorm\nactivation functions, which improve long-context comprehension, reduce\nhallucination, and enhance in-context learning capabilities. We rigorously\ntested multiple novel architectural components through extensive\nexperimentation to determine the optimal architecture for Motif-2.6B.\nComprehensive evaluations demonstrate that Motif-2.6B consistently meets or\nexceeds the performance of similarly sized state-of-the-art models across\ndiverse benchmarks, showcasing its effectiveness, scalability, and real-world\napplicability. Through detailed experiments and tailored techniques, Motif-2.6B\nsignificantly advances the landscape of efficient, scalable, and powerful\nfoundational LLMs, offering valuable insights and a robust foundation for\nfuture research and deployment.", "AI": {"tldr": "Motif-2.6B\u662f\u4e00\u4e2a2.6B\u53c2\u6570\u7684\u57fa\u7840\u6a21\u578b\uff0c\u65e8\u5728\u5e73\u8861\u9ad8\u6027\u80fd\u4e0e\u8ba1\u7b97\u6548\u7387\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u67b6\u6784\u6539\u8fdb\uff08\u5982Differential Attention\u548cPolyNorm\u6fc0\u6d3b\u51fd\u6570\uff09\u63d0\u5347\u957f\u6587\u672c\u7406\u89e3\u3001\u51cf\u5c11\u5e7b\u89c9\u5e76\u589e\u5f3a\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u65b0\u5174\u7814\u7a76\u56e2\u961f\u5728\u5f00\u53d1\u9ad8\u6027\u80fd\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u57fa\u7840LLM\u65f6\u7684\u6311\u6218\uff0c\u63a8\u52a8\u5148\u8fdbLLM\u6280\u672f\u7684\u666e\u53ca\u3002", "method": "\u5f15\u5165\u521b\u65b0\u7684\u67b6\u6784\u7ec4\u4ef6\uff08\u5982Differential Attention\u548cPolyNorm\uff09\uff0c\u5e76\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u6700\u4f18\u67b6\u6784\u3002", "result": "Motif-2.6B\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u6216\u5ab2\u7f8e\u540c\u7c7b\u5148\u8fdb\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5176\u9ad8\u6548\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "Motif-2.6B\u4e3a\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u5f3a\u5927\u7684\u57fa\u7840LLM\u63d0\u4f9b\u4e86\u91cd\u8981\u8fdb\u5c55\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u548c\u90e8\u7f72\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2508.09149", "pdf": "https://arxiv.org/pdf/2508.09149", "abs": "https://arxiv.org/abs/2508.09149", "authors": ["Seyed Hossein Ahmadpanah"], "title": "Semantic-Aware LLM Orchestration for Proactive Resource Management in Predictive Digital Twin Vehicular Networks", "categories": ["cs.NI", "cs.DC"], "comment": null, "summary": "Next-generation automotive applications require vehicular edge computing\n(VEC), but current management systems are essentially fixed and reactive. They\nare suboptimal in extremely dynamic vehicular environments because they are\nconstrained to static optimization objectives and base their decisions on the\ncurrent network states. This paper presents a novel Semantic-Aware Proactive\nLLM Orchestration (SP-LLM) framework to address these issues. Our method\ntransforms the traditional Digital Twin (DT) into a Predictive Digital Twin\n(pDT) that predicts important network parameters such as task arrivals, vehicle\nmobility, and channel quality. A Large Language Model (LLM) that serves as a\ncognitive orchestrator is at the heart of our framework. It makes proactive,\nforward-looking decisions about task offloading and resource allocation by\nutilizing the pDT's forecasts. The LLM's ability to decipher high-level\nsemantic commands given in natural language is crucial because it enables it to\ndynamically modify its optimization policy to match evolving strategic\nobjectives, like giving emergency services priority or optimizing energy\nefficiency. We show through extensive simulations that SP-LLM performs\nsignificantly better in terms of scalability, robustness in volatile\nconditions, and adaptability than state-of-the-art reactive and MARL-based\napproaches. More intelligent, autonomous, and goal-driven vehicular networks\nwill be possible due to our framework's outstanding capacity to convert human\nintent into optimal network behavior.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u611f\u77e5\u7684\u4e3b\u52a8LLM\u7f16\u6392\u6846\u67b6\uff08SP-LLM\uff09\uff0c\u7528\u4e8e\u4f18\u5316\u52a8\u6001\u8f66\u8f7d\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u4efb\u52a1\u5378\u8f7d\u548c\u8d44\u6e90\u5206\u914d\u3002", "motivation": "\u5f53\u524d\u8f66\u8f7d\u8fb9\u7f18\u8ba1\u7b97\u7ba1\u7406\u7cfb\u7edf\u5728\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u5b83\u4eec\u57fa\u4e8e\u9759\u6001\u4f18\u5316\u76ee\u6807\u548c\u5f53\u524d\u7f51\u7edc\u72b6\u6001\u505a\u51fa\u53cd\u5e94\u6027\u51b3\u7b56\u3002", "method": "\u901a\u8fc7\u5c06\u4f20\u7edf\u6570\u5b57\u5b6a\u751f\uff08DT\uff09\u5347\u7ea7\u4e3a\u9884\u6d4b\u6027\u6570\u5b57\u5b6a\u751f\uff08pDT\uff09\uff0c\u5e76\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f5c\u4e3a\u8ba4\u77e5\u7f16\u6392\u5668\uff0c\u5b9e\u73b0\u524d\u77bb\u6027\u51b3\u7b56\u3002", "result": "SP-LLM\u5728\u53ef\u6269\u5c55\u6027\u3001\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u5c06\u4eba\u7c7b\u610f\u56fe\u8f6c\u5316\u4e3a\u6700\u4f18\u7f51\u7edc\u884c\u4e3a\uff0c\u4e3a\u66f4\u667a\u80fd\u3001\u81ea\u4e3b\u548c\u76ee\u6807\u9a71\u52a8\u7684\u8f66\u8f7d\u7f51\u7edc\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2508.09676", "pdf": "https://arxiv.org/pdf/2508.09676", "abs": "https://arxiv.org/abs/2508.09676", "authors": ["Vishal Khare", "Vijay Saini", "Deepak Sharma", "Anand Kumar", "Ankit Rana", "Anshul Yadav"], "title": "DeputyDev -- AI Powered Developer Assistant: Breaking the Code Review Logjam through Contextual AI to Boost Developer Productivity", "categories": ["cs.SE", "cs.LG"], "comment": "12 pages, 5 figures, 6 pages of supplementary materials", "summary": "This study investigates the implementation and efficacy of DeputyDev, an\nAI-powered code review assistant developed to address inefficiencies in the\nsoftware development process. The process of code review is highly inefficient\nfor several reasons, such as it being a time-consuming process, inconsistent\nfeedback, and review quality not being at par most of the time. Using our\ntelemetry data, we observed that at TATA 1mg, pull request (PR) processing\nexhibits significant inefficiencies, with average pick-up and review times of\n73 and 82 hours, respectively, resulting in a 6.2 day closure cycle. The review\ncycle was marked by prolonged iterative communication between the reviewing and\nsubmitting parties. Research from the University of California, Irvine\nindicates that interruptions can lead to an average of 23 minutes of lost\nfocus, critically affecting code quality and timely delivery. To address these\nchallenges, we developed DeputyDev's PR review capabilities by providing\nautomated, contextual code reviews. We conducted a rigorous double-controlled\nA/B experiment involving over 200 engineers to evaluate DeputyDev's impact on\nreview times. The results demonstrated a statistically significant reduction in\nboth average per PR (23.09%) and average per-line-of-code (40.13%) review\ndurations. After implementing safeguards to exclude outliers, DeputyDev has\nbeen effectively rolled out across the entire organisation. Additionally, it\nhas been made available to external companies as a Software-as-a-Service (SaaS)\nsolution, currently supporting the daily work of numerous engineering\nprofessionals. This study explores the implementation and effectiveness of\nAI-assisted code reviews in improving development workflow timelines and code.", "AI": {"tldr": "DeputyDev\u662f\u4e00\u4e2aAI\u9a71\u52a8\u7684\u4ee3\u7801\u5ba1\u67e5\u52a9\u624b\uff0c\u65e8\u5728\u89e3\u51b3\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u4f4e\u6548\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u5ba1\u67e5\u65f6\u95f4\u3002", "motivation": "\u4ee3\u7801\u5ba1\u67e5\u8fc7\u7a0b\u4f4e\u6548\uff0c\u5305\u62ec\u8017\u65f6\u957f\u3001\u53cd\u9988\u4e0d\u4e00\u81f4\u548c\u8d28\u91cf\u4e0d\u7a33\u5b9a\u3002TATA 1mg\u7684\u6570\u636e\u663e\u793aPR\u5904\u7406\u5468\u671f\u957f\uff0c\u5f71\u54cd\u5f00\u53d1\u6548\u7387\u3002", "method": "\u5f00\u53d1\u4e86DeputyDev\u7684PR\u5ba1\u67e5\u529f\u80fd\uff0c\u63d0\u4f9b\u81ea\u52a8\u5316\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4ee3\u7801\u5ba1\u67e5\uff0c\u5e76\u901a\u8fc7\u53cc\u76f2A/B\u5b9e\u9a8c\u9a8c\u8bc1\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6bcfPR\u5ba1\u67e5\u65f6\u95f4\u51cf\u5c1123.09%\uff0c\u6bcf\u884c\u4ee3\u7801\u5ba1\u67e5\u65f6\u95f4\u51cf\u5c1140.13%\u3002", "conclusion": "DeputyDev\u6210\u529f\u63d0\u5347\u4e86\u5ba1\u67e5\u6548\u7387\uff0c\u5e76\u5df2\u4f5c\u4e3aSaaS\u89e3\u51b3\u65b9\u6848\u63a8\u5e7f\u81f3\u5916\u90e8\u516c\u53f8\u3002"}}
{"id": "2508.09153", "pdf": "https://arxiv.org/pdf/2508.09153", "abs": "https://arxiv.org/abs/2508.09153", "authors": ["TaekHyun Park", "Yongjae Lee", "Daesan Park", "Dohee Kim", "Hyerim Bae"], "title": "JustDense: Just using Dense instead of Sequence Mixer for Time Series analysis", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages ,planning to submit to IEEE BigData 2025", "summary": "Sequence and channel mixers, the core mechanism in sequence models, have\nbecome the de facto standard in time series analysis (TSA). However, recent\nstudies have questioned the necessity of complex sequence mixers, such as\nattention mechanisms, demonstrating that simpler architectures can achieve\ncomparable or even superior performance. This suggests that the benefits\nattributed to complex sequencemixers might instead emerge from other\narchitectural or optimization factors. Based on this observation, we pose a\ncentral question: Are common sequence mixers necessary for time-series\nanalysis? Therefore, we propose JustDense, an empirical study that\nsystematically replaces sequence mixers in various well-established TSA models\nwith dense layers. Grounded in the MatrixMixer framework, JustDense treats any\nsequence mixer as a mixing matrix and replaces it with a dense layer. This\nsubstitution isolates the mixing operation, enabling a clear theoretical\nfoundation for understanding its role. Therefore, we conducted extensive\nexperiments on 29 benchmarks covering five representative TSA tasks using seven\nstate-of-the-art TSA models to address our research question. The results show\nthat replacing sequence mixers with dense layers yields comparable or even\nsuperior performance. In the cases where dedicated sequence mixers still offer\nbenefits, JustDense challenges the assumption that \"deeper and more complex\narchitectures are inherently better\" in TSA.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u7b80\u5355\u5bc6\u96c6\u5c42\u53ef\u4ee5\u66ff\u4ee3\u590d\u6742\u5e8f\u5217\u6df7\u5408\u5668\uff0c\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u8868\u73b0\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u3002", "motivation": "\u8d28\u7591\u590d\u6742\u5e8f\u5217\u6df7\u5408\u5668\uff08\u5982\u6ce8\u610f\u529b\u673a\u5236\uff09\u7684\u5fc5\u8981\u6027\uff0c\u63a2\u7d22\u5176\u6027\u80fd\u662f\u5426\u6e90\u4e8e\u5176\u4ed6\u56e0\u7d20\u3002", "method": "\u63d0\u51faJustDense\uff0c\u7528\u5bc6\u96c6\u5c42\u66ff\u6362\u5e8f\u5217\u6df7\u5408\u5668\uff0c\u57fa\u4e8eMatrixMixer\u6846\u67b6\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u572829\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5bc6\u96c6\u5c42\u8868\u73b0\u4e0e\u590d\u6742\u6df7\u5408\u5668\u76f8\u5f53\u6216\u66f4\u4f18\u3002", "conclusion": "\u6311\u6218\u4e86\u201c\u66f4\u6df1\u66f4\u590d\u6742\u67b6\u6784\u5fc5\u7136\u66f4\u597d\u201d\u7684\u5047\u8bbe\uff0c\u7b80\u5316\u6a21\u578b\u53ef\u80fd\u66f4\u6709\u6548\u3002"}}
{"id": "2508.09150", "pdf": "https://arxiv.org/pdf/2508.09150", "abs": "https://arxiv.org/abs/2508.09150", "authors": ["Pietro Piscione", "Leonardo Lossi", "Maziar Nekovee", "Chathura Galkandage", "Phil O Connor", "Simon Davies"], "title": "Enabling On-demand Guaranteed QoS for Real Time Video Streaming from Vehicles in 5G Advanced with CAPIF & NEF APIs", "categories": ["cs.NI"], "comment": "Published in the Proceedings of 2025 EuCNC & 6G Summit, Pozna\\'n,\n  Poland, 3-6 June 2025", "summary": "This paper presents the design and implementation of a Proof of Concept (PoC)\nthat demonstrates how 5G Advanced Network Functions can be integrated with the\nCommon API Framework (CAPIF) to support enhanced connectivity for automotive\napplications. The PoC shows the continuous monitoring of the mobile network\nperformance and the on-demand and dynamic adaptation of Quality of Service\n(QoS) for selected 5G User Equipment (UE) video streaming traffic flows using\nstandard 3GPP Network Exposure Function (NEF) APIs exposed via CAPIF. Moreover,\ntraffic flows are redirected to the edge to improve latency and optimize\nnetwork resource utilization.", "AI": {"tldr": "\u8bba\u6587\u5c55\u793a\u4e86\u4e00\u4e2a\u6982\u5ff5\u9a8c\u8bc1\uff08PoC\uff09\uff0c\u5c065G\u9ad8\u7ea7\u7f51\u7edc\u529f\u80fd\u4e0e\u901a\u7528API\u6846\u67b6\uff08CAPIF\uff09\u96c6\u6210\uff0c\u4ee5\u652f\u6301\u6c7d\u8f66\u5e94\u7528\u7684\u589e\u5f3a\u8fde\u63a5\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u901a\u8fc75G\u548cCAPIF\u7684\u96c6\u6210\uff0c\u63d0\u5347\u6c7d\u8f66\u5e94\u7528\u7684\u7f51\u7edc\u6027\u80fd\u548c\u52a8\u6001\u670d\u52a1\u8d28\u91cf\uff08QoS\uff09\u8c03\u6574\u80fd\u529b\u3002", "method": "\u5229\u75283GPP\u7f51\u7edc\u66b4\u9732\u529f\u80fd\uff08NEF\uff09API\uff0c\u901a\u8fc7CAPIF\u5b9e\u73b0\u7f51\u7edc\u6027\u80fd\u7684\u6301\u7eed\u76d1\u63a7\u548cQoS\u7684\u52a8\u6001\u8c03\u6574\uff0c\u5e76\u5c06\u6d41\u91cf\u91cd\u5b9a\u5411\u81f3\u8fb9\u7f18\u4ee5\u4f18\u5316\u5ef6\u8fdf\u548c\u8d44\u6e90\u5229\u7528\u3002", "result": "PoC\u6210\u529f\u5c55\u793a\u4e86\u52a8\u6001QoS\u8c03\u6574\u548c\u6d41\u91cf\u8fb9\u7f18\u5316\u7684\u6548\u679c\uff0c\u63d0\u5347\u4e86\u89c6\u9891\u6d41\u670d\u52a1\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e865G\u4e0eCAPIF\u96c6\u6210\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u6c7d\u8f66\u5e94\u7528\u7684\u7f51\u7edc\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09680", "pdf": "https://arxiv.org/pdf/2508.09680", "abs": "https://arxiv.org/abs/2508.09680", "authors": ["Orvila Sarker", "Mona Jamshaid", "M. Ali Babar"], "title": "Inclusive Employment Pathways: Career Success Factors for Autistic Individuals in Software Engineering", "categories": ["cs.SE"], "comment": null, "summary": "Research has highlighted the valuable contributions of autistic individuals\nin the Information and Communication Technology (ICT) sector, particularly in\nareas such as software development, testing, and cybersecurity. Their strengths\nin information processing, attention to detail, innovative thinking, and\ncommitment to high-quality outcomes in the ICT domain are well-documented.\nHowever, despite their potential, autistic individuals often face barriers in\nSoftware Engineering (SE) roles due to a lack of personalised tools, complex\nwork environments, non-inclusive recruitment practices, limited co-worker\nsupport, challenging social dynamics and so on. Motivated by the ethical\nframework of the neurodiversity movement and the success of pioneering\ninitiatives like the Dandelion program, corporate Diversity, Equity, and\nInclusion (DEI) in the ICT sector has increasingly focused on autistic talent.\nThis movement fundamentally reframes challenges not as individual deficits but\nas failures of environments designed for a neurotypical majority. Despite this\nprogress, there is no synthesis of knowledge reporting the full pathway from\nsoftware engineering education through to sustainable workplace inclusion. To\naddress this, we conducted a Systematic Review of 30 studies and identified 18\nsuccess factors grouped into four thematic categories: (1) Software Engineering\nEducation, (2) Career and Employment Training, (3) Work Environment, and (4)\nTools and Assistive Technologies. Our findings offer evidence-based\nrecommendations for educational institutions, employers, organisations, and\ntool developers to enhance the inclusion of autistic individuals in SE. These\ninclude strategies for inclusive meeting and collaboration practices,\naccessible and structured work environments, clear role and responsibility\ndefinitions, and the provision of tailored workplace accommodations.", "AI": {"tldr": "\u81ea\u95ed\u75c7\u4e2a\u4f53\u5728ICT\u9886\u57df\uff08\u5982\u8f6f\u4ef6\u5f00\u53d1\u3001\u6d4b\u8bd5\u548c\u7f51\u7edc\u5b89\u5168\uff09\u6709\u663e\u8457\u8d21\u732e\uff0c\u4f46\u9762\u4e34\u804c\u573a\u969c\u788d\u3002\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\u63d0\u51fa18\u4e2a\u6210\u529f\u56e0\u7d20\uff0c\u5206\u4e3a\u56db\u7c7b\uff0c\u4e3a\u6559\u80b2\u673a\u6784\u3001\u96c7\u4e3b\u548c\u5de5\u5177\u5f00\u53d1\u8005\u63d0\u4f9b\u5305\u5bb9\u6027\u5efa\u8bae\u3002", "motivation": "\u57fa\u4e8e\u795e\u7ecf\u591a\u6837\u6027\u8fd0\u52a8\u7684\u4f26\u7406\u6846\u67b6\uff0c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u81ea\u95ed\u75c7\u4e2a\u4f53\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u4ece\u6559\u80b2\u5230\u804c\u573a\u5305\u5bb9\u7684\u5168\u9762\u8def\u5f84\u7f3a\u5931\u95ee\u9898\u3002", "method": "\u5bf930\u9879\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u7efc\u8ff0\uff0c\u8bc6\u522b\u51fa18\u4e2a\u6210\u529f\u56e0\u7d20\uff0c\u5206\u4e3a\u56db\u7c7b\u4e3b\u9898\u3002", "result": "\u63d0\u51fa\u56db\u7c7b\u6210\u529f\u56e0\u7d20\uff08\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u3001\u804c\u4e1a\u57f9\u8bad\u3001\u5de5\u4f5c\u73af\u5883\u3001\u5de5\u5177\u4e0e\u6280\u672f\uff09\uff0c\u5e76\u7ed9\u51fa\u5177\u4f53\u5305\u5bb9\u6027\u5efa\u8bae\u3002", "conclusion": "\u7814\u7a76\u4e3a\u63d0\u5347\u81ea\u95ed\u75c7\u4e2a\u4f53\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u5305\u5bb9\u6027\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u5efa\u8bae\uff0c\u5f3a\u8c03\u73af\u5883\u8bbe\u8ba1\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.09154", "pdf": "https://arxiv.org/pdf/2508.09154", "abs": "https://arxiv.org/abs/2508.09154", "authors": ["Xiaojing Du", "Jiuyong Li", "Lin Liu", "Debo Cheng", "Thuc. Le"], "title": "Peer Effect Estimation in the Presence of Simultaneous Feedback and Unobserved Confounders", "categories": ["cs.LG", "cs.AI", "stat.ME"], "comment": null, "summary": "Estimating peer causal effects within complex real-world networks such as\nsocial networks is challenging, primarily due to simultaneous feedback between\npeers and unobserved confounders. Existing methods either address unobserved\nconfounders while ignoring the simultaneous feedback, or account for feedback\nbut under restrictive linear assumptions, thus failing to obtain accurate peer\neffect estimation. In this paper, we propose DIG2RSI, a novel Deep learning\nframework which leverages I-G transformation (matrix operation) and 2SRI (an\ninstrumental variable or IV technique) to address both simultaneous feedback\nand unobserved confounding, while accommodating complex, nonlinear and\nhigh-dimensional relationships. DIG2RSI first applies the I-G transformation to\ndisentangle mutual peer influences and eliminate the bias due to the\nsimultaneous feedback. To deal with unobserved confounding, we first construct\nvalid IVs from network data. In stage 1 of 2RSI, we train a neural network on\nthese IVs to predict peer exposure, and extract residuals as proxies for the\nunobserved confounders. In the stage 2, we fit a separate neural network\naugmented by an adversarial discriminator that incorporates these residuals as\na control function and enforces the learned representation to contain no\nresidual confounding signal. The expressive power of deep learning models in\ncapturing complex non-linear relationships and adversarial debiasing enhances\nthe effectiveness of DIG2RSI in eliminating bias from both feedback loops and\nhidden confounders. We prove consistency of our estimator under standard\nregularity conditions, ensuring asymptotic recovery of the true peer effect.\nEmpirical results on two semi-synthetic benchmarks and a real-world dataset\ndemonstrate that DIG2RSI outperforms existing approaches.", "AI": {"tldr": "DIG2RSI\u662f\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7I-G\u53d8\u6362\u548c2SRI\u6280\u672f\u89e3\u51b3\u793e\u4ea4\u7f51\u7edc\u4e2d\u540c\u4f34\u6548\u5e94\u7684\u53cd\u9988\u548c\u672a\u89c2\u6d4b\u6df7\u6742\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u5904\u7406\u540c\u4f34\u6548\u5e94\u7684\u53cd\u9988\u548c\u672a\u89c2\u6d4b\u6df7\u6742\uff0c\u5bfc\u81f4\u4f30\u8ba1\u4e0d\u51c6\u786e\u3002", "method": "\u7ed3\u5408I-G\u53d8\u6362\u548c2SRI\u6280\u672f\uff0c\u5206\u4e24\u9636\u6bb5\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\uff0c\u5229\u7528\u5bf9\u6297\u6027\u53bb\u504f\u6d88\u9664\u6df7\u6742\u4fe1\u53f7\u3002", "result": "DIG2RSI\u5728\u534a\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "DIG2RSI\u80fd\u51c6\u786e\u4f30\u8ba1\u540c\u4f34\u6548\u5e94\uff0c\u89e3\u51b3\u4e86\u53cd\u9988\u548c\u6df7\u6742\u95ee\u9898\u3002"}}
{"id": "2508.09229", "pdf": "https://arxiv.org/pdf/2508.09229", "abs": "https://arxiv.org/abs/2508.09229", "authors": ["Danil Sivtsov", "Aleksandr Katrutsa", "Ivan Oseledets"], "title": "Cluster Topology-Driven Placement of Experts Reduces Network Traffic in MoE Inference", "categories": ["cs.NI", "cs.AI", "cs.DC"], "comment": null, "summary": "Efficient deployment of a pre-trained LLM to a cluster with multiple servers\nis a critical step for providing fast responses to users' queries. The recent\nsuccess of Mixture-of-Experts (MoE) LLMs raises the question of how to deploy\nthem efficiently, considering their underlying structure. During the inference\nin MoE LLMs, only a small part of the experts is selected to process a given\ntoken. Moreover, in practice, the experts' load is highly imbalanced. For\nefficient deployment, one has to distribute the model across a large number of\nservers using a model placement algorithm. Thus, to improve cluster\nutilization, the model placement algorithm has to take into account the network\ntopology. This work focuses on the efficient topology-aware placement of the\npre-trained MoE LLMs in the inference stage. We propose an integer linear\nprogram (ILP) that determines the optimal placement of experts, minimizing the\nexpected number of transmissions. Due to the internal structure, this\noptimization problem can be solved with a standard ILP solver. We demonstrate\nthat ILP-based placement strategy yields lower network traffic than competitors\nfor small-scale (DeepSeekMoE~16B) and large-scale (DeepSeek-R1~671B) models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08ILP\uff09\u7684\u6a21\u578b\u653e\u7f6e\u7b97\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u9884\u8bad\u7ec3MoE LLM\u5728\u591a\u670d\u52a1\u5668\u96c6\u7fa4\u4e2d\u7684\u90e8\u7f72\uff0c\u4ee5\u51cf\u5c11\u7f51\u7edc\u6d41\u91cf\u3002", "motivation": "\u9884\u8bad\u7ec3\u7684MoE LLM\u5728\u63a8\u7406\u9636\u6bb5\u4ec5\u6fc0\u6d3b\u90e8\u5206\u4e13\u5bb6\uff0c\u5bfc\u81f4\u8d1f\u8f7d\u4e0d\u5747\u8861\uff0c\u56e0\u6b64\u9700\u8981\u9ad8\u6548\u7684\u6a21\u578b\u653e\u7f6e\u7b97\u6cd5\u4ee5\u4f18\u5316\u96c6\u7fa4\u5229\u7528\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08ILP\uff09\u65b9\u6cd5\uff0c\u8003\u8651\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\uff0c\u4ee5\u6700\u5c0f\u5316\u9884\u671f\u4f20\u8f93\u6b21\u6570\u4e3a\u76ee\u6807\uff0c\u4f18\u5316\u4e13\u5bb6\u653e\u7f6e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cILP\u65b9\u6cd5\u5728\u5c0f\u89c4\u6a21\uff08DeepSeekMoE~16B\uff09\u548c\u5927\u89c4\u6a21\uff08DeepSeek-R1~671B\uff09\u6a21\u578b\u4e0a\u5747\u80fd\u51cf\u5c11\u7f51\u7edc\u6d41\u91cf\u3002", "conclusion": "ILP\u65b9\u6cd5\u4e3aMoE LLM\u7684\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u7f51\u7edc\u4f20\u8f93\u9700\u6c42\u3002"}}
{"id": "2508.09151", "pdf": "https://arxiv.org/pdf/2508.09151", "abs": "https://arxiv.org/abs/2508.09151", "authors": ["Chang Wu", "Yuang Chen", "Yiyuan Chen", "Fengqian Guo", "Xiaowei Qin", "Hancheng Lu"], "title": "Physiological Signal-Driven QoE Optimization for Wireless Virtual Reality Transmission", "categories": ["cs.NI", "cs.MA"], "comment": "7 pages, 6 figures", "summary": "Abrupt resolution changes in virtual reality (VR) streaming can significantly\nimpair the quality-of-experience (QoE) of users, particularly during\ntransitions from high to low resolutions. Existing QoE models and transmission\nschemes inadequately address the perceptual impact of these shifts. To bridge\nthis gap, this article proposes, for the first time, an innovative\nphysiological signal-driven QoE modeling and optimization framework that fully\nleverages users' electroencephalogram (EEG), electrocardiogram (ECG), and skin\nactivity signals. This framework precisely captures the temporal dynamics of\nphysiological responses and resolution changes in VR streaming, enabling\naccurate quantification of resolution upgrades' benefits and downgrades'\nimpacts. Integrated the proposed QoE framework into the radio access network\n(RAN) via a deep reinforcement learning (DRL) framework, adaptive transmission\nstrategies have been implemented to allocate radio resources dynamically, which\nmitigates short-term channel fluctuations and adjusts frame resolution in\nresponse to channel variations caused by user mobility. By prioritizing\nlong-term resolution while minimizing abrupt transitions, the proposed solution\nachieves an 88.7\\% improvement in resolution and an 81.0\\% reduction in\nhandover over the baseline. Experimental results demonstrate the effectiveness\nof this physiological signal-driven strategy, underscoring the promise of edge\nAI in immersive media services.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u7406\u4fe1\u53f7\u7684VR\u6d41\u5a92\u4f53QoE\u5efa\u6a21\u4e0e\u4f18\u5316\u6846\u67b6\uff0c\u5229\u7528EEG\u3001ECG\u548c\u76ae\u80a4\u6d3b\u52a8\u4fe1\u53f7\u52a8\u6001\u8c03\u6574\u5206\u8fa8\u7387\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u73b0\u6709QoE\u6a21\u578b\u548c\u4f20\u8f93\u65b9\u6848\u672a\u80fd\u5145\u5206\u89e3\u51b3VR\u6d41\u5a92\u4f53\u4e2d\u5206\u8fa8\u7387\u7a81\u53d8\u5bf9\u7528\u6237\u4f53\u9a8c\u7684\u5f71\u54cd\u3002", "method": "\u7ed3\u5408\u751f\u7406\u4fe1\u53f7\uff08EEG\u3001ECG\u3001\u76ae\u80a4\u6d3b\u52a8\uff09\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\uff0c\u52a8\u6001\u5206\u914d\u65e0\u7ebf\u8d44\u6e90\u5e76\u8c03\u6574\u5206\u8fa8\u7387\u3002", "result": "\u5206\u8fa8\u7387\u63d0\u534788.7%\uff0c\u5207\u6362\u51cf\u5c1181.0%\u3002", "conclusion": "\u751f\u7406\u4fe1\u53f7\u9a71\u52a8\u7684\u7b56\u7565\u6709\u6548\u63d0\u5347\u4e86VR\u6d41\u5a92\u4f53\u7684QoE\uff0c\u5c55\u793a\u4e86\u8fb9\u7f18AI\u5728\u6c89\u6d78\u5f0f\u5a92\u4f53\u670d\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.09791", "pdf": "https://arxiv.org/pdf/2508.09791", "abs": "https://arxiv.org/abs/2508.09791", "authors": ["Junxiao Han", "Yarong Wang", "Xiaodong Gu", "Cuiyun Gao", "Yao Wan", "Song Han", "David Lo", "Shuiguang Deng"], "title": "LibRec: Benchmarking Retrieval-Augmented LLMs for Library Migration Recommendations", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "In this paper, we propose LibRec, a novel framework that integrates the\ncapabilities of LLMs with retrieval-augmented generation(RAG) techniques to\nautomate the recommendation of alternative libraries. The framework further\nemploys in-context learning to extract migration intents from commit messages\nto enhance the accuracy of its recommendations. To evaluate the effectiveness\nof LibRec, we introduce LibEval, a benchmark designed to assess the performance\nin the library migration recommendation task. LibEval comprises 2,888 migration\nrecords associated with 2,368 libraries extracted from 2,324 Python\nrepositories. Each migration record captures source-target library pairs, along\nwith their corresponding migration intents and intent types. Based on LibEval,\nwe evaluated the effectiveness of ten popular LLMs within our framework,\nconducted an ablation study to examine the contributions of key components\nwithin our framework, explored the impact of various prompt strategies on the\nframework's performance, assessed its effectiveness across various intent\ntypes, and performed detailed failure case analyses.", "AI": {"tldr": "LibRec\u662f\u4e00\u4e2a\u7ed3\u5408LLM\u548cRAG\u6280\u672f\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u63a8\u8350\u66ff\u4ee3\u5e93\uff0c\u5e76\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u4ece\u63d0\u4ea4\u6d88\u606f\u4e2d\u63d0\u53d6\u8fc1\u79fb\u610f\u56fe\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u3002LibEval\u4f5c\u4e3a\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b2,888\u6761\u8fc1\u79fb\u8bb0\u5f55\u3002\u5b9e\u9a8c\u8bc4\u4f30\u4e8610\u79cdLLM\u7684\u6548\u679c\uff0c\u5e76\u5206\u6790\u4e86\u6846\u67b6\u7684\u5173\u952e\u7ec4\u4ef6\u3001\u63d0\u793a\u7b56\u7565\u548c\u5931\u8d25\u6848\u4f8b\u3002", "motivation": "\u81ea\u52a8\u5316\u5e93\u8fc1\u79fb\u63a8\u8350\u7684\u9700\u6c42\uff0c\u7ed3\u5408LLM\u548cRAG\u6280\u672f\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faLibRec\u6846\u67b6\uff0c\u7ed3\u5408LLM\u548cRAG\u6280\u672f\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u53d6\u8fc1\u79fb\u610f\u56fe\u3002", "result": "\u57fa\u4e8eLibEval\u57fa\u51c6\uff0c\u8bc4\u4f30\u4e8610\u79cdLLM\u7684\u6548\u679c\uff0c\u5206\u6790\u4e86\u6846\u67b6\u7ec4\u4ef6\u3001\u63d0\u793a\u7b56\u7565\u548c\u5931\u8d25\u6848\u4f8b\u3002", "conclusion": "LibRec\u6846\u67b6\u5728\u5e93\u8fc1\u79fb\u63a8\u8350\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7ed3\u5408LLM\u548cRAG\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u51c6\u786e\u6027\u3002"}}
{"id": "2508.09155", "pdf": "https://arxiv.org/pdf/2508.09155", "abs": "https://arxiv.org/abs/2508.09155", "authors": ["Wenkai Wang", "Hongcan Guo", "Zheqi Lv", "Shengyu Zhang"], "title": "A Rolling Stone Gathers No Moss: Adaptive Policy Optimization for Stable Self-Evaluation in Large Multimodal Models", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages, 9 figures", "summary": "Self-evaluation, a model's ability to assess the correctness of its own\noutput, is crucial for Large Multimodal Models (LMMs) to achieve\nself-improvement in multi-turn conversations, yet largely absent in foundation\nmodels. Recent work has employed reinforcement learning (RL) to enhance\nself-evaluation; however, its fixed reward mechanism suffers from reward\nhacking when optimizing multiple training objectives, leading to model\ncollapse. In this paper we propose AdaPO, an online reinforcement learning\nframework capable of adaptively adjusting training objective in real time\naccording to the current training state for each task. Specifically, to\nmitigate reward hacking , AdaPO introduces an Adaptive Reward Model (ARM) and a\nReward Aware Dynamic KL Regularization mechanism. ARM assesses the task's\ntraining state from the distribution of model generated multi-turn\ntrajectories' performance. Reward Aware Dynamic KL replaces a fixed penalty\nwith dynamic coefficients which is modulated by the reward gap between\ndifferent multi-turn situations. Notably, our method automatically and smoothly\nadjusts its learning focus based on sub-tasks' training progress without manual\nintervention. Extensive experiments over 8 benchmarks and various models show\nthat our method significantly enhances both direct reasoning and\nself-evaluation capability. We will release our code to contribute to the\ncommunity.", "AI": {"tldr": "AdaPO\u662f\u4e00\u79cd\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u8bad\u7ec3\u76ee\u6807\u548c\u52a8\u6001\u5956\u52b1\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u591a\u76ee\u6807\u4f18\u5316\u4e2d\u7684\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u63a8\u7406\u548c\u81ea\u6211\u8bc4\u4f30\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7f3a\u4e4f\u81ea\u6211\u8bc4\u4f30\u80fd\u529b\uff0c\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u56e0\u56fa\u5b9a\u5956\u52b1\u673a\u5236\u6613\u5bfc\u81f4\u5956\u52b1\u9ed1\u5ba2\u548c\u6a21\u578b\u5d29\u6e83\u3002", "method": "\u63d0\u51faAdaPO\u6846\u67b6\uff0c\u5305\u542b\u81ea\u9002\u5e94\u5956\u52b1\u6a21\u578b\uff08ARM\uff09\u548c\u5956\u52b1\u611f\u77e5\u52a8\u6001KL\u6b63\u5219\u5316\u673a\u5236\uff0c\u5b9e\u65f6\u8c03\u6574\u8bad\u7ec3\u76ee\u6807\u548c\u5956\u52b1\u7b56\u7565\u3002", "result": "\u57288\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u591a\u79cd\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAdaPO\u663e\u8457\u63d0\u5347\u4e86\u76f4\u63a5\u63a8\u7406\u548c\u81ea\u6211\u8bc4\u4f30\u80fd\u529b\u3002", "conclusion": "AdaPO\u901a\u8fc7\u81ea\u9002\u5e94\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898\uff0c\u4e3aLMMs\u7684\u81ea\u6211\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.09638", "pdf": "https://arxiv.org/pdf/2508.09638", "abs": "https://arxiv.org/abs/2508.09638", "authors": ["Irina Kostitsyna", "David Liedtke", "Christian Scheideler"], "title": "Distributed Diamond Formation of Sliding Squares", "categories": ["cs.CG", "cs.DC", "F.2.2"], "comment": "29 pages, 11 figures, 34 subfigures", "summary": "The sliding square model is a widely used abstraction for studying\nself-reconfigurable robotic systems, where modules are square-shaped robots\nthat move by sliding or rotating over one another. In this paper, we propose a\nnovel distributed algorithm that allows a group of modules to reconfigure into\na diamond shape, starting from an arbitrary side-connected configuration. It is\nconnectivity-preserving and operates under minimal assumptions: one leader\nmodule, common chirality, constant memory per module, and visibility and\ncommunication restricted to immediate neighbors. Unlike prior work, which\nrelaxes the original sliding square move-set, our approach uses the unmodified\nmove-set, addressing the additional challenge of handling locked\nconfigurations. Our algorithm is sequential in nature and operates with a\nworst-case time complexity of $\\mathcal{O}(n^2)$ rounds, which is optimal for\nsequential algorithms. To improve runtime, we introduce two parallel variants\nof the algorithm. Both rely on a spanning tree data structure, allowing modules\nto make decisions based on local connectivity. Our experimental results show a\nsignificant speedup for the first variant, and linear average runtime for the\nsecond variant, which is worst-case optimal for parallel algorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5206\u5e03\u5f0f\u7b97\u6cd5\uff0c\u4f7f\u65b9\u5f62\u6a21\u5757\u673a\u5668\u4eba\u80fd\u591f\u4ece\u4efb\u610f\u8fde\u63a5\u914d\u7f6e\u91cd\u6784\u4e3a\u94bb\u77f3\u5f62\u72b6\uff0c\u4fdd\u6301\u8fde\u901a\u6027\u4e14\u4ec5\u9700\u6700\u5c0f\u5047\u8bbe\u3002", "motivation": "\u7814\u7a76\u81ea\u91cd\u6784\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5bf9\u6ed1\u52a8\u65b9\u5f62\u79fb\u52a8\u96c6\u7684\u9650\u5236\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u672a\u4fee\u6539\u7684\u79fb\u52a8\u96c6\uff0c\u63d0\u51fa\u987a\u5e8f\u548c\u5e76\u884c\u7b97\u6cd5\uff0c\u57fa\u4e8e\u5c40\u90e8\u8fde\u901a\u6027\u51b3\u7b56\u3002", "result": "\u987a\u5e8f\u7b97\u6cd5\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(n\u00b2)\uff0c\u5e76\u884c\u53d8\u4f53\u663e\u8457\u52a0\u901f\uff0c\u7b2c\u4e8c\u53d8\u4f53\u5e73\u5747\u7ebf\u6027\u65f6\u95f4\u3002", "conclusion": "\u7b97\u6cd5\u5728\u4fdd\u6301\u8fde\u901a\u6027\u548c\u6700\u5c0f\u5047\u8bbe\u4e0b\u9ad8\u6548\u5b8c\u6210\u91cd\u6784\uff0c\u5e76\u884c\u53d8\u4f53\u6027\u80fd\u4f18\u8d8a\u3002"}}
{"id": "2508.09152", "pdf": "https://arxiv.org/pdf/2508.09152", "abs": "https://arxiv.org/abs/2508.09152", "authors": ["Joseph H. R. Isaac", "Harish Saradagam", "Nallamothu Pardhasaradhi"], "title": "5G Core Fault Detection and Root Cause Analysis using Machine Learning and Generative AI", "categories": ["cs.NI", "cs.AI", "cs.LG"], "comment": "8 pages, 3 figures and 2 tables. Accepted in Conference on Advances\n  in Communication Networks & Systems (CoaCoNS 2025)", "summary": "With the advent of 5G networks and technologies, ensuring the integrity and\nperformance of packet core traffic is paramount. During network analysis, test\nfiles such as Packet Capture (PCAP) files and log files will contain errors if\npresent in the system that must be resolved for better overall network\nperformance, such as connectivity strength and handover quality. Current\nmethods require numerous person-hours to sort out testing results and find the\nfaults. This paper presents a novel AI/ML-driven Fault Analysis (FA) Engine\ndesigned to classify successful and faulty frames in PCAP files, specifically\nwithin the 5G packet core. The FA engine analyses network traffic using natural\nlanguage processing techniques to identify anomalies and inefficiencies,\nsignificantly reducing the effort time required and increasing efficiency. The\nFA Engine also suggests steps to fix the issue using Generative AI via a Large\nLanguage Model (LLM) trained on several 5G packet core documents. The engine\nexplains the details of the error from the domain perspective using documents\nsuch as the 3GPP standards and user documents regarding the internal conditions\nof the tests. Test results on the ML models show high classification accuracy\non the test dataset when trained with 80-20 splits for the successful and\nfailed PCAP files. Future scopes include extending the AI engine to incorporate\n4G network traffic and other forms of network data, such as log text files and\nmultimodal systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAI/ML\u7684\u6545\u969c\u5206\u6790\u5f15\u64ce\uff0c\u7528\u4e8e\u81ea\u52a8\u5206\u7c7b5G\u6838\u5fc3\u7f51\u4e2d\u7684PCAP\u6587\u4ef6\u6545\u969c\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u5206\u6790\u65f6\u95f4\u5e76\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u968f\u77405G\u6280\u672f\u7684\u53d1\u5c55\uff0c\u786e\u4fdd\u6838\u5fc3\u7f51\u6d41\u91cf\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u5206\u6790PCAP\u6587\u4ef6\uff0c\u8017\u65f6\u4e14\u4f4e\u6548\u3002", "method": "\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u5206\u6790\u7f51\u7edc\u6d41\u91cf\uff0c\u7ed3\u5408\u751f\u6210\u5f0fAI\uff08\u57fa\u4e8eLLM\uff09\u63d0\u4f9b\u6545\u969c\u4fee\u590d\u5efa\u8bae\uff0c\u5e76\u53c2\u80033GPP\u6807\u51c6\u7b49\u6587\u6863\u89e3\u91ca\u9519\u8bef\u3002", "result": "\u572880-20\u7684\u8bad\u7ec3\u6d4b\u8bd5\u96c6\u5212\u5206\u4e0b\uff0c\u6a21\u578b\u5bf9PCAP\u6587\u4ef6\u7684\u5206\u7c7b\u51c6\u786e\u7387\u8f83\u9ad8\u3002", "conclusion": "\u8be5\u5f15\u64ce\u663e\u8457\u63d0\u5347\u4e86\u6545\u969c\u5206\u6790\u6548\u7387\uff0c\u672a\u6765\u53ef\u6269\u5c55\u81f34G\u7f51\u7edc\u548c\u5176\u4ed6\u6570\u636e\u7c7b\u578b\u3002"}}
{"id": "2508.09828", "pdf": "https://arxiv.org/pdf/2508.09828", "abs": "https://arxiv.org/abs/2508.09828", "authors": ["Sebastiano Antonio Piccolo"], "title": "Fast and Accurate Heuristics for Bus-Factor Estimation", "categories": ["cs.SE"], "comment": null, "summary": "The bus-factor is a critical risk indicator that quantifies how many key\ncontributors a project can afford to lose before core knowledge or\nfunctionality is compromised. Despite its practical importance, accurately\ncomputing the bus-factor is NP-Hard under established formalizations, making\nscalable analysis infeasible for large software systems.\n  In this paper, we model software projects as bipartite graphs of developers\nand tasks and propose two novel approximation heuristics, Minimum Coverage and\nMaximum Coverage, based on iterative graph peeling, for two influential\nbus-factor formalizations. Our methods significantly outperform the widely\nadopted degree-based heuristic, which we show can yield severely inflated\nestimates.\n  We conduct a comprehensive empirical evaluation on over $1\\,000$ synthetic\npower-law graphs and demonstrate that our heuristics provide tighter estimates\nwhile scaling to graphs with millions of nodes and edges in minutes. Our\nresults reveal that the proposed heuristics are not only more accurate but also\nrobust to structural variations in developer-task assignment graph. We release\nour implementation as open-source software to support future research and\npractical adoption.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u4e8c\u5206\u56fe\u7684\u65b0\u542f\u53d1\u5f0f\u65b9\u6cd5\uff08Minimum Coverage\u548cMaximum Coverage\uff09\uff0c\u7528\u4e8e\u8fd1\u4f3c\u8ba1\u7b97\u8f6f\u4ef6\u9879\u76ee\u7684bus-factor\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u56fe\u4e0a\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "bus-factor\u662f\u8861\u91cf\u9879\u76ee\u98ce\u9669\u7684\u91cd\u8981\u6307\u6807\uff0c\u4f46\u7cbe\u786e\u8ba1\u7b97\u5176NP-Hard\u7279\u6027\u4f7f\u5176\u96be\u4ee5\u6269\u5c55\u5230\u5927\u7cfb\u7edf\uff0c\u56e0\u6b64\u9700\u8981\u9ad8\u6548\u7684\u8fd1\u4f3c\u65b9\u6cd5\u3002", "method": "\u5c06\u8f6f\u4ef6\u9879\u76ee\u5efa\u6a21\u4e3a\u5f00\u53d1\u8005\u4e0e\u4efb\u52a1\u7684\u4e8c\u5206\u56fe\uff0c\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u8fed\u4ee3\u56fe\u5265\u79bb\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "result": "\u57281000\u591a\u4e2a\u5408\u6210\u56fe\u4e0a\u9a8c\u8bc1\uff0c\u65b0\u65b9\u6cd5\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u51c6\u786e\u4e14\u53ef\u6269\u5c55\u5230\u767e\u4e07\u7ea7\u8282\u70b9\u56fe\u3002", "conclusion": "\u65b0\u542f\u53d1\u5f0f\u65b9\u6cd5\u9ad8\u6548\u3001\u51c6\u786e\u4e14\u9c81\u68d2\uff0c\u5df2\u5f00\u6e90\u4ee5\u652f\u6301\u7814\u7a76\u548c\u5e94\u7528\u3002"}}
{"id": "2508.09156", "pdf": "https://arxiv.org/pdf/2508.09156", "abs": "https://arxiv.org/abs/2508.09156", "authors": ["Jan Tauberschmidt", "Sophie Fellenz", "Sebastian J. Vollmer", "Andrew B. Duncan"], "title": "Physics-Constrained Fine-Tuning of Flow-Matching Models for Generation and Inverse Problems", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": "7 pages main content, 10 pages appendices", "summary": "We present a framework for fine-tuning flow-matching generative models to\nenforce physical constraints and solve inverse problems in scientific systems.\nStarting from a model trained on low-fidelity or observational data, we apply a\ndifferentiable post-training procedure that minimizes weak-form residuals of\ngoverning partial differential equations (PDEs), promoting physical consistency\nand adherence to boundary conditions without distorting the underlying learned\ndistribution. To infer unknown physical inputs, such as source terms, material\nparameters, or boundary data, we augment the generative process with a\nlearnable latent parameter predictor and propose a joint optimization strategy.\nThe resulting model produces physically valid field solutions alongside\nplausible estimates of hidden parameters, effectively addressing ill-posed\ninverse problems in a data-driven yet physicsaware manner. We validate our\nmethod on canonical PDE benchmarks, demonstrating improved satisfaction of PDE\nconstraints and accurate recovery of latent coefficients. Our approach bridges\ngenerative modelling and scientific inference, opening new avenues for\nsimulation-augmented discovery and data-efficient modelling of physical\nsystems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5fae\u8c03\u6d41\u5339\u914d\u751f\u6210\u6a21\u578b\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5f3a\u5236\u6267\u884c\u7269\u7406\u7ea6\u675f\u5e76\u89e3\u51b3\u79d1\u5b66\u7cfb\u7edf\u4e2d\u7684\u9006\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u4f4e\u4fdd\u771f\u6216\u89c2\u6d4b\u6570\u636e\u8bad\u7ec3\u7684\u751f\u6210\u6a21\u578b\u5728\u7269\u7406\u4e00\u81f4\u6027\u4e0a\u7684\u4e0d\u8db3\uff0c\u540c\u65f6\u5904\u7406\u9006\u95ee\u9898\u4e2d\u7684\u672a\u77e5\u7269\u7406\u8f93\u5165\u3002", "method": "\u91c7\u7528\u53ef\u5fae\u5206\u7684\u540e\u8bad\u7ec3\u7a0b\u5e8f\uff0c\u6700\u5c0f\u5316\u63a7\u5236\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u5f31\u5f62\u5f0f\u6b8b\u5dee\uff0c\u5e76\u5f15\u5165\u53ef\u5b66\u4e60\u7684\u6f5c\u5728\u53c2\u6570\u9884\u6d4b\u5668\u8fdb\u884c\u8054\u5408\u4f18\u5316\u3002", "result": "\u6a21\u578b\u80fd\u591f\u751f\u6210\u7269\u7406\u6709\u6548\u7684\u573a\u89e3\uff0c\u5e76\u51c6\u786e\u4f30\u8ba1\u9690\u85cf\u53c2\u6570\uff0c\u9a8c\u8bc1\u4e86\u5728PDE\u7ea6\u675f\u548c\u53c2\u6570\u6062\u590d\u4e0a\u7684\u6539\u8fdb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c06\u751f\u6210\u5efa\u6a21\u4e0e\u79d1\u5b66\u63a8\u65ad\u7ed3\u5408\uff0c\u4e3a\u7269\u7406\u7cfb\u7edf\u7684\u4eff\u771f\u589e\u5f3a\u53d1\u73b0\u548c\u6570\u636e\u9ad8\u6548\u5efa\u6a21\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2508.09159", "pdf": "https://arxiv.org/pdf/2508.09159", "abs": "https://arxiv.org/abs/2508.09159", "authors": ["Ilias Chatzistefanidis", "Navid Nikaein", "Andrea Leone", "Ali Maatouk", "Leandros Tassioulas", "Roberto Morabito", "Ioannis Pitsiorlas", "Marios Kountouris"], "title": "Agoran: An Agentic Open Marketplace for 6G RAN Automation", "categories": ["cs.NI", "cs.AI"], "comment": "Pre-print submitted to Computer Networks AI-for-6G", "summary": "Next-generation mobile networks must reconcile the often-conflicting goals of\nmultiple service owners. However, today's network slice controllers remain\nrigid, policy-bound, and unaware of the business context. We introduce Agoran\nService and Resource Broker (SRB), an agentic marketplace that brings\nstakeholders directly into the operational loop. Inspired by the ancient Greek\nagora, Agoran distributes authority across three autonomous AI branches: a\nLegislative branch that answers compliance queries using retrieval-augmented\nLarge Language Models (LLMs); an Executive branch that maintains real-time\nsituational awareness through a watcher-updated vector database; and a Judicial\nbranch that evaluates each agent message with a rule-based Trust Score, while\narbitrating LLMs detect malicious behavior and apply real-time incentives to\nrestore trust. Stakeholder-side Negotiation Agents and the SRB-side Mediator\nAgent negotiate feasible, Pareto-optimal offers produced by a multi-objective\noptimizer, reaching a consensus intent in a single round, which is then\ndeployed to Open and AI RAN controllers. Deployed on a private 5G testbed and\nevaluated with realistic traces of vehicle mobility, Agoran achieved\nsignificant gains: (i) a 37% increase in throughput of eMBB slices, (ii) a 73%\nreduction in latency of URLLC slices, and concurrently (iii) an end-to-end 8.3%\nsaving in PRB usage compared to a static baseline. An 1B-parameter Llama model,\nfine-tuned for five minutes on 100 GPT-4 dialogues, recovers approximately 80%\nof GPT-4.1's decision quality, while operating within 6 GiB of memory and\nconverging in only 1.3 seconds. These results establish Agoran as a concrete,\nstandards-aligned path toward ultra-flexible, stakeholder-centric 6G networks.\nA live demo is presented\nhttps://www.youtube.com/watch?v=h7vEyMu2f5w\\&ab_channel=BubbleRAN.", "AI": {"tldr": "Agoran SRB\u662f\u4e00\u4e2a\u57fa\u4e8e\u4ee3\u7406\u7684\u5e02\u573a\uff0c\u901a\u8fc7\u4e09\u4e2a\u81ea\u6cbbAI\u5206\u652f\uff08\u7acb\u6cd5\u3001\u884c\u653f\u3001\u53f8\u6cd5\uff09\u534f\u8c03\u591a\u65b9\u5229\u76ca\uff0c\u663e\u8457\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u4e0b\u4e00\u4ee3\u79fb\u52a8\u7f51\u7edc\u4e2d\u591a\u65b9\u670d\u52a1\u6240\u6709\u8005\u76ee\u6807\u51b2\u7a81\u7684\u95ee\u9898\uff0c\u514b\u670d\u73b0\u6709\u7f51\u7edc\u5207\u7247\u63a7\u5236\u5668\u7684\u50f5\u5316\u6027\u3002", "method": "\u91c7\u7528\u4e09\u5206\u652fAI\u67b6\u6784\uff08\u7acb\u6cd5\u3001\u884c\u653f\u3001\u53f8\u6cd5\uff09\u548c\u4ee3\u7406\u534f\u5546\u673a\u5236\uff0c\u7ed3\u5408\u591a\u76ee\u6807\u4f18\u5316\u5668\u8fbe\u6210\u5171\u8bc6\u3002", "result": "\u57285G\u6d4b\u8bd5\u4e2d\uff0ceMBB\u5207\u7247\u541e\u5410\u91cf\u63d0\u534737%\uff0cURLLC\u5207\u7247\u5ef6\u8fdf\u964d\u4f4e73%\uff0cPRB\u4f7f\u7528\u8282\u77018.3%\u3002", "conclusion": "Agoran\u4e3a6G\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u3001\u4ee5\u5229\u76ca\u76f8\u5173\u8005\u4e3a\u4e2d\u5fc3\u7684\u6807\u51c6\u8def\u5f84\u3002"}}
{"id": "2508.09832", "pdf": "https://arxiv.org/pdf/2508.09832", "abs": "https://arxiv.org/abs/2508.09832", "authors": ["Linh Nguyen", "Chunhua Liu", "Hong Yi Lin", "Patanamon Thongtanunam"], "title": "Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted at 2025 IEEE International Conference on Source Code\n  Analysis & Manipulation (SCAM)", "summary": "Code review is a crucial practice in software development. As code review\nnowadays is lightweight, various issues can be identified, and sometimes, they\ncan be trivial. Research has investigated automated approaches to classify\nreview comments to gauge the effectiveness of code reviews. However, previous\nstudies have primarily relied on supervised machine learning, which requires\nextensive manual annotation to train the models effectively. To address this\nlimitation, we explore the potential of using Large Language Models (LLMs) to\nclassify code review comments. We assess the performance of LLMs to classify 17\ncategories of code review comments. Our results show that LLMs can classify\ncode review comments, outperforming the state-of-the-art approach using a\ntrained deep learning model. In particular, LLMs achieve better accuracy in\nclassifying the five most useful categories, which the state-of-the-art\napproach struggles with due to low training examples. Rather than relying\nsolely on a specific small training data distribution, our results show that\nLLMs provide balanced performance across high- and low-frequency categories.\nThese results suggest that the LLMs could offer a scalable solution for code\nreview analytics to improve the effectiveness of the code review process.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5206\u7c7b\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u7684\u6f5c\u529b\uff0c\u53d1\u73b0\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u4f4e\u9891\u7c7b\u522b\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u76d1\u7763\u5b66\u4e60\u7684\u4ee3\u7801\u8bc4\u8bba\u5206\u7c7b\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6807\u6ce8\uff0c\u9650\u5236\u4e86\u5176\u53ef\u6269\u5c55\u6027\u3002", "method": "\u5229\u7528LLMs\u5bf917\u7c7b\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u4e0e\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5bf9\u6bd4\u3002", "result": "LLMs\u5728\u5206\u7c7b\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u4f4e\u9891\u7c7b\u522b\u4e0a\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "LLMs\u4e3a\u4ee3\u7801\u5ba1\u67e5\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u63d0\u5347\u5ba1\u67e5\u6548\u7387\u3002"}}
{"id": "2508.09158", "pdf": "https://arxiv.org/pdf/2508.09158", "abs": "https://arxiv.org/abs/2508.09158", "authors": ["Siwen Jiao", "Kangan Qian", "Hao Ye", "Yang Zhong", "Ziang Luo", "Sicong Jiang", "Zilin Huang", "Yangyi Fang", "Jinyu Miao", "Zheng Fu", "Yunlong Wang", "Kun Jiang", "Diange Yang", "Rui Fan", "Baoyun Peng"], "title": "EvaDrive: Evolutionary Adversarial Policy Optimization for End-to-End Autonomous Driving", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Autonomous driving faces significant challenges in achieving human-like\niterative decision-making, which continuously generates, evaluates, and refines\ntrajectory proposals. Current generation-evaluation frameworks isolate\ntrajectory generation from quality assessment, preventing iterative refinement\nessential for planning, while reinforcement learning methods collapse\nmulti-dimensional preferences into scalar rewards, obscuring critical\ntrade-offs and yielding scalarization bias.To overcome these issues, we present\nEvaDrive, a novel multi-objective reinforcement learning framework that\nestablishes genuine closed-loop co-evolution between trajectory generation and\nevaluation via adversarial optimization. EvaDrive frames trajectory planning as\na multi-round adversarial game. In this game, a hierarchical generator\ncontinuously proposes candidate paths by combining autoregressive intent\nmodeling for temporal causality with diffusion-based refinement for spatial\nflexibility. These proposals are then rigorously assessed by a trainable\nmulti-objective critic that explicitly preserves diverse preference structures\nwithout collapsing them into a single scalarization bias.This adversarial\ninterplay, guided by a Pareto frontier selection mechanism, enables iterative\nmulti-round refinement, effectively escaping local optima while preserving\ntrajectory diversity.Extensive experiments on NAVSIM and Bench2Drive benchmarks\ndemonstrate SOTA performance, achieving 94.9 PDMS on NAVSIM v1 (surpassing\nDiffusionDrive by 6.8, DriveSuprim by 5.0, and TrajHF by 0.9) and 64.96 Driving\nScore on Bench2Drive. EvaDrive generates diverse driving styles via dynamic\nweighting without external preference data, introducing a closed-loop\nadversarial framework for human-like iterative decision-making, offering a\nnovel scalarization-free trajectory optimization approach.", "AI": {"tldr": "EvaDrive\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u4f18\u5316\u5b9e\u73b0\u8f68\u8ff9\u751f\u6210\u4e0e\u8bc4\u4f30\u7684\u95ed\u73af\u534f\u540c\u8fdb\u5316\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u65b9\u6cd5\u4e2d\u8fed\u4ee3\u4f18\u5316\u4e0d\u8db3\u548c\u6807\u91cf\u5316\u504f\u5dee\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u81ea\u52a8\u9a7e\u9a76\u51b3\u7b56\u4e2d\u65e0\u6cd5\u5b9e\u73b0\u7c7b\u4f3c\u4eba\u7c7b\u7684\u8fed\u4ee3\u4f18\u5316\uff0c\u4e14\u591a\u76ee\u6807\u504f\u597d\u88ab\u7b80\u5316\u4e3a\u6807\u91cf\u5956\u52b1\uff0c\u5bfc\u81f4\u5173\u952e\u6743\u8861\u4e22\u5931\u3002", "method": "EvaDrive\u91c7\u7528\u5206\u5c42\u751f\u6210\u5668\u548c\u53ef\u8bad\u7ec3\u7684\u591a\u76ee\u6807\u8bc4\u4f30\u5668\uff0c\u901a\u8fc7\u5bf9\u6297\u6e38\u620f\u5b9e\u73b0\u591a\u8f6e\u8fed\u4ee3\u4f18\u5316\uff0c\u5e76\u7ed3\u5408\u81ea\u56de\u5f52\u610f\u56fe\u5efa\u6a21\u548c\u6269\u6563\u6a21\u578b\u63d0\u5347\u65f6\u7a7a\u7075\u6d3b\u6027\u3002", "result": "\u5728NAVSIM\u548cBench2Drive\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5206\u522b\u8fbe\u523094.9 PDMS\u548c64.96 Driving Score\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "EvaDrive\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u6807\u91cf\u5316\u7684\u8f68\u8ff9\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u6743\u91cd\u751f\u6210\u591a\u6837\u5316\u9a7e\u9a76\u98ce\u683c\uff0c\u5b9e\u73b0\u4e86\u7c7b\u4eba\u7684\u95ed\u73af\u8fed\u4ee3\u51b3\u7b56\u3002"}}
{"id": "2508.09166", "pdf": "https://arxiv.org/pdf/2508.09166", "abs": "https://arxiv.org/abs/2508.09166", "authors": ["Wei Guo", "Shunsei Yamagishi", "Lei Jing"], "title": "WPTrack: A Wi-Fi and Pressure Insole Fusion System for Single Target Tracking", "categories": ["cs.NI", "cs.HC"], "comment": "6 pages, 12 figures, conference", "summary": "As the Internet of Things (IoT) continues to evolve, indoor location has\nbecome a critical element for enabling smart homes, behavioral monitoring, and\nelderly care. Existing WiFi-based human tracking solutions typically require\nspecialized equipment or multiple Wi-Fi links, a limitation in most indoor\nsettings where only a single pair of Wi-Fi devices is usually available.\nHowever, despite efforts to implement human tracking using one Wi-Fi link,\nsignificant challenges remain, such as difficulties in acquiring initial\npositions and blind spots in DFS estimation of tangent direction. To address\nthese challenges, this paper proposes WPTrack, the first Wi-Fi and Pressure\nInsoles Fusion System for Single Target Tracking. WPTrack collects Channel\nState Information (CSI) from a single Wi-Fi link and pressure data from 90\ninsole sensors. The phase difference and Doppler velocity are computed from the\nCSI, while the pressure sensor data is used to calculate walking velocity.\nThen, we propose the CSI-pressure fusion model, integrating CSI and pressure\ndata to accurately determine initial positions and facilitate precise human\ntracking. The simulation results show that the initial position localization\naccuracy ranges from 0.02 cm to 42.55 cm. The trajectory tracking results\nobtained from experimental data collected in a real-world environment closely\nalign with the actual trajectory.", "AI": {"tldr": "WPTrack\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408Wi-Fi\u548c\u538b\u529b\u978b\u57ab\u6570\u636e\u7684\u5355\u76ee\u6807\u8ddf\u8e2a\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709Wi-Fi\u8ddf\u8e2a\u6280\u672f\u4e2d\u521d\u59cb\u4f4d\u7f6e\u83b7\u53d6\u548c\u65b9\u5411\u4f30\u8ba1\u7684\u76f2\u70b9\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u7269\u8054\u7f51\u7684\u53d1\u5c55\uff0c\u5ba4\u5185\u5b9a\u4f4d\u5bf9\u667a\u80fd\u5bb6\u5c45\u3001\u884c\u4e3a\u76d1\u6d4b\u548c\u8001\u5e74\u62a4\u7406\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709Wi-Fi\u8ddf\u8e2a\u6280\u672f\u901a\u5e38\u9700\u8981\u591a\u8bbe\u5907\u652f\u6301\uff0c\u800c\u5355\u8bbe\u5907\u65b9\u6848\u5b58\u5728\u521d\u59cb\u4f4d\u7f6e\u83b7\u53d6\u548c\u65b9\u5411\u4f30\u8ba1\u7684\u6311\u6218\u3002", "method": "WPTrack\u901a\u8fc7\u5355Wi-Fi\u94fe\u8def\u91c7\u96c6CSI\u6570\u636e\uff0c\u7ed3\u540890\u4e2a\u978b\u57ab\u4f20\u611f\u5668\u7684\u538b\u529b\u6570\u636e\uff0c\u8ba1\u7b97\u76f8\u4f4d\u5dee\u3001\u591a\u666e\u52d2\u901f\u5ea6\u548c\u6b65\u884c\u901f\u5ea6\uff0c\u63d0\u51faCSI-\u538b\u529b\u878d\u5408\u6a21\u578b\u4ee5\u5b9e\u73b0\u7cbe\u786e\u8ddf\u8e2a\u3002", "result": "\u4eff\u771f\u663e\u793a\u521d\u59cb\u5b9a\u4f4d\u7cbe\u5ea6\u4e3a0.02 cm\u81f342.55 cm\uff0c\u5b9e\u9a8c\u6570\u636e\u4e2d\u7684\u8f68\u8ff9\u8ddf\u8e2a\u7ed3\u679c\u4e0e\u5b9e\u9645\u8f68\u8ff9\u9ad8\u5ea6\u543b\u5408\u3002", "conclusion": "WPTrack\u901a\u8fc7\u878d\u5408Wi-Fi\u548c\u538b\u529b\u6570\u636e\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5355\u8bbe\u5907\u8ddf\u8e2a\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u5ba4\u5185\u5b9a\u4f4d\u3002"}}
{"id": "2508.09875", "pdf": "https://arxiv.org/pdf/2508.09875", "abs": "https://arxiv.org/abs/2508.09875", "authors": ["Jinbao Chen", "Boyao Ding", "Yu Zhang", "Qingwei Li", "Fugen Tang"], "title": "An Empirical Study of CGO Usage in Go Projects -- Distribution, Purposes, Patterns and Critical Issues", "categories": ["cs.SE"], "comment": "Accepted for publication in The Journal of Systems and Software", "summary": "Multilingual software development integrates multiple languages into a single\napplication, with the Foreign Function Interface (FFI) enabling seamless\ninteraction. While FFI boosts efficiency and extensibility, it also introduces\nrisks. Existing studies focus on FFIs in languages like Python and Java,\nneglecting CGO, the emerging FFI in Go, which poses unique risks.\n  To address these concerns, we conduct an empirical study of CGO usage across\n920 open-source Go projects. Our study aims to reveal the distribution,\npatterns, purposes, and critical issues associated with CGO, offering insights\nfor developers and the Go team. We develop CGOAnalyzer, a tool to efficiently\nidentify and quantify CGO-related features. Our findings reveal that: (1) 11.3%\nof analyzed Go projects utilize CGO, with usage concentrated in a subset of\nprojects; (2) CGO serves 4 primary purposes, including system-level\ninteractions and performance optimizations, with 15 distinct usage patterns\nobserved; (3) 19 types of CGO-related issues exist, including one critical\nissue involving unnecessary pointer checks that pose risks of runtime crashes\ndue to limitations in the current Go compilation toolchain; (4) a temporary\nsolution reduces unnecessary pointer checks, mitigating crash risks, and (5) we\nsubmitted a proposal to improve the Go toolchain for a permanent fix, which has\nbeen grouped within an accepted proposal for future resolution. Our findings\nprovide valuable insights for developers and the Go team, enhancing development\nefficiency and reliability while improving the robustness of the Go toolchain.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u5206\u6790\u4e86Go\u8bed\u8a00\u4e2dCGO\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u63ed\u793a\u4e86\u5176\u5206\u5e03\u3001\u6a21\u5f0f\u3001\u76ee\u7684\u53ca\u5173\u952e\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u5de5\u5177\u94fe\u7684\u5efa\u8bae\u3002", "motivation": "\u5c3d\u7ba1FFI\u5728\u591a\u8bed\u8a00\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u63d0\u5347\u6548\u7387\uff0c\u4f46CGO\u4f5c\u4e3aGo\u7684\u65b0\u5174FFI\uff0c\u5176\u72ec\u7279\u98ce\u9669\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u7814\u7a76\u4e86920\u4e2a\u5f00\u6e90Go\u9879\u76ee\uff0c\u5f00\u53d1\u4e86CGOAnalyzer\u5de5\u5177\uff0c\u5206\u6790CGO\u7684\u4f7f\u7528\u7279\u5f81\u548c\u95ee\u9898\u3002", "result": "\u53d1\u73b011.3%\u7684\u9879\u76ee\u4f7f\u7528CGO\uff0c\u8bc6\u522b\u4e864\u79cd\u4e3b\u8981\u7528\u9014\u300115\u79cd\u6a21\u5f0f\u548c19\u7c7b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e34\u65f6\u89e3\u51b3\u65b9\u6848\u5e76\u63d0\u4ea4\u4e86\u5de5\u5177\u94fe\u6539\u8fdb\u63d0\u6848\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u548cGo\u56e2\u961f\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\uff0c\u63d0\u5347\u4e86\u5f00\u53d1\u6548\u7387\u548c\u5de5\u5177\u94fe\u7684\u7a33\u5065\u6027\u3002"}}
{"id": "2508.09171", "pdf": "https://arxiv.org/pdf/2508.09171", "abs": "https://arxiv.org/abs/2508.09171", "authors": ["D. Perera"], "title": "webMCP: Efficient AI-Native Client-Side Interaction for Agent-Ready Web Design", "categories": ["cs.NI", "cs.AI"], "comment": null, "summary": "Current AI agents create significant barriers for users by requiring\nextensive processing to understand web pages, making AI-assisted web\ninteraction slow and expensive. This paper introduces webMCP (Web Machine\nContext & Procedure), a client-side standard that embeds structured interaction\nmetadata directly into web pages, enabling more efficient human-AI\ncollaboration on existing websites. webMCP transforms how AI agents understand\nweb interfaces by providing explicit mappings between page elements and user\nactions. Instead of processing entire HTML documents, agents can access\npre-structured interaction data, dramatically reducing computational overhead\nwhile maintaining task accuracy. A comprehensive evaluation across 1,890 real\nAPI calls spanning online shopping, authentication, and content management\nscenarios demonstrates webMCP reduces processing requirements by 67.6% while\nmaintaining 97.9% task success rates compared to 98.8% for traditional\napproaches. Users experience significantly lower costs (34-63% reduction) and\nfaster response times across diverse web interactions. Statistical analysis\nconfirms these improvements are highly significant across multiple AI models.\nAn independent WordPress deployment study validates practical applicability,\nshowing consistent improvements across real-world content management workflows.\nwebMCP requires no server-side modifications, making it deployable across\nmillions of existing websites without technical barriers. These results\nestablish webMCP as a viable solution for making AI web assistance more\naccessible and sustainable, addressing the critical gap between user\ninteraction needs and AI computational requirements in production environments.", "AI": {"tldr": "webMCP\u662f\u4e00\u79cd\u5ba2\u6237\u7aef\u6807\u51c6\uff0c\u901a\u8fc7\u5728\u7f51\u9875\u4e2d\u5d4c\u5165\u7ed3\u6784\u5316\u4ea4\u4e92\u5143\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86AI\u4ee3\u7406\u7406\u89e3\u7f51\u9875\u7684\u6548\u7387\uff0c\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\u548c\u7528\u6237\u6210\u672c\u3002", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u9700\u8981\u5927\u91cf\u5904\u7406\u624d\u80fd\u7406\u89e3\u7f51\u9875\uff0c\u5bfc\u81f4\u4ea4\u4e92\u7f13\u6162\u4e14\u6602\u8d35\uff0cwebMCP\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "webMCP\u76f4\u63a5\u5728\u7f51\u9875\u4e2d\u5d4c\u5165\u7ed3\u6784\u5316\u4ea4\u4e92\u5143\u6570\u636e\uff0c\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u660e\u786e\u7684\u9875\u9762\u5143\u7d20\u4e0e\u7528\u6237\u52a8\u4f5c\u6620\u5c04\uff0c\u51cf\u5c11\u5bf9\u5b8c\u6574HTML\u6587\u6863\u7684\u5904\u7406\u3002", "result": "\u57281890\u4e2a\u771f\u5b9eAPI\u8c03\u7528\u4e2d\uff0cwebMCP\u5c06\u5904\u7406\u9700\u6c42\u964d\u4f4e67.6%\uff0c\u4efb\u52a1\u6210\u529f\u7387\u4fdd\u6301\u572897.9%\uff0c\u7528\u6237\u6210\u672c\u51cf\u5c1134-63%\uff0c\u54cd\u5e94\u65f6\u95f4\u66f4\u5feb\u3002", "conclusion": "webMCP\u65e0\u9700\u670d\u52a1\u5668\u7aef\u4fee\u6539\uff0c\u53ef\u90e8\u7f72\u4e8e\u73b0\u6709\u7f51\u7ad9\uff0c\u663e\u8457\u63d0\u5347\u4e86AI\u8f85\u52a9\u7f51\u9875\u4ea4\u4e92\u7684\u6548\u7387\u548c\u53ef\u6301\u7eed\u6027\u3002"}}
{"id": "2508.09219", "pdf": "https://arxiv.org/pdf/2508.09219", "abs": "https://arxiv.org/abs/2508.09219", "authors": ["Wilder Baldwin", "Sepideh Ghanavati", "Manuel Woersdoerfer"], "title": "Understanding Ethical Practices in AI: Insights from a Cross-Role, Cross-Region Survey of AI Development Teams", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.SE"], "comment": "Under Review", "summary": "Recent advances in AI applications have raised growing concerns about the\nneed for ethical guidelines and regulations to mitigate the risks posed by\nthese technologies. In this paper, we present a mixed-method survey study -\ncombining statistical and qualitative analyses - to examine the ethical\nperceptions, practices, and knowledge of individuals involved in various AI\ndevelopment roles. Our survey includes 414 participants from 43 countries,\nrepresenting roles such as AI managers, analysts, developers, quality assurance\nprofessionals, and information security and privacy experts. The results reveal\nvarying degrees of familiarity and experience with AI ethics principles,\ngovernment initiatives, and risk mitigation strategies across roles, regions,\nand other demographic factors. Our findings highlight the importance of a\ncollaborative, role-sensitive approach, involving diverse stakeholders in\nethical decision-making throughout the AI development lifecycle. We advocate\nfor developing tailored, inclusive solutions to address ethical challenges in\nAI development, and we propose future research directions and educational\nstrategies to promote ethics-aware AI practices.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u8c03\u67e5\u4e86AI\u5f00\u53d1\u4eba\u5458\u7684\u4f26\u7406\u8ba4\u77e5\u4e0e\u5b9e\u8df5\uff0c\u5f3a\u8c03\u89d2\u8272\u654f\u611f\u6027\u548c\u591a\u65b9\u534f\u4f5c\u7684\u91cd\u8981\u6027\u3002", "motivation": "AI\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\u5f15\u53d1\u4f26\u7406\u62c5\u5fe7\uff0c\u9700\u5236\u5b9a\u6307\u5357\u548c\u6cd5\u89c4\u4ee5\u964d\u4f4e\u98ce\u9669\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff08\u7edf\u8ba1\u4e0e\u5b9a\u6027\u5206\u6790\uff09\uff0c\u8c03\u67e5414\u540d\u6765\u81ea43\u56fd\u7684AI\u5f00\u53d1\u4eba\u5458\u3002", "result": "\u4e0d\u540c\u89d2\u8272\u3001\u5730\u533a\u5bf9AI\u4f26\u7406\u7684\u719f\u6089\u5ea6\u548c\u5b9e\u8df5\u7ecf\u9a8c\u5b58\u5728\u5dee\u5f02\uff0c\u9700\u89d2\u8272\u654f\u611f\u7684\u534f\u4f5c\u65b9\u6848\u3002", "conclusion": "\u547c\u5401\u5b9a\u5236\u5316\u89e3\u51b3\u65b9\u6848\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u63a8\u52a8\u4f26\u7406\u610f\u8bc6\u5728AI\u5b9e\u8df5\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2508.09161", "pdf": "https://arxiv.org/pdf/2508.09161", "abs": "https://arxiv.org/abs/2508.09161", "authors": ["Muhammad Umair Danish", "Kashif Ali", "Kamran Siddiqui", "Katarina Grolinger"], "title": "Physics-Guided Memory Network for Building Energy Modeling", "categories": ["cs.LG", "cs.AI"], "comment": "Published version. 12 pages, 6 figures. Open access under CC BY-NC-ND\n  4.0 license. Publisher: Elsevier. Journal: Energy and AI", "summary": "Accurate energy consumption forecasting is essential for efficient resource\nmanagement and sustainability in the building sector. Deep learning models are\nhighly successful but struggle with limited historical data and become unusable\nwhen historical data are unavailable, such as in newly constructed buildings.\nOn the other hand, physics-based models, such as EnergyPlus, simulate energy\nconsumption without relying on historical data but require extensive building\nparameter specifications and considerable time to model a building. This paper\nintroduces a Physics-Guided Memory Network (PgMN), a neural network that\nintegrates predictions from deep learning and physics-based models to address\ntheir limitations. PgMN comprises a Parallel Projection Layers to process\nincomplete inputs, a Memory Unit to account for persistent biases, and a Memory\nExperience Module to optimally extend forecasts beyond their input range and\nproduce output. Theoretical evaluation shows that components of PgMN are\nmathematically valid for performing their respective tasks. The PgMN was\nevaluated on short-term energy forecasting at an hourly resolution, critical\nfor operational decision-making in smart grid and smart building systems.\nExperimental validation shows accuracy and applicability of PgMN in diverse\nscenarios such as newly constructed buildings, missing data, sparse historical\ndata, and dynamic infrastructure changes. This paper provides a promising\nsolution for energy consumption forecasting in dynamic building environments,\nenhancing model applicability in scenarios where historical data are limited or\nunavailable or when physics-based models are inadequate.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u7269\u7406\u6a21\u578b\u7684Physics-Guided Memory Network (PgMN)\uff0c\u7528\u4e8e\u89e3\u51b3\u5efa\u7b51\u80fd\u8017\u9884\u6d4b\u4e2d\u5386\u53f2\u6570\u636e\u4e0d\u8db3\u6216\u65e0\u6570\u636e\u7684\u95ee\u9898\u3002", "motivation": "\u5efa\u7b51\u80fd\u8017\u9884\u6d4b\u5bf9\u8d44\u6e90\u7ba1\u7406\u548c\u53ef\u6301\u7eed\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6df1\u5ea6\u5b66\u4e60\u4f9d\u8d56\u5386\u53f2\u6570\u636e\uff0c\u800c\u7269\u7406\u6a21\u578b\u9700\u8981\u5927\u91cf\u53c2\u6570\u548c\u65f6\u95f4\u3002PgMN\u65e8\u5728\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u3002", "method": "PgMN\u5305\u542b\u5e76\u884c\u6295\u5f71\u5c42\u5904\u7406\u4e0d\u5b8c\u6574\u8f93\u5165\u3001\u8bb0\u5fc6\u5355\u5143\u5904\u7406\u6301\u7eed\u504f\u5dee\u3001\u8bb0\u5fc6\u7ecf\u9a8c\u6a21\u5757\u6269\u5c55\u9884\u6d4b\u8303\u56f4\u3002", "result": "PgMN\u5728\u77ed\u671f\u80fd\u8017\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u65b0\u5efa\u7b51\u3001\u6570\u636e\u7f3a\u5931\u3001\u7a00\u758f\u5386\u53f2\u6570\u636e\u7b49\u573a\u666f\u3002", "conclusion": "PgMN\u4e3a\u52a8\u6001\u5efa\u7b51\u73af\u5883\u4e2d\u7684\u80fd\u8017\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u6269\u5c55\u4e86\u6a21\u578b\u5728\u6570\u636e\u4e0d\u8db3\u6216\u65e0\u6570\u636e\u573a\u666f\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2508.09173", "pdf": "https://arxiv.org/pdf/2508.09173", "abs": "https://arxiv.org/abs/2508.09173", "authors": ["Hao Xu", "Long Peng", "Shezheng Song", "Xiaodong Liu", "Ma Jun", "Shasha Li", "Jie Yu", "Xiaoguang Mao"], "title": "Camel: Energy-Aware LLM Inference on Resource-Constrained Devices", "categories": ["cs.NI"], "comment": null, "summary": "Most Large Language Models (LLMs) are currently deployed in the cloud, with\nusers relying on internet connectivity for access. However, this paradigm faces\nchallenges such as network latency, privacy concerns, and bandwidth limits.\nThus, deploying LLMs on edge devices has become an important research focus. In\nedge inference, request latency is critical as high latency can impair\nreal-time tasks. At the same time, edge devices usually have limited battery\ncapacity, making energy consumption another major concern. Balancing energy\nconsumption and inference latency is essential. To address this, we propose an\nLLM inference energy management framework that optimizes GPU frequency and\nbatch size to balance latency and energy consumption. By effectively managing\nthe exploration-exploitation dilemma in configuration search, the framework\nfinds the optimal settings. The framework was implemented on the NVIDIA Jetson\nAGX Orin platform, and a series of experimental validations were conducted.\nResults demonstrate that, compared to the default configuration, our framework\nreduces energy delay product (EDP) by 12.4%-29.9%, achieving a better balance\nbetween energy consumption and latency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cdLLM\u63a8\u7406\u80fd\u91cf\u7ba1\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316GPU\u9891\u7387\u548c\u6279\u91cf\u5927\u5c0f\uff0c\u5e73\u8861\u5ef6\u8fdf\u548c\u80fd\u8017\uff0c\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u3002", "motivation": "\u5f53\u524dLLM\u4e3b\u8981\u90e8\u7f72\u5728\u4e91\u7aef\uff0c\u9762\u4e34\u7f51\u7edc\u5ef6\u8fdf\u3001\u9690\u79c1\u548c\u5e26\u5bbd\u9650\u5236\u7b49\u95ee\u9898\uff0c\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u6210\u4e3a\u7814\u7a76\u91cd\u70b9\uff0c\u4f46\u9700\u89e3\u51b3\u80fd\u8017\u4e0e\u5ef6\u8fdf\u7684\u5e73\u8861\u3002", "method": "\u63d0\u51fa\u6846\u67b6\u4f18\u5316GPU\u9891\u7387\u548c\u6279\u91cf\u5927\u5c0f\uff0c\u901a\u8fc7\u63a2\u7d22-\u5229\u7528\u7b56\u7565\u641c\u7d22\u6700\u4f18\u914d\u7f6e\uff0c\u5e76\u5728NVIDIA Jetson AGX Orin\u5e73\u53f0\u4e0a\u5b9e\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6846\u67b6\u6bd4\u9ed8\u8ba4\u914d\u7f6e\u51cf\u5c1112.4%-29.9%\u7684EDP\uff0c\u66f4\u597d\u5730\u5e73\u8861\u4e86\u80fd\u8017\u4e0e\u5ef6\u8fdf\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684LLM\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u80fd\u8017\u4e0e\u5ef6\u8fdf\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2508.09815", "pdf": "https://arxiv.org/pdf/2508.09815", "abs": "https://arxiv.org/abs/2508.09815", "authors": ["Klaudia Krawiecka", "Christian Schroeder de Witt"], "title": "Extending the OWASP Multi-Agentic System Threat Modeling Guide: Insights from Multi-Agent Security Research", "categories": ["cs.MA", "cs.CR", "cs.SE"], "comment": null, "summary": "We propose an extension to the OWASP Multi-Agentic System (MAS) Threat\nModeling Guide, translating recent anticipatory research in multi-agent\nsecurity (MASEC) into practical guidance for addressing challenges unique to\nlarge language model (LLM)-driven multi-agent architectures. Although OWASP's\nexisting taxonomy covers many attack vectors, our analysis identifies gaps in\nmodeling failures, including, but not limited to: reasoning collapse across\nplanner-executor chains, metric overfitting, unsafe delegation escalation,\nemergent covert coordination, and heterogeneous multi-agent exploits. We\nintroduce additional threat classes and scenarios grounded in practical MAS\ndeployments, highlighting risks from benign goal drift, cross-agent\nhallucination propagation, affective prompt framing, and multi-agent backdoors.\nWe also outline evaluation strategies, including robustness testing,\ncoordination assessment, safety enforcement, and emergent behavior monitoring,\nto ensure complete coverage. This work complements the framework of OWASP by\nexpanding its applicability to increasingly complex, autonomous, and adaptive\nmulti-agent systems, with the goal of improving security posture and resilience\nin real world deployments.", "AI": {"tldr": "\u6269\u5c55OWASP\u591a\u4ee3\u7406\u7cfb\u7edf\u5a01\u80c1\u5efa\u6a21\u6307\u5357\uff0c\u586b\u8865\u73b0\u6709\u5206\u7c7b\u5728LLM\u9a71\u52a8\u591a\u4ee3\u7406\u67b6\u6784\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u63d0\u51fa\u65b0\u5a01\u80c1\u7c7b\u522b\u548c\u8bc4\u4f30\u7b56\u7565\u3002", "motivation": "\u73b0\u6709OWASP\u6307\u5357\u5728\u591a\u4ee3\u7406\u7cfb\u7edf\uff08\u5c24\u5176\u662fLLM\u9a71\u52a8\u67b6\u6784\uff09\u4e2d\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8865\u5145\u4ee5\u5e94\u5bf9\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u65b0\u6311\u6218\u3002", "method": "\u5206\u6790\u73b0\u6709\u5a01\u80c1\u6a21\u578b\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u65b0\u5a01\u80c1\u7c7b\u522b\uff08\u5982\u63a8\u7406\u94fe\u5d29\u6e83\u3001\u5ea6\u91cf\u8fc7\u62df\u5408\u7b49\uff09\uff0c\u5e76\u8bbe\u8ba1\u8bc4\u4f30\u7b56\u7565\uff08\u5982\u9c81\u68d2\u6027\u6d4b\u8bd5\u3001\u534f\u8c03\u8bc4\u4f30\uff09\u3002", "result": "\u6269\u5c55\u4e86OWASP\u6846\u67b6\uff0c\u589e\u5f3a\u4e86\u5bf9\u590d\u6742\u591a\u4ee3\u7406\u7cfb\u7edf\u7684\u5b89\u5168\u8986\u76d6\uff0c\u63d0\u5347\u4e86\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u5b89\u5168\u6027\u548c\u5f39\u6027\u3002", "conclusion": "\u901a\u8fc7\u8865\u5145\u65b0\u5a01\u80c1\u7c7b\u522b\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u591a\u4ee3\u7406\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u9002\u5e94\u6027\uff0c\u9002\u7528\u4e8e\u66f4\u590d\u6742\u7684\u5b9e\u9645\u573a\u666f\u3002"}}
{"id": "2508.09162", "pdf": "https://arxiv.org/pdf/2508.09162", "abs": "https://arxiv.org/abs/2508.09162", "authors": ["Konstantinos Vasili", "Zachery T. Dahm", "William Richards", "Stylianos Chatzidakis"], "title": "An Unsupervised Deep XAI Framework for Localization of Concurrent Replay Attacks in Nuclear Reactor Signals", "categories": ["cs.LG"], "comment": null, "summary": "Next generation advanced nuclear reactors are expected to be smaller both in\nsize and power output, relying extensively on fully digital instrumentation and\ncontrol systems. These reactors will generate a large flow of information in\nthe form of multivariate time series data, conveying simultaneously various non\nlinear cyber physical, process, control, sensor, and operational states.\nEnsuring data integrity against deception attacks is becoming increasingly\nimportant for networked communication and a requirement for safe and reliable\noperation. Current efforts to address replay attacks, almost universally focus\non watermarking or supervised anomaly detection approaches without further\nidentifying and characterizing the root cause of the anomaly. In addition,\nthese approaches rely mostly on synthetic data with uncorrelated Gaussian\nprocess and measurement noise and full state feedback or are limited to\nunivariate signals, signal stationarity, linear quadratic regulators, or other\nlinear-time invariant state-space which may fail to capture any unmodeled\nsystem dynamics. In the realm of regulated nuclear cyber-physical systems,\nadditional work is needed on characterization of replay attacks and\nexplainability of predictions using real data. Here, we propose an unsupervised\nexplainable AI framework based on a combination of autoencoder and customized\nwindowSHAP algorithm to fully characterize real-time replay attacks, i.e.,\ndetection, source identification, timing and type, of increasing complexity\nduring a dynamic time evolving reactor process. The proposed XAI framework was\nbenchmarked on several real world datasets from Purdue's nuclear reactor PUR-1\nwith up to six signals concurrently being replayed. In all cases, the XAI\nframework was able to detect and identify the source and number of signals\nbeing replayed and the duration of the falsification with 95 percent or better\naccuracy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u7f16\u7801\u5668\u548c\u5b9a\u5236\u5316windowSHAP\u7b97\u6cd5\u7684\u65e0\u76d1\u7763\u53ef\u89e3\u91caAI\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u65f6\u68c0\u6d4b\u548c\u8868\u5f81\u6838\u53cd\u5e94\u5806\u4e2d\u7684\u91cd\u653e\u653b\u51fb\u3002", "motivation": "\u65b0\u4e00\u4ee3\u6838\u53cd\u5e94\u5806\u4f9d\u8d56\u6570\u5b57\u5316\u7cfb\u7edf\uff0c\u6570\u636e\u5b8c\u6574\u6027\u5bf9\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5408\u6210\u6570\u636e\u6216\u7ebf\u6027\u6a21\u578b\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u9645\u9700\u6c42\u3002", "method": "\u7ed3\u5408\u81ea\u7f16\u7801\u5668\u548cwindowSHAP\u7b97\u6cd5\uff0c\u5f00\u53d1\u65e0\u76d1\u7763\u53ef\u89e3\u91caAI\u6846\u67b6\uff0c\u68c0\u6d4b\u5e76\u8868\u5f81\u91cd\u653e\u653b\u51fb\u3002", "result": "\u5728PUR-1\u6838\u53cd\u5e94\u5806\u7684\u771f\u5b9e\u6570\u636e\u6d4b\u8bd5\u4e2d\uff0c\u6846\u67b6\u68c0\u6d4b\u548c\u8868\u5f81\u91cd\u653e\u653b\u51fb\u7684\u51c6\u786e\u7387\u8fbe95%\u4ee5\u4e0a\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6838\u53cd\u5e94\u5806\u6570\u636e\u5b89\u5168\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09184", "pdf": "https://arxiv.org/pdf/2508.09184", "abs": "https://arxiv.org/abs/2508.09184", "authors": ["Zineddine Bettouche", "Khalid Ali", "Andreas Fischer", "Andreas Kassler"], "title": "HiSTM: Hierarchical Spatiotemporal Mamba for Cellular Traffic Forecasting", "categories": ["cs.NI", "cs.AI"], "comment": null, "summary": "Cellular traffic forecasting is essential for network planning, resource\nallocation, or load-balancing traffic across cells. However, accurate\nforecasting is difficult due to intricate spatial and temporal patterns that\nexist due to the mobility of users. Existing AI-based traffic forecasting\nmodels often trade-off accuracy and computational efficiency. We present\nHierarchical SpatioTemporal Mamba (HiSTM), which combines a dual spatial\nencoder with a Mamba-based temporal module and attention mechanism. HiSTM\nemploys selective state space methods to capture spatial and temporal patterns\nin network traffic. In our evaluation, we use a real-world dataset to compare\nHiSTM against several baselines, showing a 29.4% MAE improvement over the STN\nbaseline while using 94% fewer parameters. We show that the HiSTM generalizes\nwell across different datasets and improves in accuracy over longer\ntime-horizons.", "AI": {"tldr": "HiSTM\u662f\u4e00\u79cd\u7ed3\u5408\u53cc\u7a7a\u95f4\u7f16\u7801\u5668\u548cMamba\u65f6\u5e8f\u6a21\u5757\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u8702\u7a9d\u6d41\u91cf\u9884\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u8702\u7a9d\u6d41\u91cf\u9884\u6d4b\u5bf9\u7f51\u7edc\u89c4\u5212\u548c\u8d44\u6e90\u5206\u914d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002", "method": "HiSTM\u91c7\u7528\u9009\u62e9\u6027\u72b6\u6001\u7a7a\u95f4\u65b9\u6cd5\u548c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6355\u6349\u65f6\u7a7a\u6a21\u5f0f\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cHiSTM\u6bd4STN\u57fa\u7ebfMAE\u63d0\u534729.4%\uff0c\u53c2\u6570\u51cf\u5c1194%\u3002", "conclusion": "HiSTM\u5728\u4e0d\u540c\u6570\u636e\u96c6\u548c\u957f\u65f6\u95f4\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2508.09849", "pdf": "https://arxiv.org/pdf/2508.09849", "abs": "https://arxiv.org/abs/2508.09849", "authors": ["Jan Phillipp Albrecht", "Jose R. A. Godinho", "Christina H\u00fcbers", "Deborah Schmidt"], "title": "ARI3D: A Software for Interactive Quantification of Regions in X-Ray CT 3D Images", "categories": ["cs.CV", "cs.SE"], "comment": "2 figures and 6 pages main article, 17 pages total, 8 figures total,\n  to be published in SoftwareX", "summary": "X-ray computed tomography (CT) is the main 3D technique for imaging the\ninternal microstructures of materials. Quantitative analysis of the\nmicrostructures is usually achieved by applying a sequence of steps that are\nimplemented to the entire 3D image. This is challenged by various imaging\nartifacts inherent from the technique, e.g., beam hardening and partial volume.\nConsequently, the analysis requires users to make a number of decisions to\nsegment and classify the microstructures based on the voxel gray-values. In\nthis context, a software tool, here called ARI3D, is proposed to interactively\nanalyze regions in three-dimensional X-ray CT images, assisting users through\nthe various steps of a protocol designed to classify and quantify objects\nwithin regions of a three-dimensional image. ARI3D aims to 1) Improve phase\nidentification; 2) Account for partial volume effect; 3) Increase the detection\nlimit and accuracy of object quantification; and 4) Harmonize quantitative 3D\nanalysis that can be implemented in different fields of science.", "AI": {"tldr": "ARI3D\u662f\u4e00\u6b3e\u7528\u4e8e\u4ea4\u4e92\u5f0f\u5206\u6790X\u5c04\u7ebfCT\u56fe\u50cf\u4e2d\u533a\u57df\u7684\u8f6f\u4ef6\u5de5\u5177\uff0c\u65e8\u5728\u6539\u8fdb\u76f8\u4f4d\u8bc6\u522b\u3001\u8003\u8651\u90e8\u5206\u4f53\u79ef\u6548\u5e94\u3001\u63d0\u9ad8\u68c0\u6d4b\u9650\u548c\u91cf\u5316\u51c6\u786e\u6027\uff0c\u5e76\u7edf\u4e00\u8de8\u5b66\u79d1\u76843D\u5b9a\u91cf\u5206\u6790\u3002", "motivation": "X\u5c04\u7ebfCT\u6210\u50cf\u6280\u672f\u5b58\u5728\u56fa\u6709\u6210\u50cf\u4f2a\u5f71\uff08\u5982\u675f\u786c\u5316\u548c\u90e8\u5206\u4f53\u79ef\u6548\u5e94\uff09\uff0c\u5bfc\u81f4\u7528\u6237\u9700\u57fa\u4e8e\u4f53\u7d20\u7070\u5ea6\u503c\u505a\u51fa\u591a\u9879\u51b3\u7b56\u6765\u5206\u5272\u548c\u5206\u7c7b\u5fae\u89c2\u7ed3\u6784\u3002ARI3D\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7b80\u5316\u5206\u6790\u6d41\u7a0b\u3002", "method": "\u63d0\u51faARI3D\u8f6f\u4ef6\u5de5\u5177\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u5206\u67903D X\u5c04\u7ebfCT\u56fe\u50cf\u4e2d\u7684\u533a\u57df\uff0c\u534f\u52a9\u7528\u6237\u5b8c\u6210\u5206\u7c7b\u548c\u91cf\u5316\u534f\u8bae\u4e2d\u7684\u5404\u4e2a\u6b65\u9aa4\u3002", "result": "ARI3D\u80fd\u591f\u6539\u8fdb\u76f8\u4f4d\u8bc6\u522b\u3001\u5904\u7406\u90e8\u5206\u4f53\u79ef\u6548\u5e94\u3001\u63d0\u9ad8\u68c0\u6d4b\u9650\u548c\u91cf\u5316\u51c6\u786e\u6027\uff0c\u5e76\u652f\u6301\u8de8\u5b66\u79d1\u7684\u7edf\u4e003D\u5b9a\u91cf\u5206\u6790\u3002", "conclusion": "ARI3D\u4e3aX\u5c04\u7ebfCT\u56fe\u50cf\u7684\u5b9a\u91cf\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u5de5\u5177\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6280\u672f\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2508.09163", "pdf": "https://arxiv.org/pdf/2508.09163", "abs": "https://arxiv.org/abs/2508.09163", "authors": ["Ziheng Wang", "Pedro Reviriego", "Farzad Niknia", "Zhen Gao", "Javier Conde", "Shanshan Liu", "Fabrizio Lombardi"], "title": "Energy-Efficient Stochastic Computing (SC) Neural Networks for Internet of Things Devices With Layer-Wise Adjustable Sequence Length (ASL)", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Stochastic computing (SC) has emerged as an efficient low-power alternative\nfor deploying neural networks (NNs) in resource-limited scenarios, such as the\nInternet of Things (IoT). By encoding values as serial bitstreams, SC\nsignificantly reduces energy dissipation compared to conventional\nfloating-point (FP) designs; however, further improvement of layer-wise\nmixed-precision implementation for SC remains unexplored. This article\nintroduces Adjustable Sequence Length (ASL), a novel scheme that applies\nmixed-precision concepts specifically to SC NNs. By introducing an\noperator-norm-based theoretical model, this article shows that truncation noise\ncan cumulatively propagate through the layers by the estimated amplification\nfactors. An extended sensitivity analysis is presented, using random forest\n(RF) regression to evaluate multilayer truncation effects and validate the\nalignment of theoretical predictions with practical network behaviors. To\naccommodate different application scenarios, this article proposes two\ntruncation strategies (coarse-grained and fine-grained), which apply diverse\nsequence length configurations at each layer. Evaluations on a pipelined SC MLP\nsynthesized at 32nm demonstrate that ASL can reduce energy and latency\noverheads by up to over 60% with negligible accuracy loss. It confirms the\nfeasibility of the ASL scheme for IoT applications and highlights the distinct\nadvantages of mixed-precision truncation in SC designs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aASL\u7684\u65b0\u65b9\u6848\uff0c\u5c06\u6df7\u5408\u7cbe\u5ea6\u6982\u5ff5\u5e94\u7528\u4e8e\u968f\u673a\u8ba1\u7b97\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u7406\u8bba\u6a21\u578b\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u80fd\u8017\u548c\u5ef6\u8fdf\u3002", "motivation": "\u968f\u673a\u8ba1\u7b97\uff08SC\uff09\u5728\u8d44\u6e90\u53d7\u9650\u573a\u666f\uff08\u5982\u7269\u8054\u7f51\uff09\u4e2d\u662f\u4e00\u79cd\u9ad8\u6548\u4f4e\u529f\u8017\u7684\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u65b9\u5f0f\uff0c\u4f46\u6df7\u5408\u7cbe\u5ea6\u5b9e\u73b0\u7684\u8fdb\u4e00\u6b65\u4f18\u5316\u5c1a\u672a\u63a2\u7d22\u3002", "method": "\u5f15\u5165ASL\u65b9\u6848\uff0c\u57fa\u4e8e\u7b97\u5b50\u8303\u6570\u7406\u8bba\u6a21\u578b\u5206\u6790\u622a\u65ad\u566a\u58f0\u7684\u7d2f\u79ef\u4f20\u64ad\uff0c\u5e76\u901a\u8fc7\u968f\u673a\u68ee\u6797\u56de\u5f52\u8fdb\u884c\u654f\u611f\u6027\u5206\u6790\u3002\u63d0\u51fa\u7c97\u7c92\u5ea6\u548c\u7ec6\u7c92\u5ea6\u4e24\u79cd\u622a\u65ad\u7b56\u7565\u3002", "result": "\u572832nm\u5de5\u827a\u4e0b\u5408\u6210\u7684SC MLP\u4e0a\uff0cASL\u65b9\u6848\u53ef\u964d\u4f4e60%\u4ee5\u4e0a\u7684\u80fd\u8017\u548c\u5ef6\u8fdf\uff0c\u4e14\u7cbe\u5ea6\u635f\u5931\u53ef\u5ffd\u7565\u3002", "conclusion": "ASL\u65b9\u6848\u5728\u7269\u8054\u7f51\u5e94\u7528\u4e2d\u5177\u6709\u53ef\u884c\u6027\uff0c\u5e76\u7a81\u663e\u4e86\u6df7\u5408\u7cbe\u5ea6\u622a\u65ad\u5728SC\u8bbe\u8ba1\u4e2d\u7684\u72ec\u7279\u4f18\u52bf\u3002"}}
{"id": "2508.09197", "pdf": "https://arxiv.org/pdf/2508.09197", "abs": "https://arxiv.org/abs/2508.09197", "authors": ["Ilias Chatzistefanidis", "Andrea Leone", "Ali Yaghoubian", "Mikel Irazabal", "Sehad Nassim", "Lina Bariah", "Merouane Debbah", "Navid Nikaein"], "title": "MX-AI: Agentic Observability and Control Platform for Open and AI-RAN", "categories": ["cs.NI", "cs.AI"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Future 6G radio access networks (RANs) will be artificial intelligence\n(AI)-native: observed, reasoned about, and re-configured by autonomous agents\ncooperating across the cloud-edge continuum. We introduce MX-AI, the first\nend-to-end agentic system that (i) instruments a live 5G Open RAN testbed based\non OpenAirInterface (OAI) and FlexRIC, (ii) deploys a graph of\nLarge-Language-Model (LLM)-powered agents inside the Service Management and\nOrchestration (SMO) layer, and (iii) exposes both observability and control\nfunctions for 6G RAN resources through natural-language intents. On 50\nrealistic operational queries, MX-AI attains a mean answer quality of 4.1/5.0\nand 100 % decision-action accuracy, while incurring only 8.8 seconds end-to-end\nlatency when backed by GPT-4.1. Thus, it matches human-expert performance,\nvalidating its practicality in real settings. We publicly release the agent\ngraph, prompts, and evaluation harness to accelerate open research on AI-native\nRANs. A live demo is presented here:\nhttps://www.youtube.com/watch?v=CEIya7988Ug&t=285s&ab_channel=BubbleRAN", "AI": {"tldr": "MX-AI\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684AI\u7cfb\u7edf\uff0c\u7528\u4e8e6G\u65e0\u7ebf\u63a5\u5165\u7f51\u7edc\uff08RAN\uff09\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u610f\u56fe\u5b9e\u73b0\u89c2\u5bdf\u548c\u63a7\u5236\u529f\u80fd\uff0c\u6027\u80fd\u63a5\u8fd1\u4eba\u7c7b\u4e13\u5bb6\u6c34\u5e73\u3002", "motivation": "\u672a\u67656G\u7f51\u7edc\u9700\u8981AI\u539f\u751f\u652f\u6301\uff0cMX-AI\u65e8\u5728\u901a\u8fc7\u81ea\u4e3b\u4ee3\u7406\u5b9e\u73b0\u7f51\u7edc\u7684\u89c2\u5bdf\u3001\u63a8\u7406\u548c\u91cd\u65b0\u914d\u7f6e\u3002", "method": "MX-AI\u57fa\u4e8eOpenAirInterface\u548cFlexRIC\u6784\u5efa\u4e86\u4e00\u4e2a5G Open RAN\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5e76\u5728SMO\u5c42\u90e8\u7f72\u4e86\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u4ee3\u7406\u56fe\u3002", "result": "\u572850\u4e2a\u5b9e\u9645\u67e5\u8be2\u4e2d\uff0cMX-AI\u7684\u5e73\u5747\u56de\u7b54\u8d28\u91cf\u4e3a4.1/5.0\uff0c\u51b3\u7b56\u51c6\u786e\u7387\u8fbe100%\uff0c\u7aef\u5230\u7aef\u5ef6\u8fdf\u4ec5\u4e3a8.8\u79d2\u3002", "conclusion": "MX-AI\u9a8c\u8bc1\u4e86AI\u539f\u751fRAN\u7684\u5b9e\u7528\u6027\uff0c\u5e76\u516c\u5f00\u4e86\u4ee3\u7406\u56fe\u3001\u63d0\u793a\u548c\u8bc4\u4f30\u5de5\u5177\u4ee5\u63a8\u52a8\u5f00\u653e\u7814\u7a76\u3002"}}
{"id": "2508.09164", "pdf": "https://arxiv.org/pdf/2508.09164", "abs": "https://arxiv.org/abs/2508.09164", "authors": ["Min Tang", "Peng Lu", "Qing Feng"], "title": "Generating Feasible and Diverse Synthetic Populations Using Diffusion Models", "categories": ["cs.LG"], "comment": null, "summary": "Population synthesis is a critical task that involves generating synthetic\nyet realistic representations of populations. It is a fundamental problem in\nagent-based modeling (ABM), which has become the standard to analyze\nintelligent transportation systems. The synthetic population serves as the\nprimary input for ABM transportation simulation, with traveling agents\nrepresented by population members. However, when the number of attributes\ndescribing agents becomes large, survey data often cannot densely support the\njoint distribution of the attributes in the population due to the curse of\ndimensionality. This sparsity makes it difficult to accurately model and\nproduce the population. Interestingly, deep generative models trained from\navailable sample data can potentially synthesize possible attribute\ncombinations that present in the actual population but do not exist in the\nsample data(called sampling zeros). Nevertheless, this comes at the cost of\nfalsely generating the infeasible attribute combinations that do not exist in\nthe population (called structural zeros). In this study, a novel diffusion\nmodel-based population synthesis method is proposed to estimate the underlying\njoint distribution of a population. This approach enables the recovery of\nnumerous missing sampling zeros while keeping the generated structural zeros\nminimal. Our method is compared with other recently proposed approaches such as\nVariational Autoencoders (VAE) and Generative Adversarial Network (GAN)\napproaches, which have shown success in high dimensional tabular population\nsynthesis. We assess the performance of the synthesized outputs using a range\nof metrics, including marginal distribution similarity, feasibility, and\ndiversity. The results demonstrate that our proposed method outperforms\nprevious approaches in achieving a better balance between the feasibility and\ndiversity of the synthesized population.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u4eba\u53e3\u5408\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f30\u8ba1\u4eba\u53e3\u7684\u8054\u5408\u5206\u5e03\uff0c\u80fd\u591f\u6062\u590d\u7f3a\u5931\u7684\u91c7\u6837\u96f6\u503c\u5e76\u6700\u5c0f\u5316\u7ed3\u6784\u96f6\u503c\uff0c\u4f18\u4e8eVAE\u548cGAN\u65b9\u6cd5\u3002", "motivation": "\u4eba\u53e3\u5408\u6210\u662f\u4ee3\u7406\u5efa\u6a21\uff08ABM\uff09\u4e2d\u7684\u5173\u952e\u4efb\u52a1\uff0c\u4f46\u9ad8\u7ef4\u5c5e\u6027\u5bfc\u81f4\u8c03\u67e5\u6570\u636e\u7a00\u758f\uff0c\u96be\u4ee5\u51c6\u786e\u5efa\u6a21\u3002\u73b0\u6709\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u80fd\u751f\u6210\u91c7\u6837\u96f6\u503c\uff0c\u4f46\u4f1a\u5f15\u5165\u7ed3\u6784\u96f6\u503c\u3002", "method": "\u91c7\u7528\u6269\u6563\u6a21\u578b\u4f30\u8ba1\u4eba\u53e3\u7684\u8054\u5408\u5206\u5e03\uff0c\u65e8\u5728\u6062\u590d\u91c7\u6837\u96f6\u503c\u5e76\u51cf\u5c11\u7ed3\u6784\u96f6\u503c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8fb9\u9645\u5206\u5e03\u76f8\u4f3c\u6027\u3001\u53ef\u884c\u6027\u548c\u591a\u6837\u6027\u65b9\u9762\u4f18\u4e8eVAE\u548cGAN\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u6269\u6563\u6a21\u578b\u65b9\u6cd5\u5728\u4eba\u53e3\u5408\u6210\u4e2d\u5b9e\u73b0\u4e86\u53ef\u884c\u6027\u4e0e\u591a\u6837\u6027\u7684\u66f4\u597d\u5e73\u8861\u3002"}}
{"id": "2508.09208", "pdf": "https://arxiv.org/pdf/2508.09208", "abs": "https://arxiv.org/abs/2508.09208", "authors": ["Muqing Li", "Ning Li", "Xin Yuan", "Wenchao Xu", "Quan Chen", "Song Guo", "Haijun Zhang"], "title": "CoMoE: Collaborative Optimization of Expert Aggregation and Offloading for MoE-based LLMs at Edge", "categories": ["cs.NI", "cs.AI"], "comment": null, "summary": "The proliferation of large language models (LLMs) has driven the adoption of\nMixture-of-Experts (MoE) architectures as a promising solution to scale model\ncapacity while controlling computational costs. However, deploying MoE models\nin resource-constrained mobile edge computing environments presents significant\nchallenges due to their large memory footprint and dynamic expert activation\npatterns. To address these challenges, we propose a novel dynamic\nresource-aware collaborative optimization framework that jointly optimizes\nexpert aggregation granularity and offloading strategies based on real-time\ndevice resource states, network conditions, and input characteristics in mobile\nedge environments, denoted as CoMoE. In CoMoE, we first systematically analyze\nexisting expert aggregation techniques, including expert parameter\nmerging,knowledge distillation,and parameter sharing decomposition, identifying\ntheir limitations in dynamic mobile environments.We then investigate expert\noffloading strategies encompassing expert prediction and prefetching, expert\ncaching and scheduling, and multi-tier storage architectures, revealing the\ninterdependencies between routing decisions and offloading performance.The\nCoMoE incorporates adaptive scheduling mechanisms that respond to user mobility\nand varying network conditions, enabling efficient MoE deployment across\nheterogeneous edge devices. Extensive experiments on real mobile edge testbeds\ndemonstrate that CoMoE achieves approximately 70% reduction in memory usage\ncompared to baseline methods, 10.5% lower inference latency than existing\nexpert offloading techniques, while maintaining model performance stability.\nFor large-scale MoE models (e.g,7.4B-parameter Switch-Base-128), the CoMoE\nreduces memory requirements from 15.6GB to 4.7GB, enabling deployment on\nresource-constrained mobile edge devices that previously could only support\nmuch smaller models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u8d44\u6e90\u611f\u77e5\u7684\u534f\u4f5c\u4f18\u5316\u6846\u67b6CoMoE\uff0c\u7528\u4e8e\u5728\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e2d\u9ad8\u6548\u90e8\u7f72Mixture-of-Experts\uff08MoE\uff09\u6a21\u578b\uff0c\u663e\u8457\u964d\u4f4e\u5185\u5b58\u4f7f\u7528\u548c\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "MoE\u6a21\u578b\u5728\u79fb\u52a8\u8fb9\u7f18\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u9762\u4e34\u5185\u5b58\u5360\u7528\u5927\u548c\u52a8\u6001\u4e13\u5bb6\u6fc0\u6d3b\u6a21\u5f0f\u7684\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u4f18\u5316\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "CoMoE\u901a\u8fc7\u8054\u5408\u4f18\u5316\u4e13\u5bb6\u805a\u5408\u7c92\u5ea6\u548c\u5378\u8f7d\u7b56\u7565\uff0c\u7ed3\u5408\u5b9e\u65f6\u8bbe\u5907\u8d44\u6e90\u72b6\u6001\u3001\u7f51\u7edc\u6761\u4ef6\u548c\u8f93\u5165\u7279\u5f81\uff0c\u63d0\u51fa\u81ea\u9002\u5e94\u8c03\u5ea6\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCoMoE\u5185\u5b58\u4f7f\u7528\u51cf\u5c11\u7ea670%\uff0c\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e10.5%\uff0c\u5e76\u6210\u529f\u5c06\u5927\u578bMoE\u6a21\u578b\u90e8\u7f72\u5230\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u3002", "conclusion": "CoMoE\u4e3a\u79fb\u52a8\u8fb9\u7f18\u73af\u5883\u4e2d\u7684MoE\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8d44\u6e90\u5229\u7528\u7387\u548c\u6027\u80fd\u7a33\u5b9a\u6027\u3002"}}
{"id": "2508.09165", "pdf": "https://arxiv.org/pdf/2508.09165", "abs": "https://arxiv.org/abs/2508.09165", "authors": ["Shanwei Zhang", "Deyun Zhang", "Yirao Tao", "Kexin Wang", "Shijia Geng", "Jun Li", "Qinghao Zhao", "Xingpeng Liu", "Yuxi Zhou", "Shenda Hong"], "title": "Masked Training for Robust Arrhythmia Detection from Digitalized Multiple Layout ECG Images", "categories": ["cs.LG", "cs.CV"], "comment": "18 pages, 6 figures", "summary": "Electrocardiogram (ECG) as an important tool for diagnosing cardiovascular\ndiseases such as arrhythmia. Due to the differences in ECG layouts used by\ndifferent hospitals, the digitized signals exhibit asynchronous lead time and\npartial blackout loss, which poses a serious challenge to existing models. To\naddress this challenge, the study introduced PatchECG, a framework for adaptive\nvariable block count missing representation learning based on a masking\ntraining strategy, which automatically focuses on key patches with\ncollaborative dependencies between leads, thereby achieving key recognition of\narrhythmia in ECGs with different layouts. Experiments were conducted on the\nPTB-XL dataset and 21388 asynchronous ECG images generated using ECG image kit\ntool, using the 23 Subclasses as labels. The proposed method demonstrated\nstrong robustness under different layouts, with average Area Under the Receiver\nOperating Characteristic Curve (AUROC) of 0.835 and remained stable (unchanged\nwith layout changes). In external validation based on 400 real ECG images data\nfrom Chaoyang Hospital, the AUROC for atrial fibrillation diagnosis reached\n0.778; On 12 x 1 layout ECGs, AUROC reaches 0.893. This result is superior to\nvarious classic interpolation and baseline methods, and compared to the current\noptimal large-scale pre-training model ECGFounder, it has improved by 0.111 and\n0.19.", "AI": {"tldr": "PatchECG\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u5757\u7f3a\u5931\u8868\u793a\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u4e0d\u540cECG\u5e03\u5c40\u5bfc\u81f4\u7684\u4fe1\u53f7\u5f02\u6b65\u548c\u90e8\u5206\u7f3a\u5931\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5fc3\u5f8b\u5931\u5e38\u8bc6\u522b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u4e0d\u540c\u533b\u9662\u4f7f\u7528\u7684ECG\u5e03\u5c40\u5dee\u5f02\u5bfc\u81f4\u4fe1\u53f7\u5f02\u6b65\u548c\u90e8\u5206\u7f3a\u5931\uff0c\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u5904\u7406\u3002", "method": "\u63d0\u51faPatchECG\u6846\u67b6\uff0c\u57fa\u4e8e\u63a9\u7801\u8bad\u7ec3\u7b56\u7565\uff0c\u81ea\u9002\u5e94\u5b66\u4e60\u5173\u952e\u5757\uff0c\u5e76\u5229\u7528\u5bfc\u8054\u95f4\u7684\u534f\u4f5c\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728PTB-XL\u6570\u636e\u96c6\u548c\u771f\u5b9eECG\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\uff0cAUROC\u8fbe0.835\uff0c\u4e14\u5728\u5916\u90e8\u9a8c\u8bc1\u4e2d\u8bca\u65ad\u623f\u98a4\u7684AUROC\u4e3a0.778\u3002", "conclusion": "PatchECG\u5728\u591a\u79cdECG\u5e03\u5c40\u4e0b\u8868\u73b0\u7a33\u5b9a\uff0c\u4f18\u4e8e\u7ecf\u5178\u65b9\u6cd5\u548c\u5f53\u524d\u6700\u4f18\u6a21\u578b\uff0c\u5177\u6709\u4e34\u5e8a\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.09168", "pdf": "https://arxiv.org/pdf/2508.09168", "abs": "https://arxiv.org/abs/2508.09168", "authors": ["Feiyu Wang", "Zhiyuan Zhao", "Yuandong Liu", "Da Zhang", "Junyu Gao", "Hao Sun", "Xuelong Li"], "title": "SVGen: Interpretable Vector Graphics Generation with Large Language Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Scalable Vector Graphics (SVG) is widely used in front-end development and\nUI/UX design due to its scalability, editability, and rendering efficiency.\nHowever, turning creative ideas into precise vector graphics remains a\ntime-consuming challenge. To address this, we introduce SVG-1M, a large-scale\ndataset of high-quality SVGs paired with natural language descriptions. Through\nadvanced data augmentation and annotation, we create well-aligned Text to SVG\ntraining pairs, including a subset with Chain of Thought annotations for\nenhanced semantic guidance. Based on this dataset, we propose SVGen, an\nend-to-end model that generates SVG code from natural language inputs. Our\napproach ensures semantic accuracy and structural completeness, supported by\ncurriculum learning and reinforcement learning optimization. Experiments show\nthat SVGen outperforms general large models and traditional rendering methods\nin both effectiveness and efficiency. Code, model, and dataset are available on\nGitHub.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86SVG-1M\u6570\u636e\u96c6\u548cSVGen\u6a21\u578b\uff0c\u7528\u4e8e\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210SVG\u4ee3\u7801\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5c06\u521b\u610f\u8f6c\u5316\u4e3a\u7cbe\u786e\u7684\u77e2\u91cf\u56fe\u5f62\u8017\u65f6\uff0c\u9700\u9ad8\u6548\u5de5\u5177\u652f\u6301\u3002", "method": "\u6784\u5efaSVG-1M\u6570\u636e\u96c6\uff0c\u63d0\u51faSVGen\u6a21\u578b\uff0c\u7ed3\u5408\u8bfe\u7a0b\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u3002", "result": "SVGen\u5728\u6548\u679c\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u901a\u7528\u5927\u6a21\u578b\u548c\u4f20\u7edf\u6e32\u67d3\u65b9\u6cd5\u3002", "conclusion": "SVGen\u4e3a\u77e2\u91cf\u56fe\u5f62\u751f\u6210\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u6570\u636e\u96c6\u548c\u6a21\u578b\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.09240", "pdf": "https://arxiv.org/pdf/2508.09240", "abs": "https://arxiv.org/abs/2508.09240", "authors": ["Zainab Khan", "Ahmed Hussain", "Mukesh Thakur", "Arto Hellas", "Panos Papadimitratos"], "title": "NEFMind: Parameter-Efficient Fine-Tuning of Open-Source LLMs for Telecom APIs Automation", "categories": ["cs.NI", "cs.AI", "cs.CL"], "comment": "6 pages", "summary": "The use of Service-Based Architecture in modern telecommunications has\nexponentially increased Network Functions (NFs) and Application Programming\nInterfaces (APIs), creating substantial operational complexities in service\ndiscovery and management. We introduce \\textit{NEFMind}, a framework leveraging\nparameter-efficient fine-tuning of open-source Large Language Models (LLMs) to\naddress these challenges. It integrates three core components: synthetic\ndataset generation from Network Exposure Function (NEF) API specifications,\nmodel optimization through Quantized-Low-Rank Adaptation, and performance\nevaluation via GPT-4 Ref Score and BertScore metrics. Targeting 5G\nService-Based Architecture APIs, our approach achieves 85% reduction in\ncommunication overhead compared to manual discovery methods. Experimental\nvalidation using the open-source Phi-2 model demonstrates exceptional API call\nidentification performance at 98-100% accuracy. The fine-tuned Phi-2 model\ndelivers performance comparable to significantly larger models like GPT-4 while\nmaintaining computational efficiency for telecommunications infrastructure\ndeployment. These findings validate domain-specific, parameter-efficient LLM\nstrategies for managing complex API ecosystems in next-generation\ntelecommunications networks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faNEFMind\u6846\u67b6\uff0c\u5229\u7528\u9ad8\u6548\u53c2\u6570\u5fae\u8c03\u7684\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u89e3\u51b35G\u670d\u52a1\u67b6\u6784\u4e2dAPI\u7ba1\u7406\u7684\u590d\u6742\u6027\uff0c\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u5e76\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u4ee3\u7535\u4fe1\u4e2d\u57fa\u4e8e\u670d\u52a1\u7684\u67b6\u6784\u5bfc\u81f4\u7f51\u7edc\u529f\u80fd\uff08NFs\uff09\u548cAPI\u6570\u91cf\u6fc0\u589e\uff0c\u670d\u52a1\u53d1\u73b0\u548c\u7ba1\u7406\u53d8\u5f97\u590d\u6742\u3002", "method": "NEFMind\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u4eceNEF API\u89c4\u8303\u751f\u6210\u5408\u6210\u6570\u636e\u96c6\u3001\u901a\u8fc7\u91cf\u5316\u4f4e\u79e9\u9002\u5e94\u4f18\u5316\u6a21\u578b\u3001\u4f7f\u7528GPT-4 Ref Score\u548cBertScore\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u57285G API\u7ba1\u7406\u4e2d\u901a\u4fe1\u5f00\u9500\u51cf\u5c1185%\uff0cPhi-2\u6a21\u578b\u7684API\u8c03\u7528\u8bc6\u522b\u51c6\u786e\u7387\u8fbe98-100%\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u9ad8\u6548\u53c2\u6570\u5fae\u8c03\u7684LLM\u7b56\u7565\u5728\u7ba1\u7406\u4e0b\u4e00\u4ee3\u7535\u4fe1\u7f51\u7edc\u590d\u6742API\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2508.09170", "pdf": "https://arxiv.org/pdf/2508.09170", "abs": "https://arxiv.org/abs/2508.09170", "authors": ["Amit Kumar Jaiswal", "Haiming Liu", "Ingo Frommholz"], "title": "Multimodal RAG Enhanced Visual Description", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.IR"], "comment": "Accepted by ACM CIKM 2025. 5 pages, 2 figures", "summary": "Textual descriptions for multimodal inputs entail recurrent refinement of\nqueries to produce relevant output images. Despite efforts to address\nchallenges such as scaling model size and data volume, the cost associated with\npre-training and fine-tuning remains substantial. However, pre-trained large\nmultimodal models (LMMs) encounter a modality gap, characterised by a\nmisalignment between textual and visual representations within a common\nembedding space. Although fine-tuning can potentially mitigate this gap, it is\ntypically expensive and impractical due to the requirement for extensive\ndomain-driven data. To overcome this challenge, we propose a lightweight\ntraining-free approach utilising Retrieval-Augmented Generation (RAG) to extend\nacross the modality using a linear mapping, which can be computed efficiently.\nDuring inference, this mapping is applied to images embedded by an LMM enabling\nretrieval of closest textual descriptions from the training set. These textual\ndescriptions, in conjunction with an instruction, cater as an input prompt for\nthe language model to generate new textual descriptions. In addition, we\nintroduce an iterative technique for distilling the mapping by generating\nsynthetic descriptions via the language model facilitating optimisation for\nstandard utilised image description measures. Experimental results on two\nbenchmark multimodal datasets demonstrate significant improvements.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u8de8\u6a21\u6001\u6620\u5c04\uff0c\u89e3\u51b3\u9884\u8bad\u7ec3\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u4e2d\u7684\u6a21\u6001\u9e3f\u6c9f\u95ee\u9898\u3002", "motivation": "\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u6210\u672c\u9ad8\u6602\uff0c\u4e14LMMs\u5b58\u5728\u6a21\u6001\u9e3f\u6c9f\uff08\u6587\u672c\u4e0e\u89c6\u89c9\u8868\u5f81\u4e0d\u5bf9\u9f50\uff09\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u9886\u57df\u6570\u636e\uff0c\u4e0d\u5b9e\u7528\u3002", "method": "\u91c7\u7528\u7ebf\u6027\u6620\u5c04\u7684RAG\u65b9\u6cd5\uff0c\u9ad8\u6548\u8ba1\u7b97\u8de8\u6a21\u6001\u6620\u5c04\uff1b\u63a8\u7406\u65f6\u901a\u8fc7\u6620\u5c04\u68c0\u7d22\u8bad\u7ec3\u96c6\u4e2d\u7684\u6587\u672c\u63cf\u8ff0\uff0c\u7ed3\u5408\u6307\u4ee4\u751f\u6210\u65b0\u63cf\u8ff0\uff1b\u5f15\u5165\u8fed\u4ee3\u6280\u672f\u4f18\u5316\u6620\u5c04\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u6a21\u6001\u9e3f\u6c9f\u95ee\u9898\uff0c\u4e14\u65e0\u9700\u6602\u8d35\u8bad\u7ec3\uff0c\u5177\u6709\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.09369", "pdf": "https://arxiv.org/pdf/2508.09369", "abs": "https://arxiv.org/abs/2508.09369", "authors": ["Ioannis Panitsas", "Iason Ofeidis", "Leandros Tassiulas"], "title": "On-Device Multimodal Federated Learning for Efficient Jamming Detection", "categories": ["cs.NI"], "comment": null, "summary": "Wireless networks face severe vulnerabilities from jamming attacks, which can\nsignificantly disrupt communication. Existing detection approaches are often\nunimodal, rely on centralized processing, and demand substantial computational\nresources, hindering scalability, efficiency, and deployment feasibility. To\naddress these challenges, we introduce a multimodal Federated Learning (FL)\nframework for on-device jamming detection and classification that integrates\nspectrograms with cross-layer network Key Performance Indicators (KPIs) through\na lightweight dual-encoder architecture equipped with a fusion module and a\nmultimodal projection head. This design enables privacy-preserving training and\ninference by ensuring that only model parameters are exchanged, while raw data\nremains on the device. The framework is implemented and evaluated on a wireless\nexperimental testbed using, to the best of our knowledge, the first\nover-the-air multimodal dataset with synchronized benign and three distinct\njamming scenarios. Results show that our approach surpasses state-of-the-art\nunimodal baselines by up to 15% in detection accuracy, achieves convergence\nwith 60% fewer communication rounds, and maintains low resource usage. Its\nbenefits are most evident under heterogeneous data distributions across\ndevices, where it exhibits strong robustness and reliability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u8054\u90a6\u5b66\u4e60\u7684\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u7528\u4e8e\u8bbe\u5907\u7aef\u7684\u5e72\u6270\u68c0\u6d4b\u4e0e\u5206\u7c7b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u7cbe\u5ea6\u5e76\u964d\u4f4e\u4e86\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u65e0\u7ebf\u7f51\u7edc\u6613\u53d7\u5e72\u6270\u653b\u51fb\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u591a\u4e3a\u5355\u6a21\u6001\u3001\u96c6\u4e2d\u5f0f\u4e14\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u96be\u4ee5\u6269\u5c55\u548c\u90e8\u7f72\u3002", "method": "\u91c7\u7528\u591a\u6a21\u6001\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u9891\u8c31\u56fe\u548c\u8de8\u5c42\u7f51\u7edcKPI\uff0c\u901a\u8fc7\u53cc\u7f16\u7801\u5668\u67b6\u6784\u548c\u878d\u5408\u6a21\u5757\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u8bad\u7ec3\u4e0e\u63a8\u7406\u3002", "result": "\u68c0\u6d4b\u7cbe\u5ea6\u6bd4\u73b0\u6709\u5355\u6a21\u6001\u65b9\u6cd5\u9ad815%\uff0c\u901a\u4fe1\u8f6e\u6b21\u51cf\u5c1160%\uff0c\u8d44\u6e90\u6d88\u8017\u4f4e\uff0c\u5728\u5f02\u6784\u6570\u636e\u5206\u5e03\u4e0b\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u5e72\u6270\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u5f3a\u9c81\u68d2\u6027\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2508.09174", "pdf": "https://arxiv.org/pdf/2508.09174", "abs": "https://arxiv.org/abs/2508.09174", "authors": ["Zhekai Zhou", "Shudong Liu", "Zhaokun Zhou", "Yang Liu", "Qiang Yang", "Yuesheng Zhu", "Guibo Luo"], "title": "FedMP: Tackling Medical Feature Heterogeneity in Federated Learning from a Manifold Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning (FL) is a decentralized machine learning paradigm in which\nmultiple clients collaboratively train a shared model without sharing their\nlocal private data. However, real-world applications of FL frequently encounter\nchallenges arising from the non-identically and independently distributed\n(non-IID) local datasets across participating clients, which is particularly\npronounced in the field of medical imaging, where shifts in image feature\ndistributions significantly hinder the global model's convergence and\nperformance. To address this challenge, we propose FedMP, a novel method\ndesigned to enhance FL under non-IID scenarios. FedMP employs stochastic\nfeature manifold completion to enrich the training space of individual client\nclassifiers, and leverages class-prototypes to guide the alignment of feature\nmanifolds across clients within semantically consistent subspaces, facilitating\nthe construction of more distinct decision boundaries. We validate the\neffectiveness of FedMP on multiple medical imaging datasets, including those\nwith real-world multi-center distributions, as well as on a multi-domain\nnatural image dataset. The experimental results demonstrate that FedMP\noutperforms existing FL algorithms. Additionally, we analyze the impact of\nmanifold dimensionality, communication efficiency, and privacy implications of\nfeature exposure in our method.", "AI": {"tldr": "FedMP\u662f\u4e00\u79cd\u9488\u5bf9\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\u6570\u636e\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u968f\u673a\u7279\u5f81\u6d41\u5f62\u8865\u5168\u548c\u7c7b\u539f\u578b\u5bf9\u9f50\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u5728\u975eIID\u6570\u636e\uff08\u5982\u533b\u5b66\u5f71\u50cf\uff09\u4e2d\u56e0\u7279\u5f81\u5206\u5e03\u5dee\u5f02\u5bfc\u81f4\u7684\u6a21\u578b\u6536\u655b\u548c\u6027\u80fd\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u968f\u673a\u7279\u5f81\u6d41\u5f62\u8865\u5168\u548c\u7c7b\u539f\u578b\u5bf9\u9f50\uff0c\u4f18\u5316\u5ba2\u6237\u7aef\u95f4\u7684\u7279\u5f81\u6d41\u5f62\u4e00\u81f4\u6027\u3002", "result": "\u5728\u533b\u5b66\u5f71\u50cf\u548c\u591a\u57df\u81ea\u7136\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u3002", "conclusion": "FedMP\u6709\u6548\u63d0\u5347\u4e86\u975eIID\u6570\u636e\u4e0b\u7684\u8054\u90a6\u5b66\u4e60\u6027\u80fd\uff0c\u5e76\u5206\u6790\u4e86\u6d41\u5f62\u7ef4\u5ea6\u3001\u901a\u4fe1\u6548\u7387\u548c\u9690\u79c1\u5f71\u54cd\u3002"}}
{"id": "2508.09573", "pdf": "https://arxiv.org/pdf/2508.09573", "abs": "https://arxiv.org/abs/2508.09573", "authors": ["Micha\u0142 Rzepka", "Piotr Cho\u0142da"], "title": "Metrics for Assessing Changes in Flow-based Networks", "categories": ["cs.NI", "cs.PF"], "comment": null, "summary": "This paper addresses the challenges of evaluating network performance in the\npresence of fluctuating traffic patterns, with a particular focus on the impact\nof peak data rates on network resources. We introduce a set of metrics to\nquantify network load and measure the impact of individual flows on the overall\nnetwork state. By analyzing link and flow data through percentile values and\nsample distributions, and introducing the Utilization Score metric, the\nresearch provides insights into resource utilization under varying network\nconditions. Furthermore, we employ a modified Shapley value-based approach to\nmeasure the influence of individual flows on the network, offering a better\nunderstanding of their contribution to network performance. The paper reviews\nand compares 11 metrics across various network scenarios, evaluating their\npractical relevance for research and development. Our evaluation demonstrates\nthat these metrics effectively capture changes in network state induced by\nspecific flows, with three of them offering a broad range of valuable insights\nwhile remaining relatively easy to maintain. Moreover, the methodology\ndescribed in this paper serves as a framework for future research, with the\npotential to expand and refine the set of metrics used to evaluate flow impact\non network performance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u91cf\u5316\u7f51\u7edc\u8d1f\u8f7d\u548c\u6d41\u91cf\u5f71\u54cd\u7684\u6307\u6807\uff0c\u901a\u8fc7\u767e\u5206\u4f4d\u6570\u548c\u6837\u672c\u5206\u5e03\u5206\u6790\u6570\u636e\uff0c\u5e76\u5f15\u5165\u5229\u7528\u7387\u8bc4\u5206\u6307\u6807\u3002\u91c7\u7528\u6539\u8fdb\u7684Shapley\u503c\u65b9\u6cd5\u8bc4\u4f30\u6d41\u91cf\u5bf9\u7f51\u7edc\u7684\u5f71\u54cd\uff0c\u6bd4\u8f83\u4e8611\u79cd\u6307\u6807\uff0c\u53d1\u73b0\u5176\u4e2d\u4e09\u79cd\u80fd\u6709\u6548\u6355\u6349\u7f51\u7edc\u72b6\u6001\u53d8\u5316\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u7f51\u7edc\u6027\u80fd\u8bc4\u4f30\u4e2d\u56e0\u6d41\u91cf\u6ce2\u52a8\u5e26\u6765\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5cf0\u503c\u6570\u636e\u901f\u7387\u5bf9\u7f51\u7edc\u8d44\u6e90\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u767e\u5206\u4f4d\u6570\u548c\u6837\u672c\u5206\u5e03\u5206\u6790\u94fe\u8def\u4e0e\u6d41\u91cf\u6570\u636e\uff0c\u5f15\u5165\u5229\u7528\u7387\u8bc4\u5206\u6307\u6807\uff0c\u5e76\u91c7\u7528\u6539\u8fdb\u7684Shapley\u503c\u65b9\u6cd5\u8bc4\u4f30\u6d41\u91cf\u8d21\u732e\u3002", "result": "\u6bd4\u8f83\u4e8611\u79cd\u6307\u6807\uff0c\u53d1\u73b0\u5176\u4e2d\u4e09\u79cd\u80fd\u6709\u6548\u6355\u6349\u7f51\u7edc\u72b6\u6001\u53d8\u5316\uff0c\u4e14\u6613\u4e8e\u7ef4\u62a4\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6846\u67b6\uff0c\u53ef\u6269\u5c55\u548c\u4f18\u5316\u7528\u4e8e\u8bc4\u4f30\u6d41\u91cf\u5bf9\u7f51\u7edc\u6027\u80fd\u5f71\u54cd\u7684\u6307\u6807\u96c6\u3002"}}
{"id": "2508.09176", "pdf": "https://arxiv.org/pdf/2508.09176", "abs": "https://arxiv.org/abs/2508.09176", "authors": ["Hazem Hesham Yousef Shalby", "Fabrizio Pittorino", "Francesca Palermo", "Diana Trojaniello", "Manuel Roveri"], "title": "DQT: Dynamic Quantization Training via Dequantization-Free Nested Integer Arithmetic", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The deployment of deep neural networks on resource-constrained devices relies\non quantization. While static, uniform quantization applies a fixed bit-width\nto all inputs, it fails to adapt to their varying complexity. Dynamic,\ninstance-based mixed-precision quantization promises a superior\naccuracy-efficiency trade-off by allocating higher precision only when needed.\nHowever, a critical bottleneck remains: existing methods require a costly\ndequantize-to-float and requantize-to-integer cycle to change precision,\nbreaking the integer-only hardware paradigm and compromising performance gains.\nThis paper introduces Dynamic Quantization Training (DQT), a novel framework\nthat removes this bottleneck. At the core of DQT is a nested integer\nrepresentation where lower-precision values are bit-wise embedded within\nhigher-precision ones. This design, coupled with custom integer-only\narithmetic, allows for on-the-fly bit-width switching through a near-zero-cost\nbit-shift operation. This makes DQT the first quantization framework to enable\nboth dequantization-free static mixed-precision of the backbone network, and\ntruly efficient dynamic, instance-based quantization through a lightweight\ncontroller that decides at runtime how to quantize each layer. We demonstrate\nDQT state-of-the-art performance on ResNet18 on CIFAR-10 and ResNet50 on\nImageNet. On ImageNet, our 4-bit dynamic ResNet50 achieves 77.00% top-1\naccuracy, an improvement over leading static (LSQ, 76.70%) and dynamic (DQNET,\n76.94%) methods at a comparable BitOPs budget. Crucially, DQT achieves this\nwith a bit-width transition cost of only 28.3M simple bit-shift operations, a\ndrastic improvement over the 56.6M costly Multiply-Accumulate (MAC)\nfloating-point operations required by previous dynamic approaches - unlocking a\nnew frontier in efficient, adaptive AI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u91cf\u5316\u8bad\u7ec3\uff08DQT\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5d4c\u5957\u6574\u6570\u8868\u793a\u548c\u81ea\u5b9a\u4e49\u6574\u6570\u8fd0\u7b97\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u52a8\u6001\u91cf\u5316\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u6d6e\u70b9\u8fd0\u7b97\u74f6\u9888\u3002", "motivation": "\u73b0\u6709\u52a8\u6001\u91cf\u5316\u65b9\u6cd5\u9700\u8981\u6602\u8d35\u7684\u6d6e\u70b9\u8fd0\u7b97\u6765\u5207\u6362\u7cbe\u5ea6\uff0c\u7834\u574f\u4e86\u6574\u6570\u786c\u4ef6\u8303\u5f0f\u5e76\u9650\u5236\u4e86\u6027\u80fd\u63d0\u5347\u3002", "method": "DQT\u91c7\u7528\u5d4c\u5957\u6574\u6570\u8868\u793a\u548c\u6574\u6570\u8fd0\u7b97\uff0c\u901a\u8fc7\u4f4e\u6210\u672c\u4f4d\u79fb\u64cd\u4f5c\u5b9e\u73b0\u52a8\u6001\u7cbe\u5ea6\u5207\u6362\u3002", "result": "\u5728ImageNet\u4e0a\uff0c4\u4f4d\u52a8\u6001ResNet50\u8fbe\u523077.00% top-1\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u9759\u6001\u548c\u52a8\u6001\u65b9\u6cd5\u3002", "conclusion": "DQT\u4e3a\u9ad8\u6548\u81ea\u9002\u5e94AI\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2508.09582", "pdf": "https://arxiv.org/pdf/2508.09582", "abs": "https://arxiv.org/abs/2508.09582", "authors": ["Wafaa B. M. Fadlelmula", "Sanaa Hamid Mohamed", "Taisir E. H. El-Gorashi", "Jaafar M. H. Elmirghani"], "title": "Energy-efficient PON-based Backhaul Connectivity for a VLC-enabled Indoor Fog Computing Environment", "categories": ["cs.NI"], "comment": null, "summary": "In this paper, we consider the use of visible light communication (VLC) to\nprovide connectivity to indoor fog computing resources and propose an\nenergy-efficient passive optical network (PON)-based backhaul architecture to\nsupport the VLC system. We develop a mixed-integer linear programming (MILP)\nmodel to optimize the allocation of computing resources over the proposed\narchitecture, aiming to minimize processing and networking power consumption.\nWe evaluate the performance of the proposed architecture under varying workload\ndemands and user distributions. Comparative analysis against a backhaul\narchitecture that is based on the state-of-the-art spine-and-leaf (S&L) network\ndesign demonstrates total power savings of up to 82%. Further comparison with\ncentralized cloud processing shows improvements in energy efficiency of up to\n93%. Additionally, we examine the improvements in energy efficiency obtained by\nsplitting tasks among multiple processing nodes and propose enhancements to the\narchitecture including dynamic bandwidth allocation, increased wavelength\nbandwidth and improved connectivity within rooms to alleviate networking\nbottlenecks. Furthermore, we introduce an inter-building architecture that\nleverages resources from neighboring buildings to support high-demand\nscenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u89c1\u5149\u901a\u4fe1\uff08VLC\uff09\u7684\u5ba4\u5185\u96fe\u8ba1\u7b97\u8d44\u6e90\u8fde\u63a5\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u88ab\u52a8\u5149\u7f51\u7edc\uff08PON\uff09\u67b6\u6784\u4f18\u5316\u8d44\u6e90\u5206\u914d\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u80fd\u8017\u3002", "motivation": "\u89e3\u51b3\u5ba4\u5185\u96fe\u8ba1\u7b97\u8d44\u6e90\u7684\u9ad8\u6548\u8fde\u63a5\u95ee\u9898\uff0c\u540c\u65f6\u964d\u4f4e\u80fd\u8017\u3002", "method": "\u5f00\u53d1\u4e86\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\u6a21\u578b\uff0c\u4f18\u5316\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\u548c\u7528\u6237\u5206\u5e03\u4e0b\u7684\u6027\u80fd\u3002", "result": "\u76f8\u6bd4\u73b0\u6709\u67b6\u6784\uff0c\u80fd\u8017\u964d\u4f4e82%\uff1b\u76f8\u6bd4\u96c6\u4e2d\u5f0f\u4e91\u5904\u7406\uff0c\u80fd\u6548\u63d0\u534793%\u3002", "conclusion": "\u63d0\u51fa\u7684\u67b6\u6784\u663e\u8457\u63d0\u5347\u4e86\u80fd\u6548\uff0c\u5e76\u901a\u8fc7\u4efb\u52a1\u62c6\u5206\u3001\u52a8\u6001\u5e26\u5bbd\u5206\u914d\u548c\u591a\u5efa\u7b51\u8d44\u6e90\u5171\u4eab\u8fdb\u4e00\u6b65\u4f18\u5316\u6027\u80fd\u3002"}}
{"id": "2508.09180", "pdf": "https://arxiv.org/pdf/2508.09180", "abs": "https://arxiv.org/abs/2508.09180", "authors": ["Huifa Li", "Jie Fu", "Xinlin Zhuang", "Haolin Yang", "Xinpeng Ling", "Tong Cheng", "Haochen xue", "Imran Razzak", "Zhili Chen"], "title": "scAGC: Learning Adaptive Cell Graphs with Contrastive Guidance for Single-Cell Clustering", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate cell type annotation is a crucial step in analyzing single-cell RNA\nsequencing (scRNA-seq) data, which provides valuable insights into cellular\nheterogeneity. However, due to the high dimensionality and prevalence of zero\nelements in scRNA-seq data, traditional clustering methods face significant\nstatistical and computational challenges. While some advanced methods use graph\nneural networks to model cell-cell relationships, they often depend on static\ngraph structures that are sensitive to noise and fail to capture the\nlong-tailed distribution inherent in single-cell populations.To address these\nlimitations, we propose scAGC, a single-cell clustering method that learns\nadaptive cell graphs with contrastive guidance. Our approach optimizes feature\nrepresentations and cell graphs simultaneously in an end-to-end manner.\nSpecifically, we introduce a topology-adaptive graph autoencoder that leverages\na differentiable Gumbel-Softmax sampling strategy to dynamically refine the\ngraph structure during training. This adaptive mechanism mitigates the problem\nof a long-tailed degree distribution by promoting a more balanced neighborhood\nstructure. To model the discrete, over-dispersed, and zero-inflated nature of\nscRNA-seq data, we integrate a Zero-Inflated Negative Binomial (ZINB) loss for\nrobust feature reconstruction. Furthermore, a contrastive learning objective is\nincorporated to regularize the graph learning process and prevent abrupt\nchanges in the graph topology, ensuring stability and enhancing convergence.\nComprehensive experiments on 9 real scRNA-seq datasets demonstrate that scAGC\nconsistently outperforms other state-of-the-art methods, yielding the best NMI\nand ARI scores on 9 and 7 datasets, respectively.Our code is available at\nAnonymous Github.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3ascAGC\u7684\u5355\u7ec6\u80de\u805a\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5b66\u4e60\u7ec6\u80de\u56fe\u548c\u5bf9\u6bd4\u5b66\u4e60\u4f18\u5316\u7279\u5f81\u8868\u793a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u9ad8\u7ef4\u548c\u7a00\u758f\u6570\u636e\u4e2d\u7684\u6311\u6218\u3002", "motivation": "\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u6570\u636e\u7684\u9ad8\u7ef4\u6027\u548c\u7a00\u758f\u6027\u5bfc\u81f4\u4f20\u7edf\u805a\u7c7b\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\uff0c\u73b0\u6709\u56fe\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u56fe\u7ed3\u6784\u4e14\u5bf9\u566a\u58f0\u654f\u611f\uff0c\u65e0\u6cd5\u6355\u6349\u957f\u5c3e\u5206\u5e03\u3002", "method": "scAGC\u7ed3\u5408\u62d3\u6251\u81ea\u9002\u5e94\u56fe\u81ea\u7f16\u7801\u5668\u548c\u53ef\u5faeGumbel-Softmax\u91c7\u6837\u7b56\u7565\uff0c\u52a8\u6001\u4f18\u5316\u56fe\u7ed3\u6784\uff0c\u5e76\u5f15\u5165ZINB\u635f\u5931\u548c\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\u4ee5\u63d0\u9ad8\u9c81\u68d2\u6027\u548c\u7a33\u5b9a\u6027\u3002", "result": "\u57289\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cscAGC\u5728NMI\u548cARI\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "scAGC\u901a\u8fc7\u81ea\u9002\u5e94\u56fe\u5b66\u4e60\u548c\u5bf9\u6bd4\u6307\u5bfc\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5355\u7ec6\u80de\u805a\u7c7b\u6027\u80fd\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2508.09620", "pdf": "https://arxiv.org/pdf/2508.09620", "abs": "https://arxiv.org/abs/2508.09620", "authors": ["Michel Rottleuthner", "Thomas C. Schmidt", "Matthias W\u00e4hlisch"], "title": "Duty-Cycling is Not Enough in Constrained IoT Networking: Revealing the Energy Savings of Dynamic Clock Scaling", "categories": ["cs.NI", "cs.SY", "eess.SY", "D.4.8; C.3"], "comment": null, "summary": "Minimizing energy consumption of low-power wireless nodes is a persistent\nchallenge from the constrained Internet of Things (IoT). In this paper, we\nstart from the observation that constrained IoT devices have largely different\nhardware (im-)balances than full-scale machines. We find that the performance\ngap between MCU and network throughput on constrained devices enables minimal\nenergy delay product (EDP) for IoT networking at largely reduced clock\nfrequencies. We analyze the potentials by integrating dynamic voltage and\nfrequency scaling (DVFS) into the RIOT IoT operating system and show that the\nDVFS reconfiguration overhead stays below the energy saved for a single,\ndownscaled MAC operation. Backed by these findings, we systematically\ninvestigate how DVFS further improves energy-efficiency for common networking\ntasks -- in addition to duty-cycling. We measure IoT communication scenarios\nbetween real-world systems and analyze two MAC operating modes -- CSMA/CA and\ntime slotting -- in combination with different CoAP transactions, payload\nsizes, as well as DTLS transport encryption. Our experiments reveal energy\nsavings between 24% and 52% for MAC operations and up to 37% for encrypted CoAP\ncommunication. These results shall encourage research and system design work to\nintegrate DVFS in future IoT devices for performing tasks at their optimal\nfrequencies and thereby significantly extending battery lifetimes.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u901a\u8fc7\u52a8\u6001\u7535\u538b\u9891\u7387\u8c03\u6574\uff08DVFS\uff09\u4f18\u5316\u4f4e\u529f\u8017\u65e0\u7ebf\u8282\u70b9\u7684\u80fd\u8017\uff0c\u5b9e\u9a8c\u663e\u793a\u8282\u80fd\u6548\u679c\u663e\u8457\u3002", "motivation": "\u53d7\u9650\u7269\u8054\u7f51\uff08IoT\uff09\u8bbe\u5907\u7684\u786c\u4ef6\u6027\u80fd\u5dee\u5f02\u5927\uff0c\u901a\u8fc7\u964d\u4f4e\u65f6\u949f\u9891\u7387\u53ef\u6700\u5c0f\u5316\u80fd\u8017\u5ef6\u8fdf\u79ef\uff08EDP\uff09\uff0c\u4ece\u800c\u5ef6\u957f\u7535\u6c60\u5bff\u547d\u3002", "method": "\u5c06DVFS\u96c6\u6210\u5230RIOT IoT\u64cd\u4f5c\u7cfb\u7edf\u4e2d\uff0c\u5206\u6790\u5176\u5728\u5e38\u89c1\u7f51\u7edc\u4efb\u52a1\u4e2d\u7684\u8282\u80fd\u6548\u679c\uff0c\u5305\u62ecCSMA/CA\u548c\u65f6\u5206\u591a\u5740\uff08time slotting\uff09\u4e24\u79cdMAC\u64cd\u4f5c\u6a21\u5f0f\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cMAC\u64cd\u4f5c\u8282\u80fd24%\u81f352%\uff0c\u52a0\u5bc6CoAP\u901a\u4fe1\u8282\u80fd\u9ad8\u8fbe37%\u3002", "conclusion": "DVFS\u5e94\u88ab\u96c6\u6210\u5230\u672a\u6765IoT\u8bbe\u5907\u4e2d\uff0c\u4ee5\u5728\u6700\u4f18\u9891\u7387\u4e0b\u6267\u884c\u4efb\u52a1\uff0c\u663e\u8457\u5ef6\u957f\u7535\u6c60\u5bff\u547d\u3002"}}
{"id": "2508.09181", "pdf": "https://arxiv.org/pdf/2508.09181", "abs": "https://arxiv.org/abs/2508.09181", "authors": ["Jinghong Tan", "Zhian Liu", "Kun Guo", "Mingxiong Zhao"], "title": "Long-Term Client Selection for Federated Learning with Non-IID Data: A Truthful Auction Approach", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Federated learning (FL) provides a decentralized framework that enables\nuniversal model training through collaborative efforts on mobile nodes, such as\nsmart vehicles in the Internet of Vehicles (IoV). Each smart vehicle acts as a\nmobile client, contributing to the process without uploading local data. This\nmethod leverages non-independent and identically distributed (non-IID) training\ndata from different vehicles, influenced by various driving patterns and\nenvironmental conditions, which can significantly impact model convergence and\naccuracy. Although client selection can be a feasible solution for non-IID\nissues, it faces challenges related to selection metrics. Traditional metrics\nevaluate client data quality independently per round and require client\nselection after all clients complete local training, leading to resource\nwastage from unused training results. In the IoV context, where vehicles have\nlimited connectivity and computational resources, information asymmetry in\nclient selection risks clients submitting false information, potentially making\nthe selection ineffective. To tackle these challenges, we propose a novel\nLong-term Client-Selection Federated Learning based on Truthful Auction\n(LCSFLA). This scheme maximizes social welfare with consideration of long-term\ndata quality using a new assessment mechanism and energy costs, and the advised\nauction mechanism with a deposit requirement incentivizes client participation\nand ensures information truthfulness. We theoretically prove the incentive\ncompatibility and individual rationality of the advised incentive mechanism.\nExperimental results on various datasets, including those from IoV scenarios,\ndemonstrate its effectiveness in mitigating performance degradation caused by\nnon-IID data.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bda\u5b9e\u62cd\u5356\u7684\u957f\u671f\u5ba2\u6237\u9009\u62e9\u8054\u90a6\u5b66\u4e60\u65b9\u6848\uff08LCSFLA\uff09\uff0c\u4ee5\u89e3\u51b3\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u548c\u8d44\u6e90\u6d6a\u8d39\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u548c\u8d44\u6e90\u6d6a\u8d39\u95ee\u9898\u5f71\u54cd\u6a21\u578b\u6536\u655b\u548c\u51c6\u786e\u6027\uff0c\u4f20\u7edf\u5ba2\u6237\u9009\u62e9\u65b9\u6cd5\u5b58\u5728\u4fe1\u606f\u4e0d\u5bf9\u79f0\u548c\u4f4e\u6548\u95ee\u9898\u3002", "method": "\u63d0\u51faLCSFLA\u65b9\u6848\uff0c\u7ed3\u5408\u957f\u671f\u6570\u636e\u8d28\u91cf\u8bc4\u4f30\u548c\u62cd\u5356\u673a\u5236\uff0c\u6fc0\u52b1\u5ba2\u6237\u53c2\u4e0e\u5e76\u786e\u4fdd\u4fe1\u606f\u771f\u5b9e\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eLCSFLA\u80fd\u6709\u6548\u7f13\u89e3\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "LCSFLA\u901a\u8fc7\u957f\u671f\u8bc4\u4f30\u548c\u62cd\u5356\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5ba2\u6237\u9009\u62e9\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2508.09660", "pdf": "https://arxiv.org/pdf/2508.09660", "abs": "https://arxiv.org/abs/2508.09660", "authors": ["Jesus Oma\u00f1a Iglesias", "Carlos Segura Perales", "Stefan Gei\u00dfler", "Diego Perino", "Andra Lutu"], "title": "Anomaly Detection for IoT Global Connectivity", "categories": ["cs.NI", "cs.AI", "cs.LG"], "comment": null, "summary": "Internet of Things (IoT) application providers rely on Mobile Network\nOperators (MNOs) and roaming infrastructures to deliver their services\nglobally. In this complex ecosystem, where the end-to-end communication path\ntraverses multiple entities, it has become increasingly challenging to\nguarantee communication availability and reliability. Further, most platform\noperators use a reactive approach to communication issues, responding to user\ncomplaints only after incidents have become severe, compromising service\nquality. This paper presents our experience in the design and deployment of\nANCHOR -- an unsupervised anomaly detection solution for the IoT connectivity\nservice of a large global roaming platform. ANCHOR assists engineers by\nfiltering vast amounts of data to identify potential problematic clients (i.e.,\nthose with connectivity issues affecting several of their IoT devices),\nenabling proactive issue resolution before the service is critically impacted.\nWe first describe the IoT service, infrastructure, and network visibility of\nthe IoT connectivity provider we operate. Second, we describe the main\nchallenges and operational requirements for designing an unsupervised anomaly\ndetection solution on this platform. Following these guidelines, we propose\ndifferent statistical rules, and machine- and deep-learning models for IoT\nverticals anomaly detection based on passive signaling traffic. We describe the\nsteps we followed working with the operational teams on the design and\nevaluation of our solution on the operational platform, and report an\nevaluation on operational IoT customers.", "AI": {"tldr": "ANCHOR\u662f\u4e00\u4e2a\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u5168\u7403\u6f2b\u6e38\u5e73\u53f0\u7684IoT\u8fde\u63a5\u670d\u52a1\uff0c\u65e8\u5728\u901a\u8fc7\u5206\u6790\u88ab\u52a8\u4fe1\u4ee4\u6d41\u91cf\uff0c\u63d0\u524d\u8bc6\u522b\u6f5c\u5728\u95ee\u9898\u5ba2\u6237\uff0c\u5b9e\u73b0\u4e3b\u52a8\u95ee\u9898\u89e3\u51b3\u3002", "motivation": "IoT\u670d\u52a1\u4f9d\u8d56\u591a\u5b9e\u4f53\u901a\u4fe1\u8def\u5f84\uff0c\u73b0\u6709\u5e73\u53f0\u901a\u5e38\u88ab\u52a8\u5e94\u5bf9\u95ee\u9898\uff0c\u5bfc\u81f4\u670d\u52a1\u8d28\u91cf\u4e0b\u964d\u3002ANCHOR\u65e8\u5728\u901a\u8fc7\u4e3b\u52a8\u68c0\u6d4b\u5f02\u5e38\u63d0\u5347\u670d\u52a1\u53ef\u9760\u6027\u3002", "method": "\u7ed3\u5408\u7edf\u8ba1\u89c4\u5219\u3001\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u57fa\u4e8e\u88ab\u52a8\u4fe1\u4ee4\u6d41\u91cf\u8bbe\u8ba1\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u65b9\u6848\uff0c\u5e76\u4e0e\u8fd0\u8425\u56e2\u961f\u5408\u4f5c\u8bc4\u4f30\u3002", "result": "\u5728\u8fd0\u8425\u5e73\u53f0\u4e0a\u6210\u529f\u90e8\u7f72\u5e76\u8bc4\u4f30\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u6f5c\u5728\u95ee\u9898\u5ba2\u6237\uff0c\u63d0\u5347\u670d\u52a1\u53ef\u9760\u6027\u3002", "conclusion": "ANCHOR\u4e3aIoT\u8fde\u63a5\u670d\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4e3b\u52a8\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u663e\u8457\u6539\u5584\u4e86\u670d\u52a1\u8d28\u91cf\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2508.09187", "pdf": "https://arxiv.org/pdf/2508.09187", "abs": "https://arxiv.org/abs/2508.09187", "authors": ["Almustapha A. Wakili", "Babajide J. Asaju", "Woosub Jung"], "title": "Breath as a biomarker: A survey of contact and contactless applications and approaches in respiratory monitoring", "categories": ["cs.LG"], "comment": null, "summary": "Breath analysis has emerged as a critical tool in health monitoring, offering\ninsights into respiratory function, disease detection, and continuous health\nassessment. While traditional contact-based methods are reliable, they often\npose challenges in comfort and practicality, particularly for long-term\nmonitoring. This survey comprehensively examines contact-based and contactless\napproaches, emphasizing recent advances in machine learning and deep learning\ntechniques applied to breath analysis. Contactless methods, including Wi-Fi\nChannel State Information and acoustic sensing, are analyzed for their ability\nto provide accurate, noninvasive respiratory monitoring. We explore a broad\nrange of applications, from single-user respiratory rate detection to\nmulti-user scenarios, user identification, and respiratory disease detection.\nFurthermore, this survey details essential data preprocessing, feature\nextraction, and classification techniques, offering comparative insights into\nmachine learning/deep learning models suited to each approach. Key challenges\nlike dataset scarcity, multi-user interference, and data privacy are also\ndiscussed, along with emerging trends like Explainable AI, federated learning,\ntransfer learning, and hybrid modeling. By synthesizing current methodologies\nand identifying open research directions, this survey offers a comprehensive\nframework to guide future innovations in breath analysis, bridging advanced\ntechnological capabilities with practical healthcare applications.", "AI": {"tldr": "\u7efc\u8ff0\u63a2\u8ba8\u4e86\u547c\u5438\u5206\u6790\u7684\u63a5\u89e6\u5f0f\u4e0e\u975e\u63a5\u89e6\u5f0f\u65b9\u6cd5\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5e76\u5206\u6790\u4e86\u5176\u5e94\u7528\u3001\u6311\u6218\u53ca\u672a\u6765\u8d8b\u52bf\u3002", "motivation": "\u4f20\u7edf\u63a5\u89e6\u5f0f\u547c\u5438\u76d1\u6d4b\u65b9\u6cd5\u5728\u8212\u9002\u6027\u548c\u5b9e\u7528\u6027\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u63a2\u7d22\u66f4\u9ad8\u6548\u7684\u975e\u63a5\u89e6\u5f0f\u6280\u672f\u3002", "method": "\u6bd4\u8f83\u63a5\u89e6\u5f0f\u4e0e\u975e\u63a5\u89e6\u5f0f\u65b9\u6cd5\uff0c\u5206\u6790\u673a\u5668\u5b66\u4e60/\u6df1\u5ea6\u5b66\u4e60\u5728\u547c\u5438\u5206\u6790\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u6570\u636e\u9884\u5904\u7406\u3001\u7279\u5f81\u63d0\u53d6\u548c\u5206\u7c7b\u6280\u672f\u3002", "result": "\u975e\u63a5\u89e6\u5f0f\u65b9\u6cd5\uff08\u5982Wi-Fi CSI\u548c\u58f0\u5b66\u4f20\u611f\uff09\u80fd\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u65e0\u521b\u76d1\u6d4b\uff0c\u9002\u7528\u4e8e\u591a\u7528\u6237\u573a\u666f\u548c\u75be\u75c5\u68c0\u6d4b\u3002", "conclusion": "\u7efc\u8ff0\u4e3a\u547c\u5438\u5206\u6790\u7684\u672a\u6765\u521b\u65b0\u63d0\u4f9b\u4e86\u6846\u67b6\uff0c\u5f3a\u8c03\u9700\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u3001\u9690\u79c1\u7b49\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u65b0\u5174\u6280\u672f\u5982\u8054\u90a6\u5b66\u4e60\u548c\u53ef\u89e3\u91caAI\u3002"}}
{"id": "2508.09735", "pdf": "https://arxiv.org/pdf/2508.09735", "abs": "https://arxiv.org/abs/2508.09735", "authors": ["Jorge L\u00f3pez", "Charalampos Chatzinakis", "Marc Cartigny"], "title": "Route Planning and Online Routing for Quantum Key Distribution Networks", "categories": ["cs.NI", "cs.CR"], "comment": "Initial submission, 5 pages, 4 figures", "summary": "Quantum Key Distribution (QKD) networks harness the principles of quantum\nphysics in order to securely transmit cryptographic key material, providing\nphysical guarantees. These networks require traditional management and\noperational components, such as routing information through the network\nelements. However, due to the limitations on capacity and the particularities\nof information handling in these networks, traditional shortest paths\nalgorithms for routing perform poorly on both route planning and online\nrouting, which is counterintuitive. Moreover, due to the scarce resources in\nsuch networks, often the expressed demand cannot be met by any assignment of\nroutes. To address both the route planning problem and the need for fair\nautomated suggestions in infeasible cases, we propose to model this problem as\na Quadratic Programming (QP) problem. For the online routing problem, we\nshowcase that the shortest (available) paths routing strategy performs poorly\nin the online setting. Furthermore, we prove that the widest shortest path\nrouting strategy has a competitive ratio greater or equal than $\\frac{1}{2}$,\nefficiently addressing both routing modes in QKD networks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8c\u6b21\u89c4\u5212\uff08QP\uff09\u7684\u6a21\u578b\u6765\u89e3\u51b3\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u7f51\u7edc\u4e2d\u7684\u8def\u7531\u95ee\u9898\uff0c\u5e76\u5206\u6790\u4e86\u6700\u77ed\u8def\u5f84\u548c\u6700\u77ed\u6700\u5bbd\u8def\u5f84\u7b56\u7565\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u6700\u77ed\u8def\u5f84\u7b97\u6cd5\u5728QKD\u7f51\u7edc\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u8d44\u6e90\u7a00\u7f3a\u5bfc\u81f4\u9700\u6c42\u96be\u4ee5\u6ee1\u8db3\uff0c\u9700\u8981\u65b0\u7684\u8def\u7531\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u8def\u7531\u95ee\u9898\u5efa\u6a21\u4e3a\u4e8c\u6b21\u89c4\u5212\u95ee\u9898\uff0c\u5e76\u5206\u6790\u4e86\u6700\u77ed\u8def\u5f84\u548c\u6700\u77ed\u6700\u5bbd\u8def\u5f84\u7b56\u7565\u7684\u6027\u80fd\u3002", "result": "\u6700\u77ed\u8def\u5f84\u7b56\u7565\u5728\u7ebf\u8def\u7531\u4e2d\u8868\u73b0\u5dee\uff0c\u800c\u6700\u77ed\u6700\u5bbd\u8def\u5f84\u7b56\u7565\u7684\u7ade\u4e89\u6bd4\u81f3\u5c11\u4e3a1/2\u3002", "conclusion": "\u63d0\u51fa\u7684QP\u6a21\u578b\u548c\u6700\u77ed\u6700\u5bbd\u8def\u5f84\u7b56\u7565\u80fd\u6709\u6548\u89e3\u51b3QKD\u7f51\u7edc\u4e2d\u7684\u8def\u7531\u95ee\u9898\u3002"}}
{"id": "2508.09190", "pdf": "https://arxiv.org/pdf/2508.09190", "abs": "https://arxiv.org/abs/2508.09190", "authors": ["Bing Han", "Feifei Zhao", "Dongcheng Zhao", "Guobin Shen", "Ping Wu", "Yu Shi", "Yi Zeng"], "title": "Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fine-tuning as service injects domain-specific knowledge into large language\nmodels (LLMs), while challenging the original alignment mechanisms and\nintroducing safety risks. A series of defense strategies have been proposed for\nthe alignment, fine-tuning, and post-fine-tuning phases, where most\npost-fine-tuning defenses rely on coarse-grained safety layer mapping. These\nmethods lack a comprehensive consideration of both safety layers and\nfine-grained neurons, limiting their ability to efficiently balance safety and\nutility. To address this, we propose the Fine-Grained Safety Neurons (FGSN)\nwith Training-Free Continual Projection method to reduce the fine-tuning safety\nrisks. FGSN inherently integrates the multi-scale interactions between safety\nlayers and neurons, localizing sparser and more precise fine-grained safety\nneurons while minimizing interference with downstream task neurons. We then\nproject the safety neuron parameters onto safety directions, improving model\nsafety while aligning more closely with human preferences. Extensive\nexperiments across multiple fine-tuned LLM models demonstrate that our method\nsignificantly reduce harmfulness scores and attack success rates with minimal\nparameter modifications, while preserving the model's utility. Furthermore, by\nintroducing a task-specific, multi-dimensional heterogeneous safety neuron\ncluster optimization mechanism, we achieve continual defense and generalization\ncapability against unforeseen emerging safety concerns.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ec6\u7c92\u5ea6\u5b89\u5168\u795e\u7ecf\u5143\uff08FGSN\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u65e0\u8bad\u7ec3\u6301\u7eed\u6295\u5f71\u6280\u672f\u51cf\u5c11\u5fae\u8c03LLM\u7684\u5b89\u5168\u98ce\u9669\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5fae\u8c03LLM\u53ef\u80fd\u7834\u574f\u539f\u59cb\u5bf9\u9f50\u673a\u5236\u5e76\u5f15\u5165\u5b89\u5168\u98ce\u9669\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u672a\u80fd\u5168\u9762\u8003\u8651\u5b89\u5168\u5c42\u4e0e\u7ec6\u7c92\u5ea6\u795e\u7ecf\u5143\u7684\u4ea4\u4e92\u3002", "method": "\u63d0\u51faFGSN\u65b9\u6cd5\uff0c\u7ed3\u5408\u591a\u5c3a\u5ea6\u5b89\u5168\u5c42\u4e0e\u795e\u7ecf\u5143\u4ea4\u4e92\uff0c\u5b9a\u4f4d\u7a00\u758f\u4e14\u7cbe\u786e\u7684\u5b89\u5168\u795e\u7ecf\u5143\uff0c\u5e76\u901a\u8fc7\u6295\u5f71\u6280\u672f\u63d0\u5347\u5b89\u5168\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFGSN\u663e\u8457\u964d\u4f4e\u6709\u5bb3\u6027\u8bc4\u5206\u548c\u653b\u51fb\u6210\u529f\u7387\uff0c\u4e14\u4ec5\u9700\u5c11\u91cf\u53c2\u6570\u4fee\u6539\u3002", "conclusion": "FGSN\u901a\u8fc7\u4efb\u52a1\u7279\u5f02\u6027\u591a\u7ef4\u5ea6\u4f18\u5316\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u6301\u7eed\u9632\u5fa1\u80fd\u529b\uff0c\u5e76\u80fd\u5e94\u5bf9\u672a\u77e5\u5b89\u5168\u5a01\u80c1\u3002"}}
{"id": "2508.09756", "pdf": "https://arxiv.org/pdf/2508.09756", "abs": "https://arxiv.org/abs/2508.09756", "authors": ["Mauro De Sanctis"], "title": "The Paradigm of Massive Wireless Human Sensing: Concept, Architecture and Challenges", "categories": ["cs.NI", "C.2.0"], "comment": null, "summary": "This article is a position paper which introduces the paradigm of ``Massive\nWireless Human Sensing'', i.e. an infrastructure for wireless human sensing\nbased on a plethora of heterogeneous wireless communication signals. More\nspecifically, we aim to exploit signal diversity in the time, frequency, and\nspace domains using opportunistically both device-free and device-based\nwireless sensing approaches, with the objective of enhancing human sensing\ncapabilities in terms of accuracy and service availability over different\nenvironments. The enabling element of this concept is the massive wireless\nhuman sensing edge device, that is, an embedded system acting as a\nmulti-technology and multi-approach RF receiver with feature extraction\nfunctionality, located within the monitoring area or at its borders. In this\nframework, architecture solutions and challenges are discussed to lead the\nfuture development of this new paradigm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f02\u6784\u65e0\u7ebf\u901a\u4fe1\u4fe1\u53f7\u7684\u201c\u5927\u89c4\u6a21\u65e0\u7ebf\u4eba\u4f53\u611f\u77e5\u201d\u8303\u5f0f\uff0c\u65e8\u5728\u901a\u8fc7\u65f6\u95f4\u548c\u7a7a\u95f4\u57df\u7684\u4fe1\u53f7\u591a\u6837\u6027\u63d0\u5347\u611f\u77e5\u80fd\u529b\u3002", "motivation": "\u5229\u7528\u65e0\u7ebf\u4fe1\u53f7\u7684\u591a\u6837\u6027\uff0c\u63d0\u9ad8\u4eba\u4f53\u611f\u77e5\u7684\u51c6\u786e\u6027\u548c\u670d\u52a1\u53ef\u7528\u6027\u3002", "method": "\u7ed3\u5408\u8bbe\u5907\u65e0\u5173\u548c\u8bbe\u5907\u76f8\u5173\u7684\u65e0\u7ebf\u611f\u77e5\u65b9\u6cd5\uff0c\u5229\u7528\u65f6\u95f4\u3001\u9891\u7387\u548c\u7a7a\u95f4\u57df\u7684\u4fe1\u53f7\u591a\u6837\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6280\u672f\u3001\u591a\u65b9\u6cd5\u7684\u5c04\u9891\u63a5\u6536\u5668\u67b6\u6784\uff0c\u652f\u6301\u7279\u5f81\u63d0\u53d6\u529f\u80fd\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u67b6\u6784\u89e3\u51b3\u65b9\u6848\u548c\u6311\u6218\uff0c\u4e3a\u672a\u6765\u8be5\u8303\u5f0f\u7684\u53d1\u5c55\u63d0\u4f9b\u65b9\u5411\u3002"}}
{"id": "2508.09191", "pdf": "https://arxiv.org/pdf/2508.09191", "abs": "https://arxiv.org/abs/2508.09191", "authors": ["Xiaoyu Tao", "Shilong Zhang", "Mingyue Cheng", "Daoyu Wang", "Tingyue Pan", "Bokai Pan", "Changqing Zhang", "Shijin Wang"], "title": "From Values to Tokens: An LLM-Driven Framework for Context-aware Time Series Forecasting via Symbolic Discretization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series forecasting plays a vital role in supporting decision-making\nacross a wide range of critical applications, including energy, healthcare, and\nfinance. Despite recent advances, forecasting accuracy remains limited due to\nthe challenge of integrating historical numerical sequences with contextual\nfeatures, which often comprise unstructured textual data. To address this\nchallenge, we propose TokenCast, an LLM-driven framework that leverages\nlanguage-based symbolic representations as a unified intermediary for\ncontext-aware time series forecasting. Specifically, TokenCast employs a\ndiscrete tokenizer to transform continuous numerical sequences into temporal\ntokens, enabling structural alignment with language-based inputs. To bridge the\nsemantic gap between modalities, both temporal and contextual tokens are\nembedded into a shared representation space via a pre-trained large language\nmodel (LLM), further optimized with autoregressive generative objectives.\nBuilding upon this unified semantic space, the aligned LLM is subsequently\nfine-tuned in a supervised manner to predict future temporal tokens, which are\nthen decoded back into the original numerical space. Extensive experiments on\ndiverse real-world datasets enriched with contextual features demonstrate the\neffectiveness and generalizability of TokenCast.", "AI": {"tldr": "TokenCast\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u8a00\u7b26\u53f7\u8868\u793a\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002", "motivation": "\u89e3\u51b3\u5386\u53f2\u6570\u503c\u5e8f\u5217\u4e0e\u4e0a\u4e0b\u6587\u7279\u5f81\uff08\u5982\u975e\u7ed3\u6784\u5316\u6587\u672c\u6570\u636e\uff09\u878d\u5408\u7684\u6311\u6218\uff0c\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528\u79bb\u6563\u6807\u8bb0\u5668\u5c06\u8fde\u7eed\u6570\u503c\u5e8f\u5217\u8f6c\u6362\u4e3a\u65f6\u95f4\u6807\u8bb0\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3LLM\u5d4c\u5165\u5171\u4eab\u8868\u793a\u7a7a\u95f4\uff0c\u5e76\u4f18\u5316\u751f\u6210\u76ee\u6807\u3002", "result": "\u5728\u591a\u6837\u5316\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86TokenCast\u7684\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "TokenCast\u6210\u529f\u6574\u5408\u4e86\u6570\u503c\u548c\u6587\u672c\u6570\u636e\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.09769", "pdf": "https://arxiv.org/pdf/2508.09769", "abs": "https://arxiv.org/abs/2508.09769", "authors": ["Simon Egger", "Robin Laidig", "Heiko Geppert", "Lucas Haug", "Jona Herrmann", "Frank D\u00fcrr", "Christian Becker"], "title": "An (m,k)-firm Elevation Policy to Increase the Robustness of Time-Driven Schedules in 5G Time-Sensitive Networks", "categories": ["cs.NI"], "comment": "23 pages, 10 figures", "summary": "Current standardization efforts are advancing the integration of 5G and\nTime-Sensitive Networking (TSN) to facilitate the deployment of safety-critical\nindustrial applications that require real-time communication. However, there\nremains a fundamental disconnect between the probabilistic 5G delay\ncharacteristics and the often idealistic delay models used to synthesize 5G-TSN\nnetwork configurations. For time-driven schedules in particular, any delay\noutlier unforeseen during schedule synthesis can jeopardize the robustness of\ntheir real-time guarantees. To address this challenge, we present the\n(m,k)-firm Elevation Policy to uphold a base level of weakly hard real-time\nguarantees during unstable network conditions that do not match the expected\ndelay characteristics. It augments the primary time-driven schedule with a\ndynamic priority-driven scheme to elevate the priority of m out of k\nconsecutive frames if they are delayed. Our evaluations demonstrate that weakly\nhard real-time guarantees are essential to uphold the quality of control within\na networked control system. At the same time, only a small overhead is imposed\nwhen the primary schedule can provide stronger quality of service guarantees.\nOur (m,k)-firm Elevation Policy thereby yields a robust but light-weight\nfallback mechanism to serve applications with meaningful guarantees during\nunstable network conditions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd(m,k)-firm Elevation Policy\uff0c\u7528\u4e8e\u5728\u4e0d\u7a33\u5b9a\u7f51\u7edc\u6761\u4ef6\u4e0b\u7ef4\u6301\u5f31\u786c\u5b9e\u65f6\u4fdd\u8bc1\uff0c\u589e\u5f3a5G-TSN\u7f51\u7edc\u7684\u9c81\u68d2\u6027\u3002", "motivation": "5G\u4e0eTSN\u7684\u96c6\u6210\u5728\u5b9e\u65f6\u901a\u4fe1\u4e2d\u5b58\u5728\u5ef6\u8fdf\u7279\u6027\u4e0e\u7406\u60f3\u6a21\u578b\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u5b9e\u65f6\u4fdd\u8bc1\u7684\u9c81\u68d2\u6027\u3002", "method": "\u901a\u8fc7\u52a8\u6001\u4f18\u5148\u7ea7\u9a71\u52a8\u65b9\u6848\uff0c\u63d0\u5347m/k\u8fde\u7eed\u5ef6\u8fdf\u5e27\u7684\u4f18\u5148\u7ea7\uff0c\u4f5c\u4e3a\u4e3b\u65f6\u95f4\u9a71\u52a8\u8c03\u5ea6\u7684\u8865\u5145\u3002", "result": "\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u7b56\u7565\u5728\u7ef4\u6301\u63a7\u5236\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u4ec5\u5f15\u5165\u5c11\u91cf\u5f00\u9500\u3002", "conclusion": "(m,k)-firm Elevation Policy\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u540e\u5907\u673a\u5236\uff0c\u80fd\u5728\u4e0d\u7a33\u5b9a\u7f51\u7edc\u6761\u4ef6\u4e0b\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u5b9e\u65f6\u4fdd\u8bc1\u3002"}}
{"id": "2508.09192", "pdf": "https://arxiv.org/pdf/2508.09192", "abs": "https://arxiv.org/abs/2508.09192", "authors": ["Xu Wang", "Chenkai Xu", "Yijie Jin", "Jiachun Jin", "Hao Zhang", "Zhijie Deng"], "title": "Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion Large Language Models (dLLMs) have emerged as a promising\nalternative to autoregressive (AR) LLMs for text generation, with the potential\nto decode multiple tokens in a single iteration. However, none of the existing\nopen-source dLLMs have achieved superior inference speed over AR LLMs of\nsimilar size. This paper breaks this barrier based on a simple and effective\nstrategy named discrete diffusion forcing (D2F). D2F equips dLLMs with two key\ncapabilities: (1) block-wise autoregressive generation to enable KV cache\nutilization; (2) prediction of following tokens without requiring completion of\nprior blocks for inter-block parallel decoding. In this way, the vanilla dLLMs\nare refurbished into an AR-diffusion hybrid paradigm for efficient inference.\nD2F can be implemented with an asymmetric distillation process based on\npre-trained dLLMs. We further propose a pipelined parallel decoding algorithm,\nwhich enables a trade-off between efficiency and efficacy. Empirically, D2F\ndLLMs achieve more than $\\mathbf{2.5\\times}$ inference speed than LLaMA3 and\nQwen2.5 on GSM8K. Compared to vanilla dLLMs like LLaDA and Dream, the\nacceleration can be more than $\\mathbf{50\\times}$ while maintaining comparable\noutput quality. The code is available at\nhttps://github.com/zhijie-group/Discrete-Diffusion-Forcing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u79bb\u6563\u6269\u6563\u5f3a\u8feb\uff08D2F\uff09\u7684\u7b56\u7565\uff0c\u901a\u8fc7\u6539\u9020\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff08dLLMs\uff09\u4e3a\u81ea\u56de\u5f52-\u6269\u6563\u6df7\u5408\u8303\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u5f00\u6e90dLLMs\u5728\u63a8\u7406\u901f\u5ea6\u4e0a\u672a\u80fd\u8d85\u8d8a\u7c7b\u4f3c\u89c4\u6a21\u7684\u81ea\u56de\u5f52\uff08AR\uff09LLMs\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u89e3\u7801\u65b9\u6cd5\u3002", "method": "D2F\u901a\u8fc7\u5757\u7ea7\u81ea\u56de\u5f52\u751f\u6210\u548c\u8de8\u5757\u5e76\u884c\u89e3\u7801\uff0c\u7ed3\u5408\u975e\u5bf9\u79f0\u84b8\u998f\u548c\u6d41\u6c34\u7ebf\u5e76\u884c\u89e3\u7801\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u63a8\u7406\u3002", "result": "D2F dLLMs\u5728GSM8K\u4e0a\u7684\u63a8\u7406\u901f\u5ea6\u6bd4LLaMA3\u548cQwen2.5\u5feb2.5\u500d\u4ee5\u4e0a\uff0c\u6bd4LLaDA\u548cDream\u5feb50\u500d\u4ee5\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u8f93\u51fa\u8d28\u91cf\u3002", "conclusion": "D2F\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u7b56\u7565\uff0c\u6210\u529f\u7a81\u7834\u4e86dLLMs\u63a8\u7406\u901f\u5ea6\u7684\u74f6\u9888\uff0c\u4e3a\u9ad8\u6548\u6587\u672c\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.09839", "pdf": "https://arxiv.org/pdf/2508.09839", "abs": "https://arxiv.org/abs/2508.09839", "authors": ["Muhammad Asad Ullah", "Luca Borgianni", "Heikki Kokkinen", "Antti Anttonen", "Stefano Giordano"], "title": "A First Look at Starlink In-Flight Performance: An Intercontinental Empirical Study", "categories": ["cs.NI"], "comment": "This work has been submitted to the 2025 IEEE Global Communications\n  Conference (GLOBECOM). Copyright to IEEE may be transferred without notice", "summary": "Starlink delivers Internet services to users across terrestrial, maritime,\nand aviation domains. The prior works have studied its performance at fixed\nsites and in-motion vehicles, while an in-depth analysis of in-flight\nperformance remains absent. With major airlines now offering Starlink Internet\nonboard, there is a growing need to evaluate and improve its performance for\naviation users. This paper addresses this shortcoming by conducting in-flight\nmeasurements over the Baltic Sea and the Pacific Ocean. Our measurement results\nshow that a single user device experiences median throughputs of 64 Mbps and 24\nMbps for the downlink and uplink, respectively. The median uplink throughput is\napproximately 33 Mbps when the aircraft maintains an altitude above 17,000\nfeet. However, a significant reduction in uplink performance is observed during\nthe aircraft descent phase, with the median throughput dropping to around 20\nMbps at lower altitudes. Round-trip time (RTT) is highly dependent on the\nlocation of the ground station being pinged and the use of inter-satellite\nlinks (ISLs). We dive deeper into 5.5 hours of ping measurements collected over\nthe Pacific Ocean and investigate factors influencing RTT, hypothesizing that\nISLs routing, data queuing at satellites, and feeder link congestion contribute\nto deviations from theoretical values. For comparative analysis, we evaluate\nthe Starlink ground terminal and in-flight connectivity performance from the\nperspectives of a residential user and an airline passenger, respectively.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u6d4b\u5206\u6790\u4e86Starlink\u5728\u98de\u884c\u4e2d\u7684\u6027\u80fd\uff0c\u586b\u8865\u4e86\u76f8\u5173\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u91cd\u70b9\u5173\u6ce8\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\u3002", "motivation": "\u968f\u7740\u822a\u7a7a\u516c\u53f8\u5f00\u59cb\u63d0\u4f9bStarlink\u673a\u4e0a\u4e92\u8054\u7f51\u670d\u52a1\uff0c\u9700\u8981\u6df1\u5165\u8bc4\u4f30\u5176\u6027\u80fd\u4ee5\u6ee1\u8db3\u822a\u7a7a\u7528\u6237\u9700\u6c42\u3002", "method": "\u5728\u6ce2\u7f57\u7684\u6d77\u548c\u592a\u5e73\u6d0b\u4e0a\u7a7a\u8fdb\u884c\u98de\u884c\u5b9e\u6d4b\uff0c\u6d4b\u91cf\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\uff0c\u5e76\u5206\u6790\u5f71\u54cd\u56e0\u7d20\u3002", "result": "\u5355\u7528\u6237\u8bbe\u5907\u7684\u4e0b\u884c\u548c\u4e0a\u884c\u4e2d\u4f4d\u6570\u541e\u5410\u91cf\u5206\u522b\u4e3a64 Mbps\u548c24 Mbps\uff1b\u9ad8\u5ea6\u5f71\u54cd\u6027\u80fd\uff0c\u4e0b\u964d\u9636\u6bb5\u4e0a\u884c\u541e\u5410\u91cf\u964d\u81f320 Mbps\uff1bRTT\u53d7\u5730\u9762\u7ad9\u4f4d\u7f6e\u548c\u661f\u95f4\u94fe\u8def\u5f71\u54cd\u3002", "conclusion": "Starlink\u5728\u98de\u884c\u4e2d\u8868\u73b0\u7a33\u5b9a\uff0c\u4f46\u6027\u80fd\u53d7\u9ad8\u5ea6\u548c\u94fe\u8def\u56e0\u7d20\u5f71\u54cd\uff0c\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u3002"}}
{"id": "2508.09193", "pdf": "https://arxiv.org/pdf/2508.09193", "abs": "https://arxiv.org/abs/2508.09193", "authors": ["Sung-Hyun Kim", "In-Chang Baek", "Seo-Young Lee", "Geum-Hwan Hwang", "Kyung-Joong Kim"], "title": "Multi-Objective Instruction-Aware Representation Learning in Procedural Content Generation RL", "categories": ["cs.LG", "cs.AI"], "comment": "5 pages, 3 figures", "summary": "Recent advancements in generative modeling emphasize the importance of\nnatural language as a highly expressive and accessible modality for controlling\ncontent generation. However, existing instructed reinforcement learning for\nprocedural content generation (IPCGRL) method often struggle to leverage the\nexpressive richness of textual input, especially under complex, multi-objective\ninstructions, leading to limited controllability. To address this problem, we\npropose \\textit{MIPCGRL}, a multi-objective representation learning method for\ninstructed content generators, which incorporates sentence embeddings as\nconditions. MIPCGRL effectively trains a multi-objective embedding space by\nincorporating multi-label classification and multi-head regression networks.\nExperimental results show that the proposed method achieves up to a 13.8\\%\nimprovement in controllability with multi-objective instructions. The ability\nto process complex instructions enables more expressive and flexible content\ngeneration.", "AI": {"tldr": "MIPCGRL\u662f\u4e00\u79cd\u591a\u76ee\u6807\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u53e5\u5b50\u5d4c\u5165\u548c\u591a\u6807\u7b7e\u5206\u7c7b\u7f51\u7edc\uff0c\u63d0\u5347\u4e86\u751f\u6210\u6a21\u578b\u5bf9\u590d\u6742\u6587\u672c\u6307\u4ee4\u7684\u54cd\u5e94\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u53ef\u63a7\u6027\u63d0\u5347\u4e8613.8%\u3002", "motivation": "\u73b0\u6709IPCGRL\u65b9\u6cd5\u96be\u4ee5\u5145\u5206\u5229\u7528\u6587\u672c\u8f93\u5165\u7684\u4e30\u5bcc\u8868\u8fbe\u529b\uff0c\u5c24\u5176\u5728\u591a\u76ee\u6807\u6307\u4ee4\u4e0b\u53ef\u63a7\u6027\u53d7\u9650\u3002", "method": "\u63d0\u51faMIPCGRL\uff0c\u7ed3\u5408\u53e5\u5b50\u5d4c\u5165\u548c\u591a\u6807\u7b7e\u5206\u7c7b\u7f51\u7edc\uff0c\u8bad\u7ec3\u591a\u76ee\u6807\u5d4c\u5165\u7a7a\u95f4\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMIPCGRL\u5728\u591a\u76ee\u6807\u6307\u4ee4\u4e0b\u7684\u53ef\u63a7\u6027\u63d0\u5347\u4e8613.8%\u3002", "conclusion": "MIPCGRL\u80fd\u591f\u5904\u7406\u590d\u6742\u6307\u4ee4\uff0c\u5b9e\u73b0\u66f4\u5177\u8868\u8fbe\u529b\u548c\u7075\u6d3b\u6027\u7684\u5185\u5bb9\u751f\u6210\u3002"}}
{"id": "2508.09140", "pdf": "https://arxiv.org/pdf/2508.09140", "abs": "https://arxiv.org/abs/2508.09140", "authors": ["Honggang Jia", "Nan Cheng", "Xiucheng Wang", "Conghao Zhou", "Ruijin Sun", "Xuemin", "Shen"], "title": "RadioMamba: Breaking the Accuracy-Efficiency Trade-off in Radio Map Construction via a Hybrid Mamba-UNet", "categories": ["eess.SP", "cs.LG", "cs.NI"], "comment": null, "summary": "Radio map (RM) has recently attracted much attention since it can provide\nreal-time and accurate spatial channel information for 6G services and\napplications. However, current deep learning-based methods for RM construction\nexhibit well known accuracy-efficiency trade-off. In this paper, we introduce\nRadioMamba, a hybrid Mamba-UNet architecture for RM construction to address the\ntrade-off. Generally, accurate RM construction requires modeling long-range\nspatial dependencies, reflecting the global nature of wave propagation physics.\nRadioMamba utilizes a Mamba-Convolutional block where the Mamba branch captures\nthese global dependencies with linear complexity, while a parallel\nconvolutional branch extracts local features. This hybrid design generates\nfeature representations that capture both global context and local detail.\nExperiments show that RadioMamba achieves higher accuracy than existing\nmethods, including diffusion models, while operating nearly 20 times faster and\nusing only 2.9\\% of the model parameters. By improving both accuracy and\nefficiency, RadioMamba presents a viable approach for real-time intelligent\noptimization in next generation wireless systems.", "AI": {"tldr": "RadioMamba\u662f\u4e00\u79cd\u6df7\u5408Mamba-UNet\u67b6\u6784\uff0c\u7528\u4e8e\u89e3\u51b3\u65e0\u7ebf\u7535\u5730\u56fe\u6784\u5efa\u4e2d\u7684\u7cbe\u5ea6\u4e0e\u6548\u7387\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u65e0\u7ebf\u7535\u5730\u56fe\u6784\u5efa\u65b9\u6cd5\u5b58\u5728\u7cbe\u5ea6\u4e0e\u6548\u7387\u7684\u6743\u8861\u95ee\u9898\uff0c\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u5b9e\u65f6\u6027\u548c\u51c6\u786e\u6027\u9700\u6c42\u3002", "method": "\u91c7\u7528Mamba-\u5377\u79ef\u5757\uff0cMamba\u5206\u652f\u4ee5\u7ebf\u6027\u590d\u6742\u5ea6\u6355\u83b7\u5168\u5c40\u7a7a\u95f4\u4f9d\u8d56\uff0c\u5377\u79ef\u5206\u652f\u63d0\u53d6\u5c40\u90e8\u7279\u5f81\uff0c\u5b9e\u73b0\u5168\u5c40\u4e0e\u5c40\u90e8\u7279\u5f81\u7684\u7ed3\u5408\u3002", "result": "RadioMamba\u5728\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff08\u5305\u62ec\u6269\u6563\u6a21\u578b\uff09\uff0c\u901f\u5ea6\u5feb20\u500d\uff0c\u4e14\u4ec5\u97002.9%\u7684\u6a21\u578b\u53c2\u6570\u3002", "conclusion": "RadioMamba\u901a\u8fc7\u63d0\u5347\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7cfb\u7edf\u7684\u5b9e\u65f6\u667a\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.09194", "pdf": "https://arxiv.org/pdf/2508.09194", "abs": "https://arxiv.org/abs/2508.09194", "authors": ["Yipeng Du", "Zihao Wang", "Ahmad Farhan", "Claudio Angione", "Harry Yang", "Fielding Johnston", "James P. Buban", "Patrick Colangelo", "Yue Zhao", "Yuzhe Yang"], "title": "Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments", "categories": ["cs.LG", "cs.AI"], "comment": "COLM2025", "summary": "The deployment of large-scale models, such as large language models (LLMs),\nincurs substantial costs due to their computational demands. To mitigate these\ncosts and address challenges related to scalability and data security, there is\na growing shift towards decentralized systems for model deployment, where\nchoosing efficient inference acceleration schemes become crucial to manage\ncomputational resources effectively and enhance system responsiveness. In this\nwork, we address the challenge of selecting optimal acceleration methods in\ndecentralized systems by introducing a meta-learning-based framework. This\nframework automates the selection process by learning from historical\nperformance data of various acceleration techniques across different tasks.\nUnlike traditional methods that rely on random selection or expert intuition,\nour approach systematically identifies the best acceleration strategies based\non the specific characteristics of each task. We demonstrate that our\nmeta-learning framework not only streamlines the decision-making process but\nalso consistently outperforms conventional methods in terms of efficiency and\nperformance. Our results highlight the potential of inference acceleration in\ndecentralized AI systems, offering a path towards more democratic and\neconomically feasible artificial intelligence solutions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5143\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5206\u6563\u5f0f\u7cfb\u7edf\u4e2d\u81ea\u52a8\u9009\u62e9\u6700\u4f18\u7684\u63a8\u7406\u52a0\u901f\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u5927\u89c4\u6a21\u6a21\u578b\uff08\u5982LLMs\uff09\u90e8\u7f72\u6210\u672c\u9ad8\uff0c\u5206\u6563\u5f0f\u7cfb\u7edf\u53ef\u89e3\u51b3\u53ef\u6269\u5c55\u6027\u548c\u6570\u636e\u5b89\u5168\u95ee\u9898\uff0c\u4f46\u9700\u9ad8\u6548\u63a8\u7406\u52a0\u901f\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u4ece\u5386\u53f2\u6027\u80fd\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u81ea\u52a8\u9009\u62e9\u9002\u5408\u4e0d\u540c\u4efb\u52a1\u7279\u70b9\u7684\u52a0\u901f\u7b56\u7565\u3002", "result": "\u8be5\u6846\u67b6\u5728\u6548\u7387\u548c\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4e3a\u5206\u6563\u5f0fAI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u7ecf\u6d4e\u548c\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u5143\u5b66\u4e60\u6846\u67b6\u4e3a\u5206\u6563\u5f0fAI\u7cfb\u7edf\u4e2d\u7684\u63a8\u7406\u52a0\u901f\u63d0\u4f9b\u4e86\u6709\u6548\u8def\u5f84\uff0c\u63a8\u52a8\u4e86\u66f4\u6c11\u4e3b\u548c\u7ecf\u6d4e\u7684\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u3002"}}
{"id": "2508.09198", "pdf": "https://arxiv.org/pdf/2508.09198", "abs": "https://arxiv.org/abs/2508.09198", "authors": ["Li Kong", "Bingzhe Wang", "Zhou Chen", "Suhan Hu", "Yuchao Ma", "Qi Qi", "Suoyuan Song", "Bicheng Jin"], "title": "ADT4Coupons: An Innovative Framework for Sequential Coupon Distribution in E-commerce", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Coupon distribution is a critical marketing strategy used by online platforms\nto boost revenue and enhance user engagement. Regrettably, existing coupon\ndistribution strategies fall far short of effectively leveraging the complex\nsequential interactions between platforms and users. This critical oversight,\ndespite the abundance of e-commerce log data, has precipitated a performance\nplateau. In this paper, we focus on the scene that the platforms make\nsequential coupon distribution decision multiple times for various users, with\neach user interacting with the platform repeatedly. Based on this marketing\nscenario, we propose a novel marketing framework, named Aligned Decision\nTransformer for Coupons (ADT4Coupons), to directly devise coupon distribution\npolicy for long-term revenue boosting. ADT4Coupons enables optimized online\ndecision-making in a variety of real-world marketing scenarios. It achieves\nthis by seamlessly integrating three key characteristics, general scenarios,\nsequential modeling with more comprehensive historical data, and efficient\niterative updates within a unified framework. Furthermore, empirical results on\nreal-world industrial dataset, alongside public and synthetic datasets\ndemonstrate the superiority of our framework.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8425\u9500\u6846\u67b6ADT4Coupons\uff0c\u7528\u4e8e\u4f18\u5316\u5728\u7ebf\u5e73\u53f0\u7684\u4f18\u60e0\u5238\u5206\u53d1\u7b56\u7565\uff0c\u4ee5\u63d0\u5347\u957f\u671f\u6536\u5165\u3002", "motivation": "\u73b0\u6709\u4f18\u60e0\u5238\u5206\u53d1\u7b56\u7565\u672a\u80fd\u6709\u6548\u5229\u7528\u5e73\u53f0\u4e0e\u7528\u6237\u4e4b\u95f4\u7684\u590d\u6742\u5e8f\u5217\u4ea4\u4e92\uff0c\u5bfc\u81f4\u6027\u80fd\u74f6\u9888\u3002", "method": "\u63d0\u51faADT4Coupons\u6846\u67b6\uff0c\u6574\u5408\u901a\u7528\u573a\u666f\u3001\u5e8f\u5217\u5efa\u6a21\u548c\u9ad8\u6548\u8fed\u4ee3\u66f4\u65b0\uff0c\u76f4\u63a5\u8bbe\u8ba1\u957f\u671f\u6536\u5165\u4f18\u5316\u7684\u5206\u53d1\u7b56\u7565\u3002", "result": "\u5728\u771f\u5b9e\u5de5\u4e1a\u6570\u636e\u96c6\u3001\u516c\u5f00\u6570\u636e\u96c6\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "ADT4Coupons\u80fd\u6709\u6548\u63d0\u5347\u4f18\u60e0\u5238\u5206\u53d1\u7684\u957f\u671f\u6536\u5165\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u7684\u5b9e\u9645\u8425\u9500\u573a\u666f\u3002"}}
{"id": "2508.09213", "pdf": "https://arxiv.org/pdf/2508.09213", "abs": "https://arxiv.org/abs/2508.09213", "authors": ["Clifton Paul Robinson", "Salvatore D'Oro", "Tommaso Melodia"], "title": "VeriPHY: Physical Layer Signal Authentication for Wireless Communication in 5G Environments", "categories": ["cs.CR", "cs.NI"], "comment": "7 pages, 10 figures, 2 tables, IEEE Military Communications\n  Conference 2025 (MILCOM '25)", "summary": "Physical layer authentication (PLA) uses inherent characteristics of the\ncommunication medium to provide secure and efficient authentication in wireless\nnetworks, bypassing the need for traditional cryptographic methods. With\nadvancements in deep learning, PLA has become a widely adopted technique for\nits accuracy and reliability. In this paper, we introduce VeriPHY, a novel deep\nlearning-based PLA solution for 5G networks, which enables unique device\nidentification by embedding signatures within wireless I/Q transmissions using\nsteganography. VeriPHY continuously generates pseudo-random signatures by\nsampling from Gaussian Mixture Models whose distribution is carefully varied to\nensure signature uniqueness and stealthiness over time, and then embeds the\nnewly generated signatures over I/Q samples transmitted by users to the 5G gNB.\nUtilizing deep neural networks, VeriPHY identifies and authenticates users\nbased on these embedded signatures. VeriPHY achieves high precision,\nidentifying unique signatures between 93% and 100% with low false positive\nrates and an inference time of 28 ms when signatures are updated every 20 ms.\nAdditionally, we also demonstrate a stealth generation mode where signatures\nare generated in a way that makes them virtually indistinguishable from\nunaltered 5G signals while maintaining over 93% detection accuracy.", "AI": {"tldr": "VeriPHY\u662f\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u7269\u7406\u5c42\u8ba4\u8bc1\u65b9\u6848\uff0c\u7528\u4e8e5G\u7f51\u7edc\uff0c\u901a\u8fc7\u9690\u5199\u672f\u5728\u65e0\u7ebfI/Q\u4f20\u8f93\u4e2d\u5d4c\u5165\u7b7e\u540d\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u8bbe\u5907\u8ba4\u8bc1\u3002", "motivation": "\u4f20\u7edf\u52a0\u5bc6\u65b9\u6cd5\u5728\u65e0\u7ebf\u7f51\u7edc\u4e2d\u5b58\u5728\u6548\u7387\u548c\u5b89\u5168\u95ee\u9898\uff0c\u7269\u7406\u5c42\u8ba4\u8bc1\uff08PLA\uff09\u5229\u7528\u901a\u4fe1\u4ecb\u8d28\u7684\u56fa\u6709\u7279\u6027\u63d0\u4f9b\u9ad8\u6548\u8ba4\u8bc1\u3002\u6df1\u5ea6\u5b66\u4e60\u7684\u53d1\u5c55\u4f7fPLA\u66f4\u51c6\u786e\u53ef\u9760\u3002", "method": "VeriPHY\u901a\u8fc7\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u751f\u6210\u4f2a\u968f\u673a\u7b7e\u540d\uff0c\u5e76\u5c06\u5176\u5d4c\u51655G\u7f51\u7edc\u7684I/Q\u4f20\u8f93\u4e2d\uff0c\u5229\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8bc6\u522b\u548c\u8ba4\u8bc1\u8bbe\u5907\u3002", "result": "VeriPHY\u5728\u7b7e\u540d\u66f4\u65b0\u9891\u7387\u4e3a20\u6beb\u79d2\u65f6\uff0c\u8bc6\u522b\u7cbe\u5ea6\u8fbe93%-100%\uff0c\u8bef\u62a5\u7387\u4f4e\uff0c\u63a8\u7406\u65f6\u95f4\u4e3a28\u6beb\u79d2\u3002\u5176\u9690\u5199\u6a21\u5f0f\u80fd\u4fdd\u630193%\u4ee5\u4e0a\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "conclusion": "VeriPHY\u4e3a5G\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u9ad8\u7cbe\u5ea6\u7684\u7269\u7406\u5c42\u8ba4\u8bc1\u65b9\u6848\uff0c\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u9690\u5199\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bbe\u5907\u8ba4\u8bc1\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2508.09203", "pdf": "https://arxiv.org/pdf/2508.09203", "abs": "https://arxiv.org/abs/2508.09203", "authors": ["Zhenhui Ou", "Dawei Li", "Zhen Tan", "Wenlin Li", "Huan Liu", "Siyuan Song"], "title": "Building Safer Sites: A Large-Scale Multi-Level Dataset for Construction Safety Research", "categories": ["cs.LG"], "comment": "The paper was accepted on the CIKM 2025", "summary": "Construction safety research is a critical field in civil engineering, aiming\nto mitigate risks and prevent injuries through the analysis of site conditions\nand human factors. However, the limited volume and lack of diversity in\nexisting construction safety datasets pose significant challenges to conducting\nin-depth analyses. To address this research gap, this paper introduces the\nConstruction Safety Dataset (CSDataset), a well-organized comprehensive\nmulti-level dataset that encompasses incidents, inspections, and violations\nrecorded sourced from the Occupational Safety and Health Administration (OSHA).\nThis dataset uniquely integrates structured attributes with unstructured\nnarratives, facilitating a wide range of approaches driven by machine learning\nand large language models. We also conduct a preliminary approach benchmarking\nand various cross-level analyses using our dataset, offering insights to inform\nand enhance future efforts in construction safety. For example, we found that\ncomplaint-driven inspections were associated with a 17.3% reduction in the\nlikelihood of subsequent incidents. Our dataset and code are released at\nhttps://github.com/zhenhuiou/Construction-Safety-Dataset-CSDataset.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86Construction Safety Dataset (CSDataset)\uff0c\u4e00\u4e2a\u7efc\u5408\u591a\u5c42\u7ea7\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u89e3\u51b3\u5efa\u7b51\u5b89\u5168\u7814\u7a76\u4e2d\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u652f\u6301\u673a\u5668\u5b66\u4e60\u548c\u8bed\u8a00\u6a21\u578b\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u5efa\u7b51\u5b89\u5168\u6570\u636e\u96c6\u6570\u91cf\u6709\u9650\u4e14\u591a\u6837\u6027\u4e0d\u8db3\uff0c\u96be\u4ee5\u652f\u6301\u6df1\u5165\u5206\u6790\u3002", "method": "\u5f15\u5165CSDataset\uff0c\u6574\u5408OSHA\u7684\u7ed3\u6784\u5316\u5c5e\u6027\u548c\u975e\u7ed3\u6784\u5316\u53d9\u8ff0\uff0c\u5e76\u8fdb\u884c\u521d\u6b65\u57fa\u51c6\u6d4b\u8bd5\u548c\u8de8\u5c42\u7ea7\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6295\u8bc9\u9a71\u52a8\u7684\u68c0\u67e5\u4e0e\u540e\u7eed\u4e8b\u6545\u6982\u7387\u964d\u4f4e17.3%\u76f8\u5173\u3002", "conclusion": "CSDataset\u4e3a\u5efa\u7b51\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u5206\u6790\u3002"}}
{"id": "2508.09532", "pdf": "https://arxiv.org/pdf/2508.09532", "abs": "https://arxiv.org/abs/2508.09532", "authors": ["Bokeng Zheng", "Jianqiang Zhong", "Jiayi Liu", "Xiaoxi Zhang"], "title": "Decentralized Rank Scheduling for Energy-Constrained Multi-Task Federated Fine-Tuning in Edge-Assisted IoV Networks", "categories": ["cs.LG", "cs.AI", "cs.NI"], "comment": null, "summary": "Federated fine-tuning has emerged as a promising approach for adapting\nfoundation models (FMs) to diverse downstream tasks in edge environments. In\nInternet of Vehicles (IoV) systems, enabling efficient and low-latency\nmulti-task adaptation is particularly challenging due to client mobility,\nheterogeneous resources, and intermittent connectivity. This paper proposes a\nhierarchical federated fine-tuning framework that coordinates roadside units\n(RSUs) and vehicles to support resource-aware and mobility-resilient learning\nacross dynamic IoV scenarios. Leveraging Low-Rank Adaptation (LoRA), we\nintroduce a decentralized, energy-aware rank adaptation mechanism formulated as\na constrained multi-armed bandit problem. A novel UCB-DUAL algorithm is\ndeveloped to enable adaptive exploration under per-task energy budgets,\nachieving provable sublinear regret. To evaluate our method, we construct a\nlarge-scale IoV simulator based on real-world trajectories, capturing dynamic\nparticipation, RSU handoffs, and communication variability. Extensive\nexperiments show that our approach achieves the best accuracy-efficiency\ntrade-off among all baselines, reducing latency by over 24\\% and improving\naverage accuracy by more than 2.5\\%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u8054\u90a6\u5fae\u8c03\u6846\u67b6\uff0c\u7528\u4e8e\u52a8\u6001\u8f66\u8054\u7f51\u573a\u666f\u4e2d\u7684\u8d44\u6e90\u611f\u77e5\u548c\u79fb\u52a8\u5f39\u6027\u5b66\u4e60\uff0c\u901a\u8fc7LoRA\u548cUCB-DUAL\u7b97\u6cd5\u4f18\u5316\u80fd\u6548\u548c\u5ef6\u8fdf\u3002", "motivation": "\u89e3\u51b3\u8f66\u8054\u7f51\u7cfb\u7edf\u4e2d\u7531\u4e8e\u5ba2\u6237\u7aef\u79fb\u52a8\u6027\u3001\u8d44\u6e90\u5f02\u6784\u6027\u548c\u95f4\u6b47\u6027\u8fde\u63a5\u5bfc\u81f4\u7684\u591a\u4efb\u52a1\u9002\u5e94\u6548\u7387\u4f4e\u548c\u5ef6\u8fdf\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5206\u5c42\u8054\u90a6\u5fae\u8c03\u6846\u67b6\uff0c\u7ed3\u5408LoRA\u548cUCB-DUAL\u7b97\u6cd5\uff0c\u5b9e\u73b0\u8d44\u6e90\u611f\u77e5\u548c\u79fb\u52a8\u5f39\u6027\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5ef6\u8fdf\u548c\u51c6\u786e\u6027\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5ef6\u8fdf\u964d\u4f4e24%\uff0c\u5e73\u5747\u51c6\u786e\u6027\u63d0\u9ad82.5%\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u52a8\u6001\u8f66\u8054\u7f51\u573a\u666f\u4e0b\u7684\u9ad8\u6548\u591a\u4efb\u52a1\u9002\u5e94\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2508.09204", "pdf": "https://arxiv.org/pdf/2508.09204", "abs": "https://arxiv.org/abs/2508.09204", "authors": ["Jinhao Zhang", "Yunquan Zhang", "Boyang Zhang", "Zeyu Liu", "Daning Cheng"], "title": "MoQE: Improve Quantization Model performance via Mixture of Quantization Experts", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Quantization method plays a crucial role in improving model efficiency and\nreducing deployment costs, enabling the widespread application of deep learning\nmodels on resource-constrained devices. However, the quantization process\ninevitably introduces accuracy degradation. In this paper, we propose Mixture\nof Quantization Experts( abbr. MoQE), a quantization inference framework based\non the Mixture-of-Experts (MoE) architecture, aiming to jointly improve the\nperformance of quantization models. MoQE combines multiple quantization\nvariants of one full-precision model as specialized \"quantization experts\" and\ndynamically routes input data to the most suitable expert based on its\ncharacteristics. MoQE alleviates the performance degradation commonly seen in\nsingle quantization models through specialization quantization expert models.\nWe design lightweight, structure-aware router models tailored for both CV and\nNLP tasks. Experimental evaluations on ResNet, LLaMA, and Qwen model families\nacross benchmark datasets including ImageNet, WikiText, C4, and OpenWebText\ndemonstrate that MoQE achieves performance comparable to SOTA quantization\nmodel, without incurring significant increases in inference latency.", "AI": {"tldr": "MoQE\u662f\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\u7684\u91cf\u5316\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8def\u7531\u8f93\u5165\u6570\u636e\u5230\u6700\u5408\u9002\u7684\u91cf\u5316\u4e13\u5bb6\u6a21\u578b\uff0c\u7f13\u89e3\u5355\u4e00\u91cf\u5316\u6a21\u578b\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "motivation": "\u91cf\u5316\u65b9\u6cd5\u5728\u63d0\u9ad8\u6a21\u578b\u6548\u7387\u548c\u964d\u4f4e\u90e8\u7f72\u6210\u672c\u65b9\u9762\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u91cf\u5316\u8fc7\u7a0b\u4f1a\u5bfc\u81f4\u7cbe\u5ea6\u4e0b\u964d\u3002MoQE\u65e8\u5728\u901a\u8fc7\u7ed3\u5408\u591a\u4e2a\u91cf\u5316\u53d8\u4f53\u4f5c\u4e3a\u4e13\u5bb6\u6a21\u578b\uff0c\u63d0\u5347\u91cf\u5316\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "MoQE\u7ed3\u5408\u5168\u7cbe\u5ea6\u6a21\u578b\u7684\u591a\u4e2a\u91cf\u5316\u53d8\u4f53\u4f5c\u4e3a\u4e13\u95e8\u7684\u91cf\u5316\u4e13\u5bb6\uff0c\u5e76\u57fa\u4e8e\u8f93\u5165\u6570\u636e\u7279\u5f81\u52a8\u6001\u8def\u7531\u5230\u6700\u5408\u9002\u7684\u4e13\u5bb6\u3002\u8bbe\u8ba1\u4e86\u8f7b\u91cf\u7ea7\u3001\u7ed3\u6784\u611f\u77e5\u7684\u8def\u7531\u5668\u6a21\u578b\uff0c\u9002\u7528\u4e8eCV\u548cNLP\u4efb\u52a1\u3002", "result": "\u5728ResNet\u3001LLaMA\u548cQwen\u6a21\u578b\u5bb6\u65cf\u53ca\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMoQE\u6027\u80fd\u63a5\u8fd1SOTA\u91cf\u5316\u6a21\u578b\uff0c\u4e14\u672a\u663e\u8457\u589e\u52a0\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "MoQE\u901a\u8fc7\u52a8\u6001\u8def\u7531\u548c\u4e13\u5bb6\u6a21\u578b\u7ed3\u5408\uff0c\u6709\u6548\u7f13\u89e3\u91cf\u5316\u6a21\u578b\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09206", "pdf": "https://arxiv.org/pdf/2508.09206", "abs": "https://arxiv.org/abs/2508.09206", "authors": ["Ning-Yuan Lue"], "title": "The First Differentiable Transfer-Based Algorithm for Discrete MicroLED Repair", "categories": ["cs.LG", "physics.comp-ph"], "comment": "15 pages, 7 figures. Presents a differentiable optimization method\n  for laser-enabled MicroLED repair planning, modeling discrete stage shifts in\n  a manufacturing physics context. Includes loss landscape and gradient\n  analyses, with large-array simulation results", "summary": "Laser-enabled selective transfer, a key process in high-throughput microLED\nfabrication, requires computational models that can plan shift sequences to\nminimize motion of XY stages and adapt to varying optimization objectives\nacross the substrate. We propose the first repair algorithm based on a\ndifferentiable transfer module designed to model discrete shifts of transfer\nplatforms, while remaining trainable via gradient-based optimization. Compared\nto local proximity searching algorithms, our approach achieves superior repair\nperformance and enables more flexible objective designs, such as minimizing the\nnumber of steps. Unlike reinforcement learning (RL)-based approaches, our\nmethod eliminates the need for handcrafted feature extractors and trains\nsignificantly faster, allowing scalability to large arrays. Experiments show a\n50% reduction in transfer steps and sub-2-minute planning time on 2000x2000\narrays. This method provides a practical and adaptable solution for\naccelerating microLED repair in AR/VR and next-generation display fabrication.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u5fae\u5206\u8f6c\u79fb\u6a21\u5757\u7684\u4fee\u590d\u7b97\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u5faeLED\u5236\u9020\u4e2d\u7684\u9009\u62e9\u6027\u8f6c\u79fb\u8fc7\u7a0b\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8f6c\u79fb\u6b65\u9aa4\u548c\u89c4\u5212\u65f6\u95f4\u3002", "motivation": "\u5faeLED\u5236\u9020\u4e2d\u7684\u9009\u62e9\u6027\u8f6c\u79fb\u9700\u8981\u9ad8\u6548\u7684\u8ba1\u7b97\u6a21\u578b\u6765\u4f18\u5316XY\u5e73\u53f0\u7684\u8fd0\u52a8\uff0c\u5e76\u9002\u5e94\u4e0d\u540c\u7684\u4f18\u5316\u76ee\u6807\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u5fae\u5206\u8f6c\u79fb\u6a21\u5757\u7684\u4fee\u590d\u7b97\u6cd5\uff0c\u652f\u6301\u68af\u5ea6\u4f18\u5316\uff0c\u907f\u514d\u4e86\u624b\u5de5\u7279\u5f81\u63d0\u53d6\uff0c\u8bad\u7ec3\u901f\u5ea6\u66f4\u5feb\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u57282000x2000\u9635\u5217\u4e0a\u51cf\u5c11\u4e8650%\u7684\u8f6c\u79fb\u6b65\u9aa4\uff0c\u89c4\u5212\u65f6\u95f4\u4f4e\u4e8e2\u5206\u949f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5faeLED\u4fee\u590d\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8eAR/VR\u548c\u4e0b\u4e00\u4ee3\u663e\u793a\u5668\u7684\u5236\u9020\u3002"}}
{"id": "2508.09708", "pdf": "https://arxiv.org/pdf/2508.09708", "abs": "https://arxiv.org/abs/2508.09708", "authors": ["Thomas Fehrenbach", "Luis Omar Ortiz Abrego", "Cornelius Hellge", "Thomas Schierl", "J\u00f6rg Ott"], "title": "3GPP NR V2X Mode 2d: Analysis of Distributed Scheduling for Groupcast using ns-3 5G LENA Simulator", "categories": ["eess.SP", "cs.NI", "C.2.1; C.2.2; C.2.4"], "comment": "7 pages, 10 figures, 2 tables, V2X communication, vehicular networks,\n  platooning simulation", "summary": "Vehicle-to-everything (V2X) communication is a key technology for enabling\nintelligent transportation systems (ITS) that can improve road safety, traffic\nefficiency, and environmental sustainability. Among the various V2X\napplications, platooning is one of the most promising ones, as it allows a\ngroup of vehicles to travel closely together at high speeds, reducing fuel\nconsumption and emissions. However, it poses significant challenges for\nwireless communication, such as high reliability and low latency. In this\npaper, we evaluate the benefits of group scheduling, also referred to as Mode\n2d, which is based on a distributed and scheduled resource allocation scheme\nthat allows the group of cars to select resources from a configured pool\nwithout network assistance. We evaluated the scheme through simulations, and\nthe results show that this approach can meet the reliability, low latency, and\ndata rate requirements for platooning.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86V2X\u901a\u4fe1\u4e2d\u7684\u7fa4\u7ec4\u8c03\u5ea6\uff08Mode 2d\uff09\u5bf9\u8f66\u8f86\u7f16\u961f\u884c\u9a76\u7684\u65e0\u7ebf\u901a\u4fe1\u6027\u80fd\u63d0\u5347\u6548\u679c\u3002", "motivation": "\u8f66\u8f86\u7f16\u961f\u884c\u9a76\uff08platooning\uff09\u662fV2X\u901a\u4fe1\u7684\u91cd\u8981\u5e94\u7528\uff0c\u4f46\u5176\u5bf9\u65e0\u7ebf\u901a\u4fe1\u7684\u9ad8\u53ef\u9760\u6027\u548c\u4f4e\u5ef6\u8fdf\u63d0\u51fa\u4e86\u6311\u6218\u3002", "method": "\u91c7\u7528\u5206\u5e03\u5f0f\u548c\u9884\u5b9a\u7684\u8d44\u6e90\u5206\u914d\u65b9\u6848\uff08Mode 2d\uff09\uff0c\u8f66\u8f86\u7fa4\u7ec4\u4ece\u914d\u7f6e\u7684\u8d44\u6e90\u6c60\u4e2d\u9009\u62e9\u8d44\u6e90\uff0c\u65e0\u9700\u7f51\u7edc\u8f85\u52a9\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6848\u80fd\u6ee1\u8db3\u7f16\u961f\u884c\u9a76\u5bf9\u53ef\u9760\u6027\u3001\u4f4e\u5ef6\u8fdf\u548c\u6570\u636e\u901f\u7387\u7684\u8981\u6c42\u3002", "conclusion": "\u7fa4\u7ec4\u8c03\u5ea6\uff08Mode 2d\uff09\u662f\u4e00\u79cd\u6709\u6548\u7684\u8d44\u6e90\u5206\u914d\u65b9\u6848\uff0c\u9002\u7528\u4e8eV2X\u901a\u4fe1\u4e2d\u7684\u8f66\u8f86\u7f16\u961f\u884c\u9a76\u3002"}}
{"id": "2508.09223", "pdf": "https://arxiv.org/pdf/2508.09223", "abs": "https://arxiv.org/abs/2508.09223", "authors": ["Sameer Ambekar", "Daniel M. Lang", "Julia A. Schnabel"], "title": "Hierarchical Adaptive networks with Task vectors for Test-Time Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Test-time adaptation allows pretrained models to adjust to incoming data\nstreams, addressing distribution shifts between source and target domains.\nHowever, standard methods rely on single-dimensional linear classification\nlayers, which often fail to handle diverse and complex shifts. We propose\nHierarchical Adaptive Networks with Task Vectors (Hi-Vec), which leverages\nmultiple layers of increasing size for dynamic test-time adaptation. By\ndecomposing the encoder's representation space into such hierarchically\norganized layers, Hi-Vec, in a plug-and-play manner, allows existing methods to\nadapt to shifts of varying complexity. Our contributions are threefold: First,\nwe propose dynamic layer selection for automatic identification of the optimal\nlayer for adaptation to each test batch. Second, we propose a mechanism that\nmerges weights from the dynamic layer to other layers, ensuring all layers\nreceive target information. Third, we propose linear layer agreement that acts\nas a gating function, preventing erroneous fine-tuning by adaptation on noisy\nbatches. We rigorously evaluate the performance of Hi-Vec in challenging\nscenarios and on multiple target datasets, proving its strong capability to\nadvance state-of-the-art methods. Our results show that Hi-Vec improves\nrobustness, addresses uncertainty, and handles limited batch sizes and\nincreased outlier rates.", "AI": {"tldr": "Hi-Vec\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u81ea\u9002\u5e94\u7f51\u7edc\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u5c42\u548c\u6743\u91cd\u5408\u5e76\u673a\u5236\uff0c\u63d0\u5347\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u6d4b\u8bd5\u65f6\u5bf9\u5206\u5e03\u53d8\u5316\u7684\u9002\u5e94\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u56e0\u5355\u7ef4\u7ebf\u6027\u5206\u7c7b\u5c42\u65e0\u6cd5\u5e94\u5bf9\u590d\u6742\u5206\u5e03\u53d8\u5316\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5206\u5c42\u7ec4\u7ec7\u5c42\u7ed3\u6784\uff0c\u52a8\u6001\u9009\u62e9\u6700\u4f18\u5c42\uff0c\u5408\u5e76\u6743\u91cd\u81f3\u5176\u4ed6\u5c42\uff0c\u5e76\u901a\u8fc7\u7ebf\u6027\u5c42\u4e00\u81f4\u6027\u9632\u6b62\u566a\u58f0\u6279\u6b21\u5e72\u6270\u3002", "result": "\u5728\u591a\u79cd\u6311\u6218\u6027\u573a\u666f\u548c\u76ee\u6807\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u63d0\u5347\u4e86\u9c81\u68d2\u6027\u3001\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u548c\u5f02\u5e38\u503c\u80fd\u529b\u3002", "conclusion": "Hi-Vec\u663e\u8457\u63d0\u5347\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u9002\u5e94\u6027\uff0c\u9002\u7528\u4e8e\u590d\u6742\u5206\u5e03\u53d8\u5316\u573a\u666f\u3002"}}
{"id": "2508.09227", "pdf": "https://arxiv.org/pdf/2508.09227", "abs": "https://arxiv.org/abs/2508.09227", "authors": ["Fan Ding", "Hwa Hui Tew", "Junn Yong Loo", "Susilawati", "LiTong Liu", "Fang Yu Leong", "Xuewen Luo", "Kar Keong Chin", "Jia Jun Gan"], "title": "GSMT: Graph Fusion and Spatiotemporal TaskCorrection for Multi-Bus Trajectory Prediction", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": "This paper has been accepted by ITSC 2025", "summary": "Accurate trajectory prediction for buses is crucial in intelligent\ntransportation systems, particularly within urban environments. In developing\nregions where access to multimodal data is limited, relying solely on onboard\nGPS data remains indispensable despite inherent challenges. To address this\nproblem, we propose GSMT, a hybrid model that integrates a Graph Attention\nNetwork (GAT) with a sequence-to-sequence Recurrent Neural Network (RNN), and\nincorporates a task corrector capable of extracting complex behavioral patterns\nfrom large-scale trajectory data. The task corrector clusters historical\ntrajectories to identify distinct motion patterns and fine-tunes the\npredictions generated by the GAT and RNN. Specifically, GSMT fuses dynamic bus\ninformation and static station information through embedded hybrid networks to\nperform trajectory prediction, and applies the task corrector for secondary\nrefinement after the initial predictions are generated. This two-stage approach\nenables multi-node trajectory prediction among buses operating in dense urban\ntraffic environments under complex conditions. Experiments conducted on a\nreal-world dataset from Kuala Lumpur, Malaysia, demonstrate that our method\nsignificantly outperforms existing approaches, achieving superior performance\nin both short-term and long-term trajectory prediction tasks.", "AI": {"tldr": "GSMT\u662f\u4e00\u79cd\u6df7\u5408\u6a21\u578b\uff0c\u7ed3\u5408\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u548c\u5e8f\u5217\u5230\u5e8f\u5217RNN\uff0c\u901a\u8fc7\u4efb\u52a1\u6821\u6b63\u5668\u4f18\u5316\u516c\u4ea4\u8f68\u8ff9\u9884\u6d4b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5728\u6570\u636e\u6709\u9650\u7684\u53d1\u5c55\u4e2d\u5730\u533a\uff0c\u4ec5\u4f9d\u8d56GPS\u6570\u636e\u9884\u6d4b\u516c\u4ea4\u8f68\u8ff9\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u6a21\u578b\u3002", "method": "GSMT\u6574\u5408GAT\u548cRNN\uff0c\u5229\u7528\u4efb\u52a1\u6821\u6b63\u5668\u805a\u7c7b\u5386\u53f2\u8f68\u8ff9\u5e76\u4f18\u5316\u9884\u6d4b\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u65b9\u6cd5\u5b9e\u73b0\u591a\u8282\u70b9\u8f68\u8ff9\u9884\u6d4b\u3002", "result": "\u5728\u5409\u9686\u5761\u7684\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cGSMT\u5728\u77ed\u671f\u548c\u957f\u671f\u8f68\u8ff9\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "GSMT\u901a\u8fc7\u6df7\u5408\u6a21\u578b\u548c\u4efb\u52a1\u6821\u6b63\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u57ce\u5e02\u73af\u5883\u4e2d\u516c\u4ea4\u8f68\u8ff9\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2508.09237", "pdf": "https://arxiv.org/pdf/2508.09237", "abs": "https://arxiv.org/abs/2508.09237", "authors": ["Luigi D'Amico", "Daniel De Rosso", "Ninad Dixit", "Raul Salles de Padua", "Samuel Palmer", "Samuel Mugel", "Rom\u00e1n Or\u00fas", "Holger Eble", "Ali Abedi"], "title": "Blockchain Network Analysis using Quantum Inspired Graph Neural Networks & Ensemble Models", "categories": ["cs.LG", "quant-ph"], "comment": null, "summary": "In the rapidly evolving domain of financial technology, the detection of\nillicit transactions within blockchain networks remains a critical challenge,\nnecessitating robust and innovative solutions. This work proposes a novel\napproach by combining Quantum Inspired Graph Neural Networks (QI-GNN) with\nflexibility of choice of an Ensemble Model using QBoost or a classic model such\nas Random Forrest Classifier. This system is tailored specifically for\nblockchain network analysis in anti-money laundering (AML) efforts. Our\nmethodology to design this system incorporates a novel component, a Canonical\nPolyadic (CP) decomposition layer within the graph neural network framework,\nenhancing its capability to process and analyze complex data structures\nefficiently. Our technical approach has undergone rigorous evaluation against\nclassical machine learning implementations, achieving an F2 score of 74.8% in\ndetecting fraudulent transactions. These results highlight the potential of\nquantum-inspired techniques, supplemented by the structural advancements of the\nCP layer, to not only match but potentially exceed traditional methods in\ncomplex network analysis for financial security. The findings advocate for a\nbroader adoption and further exploration of quantum-inspired algorithms within\nthe financial sector to effectively combat fraud.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u91cf\u5b50\u542f\u53d1\u56fe\u795e\u7ecf\u7f51\u7edc\uff08QI-GNN\uff09\u4e0e\u96c6\u6210\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u533a\u5757\u94fe\u7f51\u7edc\u4e2d\u7684\u53cd\u6d17\u94b1\uff08AML\uff09\u4ea4\u6613\u68c0\u6d4b\uff0c\u901a\u8fc7\u5f15\u5165CP\u5206\u89e3\u5c42\u63d0\u5347\u6027\u80fd\uff0cF2\u5206\u6570\u8fbe74.8%\u3002", "motivation": "\u91d1\u878d\u79d1\u6280\u9886\u57df\u5feb\u901f\u53d1\u5c55\uff0c\u533a\u5757\u94fe\u7f51\u7edc\u4e2d\u7684\u975e\u6cd5\u4ea4\u6613\u68c0\u6d4b\u9700\u6c42\u8feb\u5207\uff0c\u9700\u8981\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408QI-GNN\u4e0e\u96c6\u6210\u6a21\u578b\uff08QBoost\u6216\u968f\u673a\u68ee\u6797\uff09\uff0c\u5e76\u5728\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u5f15\u5165CP\u5206\u89e3\u5c42\u4ee5\u9ad8\u6548\u5904\u7406\u590d\u6742\u6570\u636e\u7ed3\u6784\u3002", "result": "\u5728\u68c0\u6d4b\u6b3a\u8bc8\u4ea4\u6613\u4e2d\uff0cF2\u5206\u6570\u8fbe\u523074.8%\uff0c\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u91cf\u5b50\u542f\u53d1\u7b97\u6cd5\u7ed3\u5408\u7ed3\u6784\u4f18\u5316\u5728\u91d1\u878d\u5b89\u5168\u9886\u57df\u5177\u6709\u6f5c\u529b\uff0c\u503c\u5f97\u8fdb\u4e00\u6b65\u63a2\u7d22\u548c\u63a8\u5e7f\u3002"}}
{"id": "2508.09263", "pdf": "https://arxiv.org/pdf/2508.09263", "abs": "https://arxiv.org/abs/2508.09263", "authors": ["Peng Wang", "Dongsheng Wang", "He Zhao", "Hangting Ye", "Dandan Guo", "Yi Chang"], "title": "LLM Empowered Prototype Learning for Zero and Few-Shot Tasks on Tabular Data", "categories": ["cs.LG"], "comment": null, "summary": "Recent breakthroughs in large language models (LLMs) have opened the door to\nin-depth investigation of their potential in tabular data modeling. However,\neffectively utilizing advanced LLMs in few-shot and even zero-shot scenarios is\nstill challenging. To this end, we propose a novel LLM-based prototype\nestimation framework for tabular learning. Our key idea is to query the LLM to\ngenerate feature values based example-free prompt, which solely relies on task\nand feature descriptions. With the feature values generated by LLM, we can\nbuild a zero-shot prototype in a training-free manner, which can be further\nenhanced by fusing few-shot samples, avoiding training a classifier or\nfinetuning the LLMs. Thanks to the example-free prompt and prototype\nestimation, ours bypasses the constraints brought by the example-based prompt,\nproviding a scalable and robust framework. Extensive experiments demonstrate\nthe effectiveness of ours in zero and few-shot tabular learning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u539f\u578b\u4f30\u8ba1\u6846\u67b6\uff0c\u7528\u4e8e\u96f6\u6837\u672c\u548c\u5c0f\u6837\u672c\u8868\u683c\u6570\u636e\u5b66\u4e60\uff0c\u65e0\u9700\u8bad\u7ec3\u5206\u7c7b\u5668\u6216\u5fae\u8c03\u6a21\u578b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8868\u683c\u6570\u636e\u5efa\u6a21\u4e2d\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u5728\u96f6\u6837\u672c\u548c\u5c0f\u6837\u672c\u573a\u666f\u4e0b\u6709\u6548\u5229\u7528\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "\u901a\u8fc7\u4efb\u52a1\u548c\u7279\u5f81\u63cf\u8ff0\u751f\u6210\u7279\u5f81\u503c\uff0c\u6784\u5efa\u96f6\u6837\u672c\u539f\u578b\uff0c\u5e76\u878d\u5408\u5c0f\u6837\u672c\u6570\u636e\u589e\u5f3a\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u96f6\u6837\u672c\u548c\u5c0f\u6837\u672c\u8868\u683c\u5b66\u4e60\u4e2d\u8868\u73b0\u6709\u6548\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u9c81\u68d2\u7684\u6846\u67b6\uff0c\u514b\u670d\u4e86\u57fa\u4e8e\u793a\u4f8b\u63d0\u793a\u7684\u9650\u5236\u3002"}}
{"id": "2508.09264", "pdf": "https://arxiv.org/pdf/2508.09264", "abs": "https://arxiv.org/abs/2508.09264", "authors": ["Matin Hassanloo", "Ali Zareh", "Mehmet Kemal \u00d6zdemir"], "title": "Detection of Odor Presence via Deep Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Odor detection underpins food safety, environmental monitoring, medical\ndiagnostics, and many more fields. The current artificial sensors developed for\nodor detection struggle with complex mixtures while non-invasive recordings\nlack reliable single-trial fidelity. To develop a general system for odor\ndetection, in this study we present a preliminary work where we aim to test two\nhypotheses: (i) that spectral features of local field potentials (LFPs) are\nsufficient for robust single-trial odor detection and (ii) that signals from\nthe olfactory bulb alone are adequate. To test two hypotheses, we propose an\nensemble of complementary one-dimensional convolutional networks (ResCNN and\nAttentionCNN) that decodes the presence of odor from multichannel olfactory\nbulb LFPs. Tested on 2,349 trials from seven awake mice, our final ensemble\nmodel supports both hypotheses, achieving a mean accuracy of 86.6%, an F1-score\nof 81.0%, and an AUC of 0.9247, substantially outperforming previous\nbenchmarks. In addition, the t-SNE visualization confirms that our framework\ncaptures biologically significant signatures. These findings establish the\nfeasibility of robust single-trial detection of the presence of odor from\nextracellular LFPs, as well as demonstrate the potential of deep learning\nmodels to provide a deeper understanding of olfactory representations.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c40\u90e8\u573a\u7535\u4f4d\uff08LFPs\uff09\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u5355\u6b21\u8bd5\u9a8c\u6c14\u5473\u68c0\u6d4b\uff0c\u9a8c\u8bc1\u4e86\u55c5\u89c9\u7403\u4fe1\u53f7\u7684\u6709\u6548\u6027\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "motivation": "\u5f53\u524d\u6c14\u5473\u68c0\u6d4b\u4f20\u611f\u5668\u5728\u590d\u6742\u6df7\u5408\u7269\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u975e\u4fb5\u5165\u6027\u8bb0\u5f55\u7f3a\u4e4f\u5355\u6b21\u8bd5\u9a8c\u53ef\u9760\u6027\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u901a\u7528\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u4e92\u8865\u7684\u4e00\u7ef4\u5377\u79ef\u7f51\u7edc\uff08ResCNN\u548cAttentionCNN\uff09\u89e3\u7801\u55c5\u89c9\u7403\u591a\u901a\u9053LFPs\u4fe1\u53f7\u3002", "result": "\u5728\u4e03\u53ea\u6e05\u9192\u5c0f\u9f20\u76842,349\u6b21\u8bd5\u9a8c\u4e2d\uff0c\u6a21\u578b\u5e73\u5747\u51c6\u786e\u7387\u8fbe86.6%\uff0cF1\u5206\u657081.0%\uff0cAUC\u4e3a0.9247\uff0c\u663e\u8457\u4f18\u4e8e\u4ee5\u5f80\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u8bc1\u5b9e\u4e86\u4eceLFPs\u4e2d\u5b9e\u73b0\u5355\u6b21\u6c14\u5473\u68c0\u6d4b\u7684\u53ef\u884c\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u6df1\u5ea6\u5b66\u4e60\u5728\u7406\u89e3\u55c5\u89c9\u8868\u5f81\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.09265", "pdf": "https://arxiv.org/pdf/2508.09265", "abs": "https://arxiv.org/abs/2508.09265", "authors": ["Danial Saber", "Amirali Salehi-Abari"], "title": "Over-Squashing in GNNs and Causal Inference of Rewiring Strategies", "categories": ["cs.LG", "stat.ME"], "comment": "14 pages, 2 figures", "summary": "Graph neural networks (GNNs) have exhibited state-of-the-art performance\nacross wide-range of domains such as recommender systems, material design, and\ndrug repurposing. Yet message-passing GNNs suffer from over-squashing --\nexponential compression of long-range information from distant nodes -- which\nlimits expressivity. Rewiring techniques can ease this bottleneck; but their\npractical impacts are unclear due to the lack of a direct empirical\nover-squashing metric. We propose a rigorous, topology-focused method for\nassessing over-squashing between node pairs using the decay rate of their\nmutual sensitivity. We then extend these pairwise assessments to four\ngraph-level statistics (prevalence, intensity, variability, extremity).\nCoupling these metrics with a within-graph causal design, we quantify how\nrewiring strategies affect over-squashing on diverse graph- and\nnode-classification benchmarks. Our extensive empirical analyses show that most\ngraph classification datasets suffer from over-squashing (but to various\nextents), and rewiring effectively mitigates it -- though the degree of\nmitigation, and its translation into performance gains, varies by dataset and\nmethod. We also found that over-squashing is less notable in node\nclassification datasets, where rewiring often increases over-squashing, and\nperformance variations are uncorrelated with over-squashing changes. These\nfindings suggest that rewiring is most beneficial when over-squashing is both\nsubstantial and corrected with restraint -- while overly aggressive rewiring,\nor rewiring applied to minimally over-squashed graphs, is unlikely to help and\nmay even harm performance. Our plug-and-play diagnostic tool lets practitioners\ndecide -- before any training -- whether rewiring is likely to pay off.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u62d3\u6251\u7ed3\u6784\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u4e2d\u7684\u4fe1\u606f\u8fc7\u5ea6\u538b\u7f29\uff08over-squashing\uff09\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u91cd\u8fde\uff08rewiring\uff09\u7b56\u7565\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u6548\u679c\u3002", "motivation": "\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u5728\u591a\u4e2a\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u6d88\u606f\u4f20\u9012\u673a\u5236\u5bfc\u81f4\u957f\u8ddd\u79bb\u4fe1\u606f\u8fc7\u5ea6\u538b\u7f29\uff0c\u9650\u5236\u4e86\u6a21\u578b\u8868\u8fbe\u80fd\u529b\u3002\u76ee\u524d\u7f3a\u4e4f\u76f4\u63a5\u7684\u5ea6\u91cf\u65b9\u6cd5\u8bc4\u4f30\u8fd9\u4e00\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u4e25\u8c28\u7684\u8bc4\u4f30\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8282\u70b9\u5bf9\u95f4\u4e92\u654f\u611f\u5ea6\u8870\u51cf\u7387\u7684\u62d3\u6251\u65b9\u6cd5\uff0c\u5e76\u6269\u5c55\u4e3a\u56db\u79cd\u56fe\u7ea7\u7edf\u8ba1\u91cf\u3002\u7ed3\u5408\u56e0\u679c\u8bbe\u8ba1\uff0c\u91cf\u5316\u4e86\u91cd\u8fde\u7b56\u7565\u5bf9\u4fe1\u606f\u538b\u7f29\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u56fe\u5206\u7c7b\u6570\u636e\u96c6\u666e\u904d\u5b58\u5728\u4fe1\u606f\u8fc7\u5ea6\u538b\u7f29\u95ee\u9898\uff0c\u91cd\u8fde\u80fd\u6709\u6548\u7f13\u89e3\uff0c\u4f46\u6548\u679c\u56e0\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u800c\u5f02\uff1b\u8282\u70b9\u5206\u7c7b\u4e2d\u4fe1\u606f\u538b\u7f29\u95ee\u9898\u8f83\u8f7b\uff0c\u91cd\u8fde\u53ef\u80fd\u9002\u5f97\u5176\u53cd\u3002", "conclusion": "\u91cd\u8fde\u7b56\u7565\u5728\u4fe1\u606f\u538b\u7f29\u4e25\u91cd\u4e14\u9002\u5ea6\u8c03\u6574\u65f6\u6700\u6709\u6548\uff0c\u8fc7\u5ea6\u91cd\u8fde\u6216\u5e94\u7528\u4e8e\u8f7b\u5ea6\u538b\u7f29\u7684\u56fe\u53ef\u80fd\u6709\u5bb3\u3002\u8bba\u6587\u63d0\u4f9b\u7684\u8bca\u65ad\u5de5\u5177\u53ef\u5e2e\u52a9\u5b9e\u8df5\u8005\u5728\u8bad\u7ec3\u524d\u5224\u65ad\u91cd\u8fde\u662f\u5426\u6709\u6548\u3002"}}
{"id": "2508.09275", "pdf": "https://arxiv.org/pdf/2508.09275", "abs": "https://arxiv.org/abs/2508.09275", "authors": ["Amine Andam", "Jamal Bentahar", "Mustapha Hedabou"], "title": "Constrained Black-Box Attacks Against Multi-Agent Reinforcement Learning", "categories": ["cs.LG", "cs.MA"], "comment": "Under review in TNNLS", "summary": "Collaborative multi-agent reinforcement learning (c-MARL) has rapidly\nevolved, offering state-of-the-art algorithms for real-world applications,\nincluding sensitive domains. However, a key challenge to its widespread\nadoption is the lack of a thorough investigation into its vulnerabilities to\nadversarial attacks. Existing work predominantly focuses on training-time\nattacks or unrealistic scenarios, such as access to policy weights or the\nability to train surrogate policies. In this paper, we investigate new\nvulnerabilities under more realistic and constrained conditions, assuming an\nadversary can only collect and perturb the observations of deployed agents. We\nalso consider scenarios where the adversary has no access at all. We propose\nsimple yet highly effective algorithms for generating adversarial perturbations\ndesigned to misalign how victim agents perceive their environment. Our approach\nis empirically validated on three benchmarks and 22 environments, demonstrating\nits effectiveness across diverse algorithms and environments. Furthermore, we\nshow that our algorithm is sample-efficient, requiring only 1,000 samples\ncompared to the millions needed by previous methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08c-MARL\uff09\u5728\u73b0\u5b9e\u7ea6\u675f\u6761\u4ef6\u4e0b\u7684\u65b0\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5bf9\u6297\u6270\u52a8\u751f\u6210\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u8bad\u7ec3\u65f6\u653b\u51fb\u6216\u4e0d\u73b0\u5b9e\u573a\u666f\uff0c\u800c\u8be5\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u66f4\u5b9e\u9645\u6761\u4ef6\u4e0bc-MARL\u7684\u8106\u5f31\u6027\u3002", "method": "\u5047\u8bbe\u653b\u51fb\u8005\u4ec5\u80fd\u6536\u96c6\u5e76\u6270\u52a8\u90e8\u7f72\u667a\u80fd\u4f53\u7684\u89c2\u6d4b\u6570\u636e\uff0c\u63d0\u51fa\u7b80\u5355\u9ad8\u6548\u7684\u5bf9\u6297\u6270\u52a8\u7b97\u6cd5\u3002", "result": "\u57283\u4e2a\u57fa\u51c6\u548c22\u4e2a\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e14\u4ec5\u97001,000\u6837\u672c\uff0c\u8fdc\u5c11\u4e8e\u5148\u524d\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u5728\u591a\u6837\u73af\u5883\u548c\u7b97\u6cd5\u4e2d\u5747\u8868\u73b0\u51fa\u9ad8\u6548\u6027\uff0c\u4e3ac-MARL\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2508.09281", "pdf": "https://arxiv.org/pdf/2508.09281", "abs": "https://arxiv.org/abs/2508.09281", "authors": ["Muntasir Hoq", "Griffin Pitts", "Andrew Lan", "Peter Brusilovsky", "Bita Akram"], "title": "Pattern-based Knowledge Component Extraction from Student Code Using Representation Learning", "categories": ["cs.LG", "K.3.2"], "comment": null, "summary": "Effective personalized learning in computer science education depends on\naccurately modeling what students know and what they need to learn. While\nKnowledge Components (KCs) provide a foundation for such modeling, automated KC\nextraction from student code is inherently challenging due to insufficient\nexplainability of discovered KCs and the open-endedness of programming problems\nwith significant structural variability across student solutions and complex\ninteractions among programming concepts. In this work, we propose a novel,\nexplainable framework for automated KC discovery through pattern-based KCs:\nrecurring structural patterns within student code that capture the specific\nprogramming patterns and language constructs that students must master. Toward\nthis, we train a Variational Autoencoder to generate important representative\npatterns from student code guided by an explainable, attention-based code\nrepresentation model that identifies important correct and incorrect pattern\nimplementations from student code. These patterns are then clustered to form\npattern-based KCs. We evaluate our KCs using two well-established methods\ninformed by Cognitive Science: learning curve analysis and Deep Knowledge\nTracing (DKT). Experimental results demonstrate meaningful learning\ntrajectories and significant improvements in DKT predictive performance over\ntraditional KT methods. This work advances knowledge modeling in CS education\nby providing an automated, scalable, and explainable framework for identifying\ngranular code patterns and algorithmic constructs, essential for student\nlearning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u5f0f\u7684\u77e5\u8bc6\u7ec4\u4ef6\uff08KC\uff09\u81ea\u52a8\u53d1\u73b0\u6846\u67b6\uff0c\u901a\u8fc7\u53d8\u5206\u81ea\u7f16\u7801\u5668\u548c\u6ce8\u610f\u529b\u673a\u5236\u63d0\u53d6\u5b66\u751f\u4ee3\u7801\u4e2d\u7684\u6a21\u5f0f\uff0c\u5f62\u6210\u53ef\u89e3\u91ca\u7684KC\uff0c\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u8ffd\u8e2a\u6027\u80fd\u3002", "motivation": "\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u4e2d\u4e2a\u6027\u5316\u5b66\u4e60\u9700\u8981\u51c6\u786e\u5efa\u6a21\u5b66\u751f\u77e5\u8bc6\uff0c\u4f46\u73b0\u6709KC\u63d0\u53d6\u65b9\u6cd5\u56e0\u4ee3\u7801\u7ed3\u6784\u591a\u53d8\u548c\u6982\u5ff5\u4ea4\u4e92\u590d\u6742\u800c\u96be\u4ee5\u89e3\u91ca\u548c\u81ea\u52a8\u5316\u3002", "method": "\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u751f\u6210\u4ee3\u8868\u6027\u4ee3\u7801\u6a21\u5f0f\uff0c\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u8bc6\u522b\u91cd\u8981\u6a21\u5f0f\uff0c\u805a\u7c7b\u5f62\u6210\u6a21\u5f0f\u5316KC\uff0c\u5e76\u901a\u8fc7\u5b66\u4e60\u66f2\u7ebf\u5206\u6790\u548c\u6df1\u5ea6\u77e5\u8bc6\u8ffd\u8e2a\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u80fd\u751f\u6210\u6709\u610f\u4e49\u7684\u5b66\u4e60\u8f68\u8ff9\uff0c\u5e76\u5728\u77e5\u8bc6\u8ffd\u8e2a\u9884\u6d4b\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aCS\u6559\u80b2\u4e2d\u7684\u77e5\u8bc6\u5efa\u6a21\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09283", "pdf": "https://arxiv.org/pdf/2508.09283", "abs": "https://arxiv.org/abs/2508.09283", "authors": ["Connor Wilhelm", "Dan Ventura"], "title": "Distilling Reinforcement Learning into Single-Batch Datasets", "categories": ["cs.LG"], "comment": "to be published in ECAI 2025 (appendix in arXiv version only), 11\n  pages (7 content, 4 appendix), 6 figures", "summary": "Dataset distillation compresses a large dataset into a small synthetic\ndataset such that learning on the synthetic dataset approximates learning on\nthe original. Training on the distilled dataset can be performed in as little\nas one step of gradient descent. We demonstrate that distillation is\ngeneralizable to different tasks by distilling reinforcement learning\nenvironments into one-batch supervised learning datasets. This demonstrates not\nonly distillation's ability to compress a reinforcement learning task but also\nits ability to transform one learning modality (reinforcement learning) into\nanother (supervised learning). We present a novel extension of proximal policy\noptimization for meta-learning and use it in distillation of a\nmulti-dimensional extension of the classic cart-pole problem, all MuJoCo\nenvironments, and several Atari games. We demonstrate distillation's ability to\ncompress complex RL environments into one-step supervised learning, explore RL\ndistillation's generalizability across learner architectures, and demonstrate\ndistilling an environment into the smallest-possible synthetic dataset.", "AI": {"tldr": "\u6570\u636e\u96c6\u84b8\u998f\u5c06\u5927\u6570\u636e\u96c6\u538b\u7f29\u4e3a\u5c0f\u578b\u5408\u6210\u6570\u636e\u96c6\uff0c\u4f7f\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b66\u4e60\u8fd1\u4f3c\u4e8e\u539f\u59cb\u6570\u636e\u96c6\u3002\u8be5\u65b9\u6cd5\u53ef\u5e94\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u6570\u636e\u96c6\u84b8\u998f\u6280\u672f\u538b\u7f29\u590d\u6742\u4efb\u52a1\uff08\u5982\u5f3a\u5316\u5b66\u4e60\uff09\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u5176\u4ed6\u5b66\u4e60\u6a21\u5f0f\uff08\u5982\u76d1\u7763\u5b66\u4e60\uff09\uff0c\u4ee5\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u548c\u901a\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u7684\u5143\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u84b8\u998f\u591a\u7ef4\u5ea6\u4efb\u52a1\uff08\u5982\u7ecf\u5178cart-pole\u95ee\u9898\u3001MuJoCo\u73af\u5883\u548cAtari\u6e38\u620f\uff09\u3002", "result": "\u6210\u529f\u5c06\u590d\u6742\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u538b\u7f29\u4e3a\u4e00\u6b65\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u5b66\u4e60\u67b6\u6784\u4e2d\u7684\u901a\u7528\u6027\u3002", "conclusion": "\u6570\u636e\u96c6\u84b8\u998f\u6280\u672f\u80fd\u591f\u9ad8\u6548\u538b\u7f29\u590d\u6742\u4efb\u52a1\uff0c\u5e76\u5b9e\u73b0\u8de8\u5b66\u4e60\u6a21\u5f0f\u7684\u8f6c\u6362\uff0c\u5c55\u793a\u4e86\u5176\u5728\u591a\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.09299", "pdf": "https://arxiv.org/pdf/2508.09299", "abs": "https://arxiv.org/abs/2508.09299", "authors": ["Rilwan Umar", "Aydin Abadi", "Basil Aldali", "Benito Vincent", "Elliot A. J. Hurley", "Hotoon Aljazaeri", "Jamie Hedley-Cook", "Jamie-Lee Bell", "Lambert Uwuigbusun", "Mujeeb Ahmed", "Shishir Nagaraja", "Suleiman Sabo", "Weaam Alrbeiqi"], "title": "Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Weather forecasting plays a vital role in disaster preparedness, agriculture,\nand resource management, yet current centralized forecasting systems are\nincreasingly strained by security vulnerabilities, limited scalability, and\nsusceptibility to single points of failure. To address these challenges, we\npropose a decentralized weather forecasting framework that integrates Federated\nLearning (FL) with blockchain technology. FL enables collaborative model\ntraining without exposing sensitive local data; this approach enhances privacy\nand reduces data transfer overhead. Meanwhile, the Ethereum blockchain ensures\ntransparent and dependable verification of model updates. To further enhance\nthe system's security, we introduce a reputation-based voting mechanism that\nassesses the trustworthiness of submitted models while utilizing the\nInterplanetary File System (IPFS) for efficient off-chain storage. Experimental\nresults demonstrate that our approach not only improves forecasting accuracy\nbut also enhances system resilience and scalability, making it a viable\ncandidate for deployment in real-world, security-critical environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\u548c\u533a\u5757\u94fe\u6280\u672f\u7684\u53bb\u4e2d\u5fc3\u5316\u5929\u6c14\u9884\u6d4b\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u9690\u79c1\u6027\u3001\u5b89\u5168\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5f53\u524d\u96c6\u4e2d\u5f0f\u5929\u6c14\u9884\u6d4b\u7cfb\u7edf\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\u3001\u53ef\u6269\u5c55\u6027\u5dee\u548c\u5355\u70b9\u6545\u969c\u95ee\u9898\uff0c\u4e9f\u9700\u6539\u8fdb\u3002", "method": "\u6574\u5408\u8054\u90a6\u5b66\u4e60\uff08\u4fdd\u62a4\u9690\u79c1\uff09\u548c\u533a\u5757\u94fe\u6280\u672f\uff08\u900f\u660e\u9a8c\u8bc1\uff09\uff0c\u5f15\u5165\u57fa\u4e8e\u4fe1\u8a89\u7684\u6295\u7968\u673a\u5236\u548cIPFS\u5b58\u50a8\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3001\u7cfb\u7edf\u5f39\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u9002\u5408\u5728\u73b0\u5b9e\u5b89\u5168\u5173\u952e\u73af\u5883\u4e2d\u90e8\u7f72\u3002"}}
{"id": "2508.09320", "pdf": "https://arxiv.org/pdf/2508.09320", "abs": "https://arxiv.org/abs/2508.09320", "authors": ["Minghao Liu", "Chia-Hsuan Lu", "Marta Kwiatkowska"], "title": "Exact Verification of Graph Neural Networks with Incremental Constraint Solving", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Graph neural networks (GNNs) are increasingly employed in high-stakes\napplications, such as fraud detection or healthcare, but are susceptible to\nadversarial attacks. A number of techniques have been proposed to provide\nadversarial robustness guarantees, but support for commonly used aggregation\nfunctions in message-passing GNNs is still lacking. In this paper, we develop\nan exact (sound and complete) verification method for GNNs to compute\nguarantees against attribute and structural perturbations that involve edge\naddition or deletion, subject to budget constraints. Focusing on node\nclassification tasks, our method employs constraint solving with bound\ntightening, and iteratively solves a sequence of relaxed constraint\nsatisfaction problems while relying on incremental solving capabilities of\nsolvers to improve efficiency. We implement GNNev, a versatile solver for\nmessage-passing neural networks, which supports three aggregation functions,\nsum, max and mean, with the latter two considered here for the first time.\nExtensive experimental evaluation of GNNev on two standard benchmarks (Cora and\nCiteSeer) and two real-world fraud datasets (Amazon and Yelp) demonstrates its\nusability and effectiveness, as well as superior performance compared to\nexisting {exact verification} tools on sum-aggregated node classification\ntasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7cbe\u786e\u9a8c\u8bc1\u65b9\u6cd5GNNev\uff0c\u7528\u4e8e\u8bc4\u4f30\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u652f\u6301\u591a\u79cd\u805a\u5408\u51fd\u6570\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "GNNs\u5728\u5173\u952e\u5e94\u7528\u4e2d\u6613\u53d7\u5bf9\u6297\u653b\u51fb\uff0c\u73b0\u6709\u65b9\u6cd5\u5bf9\u5e38\u7528\u805a\u5408\u51fd\u6570\u7684\u652f\u6301\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u5168\u9762\u7684\u9a8c\u8bc1\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u7ea6\u675f\u6c42\u89e3\u548c\u8fb9\u754c\u6536\u7d27\u6280\u672f\uff0c\u8fed\u4ee3\u89e3\u51b3\u677e\u5f1b\u7ea6\u675f\u95ee\u9898\uff0c\u652f\u6301sum\u3001max\u548cmean\u805a\u5408\u51fd\u6570\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\uff08Cora\u3001CiteSeer\u3001Amazon\u3001Yelp\uff09\u4e0a\u9a8c\u8bc1\u4e86GNNev\u7684\u6709\u6548\u6027\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u3002", "conclusion": "GNNev\u4e3aGNNs\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u53ef\u9760\u9a8c\u8bc1\u5de5\u5177\uff0c\u5c24\u5176\u5728sum\u805a\u5408\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2508.09330", "pdf": "https://arxiv.org/pdf/2508.09330", "abs": "https://arxiv.org/abs/2508.09330", "authors": ["Gideon Vos", "Liza van Eijk", "Zoltan Sarnyai", "Mostafa Rahimi Azghadi"], "title": "Synaptic Pruning: A Biological Inspiration for Deep Learning Regularization", "categories": ["cs.LG", "cs.AI"], "comment": "24 pages, 7 figures", "summary": "Synaptic pruning in biological brains removes weak connections to improve\nefficiency. In contrast, dropout regularization in artificial neural networks\nrandomly deactivates neurons without considering activity-dependent pruning. We\npropose a magnitude-based synaptic pruning method that better reflects biology\nby progressively removing low-importance connections during training.\nIntegrated directly into the training loop as a dropout replacement, our\napproach computes weight importance from absolute magnitudes across layers and\napplies a cubic schedule to gradually increase global sparsity. At fixed\nintervals, pruning masks permanently remove low-importance weights while\nmaintaining gradient flow for active ones, eliminating the need for separate\npruning and fine-tuning phases. Experiments on multiple time series forecasting\nmodels including RNN, LSTM, and Patch Time Series Transformer across four\ndatasets show consistent gains. Our method ranked best overall, with\nstatistically significant improvements confirmed by Friedman tests (p < 0.01).\nIn financial forecasting, it reduced Mean Absolute Error by up to 20% over\nmodels with no or standard dropout, and up to 52% in select transformer models.\nThis dynamic pruning mechanism advances regularization by coupling weight\nelimination with progressive sparsification, offering easy integration into\ndiverse architectures. Its strong performance, especially in financial time\nseries forecasting, highlights its potential as a practical alternative to\nconventional dropout techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6743\u91cd\u5927\u5c0f\u7684\u7a81\u89e6\u4fee\u526a\u65b9\u6cd5\uff0c\u6a21\u62df\u751f\u7269\u5927\u8111\u7684\u4fee\u526a\u673a\u5236\uff0c\u9010\u6b65\u79fb\u9664\u4f4e\u91cd\u8981\u6027\u8fde\u63a5\uff0c\u663e\u8457\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u751f\u7269\u5927\u8111\u901a\u8fc7\u7a81\u89e6\u4fee\u526a\u4f18\u5316\u6548\u7387\uff0c\u800c\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684dropout\u968f\u673a\u5931\u6d3b\u795e\u7ecf\u5143\uff0c\u7f3a\u4e4f\u6d3b\u52a8\u4f9d\u8d56\u6027\u3002\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u66f4\u63a5\u8fd1\u751f\u7269\u673a\u5236\u7684\u4fee\u526a\u65b9\u6cd5\u3002", "method": "\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u57fa\u4e8e\u6743\u91cd\u7684\u7edd\u5bf9\u503c\u8ba1\u7b97\u91cd\u8981\u6027\uff0c\u91c7\u7528\u7acb\u65b9\u8c03\u5ea6\u9010\u6b65\u589e\u52a0\u5168\u5c40\u7a00\u758f\u6027\uff0c\u5b9a\u671f\u6c38\u4e45\u79fb\u9664\u4f4e\u91cd\u8981\u6027\u6743\u91cd\uff0c\u540c\u65f6\u4fdd\u6301\u68af\u5ea6\u6d41\u52a8\u3002", "result": "\u5728\u591a\u4e2a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u964d\u4f4e\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08\u91d1\u878d\u9884\u6d4b\u4e2d\u6700\u9ad8\u964d\u4f4e20%\uff09\uff0c\u5728\u90e8\u5206Transformer\u6a21\u578b\u4e2d\u964d\u4f4e52%\u3002", "conclusion": "\u52a8\u6001\u4fee\u526a\u673a\u5236\u7ed3\u5408\u6743\u91cd\u6d88\u9664\u4e0e\u6e10\u8fdb\u7a00\u758f\u5316\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edfdropout\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u6613\u4e8e\u96c6\u6210\u5230\u591a\u79cd\u67b6\u6784\u4e2d\u3002"}}
{"id": "2508.09334", "pdf": "https://arxiv.org/pdf/2508.09334", "abs": "https://arxiv.org/abs/2508.09334", "authors": ["Zhongtian Sun", "Anoushka Harit"], "title": "RicciFlowRec: A Geometric Root Cause Recommender Using Ricci Curvature on Financial Graphs", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": "Accepted at ACM RecSys 2025 (Late Breaking Results Track)", "summary": "We propose RicciFlowRec, a geometric recommendation framework that performs\nroot cause attribution via Ricci curvature and flow on dynamic financial\ngraphs. By modelling evolving interactions among stocks, macroeconomic\nindicators, and news, we quantify local stress using discrete Ricci curvature\nand trace shock propagation via Ricci flow. Curvature gradients reveal causal\nsubstructures, informing a structural risk-aware ranking function. Preliminary\nresults on S\\&P~500 data with FinBERT-based sentiment show improved robustness\nand interpretability under synthetic perturbations. This ongoing work supports\ncurvature-based attribution and early-stage risk-aware ranking, with plans for\nportfolio optimization and return forecasting. To our knowledge, RicciFlowRec\nis the first recommender to apply geometric flow-based reasoning in financial\ndecision support.", "AI": {"tldr": "RicciFlowRec\u662f\u4e00\u4e2a\u57fa\u4e8e\u51e0\u4f55\u7684\u63a8\u8350\u6846\u67b6\uff0c\u5229\u7528Ricci\u66f2\u7387\u548c\u6d41\u5206\u6790\u52a8\u6001\u91d1\u878d\u56fe\u4e2d\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u51e0\u4f55\u65b9\u6cd5\uff08Ricci\u66f2\u7387\u548c\u6d41\uff09\u91cf\u5316\u91d1\u878d\u56fe\u4e2d\u7684\u5c40\u90e8\u538b\u529b\uff0c\u8ffd\u8e2a\u51b2\u51fb\u4f20\u64ad\uff0c\u4ece\u800c\u6539\u8fdb\u91d1\u878d\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u52a8\u6001\u91d1\u878d\u56fe\u5efa\u6a21\u80a1\u7968\u3001\u5b8f\u89c2\u7ecf\u6d4e\u6307\u6807\u548c\u65b0\u95fb\u7684\u4ea4\u4e92\uff0c\u5229\u7528\u79bb\u6563Ricci\u66f2\u7387\u91cf\u5316\u5c40\u90e8\u538b\u529b\uff0cRicci\u6d41\u8ffd\u8e2a\u51b2\u51fb\u4f20\u64ad\uff0c\u66f2\u7387\u68af\u5ea6\u63ed\u793a\u56e0\u679c\u5b50\u7ed3\u6784\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\uff0c\u5728S&P 500\u6570\u636e\u548cFinBERT\u60c5\u611f\u5206\u6790\u4e0b\uff0cRicciFlowRec\u5728\u5408\u6210\u6270\u52a8\u4e0b\u8868\u73b0\u51fa\u66f4\u597d\u7684\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "RicciFlowRec\u662f\u9996\u4e2a\u5c06\u51e0\u4f55\u6d41\u63a8\u7406\u5e94\u7528\u4e8e\u91d1\u878d\u51b3\u7b56\u652f\u6301\u7684\u63a8\u8350\u7cfb\u7edf\uff0c\u672a\u6765\u8ba1\u5212\u6269\u5c55\u81f3\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u548c\u6536\u76ca\u9884\u6d4b\u3002"}}
{"id": "2508.09363", "pdf": "https://arxiv.org/pdf/2508.09363", "abs": "https://arxiv.org/abs/2508.09363", "authors": ["Charles O'Neill", "Mudith Jayasekara", "Max Kirkby"], "title": "Resurrecting the Salmon: Rethinking Mechanistic Interpretability with Domain-Specific Sparse Autoencoders", "categories": ["cs.LG"], "comment": null, "summary": "Sparse autoencoders (SAEs) decompose large language model (LLM) activations\ninto latent features that reveal mechanistic structure. Conventional SAEs train\non broad data distributions, forcing a fixed latent budget to capture only\nhigh-frequency, generic patterns. This often results in significant linear\n``dark matter'' in reconstruction error and produces latents that fragment or\nabsorb each other, complicating interpretation. We show that restricting SAE\ntraining to a well-defined domain (medical text) reallocates capacity to\ndomain-specific features, improving both reconstruction fidelity and\ninterpretability. Training JumpReLU SAEs on layer-20 activations of Gemma-2\nmodels using 195k clinical QA examples, we find that domain-confined SAEs\nexplain up to 20\\% more variance, achieve higher loss recovery, and reduce\nlinear residual error compared to broad-domain SAEs. Automated and human\nevaluations confirm that learned features align with clinically meaningful\nconcepts (e.g., ``taste sensations'' or ``infectious mononucleosis''), rather\nthan frequent but uninformative tokens. These domain-specific SAEs capture\nrelevant linear structure, leaving a smaller, more purely nonlinear residual.\nWe conclude that domain-confinement mitigates key limitations of broad-domain\nSAEs, enabling more complete and interpretable latent decompositions, and\nsuggesting the field may need to question ``foundation-model'' scaling for\ngeneral-purpose SAEs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u9650\u5236\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAEs\uff09\u7684\u8bad\u7ec3\u9886\u57df\uff08\u5982\u533b\u5b66\u6587\u672c\uff09\uff0c\u53ef\u4ee5\u63d0\u5347\u7279\u5f81\u91cd\u5efa\u7684\u4fdd\u771f\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u51cf\u5c11\u7ebf\u6027\u6b8b\u5dee\uff0c\u5e76\u6355\u6349\u66f4\u6709\u610f\u4e49\u7684\u9886\u57df\u7279\u5b9a\u7279\u5f81\u3002", "motivation": "\u4f20\u7edfSAEs\u5728\u5e7f\u6cdb\u6570\u636e\u5206\u5e03\u4e0a\u8bad\u7ec3\uff0c\u5bfc\u81f4\u56fa\u5b9a\u9884\u7b97\u53ea\u80fd\u6355\u6349\u9ad8\u9891\u901a\u7528\u6a21\u5f0f\uff0c\u4ea7\u751f\u7ebf\u6027\u6b8b\u5dee\u548c\u7279\u5f81\u788e\u7247\u5316\u95ee\u9898\u3002", "method": "\u5728\u7279\u5b9a\u9886\u57df\uff08\u533b\u5b66\u6587\u672c\uff09\u8bad\u7ec3JumpReLU SAEs\uff0c\u4f7f\u7528195k\u4e34\u5e8a\u95ee\u7b54\u6570\u636e\uff0c\u5206\u6790Gemma-2\u6a21\u578b\u7684\u7b2c20\u5c42\u6fc0\u6d3b\u3002", "result": "\u9886\u57df\u9650\u5236\u7684SAEs\u89e3\u91ca\u66f4\u591a\u65b9\u5dee\uff0820%\uff09\uff0c\u63d0\u9ad8\u635f\u5931\u6062\u590d\uff0c\u51cf\u5c11\u7ebf\u6027\u6b8b\u5dee\uff0c\u7279\u5f81\u4e0e\u4e34\u5e8a\u6982\u5ff5\u5bf9\u9f50\u3002", "conclusion": "\u9886\u57df\u9650\u5236\u53ef\u89e3\u51b3\u5e7f\u6cdb\u9886\u57dfSAEs\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u66f4\u5b8c\u6574\u548c\u53ef\u89e3\u91ca\u7684\u6f5c\u5728\u5206\u89e3\uff0c\u8d28\u7591\u901a\u7528SAEs\u7684\u6269\u5c55\u9700\u6c42\u3002"}}
{"id": "2508.09385", "pdf": "https://arxiv.org/pdf/2508.09385", "abs": "https://arxiv.org/abs/2508.09385", "authors": ["Mansi", "Anastasios Lepipas", "Dominika Woszczyk", "Yiying Guan", "Soteris Demetriou"], "title": "Understanding Dementia Speech Alignment with Diffusion-Based Image Generation", "categories": ["cs.LG", "cs.AI"], "comment": "Paper accepted at Interspeech 2025", "summary": "Text-to-image models generate highly realistic images based on natural\nlanguage descriptions and millions of users use them to create and share images\nonline. While it is expected that such models can align input text and\ngenerated image in the same latent space little has been done to understand\nwhether this alignment is possible between pathological speech and generated\nimages. In this work, we examine the ability of such models to align\ndementia-related speech information with the generated images and develop\nmethods to explain this alignment. Surprisingly, we found that dementia\ndetection is possible from generated images alone achieving 75% accuracy on the\nADReSS dataset. We then leverage explainability methods to show which parts of\nthe language contribute to the detection.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u751f\u6210\u7684\u56fe\u50cf\u53ef\u4ee5\u68c0\u6d4b\u75f4\u5446\u75c7\uff0c\u51c6\u786e\u7387\u8fbe75%\uff0c\u5e76\u63ed\u793a\u4e86\u8bed\u8a00\u4e2d\u54ea\u4e9b\u90e8\u5206\u5bf9\u68c0\u6d4b\u6709\u8d21\u732e\u3002", "motivation": "\u63a2\u7d22\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u662f\u5426\u80fd\u5c06\u75c5\u7406\u8bed\u97f3\uff08\u5982\u75f4\u5446\u76f8\u5173\u8bed\u8a00\uff09\u4e0e\u751f\u6210\u56fe\u50cf\u5bf9\u9f50\uff0c\u5e76\u89e3\u91ca\u8fd9\u79cd\u5bf9\u9f50\u7684\u673a\u5236\u3002", "method": "\u4f7f\u7528ADReSS\u6570\u636e\u96c6\uff0c\u5206\u6790\u6a21\u578b\u751f\u6210\u7684\u56fe\u50cf\u4e0e\u75f4\u5446\u76f8\u5173\u8bed\u8a00\u7684\u5173\u8054\uff0c\u5e76\u5e94\u7528\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u3002", "result": "\u4ec5\u901a\u8fc7\u751f\u6210\u56fe\u50cf\u5373\u53ef\u5b9e\u73b0\u75f4\u5446\u68c0\u6d4b\uff0c\u51c6\u786e\u7387\u4e3a75%\u3002", "conclusion": "\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u5728\u75c5\u7406\u8bed\u97f3\u5bf9\u9f50\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4e3a\u75f4\u5446\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2508.09399", "pdf": "https://arxiv.org/pdf/2508.09399", "abs": "https://arxiv.org/abs/2508.09399", "authors": ["Yue Yao", "Zhen Xu", "Youzhu Liu", "Kunyuan Ma", "Yuxiu Lin", "Mohan Jiang"], "title": "Integrating Feature Attention and Temporal Modeling for Collaborative Financial Risk Assessment", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "This paper addresses the challenges of data privacy and collaborative\nmodeling in cross-institution financial risk analysis. It proposes a risk\nassessment framework based on federated learning. Without sharing raw data, the\nmethod enables joint modeling and risk identification across multiple\ninstitutions. This is achieved by incorporating a feature attention mechanism\nand temporal modeling structure. Specifically, the model adopts a distributed\noptimization strategy. Each financial institution trains a local sub-model. The\nmodel parameters are protected using differential privacy and noise injection\nbefore being uploaded. A central server then aggregates these parameters to\ngenerate a global model. This global model is used for systemic risk\nidentification. To validate the effectiveness of the proposed method, multiple\nexperiments are conducted. These evaluate communication efficiency, model\naccuracy, systemic risk detection, and cross-market generalization. The results\nshow that the proposed model outperforms both traditional centralized methods\nand existing federated learning variants across all evaluation metrics. It\ndemonstrates strong modeling capabilities and practical value in sensitive\nfinancial environments. The method enhances the scope and efficiency of risk\nidentification while preserving data sovereignty. It offers a secure and\nefficient solution for intelligent financial risk analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8054\u90a6\u5b66\u4e60\u7684\u91d1\u878d\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u7279\u5f81\u6ce8\u610f\u529b\u548c\u65f6\u5e8f\u5efa\u6a21\u5b9e\u73b0\u8de8\u673a\u6784\u8054\u5408\u5efa\u6a21\uff0c\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u3002", "motivation": "\u89e3\u51b3\u8de8\u673a\u6784\u91d1\u878d\u98ce\u9669\u5206\u6790\u4e2d\u7684\u6570\u636e\u9690\u79c1\u548c\u534f\u4f5c\u5efa\u6a21\u6311\u6218\u3002", "method": "\u91c7\u7528\u8054\u90a6\u5b66\u4e60\uff0c\u7ed3\u5408\u7279\u5f81\u6ce8\u610f\u529b\u673a\u5236\u548c\u65f6\u5e8f\u5efa\u6a21\uff0c\u4f7f\u7528\u5dee\u5206\u9690\u79c1\u548c\u566a\u58f0\u6ce8\u5165\u4fdd\u62a4\u53c2\u6570\uff0c\u5206\u5e03\u5f0f\u4f18\u5316\u7b56\u7565\u8bad\u7ec3\u672c\u5730\u5b50\u6a21\u578b\uff0c\u4e2d\u592e\u670d\u52a1\u5668\u805a\u5408\u751f\u6210\u5168\u5c40\u6a21\u578b\u3002", "result": "\u5728\u901a\u4fe1\u6548\u7387\u3001\u6a21\u578b\u51c6\u786e\u6027\u3001\u7cfb\u7edf\u6027\u98ce\u9669\u68c0\u6d4b\u548c\u8de8\u5e02\u573a\u6cdb\u5316\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u548c\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u53d8\u4f53\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u654f\u611f\u91d1\u878d\u73af\u5883\u4e2d\u5177\u6709\u5f3a\u5927\u7684\u5efa\u6a21\u80fd\u529b\u548c\u5b9e\u7528\u4ef7\u503c\uff0c\u540c\u65f6\u4fdd\u62a4\u6570\u636e\u4e3b\u6743\uff0c\u4e3a\u667a\u80fd\u91d1\u878d\u98ce\u9669\u5206\u6790\u63d0\u4f9b\u4e86\u5b89\u5168\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09401", "pdf": "https://arxiv.org/pdf/2508.09401", "abs": "https://arxiv.org/abs/2508.09401", "authors": ["Yun Zi", "Ming Gong", "Zhihao Xue", "Yujun Zou", "Nia Qi", "Yingnan Deng"], "title": "Graph Neural Network and Transformer Integration for Unsupervised System Anomaly Discovery", "categories": ["cs.LG"], "comment": null, "summary": "This study proposes an unsupervised anomaly detection method for distributed\nbackend service systems, addressing practical challenges such as complex\nstructural dependencies, diverse behavioral evolution, and the absence of\nlabeled data. The method constructs a dynamic graph based on service invocation\nrelationships and applies graph convolution to extract high-order structural\nrepresentations from multi-hop topologies. A Transformer is used to model the\ntemporal behavior of each node, capturing long-term dependencies and local\nfluctuations. During the feature fusion stage, a learnable joint embedding\nmechanism integrates structural and behavioral representations into a unified\nanomaly vector. A nonlinear mapping is then applied to compute anomaly scores,\nenabling an end-to-end detection process without supervision. Experiments on\nreal-world cloud monitoring data include sensitivity analyses across different\ngraph depths, sequence lengths, and data perturbations. Results show that the\nproposed method outperforms existing models on several key metrics,\ndemonstrating stronger expressiveness and stability in capturing anomaly\npropagation paths and modeling dynamic behavior sequences, with high potential\nfor practical deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u5e03\u5f0f\u540e\u7aef\u670d\u52a1\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u590d\u6742\u7ed3\u6784\u4f9d\u8d56\u3001\u884c\u4e3a\u6f14\u5316\u548c\u65e0\u6807\u7b7e\u6570\u636e\u7b49\u6311\u6218\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u540e\u7aef\u670d\u52a1\u7cfb\u7edf\u4e2d\u5f02\u5e38\u68c0\u6d4b\u7684\u5b9e\u9645\u6311\u6218\uff0c\u5982\u590d\u6742\u7684\u7ed3\u6784\u4f9d\u8d56\u3001\u591a\u6837\u5316\u7684\u884c\u4e3a\u6f14\u5316\u548c\u7f3a\u4e4f\u6807\u7b7e\u6570\u636e\u3002", "method": "\u6784\u5efa\u52a8\u6001\u56fe\u8868\u793a\u670d\u52a1\u8c03\u7528\u5173\u7cfb\uff0c\u4f7f\u7528\u56fe\u5377\u79ef\u63d0\u53d6\u9ad8\u9636\u7ed3\u6784\u7279\u5f81\uff0cTransformer\u5efa\u6a21\u8282\u70b9\u65f6\u95f4\u884c\u4e3a\uff0c\u878d\u5408\u7ed3\u6784\u548c\u884c\u4e3a\u7279\u5f81\u4e3a\u7edf\u4e00\u5f02\u5e38\u5411\u91cf\uff0c\u975e\u7ebf\u6027\u6620\u5c04\u8ba1\u7b97\u5f02\u5e38\u5206\u6570\u3002", "result": "\u5728\u771f\u5b9e\u4e91\u76d1\u63a7\u6570\u636e\u4e0a\u5b9e\u9a8c\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u80fd\u66f4\u597d\u5730\u6355\u6349\u5f02\u5e38\u4f20\u64ad\u8def\u5f84\u548c\u52a8\u6001\u884c\u4e3a\u5e8f\u5217\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u5f3a\u8868\u8fbe\u529b\u548c\u7a33\u5b9a\u6027\uff0c\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2508.09418", "pdf": "https://arxiv.org/pdf/2508.09418", "abs": "https://arxiv.org/abs/2508.09418", "authors": ["Usman Anjum", "Chris Stockman", "Cat Luong", "Justin Zhan"], "title": "Domain-Generalization to Improve Learning in Meta-Learning Algorithms", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper introduces Domain Generalization Sharpness-Aware Minimization\nModel-Agnostic Meta-Learning (DGS-MAML), a novel meta-learning algorithm\ndesigned to generalize across tasks with limited training data. DGS-MAML\ncombines gradient matching with sharpness-aware minimization in a bi-level\noptimization framework to enhance model adaptability and robustness. We support\nour method with theoretical analysis using PAC-Bayes and convergence\nguarantees. Experimental results on benchmark datasets show that DGS-MAML\noutperforms existing approaches in terms of accuracy and generalization. The\nproposed method is particularly useful for scenarios requiring few-shot\nlearning and quick adaptation, and the source code is publicly available at\nGitHub.", "AI": {"tldr": "DGS-MAML\u662f\u4e00\u79cd\u65b0\u7684\u5143\u5b66\u4e60\u7b97\u6cd5\uff0c\u7ed3\u5408\u68af\u5ea6\u5339\u914d\u548c\u9510\u5ea6\u611f\u77e5\u6700\u5c0f\u5316\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u6846\u67b6\u63d0\u5347\u6a21\u578b\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3\u5728\u6709\u9650\u8bad\u7ec3\u6570\u636e\u4e0b\u8de8\u4efb\u52a1\u6cdb\u5316\u7684\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u5c11\u6837\u672c\u5b66\u4e60\u548c\u5feb\u901f\u9002\u5e94\u573a\u666f\u3002", "method": "\u7ed3\u5408\u68af\u5ea6\u5339\u914d\u4e0e\u9510\u5ea6\u611f\u77e5\u6700\u5c0f\u5316\uff0c\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u6846\u67b6\uff0c\u5e76\u8f85\u4ee5PAC-Bayes\u7406\u8bba\u548c\u6536\u655b\u6027\u5206\u6790\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u548c\u6cdb\u5316\u80fd\u529b\u66f4\u4f18\u3002", "conclusion": "DGS-MAML\u5728\u5c11\u6837\u672c\u5b66\u4e60\u548c\u5feb\u901f\u9002\u5e94\u573a\u666f\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.09427", "pdf": "https://arxiv.org/pdf/2508.09427", "abs": "https://arxiv.org/abs/2508.09427", "authors": ["Xiaoyu Li", "Guangyu Tang", "Jiaojiao Jiang"], "title": "Implicit Hypergraph Neural Networks: A Stable Framework for Higher-Order Relational Learning with Provable Guarantees", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Many real-world interactions are group-based rather than pairwise such as\npapers with multiple co-authors and users jointly engaging with items.\nHypergraph neural networks have shown great promise at modeling higher-order\nrelations, but their reliance on a fixed number of explicit message-passing\nlayers limits long-range dependency capture and can destabilize training as\ndepth grows. In this work, we introduce Implicit Hypergraph Neural Networks\n(IHGNN), which bring the implicit equilibrium formulation to hypergraphs:\ninstead of stacking layers, IHGNN computes representations as the solution to a\nnonlinear fixed-point equation, enabling stable and efficient global\npropagation across hyperedges without deep architectures. We develop a\nwell-posed training scheme with provable convergence, analyze the oversmoothing\nconditions and expressivity of the model, and derive a transductive\ngeneralization bound on hypergraphs. We further present an implicit-gradient\ntraining procedure coupled with a projection-based stabilization strategy.\nExtensive experiments on citation benchmarks show that IHGNN consistently\noutperforms strong traditional graph/hypergraph neural network baselines in\nboth accuracy and robustness. Empirically, IHGNN is resilient to random\ninitialization and hyperparameter variation, highlighting its strong\ngeneralization and practical value for higher-order relational learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9690\u5f0f\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\uff08IHGNN\uff09\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u56fa\u5b9a\u70b9\u65b9\u7a0b\u89e3\u51b3\u8868\u793a\u95ee\u9898\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6df1\u5ea6\u9650\u5236\uff0c\u63d0\u5347\u4e86\u957f\u8ddd\u79bb\u4f9d\u8d56\u6355\u83b7\u80fd\u529b\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u7684\u8bb8\u591a\u4ea4\u4e92\u662f\u7fa4\u4f53\u6027\u7684\uff08\u5982\u591a\u4f5c\u8005\u8bba\u6587\u6216\u7528\u6237\u8054\u5408\u53c2\u4e0e\u9879\u76ee\uff09\uff0c\u4f20\u7edf\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\u4f9d\u8d56\u56fa\u5b9a\u5c42\u6570\u7684\u663e\u5f0f\u6d88\u606f\u4f20\u9012\uff0c\u9650\u5236\u4e86\u957f\u8ddd\u79bb\u4f9d\u8d56\u6355\u83b7\u4e14\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3002", "method": "\u5f15\u5165IHGNN\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u56fa\u5b9a\u70b9\u65b9\u7a0b\u8ba1\u7b97\u8868\u793a\uff0c\u907f\u514d\u4e86\u6df1\u5ea6\u67b6\u6784\uff1b\u5f00\u53d1\u4e86\u6536\u655b\u6027\u53ef\u8bc1\u660e\u7684\u8bad\u7ec3\u65b9\u6848\uff0c\u5206\u6790\u4e86\u6a21\u578b\u7684\u8fc7\u5e73\u6ed1\u6761\u4ef6\u548c\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u63a8\u5bfc\u4e86\u8d85\u56fe\u4e0a\u7684\u8f6c\u5bfc\u6cdb\u5316\u754c\u3002", "result": "\u5728\u5f15\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cIHGNN\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u56fe/\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\u57fa\u7ebf\uff0c\u4e14\u5bf9\u968f\u673a\u521d\u59cb\u5316\u548c\u8d85\u53c2\u6570\u53d8\u5316\u5177\u6709\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "IHGNN\u4e3a\u9ad8\u9636\u5173\u7cfb\u5b66\u4e60\u63d0\u4f9b\u4e86\u7a33\u5b9a\u3001\u9ad8\u6548\u4e14\u6cdb\u5316\u80fd\u529b\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.09447", "pdf": "https://arxiv.org/pdf/2508.09447", "abs": "https://arxiv.org/abs/2508.09447", "authors": ["Siddharth Srikanth", "John Krumm", "Jonathan Qin"], "title": "NEXICA: Discovering Road Traffic Causality (Extended arXiv Version)", "categories": ["cs.LG"], "comment": "Extended version of short paper in 32nd ACM SIGSPATIAL International\n  Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL\n  2024)", "summary": "Road traffic congestion is a persistent problem. Focusing resources on the\ncauses of congestion is a potentially efficient strategy for reducing\nslowdowns. We present NEXICA, an algorithm to discover which parts of the\nhighway system tend to cause slowdowns on other parts of the highway. We use\ntime series of road speeds as inputs to our causal discovery algorithm. Finding\nother algorithms inadequate, we develop a new approach that is novel in three\nways. First, it concentrates on just the presence or absence of events in the\ntime series, where an event indicates the temporal beginning of a traffic\nslowdown. Second, we develop a probabilistic model using maximum likelihood\nestimation to compute the probabilities of spontaneous and caused slowdowns\nbetween two locations on the highway. Third, we train a binary classifier to\nidentify pairs of cause/effect locations trained on pairs of road locations\nwhere we are reasonably certain a priori of their causal connections, both\npositive and negative. We test our approach on six months of road speed data\nfrom 195 different highway speed sensors in the Los Angeles area, showing that\nour approach is superior to state-of-the-art baselines in both accuracy and\ncomputation speed.", "AI": {"tldr": "NEXICA\u662f\u4e00\u79cd\u65b0\u7b97\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u9ad8\u901f\u516c\u8def\u7cfb\u7edf\u4e2d\u5bfc\u81f4\u5176\u4ed6\u90e8\u5206\u62e5\u5835\u7684\u533a\u57df\uff0c\u901a\u8fc7\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u548c\u6982\u7387\u6a21\u578b\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u4ea4\u901a\u62e5\u5835\u95ee\u9898\uff0c\u901a\u8fc7\u8bc6\u522b\u62e5\u5835\u6e90\u5934\u66f4\u9ad8\u6548\u5730\u5206\u914d\u8d44\u6e90\u3002", "method": "\u5229\u7528\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5f00\u53d1\u65b0\u7b97\u6cd5\uff0c\u5305\u62ec\u4e8b\u4ef6\u68c0\u6d4b\u3001\u6982\u7387\u6a21\u578b\u548c\u4e8c\u5143\u5206\u7c7b\u5668\u3002", "result": "\u5728\u6d1b\u6749\u77f6\u5730\u533a195\u4e2a\u4f20\u611f\u5668\u6570\u636e\u4e0a\u6d4b\u8bd5\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "NEXICA\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u901f\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u53ef\u7528\u4e8e\u5b9e\u9645\u4ea4\u901a\u7ba1\u7406\u3002"}}
{"id": "2508.09451", "pdf": "https://arxiv.org/pdf/2508.09451", "abs": "https://arxiv.org/abs/2508.09451", "authors": ["Ziyu Liu", "Azadeh Alavi", "Minyi Li", "Xiang Zhang"], "title": "A Unified Contrastive-Generative Framework for Time Series Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Self-supervised learning (SSL) for multivariate time series mainly includes\ntwo paradigms: contrastive methods that excel at instance discrimination and\ngenerative approaches that model data distributions. While effective\nindividually, their complementary potential remains unexplored. We propose a\nContrastive Generative Time series framework (CoGenT), the first framework to\nunify these paradigms through joint contrastive-generative optimization. CoGenT\naddresses fundamental limitations of both approaches: it overcomes contrastive\nlearning's sensitivity to high intra-class similarity in temporal data while\nreducing generative methods' dependence on large datasets. We evaluate CoGenT\non six diverse time series datasets. The results show consistent improvements,\nwith up to 59.2% and 14.27% F1 gains over standalone SimCLR and MAE,\nrespectively. Our analysis reveals that the hybrid objective preserves\ndiscriminative power while acquiring generative robustness. These findings\nestablish a foundation for hybrid SSL in temporal domains. We will release the\ncode shortly.", "AI": {"tldr": "CoGenT\u6846\u67b6\u9996\u6b21\u5c06\u5bf9\u6bd4\u5b66\u4e60\u548c\u751f\u6210\u65b9\u6cd5\u7ed3\u5408\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u89e3\u51b3\u5404\u81ea\u5c40\u9650\u6027\uff0c\u5728\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u63a2\u7d22\u5bf9\u6bd4\u5b66\u4e60\u548c\u751f\u6210\u65b9\u6cd5\u5728\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u7684\u4e92\u8865\u6f5c\u529b\uff0c\u89e3\u51b3\u5404\u81ea\u7684\u9ad8\u7c7b\u5185\u76f8\u4f3c\u6027\u548c\u5927\u6570\u636e\u4f9d\u8d56\u95ee\u9898\u3002", "method": "\u63d0\u51faContrastive Generative Time series\u6846\u67b6\uff08CoGenT\uff09\uff0c\u901a\u8fc7\u8054\u5408\u5bf9\u6bd4-\u751f\u6210\u4f18\u5316\u7edf\u4e00\u4e24\u79cd\u8303\u5f0f\u3002", "result": "\u5728\u516d\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u5355\u72ec\u65b9\u6cd5\uff0cF1\u5206\u6570\u63d0\u5347\u6700\u9ad8\u8fbe59.2%\u548c14.27%\u3002", "conclusion": "CoGenT\u4e3a\u65f6\u95f4\u5e8f\u5217\u9886\u57df\u7684\u6df7\u5408\u81ea\u76d1\u7763\u5b66\u4e60\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u517c\u5177\u5224\u522b\u529b\u548c\u751f\u6210\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.09462", "pdf": "https://arxiv.org/pdf/2508.09462", "abs": "https://arxiv.org/abs/2508.09462", "authors": ["Guangqiang Li", "M. Amine Atoui", "Xiangshun Li"], "title": "Open-Set Fault Diagnosis in Multimode Processes via Fine-Grained Deep Feature Representation", "categories": ["cs.LG"], "comment": "34 pages, 12 figures", "summary": "A reliable fault diagnosis system should not only accurately classify known\nhealth states but also effectively identify unknown faults. In multimode\nprocesses, samples belonging to the same health state often show multiple\ncluster distributions, making it difficult to construct compact and accurate\ndecision boundaries for that state. To address this challenge, a novel open-set\nfault diagnosis model named fine-grained clustering and rejection network\n(FGCRN) is proposed. It combines multiscale depthwise convolution,\nbidirectional gated recurrent unit and temporal attention mechanism to capture\ndiscriminative features. A distance-based loss function is designed to enhance\nthe intra-class compactness. Fine-grained feature representations are\nconstructed through unsupervised learning to uncover the intrinsic structures\nof each health state. Extreme value theory is employed to model the distance\nbetween sample features and their corresponding fine-grained representations,\nenabling effective identification of unknown faults. Extensive experiments\ndemonstrate the superior performance of the proposed method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFGCRN\u7684\u65b0\u578b\u5f00\u653e\u96c6\u6545\u969c\u8bca\u65ad\u6a21\u578b\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u6df1\u5ea6\u5377\u79ef\u3001\u53cc\u5411\u95e8\u63a7\u5faa\u73af\u5355\u5143\u548c\u65f6\u95f4\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u7279\u5f81\uff0c\u7ed3\u5408\u65e0\u76d1\u7763\u5b66\u4e60\u6784\u5efa\u7ec6\u7c92\u5ea6\u7279\u5f81\u8868\u793a\uff0c\u6709\u6548\u8bc6\u522b\u672a\u77e5\u6545\u969c\u3002", "motivation": "\u5728\u591a\u91cd\u6a21\u5f0f\u8fc7\u7a0b\u4e2d\uff0c\u540c\u4e00\u5065\u5eb7\u72b6\u6001\u7684\u6837\u672c\u5e38\u5448\u73b0\u591a\u7c07\u5206\u5e03\uff0c\u96be\u4ee5\u6784\u5efa\u7d27\u51d1\u51c6\u786e\u7684\u51b3\u7b56\u8fb9\u754c\uff0c\u9700\u5f00\u53d1\u80fd\u8bc6\u522b\u672a\u77e5\u6545\u969c\u7684\u8bca\u65ad\u7cfb\u7edf\u3002", "method": "\u7ed3\u5408\u591a\u5c3a\u5ea6\u6df1\u5ea6\u5377\u79ef\u3001\u53cc\u5411\u95e8\u63a7\u5faa\u73af\u5355\u5143\u548c\u65f6\u95f4\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u7279\u5f81\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u8ddd\u79bb\u7684\u635f\u5931\u51fd\u6570\u589e\u5f3a\u7c7b\u5185\u7d27\u51d1\u6027\uff0c\u5229\u7528\u65e0\u76d1\u7763\u5b66\u4e60\u6784\u5efa\u7ec6\u7c92\u5ea6\u7279\u5f81\u8868\u793a\uff0c\u5e76\u91c7\u7528\u6781\u503c\u7406\u8bba\u5efa\u6a21\u6837\u672c\u7279\u5f81\u4e0e\u7ec6\u7c92\u5ea6\u8868\u793a\u7684\u8ddd\u79bb\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u6027\u80fd\u4f18\u8d8a\u3002", "conclusion": "FGCRN\u6a21\u578b\u80fd\u6709\u6548\u8bc6\u522b\u672a\u77e5\u6545\u969c\uff0c\u4e3a\u5f00\u653e\u96c6\u6545\u969c\u8bca\u65ad\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09467", "pdf": "https://arxiv.org/pdf/2508.09467", "abs": "https://arxiv.org/abs/2508.09467", "authors": ["Zijun Sun", "Yanning Shen"], "title": "Learn to Explore: Meta NAS via Bayesian Optimization Guided Graph Generation", "categories": ["cs.LG"], "comment": null, "summary": "Neural Architecture Search (NAS) automates the design of high-performing\nneural networks but typically targets a single predefined task, thereby\nrestricting its real-world applicability. To address this, Meta Neural\nArchitecture Search (Meta-NAS) has emerged as a promising paradigm that\nleverages prior knowledge across tasks to enable rapid adaptation to new ones.\nNevertheless, existing Meta-NAS methods often struggle with poor\ngeneralization, limited search spaces, or high computational costs. In this\npaper, we propose a novel Meta-NAS framework, GraB-NAS. Specifically, GraB-NAS\nfirst models neural architectures as graphs, and then a hybrid search strategy\nis developed to find and generate new graphs that lead to promising neural\narchitectures. The search strategy combines global architecture search via\nBayesian Optimization in the search space with local exploration for novel\nneural networks via gradient ascent in the latent space. Such a hybrid search\nstrategy allows GraB-NAS to discover task-aware architectures with strong\nperformance, even beyond the predefined search space. Extensive experiments\ndemonstrate that GraB-NAS outperforms state-of-the-art Meta-NAS baselines,\nachieving better generalization and search effectiveness.", "AI": {"tldr": "GraB-NAS\u662f\u4e00\u79cd\u65b0\u578bMeta-NAS\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u5efa\u6a21\u548c\u6df7\u5408\u641c\u7d22\u7b56\u7565\uff08\u5168\u5c40\u8d1d\u53f6\u65af\u4f18\u5316\u4e0e\u5c40\u90e8\u68af\u5ea6\u4e0a\u5347\uff09\u63d0\u5347\u4efb\u52a1\u611f\u77e5\u67b6\u6784\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709Meta-NAS\u65b9\u6cd5\u5b58\u5728\u6cdb\u5316\u6027\u5dee\u3001\u641c\u7d22\u7a7a\u95f4\u6709\u9650\u6216\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "GraB-NAS\u5c06\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5efa\u6a21\u4e3a\u56fe\uff0c\u91c7\u7528\u6df7\u5408\u641c\u7d22\u7b56\u7565\uff08\u5168\u5c40\u8d1d\u53f6\u65af\u4f18\u5316+\u5c40\u90e8\u68af\u5ea6\u4e0a\u5347\uff09\u751f\u6210\u65b0\u67b6\u6784\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGraB-NAS\u5728\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u4f18\u4e8e\u73b0\u6709Meta-NAS\u65b9\u6cd5\uff0c\u5e76\u80fd\u8d85\u8d8a\u9884\u5b9a\u4e49\u641c\u7d22\u7a7a\u95f4\u3002", "conclusion": "GraB-NAS\u901a\u8fc7\u6df7\u5408\u641c\u7d22\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86Meta-NAS\u7684\u6548\u80fd\uff0c\u4e3a\u4efb\u52a1\u611f\u77e5\u67b6\u6784\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.09468", "pdf": "https://arxiv.org/pdf/2508.09468", "abs": "https://arxiv.org/abs/2508.09468", "authors": ["Muhammad Sakib Khan Inan", "Kewen Liao"], "title": "DeepFeatIoT: Unifying Deep Learned, Randomized, and LLM Features for Enhanced IoT Time Series Sensor Data Classification in Smart Industries", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted for publication at IJCAI 2025", "summary": "Internet of Things (IoT) sensors are ubiquitous technologies deployed across\nsmart cities, industrial sites, and healthcare systems. They continuously\ngenerate time series data that enable advanced analytics and automation in\nindustries. However, challenges such as the loss or ambiguity of sensor\nmetadata, heterogeneity in data sources, varying sampling frequencies,\ninconsistent units of measurement, and irregular timestamps make raw IoT time\nseries data difficult to interpret, undermining the effectiveness of smart\nsystems. To address these challenges, we propose a novel deep learning model,\nDeepFeatIoT, which integrates learned local and global features with\nnon-learned randomized convolutional kernel-based features and features from\nlarge language models (LLMs). This straightforward yet unique fusion of diverse\nlearned and non-learned features significantly enhances IoT time series sensor\ndata classification, even in scenarios with limited labeled data. Our model's\neffectiveness is demonstrated through its consistent and generalized\nperformance across multiple real-world IoT sensor datasets from diverse\ncritical application domains, outperforming state-of-the-art benchmark models.\nThese results highlight DeepFeatIoT's potential to drive significant\nadvancements in IoT analytics and support the development of next-generation\nsmart systems.", "AI": {"tldr": "DeepFeatIoT\u662f\u4e00\u79cd\u65b0\u578b\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u5c40\u90e8\u548c\u5168\u5c40\u7279\u5f81\u3001\u968f\u673a\u5377\u79ef\u6838\u7279\u5f81\u53ca\u5927\u8bed\u8a00\u6a21\u578b\u7279\u5f81\uff0c\u663e\u8457\u63d0\u5347\u7269\u8054\u7f51\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u5206\u7c7b\u6548\u679c\u3002", "motivation": "\u7269\u8054\u7f51\u4f20\u611f\u5668\u6570\u636e\u5b58\u5728\u5143\u6570\u636e\u4e22\u5931\u3001\u6570\u636e\u6e90\u5f02\u6784\u3001\u91c7\u6837\u9891\u7387\u4e0d\u4e00\u81f4\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u539f\u59cb\u6570\u636e\u96be\u4ee5\u89e3\u6790\uff0c\u5f71\u54cd\u667a\u80fd\u7cfb\u7edf\u6548\u679c\u3002", "method": "\u63d0\u51faDeepFeatIoT\u6a21\u578b\uff0c\u878d\u5408\u5b66\u4e60\u4e0e\u975e\u5b66\u4e60\u7279\u5f81\uff0c\u5305\u62ec\u5c40\u90e8/\u5168\u5c40\u7279\u5f81\u3001\u968f\u673a\u5377\u79ef\u6838\u7279\u5f81\u53ca\u5927\u8bed\u8a00\u6a21\u578b\u7279\u5f81\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u7269\u8054\u7f51\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u6a21\u578b\uff0c\u5c24\u5176\u5728\u6807\u8bb0\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "DeepFeatIoT\u6709\u671b\u63a8\u52a8\u7269\u8054\u7f51\u5206\u6790\u8fdb\u6b65\uff0c\u652f\u6301\u4e0b\u4e00\u4ee3\u667a\u80fd\u7cfb\u7edf\u53d1\u5c55\u3002"}}
{"id": "2508.09471", "pdf": "https://arxiv.org/pdf/2508.09471", "abs": "https://arxiv.org/abs/2508.09471", "authors": ["Omar Bazarbachi", "Zijun Sun", "Yanning Shen"], "title": "EGGS-PTP: An Expander-Graph Guided Structured Post-training Pruning Method for Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "As Large Language Models (LLMs) become more widely adopted and scale up in\nsize, the computational and memory challenges involved in deploying these\nmassive foundation models have grown increasingly severe. This underscores the\nurgent need to develop more efficient model variants. Faced with this\nchallenge, the present work introduces EGGS-PTP: an Expander-Graph Guided\nStructured Post-training Pruning method. The proposed approach leverages graph\ntheory to guide the design of N:M structured pruning, effectively reducing\nmodel size and computational demands. By incorporating concepts from expander\ngraphs, EGGS-PTP ensures information flow within the pruned network, preserving\nessential model functionality. Extensive numerical experiments demonstrate that\nEGGS-PTP not only achieves significant acceleration and memory savings due to\nstructured sparsity but also outperforms existing structured pruning techniques\nin terms of accuracy across various LLMs.", "AI": {"tldr": "EGGS-PTP\u662f\u4e00\u79cd\u57fa\u4e8e\u6269\u5c55\u56fe\u7406\u8bba\u7684N:M\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\uff0c\u6709\u6548\u51cf\u5c11LLMs\u7684\u6a21\u578b\u5927\u5c0f\u548c\u8ba1\u7b97\u9700\u6c42\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u89c4\u6a21\u6269\u5927\uff0c\u90e8\u7f72\u8fd9\u4e9b\u6a21\u578b\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u6311\u6218\u65e5\u76ca\u4e25\u91cd\uff0c\u4e9f\u9700\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u6a21\u578b\u53d8\u4f53\u3002", "method": "\u5229\u7528\u6269\u5c55\u56fe\u7406\u8bba\u6307\u5bfcN:M\u7ed3\u6784\u5316\u526a\u679d\u8bbe\u8ba1\uff0c\u786e\u4fdd\u526a\u679d\u7f51\u7edc\u4e2d\u4fe1\u606f\u6d41\u52a8\uff0c\u4fdd\u7559\u6a21\u578b\u529f\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEGGS-PTP\u4e0d\u4ec5\u663e\u8457\u52a0\u901f\u5e76\u8282\u7701\u5185\u5b58\uff0c\u8fd8\u5728\u591a\u79cdLLMs\u4e0a\u4f18\u4e8e\u73b0\u6709\u7ed3\u6784\u5316\u526a\u679d\u6280\u672f\u7684\u51c6\u786e\u6027\u3002", "conclusion": "EGGS-PTP\u4e3aLLMs\u7684\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u517c\u5177\u6027\u80fd\u548c\u51c6\u786e\u6027\u4f18\u52bf\u3002"}}
{"id": "2508.09473", "pdf": "https://arxiv.org/pdf/2508.09473", "abs": "https://arxiv.org/abs/2508.09473", "authors": ["Birong Pan", "Mayi Xu", "Qiankun Pi", "Jianhao Chen", "Yuanyuan Zhu", "Ming Zhong", "Tieyun Qian"], "title": "NeuronTune: Fine-Grained Neuron Modulation for Balanced Safety-Utility Alignment in LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Ensuring robust safety alignment while preserving utility is critical for the\nreliable deployment of Large Language Models (LLMs). However, current\ntechniques fundamentally suffer from intertwined deficiencies: insufficient\nrobustness against malicious attacks, frequent refusal of benign queries,\ndegradation in generated text quality and general task performance--the former\ntwo reflecting deficits in robust safety and the latter constituting utility\nimpairment. We trace these limitations to the coarse-grained layer-wise\ninterventions in existing methods. To resolve this, we propose NeuronTune, a\nfine-grained framework that dynamically modulates sparse neurons to achieve\nsimultaneous safety-utility optimization. Our approach first identifies\nsafety-critical and utility-preserving neurons across all layers via\nattribution, then employs meta-learning to adaptively amplify safety-neuron\nactivations and suppress utility-neuron activations. Crucially, NeuronTune\nenables tunable adjustment of intervention scope via neuron-count thresholds,\nsupporting flexible adaptation to security-critical or utility-priority\nscenarios. Extensive experimental results demonstrate that our method\nsignificantly outperforms existing state-of-the-art technologies, achieving\nsuperior model safety while maintaining excellent utility.", "AI": {"tldr": "NeuronTune\u901a\u8fc7\u7ec6\u7c92\u5ea6\u795e\u7ecf\u5143\u52a8\u6001\u8c03\u5236\uff0c\u540c\u65f6\u4f18\u5316LLM\u7684\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u5f53\u524dLLM\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u5b58\u5728\u9c81\u68d2\u6027\u4e0d\u8db3\u3001\u9891\u7e41\u62d2\u7edd\u826f\u6027\u67e5\u8be2\u53ca\u5b9e\u7528\u6027\u4e0b\u964d\u7b49\u95ee\u9898\uff0c\u4e9f\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51faNeuronTune\u6846\u67b6\uff0c\u901a\u8fc7\u5f52\u56e0\u8bc6\u522b\u5b89\u5168\u4e0e\u5b9e\u7528\u795e\u7ecf\u5143\uff0c\u5e76\u5229\u7528\u5143\u5b66\u4e60\u52a8\u6001\u8c03\u6574\u5176\u6fc0\u6d3b\u5f3a\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cNeuronTune\u5728\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "NeuronTune\u4e3aLLM\u7684\u5b89\u5168\u4e0e\u5b9e\u7528\u5e73\u8861\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09489", "pdf": "https://arxiv.org/pdf/2508.09489", "abs": "https://arxiv.org/abs/2508.09489", "authors": ["Hao Yu", "Xin Yang", "Boyang Fan", "Xuemei Cao", "Hanlin Gu", "Lixin Fan", "Qiang Yang"], "title": "Large-Small Model Collaborative Framework for Federated Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Continual learning (CL) for Foundation Models (FMs) is an essential yet\nunderexplored challenge, especially in Federated Continual Learning (FCL),\nwhere each client learns from a private, evolving task stream under strict data\nand communication constraints. Despite their powerful generalization abilities,\nFMs often exhibit suboptimal performance on local downstream tasks, as they are\nunable to utilize private local data. Furthermore, enabling FMs to learn new\ntasks without forgetting prior knowledge is inherently a challenging problem,\nprimarily due to their immense parameter count and high model complexity. In\ncontrast, small models can be trained locally under resource-constrained\nconditions and benefit from more mature CL techniques. To bridge the gap\nbetween small models and FMs, we propose the first collaborative framework in\nFCL, where lightweight local models act as a dynamic bridge, continually\nadapting to new tasks while enhancing the utility of the large model. Two novel\ncomponents are also included: Small Model Continual Fine-tuning is for\npreventing small models from temporal forgetting; One-by-One Distillation\nperforms personalized fusion of heterogeneous local knowledge on the server.\nExperimental results demonstrate its superior performance, even when clients\nutilize heterogeneous small models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u90a6\u6301\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u672c\u5730\u6a21\u578b\u52a8\u6001\u9002\u5e94\u65b0\u4efb\u52a1\u5e76\u63d0\u5347\u5927\u6a21\u578b\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u57fa\u7840\u6a21\u578b\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u6311\u6218\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u8054\u90a6\u6301\u7eed\u5b66\u4e60\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u65e0\u6cd5\u6709\u6548\u5229\u7528\u672c\u5730\u79c1\u6709\u6570\u636e\u4e14\u5bb9\u6613\u9057\u5fd8\u5148\u524d\u77e5\u8bc6\uff0c\u800c\u5c0f\u6a21\u578b\u5219\u66f4\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u3002", "method": "\u63d0\u51fa\u534f\u4f5c\u6846\u67b6\uff0c\u5305\u62ec\u5c0f\u6a21\u578b\u6301\u7eed\u5fae\u8c03\u9632\u6b62\u9057\u5fd8\uff0c\u4ee5\u53ca\u4e00\u5bf9\u4e00\u84b8\u998f\u5b9e\u73b0\u5f02\u6784\u672c\u5730\u77e5\u8bc6\u7684\u4e2a\u6027\u5316\u878d\u5408\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6846\u67b6\u6027\u80fd\u4f18\u8d8a\uff0c\u5373\u4f7f\u5ba2\u6237\u7aef\u4f7f\u7528\u5f02\u6784\u5c0f\u6a21\u578b\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u57fa\u7840\u6a21\u578b\u5728\u8054\u90a6\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2508.09500", "pdf": "https://arxiv.org/pdf/2508.09500", "abs": "https://arxiv.org/abs/2508.09500", "authors": ["Zijun Jiang", "Yangdi Lyu"], "title": "MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI", "categories": ["cs.LG", "cs.AR"], "comment": "9 pages, 6 figures, accepted by ICCAD'25", "summary": "Quantized Neural Networks (QNN) with extremely low-bitwidth data have proven\npromising in efficient storage and computation on edge devices. To further\nreduce the accuracy drop while increasing speedup, layer-wise mixed-precision\nquantization (MPQ) becomes a popular solution. However, existing algorithms for\nexploring MPQ schemes are limited in flexibility and efficiency. Comprehending\nthe complex impacts of different MPQ schemes on post-training quantization and\nquantization-aware training results is a challenge for conventional methods.\nFurthermore, an end-to-end framework for the optimization and deployment of MPQ\nmodels is missing in existing work.\n  In this paper, we propose the MiCo framework, a holistic MPQ exploration and\ndeployment framework for edge AI applications. The framework adopts a novel\noptimization algorithm to search for optimal quantization schemes with the\nhighest accuracies while meeting latency constraints. Hardware-aware latency\nmodels are built for different hardware targets to enable fast explorations.\nAfter the exploration, the framework enables direct deployment from PyTorch MPQ\nmodels to bare-metal C codes, leading to end-to-end speedup with minimal\naccuracy drops.", "AI": {"tldr": "MiCo\u6846\u67b6\u662f\u4e00\u4e2a\u7528\u4e8e\u8fb9\u7f18AI\u5e94\u7528\u7684\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\uff08MPQ\uff09\u63a2\u7d22\u548c\u90e8\u7f72\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u4f18\u5316\u7b97\u6cd5\u641c\u7d22\u6700\u4f73\u91cf\u5316\u65b9\u6848\uff0c\u540c\u65f6\u6ee1\u8db3\u5ef6\u8fdf\u7ea6\u675f\u3002", "motivation": "\u73b0\u6709MPQ\u65b9\u6848\u63a2\u7d22\u7b97\u6cd5\u5728\u7075\u6d3b\u6027\u548c\u6548\u7387\u4e0a\u53d7\u9650\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u540e\u8bad\u7ec3\u91cf\u5316\u548c\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u7ed3\u679c\u7684\u590d\u6742\u5f71\u54cd\u7684\u7406\u89e3\uff0c\u540c\u65f6\u7f3a\u5c11\u7aef\u5230\u7aef\u7684MPQ\u6a21\u578b\u4f18\u5316\u548c\u90e8\u7f72\u6846\u67b6\u3002", "method": "\u63d0\u51faMiCo\u6846\u67b6\uff0c\u91c7\u7528\u65b0\u578b\u4f18\u5316\u7b97\u6cd5\u641c\u7d22\u6700\u4f18\u91cf\u5316\u65b9\u6848\uff0c\u6784\u5efa\u786c\u4ef6\u611f\u77e5\u5ef6\u8fdf\u6a21\u578b\u4ee5\u5feb\u901f\u63a2\u7d22\uff0c\u5e76\u652f\u6301\u4ecePyTorch MPQ\u6a21\u578b\u76f4\u63a5\u90e8\u7f72\u5230\u88f8\u673aC\u4ee3\u7801\u3002", "result": "\u6846\u67b6\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u52a0\u901f\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u7cbe\u5ea6\u635f\u5931\u3002", "conclusion": "MiCo\u4e3a\u8fb9\u7f18AI\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u7075\u6d3b\u7684MPQ\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09504", "pdf": "https://arxiv.org/pdf/2508.09504", "abs": "https://arxiv.org/abs/2508.09504", "authors": ["Arun Vignesh Malarkkan", "Haoyue Bai", "Dongjie Wang", "Yanjie Fu"], "title": "Causal Graph Profiling via Structural Divergence for Robust Anomaly Detection in Cyber-Physical Systems", "categories": ["cs.LG", "cs.CR"], "comment": "7 Pages, 5 figures, Submission for ACM TKDD", "summary": "With the growing complexity of cyberattacks targeting critical\ninfrastructures such as water treatment networks, there is a pressing need for\nrobust anomaly detection strategies that account for both system\nvulnerabilities and evolving attack patterns. Traditional methods --\nstatistical, density-based, and graph-based models struggle with distribution\nshifts and class imbalance in multivariate time series, often leading to high\nfalse positive rates. To address these challenges, we propose CGAD, a Causal\nGraph-based Anomaly Detection framework designed for reliable cyberattack\ndetection in public infrastructure systems. CGAD follows a two-phase supervised\nframework -- causal profiling and anomaly scoring. First, it learns causal\ninvariant graph structures representing the system's behavior under \"Normal\"\nand \"Attack\" states using Dynamic Bayesian Networks. Second, it employs\nstructural divergence to detect anomalies via causal graph comparison by\nevaluating topological deviations in causal graphs over time. By leveraging\ncausal structures, CGAD achieves superior adaptability and accuracy in\nnon-stationary and imbalanced time series environments compared to conventional\nmachine learning approaches. By uncovering causal structures beneath volatile\nsensor data, our framework not only detects cyberattacks with markedly higher\nprecision but also redefines robustness in anomaly detection, proving\nresilience where traditional models falter under imbalance and drift. Our\nframework achieves substantial gains in F1 and ROC-AUC scores over\nbest-performing baselines across four industrial datasets, demonstrating robust\ndetection of delayed and structurally complex anomalies.", "AI": {"tldr": "CGAD\u662f\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u56fe\u7684\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u516c\u5171\u57fa\u7840\u8bbe\u65bd\u7cfb\u7edf\u4e2d\u7684\u7f51\u7edc\u653b\u51fb\u68c0\u6d4b\uff0c\u901a\u8fc7\u56e0\u679c\u5206\u6790\u548c\u56fe\u7ed3\u6784\u6bd4\u8f83\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u968f\u7740\u9488\u5bf9\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7684\u7f51\u7edc\u653b\u51fb\u65e5\u76ca\u590d\u6742\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u5206\u5e03\u504f\u79fb\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4e9f\u9700\u66f4\u9c81\u68d2\u7684\u5f02\u5e38\u68c0\u6d4b\u7b56\u7565\u3002", "method": "CGAD\u91c7\u7528\u4e24\u9636\u6bb5\u76d1\u7763\u6846\u67b6\uff1a1) \u4f7f\u7528\u52a8\u6001\u8d1d\u53f6\u65af\u7f51\u7edc\u5b66\u4e60\u56e0\u679c\u4e0d\u53d8\u56fe\u7ed3\u6784\uff1b2) \u901a\u8fc7\u56e0\u679c\u56fe\u6bd4\u8f83\u68c0\u6d4b\u5f02\u5e38\u3002", "result": "CGAD\u5728\u975e\u5e73\u7a33\u548c\u4e0d\u5e73\u8861\u65f6\u95f4\u5e8f\u5217\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\uff0cF1\u548cROC-AUC\u5206\u6570\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "CGAD\u901a\u8fc7\u63ed\u793a\u56e0\u679c\u7ed3\u6784\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u8fd8\u91cd\u65b0\u5b9a\u4e49\u4e86\u5f02\u5e38\u68c0\u6d4b\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.09510", "pdf": "https://arxiv.org/pdf/2508.09510", "abs": "https://arxiv.org/abs/2508.09510", "authors": ["Iing Muttakhiroh", "Thomas Fevens"], "title": "Enhancing Memory Recall in LLMs with Gauss-Tin: A Hybrid Instructional and Gaussian Replay Approach", "categories": ["cs.LG"], "comment": null, "summary": "Despite the significant advancements in Large Language Models (LLMs),\ncatastrophic forgetting remains a substantial challenge, where models lose\npreviously acquired knowledge upon learning new information. Continual learning\n(CL) strategies have emerged as a potential solution to this problem, with\nreplay-based techniques demonstrating superior performance in preserving\nlearned knowledge. In this context, we introduce Gauss-Tin, a novel approach\nthat integrates the replay strategy with a Gaussian mixture model to enhance\nthe quality of sample selection during training, supplemented by instructional\nguidance to facilitate the generation of past learning. This method aims to\nimprove LLMs' retention capabilities by strategically reinforcing important\npast learnings while accommodating new information. Our experimental results\nindicate a promising 6\\% improvement in retention metrics over traditional\nmethods, suggesting that Gauss-Tin is an effective strategy for mitigating\ncatastrophic forgetting in LLMs. This study underscores the potential of hybrid\nmodels in enhancing the robustness and adaptability of LLMs in dynamic learning\nenvironments.", "AI": {"tldr": "Gauss-Tin\u662f\u4e00\u79cd\u7ed3\u5408\u56de\u653e\u7b56\u7565\u4e0e\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u65e8\u5728\u901a\u8fc7\u4f18\u5316\u6837\u672c\u9009\u62e9\u548c\u6307\u5bfc\u751f\u6210\u6765\u51cf\u8f7b\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5176\u6027\u80fd\u6bd4\u4f20\u7edf\u65b9\u6cd5\u63d0\u53476%\u3002", "motivation": "\u707e\u96be\u6027\u9057\u5fd8\u662fLLMs\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\uff0c\u5373\u5728\u5b66\u4e60\u65b0\u77e5\u8bc6\u65f6\u9057\u5fd8\u65e7\u77e5\u8bc6\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u63a2\u7d22\u4e86\u6301\u7eed\u5b66\u4e60\u7b56\u7565\uff0c\u5c24\u5176\u662f\u56de\u653e\u6280\u672f\u3002", "method": "Gauss-Tin\u7ed3\u5408\u56de\u653e\u7b56\u7565\u4e0e\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff0c\u4f18\u5316\u6837\u672c\u9009\u62e9\uff0c\u5e76\u901a\u8fc7\u6307\u5bfc\u751f\u6210\u5f3a\u5316\u8fc7\u53bb\u7684\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGauss-Tin\u5728\u4fdd\u7559\u6307\u6807\u4e0a\u6bd4\u4f20\u7edf\u65b9\u6cd5\u63d0\u53476%\uff0c\u6709\u6548\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\u3002", "conclusion": "Gauss-Tin\u5c55\u793a\u4e86\u6df7\u5408\u6a21\u578b\u5728\u52a8\u6001\u5b66\u4e60\u73af\u5883\u4e2d\u589e\u5f3aLLMs\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.09527", "pdf": "https://arxiv.org/pdf/2508.09527", "abs": "https://arxiv.org/abs/2508.09527", "authors": ["Fang Wang", "Ernesto Damiani"], "title": "Time-Aware and Transition-Semantic Graph Neural Networks for Interpretable Predictive Business Process Monitoring", "categories": ["cs.LG"], "comment": "32 pages", "summary": "Predictive Business Process Monitoring (PBPM) aims to forecast future events\nin ongoing cases based on historical event logs. While Graph Neural Networks\n(GNNs) are well suited to capture structural dependencies in process data,\nexisting GNN-based PBPM models remain underdeveloped. Most rely either on short\nprefix subgraphs or global architectures that overlook temporal relevance and\ntransition semantics. We propose a unified, interpretable GNN framework that\nadvances the state of the art along three key axes. First, we compare\nprefix-based Graph Convolutional Networks(GCNs) and full trace Graph Attention\nNetworks(GATs) to quantify the performance gap between localized and global\nmodeling. Second, we introduce a novel time decay attention mechanism that\nconstructs dynamic, prediction-centered windows, emphasizing temporally\nrelevant history and suppressing noise. Third, we embed transition type\nsemantics into edge features to enable fine grained reasoning over structurally\nambiguous traces. Our architecture includes multilevel interpretability\nmodules, offering diverse visualizations of attention behavior. Evaluated on\nfive benchmarks, the proposed models achieve competitive Top-k accuracy and DL\nscores without per-dataset tuning. By addressing architectural, temporal, and\nsemantic gaps, this work presents a robust, generalizable, and explainable\nsolution for next event prediction in PBPM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u7684\u7edf\u4e00\u3001\u53ef\u89e3\u91ca\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u4e1a\u52a1\u6d41\u7a0b\u76d1\u63a7\uff08PBPM\uff09\u4e2d\u7684\u672a\u6765\u4e8b\u4ef6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5c40\u90e8\u5efa\u6a21\u3001\u65f6\u95f4\u76f8\u5173\u6027\u548c\u8bed\u4e49\u8868\u8fbe\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eGNN\u7684PBPM\u6a21\u578b\u5728\u6355\u6349\u65f6\u95f4\u76f8\u5173\u6027\u548c\u8bed\u4e49\u4fe1\u606f\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u5168\u9762\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u524d\u7f00\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCN\uff09\u548c\u5168\u8ff9\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff08GAT\uff09\uff0c\u5f15\u5165\u65f6\u95f4\u8870\u51cf\u6ce8\u610f\u529b\u673a\u5236\u548c\u8fb9\u7279\u5f81\u5d4c\u5165\u8bed\u4e49\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6a21\u578b\u8868\u73b0\u51fa\u8272\uff0c\u65e0\u9700\u9488\u5bf9\u6bcf\u4e2a\u6570\u636e\u96c6\u8c03\u6574\u5373\u53ef\u8fbe\u5230\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6539\u8fdb\u67b6\u6784\u3001\u65f6\u95f4\u548c\u8bed\u4e49\u8868\u8fbe\uff0c\u4e3aPBPM\u4e2d\u7684\u4e8b\u4ef6\u9884\u6d4b\u63d0\u4f9b\u4e86\u9c81\u68d2\u3001\u901a\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09544", "pdf": "https://arxiv.org/pdf/2508.09544", "abs": "https://arxiv.org/abs/2508.09544", "authors": ["Sasan Tavakkol", "Lin Chen", "Max Springer", "Abigail Schantz", "Bla\u017e Bratani\u010d", "Vincent Cohen-Addad", "MohammadHossein Bateni"], "title": "SYNAPSE-G: Bridging Large Language Models and Graph Learning for Rare Event Classification", "categories": ["cs.LG"], "comment": null, "summary": "Scarcity of labeled data, especially for rare events, hinders training\neffective machine learning models. This paper proposes SYNAPSE-G (Synthetic\nAugmentation for Positive Sampling via Expansion on Graphs), a novel pipeline\nleveraging Large Language Models (LLMs) to generate synthetic training data for\nrare event classification, addressing the cold-start problem. This synthetic\ndata serve as seeds for semi-supervised label propagation on a similarity graph\nconstructed between the seeds and a large unlabeled dataset. This identifies\ncandidate positive examples, subsequently labeled by an oracle (human or LLM).\nThe expanded dataset then trains/fine-tunes a classifier. We theoretically\nanalyze how the quality (validity and diversity) of the synthetic data impacts\nthe precision and recall of our method. Experiments on the imbalanced SST2 and\nMHS datasets demonstrate SYNAPSE-G's effectiveness in finding positive labels,\noutperforming baselines including nearest neighbor search.", "AI": {"tldr": "SYNAPSE-G\u5229\u7528LLMs\u751f\u6210\u5408\u6210\u6570\u636e\u89e3\u51b3\u7a00\u6709\u4e8b\u4ef6\u5206\u7c7b\u7684\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u901a\u8fc7\u534a\u76d1\u7763\u6807\u7b7e\u4f20\u64ad\u6269\u5c55\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u6807\u8bb0\u6570\u636e\u7a00\u7f3a\uff0c\u5c24\u5176\u662f\u7a00\u6709\u4e8b\u4ef6\uff0c\u963b\u788d\u4e86\u6709\u6548\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u8bad\u7ec3\u3002", "method": "\u63d0\u51faSYNAPSE-G\uff0c\u5229\u7528LLMs\u751f\u6210\u5408\u6210\u6570\u636e\u4f5c\u4e3a\u79cd\u5b50\uff0c\u901a\u8fc7\u534a\u76d1\u7763\u6807\u7b7e\u4f20\u64ad\u6269\u5c55\u6570\u636e\u96c6\uff0c\u6700\u7ec8\u8bad\u7ec3\u5206\u7c7b\u5668\u3002", "result": "\u5728SST2\u548cMHS\u6570\u636e\u96c6\u4e0a\uff0cSYNAPSE-G\u5728\u53d1\u73b0\u6b63\u6807\u7b7e\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "SYNAPSE-G\u901a\u8fc7\u5408\u6210\u6570\u636e\u548c\u534a\u76d1\u7763\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u4e86\u7a00\u6709\u4e8b\u4ef6\u5206\u7c7b\u95ee\u9898\u3002"}}
{"id": "2508.09561", "pdf": "https://arxiv.org/pdf/2508.09561", "abs": "https://arxiv.org/abs/2508.09561", "authors": ["Changyuan Zhao", "Guangyuan Liu", "Ruichen Zhang", "Yinqiu Liu", "Jiacheng Wang", "Jiawen Kang", "Dusit Niyato", "Zan Li", "Xuemin", "Shen", "Zhu Han", "Sumei Sun", "Chau Yuen", "Dong In Kim"], "title": "Edge General Intelligence Through World Models and Agentic AI: Fundamentals, Solutions, and Challenges", "categories": ["cs.LG"], "comment": "21 pages. 9 figures", "summary": "Edge General Intelligence (EGI) represents a transformative evolution of edge\ncomputing, where distributed agents possess the capability to perceive, reason,\nand act autonomously across diverse, dynamic environments. Central to this\nvision are world models, which act as proactive internal simulators that not\nonly predict but also actively imagine future trajectories, reason under\nuncertainty, and plan multi-step actions with foresight. This proactive nature\nallows agents to anticipate potential outcomes and optimize decisions ahead of\nreal-world interactions. While prior works in robotics and gaming have\nshowcased the potential of world models, their integration into the wireless\nedge for EGI remains underexplored. This survey bridges this gap by offering a\ncomprehensive analysis of how world models can empower agentic artificial\nintelligence (AI) systems at the edge. We first examine the architectural\nfoundations of world models, including latent representation learning, dynamics\nmodeling, and imagination-based planning. Building on these core capabilities,\nwe illustrate their proactive applications across EGI scenarios such as\nvehicular networks, unmanned aerial vehicle (UAV) networks, the Internet of\nThings (IoT) systems, and network functions virtualization, thereby\nhighlighting how they can enhance optimization under latency, energy, and\nprivacy constraints. We then explore their synergy with foundation models and\ndigital twins, positioning world models as the cognitive backbone of EGI.\nFinally, we highlight open challenges, such as safety guarantees, efficient\ntraining, and constrained deployment, and outline future research directions.\nThis survey provides both a conceptual foundation and a practical roadmap for\nrealizing the next generation of intelligent, autonomous edge systems.", "AI": {"tldr": "EGI\uff08\u8fb9\u7f18\u901a\u7528\u667a\u80fd\uff09\u901a\u8fc7\u4e16\u754c\u6a21\u578b\u5b9e\u73b0\u8fb9\u7f18\u8ba1\u7b97\u7684\u81ea\u4e3b\u611f\u77e5\u3001\u63a8\u7406\u548c\u884c\u52a8\uff0c\u586b\u8865\u4e86\u65e0\u7ebf\u8fb9\u7f18\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002", "motivation": "\u63a2\u7d22\u4e16\u754c\u6a21\u578b\u5728\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u63d0\u5347\u81ea\u4e3bAI\u7cfb\u7edf\u7684\u80fd\u529b\u3002", "method": "\u5206\u6790\u4e16\u754c\u6a21\u578b\u7684\u67b6\u6784\u57fa\u7840\uff08\u5982\u6f5c\u5728\u8868\u793a\u5b66\u4e60\u3001\u52a8\u6001\u5efa\u6a21\u548c\u57fa\u4e8e\u60f3\u8c61\u7684\u89c4\u5212\uff09\u53ca\u5176\u5728EGI\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u5c55\u793a\u4e86\u4e16\u754c\u6a21\u578b\u5728\u8f66\u8f86\u7f51\u7edc\u3001\u65e0\u4eba\u673a\u7f51\u7edc\u7b49\u573a\u666f\u4e2d\u7684\u4f18\u5316\u6f5c\u529b\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e0e\u57fa\u7840\u6a21\u578b\u548c\u6570\u5b57\u5b6a\u751f\u7684\u534f\u540c\u4f5c\u7528\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5b89\u5168\u4fdd\u8bc1\u3001\u9ad8\u6548\u8bad\u7ec3\u7b49\u5f00\u653e\u6311\u6218\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u667a\u80fd\u8fb9\u7f18\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2508.09624", "pdf": "https://arxiv.org/pdf/2508.09624", "abs": "https://arxiv.org/abs/2508.09624", "authors": ["Yan Yu", "Yaodong Yang", "Zhengbo Lu", "Chengdong Ma", "Wengang Zhou", "Houqiang Li"], "title": "Goal Discovery with Causal Capacity for Efficient Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Causal inference is crucial for humans to explore the world, which can be\nmodeled to enable an agent to efficiently explore the environment in\nreinforcement learning. Existing research indicates that establishing the\ncausality between action and state transition will enhance an agent to reason\nhow a policy affects its future trajectory, thereby promoting directed\nexploration. However, it is challenging to measure the causality due to its\nintractability in the vast state-action space of complex scenarios. In this\npaper, we propose a novel Goal Discovery with Causal Capacity (GDCC) framework\nfor efficient environment exploration. Specifically, we first derive a\nmeasurement of causality in state space, \\emph{i.e.,} causal capacity, which\nrepresents the highest influence of an agent's behavior on future trajectories.\nAfter that, we present a Monte Carlo based method to identify critical points\nin discrete state space and further optimize this method for continuous\nhigh-dimensional environments. Those critical points are used to uncover where\nthe agent makes important decisions in the environment, which are then regarded\nas our subgoals to guide the agent to make exploration more purposefully and\nefficiently. Empirical results from multi-objective tasks demonstrate that\nstates with high causal capacity align with our expected subgoals, and our GDCC\nachieves significant success rate improvements compared to baselines.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u80fd\u529b\u7684GDCC\u6846\u67b6\uff0c\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u9ad8\u6548\u73af\u5883\u63a2\u7d22\uff0c\u901a\u8fc7\u6d4b\u91cf\u56e0\u679c\u80fd\u529b\u5e76\u8bc6\u522b\u5173\u952e\u70b9\u4f5c\u4e3a\u5b50\u76ee\u6807\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a2\u7d22\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u96be\u4ee5\u5728\u590d\u6742\u573a\u666f\u4e2d\u6d4b\u91cf\u52a8\u4f5c\u4e0e\u72b6\u6001\u8f6c\u79fb\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u9650\u5236\u4e86\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u9ad8\u6548\u63a2\u7d22\u80fd\u529b\u3002", "method": "\u63d0\u51faGDCC\u6846\u67b6\uff0c\u9996\u5148\u6d4b\u91cf\u72b6\u6001\u7a7a\u95f4\u4e2d\u7684\u56e0\u679c\u80fd\u529b\uff0c\u7136\u540e\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u8bc6\u522b\u5173\u952e\u70b9\u4f5c\u4e3a\u5b50\u76ee\u6807\uff0c\u4f18\u5316\u63a2\u7d22\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u9ad8\u56e0\u679c\u80fd\u529b\u7684\u72b6\u6001\u4e0e\u9884\u671f\u5b50\u76ee\u6807\u4e00\u81f4\uff0cGDCC\u5728\u591a\u76ee\u6807\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6210\u529f\u7387\u3002", "conclusion": "GDCC\u6846\u67b6\u901a\u8fc7\u56e0\u679c\u80fd\u529b\u548c\u5b50\u76ee\u6807\u5f15\u5bfc\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u548c\u6709\u76ee\u7684\u7684\u73af\u5883\u63a2\u7d22\u3002"}}
{"id": "2508.09627", "pdf": "https://arxiv.org/pdf/2508.09627", "abs": "https://arxiv.org/abs/2508.09627", "authors": ["Subhankar Sarkar", "Souvik Chakraborty"], "title": "Physics- and geometry-aware spatio-spectral graph neural operator for time-independent and time-dependent PDEs", "categories": ["cs.LG"], "comment": null, "summary": "Solving partial differential equations (PDEs) efficiently and accurately\nremains a cornerstone challenge in science and engineering, especially for\nproblems involving complex geometries and limited labeled data. We introduce a\nPhysics- and Geometry- Aware Spatio-Spectral Graph Neural Operator\n($\\pi$G-Sp$^2$GNO) for learning the solution operators of time-independent and\ntime-dependent PDEs. The proposed approach first improves upon the recently\ndeveloped Sp$^2$GNO by enabling geometry awareness and subsequently exploits\nthe governing physics to learn the underlying solution operator in a\nsimulation-free setup. While the spatio-spectral structure present in the\nproposed architecture allows multiscale learning, two separate strategies for\nenabling geometry awareness is introduced in this paper. For time dependent\nproblems, we also introduce a novel hybrid physics informed loss function that\ncombines higher-order time-marching scheme with upscaled theory inspired\nstochastic projection scheme. This allows accurate integration of the\nphysics-information into the loss function. The performance of the proposed\napproach is illustrated on number of benchmark examples involving regular and\ncomplex domains, variation in geometry during inference, and time-independent\nand time-dependent problems. The results obtained illustrate the efficacy of\nthe proposed approach as compared to the state-of-the-art physics-informed\nneural operator algorithms in the literature.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7269\u7406\u548c\u51e0\u4f55\u611f\u77e5\u7684\u65f6\u7a7a\u8c31\u56fe\u795e\u7ecf\u7b97\u5b50\uff08\u03c0G-Sp\u00b2GNO\uff09\uff0c\u7528\u4e8e\u9ad8\u6548\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDEs\uff09\uff0c\u5728\u590d\u6742\u51e0\u4f55\u548c\u6709\u9650\u6807\u6ce8\u6570\u636e\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u9ad8\u6548\u51c6\u786e\u5730\u6c42\u89e3PDEs\u662f\u79d1\u5b66\u4e0e\u5de5\u7a0b\u4e2d\u7684\u6838\u5fc3\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u51e0\u4f55\u548c\u6709\u9650\u6807\u6ce8\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u6539\u8fdb\u73b0\u6709\u7684Sp\u00b2GNO\uff0c\u5f15\u5165\u51e0\u4f55\u611f\u77e5\u80fd\u529b\uff0c\u5e76\u7ed3\u5408\u7269\u7406\u4fe1\u606f\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u7269\u7406\u635f\u5931\u51fd\u6570\uff0c\u7528\u4e8e\u65f6\u95f4\u76f8\u5173\u95ee\u9898\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7b97\u5b50\u7b97\u6cd5\u3002", "conclusion": "\u03c0G-Sp\u00b2GNO\u5728\u590d\u6742\u51e0\u4f55\u548c\u65f6\u95f4\u76f8\u5173\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3aPDEs\u6c42\u89e3\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09630", "pdf": "https://arxiv.org/pdf/2508.09630", "abs": "https://arxiv.org/abs/2508.09630", "authors": ["Yifei Sun", "Junming Liu", "Ding Wang", "Yirong Chen", "Xuefeng Yan"], "title": "TimeMKG: Knowledge-Infused Causal Reasoning for Multivariate Time Series Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multivariate time series data typically comprises two distinct modalities:\nvariable semantics and sampled numerical observations. Traditional time series\nmodels treat variables as anonymous statistical signals, overlooking the rich\nsemantic information embedded in variable names and data descriptions. However,\nthese textual descriptors often encode critical domain knowledge that is\nessential for robust and interpretable modeling. Here we present TimeMKG, a\nmultimodal causal reasoning framework that elevates time series modeling from\nlow-level signal processing to knowledge informed inference. TimeMKG employs\nlarge language models to interpret variable semantics and constructs structured\nMultivariate Knowledge Graphs that capture inter-variable relationships. A\ndual-modality encoder separately models the semantic prompts, generated from\nknowledge graph triplets, and the statistical patterns from historical time\nseries. Cross-modality attention aligns and fuses these representations at the\nvariable level, injecting causal priors into downstream tasks such as\nforecasting and classification, providing explicit and interpretable priors to\nguide model reasoning. The experiment in diverse datasets demonstrates that\nincorporating variable-level knowledge significantly improves both predictive\nperformance and generalization.", "AI": {"tldr": "TimeMKG\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u56e0\u679c\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u53d8\u91cf\u8bed\u4e49\u548c\u5386\u53f2\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u7684\u9884\u6d4b\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u5ffd\u7565\u53d8\u91cf\u8bed\u4e49\u4fe1\u606f\uff0c\u800cTimeMKG\u65e8\u5728\u5229\u7528\u53d8\u91cf\u540d\u79f0\u548c\u63cf\u8ff0\u4e2d\u7684\u9886\u57df\u77e5\u8bc6\uff0c\u5b9e\u73b0\u66f4\u9c81\u68d2\u548c\u53ef\u89e3\u91ca\u7684\u5efa\u6a21\u3002", "method": "TimeMKG\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u6790\u53d8\u91cf\u8bed\u4e49\uff0c\u6784\u5efa\u591a\u53d8\u91cf\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e76\u901a\u8fc7\u53cc\u6a21\u6001\u7f16\u7801\u5668\u5206\u522b\u5efa\u6a21\u8bed\u4e49\u63d0\u793a\u548c\u7edf\u8ba1\u6a21\u5f0f\uff0c\u6700\u540e\u901a\u8fc7\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u878d\u5408\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5f15\u5165\u53d8\u91cf\u7ea7\u77e5\u8bc6\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "TimeMKG\u901a\u8fc7\u878d\u5408\u8bed\u4e49\u548c\u7edf\u8ba1\u4fe1\u606f\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u548c\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09659", "pdf": "https://arxiv.org/pdf/2508.09659", "abs": "https://arxiv.org/abs/2508.09659", "authors": ["Johannes F. Hevler", "Shivam Verma", "Mirat Soijtra", "Carolyn R. Bertozzi"], "title": "Thermal Tracks: A Gaussian process-based framework for universal melting curve analysis enabling unconstrained hit identification in thermal proteome profiling experiments", "categories": ["cs.LG", "q-bio.QM"], "comment": "5 pages, 2 figures, short communication", "summary": "Thermal Tracks is a Python-based statistical framework for analyzing protein\nthermal stability data that overcomes key limitations of existing thermal\nproteome profiling (TPP) work-flows. Unlike standard approaches that assume\nsigmoidal melting curves and are constrained by empirical null distributions\n(limiting significant hits to approximately 5 % of data), Thermal Tracks uses\nGaussian Process (GP) models with squared-exponential kernels to flexibly model\nany melting curve shape while generating unbiased null distributions through\nkernel priors. This framework is particularly valuable for analyzing\nproteome-wide perturbations that significantly alter protein thermal stability,\nsuch as pathway inhibitions, genetic modifications, or environmental stresses,\nwhere conventional TPP methods may miss biologically relevant changes due to\ntheir statistical constraints. Furthermore, Thermal Tracks excels at analyzing\nproteins with un-conventional melting profiles, including phase-separating\nproteins and membrane proteins, which often exhibit complex, non-sigmoidal\nthermal stability behaviors. Thermal Tracks is freely available from GitHub and\nis implemented in Python, providing an accessible and flexible tool for\nproteome-wide thermal profiling studies.", "AI": {"tldr": "Thermal Tracks\u662f\u4e00\u4e2a\u57fa\u4e8ePython\u7684\u7edf\u8ba1\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u86cb\u767d\u8d28\u70ed\u7a33\u5b9a\u6027\u6570\u636e\uff0c\u514b\u670d\u4e86\u73b0\u6709\u70ed\u86cb\u767d\u8d28\u7ec4\u5206\u6790\uff08TPP\uff09\u65b9\u6cd5\u7684\u5173\u952e\u9650\u5236\u3002", "motivation": "\u73b0\u6709TPP\u65b9\u6cd5\u5047\u8bbe\u7194\u89e3\u66f2\u7ebf\u4e3aS\u5f62\uff0c\u5e76\u53d7\u9650\u4e8e\u7ecf\u9a8c\u96f6\u5206\u5e03\uff0c\u5bfc\u81f4\u4ec5\u80fd\u8bc6\u522b\u7ea65%\u7684\u6570\u636e\u3002Thermal Tracks\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u4f9b\u66f4\u7075\u6d3b\u7684\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u9ad8\u65af\u8fc7\u7a0b\uff08GP\uff09\u6a21\u578b\u548c\u5e73\u65b9\u6307\u6570\u6838\uff0c\u7075\u6d3b\u5efa\u6a21\u4efb\u610f\u7194\u89e3\u66f2\u7ebf\u5f62\u72b6\uff0c\u5e76\u901a\u8fc7\u6838\u5148\u9a8c\u751f\u6210\u65e0\u504f\u96f6\u5206\u5e03\u3002", "result": "Thermal Tracks\u80fd\u6709\u6548\u5206\u6790\u86cb\u767d\u8d28\u70ed\u7a33\u5b9a\u6027\u7684\u5168\u5c40\u6270\u52a8\uff0c\u5982\u901a\u8def\u6291\u5236\u3001\u57fa\u56e0\u4fee\u9970\u6216\u73af\u5883\u538b\u529b\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u975e\u4f20\u7edf\u7194\u89e3\u66f2\u7ebf\u7684\u86cb\u767d\u8d28\u3002", "conclusion": "Thermal Tracks\u662f\u4e00\u4e2a\u514d\u8d39\u3001\u7075\u6d3b\u7684\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u86cb\u767d\u8d28\u7ec4\u8303\u56f4\u5185\u7684\u70ed\u7a33\u5b9a\u6027\u7814\u7a76\u3002"}}
{"id": "2508.09685", "pdf": "https://arxiv.org/pdf/2508.09685", "abs": "https://arxiv.org/abs/2508.09685", "authors": ["Xu Zhang", "Shuo Chen", "Jinsheng Li", "Xiangying Pang", "Maoguo Gong"], "title": "Global Convergence Analysis of Vanilla Gradient Descent for Asymmetric Matrix Completion", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": null, "summary": "This paper investigates the asymmetric low-rank matrix completion problem,\nwhich can be formulated as an unconstrained non-convex optimization problem\nwith a nonlinear least-squares objective function, and is solved via gradient\ndescent methods. Previous gradient descent approaches typically incorporate\nregularization terms into the objective function to guarantee convergence.\nHowever, numerical experiments and theoretical analysis of the gradient flow\nboth demonstrate that the elimination of regularization terms in gradient\ndescent algorithms does not adversely affect convergence performance. By\nintroducing the leave-one-out technique, we inductively prove that the vanilla\ngradient descent with spectral initialization achieves a linear convergence\nrate with high probability. Besides, we demonstrate that the balancing\nregularization term exhibits a small norm during iterations, which reveals the\nimplicit regularization property of gradient descent. Empirical results show\nthat our algorithm has a lower computational cost while maintaining comparable\ncompletion performance compared to other gradient descent algorithms.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u975e\u5bf9\u79f0\u4f4e\u79e9\u77e9\u9635\u8865\u5168\u95ee\u9898\uff0c\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\u89e3\u51b3\u65e0\u7ea6\u675f\u975e\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u53d1\u73b0\u65e0\u9700\u6b63\u5219\u5316\u9879\u4e5f\u80fd\u4fdd\u8bc1\u6536\u655b\u3002", "motivation": "\u63a2\u7d22\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\u5728\u975e\u5bf9\u79f0\u4f4e\u79e9\u77e9\u9635\u8865\u5168\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u53bb\u9664\u6b63\u5219\u5316\u9879\u5bf9\u6536\u655b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u8c31\u521d\u59cb\u5316\u7684\u666e\u901a\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\uff0c\u7ed3\u5408\u7559\u4e00\u6280\u672f\u8fdb\u884c\u7406\u8bba\u5206\u6790\u3002", "result": "\u8bc1\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u9ad8\u6982\u7387\u7ebf\u6027\u6536\u655b\u7387\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u66f4\u4f4e\u3002", "conclusion": "\u68af\u5ea6\u4e0b\u964d\u5177\u6709\u9690\u5f0f\u6b63\u5219\u5316\u7279\u6027\uff0c\u65e0\u9700\u663e\u5f0f\u6b63\u5219\u5316\u9879\u5373\u53ef\u9ad8\u6548\u5b8c\u6210\u77e9\u9635\u8865\u5168\u3002"}}
{"id": "2508.09693", "pdf": "https://arxiv.org/pdf/2508.09693", "abs": "https://arxiv.org/abs/2508.09693", "authors": ["Faruk Alpay", "Bugra Kilictas", "Hamdi Alakkad"], "title": "Temporal Anchoring in Deepening Embedding Spaces: Event-Indexed Projections, Drift, Convergence, and an Internal Computational Architecture", "categories": ["cs.LG", "math.FA", "math.OC", "stat.ML", "47H09, 47H10, 90C25, 65K10, 68T07", "F.1.1; G.1.6; I.2.6; G.1.2"], "comment": "16 pages, 2 figures, 2 tables", "summary": "We develop an operator-theoretic framework for temporal anchoring in\nembedding spaces, modeled as drift maps interleaved with event-indexed blocks\nculminating in affine projections. We provide complete proofs for a\nvariable-block contraction lemma (products of Lipschitz factors), a\ndrift--projection convergence theorem with explicit uniform-gap envelopes, and\nontological convergence under nested affine anchors with a robustness variant.\nWe formalize an internal Manuscript Computer (MC) whose computations are\ndefined purely by these operators and prove a rigorous finite-run equivalence\ntheorem (with perturbation bounds). For attention layers, we give a\nself-contained proof that softmax is $1/2$-Lipschitz in $\\ell_2$ and derive\nsufficient layer-contraction conditions (orthogonal/non-orthogonal heads). All\nfloats are placed exactly where written; the manuscript uses only in-paper\npseudocode and appendix figures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7b97\u5b50\u7406\u8bba\u7684\u65f6\u6001\u951a\u5b9a\u6846\u67b6\uff0c\u7ed3\u5408\u6f02\u79fb\u6620\u5c04\u548c\u4e8b\u4ef6\u7d22\u5f15\u5757\uff0c\u6700\u7ec8\u901a\u8fc7\u4eff\u5c04\u6295\u5f71\u5b9e\u73b0\u3002", "motivation": "\u4e3a\u89e3\u51b3\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u65f6\u6001\u951a\u5b9a\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u79cd\u7edf\u4e00\u7684\u7b97\u5b50\u7406\u8bba\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u6f02\u79fb\u6620\u5c04\u4e0e\u4e8b\u4ef6\u7d22\u5f15\u5757\u7ed3\u5408\u4eff\u5c04\u6295\u5f71\uff0c\u5e76\u8bc1\u660e\u76f8\u5173\u5b9a\u7406\uff08\u5982\u6536\u7f29\u5f15\u7406\u3001\u6536\u655b\u5b9a\u7406\uff09\u3002", "result": "\u8bc1\u660e\u4e86\u8f6f\u6ce8\u610f\u529b\u5c42\u7684Lipschitz\u6027\u8d28\uff0c\u5e76\u7ed9\u51fa\u4e86\u5c42\u6536\u7f29\u7684\u5145\u5206\u6761\u4ef6\u3002", "conclusion": "\u6846\u67b6\u5177\u6709\u4e25\u683c\u7684\u6570\u5b66\u57fa\u7840\uff0c\u9002\u7528\u4e8e\u6ce8\u610f\u529b\u5c42\u7b49\u573a\u666f\uff0c\u4e14\u8ba1\u7b97\u7b49\u4ef7\u6027\u5f97\u5230\u9a8c\u8bc1\u3002"}}
{"id": "2508.09697", "pdf": "https://arxiv.org/pdf/2508.09697", "abs": "https://arxiv.org/abs/2508.09697", "authors": ["Xinlei Zhang", "Fan Liu", "Chuanyi Zhang", "Fan Cheng", "Yuhui Zheng"], "title": "Combating Noisy Labels via Dynamic Connection Masking", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Noisy labels are inevitable in real-world scenarios. Due to the strong\ncapacity of deep neural networks to memorize corrupted labels, these noisy\nlabels can cause significant performance degradation. Existing research on\nmitigating the negative effects of noisy labels has mainly focused on robust\nloss functions and sample selection, with comparatively limited exploration of\nregularization in model architecture. Inspired by the sparsity regularization\nused in Kolmogorov-Arnold Networks (KANs), we propose a Dynamic Connection\nMasking (DCM) mechanism for both Multi-Layer Perceptron Networks (MLPs) and\nKANs to enhance the robustness of classifiers against noisy labels. The\nmechanism can adaptively mask less important edges during training by\nevaluating their information-carrying capacity. Through theoretical analysis,\nwe demonstrate its efficiency in reducing gradient error. Our approach can be\nseamlessly integrated into various noise-robust training methods to build more\nrobust deep networks, including robust loss functions, sample selection\nstrategies, and regularization techniques. Extensive experiments on both\nsynthetic and real-world benchmarks demonstrate that our method consistently\noutperforms state-of-the-art (SOTA) approaches. Furthermore, we are also the\nfirst to investigate KANs as classifiers against noisy labels, revealing their\nsuperior noise robustness over MLPs in real-world noisy scenarios. Our code\nwill soon be publicly available.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u8fde\u63a5\u63a9\u7801\uff08DCM\uff09\u673a\u5236\uff0c\u7528\u4e8e\u589e\u5f3aMLPs\u548cKANs\u5bf9\u566a\u58f0\u6807\u7b7e\u7684\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u63a9\u7801\u4e0d\u91cd\u8981\u8fb9\u51cf\u5c11\u68af\u5ea6\u8bef\u5dee\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u5b9e\u573a\u666f\u4e2d\u566a\u58f0\u6807\u7b7e\u4e0d\u53ef\u907f\u514d\uff0c\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u9c81\u68d2\u635f\u5931\u51fd\u6570\u548c\u6837\u672c\u9009\u62e9\uff0c\u5bf9\u6a21\u578b\u67b6\u6784\u6b63\u5219\u5316\u7684\u63a2\u7d22\u8f83\u5c11\u3002", "method": "\u57fa\u4e8eKANs\u7684\u7a00\u758f\u6b63\u5219\u5316\uff0c\u63d0\u51faDCM\u673a\u5236\uff0c\u52a8\u6001\u8bc4\u4f30\u5e76\u63a9\u7801\u4e0d\u91cd\u8981\u8fb9\uff0c\u51cf\u5c11\u68af\u5ea6\u8bef\u5dee\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cDCM\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u9996\u6b21\u53d1\u73b0KANs\u5728\u566a\u58f0\u573a\u666f\u4e2d\u4f18\u4e8eMLPs\u3002", "conclusion": "DCM\u673a\u5236\u6709\u6548\u63d0\u5347\u6a21\u578b\u5bf9\u566a\u58f0\u6807\u7b7e\u7684\u9c81\u68d2\u6027\uff0c\u53ef\u4e0e\u5176\u4ed6\u566a\u58f0\u9c81\u68d2\u65b9\u6cd5\u7ed3\u5408\uff0cKANs\u5728\u566a\u58f0\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2508.09710", "pdf": "https://arxiv.org/pdf/2508.09710", "abs": "https://arxiv.org/abs/2508.09710", "authors": ["Yitong Luo", "Islem Rekik"], "title": "GraphTreeGen: Subtree-Centric Approach to Efficient and Supervised Graph Generation", "categories": ["cs.LG"], "comment": null, "summary": "Brain connectomes, representing neural connectivity as graphs, are crucial\nfor understanding brain organization but costly and time-consuming to acquire,\nmotivating generative approaches. Recent advances in graph generative modeling\noffer a data-driven alternative, enabling synthetic connectome generation and\nreducing dependence on large neuroimaging datasets. However, current models\nface key limitations: (i) compressing the whole graph into a single latent code\n(e.g., VGAEs) blurs fine-grained local motifs; (ii) relying on rich node\nattributes rarely available in connectomes reduces reconstruction quality;\n(iii) edge-centric models emphasize topology but overlook accurate edge-weight\nprediction, harming quantitative fidelity; and (iv) computationally expensive\ndesigns (e.g., edge-conditioned convolutions) impose high memory demands,\nlimiting scalability. We propose GraphTreeGen (GTG), a subtree-centric\ngenerative framework for efficient, accurate connectome synthesis. GTG\ndecomposes each connectome into entropy-guided k-hop trees capturing\ninformative local structure, encoded by a shared GCN. A bipartite\nmessage-passing layer fuses subtree embeddings with global node features, while\na dual-branch decoder jointly predicts edge existence and weights to\nreconstruct the adjacency matrix. GTG outperforms state-of-the-art baselines in\nself-supervised tasks and remains competitive in supervised settings,\ndelivering higher structural fidelity and more precise weights with far less\nmemory. Its modular design enables extensions to connectome super-resolution\nand cross-modality synthesis. Code: https://github.com/basiralab/GTG/", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faGraphTreeGen\uff08GTG\uff09\uff0c\u4e00\u79cd\u57fa\u4e8e\u5b50\u6811\u7684\u751f\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u3001\u51c6\u786e\u5730\u5408\u6210\u8111\u8fde\u63a5\u7ec4\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u5728\u5c40\u90e8\u7ed3\u6784\u3001\u8282\u70b9\u5c5e\u6027\u4f9d\u8d56\u3001\u8fb9\u6743\u91cd\u9884\u6d4b\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u8111\u8fde\u63a5\u7ec4\u7684\u83b7\u53d6\u6210\u672c\u9ad8\u4e14\u8017\u65f6\uff0c\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u5c40\u90e8\u7ed3\u6784\u4fdd\u7559\u3001\u8282\u70b9\u5c5e\u6027\u4f9d\u8d56\u3001\u8fb9\u6743\u91cd\u9884\u6d4b\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u751f\u6210\u65b9\u6cd5\u3002", "method": "GTG\u5c06\u8fde\u63a5\u7ec4\u5206\u89e3\u4e3a\u71b5\u5f15\u5bfc\u7684k\u8df3\u5b50\u6811\uff0c\u901a\u8fc7\u5171\u4eabGCN\u7f16\u7801\u5c40\u90e8\u7ed3\u6784\uff0c\u5229\u7528\u4e8c\u5206\u6d88\u606f\u4f20\u9012\u5c42\u878d\u5408\u5b50\u6811\u5d4c\u5165\u4e0e\u5168\u5c40\u8282\u70b9\u7279\u5f81\uff0c\u53cc\u5206\u652f\u89e3\u7801\u5668\u8054\u5408\u9884\u6d4b\u8fb9\u5b58\u5728\u548c\u6743\u91cd\u3002", "result": "GTG\u5728\u81ea\u76d1\u7763\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5728\u76d1\u7763\u4efb\u52a1\u4e2d\u8868\u73b0\u7ade\u4e89\u6027\uff0c\u63d0\u4f9b\u66f4\u9ad8\u7684\u7ed3\u6784\u4fdd\u771f\u5ea6\u548c\u66f4\u7cbe\u786e\u7684\u6743\u91cd\u9884\u6d4b\uff0c\u540c\u65f6\u5185\u5b58\u6d88\u8017\u66f4\u4f4e\u3002", "conclusion": "GTG\u4e3a\u8111\u8fde\u63a5\u7ec4\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5176\u6a21\u5757\u5316\u8bbe\u8ba1\u652f\u6301\u6269\u5c55\u5230\u8d85\u5206\u8fa8\u7387\u548c\u8de8\u6a21\u6001\u5408\u6210\u3002"}}
{"id": "2508.09719", "pdf": "https://arxiv.org/pdf/2508.09719", "abs": "https://arxiv.org/abs/2508.09719", "authors": ["Anish Narain", "Ritam Majumdar", "Nikita Narayanan", "Dominic Marshall", "Sonali Parbhoo"], "title": "Improving ARDS Diagnosis Through Context-Aware Concept Bottleneck Models", "categories": ["cs.LG", "cs.AI"], "comment": "32 pages, 7 figures, accepted at Machine Learning for Healthcare\n  Conference (MLHC) 2025", "summary": "Large, publicly available clinical datasets have emerged as a novel resource\nfor understanding disease heterogeneity and to explore personalization of\ntherapy. These datasets are derived from data not originally collected for\nresearch purposes and, as a result, are often incomplete and lack critical\nlabels. Many AI tools have been developed to retrospectively label these\ndatasets, such as by performing disease classification; however, they often\nsuffer from limited interpretability. Previous work has attempted to explain\npredictions using Concept Bottleneck Models (CBMs), which learn interpretable\nconcepts that map to higher-level clinical ideas, facilitating human\nevaluation. However, these models often experience performance limitations when\nthe concepts fail to adequately explain or characterize the task. We use the\nidentification of Acute Respiratory Distress Syndrome (ARDS) as a challenging\ntest case to demonstrate the value of incorporating contextual information from\nclinical notes to improve CBM performance. Our approach leverages a Large\nLanguage Model (LLM) to process clinical notes and generate additional\nconcepts, resulting in a 10% performance gain over existing methods.\nAdditionally, it facilitates the learning of more comprehensive concepts,\nthereby reducing the risk of information leakage and reliance on spurious\nshortcuts, thus improving the characterization of ARDS.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5904\u7406\u4e34\u5e8a\u7b14\u8bb0\u7684\u65b9\u6cd5\uff0c\u4ee5\u6539\u8fdb\u6982\u5ff5\u74f6\u9888\u6a21\u578b\uff08CBM\uff09\u5728\u6025\u6027\u547c\u5438\u7a98\u8feb\u7efc\u5408\u5f81\uff08ARDS\uff09\u8bc6\u522b\u4e2d\u7684\u6027\u80fd\uff0c\u5b9e\u73b0\u4e8610%\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5229\u7528\u516c\u5f00\u4e34\u5e8a\u6570\u636e\u96c6\u7814\u7a76\u75be\u75c5\u5f02\u8d28\u6027\u548c\u4e2a\u6027\u5316\u6cbb\u7597\uff0c\u4f46\u8fd9\u4e9b\u6570\u636e\u96c6\u901a\u5e38\u4e0d\u5b8c\u6574\u4e14\u7f3a\u4e4f\u5173\u952e\u6807\u7b7e\u3002\u73b0\u6709AI\u5de5\u5177\u5728\u89e3\u91ca\u6027\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u800cCBM\u867d\u80fd\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u6982\u5ff5\uff0c\u4f46\u6027\u80fd\u53d7\u9650\u3002", "method": "\u901a\u8fc7LLM\u5904\u7406\u4e34\u5e8a\u7b14\u8bb0\u751f\u6210\u989d\u5916\u6982\u5ff5\uff0c\u7ed3\u5408CBM\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u51cf\u5c11\u4fe1\u606f\u6cc4\u6f0f\u548c\u5bf9\u865a\u5047\u6377\u5f84\u7684\u4f9d\u8d56\u3002", "result": "\u65b9\u6cd5\u5728ARDS\u8bc6\u522b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e8610%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5b66\u4e60\u5230\u66f4\u5168\u9762\u7684\u6982\u5ff5\u3002", "conclusion": "\u7ed3\u5408LLM\u7684CBM\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u540c\u65f6\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5bf9ARDS\u7684\u8868\u5f81\u80fd\u529b\u3002"}}
{"id": "2508.09730", "pdf": "https://arxiv.org/pdf/2508.09730", "abs": "https://arxiv.org/abs/2508.09730", "authors": ["Qiaolei Gu", "Yu Li", "DingYi Zeng", "Lu Wang", "Ming Pang", "Changping Peng", "Zhangang Lin", "Ching Law", "Jingping Shao"], "title": "Generative Modeling with Multi-Instance Reward Learning for E-commerce Creative Optimization", "categories": ["cs.LG"], "comment": "9 pages, 3 figures, conference paper", "summary": "In e-commerce advertising, selecting the most compelling combination of\ncreative elements -- such as titles, images, and highlights -- is critical for\ncapturing user attention and driving conversions. However, existing methods\noften evaluate creative components individually, failing to navigate the\nexponentially large search space of possible combinations. To address this\nchallenge, we propose a novel framework named GenCO that integrates generative\nmodeling with multi-instance reward learning. Our unified two-stage\narchitecture first employs a generative model to efficiently produce a diverse\nset of creative combinations. This generative process is optimized with\nreinforcement learning, enabling the model to effectively explore and refine\nits selections. Next, to overcome the challenge of sparse user feedback, a\nmulti-instance learning model attributes combination-level rewards, such as\nclicks, to the individual creative elements. This allows the reward model to\nprovide a more accurate feedback signal, which in turn guides the generative\nmodel toward creating more effective combinations. Deployed on a leading\ne-commerce platform, our approach has significantly increased advertising\nrevenue, demonstrating its practical value. Additionally, we are releasing a\nlarge-scale industrial dataset to facilitate further research in this important\ndomain.", "AI": {"tldr": "GenCO\u6846\u67b6\u901a\u8fc7\u751f\u6210\u6a21\u578b\u4e0e\u591a\u5b9e\u4f8b\u5956\u52b1\u5b66\u4e60\u7ed3\u5408\uff0c\u4f18\u5316\u7535\u5546\u5e7f\u544a\u521b\u610f\u7ec4\u5408\u9009\u62e9\uff0c\u663e\u8457\u63d0\u5347\u5e7f\u544a\u6536\u5165\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5355\u72ec\u8bc4\u4f30\u521b\u610f\u5143\u7d20\uff0c\u65e0\u6cd5\u9ad8\u6548\u63a2\u7d22\u5927\u91cf\u7ec4\u5408\u7a7a\u95f4\uff0c\u9700\u6539\u8fdb\u4ee5\u63d0\u5347\u5e7f\u544a\u6548\u679c\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u67b6\u6784\uff1a\u751f\u6210\u6a21\u578b\u751f\u6210\u591a\u6837\u5316\u521b\u610f\u7ec4\u5408\uff0c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u9009\u62e9\uff1b\u591a\u5b9e\u4f8b\u5b66\u4e60\u6a21\u578b\u5c06\u7ec4\u5408\u7ea7\u53cd\u9988\uff08\u5982\u70b9\u51fb\uff09\u5f52\u56e0\u4e8e\u5355\u4e2a\u5143\u7d20\u3002", "result": "\u5728\u7535\u5546\u5e73\u53f0\u90e8\u7f72\u540e\u663e\u8457\u589e\u52a0\u5e7f\u544a\u6536\u5165\uff0c\u5e76\u53d1\u5e03\u5de5\u4e1a\u6570\u636e\u96c6\u4fc3\u8fdb\u7814\u7a76\u3002", "conclusion": "GenCO\u6846\u67b6\u6709\u6548\u89e3\u51b3\u521b\u610f\u7ec4\u5408\u9009\u62e9\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u548c\u7814\u7a76\u610f\u4e49\u3002"}}
{"id": "2508.09743", "pdf": "https://arxiv.org/pdf/2508.09743", "abs": "https://arxiv.org/abs/2508.09743", "authors": ["Yanick Chistian Tchenko", "Felix Mohr", "Hicham Hadj Abdelkader", "Hedi Tabia"], "title": "HKT: A Biologically Inspired Framework for Modular Hereditary Knowledge Transfer in Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "A prevailing trend in neural network research suggests that model performance\nimproves with increasing depth and capacity - often at the cost of\nintegrability and efficiency. In this paper, we propose a strategy to optimize\nsmall, deployable models by enhancing their capabilities through structured\nknowledge inheritance. We introduce Hereditary Knowledge Transfer (HKT), a\nbiologically inspired framework for modular and selective transfer of\ntask-relevant features from a larger, pretrained parent network to a smaller\nchild model. Unlike standard knowledge distillation, which enforces uniform\nimitation of teacher outputs, HKT draws inspiration from biological inheritance\nmechanisms - such as memory RNA transfer in planarians - to guide a multi-stage\nprocess of feature transfer. Neural network blocks are treated as functional\ncarriers, and knowledge is transmitted through three biologically motivated\ncomponents: Extraction, Transfer, and Mixture (ETM). A novel Genetic Attention\n(GA) mechanism governs the integration of inherited and native representations,\nensuring both alignment and selectivity. We evaluate HKT across diverse vision\ntasks, including optical flow (Sintel, KITTI), image classification (CIFAR-10),\nand semantic segmentation (LiTS), demonstrating that it significantly improves\nchild model performance while preserving its compactness. The results show that\nHKT consistently outperforms conventional distillation approaches, offering a\ngeneral-purpose, interpretable, and scalable solution for deploying\nhigh-performance neural networks in resource-constrained environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHereditary Knowledge Transfer\uff08HKT\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u548c\u9009\u62e9\u6027\u7279\u5f81\u8f6c\u79fb\u4f18\u5316\u5c0f\u578b\u53ef\u90e8\u7f72\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u6027\u80fd\u548c\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u53d7\u751f\u7269\u5b66\u542f\u53d1\u7684\u77e5\u8bc6\u7ee7\u627f\u6846\u67b6\u3002", "method": "\u91c7\u7528\u63d0\u53d6\u3001\u8f6c\u79fb\u548c\u6df7\u5408\uff08ETM\uff09\u4e09\u9636\u6bb5\u8fc7\u7a0b\uff0c\u7ed3\u5408\u9057\u4f20\u6ce8\u610f\u529b\u673a\u5236\uff08GA\uff09\u9009\u62e9\u6027\u96c6\u6210\u7279\u5f81\u3002", "result": "\u5728\u591a\u4e2a\u89c6\u89c9\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u84b8\u998f\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7d27\u51d1\u6027\u3002", "conclusion": "HKT\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u6269\u5c55\u7684\u9ad8\u6027\u80fd\u795e\u7ecf\u7f51\u7edc\u90e8\u7f72\u65b9\u6848\u3002"}}
{"id": "2508.09747", "pdf": "https://arxiv.org/pdf/2508.09747", "abs": "https://arxiv.org/abs/2508.09747", "authors": ["Nazira Dunbayeva", "Yulong Li", "Yutong Xie", "Imran Razzak"], "title": "A Machine Learning Approach to Predict Biological Age and its Longitudinal Drivers", "categories": ["cs.LG"], "comment": null, "summary": "Predicting an individual's aging trajectory is a central challenge in\npreventative medicine and bioinformatics. While machine learning models can\npredict chronological age from biomarkers, they often fail to capture the\ndynamic, longitudinal nature of the aging process. In this work, we developed\nand validated a machine learning pipeline to predict age using a longitudinal\ncohort with data from two distinct time periods (2019-2020 and 2021-2022). We\ndemonstrate that a model using only static, cross-sectional biomarkers has\nlimited predictive power when generalizing to future time points. However, by\nengineering novel features that explicitly capture the rate of change (slope)\nof key biomarkers over time, we significantly improved model performance. Our\nfinal LightGBM model, trained on the initial wave of data, successfully\npredicted age in the subsequent wave with high accuracy ($R^2 = 0.515$ for\nmales, $R^2 = 0.498$ for females), significantly outperforming both traditional\nlinear models and other tree-based ensembles. SHAP analysis of our successful\nmodel revealed that the engineered slope features were among the most important\npredictors, highlighting that an individual's health trajectory, not just their\nstatic health snapshot, is a key determinant of biological age. Our framework\npaves the way for clinical tools that dynamically track patient health\ntrajectories, enabling early intervention and personalized prevention\nstrategies for age-related diseases.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u673a\u5668\u5b66\u4e60\u6d41\u7a0b\uff0c\u901a\u8fc7\u7eb5\u5411\u6570\u636e\u9884\u6d4b\u8870\u8001\u8f68\u8ff9\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\u3002", "motivation": "\u9884\u6d4b\u4e2a\u4f53\u8870\u8001\u8f68\u8ff9\u662f\u9884\u9632\u533b\u5b66\u548c\u751f\u7269\u4fe1\u606f\u5b66\u7684\u6838\u5fc3\u6311\u6218\uff0c\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u6355\u6349\u8870\u8001\u7684\u52a8\u6001\u7279\u6027\u3002", "method": "\u5229\u7528\u7eb5\u5411\u961f\u5217\u6570\u636e\uff082019-2020\u548c2021-2022\uff09\uff0c\u901a\u8fc7\u8bbe\u8ba1\u6355\u6349\u751f\u7269\u6807\u5fd7\u7269\u53d8\u5316\u7387\u7684\u65b0\u7279\u5f81\uff0c\u8bad\u7ec3LightGBM\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5728\u9884\u6d4b\u540e\u7eed\u65f6\u95f4\u70b9\u5e74\u9f84\u65f6\u8868\u73b0\u4f18\u5f02\uff08\u7537\u6027R\u00b2=0.515\uff0c\u5973\u6027R\u00b2=0.498\uff09\uff0c\u663e\u8457\u4f18\u4e8e\u7ebf\u6027\u6a21\u578b\u548c\u5176\u4ed6\u6811\u6a21\u578b\u3002", "conclusion": "\u52a8\u6001\u5065\u5eb7\u8f68\u8ff9\u6bd4\u9759\u6001\u5065\u5eb7\u5feb\u7167\u66f4\u80fd\u9884\u6d4b\u751f\u7269\u5e74\u9f84\uff0c\u4e3a\u4e34\u5e8a\u52a8\u6001\u8ddf\u8e2a\u548c\u4e2a\u6027\u5316\u5e72\u9884\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2508.09752", "pdf": "https://arxiv.org/pdf/2508.09752", "abs": "https://arxiv.org/abs/2508.09752", "authors": ["Jan Ma\u0142a\u015bnicki", "Kamil Ciebiera", "Mateusz Boru\u0144", "Maciej Pi\u00f3ro", "Jan Ludziejewski", "Maciej Stefaniak", "Micha\u0142 Krutul", "Sebastian Jaszczur", "Marek Cygan", "Kamil Adamczewski", "Jakub Krajewski"], "title": "$\u03bc$-Parametrization for Mixture of Experts", "categories": ["cs.LG"], "comment": null, "summary": "Recent years have seen a growing interest and adoption of LLMs, with\n$\\mu$Transfer becoming a key technique for tuning hyperparameters in\nlarge-scale training. Meanwhile, Mixture-of-Experts (MoE) has emerged as a\nleading architecture in extremely large models. However, the intersection of\nthese two advancements has remained unexplored. In this work, we derive a\n$\\mu$-Parameterization ($\\mu$P) for MoE, providing theoretical guarantees for\nfeature learning across model widths in both the router and experts. We\nempirically validate our parameterization and further investigate how scaling\nthe number of experts and granularity affects the optimal learning rate.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5c06\u03bcTransfer\u6280\u672f\u5e94\u7528\u4e8eMoE\u67b6\u6784\uff0c\u63d0\u51fa\u4e86\u03bcP\u65b9\u6cd5\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u6a21\u578b\u5bbd\u5ea6\u548c\u5b66\u4e60\u7387\u4f18\u5316\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0cLLMs\u548cMoE\u67b6\u6784\u5206\u522b\u6210\u4e3a\u91cd\u8981\u6280\u672f\uff0c\u4f46\u4e8c\u8005\u7684\u7ed3\u5408\u5c1a\u672a\u88ab\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86\u03bc-\u53c2\u6570\u5316\uff08\u03bcP\uff09\u65b9\u6cd5\uff0c\u4e3aMoE\u67b6\u6784\u4e2d\u7684\u8def\u7531\u5668\u548c\u4e13\u5bb6\u6a21\u5757\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u03bcP\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u7814\u7a76\u4e86\u4e13\u5bb6\u6570\u91cf\u548c\u7c92\u5ea6\u5bf9\u6700\u4f18\u5b66\u4e60\u7387\u7684\u5f71\u54cd\u3002", "conclusion": "\u03bcP\u65b9\u6cd5\u4e3aMoE\u67b6\u6784\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u8d85\u53c2\u6570\u4f18\u5316\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.09753", "pdf": "https://arxiv.org/pdf/2508.09753", "abs": "https://arxiv.org/abs/2508.09753", "authors": ["Zhaoyang Zhu", "Zhipeng Zeng", "Qiming Chen", "Linxiao Yang", "Peiyuan Liu", "Weiqi Chen", "Liang Sun"], "title": "TriForecaster: A Mixture of Experts Framework for Multi-Region Electric Load Forecasting with Tri-dimensional Specialization", "categories": ["cs.LG"], "comment": "11 pages, 4 figures", "summary": "Electric load forecasting is pivotal for power system operation, planning and\ndecision-making. The rise of smart grids and meters has provided more detailed\nand high-quality load data at multiple levels of granularity, from home to bus\nand cities. Motivated by similar patterns of loads across different cities in a\nprovince in eastern China, in this paper we focus on the Multi-Region Electric\nLoad Forecasting (MRELF) problem, targeting accurate short-term load\nforecasting for multiple sub-regions within a large region. We identify three\nchallenges for MRELF, including regional variation, contextual variation, and\ntemporal variation. To address them, we propose TriForecaster, a new framework\nleveraging the Mixture of Experts (MoE) approach within a Multi-Task Learning\n(MTL) paradigm to overcome these challenges. TriForecaster features RegionMixer\nand Context-Time Specializer (CTSpecializer) layers, enabling dynamic\ncooperation and specialization of expert models across regional, contextual,\nand temporal dimensions. Based on evaluation on four real-world MRELF datasets\nwith varied granularity, TriForecaster outperforms state-of-the-art models by\nachieving an average forecast error reduction of 22.4\\%, thereby demonstrating\nits flexibility and broad applicability. In particular, the deployment of\nTriForecaster on the eForecaster platform in eastern China exemplifies its\npractical utility, effectively providing city-level, short-term load forecasts\nfor 17 cities, supporting a population exceeding 110 million and daily\nelectricity usage over 100 gigawatt-hours.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faTriForecaster\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u548c\u591a\u4efb\u52a1\u5b66\u4e60\uff08MTL\uff09\u89e3\u51b3\u591a\u533a\u57df\u7535\u529b\u8d1f\u8377\u9884\u6d4b\uff08MRELF\uff09\u95ee\u9898\uff0c\u5e73\u5747\u9884\u6d4b\u8bef\u5dee\u964d\u4f4e22.4%\u3002", "motivation": "\u667a\u80fd\u7535\u7f51\u548c\u7535\u8868\u7684\u666e\u53ca\u63d0\u4f9b\u4e86\u66f4\u8be6\u7ec6\u7684\u8d1f\u8377\u6570\u636e\uff0c\u4f46\u4e0d\u540c\u533a\u57df\u7684\u8d1f\u8377\u9884\u6d4b\u9762\u4e34\u533a\u57df\u3001\u4e0a\u4e0b\u6587\u548c\u65f6\u95f4\u53d8\u5316\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faTriForecaster\u6846\u67b6\uff0c\u5305\u542bRegionMixer\u548cCTSpecializer\u5c42\uff0c\u52a8\u6001\u534f\u8c03\u4e13\u5bb6\u6a21\u578b\u5728\u533a\u57df\u3001\u4e0a\u4e0b\u6587\u548c\u65f6\u95f4\u7ef4\u5ea6\u7684\u5408\u4f5c\u4e0e\u4e13\u4e1a\u5316\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cTriForecaster\u5e73\u5747\u9884\u6d4b\u8bef\u5dee\u964d\u4f4e22.4%\uff0c\u5e76\u5728\u4e2d\u56fd\u4e1c\u90e817\u4e2a\u57ce\u5e02\u6210\u529f\u90e8\u7f72\u3002", "conclusion": "TriForecaster\u5728\u591a\u533a\u57df\u7535\u529b\u8d1f\u8377\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u7075\u6d3b\u6027\u548c\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2508.09787", "pdf": "https://arxiv.org/pdf/2508.09787", "abs": "https://arxiv.org/abs/2508.09787", "authors": ["Mauro Tucci"], "title": "Prototype Training with Dual Pseudo-Inverse and Optimized Hidden Activations", "categories": ["cs.LG", "cs.AI"], "comment": "7 pages, 1 table, reproducible, one proof", "summary": "We present Proto-PINV+H, a fast training paradigm that combines closed-form\nweight computation with gradient-based optimisation of a small set of synthetic\ninputs, soft labels, and-crucially-hidden activations. At each iteration we\nrecompute all weight matrices in closed form via two (or more)\nridge-regularised pseudo-inverse solves, while updating only the prototypes\nwith Adam. The trainable degrees of freedom are thus shifted from weight space\nto data/activation space. On MNIST (60k train, 10k test) and Fashion-MNIST (60k\ntrain, 10k test), our method reaches 97.8% and 89.3% test accuracy on the\nofficial 10k test sets, respectively, in 3.9s--4.5s using approximately 130k\ntrainable parameters and only 250 epochs on an RTX 5060 (16GB). We provide a\nmulti-layer extension (optimised activations at each hidden stage), learnable\nridge parameters, optional PCA/PLS projections, and theory linking the\ncondition number of prototype matrices to generalisation. The approach yields\nfavourable accuracy--speed--size trade-offs against ELM, random-feature ridge,\nand shallow MLPs trained by back-propagation.", "AI": {"tldr": "Proto-PINV+H\u662f\u4e00\u79cd\u5feb\u901f\u8bad\u7ec3\u8303\u5f0f\uff0c\u7ed3\u5408\u95ed\u5f0f\u6743\u91cd\u8ba1\u7b97\u548c\u68af\u5ea6\u4f18\u5316\u5c11\u91cf\u5408\u6210\u8f93\u5165\u3001\u8f6f\u6807\u7b7e\u53ca\u9690\u85cf\u6fc0\u6d3b\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u51cf\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\u6570\u91cf\u5e76\u5229\u7528\u95ed\u5f0f\u89e3\u52a0\u901f\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u95ed\u5f0f\u89e3\u8ba1\u7b97\u6743\u91cd\u77e9\u9635\uff0c\u5e76\u7528Adam\u4f18\u5316\u539f\u578b\uff08\u5408\u6210\u8f93\u5165\u3001\u8f6f\u6807\u7b7e\u548c\u9690\u85cf\u6fc0\u6d3b\uff09\uff0c\u5c06\u53ef\u8bad\u7ec3\u81ea\u7531\u5ea6\u4ece\u6743\u91cd\u7a7a\u95f4\u8f6c\u79fb\u5230\u6570\u636e/\u6fc0\u6d3b\u7a7a\u95f4\u3002", "result": "\u5728MNIST\u548cFashion-MNIST\u4e0a\u5206\u522b\u8fbe\u523097.8%\u548c89.3%\u7684\u6d4b\u8bd5\u51c6\u786e\u7387\uff0c\u8bad\u7ec3\u65f6\u95f4\u4ec5\u97003.9-4.5\u79d2\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u3001\u901f\u5ea6\u548c\u6a21\u578b\u5927\u5c0f\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u4f18\u4e8eELM\u3001\u968f\u673a\u7279\u5f81\u5cad\u56de\u5f52\u548c\u6d45\u5c42MLP\u3002"}}
{"id": "2508.09792", "pdf": "https://arxiv.org/pdf/2508.09792", "abs": "https://arxiv.org/abs/2508.09792", "authors": ["Wouter M. Kouw"], "title": "Bayesian autoregression to optimize temporal Mat\u00e9rn kernel Gaussian process hyperparameters", "categories": ["cs.LG", "eess.SP", "stat.ML"], "comment": "9 pages, 4 figures, accepted to the International Conference on\n  Probabilistic Numerics 2025", "summary": "Gaussian processes are important models in the field of probabilistic\nnumerics. We present a procedure for optimizing Mat\\'ern kernel temporal\nGaussian processes with respect to the kernel covariance function's\nhyperparameters. It is based on casting the optimization problem as a recursive\nBayesian estimation procedure for the parameters of an autoregressive model. We\ndemonstrate that the proposed procedure outperforms maximizing the marginal\nlikelihood as well as Hamiltonian Monte Carlo sampling, both in terms of\nruntime and ultimate root mean square error in Gaussian process regression.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316Mat\u00e9rn\u6838\u65f6\u95f4\u9ad8\u65af\u8fc7\u7a0b\u8d85\u53c2\u6570\u7684\u65b9\u6cd5\uff0c\u57fa\u4e8e\u9012\u5f52\u8d1d\u53f6\u65af\u4f30\u8ba1\uff0c\u6027\u80fd\u4f18\u4e8e\u8fb9\u9645\u4f3c\u7136\u6700\u5927\u5316\u548c\u54c8\u5bc6\u987f\u8499\u7279\u5361\u6d1b\u91c7\u6837\u3002", "motivation": "\u9ad8\u65af\u8fc7\u7a0b\u5728\u6982\u7387\u6570\u503c\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u8d85\u53c2\u6570\u4f18\u5316\u65b9\u6cd5\u6548\u7387\u4e0d\u8db3\u3002", "method": "\u5c06\u8d85\u53c2\u6570\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u4e3a\u81ea\u56de\u5f52\u6a21\u578b\u53c2\u6570\u7684\u9012\u5f52\u8d1d\u53f6\u65af\u4f30\u8ba1\u3002", "result": "\u5728\u8fd0\u884c\u65f6\u95f4\u548c\u5747\u65b9\u6839\u8bef\u5dee\u4e0a\u4f18\u4e8e\u8fb9\u9645\u4f3c\u7136\u6700\u5927\u5316\u548c\u54c8\u5bc6\u987f\u8499\u7279\u5361\u6d1b\u91c7\u6837\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u9002\u7528\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u3002"}}
{"id": "2508.09810", "pdf": "https://arxiv.org/pdf/2508.09810", "abs": "https://arxiv.org/abs/2508.09810", "authors": ["Qi Gan", "Stephan Cl\u00e9men\u00e7on", "Moun\u00eem A. El-Yacoubi", "Sao Mai Nguyen", "Eric Fenaux", "Ons Jelassi"], "title": "Feature Impact Analysis on Top Long-Jump Performances with Quantile Random Forest and Explainable AI Techniques", "categories": ["cs.LG", "stat.AP"], "comment": "15 pages, 6 figures", "summary": "Biomechanical features have become important indicators for evaluating\nathletes' techniques. Traditionally, experts propose significant features and\nevaluate them using physics equations. However, the complexity of the human\nbody and its movements makes it challenging to explicitly analyze the\nrelationships between some features and athletes' final performance. With\nadvancements in modern machine learning and statistics, data analytics methods\nhave gained increasing importance in sports analytics. In this study, we\nleverage machine learning models to analyze expert-proposed biomechanical\nfeatures from the finals of long jump competitions in the World Championships.\nThe objectives of the analysis include identifying the most important features\ncontributing to top-performing jumps and exploring the combined effects of\nthese key features. Using quantile regression, we model the relationship\nbetween the biomechanical feature set and the target variable (effective\ndistance), with a particular focus on elite-level jumps. To interpret the\nmodel, we apply SHapley Additive exPlanations (SHAP) alongside Partial\nDependence Plots (PDPs) and Individual Conditional Expectation (ICE) plots. The\nfindings reveal that, beyond the well-documented velocity-related features,\nspecific technical aspects also play a pivotal role. For male athletes, the\nangle of the knee of the supporting leg before take-off is identified as a key\nfactor for achieving top 10% performance in our dataset, with angles greater\nthan 169{\\deg}contributing significantly to jump performance. In contrast, for\nfemale athletes, the landing pose and approach step technique emerge as the\nmost critical features influencing top 10% performances, alongside velocity.\nThis study establishes a framework for analyzing the impact of various features\non athletic performance, with a particular emphasis on top-performing events.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528\u673a\u5668\u5b66\u4e60\u5206\u6790\u8df3\u8fdc\u6bd4\u8d5b\u4e2d\u7684\u751f\u7269\u529b\u5b66\u7279\u5f81\uff0c\u8bc6\u522b\u5173\u952e\u7279\u5f81\u53ca\u5176\u7ec4\u5408\u6548\u5e94\uff0c\u53d1\u73b0\u7537\u5973\u8fd0\u52a8\u5458\u7684\u5173\u952e\u6280\u672f\u5dee\u5f02\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u660e\u786e\u5206\u6790\u751f\u7269\u529b\u5b66\u7279\u5f81\u4e0e\u8fd0\u52a8\u5458\u8868\u73b0\u7684\u5173\u7cfb\uff0c\u73b0\u4ee3\u6570\u636e\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u4e3a\u6b64\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002", "method": "\u4f7f\u7528\u5206\u4f4d\u6570\u56de\u5f52\u5efa\u6a21\u751f\u7269\u529b\u5b66\u7279\u5f81\u4e0e\u8df3\u8fdc\u6210\u7ee9\u7684\u5173\u7cfb\uff0c\u5e76\u7ed3\u5408SHAP\u3001PDP\u548cICE\u56fe\u89e3\u91ca\u6a21\u578b\u3002", "result": "\u7537\u6027\u8fd0\u52a8\u5458\u7684\u5173\u952e\u7279\u5f81\u662f\u8d77\u8df3\u524d\u652f\u6491\u817f\u819d\u76d6\u89d2\u5ea6\uff08>169\u00b0\uff09\uff0c\u5973\u6027\u8fd0\u52a8\u5458\u7684\u5173\u952e\u7279\u5f81\u662f\u7740\u9646\u59ff\u52bf\u548c\u52a9\u8dd1\u6280\u672f\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5206\u6790\u8fd0\u52a8\u8868\u73b0\u7279\u5f81\u63d0\u4f9b\u4e86\u6846\u67b6\uff0c\u7279\u522b\u5173\u6ce8\u9876\u7ea7\u8d5b\u4e8b\u4e2d\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2508.09820", "pdf": "https://arxiv.org/pdf/2508.09820", "abs": "https://arxiv.org/abs/2508.09820", "authors": ["Dake Bu", "Wei Huang", "Andi Han", "Atsushi Nitanda", "Qingfu Zhang", "Hau-San Wong", "Taiji Suzuki"], "title": "Provable In-Context Vector Arithmetic via Retrieving Task Concepts", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by the 42nd International Conference on Machine Learning\n  (ICML 2025)", "summary": "In-context learning (ICL) has garnered significant attention for its ability\nto grasp functions/tasks from demonstrations. Recent studies suggest the\npresence of a latent task/function vector in LLMs during ICL. Merullo et al.\n(2024) showed that LLMs leverage this vector alongside the residual stream for\nWord2Vec-like vector arithmetic, solving factual-recall ICL tasks.\nAdditionally, recent work empirically highlighted the key role of\nQuestion-Answer data in enhancing factual-recall capabilities. Despite these\ninsights, a theoretical explanation remains elusive. To move one step forward,\nwe propose a theoretical framework building on empirically grounded\nhierarchical concept modeling. We develop an optimization theory, showing how\nnonlinear residual transformers trained via gradient descent on cross-entropy\nloss perform factual-recall ICL tasks via vector arithmetic. We prove 0-1 loss\nconvergence and show the strong generalization, including robustness to concept\nrecombination and distribution shifts. These results elucidate the advantages\nof transformers over static embedding predecessors. Empirical simulations\ncorroborate our theoretical insights.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7406\u8bba\u6846\u67b6\uff0c\u89e3\u91ca\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u4e2d\u5982\u4f55\u901a\u8fc7\u5411\u91cf\u7b97\u672f\u5b8c\u6210\u4e8b\u5b9e\u56de\u5fc6\u4efb\u52a1\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u7814\u7a76\u8868\u660eLLMs\u5728ICL\u4e2d\u5b58\u5728\u6f5c\u5728\u4efb\u52a1\u5411\u91cf\u5e76\u901a\u8fc7\u5411\u91cf\u7b97\u672f\u89e3\u51b3\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u7406\u8bba\u89e3\u91ca\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u57fa\u4e8e\u5c42\u6b21\u6982\u5ff5\u5efa\u6a21\uff0c\u63d0\u51fa\u4f18\u5316\u7406\u8bba\uff0c\u5206\u6790\u975e\u7ebf\u6027\u6b8b\u5dee\u53d8\u6362\u5668\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u548c\u4ea4\u53c9\u71b5\u635f\u5931\u5b8c\u6210\u4e8b\u5b9e\u56de\u5fc6\u4efb\u52a1\u7684\u673a\u5236\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e860-1\u635f\u5931\u7684\u6536\u655b\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u6a21\u578b\u5bf9\u6982\u5ff5\u91cd\u7ec4\u548c\u5206\u5e03\u53d8\u5316\u7684\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u53d8\u6362\u5668\u4f18\u4e8e\u9759\u6001\u5d4c\u5165\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002"}}
{"id": "2508.09826", "pdf": "https://arxiv.org/pdf/2508.09826", "abs": "https://arxiv.org/abs/2508.09826", "authors": ["Abinay Reddy Naini", "Fernando Diaz", "Carlos Busso"], "title": "RankList -- A Listwise Preference Learning Framework for Predicting Subjective Preferences", "categories": ["cs.LG"], "comment": "12 pages, 2 figures", "summary": "Preference learning has gained significant attention in tasks involving\nsubjective human judgments, such as \\emph{speech emotion recognition} (SER) and\nimage aesthetic assessment. While pairwise frameworks such as RankNet offer\nrobust modeling of relative preferences, they are inherently limited to local\ncomparisons and struggle to capture global ranking consistency. To address\nthese limitations, we propose RankList, a novel listwise preference learning\nframework that generalizes RankNet to structured list-level supervision. Our\nformulation explicitly models local and non-local ranking constraints within a\nprobabilistic framework. The paper introduces a log-sum-exp approximation to\nimprove training efficiency. We further extend RankList with skip-wise\ncomparisons, enabling progressive exposure to complex list structures and\nenhancing global ranking fidelity. Extensive experiments demonstrate the\nsuperiority of our method across diverse modalities. On benchmark SER datasets\n(MSP-Podcast, IEMOCAP, BIIC Podcast), RankList achieves consistent improvements\nin Kendall's Tau and ranking accuracy compared to standard listwise baselines.\nWe also validate our approach on aesthetic image ranking using the Artistic\nImage Aesthetics dataset, highlighting its broad applicability. Through\nablation and cross-domain studies, we show that RankList not only improves\nin-domain ranking but also generalizes better across datasets. Our framework\noffers a unified, extensible approach for modeling ordered preferences in\nsubjective learning scenarios.", "AI": {"tldr": "RankList\u662f\u4e00\u79cd\u65b0\u9896\u7684\u5217\u8868\u5f0f\u504f\u597d\u5b66\u4e60\u6846\u67b6\uff0c\u6269\u5c55\u4e86RankNet\uff0c\u901a\u8fc7\u5168\u5c40\u6392\u540d\u4e00\u81f4\u6027\u5efa\u6a21\u548c\u8df3\u8fc7\u5f0f\u6bd4\u8f83\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3RankNet\u7b49\u6210\u5bf9\u6846\u67b6\u5728\u5168\u5c40\u6392\u540d\u4e00\u81f4\u6027\u4e0a\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faRankList\u6846\u67b6\uff0c\u7ed3\u5408\u5c40\u90e8\u548c\u975e\u5c40\u90e8\u6392\u540d\u7ea6\u675f\uff0c\u4f7f\u7528log-sum-exp\u8fd1\u4f3c\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\uff0c\u5e76\u5f15\u5165\u8df3\u8fc7\u5f0f\u6bd4\u8f83\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08MSP-Podcast\u3001IEMOCAP\u7b49\uff09\u4e0a\uff0cRankList\u5728Kendall's Tau\u548c\u6392\u540d\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "RankList\u4e3a\u4e3b\u89c2\u5b66\u4e60\u573a\u666f\u63d0\u4f9b\u4e86\u4e00\u79cd\u7edf\u4e00\u4e14\u53ef\u6269\u5c55\u7684\u504f\u597d\u5efa\u6a21\u65b9\u6cd5\u3002"}}
{"id": "2508.09866", "pdf": "https://arxiv.org/pdf/2508.09866", "abs": "https://arxiv.org/abs/2508.09866", "authors": ["Siyuan Wen", "Meng Zhang", "Yang Yang", "Ningning Ding"], "title": "FedShard: Federated Unlearning with Efficiency Fairness and Performance Fairness", "categories": ["cs.LG"], "comment": null, "summary": "To protect clients' right to be forgotten in federated learning, federated\nunlearning aims to remove the data contribution of leaving clients from the\nglobal learned model. While current studies mainly focused on enhancing\nunlearning efficiency and effectiveness, the crucial aspects of efficiency\nfairness and performance fairness among decentralized clients during unlearning\nhave remained largely unexplored. In this study, we introduce FedShard, the\nfirst federated unlearning algorithm designed to concurrently guarantee both\nefficiency fairness and performance fairness. FedShard adaptively addresses the\nchallenges introduced by dilemmas among convergence, unlearning efficiency, and\nunlearning fairness. Furthermore, we propose two novel metrics to\nquantitatively assess the fairness of unlearning algorithms, which we prove to\nsatisfy well-known properties in other existing fairness measurements. Our\ntheoretical analysis and numerical evaluation validate FedShard's fairness in\nterms of both unlearning performance and efficiency. We demonstrate that\nFedShard mitigates unfairness risks such as cascaded leaving and poisoning\nattacks and realizes more balanced unlearning costs among clients. Experimental\nresults indicate that FedShard accelerates the data unlearning process 1.3-6.2\ntimes faster than retraining from scratch and 4.9 times faster than the\nstate-of-the-art exact unlearning methods.", "AI": {"tldr": "FedShard\u662f\u4e00\u79cd\u8054\u90a6\u5b66\u4e60\u9057\u5fd8\u7b97\u6cd5\uff0c\u9996\u6b21\u540c\u65f6\u4fdd\u8bc1\u6548\u7387\u516c\u5e73\u6027\u548c\u6027\u80fd\u516c\u5e73\u6027\uff0c\u89e3\u51b3\u4e86\u6536\u655b\u3001\u9057\u5fd8\u6548\u7387\u548c\u516c\u5e73\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u516c\u5e73\u6027\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u5f53\u524d\u8054\u90a6\u9057\u5fd8\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6548\u7387\u548c\u6709\u6548\u6027\uff0c\u800c\u5ffd\u7565\u4e86\u53bb\u4e2d\u5fc3\u5316\u5ba2\u6237\u5728\u9057\u5fd8\u8fc7\u7a0b\u4e2d\u7684\u6548\u7387\u516c\u5e73\u6027\u548c\u6027\u80fd\u516c\u5e73\u6027\u3002", "method": "\u63d0\u51faFedShard\u7b97\u6cd5\uff0c\u81ea\u9002\u5e94\u89e3\u51b3\u6536\u655b\u3001\u9057\u5fd8\u6548\u7387\u548c\u516c\u5e73\u6027\u4e4b\u95f4\u7684\u56f0\u5883\uff0c\u5e76\u8bbe\u8ba1\u4e24\u79cd\u65b0\u6307\u6807\u91cf\u5316\u516c\u5e73\u6027\u3002", "result": "FedShard\u5728\u9057\u5fd8\u6027\u80fd\u548c\u6548\u7387\u4e0a\u5747\u8868\u73b0\u516c\u5e73\uff0c\u80fd\u62b5\u5fa1\u7ea7\u8054\u79bb\u5f00\u548c\u6295\u6bd2\u653b\u51fb\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u9057\u5fd8\u901f\u5ea6\u6bd4\u4ece\u5934\u8bad\u7ec3\u5feb1.3-6.2\u500d\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u5feb4.9\u500d\u3002", "conclusion": "FedShard\u9996\u6b21\u5b9e\u73b0\u4e86\u8054\u90a6\u9057\u5fd8\u4e2d\u7684\u53cc\u91cd\u516c\u5e73\u6027\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u5e73\u8861\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09883", "pdf": "https://arxiv.org/pdf/2508.09883", "abs": "https://arxiv.org/abs/2508.09883", "authors": ["Xiaojun Wu", "Xiaoguang Jiang", "Huiyang Li", "Jucai Zhai", "Dengfeng Liu", "Qiaobo Hao", "Huang Liu", "Zhiguo Yang", "Ji Xie", "Ninglun Gu", "Jin Yang", "Kailai Zhang", "Yelun Bao", "Jun Wang"], "title": "Beyond Scaling Law: A Data-Efficient Distillation Framework for Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) demonstrate remarkable reasoning capabilities in\ntasks such as algorithmic coding and mathematical problem-solving. Recent\nmethods have improved reasoning through expanded corpus and multistage training\ncombining reinforcement learning and supervised fine-tuning. Although some\nmethods suggest that small but targeted dataset can incentivize reasoning via\nonly distillation, a reasoning scaling laws is still taking shape, increasing\ncomputational costs. To address this, we propose a data-efficient distillation\nframework (DED) that optimizes the Pareto frontier of reasoning distillation.\nInspired by the on-policy learning and diverse roll-out strategies of\nreinforcement learning, the key idea of our approach is threefold: (1) We\nidentify that benchmark scores alone do not determine an effective teacher\nmodel. Through comprehensive comparisons of leading reasoning LLMs, we develop\na method to select an optimal teacher model. (2) While scaling distillation can\nenhance reasoning, it often degrades out-of-domain performance. A carefully\ncurated, smaller corpus achieves a balanced trade-off between in-domain and\nout-of-domain capabilities. (3) Diverse reasoning trajectories encourage the\nstudent model to develop robust reasoning skills. We validate our method\nthrough evaluations on mathematical reasoning (AIME 2024/2025, MATH-500) and\ncode generation (LiveCodeBench), achieving state-of-the-art results with only\n0.8k carefully curated examples, bypassing the need for extensive scaling. Our\nsystematic analysis demonstrates that DED outperforms existing methods by\nconsidering factors beyond superficial hardness, token length, or teacher model\ncapability. This work offers a practical and efficient pathway to advanced\nreasoning while preserving general capabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9ad8\u6548\u84b8\u998f\u6846\u67b6\uff08DED\uff09\uff0c\u901a\u8fc7\u4f18\u5316\u63a8\u7406\u84b8\u998f\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u5b9e\u73b0\u4e86\u5728\u5c11\u91cf\u7cbe\u9009\u6570\u636e\u4e0b\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u6269\u5c55\u8bed\u6599\u5e93\u548c\u591a\u9636\u6bb5\u8bad\u7ec3\u63d0\u5347\u4e86\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u63a8\u7406\u6269\u5c55\u5b9a\u5f8b\u4ecd\u589e\u52a0\u4e86\u8ba1\u7b97\u6210\u672c\u3002DED\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u4f9b\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u63a8\u7406\u80fd\u529b\u63d0\u5347\u9014\u5f84\u3002", "method": "DED\u6846\u67b6\u5305\u62ec\u4e09\u4e2a\u5173\u952e\u70b9\uff1a(1) \u901a\u8fc7\u7efc\u5408\u6bd4\u8f83\u9009\u62e9\u6700\u4f18\u6559\u5e08\u6a21\u578b\uff1b(2) \u4f7f\u7528\u7cbe\u9009\u5c0f\u8bed\u6599\u5e93\u5e73\u8861\u9886\u57df\u5185\u5916\u6027\u80fd\uff1b(3) \u591a\u6837\u5316\u7684\u63a8\u7406\u8f68\u8ff9\u63d0\u5347\u5b66\u751f\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\uff08AIME 2024/2025, MATH-500\uff09\u548c\u4ee3\u7801\u751f\u6210\uff08LiveCodeBench\uff09\u4efb\u52a1\u4e2d\uff0c\u4ec5\u75280.8k\u7cbe\u9009\u6570\u636e\u5373\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "DED\u901a\u8fc7\u8d85\u8d8a\u8868\u9762\u96be\u5ea6\u3001\u6807\u8bb0\u957f\u5ea6\u6216\u6559\u5e08\u6a21\u578b\u80fd\u529b\u7684\u56e0\u7d20\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u63a8\u7406\u80fd\u529b\u63d0\u5347\u65b9\u6cd5\u3002"}}
{"id": "2508.09888", "pdf": "https://arxiv.org/pdf/2508.09888", "abs": "https://arxiv.org/abs/2508.09888", "authors": ["Viacheslav Barkov", "Jonas Schmidinger", "Robin Gebbers", "Martin Atzmueller"], "title": "Modern Neural Networks for Small Tabular Datasets: The New Default for Field-Scale Digital Soil Mapping?", "categories": ["cs.LG"], "comment": null, "summary": "In the field of pedometrics, tabular machine learning is the predominant\nmethod for predicting soil properties from remote and proximal soil sensing\ndata, forming a central component of digital soil mapping. At the field-scale,\nthis predictive soil modeling (PSM) task is typically constrained by small\ntraining sample sizes and high feature-to-sample ratios in soil spectroscopy.\nTraditionally, these conditions have proven challenging for conventional deep\nlearning methods. Classical machine learning algorithms, particularly\ntree-based models like Random Forest and linear models such as Partial Least\nSquares Regression, have long been the default choice for field-scale PSM.\nRecent advances in artificial neural networks (ANN) for tabular data challenge\nthis view, yet their suitability for field-scale PSM has not been proven. We\nintroduce a comprehensive benchmark that evaluates state-of-the-art ANN\narchitectures, including the latest multilayer perceptron (MLP)-based models\n(TabM, RealMLP), attention-based transformer variants (FT-Transformer,\nExcelFormer, T2G-Former, AMFormer), retrieval-augmented approaches (TabR,\nModernNCA), and an in-context learning foundation model (TabPFN). Our\nevaluation encompasses 31 field- and farm-scale datasets containing 30 to 460\nsamples and three critical soil properties: soil organic matter or soil organic\ncarbon, pH, and clay content. Our results reveal that modern ANNs consistently\noutperform classical methods on the majority of tasks, demonstrating that deep\nlearning has matured sufficiently to overcome the long-standing dominance of\nclassical machine learning for PSM. Notably, TabPFN delivers the strongest\noverall performance, showing robustness across varying conditions. We therefore\nrecommend the adoption of modern ANNs for field-scale PSM and propose TabPFN as\nthe new default choice in the toolkit of every pedometrician.", "AI": {"tldr": "\u73b0\u4ee3\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff08ANN\uff09\u5728\u571f\u58e4\u5c5e\u6027\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5c24\u5176\u662fTabPFN\u6a21\u578b\u3002", "motivation": "\u9a8c\u8bc1\u73b0\u4ee3ANN\u5728\u7530\u95f4\u5c3a\u5ea6\u571f\u58e4\u9884\u6d4b\u5efa\u6a21\uff08PSM\uff09\u4e2d\u7684\u9002\u7528\u6027\uff0c\u6311\u6218\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7684\u4e3b\u5bfc\u5730\u4f4d\u3002", "method": "\u901a\u8fc731\u4e2a\u7530\u95f4\u6570\u636e\u96c6\u8bc4\u4f30\u591a\u79cdANN\u67b6\u6784\uff08\u5982TabM\u3001RealMLP\u3001FT-Transformer\u7b49\uff09\u4e0e\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u968f\u673a\u68ee\u6797\u3001\u504f\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\uff09\u7684\u6027\u80fd\u3002", "result": "\u73b0\u4ee3ANN\u5728\u591a\u6570\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\uff0cTabPFN\u8868\u73b0\u6700\u7a33\u5065\u3002", "conclusion": "\u63a8\u8350\u73b0\u4ee3ANN\uff08\u5c24\u5176\u662fTabPFN\uff09\u4f5c\u4e3a\u7530\u95f4\u5c3a\u5ea6PSM\u7684\u65b0\u6807\u51c6\u5de5\u5177\u3002"}}
{"id": "2508.09894", "pdf": "https://arxiv.org/pdf/2508.09894", "abs": "https://arxiv.org/abs/2508.09894", "authors": ["Simon Kl\u00fcttermann", "Emmanuel M\u00fcller"], "title": "Rare anomalies require large datasets: About proving the existence of anomalies", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 8 figures", "summary": "Detecting whether any anomalies exist within a dataset is crucial for\neffective anomaly detection, yet it remains surprisingly underexplored in\nanomaly detection literature. This paper presents a comprehensive study that\naddresses the fundamental question: When can we conclusively determine that\nanomalies are present? Through extensive experimentation involving over three\nmillion statistical tests across various anomaly detection tasks and\nalgorithms, we identify a relationship between the dataset size, contamination\nrate, and an algorithm-dependent constant $ \\alpha_{\\text{algo}} $. Our results\ndemonstrate that, for an unlabeled dataset of size $ N $ and contamination rate\n$ \\nu $, the condition $ N \\ge \\frac{\\alpha_{\\text{algo}}}{\\nu^2} $ represents\na lower bound on the number of samples required to confirm anomaly existence.\nThis threshold implies a limit to how rare anomalies can be before proving\ntheir existence becomes infeasible.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u786e\u5b9a\u6570\u636e\u96c6\u4e2d\u662f\u5426\u5b58\u5728\u5f02\u5e38\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6570\u636e\u96c6\u5927\u5c0f\u3001\u6c61\u67d3\u7387\u548c\u7b97\u6cd5\u5e38\u6570\u7684\u4e0b\u9650\u6761\u4ef6\u3002", "motivation": "\u5f02\u5e38\u68c0\u6d4b\u4e2d\u786e\u8ba4\u5f02\u5e38\u5b58\u5728\u7684\u57fa\u7840\u95ee\u9898\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u8d85\u8fc7\u4e09\u767e\u4e07\u6b21\u7edf\u8ba1\u6d4b\u8bd5\uff0c\u5206\u6790\u6570\u636e\u96c6\u5927\u5c0f\u3001\u6c61\u67d3\u7387\u4e0e\u7b97\u6cd5\u5e38\u6570\u03b1_algo\u7684\u5173\u7cfb\u3002", "result": "\u53d1\u73b0N \u2265 \u03b1_algo/\u03bd\u00b2\u662f\u786e\u8ba4\u5f02\u5e38\u5b58\u5728\u7684\u6837\u672c\u6570\u91cf\u4e0b\u9650\uff0c\u63ed\u793a\u4e86\u5f02\u5e38\u7a00\u6709\u6027\u7684\u6781\u9650\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f02\u5e38\u68c0\u6d4b\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u660e\u786e\u4e86\u786e\u8ba4\u5f02\u5e38\u5b58\u5728\u7684\u6761\u4ef6\u9650\u5236\u3002"}}
{"id": "2508.09904", "pdf": "https://arxiv.org/pdf/2508.09904", "abs": "https://arxiv.org/abs/2508.09904", "authors": ["Arjun Ashok", "Andrew Robert Williams", "Vincent Zhihao Zheng", "Irina Rish", "Nicolas Chapados", "\u00c9tienne Marcotte", "Valentina Zantedeschi", "Alexandre Drouin"], "title": "Beyond Na\u00efve Prompting: Strategies for Improved Zero-shot Context-aided Forecasting with LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Forecasting in real-world settings requires models to integrate not only\nhistorical data but also relevant contextual information, often available in\ntextual form. While recent work has shown that large language models (LLMs) can\nbe effective context-aided forecasters via na\\\"ive direct prompting, their full\npotential remains underexplored. We address this gap with 4 strategies,\nproviding new insights into the zero-shot capabilities of LLMs in this setting.\nReDP improves interpretability by eliciting explicit reasoning traces, allowing\nus to assess the model's reasoning over the context independently from its\nforecast accuracy. CorDP leverages LLMs solely to refine existing forecasts\nwith context, enhancing their applicability in real-world forecasting\npipelines. IC-DP proposes embedding historical examples of context-aided\nforecasting tasks in the prompt, substantially improving accuracy even for the\nlargest models. Finally, RouteDP optimizes resource efficiency by using LLMs to\nestimate task difficulty, and routing the most challenging tasks to larger\nmodels. Evaluated on different kinds of context-aided forecasting tasks from\nthe CiK benchmark, our strategies demonstrate distinct benefits over na\\\"ive\nprompting across LLMs of different sizes and families. These results open the\ndoor to further simple yet effective improvements in LLM-based context-aided\nforecasting.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u56db\u79cd\u7b56\u7565\uff08ReDP\u3001CorDP\u3001IC-DP\u3001RouteDP\uff09\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e0a\u4e0b\u6587\u8f85\u52a9\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u96f6\u6837\u672c\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u6bd4\u76f4\u63a5\u63d0\u793a\u66f4\u4f18\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4ec5\u901a\u8fc7\u76f4\u63a5\u63d0\u793a\u5229\u7528LLMs\u8fdb\u884c\u4e0a\u4e0b\u6587\u8f85\u52a9\u9884\u6d4b\uff0c\u672a\u80fd\u5145\u5206\u53d1\u6325\u5176\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u56db\u79cd\u7b56\u7565\uff1aReDP\uff08\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\uff09\u3001CorDP\uff08\u4f18\u5316\u73b0\u6709\u9884\u6d4b\uff09\u3001IC-DP\uff08\u5d4c\u5165\u5386\u53f2\u793a\u4f8b\uff09\u3001RouteDP\uff08\u4efb\u52a1\u8def\u7531\u4f18\u5316\uff09\u3002", "result": "\u5728CiK\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8fd9\u4e9b\u7b56\u7565\u5728\u4e0d\u540c\u89c4\u6a21\u548c\u5bb6\u65cf\u7684LLMs\u4e0a\u5747\u4f18\u4e8e\u76f4\u63a5\u63d0\u793a\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u4e9b\u7b80\u5355\u800c\u6709\u6548\u7684\u7b56\u7565\u4e3aLLM\u5728\u4e0a\u4e0b\u6587\u8f85\u52a9\u9884\u6d4b\u4e2d\u7684\u8fdb\u4e00\u6b65\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2508.09922", "pdf": "https://arxiv.org/pdf/2508.09922", "abs": "https://arxiv.org/abs/2508.09922", "authors": ["Bilal Faye", "Hanane Azzag", "Mustapha Lebbah"], "title": "Prototype-Guided Diffusion: Visual Conditioning without External Memory", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion models have emerged as a leading framework for high-quality image\ngeneration, offering stable training and strong performance across diverse\ndomains. However, they remain computationally intensive, particularly during\nthe iterative denoising process. Latent-space models like Stable Diffusion\nalleviate some of this cost by operating in compressed representations, though\nat the expense of fine-grained detail. More recent approaches such as\nRetrieval-Augmented Diffusion Models (RDM) address efficiency by conditioning\ndenoising on similar examples retrieved from large external memory banks. While\neffective, these methods introduce drawbacks: they require costly storage and\nretrieval infrastructure, depend on static vision-language models like CLIP for\nsimilarity, and lack adaptability during training. We propose the Prototype\nDiffusion Model (PDM), a method that integrates prototype learning directly\ninto the diffusion process for efficient and adaptive visual conditioning -\nwithout external memory. Instead of retrieving reference samples, PDM\nconstructs a dynamic set of compact visual prototypes from clean image features\nusing contrastive learning. These prototypes guide the denoising steps by\naligning noisy representations with semantically relevant visual patterns,\nenabling efficient generation with strong semantic grounding. Experiments show\nthat PDM maintains high generation quality while reducing computational and\nstorage overhead, offering a scalable alternative to retrieval-based\nconditioning in diffusion models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u539f\u578b\u6269\u6563\u6a21\u578b\uff08PDM\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6269\u6563\u8fc7\u7a0b\u4e2d\u76f4\u63a5\u96c6\u6210\u539f\u578b\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u81ea\u9002\u5e94\u7684\u89c6\u89c9\u6761\u4ef6\u751f\u6210\uff0c\u65e0\u9700\u5916\u90e8\u5b58\u50a8\u3002", "motivation": "\u5f53\u524d\u6269\u6563\u6a21\u578b\u5728\u9ad8\u8d28\u91cf\u56fe\u50cf\u751f\u6210\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5c24\u5176\u662f\u8fed\u4ee3\u53bb\u566a\u8fc7\u7a0b\u3002\u73b0\u6709\u65b9\u6cd5\u5982RDM\u867d\u63d0\u5347\u6548\u7387\uff0c\u4f46\u4f9d\u8d56\u5916\u90e8\u5b58\u50a8\u548c\u68c0\u7d22\u57fa\u7840\u8bbe\u65bd\uff0c\u4e14\u7f3a\u4e4f\u8bad\u7ec3\u9002\u5e94\u6027\u3002", "method": "PDM\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u4ece\u5e72\u51c0\u56fe\u50cf\u7279\u5f81\u4e2d\u6784\u5efa\u52a8\u6001\u7d27\u51d1\u89c6\u89c9\u539f\u578b\u96c6\uff0c\u8fd9\u4e9b\u539f\u578b\u901a\u8fc7\u8bed\u4e49\u5bf9\u9f50\u5f15\u5bfc\u53bb\u566a\u6b65\u9aa4\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPDM\u5728\u4fdd\u6301\u9ad8\u8d28\u91cf\u751f\u6210\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u5b58\u50a8\u5f00\u9500\u3002", "conclusion": "PDM\u4e3a\u6269\u6563\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u68c0\u7d22\u6761\u4ef6\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2508.09925", "pdf": "https://arxiv.org/pdf/2508.09925", "abs": "https://arxiv.org/abs/2508.09925", "authors": ["Matteo Pinna", "Andrea Ceni", "Claudio Gallicchio"], "title": "Residual Reservoir Memory Networks", "categories": ["cs.LG", "cs.AI", "I.2.6"], "comment": "7 pages, 6 figures, accepted at IJCNN 2025", "summary": "We introduce a novel class of untrained Recurrent Neural Networks (RNNs)\nwithin the Reservoir Computing (RC) paradigm, called Residual Reservoir Memory\nNetworks (ResRMNs). ResRMN combines a linear memory reservoir with a non-linear\nreservoir, where the latter is based on residual orthogonal connections along\nthe temporal dimension for enhanced long-term propagation of the input. The\nresulting reservoir state dynamics are studied through the lens of linear\nstability analysis, and we investigate diverse configurations for the temporal\nresidual connections. The proposed approach is empirically assessed on\ntime-series and pixel-level 1-D classification tasks. Our experimental results\nhighlight the advantages of the proposed approach over other conventional RC\nmodels.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u672a\u8bad\u7ec3\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edcResRMN\uff0c\u7ed3\u5408\u7ebf\u6027\u8bb0\u5fc6\u5e93\u548c\u975e\u7ebf\u6027\u5e93\uff0c\u901a\u8fc7\u6b8b\u5dee\u6b63\u4ea4\u8fde\u63a5\u589e\u5f3a\u957f\u671f\u8f93\u5165\u4f20\u64ad\u3002\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u4f20\u7edfRC\u6a21\u578b\u3002", "motivation": "\u4f20\u7edfRC\u6a21\u578b\u5728\u957f\u671f\u8f93\u5165\u4f20\u64ad\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0cResRMN\u901a\u8fc7\u6b8b\u5dee\u6b63\u4ea4\u8fde\u63a5\u6539\u8fdb\u8fd9\u4e00\u95ee\u9898\u3002", "method": "ResRMN\u7ed3\u5408\u7ebf\u6027\u8bb0\u5fc6\u5e93\u548c\u975e\u7ebf\u6027\u5e93\uff0c\u5229\u7528\u6b8b\u5dee\u6b63\u4ea4\u8fde\u63a5\u4f18\u5316\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u7684\u4f20\u64ad\uff0c\u5e76\u901a\u8fc7\u7ebf\u6027\u7a33\u5b9a\u6027\u5206\u6790\u7814\u7a76\u52a8\u6001\u3002", "result": "\u5728\u65f6\u95f4\u5e8f\u5217\u548c\u50cf\u7d20\u7ea71-D\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cResRMN\u8868\u73b0\u4f18\u4e8e\u4f20\u7edfRC\u6a21\u578b\u3002", "conclusion": "ResRMN\u901a\u8fc7\u6b8b\u5dee\u6b63\u4ea4\u8fde\u63a5\u663e\u8457\u63d0\u5347\u4e86\u957f\u671f\u8f93\u5165\u4f20\u64ad\u80fd\u529b\uff0c\u4e3aRC\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u4f18\u5316\u65b9\u5411\u3002"}}
{"id": "2508.09968", "pdf": "https://arxiv.org/pdf/2508.09968", "abs": "https://arxiv.org/abs/2508.09968", "authors": ["Luca Eyring", "Shyamgopal Karthik", "Alexey Dosovitskiy", "Nataniel Ruiz", "Zeynep Akata"], "title": "Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models", "categories": ["cs.LG", "cs.CV"], "comment": "Project page: https://noisehypernetworks.github.io/", "summary": "The new paradigm of test-time scaling has yielded remarkable breakthroughs in\nLarge Language Models (LLMs) (e.g. reasoning models) and in generative vision\nmodels, allowing models to allocate additional computation during inference to\neffectively tackle increasingly complex problems. Despite the improvements of\nthis approach, an important limitation emerges: the substantial increase in\ncomputation time makes the process slow and impractical for many applications.\nGiven the success of this paradigm and its growing usage, we seek to preserve\nits benefits while eschewing the inference overhead. In this work we propose\none solution to the critical problem of integrating test-time scaling knowledge\ninto a model during post-training. Specifically, we replace reward guided\ntest-time noise optimization in diffusion models with a Noise Hypernetwork that\nmodulates initial input noise. We propose a theoretically grounded framework\nfor learning this reward-tilted distribution for distilled generators, through\na tractable noise-space objective that maintains fidelity to the base model\nwhile optimizing for desired characteristics. We show that our approach\nrecovers a substantial portion of the quality gains from explicit test-time\noptimization at a fraction of the computational cost. Code is available at\nhttps://github.com/ExplainableML/HyperNoise", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u566a\u58f0\u8d85\u7f51\u7edc\u66ff\u4ee3\u5956\u52b1\u5f15\u5bfc\u7684\u6d4b\u8bd5\u65f6\u566a\u58f0\u4f18\u5316\u7684\u65b9\u6cd5\uff0c\u4ee5\u51cf\u5c11\u63a8\u7406\u8ba1\u7b97\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u7559\u6d4b\u8bd5\u65f6\u6269\u5c55\u7684\u4f18\u52bf\u3002", "motivation": "\u6d4b\u8bd5\u65f6\u6269\u5c55\u867d\u7136\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u663e\u8457\u589e\u52a0\u4e86\u8ba1\u7b97\u65f6\u95f4\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u566a\u58f0\u8d85\u7f51\u7edc\uff0c\u901a\u8fc7\u8c03\u5236\u521d\u59cb\u8f93\u5165\u566a\u58f0\u6765\u4f18\u5316\u751f\u6210\u6a21\u578b\uff0c\u5b66\u4e60\u5956\u52b1\u503e\u659c\u7684\u5206\u5e03\u3002", "result": "\u65b9\u6cd5\u5728\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\uff0c\u6062\u590d\u4e86\u5927\u90e8\u5206\u6d4b\u8bd5\u65f6\u4f18\u5316\u7684\u8d28\u91cf\u63d0\u5347\u3002", "conclusion": "\u566a\u58f0\u8d85\u7f51\u7edc\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u7406\u8bba\u652f\u6301\u7684\u65b9\u6cd5\uff0c\u53ef\u5728\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u7684\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2508.09974", "pdf": "https://arxiv.org/pdf/2508.09974", "abs": "https://arxiv.org/abs/2508.09974", "authors": ["Lecheng Kong", "Theodore Vasiloudis", "Seongjun Yun", "Han Xie", "Xiang Song"], "title": "Dynamic Mixture-of-Experts for Incremental Graph Learning", "categories": ["cs.LG"], "comment": null, "summary": "Graph incremental learning is a learning paradigm that aims to adapt trained\nmodels to continuously incremented graphs and data over time without the need\nfor retraining on the full dataset. However, regular graph machine learning\nmethods suffer from catastrophic forgetting when applied to incremental\nlearning settings, where previously learned knowledge is overridden by new\nknowledge. Previous approaches have tried to address this by treating the\npreviously trained model as an inseparable unit and using techniques to\nmaintain old behaviors while learning new knowledge. These approaches, however,\ndo not account for the fact that previously acquired knowledge at different\ntimestamps contributes differently to learning new tasks. Some prior patterns\ncan be transferred to help learn new data, while others may deviate from the\nnew data distribution and be detrimental. To address this, we propose a dynamic\nmixture-of-experts (DyMoE) approach for incremental learning. Specifically, a\nDyMoE GNN layer adds new expert networks specialized in modeling the incoming\ndata blocks. We design a customized regularization loss that utilizes data\nsequence information so existing experts can maintain their ability to solve\nold tasks while helping the new expert learn the new data effectively. As the\nnumber of data blocks grows over time, the computational cost of the full\nmixture-of-experts (MoE) model increases. To address this, we introduce a\nsparse MoE approach, where only the top-$k$ most relevant experts make\npredictions, significantly reducing the computation time. Our model achieved\n4.92\\% relative accuracy increase compared to the best baselines on class\nincremental learning, showing the model's exceptional power.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u6df7\u5408\u4e13\u5bb6\uff08DyMoE\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u56fe\u589e\u91cf\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u901a\u8fc7\u5b9a\u5236\u6b63\u5219\u5316\u635f\u5931\u548c\u7a00\u758fMoE\u8bbe\u8ba1\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u56fe\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u589e\u91cf\u5b66\u4e60\u573a\u666f\u4e2d\u4f1a\u51fa\u73b0\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u672a\u8003\u8651\u4e0d\u540c\u65f6\u95f4\u70b9\u83b7\u53d6\u7684\u77e5\u8bc6\u5bf9\u65b0\u4efb\u52a1\u5b66\u4e60\u7684\u8d21\u732e\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u6df7\u5408\u4e13\u5bb6\uff08DyMoE\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u65b0\u589e\u4e13\u5bb6\u7f51\u7edc\u548c\u5b9a\u5236\u6b63\u5219\u5316\u635f\u5931\u4f18\u5316\u5b66\u4e60\uff0c\u5e76\u5f15\u5165\u7a00\u758fMoE\u8bbe\u8ba1\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "result": "\u6a21\u578b\u5728\u7c7b\u589e\u91cf\u5b66\u4e60\u4efb\u52a1\u4e2d\u76f8\u5bf9\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u4e864.92%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "DyMoE\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u7a00\u758f\u8bbe\u8ba1\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2508.09183", "pdf": "https://arxiv.org/pdf/2508.09183", "abs": "https://arxiv.org/abs/2508.09183", "authors": ["Farzan Moosavi", "Bilal Farooq"], "title": "Quantum-Efficient Reinforcement Learning Solutions for Last-Mile On-Demand Delivery", "categories": ["quant-ph", "cs.AI", "cs.LG", "math.OC"], "comment": null, "summary": "Quantum computation has demonstrated a promising alternative to solving the\nNP-hard combinatorial problems. Specifically, when it comes to optimization,\nclassical approaches become intractable to account for large-scale solutions.\nSpecifically, we investigate quantum computing to solve the large-scale\nCapacitated Pickup and Delivery Problem with Time Windows (CPDPTW). In this\nregard, a Reinforcement Learning (RL) framework augmented with a Parametrized\nQuantum Circuit (PQC) is designed to minimize the travel time in a realistic\nlast-mile on-demand delivery. A novel problem-specific encoding quantum circuit\nwith an entangling and variational layer is proposed. Moreover, Proximal Policy\nOptimization (PPO) and Quantum Singular Value Transformation (QSVT) are\ndesigned for comparison through numerical experiments, highlighting the\nsuperiority of the proposed method in terms of the scale of the solution and\ntraining complexity while incorporating the real-world constraints.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u89c4\u6a21CPDPTW\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u91cf\u5b50\u8ba1\u7b97\u5728\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u7ecf\u5178\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u96be\u4ee5\u5904\u7406\uff0c\u91cf\u5b50\u8ba1\u7b97\u4e3a\u89e3\u51b3\u6b64\u7c7b\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u548c\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\u7684\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u95ee\u9898\u7279\u5b9a\u7684\u91cf\u5b50\u7f16\u7801\u7535\u8def\uff0c\u5e76\u5bf9\u6bd4\u4e86PPO\u548cQSVT\u65b9\u6cd5\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u89e3\u51b3\u65b9\u6848\u89c4\u6a21\u548c\u8bad\u7ec3\u590d\u6742\u5ea6\u4e0a\u4f18\u4e8e\u5bf9\u6bd4\u65b9\u6cd5\uff0c\u540c\u65f6\u8003\u8651\u4e86\u73b0\u5b9e\u7ea6\u675f\u3002", "conclusion": "\u91cf\u5b50\u8ba1\u7b97\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u4e3a\u89e3\u51b3\u5927\u89c4\u6a21CPDPTW\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6848\u3002"}}
{"id": "2508.09196", "pdf": "https://arxiv.org/pdf/2508.09196", "abs": "https://arxiv.org/abs/2508.09196", "authors": ["Asim Ukaye", "Numan Saeed", "Karthik Nandakumar"], "title": "FIVA: Federated Inverse Variance Averaging for Universal CT Segmentation with Uncertainty Estimation", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": "17 pages, 5 figures, Machine Learning for Healthcare Conference", "summary": "Different CT segmentation datasets are typically obtained from different\nscanners under different capture settings and often provide segmentation labels\nfor a limited and often disjoint set of organs. Using these heterogeneous data\neffectively while preserving patient privacy can be challenging. This work\npresents a novel federated learning approach to achieve universal segmentation\nacross diverse abdominal CT datasets by utilizing model uncertainty for\naggregation and predictive uncertainty for inference. Our approach leverages\nthe inherent noise in stochastic mini-batch gradient descent to estimate a\ndistribution over the model weights to provide an on-the-go uncertainty over\nthe model parameters at the client level. The parameters are then aggregated at\nthe server using the additional uncertainty information using a\nBayesian-inspired inverse-variance aggregation scheme. Furthermore, the\nproposed method quantifies prediction uncertainty by propagating the\nuncertainty from the model weights, providing confidence measures essential for\nclinical decision-making. In line with recent work shown, predictive\nuncertainty is utilized in the inference stage to improve predictive\nperformance. Experimental evaluations demonstrate the effectiveness of this\napproach in improving both the quality of federated aggregation and\nuncertainty-weighted inference compared to previously established baselines.\nThe code for this work is made available at: https://github.com/asimukaye/fiva", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u8fdb\u884c\u805a\u5408\u548c\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u8fdb\u884c\u63a8\u7406\uff0c\u5b9e\u73b0\u4e86\u8de8\u591a\u6837\u8179\u90e8CT\u6570\u636e\u96c6\u7684\u901a\u7528\u5206\u5272\u3002", "motivation": "\u89e3\u51b3\u4e0d\u540cCT\u6570\u636e\u96c6\u56e0\u626b\u63cf\u5668\u548c\u8bbe\u7f6e\u5dee\u5f02\u5bfc\u81f4\u7684\u6807\u7b7e\u4e0d\u7edf\u4e00\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u62a4\u60a3\u8005\u9690\u79c1\u3002", "method": "\u5229\u7528\u968f\u673a\u5c0f\u6279\u91cf\u68af\u5ea6\u4e0b\u964d\u7684\u566a\u58f0\u4f30\u8ba1\u6a21\u578b\u6743\u91cd\u5206\u5e03\uff0c\u91c7\u7528\u8d1d\u53f6\u65af\u9006\u65b9\u5dee\u805a\u5408\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u4f20\u64ad\u6a21\u578b\u6743\u91cd\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8054\u90a6\u805a\u5408\u8d28\u91cf\u548c\u4e0d\u786e\u5b9a\u6027\u52a0\u6743\u63a8\u7406\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u8de8\u6570\u636e\u96c6\u5206\u5272\u7684\u901a\u7528\u6027\u548c\u4e34\u5e8a\u51b3\u7b56\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2508.09207", "pdf": "https://arxiv.org/pdf/2508.09207", "abs": "https://arxiv.org/abs/2508.09207", "authors": ["Tai Vu", "Robert Yang"], "title": "GANime: Generating Anime and Manga Character Drawings from Sketches with Deep Learning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The process of generating fully colorized drawings from sketches is a large,\nusually costly bottleneck in the manga and anime industry. In this study, we\nexamine multiple models for image-to-image translation between anime characters\nand their sketches, including Neural Style Transfer, C-GAN, and CycleGAN. By\nassessing them qualitatively and quantitatively, we find that C-GAN is the most\neffective model that is able to produce high-quality and high-resolution images\nclose to those created by humans.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u591a\u79cd\u56fe\u50cf\u5230\u56fe\u50cf\u8f6c\u6362\u6a21\u578b\uff0c\u53d1\u73b0C-GAN\u5728\u52a8\u6f2b\u89d2\u8272\u8349\u56fe\u7740\u8272\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u89e3\u51b3\u52a8\u6f2b\u884c\u4e1a\u4e2d\u8349\u56fe\u7740\u8272\u8017\u65f6\u4e14\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u8bc4\u4f30\u4e86Neural Style Transfer\u3001C-GAN\u548cCycleGAN\u7b49\u6a21\u578b\u3002", "result": "C-GAN\u80fd\u751f\u6210\u63a5\u8fd1\u4eba\u7c7b\u521b\u4f5c\u7684\u9ad8\u8d28\u91cf\u3001\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u3002", "conclusion": "C-GAN\u662f\u52a8\u6f2b\u8349\u56fe\u7740\u8272\u4efb\u52a1\u4e2d\u6700\u6709\u6548\u7684\u6a21\u578b\u3002"}}
{"id": "2508.09209", "pdf": "https://arxiv.org/pdf/2508.09209", "abs": "https://arxiv.org/abs/2508.09209", "authors": ["Kun Ming Goh"], "title": "Quantum-Enhanced Generative Adversarial Networks: Comparative Analysis of Classical and Hybrid Quantum-Classical Generative Adversarial Networks", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "9 pages, 9 figures, 3 tables", "summary": "Generative adversarial networks (GANs) have emerged as a powerful paradigm\nfor producing high-fidelity data samples, yet their performance is constrained\nby the quality of latent representations, typically sampled from classical\nnoise distributions. This study investigates hybrid quantum-classical GANs\n(HQCGANs) in which a quantum generator, implemented via parameterised quantum\ncircuits, produces latent vectors for a classical discriminator. We evaluate a\nclassical GAN alongside three HQCGAN variants with 3, 5, and 7 qubits, using\nQiskit's AerSimulator with realistic noise models to emulate near-term quantum\ndevices. The binary MNIST dataset (digits 0 and 1) is used to align with the\nlow-dimensional latent spaces imposed by current quantum hardware. Models are\ntrained for 150 epochs and assessed with Frechet Inception Distance (FID) and\nKernel Inception Distance (KID). Results show that while the classical GAN\nachieved the best scores, the 7-qubit HQCGAN produced competitive performance,\nnarrowing the gap in later epochs, whereas the 3-qubit model exhibited earlier\nconvergence limitations. Efficiency analysis indicates only moderate training\ntime increases despite quantum sampling overhead. These findings validate the\nfeasibility of noisy quantum circuits as latent priors in GAN architectures,\nhighlighting their potential to enhance generative modelling within the\nconstraints of the noisy intermediate-scale quantum (NISQ) era.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08HQCGANs\uff09\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u91cf\u5b50\u7535\u8def\u751f\u6210\u6f5c\u5728\u5411\u91cf\uff0c\u5e76\u4e0e\u7ecf\u5178GAN\u6027\u80fd\u5bf9\u6bd4\u3002\u7ed3\u679c\u663e\u793a7-qubit HQCGAN\u8868\u73b0\u63a5\u8fd1\u7ecf\u5178GAN\uff0c\u9a8c\u8bc1\u4e86\u5728NISQ\u65f6\u4ee3\u91cf\u5b50\u7535\u8def\u4f5c\u4e3a\u6f5c\u5728\u5148\u9a8c\u7684\u6f5c\u529b\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u91cf\u5b50\u7535\u8def\u5728\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u5f53\u524d\u91cf\u5b50\u786c\u4ef6\u9650\u5236\u4e0b\uff0c\u662f\u5426\u80fd\u63d0\u5347\u751f\u6210\u6a21\u578b\u6027\u80fd\u3002", "method": "\u91c7\u7528\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178GAN\u67b6\u6784\uff0c\u91cf\u5b50\u751f\u6210\u5668\u901a\u8fc7\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\u751f\u6210\u6f5c\u5728\u5411\u91cf\uff0c\u7ecf\u5178\u5224\u522b\u5668\u8fdb\u884c\u5224\u522b\u3002\u5bf9\u6bd4\u4e86\u7ecf\u5178GAN\u4e0e3\u30015\u30017-qubit HQCGAN\u7684\u6027\u80fd\u3002", "result": "\u7ecf\u5178GAN\u8868\u73b0\u6700\u4f73\uff0c\u4f467-qubit HQCGAN\u5728\u540e\u671f\u8868\u73b0\u63a5\u8fd1\uff0c3-qubit\u6a21\u578b\u56e0\u6536\u655b\u9650\u5236\u8868\u73b0\u8f83\u5dee\u3002\u91cf\u5b50\u91c7\u6837\u5f00\u9500\u4ec5\u5bfc\u81f4\u8bad\u7ec3\u65f6\u95f4\u9002\u5ea6\u589e\u52a0\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728NISQ\u65f6\u4ee3\uff0c\u91cf\u5b50\u7535\u8def\u53ef\u4f5c\u4e3aGAN\u7684\u6f5c\u5728\u5148\u9a8c\uff0c\u4e3a\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2508.09212", "pdf": "https://arxiv.org/pdf/2508.09212", "abs": "https://arxiv.org/abs/2508.09212", "authors": ["Sihan Xie", "Thierry Tribout", "Didier Boichard", "Blaise Hanczar", "Julien Chiquet", "Eric Barrey"], "title": "Deep Generative Models for Discrete Genotype Simulation", "categories": ["q-bio.GN", "cs.AI", "cs.LG"], "comment": null, "summary": "Deep generative models open new avenues for simulating realistic genomic data\nwhile preserving privacy and addressing data accessibility constraints. While\nprevious studies have primarily focused on generating gene expression or\nhaplotype data, this study explores generating genotype data in both\nunconditioned and phenotype-conditioned settings, which is inherently more\nchallenging due to the discrete nature of genotype data. In this work, we\ndeveloped and evaluated commonly used generative models, including Variational\nAutoencoders (VAEs), Diffusion Models, and Generative Adversarial Networks\n(GANs), and proposed adaptation tailored to discrete genotype data. We\nconducted extensive experiments on large-scale datasets, including all\nchromosomes from cow and multiple chromosomes from human. Model performance was\nassessed using a well-established set of metrics drawn from both deep learning\nand quantitative genetics literature. Our results show that these models can\neffectively capture genetic patterns and preserve genotype-phenotype\nassociation. Our findings provide a comprehensive comparison of these models\nand offer practical guidelines for future research in genotype simulation. We\nhave made our code publicly available at\nhttps://github.com/SihanXXX/DiscreteGenoGen.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u751f\u6210\u79bb\u6563\u57fa\u56e0\u578b\u6570\u636e\u7684\u6df1\u5ea6\u751f\u6210\u6a21\u578b\uff0c\u6bd4\u8f83\u4e86VAE\u3001\u6269\u6563\u6a21\u578b\u548cGAN\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u57fa\u56e0\u578b\u6570\u636e\u751f\u6210\u7684\u6311\u6218\uff0c\u540c\u65f6\u4fdd\u62a4\u9690\u79c1\u5e76\u63d0\u9ad8\u6570\u636e\u53ef\u8bbf\u95ee\u6027\u3002", "method": "\u5f00\u53d1\u5e76\u8bc4\u4f30\u4e86VAE\u3001\u6269\u6563\u6a21\u578b\u548cGAN\uff0c\u9488\u5bf9\u79bb\u6563\u57fa\u56e0\u578b\u6570\u636e\u8fdb\u884c\u4e86\u9002\u5e94\u6027\u8c03\u6574\u3002", "result": "\u6a21\u578b\u80fd\u6709\u6548\u6355\u6349\u9057\u4f20\u6a21\u5f0f\u5e76\u4fdd\u6301\u57fa\u56e0\u578b-\u8868\u578b\u5173\u8054\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u6a21\u578b\u6bd4\u8f83\u548c\u672a\u6765\u7814\u7a76\u7684\u5b9e\u7528\u6307\u5357\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.09215", "pdf": "https://arxiv.org/pdf/2508.09215", "abs": "https://arxiv.org/abs/2508.09215", "authors": ["Kerem Delikoyun", "Qianyu Chen", "Liu Wei", "Si Ko Myo", "Johannes Krell", "Martin Schlegel", "Win Sen Kuan", "John Tshon Yit Soong", "Gerhard Schneider", "Clarissa Prazeres da Costa", "Percy A. Knolle", "Laurent Renia", "Matthew Edward Cove", "Hwee Kuan Lee", "Klaus Diepold", "Oliver Hayden"], "title": "Real-time deep learning phase imaging flow cytometer reveals blood cell aggregate biomarkers for haematology diagnostics", "categories": ["q-bio.QM", "cs.AI", "cs.CV", "cs.LG", "eess.IV"], "comment": null, "summary": "While analysing rare blood cell aggregates remains challenging in automated\nhaematology, they could markedly advance label-free functional diagnostics.\nConventional flow cytometers efficiently perform cell counting with leukocyte\ndifferentials but fail to identify aggregates with flagged results, requiring\nmanual reviews. Quantitative phase imaging flow cytometry captures detailed\naggregate morphologies, but clinical use is hampered by massive data storage\nand offline processing. Incorporating hidden biomarkers into routine\nhaematology panels would significantly improve diagnostics without flagged\nresults. We present RT-HAD, an end-to-end deep learning-based image and data\nprocessing framework for off-axis digital holographic microscopy (DHM), which\ncombines physics-consistent holographic reconstruction and detection,\nrepresenting each blood cell in a graph to recognize aggregates. RT-HAD\nprocesses >30 GB of image data on-the-fly with turnaround time of <1.5 min and\nerror rate of 8.9% in platelet aggregate detection, which matches acceptable\nlaboratory error rates of haematology biomarkers and solves the big data\nchallenge for point-of-care diagnostics.", "AI": {"tldr": "RT-HAD\u662f\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u7aef\u5230\u7aef\u56fe\u50cf\u6570\u636e\u5904\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u5feb\u901f\u8bc6\u522b\u8840\u7ec6\u80de\u805a\u96c6\u4f53\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u6570\u636e\u5b58\u50a8\u548c\u5904\u7406\u96be\u9898\u3002", "motivation": "\u4f20\u7edf\u6d41\u5f0f\u7ec6\u80de\u4eea\u65e0\u6cd5\u6709\u6548\u8bc6\u522b\u8840\u7ec6\u80de\u805a\u96c6\u4f53\uff0c\u800c\u5b9a\u91cf\u76f8\u4f4d\u6210\u50cf\u6d41\u5f0f\u7ec6\u80de\u672f\u7684\u6570\u636e\u5b58\u50a8\u548c\u5904\u7406\u95ee\u9898\u9650\u5236\u4e86\u4e34\u5e8a\u5e94\u7528\u3002", "method": "RT-HAD\u7ed3\u5408\u7269\u7406\u4e00\u81f4\u7684\u5168\u606f\u91cd\u5efa\u548c\u68c0\u6d4b\u6280\u672f\uff0c\u5c06\u6bcf\u4e2a\u8840\u7ec6\u80de\u8868\u793a\u4e3a\u56fe\u7ed3\u6784\u4ee5\u8bc6\u522b\u805a\u96c6\u4f53\u3002", "result": "RT-HAD\u80fd\u57281.5\u5206\u949f\u5185\u5b9e\u65f6\u5904\u740630GB\u56fe\u50cf\u6570\u636e\uff0c\u8840\u5c0f\u677f\u805a\u96c6\u4f53\u68c0\u6d4b\u9519\u8bef\u7387\u4e3a8.9%\u3002", "conclusion": "RT-HAD\u89e3\u51b3\u4e86\u5373\u65f6\u8bca\u65ad\u4e2d\u7684\u5927\u6570\u636e\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65e0\u6807\u8bb0\u529f\u80fd\u8bca\u65ad\u7684\u6548\u7387\u3002"}}
{"id": "2508.09217", "pdf": "https://arxiv.org/pdf/2508.09217", "abs": "https://arxiv.org/abs/2508.09217", "authors": ["Akshay Sajan", "Stijn Sluis", "Reza Haydarlou", "Sanne Abeln", "Pasquale Lisena", "Raphael Troncy", "Caro Verbeek", "Inger Leemans", "Halima Mouhib"], "title": "Exploring Molecular Odor Taxonomies for Structure-based Odor Predictions using Machine Learning", "categories": ["q-bio.QM", "cs.LG", "research article"], "comment": "24 pages (58 pages including supporting information), 9 Figures, 4\n  Tables; additional Tables and Figures in the supporting information", "summary": "One of the key challenges to predict odor from molecular structure is\nunarguably our limited understanding of the odor space and the complexity of\nthe underlying structure-odor relationships. Here, we show that the predictive\nperformance of machine learning models for structure-based odor predictions can\nbe improved using both, an expert and a data-driven odor taxonomy. The expert\ntaxonomy is based on semantic and perceptual similarities, while the\ndata-driven taxonomy is based on clustering co-occurrence patterns of odor\ndescriptors directly from the prepared dataset. Both taxonomies improve the\npredictions of different machine learning models and outperform random\ngroupings of descriptors that do not reflect existing relations between odor\ndescriptors. We assess the quality of both taxonomies through their predictive\nperformance across different odor classes and perform an in-depth error\nanalysis highlighting the complexity of odor-structure relationships and\nidentifying potential inconsistencies within the taxonomies by showcasing pear\nodorants used in perfumery. The data-driven taxonomy allows us to critically\nevaluate our expert taxonomy and better understand the molecular odor space.\nBoth taxonomies as well as a full dataset are made available to the community,\nproviding a stepping stone for a future community-driven exploration of the\nmolecular basis of smell. In addition, we provide a detailed multi-layer expert\ntaxonomy including a total of 777 different descriptors from the Pyrfume\nrepository.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u4e13\u5bb6\u548c\u6570\u636e\u9a71\u52a8\u7684\u6c14\u5473\u5206\u7c7b\u6cd5\u6539\u8fdb\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5bf9\u6c14\u5473\u9884\u6d4b\u7684\u6027\u80fd\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e24\u79cd\u5206\u7c7b\u6cd5\u7684\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u4ece\u5206\u5b50\u7ed3\u6784\u9884\u6d4b\u6c14\u5473\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u6c14\u5473\u7a7a\u95f4\u7406\u89e3\u7684\u4e0d\u8db3\u548c\u7ed3\u6784-\u6c14\u5473\u5173\u7cfb\u7684\u590d\u6742\u6027\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u8bed\u4e49\u548c\u611f\u77e5\u76f8\u4f3c\u6027\u7684\u4e13\u5bb6\u5206\u7c7b\u6cd5\uff0c\u4ee5\u53ca\u57fa\u4e8e\u6c14\u5473\u63cf\u8ff0\u7b26\u5171\u73b0\u6a21\u5f0f\u7684\u6570\u636e\u9a71\u52a8\u5206\u7c7b\u6cd5\uff0c\u6539\u8fdb\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002", "result": "\u4e24\u79cd\u5206\u7c7b\u6cd5\u5747\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\uff0c\u4f18\u4e8e\u968f\u673a\u5206\u7ec4\uff0c\u6570\u636e\u9a71\u52a8\u5206\u7c7b\u6cd5\u6709\u52a9\u4e8e\u8bc4\u4f30\u4e13\u5bb6\u5206\u7c7b\u6cd5\u5e76\u7406\u89e3\u6c14\u5473\u7a7a\u95f4\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e24\u79cd\u5206\u7c7b\u6cd5\u548c\u5b8c\u6574\u6570\u636e\u96c6\uff0c\u4e3a\u672a\u6765\u6c14\u5473\u5206\u5b50\u57fa\u7840\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.09228", "pdf": "https://arxiv.org/pdf/2508.09228", "abs": "https://arxiv.org/abs/2508.09228", "authors": ["A F M Saif", "Lisha Chen", "Xiaodong Cui", "Songtao Lu", "Brian Kingsbury", "Tianyi Chen"], "title": "Objective Soups: Multilingual Multi-Task Modeling for Speech Processing", "categories": ["eess.AS", "cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Training a single model for multilingual, multi-task speech processing (MSP)\nis severely hampered by conflicting objectives between tasks like speech\nrecognition and translation. While multi-objective optimization (MOO) aims to\nalign gradient updates, its effectiveness diminishes as the number of tasks\ngrows, making it difficult to find a common descent direction. This raises a\nfundamental question: should highly conflicting objectives be optimized jointly\nor separated into a hierarchical structure? To address this question, this\npaper investigates three multi-objective MSP formulations, which we refer to as\n\\textbf{objective soup recipes}. These formulations apply multi-objective\noptimization at different optimization levels to mitigate potential conflicts\namong all objectives. To ensure efficiency, we introduce a lightweight\nlayer-selection mechanism that computes the conflict-avoiding gradient using\nonly the most problematic layers, minimizing computational and memory overhead.\nExtensive experiments on CoVoST v2, LibriSpeech, and AISHELL-1 reveal that a\nbi-level recipe separating recognition and translation tasks consistently\noutperforms standard flat optimization. Our work demonstrates that hierarchical\nMOO is a more effective and scalable approach for building state-of-the-art MSP\nmodels. Our code has been released at\nhttps://github.com/afmsaif/Objective_Soups.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u591a\u4efb\u52a1\u8bed\u97f3\u5904\u7406\u4e2d\u76ee\u6807\u51b2\u7a81\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5206\u5c42\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u3002", "motivation": "\u591a\u4efb\u52a1\u8bed\u97f3\u5904\u7406\u4e2d\uff0c\u4efb\u52a1\u76ee\u6807\u51b2\u7a81\u5bfc\u81f4\u4f18\u5316\u56f0\u96be\uff0c\u4f20\u7edf\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\u5728\u4efb\u52a1\u589e\u591a\u65f6\u6548\u679c\u4e0b\u964d\u3002", "method": "\u7814\u7a76\u4e86\u4e09\u79cd\u591a\u76ee\u6807\u4f18\u5316\u914d\u65b9\uff0c\u5f15\u5165\u8f7b\u91cf\u7ea7\u5c42\u9009\u62e9\u673a\u5236\u4ee5\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5206\u5c42\u4f18\u5316\u65b9\u6cd5\u5728\u8bed\u97f3\u8bc6\u522b\u548c\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u5206\u5c42\u591a\u76ee\u6807\u4f18\u5316\u662f\u6784\u5efa\u9ad8\u6548\u591a\u4efb\u52a1\u8bed\u97f3\u5904\u7406\u6a21\u578b\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2508.09243", "pdf": "https://arxiv.org/pdf/2508.09243", "abs": "https://arxiv.org/abs/2508.09243", "authors": ["Sebastian Kot"], "title": "Forecasting Binary Economic Events in Modern Mercantilism: Traditional methodologies coupled with PCA and K-means Quantitative Analysis of Qualitative Sentimental Data", "categories": ["econ.GN", "cs.LG", "q-fin.EC", "stat.ME"], "comment": null, "summary": "This paper examines Modern Mercantilism, characterized by rising economic\nnationalism, strategic technological decoupling, and geopolitical\nfragmentation, as a disruptive shift from the post-1945 globalization paradigm.\nIt applies Principal Component Analysis (PCA) to 768-dimensional\nSBERT-generated semantic embeddings of curated news articles to extract\northogonal latent factors that discriminate binary event outcomes linked to\nprotectionism, technological sovereignty, and bloc realignments. Analysis of\nprincipal component loadings identifies key semantic features driving\nclassification performance, enhancing interpretability and predictive accuracy.\nThis methodology provides a scalable, data-driven framework for quantitatively\ntracking emergent mercantilist dynamics through high-dimensional text analytics", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u4e3b\u6210\u5206\u5206\u6790\uff08PCA\uff09\u7814\u7a76\u73b0\u4ee3\u91cd\u5546\u4e3b\u4e49\uff0c\u63ed\u793a\u5176\u4e0e\u5168\u7403\u5316\u8303\u5f0f\u7684\u5dee\u5f02\uff0c\u5e76\u5229\u7528\u6587\u672c\u5206\u6790\u91cf\u5316\u4fdd\u62a4\u4e3b\u4e49\u548c\u6280\u672f\u4e3b\u6743\u7b49\u52a8\u6001\u3002", "motivation": "\u63a2\u8ba8\u73b0\u4ee3\u91cd\u5546\u4e3b\u4e49\u5bf9\u5168\u7403\u5316\u8303\u5f0f\u7684\u98a0\u8986\u6027\u5f71\u54cd\uff0c\u63d0\u4f9b\u6570\u636e\u9a71\u52a8\u7684\u91cf\u5316\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528PCA\u5206\u6790768\u7ef4SBERT\u751f\u6210\u7684\u65b0\u95fb\u8bed\u4e49\u5d4c\u5165\uff0c\u63d0\u53d6\u4e0e\u4fdd\u62a4\u4e3b\u4e49\u548c\u6280\u672f\u4e3b\u6743\u76f8\u5173\u7684\u6f5c\u5728\u56e0\u5b50\u3002", "result": "\u901a\u8fc7\u4e3b\u6210\u5206\u8f7d\u8377\u8bc6\u522b\u5173\u952e\u8bed\u4e49\u7279\u5f81\uff0c\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u548c\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9ad8\u7ef4\u6587\u672c\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8ffd\u8e2a\u91cd\u5546\u4e3b\u4e49\u52a8\u6001\u3002"}}
{"id": "2508.09262", "pdf": "https://arxiv.org/pdf/2508.09262", "abs": "https://arxiv.org/abs/2508.09262", "authors": ["Dongwoo Kang", "Akhil Perincherry", "Zachary Coalson", "Aiden Gabriel", "Stefan Lee", "Sanghyun Hong"], "title": "Harnessing Input-Adaptive Inference for Efficient VLN", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted to ICCV 2025 [Poster]", "summary": "An emerging paradigm in vision-and-language navigation (VLN) is the use of\nhistory-aware multi-modal transformer models. Given a language instruction,\nthese models process observation and navigation history to predict the most\nappropriate action for an agent. While they have significantly improved\nperformance, the scale of these models can be a bottleneck in practical\nsettings with limited computational resources. In this work, we propose a novel\ninput-adaptive navigation method to enhance VLN model efficiency. We first show\nthat existing input-adaptive mechanisms fail to reduce computations without\nsubstantial performance degradation. To address this, we introduce three\nadaptive algorithms, each deployed at a different level: (1) To improve spatial\nefficiency, we selectively process panoramic views at each observation of an\nagent. (2) To improve intra-model efficiency, we propose importance-based\nadaptive thresholding for the early-exit methods. (3) To improve temporal\nefficiency, we implement a caching mechanism that prevents reprocessing of\nviews previously seen by the agent. In evaluations on seven VLN benchmarks, we\ndemonstrate over a 2$\\times$ reduction in computation across three\noff-the-shelf agents in both standard and continuous environments. Our code is\npublicly available at\nhttps://github.com/secure-ai-systems-group/adaptive-vision-and-language-navigation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8f93\u5165\u81ea\u9002\u5e94\u5bfc\u822a\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u79cd\u7b97\u6cd5\u63d0\u5347\u89c6\u89c9\u4e0e\u8bed\u8a00\u5bfc\u822a\uff08VLN\uff09\u6a21\u578b\u7684\u6548\u7387\uff0c\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u91cf\u3002", "motivation": "\u73b0\u6709\u8f93\u5165\u81ea\u9002\u5e94\u673a\u5236\u5728\u51cf\u5c11\u8ba1\u7b97\u91cf\u65f6\u6027\u80fd\u4e0b\u964d\u4e25\u91cd\uff0c\u9700\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e09\u79cd\u81ea\u9002\u5e94\u7b97\u6cd5\uff1a\u9009\u62e9\u6027\u5904\u7406\u5168\u666f\u89c6\u56fe\u3001\u57fa\u4e8e\u91cd\u8981\u6027\u7684\u81ea\u9002\u5e94\u9608\u503c\u548c\u7f13\u5b58\u673a\u5236\u3002", "result": "\u5728\u4e03\u4e2aVLN\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8ba1\u7b97\u91cf\u51cf\u5c11\u8d85\u8fc72\u500d\uff0c\u6027\u80fd\u65e0\u660e\u663e\u4e0b\u964d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86VLN\u6a21\u578b\u7684\u6548\u7387\uff0c\u9002\u7528\u4e8e\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u7684\u573a\u666f\u3002"}}
{"id": "2508.09271", "pdf": "https://arxiv.org/pdf/2508.09271", "abs": "https://arxiv.org/abs/2508.09271", "authors": ["Reihaneh Hassanzadeh", "Anees Abrol", "Hamid Reza Hassanzadeh", "Vince D. Calhoun"], "title": "A Generative Imputation Method for Multimodal Alzheimer's Disease Diagnosis", "categories": ["eess.IV", "cs.LG"], "comment": null, "summary": "Multimodal data analysis can lead to more accurate diagnoses of brain\ndisorders due to the complementary information that each modality adds.\nHowever, a major challenge of using multimodal datasets in the neuroimaging\nfield is incomplete data, where some of the modalities are missing for certain\nsubjects. Hence, effective strategies are needed for completing the data.\nTraditional methods, such as subsampling or zero-filling, may reduce the\naccuracy of predictions or introduce unintended biases. In contrast, advanced\nmethods such as generative models have emerged as promising solutions without\nthese limitations. In this study, we proposed a generative adversarial network\nmethod designed to reconstruct missing modalities from existing ones while\npreserving the disease patterns. We used T1-weighted structural magnetic\nresonance imaging and functional network connectivity as two modalities. Our\nfindings showed a 9% improvement in the classification accuracy for Alzheimer's\ndisease versus cognitive normal groups when using our generative imputation\nmethod compared to the traditional approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u73b0\u6709\u6a21\u6001\u91cd\u5efa\u7f3a\u5931\u7684\u795e\u7ecf\u5f71\u50cf\u6570\u636e\uff0c\u63d0\u9ad8\u4e86\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u5206\u7c7b\u51c6\u786e\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u6570\u636e\u5206\u6790\u80fd\u63d0\u9ad8\u8111\u90e8\u75be\u75c5\u8bca\u65ad\u51c6\u786e\u6027\uff0c\u4f46\u6570\u636e\u7f3a\u5931\u662f\u4e3b\u8981\u6311\u6218\u3002\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u964d\u4f4e\u51c6\u786e\u6027\u6216\u5f15\u5165\u504f\u5dee\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u4eceT1\u52a0\u6743\u7ed3\u6784\u78c1\u5171\u632f\u6210\u50cf\u548c\u529f\u80fd\u7f51\u7edc\u8fde\u63a5\u4e2d\u91cd\u5efa\u7f3a\u5931\u6a21\u6001\uff0c\u4fdd\u7559\u75be\u75c5\u6a21\u5f0f\u3002", "result": "\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u751f\u6210\u586b\u8865\u65b9\u6cd5\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u4e0e\u8ba4\u77e5\u6b63\u5e38\u7ec4\u7684\u5206\u7c7b\u51c6\u786e\u6027\u4e0a\u63d0\u9ad8\u4e869%\u3002", "conclusion": "\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u662f\u89e3\u51b3\u795e\u7ecf\u5f71\u50cf\u6570\u636e\u7f3a\u5931\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u663e\u8457\u63d0\u5347\u8bca\u65ad\u51c6\u786e\u6027\u3002"}}
{"id": "2508.09277", "pdf": "https://arxiv.org/pdf/2508.09277", "abs": "https://arxiv.org/abs/2508.09277", "authors": ["Soumia Mehimeh"], "title": "Value Function Initialization for Knowledge Transfer and Jump-start in Deep Reinforcement Learning", "categories": ["cs.AI", "cs.LG", "cs.LO"], "comment": null, "summary": "Value function initialization (VFI) is an effective way to achieve a\njumpstart in reinforcement learning (RL) by leveraging value estimates from\nprior tasks. While this approach is well established in tabular settings,\nextending it to deep reinforcement learning (DRL) poses challenges due to the\ncontinuous nature of the state-action space, the noisy approximations of neural\nnetworks, and the impracticality of storing all past models for reuse. In this\nwork, we address these challenges and introduce DQInit, a method that adapts\nvalue function initialization to DRL. DQInit reuses compact tabular Q-values\nextracted from previously solved tasks as a transferable knowledge base. It\nemploys a knownness-based mechanism to softly integrate these transferred\nvalues into underexplored regions and gradually shift toward the agent's\nlearned estimates, avoiding the limitations of fixed time decay. Our approach\noffers a novel perspective on knowledge transfer in DRL by relying solely on\nvalue estimates rather than policies or demonstrations, effectively combining\nthe strengths of jumpstart RL and policy distillation while mitigating their\ndrawbacks. Experiments across multiple continuous control tasks demonstrate\nthat DQInit consistently improves early learning efficiency, stability, and\noverall performance compared to standard initialization and existing transfer\ntechniques.", "AI": {"tldr": "DQInit\u662f\u4e00\u79cd\u5c06\u503c\u51fd\u6570\u521d\u59cb\u5316\uff08VFI\uff09\u6269\u5c55\u5230\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u7528\u5148\u524d\u4efb\u52a1\u7684\u7d27\u51d1\u8868\u683cQ\u503c\u4f5c\u4e3a\u53ef\u8f6c\u79fb\u77e5\u8bc6\u5e93\uff0c\u63d0\u5347\u5b66\u4e60\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u5728DRL\u4e2d\uff0cVFI\u9762\u4e34\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u8fde\u7eed\u3001\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u566a\u58f0\u548c\u5b58\u50a8\u8fc7\u53bb\u6a21\u578b\u4e0d\u5207\u5b9e\u9645\u7684\u6311\u6218\uff0cDQInit\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "DQInit\u901a\u8fc7\u57fa\u4e8e\u5df2\u77e5\u5ea6\u7684\u673a\u5236\uff0c\u5c06\u8f6c\u79fb\u7684\u503c\u8f6f\u6027\u6574\u5408\u5230\u672a\u63a2\u7d22\u533a\u57df\uff0c\u5e76\u9010\u6b65\u8f6c\u5411\u4ee3\u7406\u7684\u5b66\u4e60\u4f30\u8ba1\uff0c\u907f\u514d\u56fa\u5b9a\u65f6\u95f4\u8870\u51cf\u7684\u9650\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDQInit\u5728\u591a\u4e2a\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u65e9\u671f\u5b66\u4e60\u6548\u7387\u3001\u7a33\u5b9a\u6027\u548c\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "DQInit\u4e3aDRL\u4e2d\u7684\u77e5\u8bc6\u8f6c\u79fb\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u4ec5\u4f9d\u8d56\u503c\u4f30\u8ba1\u800c\u975e\u7b56\u7565\u6216\u6f14\u793a\uff0c\u7ed3\u5408\u4e86\u8df3\u542f\u52a8RL\u548c\u7b56\u7565\u84b8\u998f\u7684\u4f18\u52bf\u3002"}}
{"id": "2508.09294", "pdf": "https://arxiv.org/pdf/2508.09294", "abs": "https://arxiv.org/abs/2508.09294", "authors": ["Xi Xuan", "Zimo Zhu", "Wenxin Zhang", "Yi-Cheng Lin", "Tomi Kinnunen"], "title": "Fake-Mamba: Real-Time Speech Deepfake Detection Using Bidirectional Mamba as Self-Attention's Alternative", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted at IEEE ASRU 2025", "summary": "Advances in speech synthesis intensify security threats, motivating real-time\ndeepfake detection research. We investigate whether bidirectional Mamba can\nserve as a competitive alternative to Self-Attention in detecting synthetic\nspeech. Our solution, Fake-Mamba, integrates an XLSR front-end with\nbidirectional Mamba to capture both local and global artifacts. Our core\ninnovation introduces three efficient encoders: TransBiMamba, ConBiMamba, and\nPN-BiMamba. Leveraging XLSR's rich linguistic representations, PN-BiMamba can\neffectively capture the subtle cues of synthetic speech. Evaluated on ASVspoof\n21 LA, 21 DF, and In-The-Wild benchmarks, Fake-Mamba achieves 0.97%, 1.74%, and\n5.85% EER, respectively, representing substantial relative gains over SOTA\nmodels XLSR-Conformer and XLSR-Mamba. The framework maintains real-time\ninference across utterance lengths, demonstrating strong generalization and\npractical viability. The code is available at\nhttps://github.com/xuanxixi/Fake-Mamba.", "AI": {"tldr": "Fake-Mamba\u662f\u4e00\u79cd\u57fa\u4e8e\u53cc\u5411Mamba\u7684\u5b9e\u65f6\u6df1\u5ea6\u4f2a\u9020\u8bed\u97f3\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408XLSR\u524d\u7aef\u548c\u4e09\u79cd\u9ad8\u6548\u7f16\u7801\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u8bed\u97f3\u5408\u6210\u6280\u672f\u7684\u8fdb\u6b65\uff0c\u6df1\u5ea6\u4f2a\u9020\u8bed\u97f3\u7684\u5b89\u5168\u5a01\u80c1\u52a0\u5267\uff0c\u63a8\u52a8\u4e86\u5b9e\u65f6\u68c0\u6d4b\u65b9\u6cd5\u7684\u7814\u7a76\u3002", "method": "Fake-Mamba\u6574\u5408\u4e86XLSR\u524d\u7aef\u548c\u53cc\u5411Mamba\uff0c\u5e76\u63d0\u51fa\u4e86\u4e09\u79cd\u9ad8\u6548\u7f16\u7801\u5668\uff08TransBiMamba\u3001ConBiMamba\u3001PN-BiMamba\uff09\uff0c\u4ee5\u6355\u6349\u5c40\u90e8\u548c\u5168\u5c40\u7279\u5f81\u3002", "result": "\u5728ASVspoof 21 LA\u300121 DF\u548cIn-The-Wild\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFake-Mamba\u7684EER\u5206\u522b\u4e3a0.97%\u30011.74%\u548c5.85%\uff0c\u4f18\u4e8e\u73b0\u6709SOTA\u6a21\u578b\u3002", "conclusion": "Fake-Mamba\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5b9e\u65f6\u63a8\u7406\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.09362", "pdf": "https://arxiv.org/pdf/2508.09362", "abs": "https://arxiv.org/abs/2508.09362", "authors": ["Md. Milon Islam", "Md Rezwanul Haque", "S M Taslim Uddin Raju", "Fakhri Karray"], "title": "FusionEnsemble-Net: An Attention-Based Ensemble of Spatiotemporal Networks for Multimodal Sign Language Recognition", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted for the IEEE/CVF International Conference on Computer Vision\n  (ICCV), Honolulu, Hawaii, USA. 1st MSLR Workshop 2025", "summary": "Accurate recognition of sign language in healthcare communication poses a\nsignificant challenge, requiring frameworks that can accurately interpret\ncomplex multimodal gestures. To deal with this, we propose FusionEnsemble-Net,\na novel attention-based ensemble of spatiotemporal networks that dynamically\nfuses visual and motion data to enhance recognition accuracy. The proposed\napproach processes RGB video and range Doppler map radar modalities\nsynchronously through four different spatiotemporal networks. For each network,\nfeatures from both modalities are continuously fused using an attention-based\nfusion module before being fed into an ensemble of classifiers. Finally, the\noutputs of these four different fused channels are combined in an ensemble\nclassification head, thereby enhancing the model's robustness. Experiments\ndemonstrate that FusionEnsemble-Net outperforms state-of-the-art approaches\nwith a test accuracy of 99.44% on the large-scale MultiMeDaLIS dataset for\nItalian Sign Language. Our findings indicate that an ensemble of diverse\nspatiotemporal networks, unified by attention-based fusion, yields a robust and\naccurate framework for complex, multimodal isolated gesture recognition tasks.\nThe source code is available at:\nhttps://github.com/rezwanh001/Multimodal-Isolated-Italian-Sign-Language-Recognition.", "AI": {"tldr": "FusionEnsemble-Net\u662f\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u65f6\u7a7a\u7f51\u7edc\u96c6\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u878d\u5408\u89c6\u89c9\u548c\u8fd0\u52a8\u6570\u636e\u63d0\u5347\u624b\u8bed\u8bc6\u522b\u7cbe\u5ea6\uff0c\u6d4b\u8bd5\u51c6\u786e\u7387\u8fbe99.44%\u3002", "motivation": "\u89e3\u51b3\u533b\u7597\u6c9f\u901a\u4e2d\u590d\u6742\u591a\u6a21\u6001\u624b\u52bf\u8bc6\u522b\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faFusionEnsemble-Net\uff0c\u540c\u6b65\u5904\u7406RGB\u89c6\u9891\u548c\u96f7\u8fbe\u6570\u636e\uff0c\u901a\u8fc7\u56db\u79cd\u65f6\u7a7a\u7f51\u7edc\u548c\u6ce8\u610f\u529b\u878d\u5408\u6a21\u5757\u52a8\u6001\u878d\u5408\u7279\u5f81\uff0c\u6700\u7ec8\u901a\u8fc7\u96c6\u6210\u5206\u7c7b\u5668\u8f93\u51fa\u7ed3\u679c\u3002", "result": "\u5728\u610f\u5927\u5229\u624b\u8bed\u6570\u636e\u96c6MultiMeDaLIS\u4e0a\u8fbe\u523099.44%\u7684\u6d4b\u8bd5\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u6ce8\u610f\u529b\u878d\u5408\u7684\u591a\u6837\u5316\u65f6\u7a7a\u7f51\u7edc\u96c6\u6210\u65b9\u6cd5\u4e3a\u590d\u6742\u591a\u6a21\u6001\u624b\u52bf\u8bc6\u522b\u63d0\u4f9b\u4e86\u9c81\u68d2\u4e14\u51c6\u786e\u7684\u6846\u67b6\u3002"}}
{"id": "2508.09370", "pdf": "https://arxiv.org/pdf/2508.09370", "abs": "https://arxiv.org/abs/2508.09370", "authors": ["Tianxing Zhou", "Christopher A. Theissen", "S. Jean Feeser", "William M. J. Best", "Adam J. Burgasser", "Kelle L. Cruz", "Lexu Zhao"], "title": "Classifying Cool Dwarfs: Comprehensive Spectral Typing of Field and Peculiar Dwarfs Using Machine Learning", "categories": ["astro-ph.SR", "astro-ph.EP", "astro-ph.GA", "astro-ph.IM", "cs.LG"], "comment": "35 pages, 24 figures, 9 tables, accepted for publication in The\n  Astrophysical Journal", "summary": "Low-mass stars and brown dwarfs -- spectral types (SpTs) M0 and later -- play\na significant role in studying stellar and substellar processes and\ndemographics, reaching down to planetary-mass objects. Currently, the\nclassification of these sources remains heavily reliant on visual inspection of\nspectral features, equivalent width measurements, or narrow-/wide-band spectral\nindices. Recent advances in machine learning (ML) methods offer automated\napproaches for spectral typing, which are becoming increasingly important as\nlarge spectroscopic surveys such as Gaia, SDSS, and SPHEREx generate datasets\ncontaining millions of spectra. We investigate the application of ML in\nspectral type classification on low-resolution (R $\\sim$ 120) near-infrared\nspectra of M0--T9 dwarfs obtained with the SpeX instrument on the NASA Infrared\nTelescope Facility. We specifically aim to classify the gravity- and\nmetallicity-dependent subclasses for late-type dwarfs. We used binned fluxes as\ninput features and compared the efficacy of spectral type estimators built\nusing Random Forest (RF), Support Vector Machine (SVM), and K-Nearest Neighbor\n(KNN) models. We tested the influence of different normalizations and analyzed\nthe relative importance of different spectral regions for surface gravity and\nmetallicity subclass classification. Our best-performing model (using KNN)\nclassifies 95.5 $\\pm$ 0.6% of sources to within $\\pm$1 SpT, and assigns surface\ngravity and metallicity subclasses with 89.5 $\\pm$ 0.9% accuracy. We test the\ndependence of signal-to-noise ratio on classification accuracy and find sources\nwith SNR $\\gtrsim$ 60 have $\\gtrsim$ 95% accuracy. We also find that zy-band\nplays the most prominent role in the RF model, with FeH and TiO having the\nhighest feature importance.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u673a\u5668\u5b66\u4e60\u5728\u4f4e\u8d28\u91cf\u6052\u661f\u548c\u8910\u77ee\u661f\u5149\u8c31\u5206\u7c7b\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u9488\u5bf9M0-T9\u578b\u77ee\u661f\u7684\u4f4e\u5206\u8fa8\u7387\u8fd1\u7ea2\u5916\u5149\u8c31\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u5206\u6790\u4e86\u5149\u8c31\u533a\u57df\u5bf9\u5206\u7c7b\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u4f4e\u8d28\u91cf\u6052\u661f\u548c\u8910\u77ee\u661f\u5728\u6052\u661f\u548c\u4e9a\u6052\u661f\u7814\u7a76\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u76ee\u524d\u5206\u7c7b\u4ecd\u4f9d\u8d56\u4eba\u5de5\u65b9\u6cd5\uff0c\u673a\u5668\u5b66\u4e60\u4e3a\u5927\u89c4\u6a21\u5149\u8c31\u6570\u636e\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u968f\u673a\u68ee\u6797\uff08RF\uff09\u3001\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u548cK\u8fd1\u90bb\uff08KNN\uff09\u6a21\u578b\uff0c\u4ee5\u5206\u7bb1\u901a\u91cf\u4e3a\u8f93\u5165\u7279\u5f81\uff0c\u6d4b\u8bd5\u4e0d\u540c\u5f52\u4e00\u5316\u65b9\u6cd5\u53ca\u5149\u8c31\u533a\u57df\u7684\u91cd\u8981\u6027\u3002", "result": "\u6700\u4f73\u6a21\u578b\uff08KNN\uff09\u5728\u00b11\u5149\u8c31\u7c7b\u578b\u5185\u5206\u7c7b\u51c6\u786e\u7387\u4e3a95.5\u00b10.6%\uff0c\u8868\u9762\u91cd\u529b\u548c\u91d1\u5c5e\u4e30\u5ea6\u5b50\u7c7b\u5206\u7c7b\u51c6\u786e\u7387\u4e3a89.5\u00b10.9%\u3002\u4fe1\u566a\u6bd4\u226560\u65f6\u51c6\u786e\u7387\u226595%\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u53ef\u6709\u6548\u5206\u7c7b\u4f4e\u5206\u8fa8\u7387\u5149\u8c31\uff0czy\u6ce2\u6bb5\u548cFeH\u3001TiO\u7279\u5f81\u5728\u5206\u7c7b\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2508.09372", "pdf": "https://arxiv.org/pdf/2508.09372", "abs": "https://arxiv.org/abs/2508.09372", "authors": ["Md Rezwanul Haque", "Md. Milon Islam", "S M Taslim Uddin Raju", "Fakhri Karray"], "title": "A Signer-Invariant Conformer and Multi-Scale Fusion Transformer for Continuous Sign Language Recognition", "categories": ["cs.CV", "cs.AI", "cs.IR", "cs.LG"], "comment": "Accepted for the IEEE/CVF International Conference on Computer Vision\n  (ICCV), Honolulu, Hawaii, USA. 1st MSLR Workshop 2025", "summary": "Continuous Sign Language Recognition (CSLR) faces multiple challenges,\nincluding significant inter-signer variability and poor generalization to novel\nsentence structures. Traditional solutions frequently fail to handle these\nissues efficiently. For overcoming these constraints, we propose a\ndual-architecture framework. For the Signer-Independent (SI) challenge, we\npropose a Signer-Invariant Conformer that combines convolutions with multi-head\nself-attention to learn robust, signer-agnostic representations from pose-based\nskeletal keypoints. For the Unseen-Sentences (US) task, we designed a\nMulti-Scale Fusion Transformer with a novel dual-path temporal encoder that\ncaptures both fine-grained posture dynamics, enabling the model's ability to\ncomprehend novel grammatical compositions. Experiments on the challenging\nIsharah-1000 dataset establish a new standard for both CSLR benchmarks. The\nproposed conformer architecture achieves a Word Error Rate (WER) of 13.07% on\nthe SI challenge, a reduction of 13.53% from the state-of-the-art. On the US\ntask, the transformer model scores a WER of 47.78%, surpassing previous work.\nIn the SignEval 2025 CSLR challenge, our team placed 2nd in the US task and 4th\nin the SI task, demonstrating the performance of these models. The findings\nvalidate our key hypothesis: that developing task-specific networks designed\nfor the particular challenges of CSLR leads to considerable performance\nimprovements and establishes a new baseline for further research. The source\ncode is available at: https://github.com/rezwanh001/MSLR-Pose86K-CSLR-Isharah.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u67b6\u6784\u6846\u67b6\u89e3\u51b3\u8fde\u7eed\u624b\u8bed\u8bc6\u522b\u4e2d\u7684\u7b7e\u540d\u8005\u72ec\u7acb\u6027\u548c\u672a\u89c1\u53e5\u5b50\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u8fde\u7eed\u624b\u8bed\u8bc6\u522b\u9762\u4e34\u7b7e\u540d\u8005\u95f4\u5dee\u5f02\u5927\u548c\u672a\u89c1\u53e5\u5b50\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u4f7f\u7528\u7b7e\u540d\u8005\u4e0d\u53d8Conformer\u548c\u591a\u5c3a\u5ea6\u878d\u5408Transformer\uff0c\u5206\u522b\u5904\u7406\u7b7e\u540d\u8005\u72ec\u7acb\u6027\u548c\u672a\u89c1\u53e5\u5b50\u4efb\u52a1\u3002", "result": "\u5728Isharah-1000\u6570\u636e\u96c6\u4e0a\uff0c\u7b7e\u540d\u8005\u4e0d\u53d8\u4efb\u52a1WER\u964d\u81f313.07%\uff0c\u672a\u89c1\u53e5\u5b50\u4efb\u52a1WER\u4e3a47.78%\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u4efb\u52a1\u7279\u5b9a\u7f51\u7edc\u8bbe\u8ba1\u663e\u8457\u63d0\u5347\u4e86\u8fde\u7eed\u624b\u8bed\u8bc6\u522b\u6027\u80fd\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u8bbe\u5b9a\u4e86\u65b0\u57fa\u51c6\u3002"}}
{"id": "2508.09381", "pdf": "https://arxiv.org/pdf/2508.09381", "abs": "https://arxiv.org/abs/2508.09381", "authors": ["Kumar Abhishek", "Jeremy Kawahara", "Ghassan Hamarneh"], "title": "What Can We Learn from Inter-Annotator Variability in Skin Lesion Segmentation?", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Medical Image Computing and Computer-Assisted Intervention (MICCAI)\n  ISIC Skin Image Analysis Workshop (MICCAI ISIC) 2025; 12 pages, 4 tables, 3\n  figures", "summary": "Medical image segmentation exhibits intra- and inter-annotator variability\ndue to ambiguous object boundaries, annotator preferences, expertise, and\ntools, among other factors. Lesions with ambiguous boundaries, e.g., spiculated\nor infiltrative nodules, or irregular borders per the ABCD rule, are\nparticularly prone to disagreement and are often associated with malignancy. In\nthis work, we curate IMA++, the largest multi-annotator skin lesion\nsegmentation dataset, on which we conduct an in-depth study of variability due\nto annotator, malignancy, tool, and skill factors. We find a statistically\nsignificant (p<0.001) association between inter-annotator agreement (IAA),\nmeasured using Dice, and the malignancy of skin lesions. We further show that\nIAA can be accurately predicted directly from dermoscopic images, achieving a\nmean absolute error of 0.108. Finally, we leverage this association by\nutilizing IAA as a \"soft\" clinical feature within a multi-task learning\nobjective, yielding a 4.2% improvement in balanced accuracy averaged across\nmultiple model architectures and across IMA++ and four public dermoscopic\ndatasets. The code is available at https://github.com/sfu-mial/skin-IAV.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u533b\u5b66\u56fe\u50cf\u5206\u5272\u4e2d\u6ce8\u91ca\u8005\u95f4\u5dee\u5f02\u4e0e\u76ae\u80a4\u75c5\u53d8\u6076\u6027\u7a0b\u5ea6\u7684\u5173\u7cfb\uff0c\u5e76\u5229\u7528\u591a\u4efb\u52a1\u5b66\u4e60\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u533b\u5b66\u56fe\u50cf\u5206\u5272\u5b58\u5728\u6ce8\u91ca\u8005\u95f4\u5dee\u5f02\uff0c\u5c24\u5176\u662f\u8fb9\u754c\u6a21\u7cca\u7684\u75c5\u53d8\uff08\u5982\u6076\u6027\u76ae\u80a4\u75c5\u53d8\uff09\uff0c\u7814\u7a76\u8fd9\u4e9b\u5dee\u5f02\u53ca\u5176\u4e0e\u6076\u6027\u7a0b\u5ea6\u7684\u5173\u7cfb\u5bf9\u4e34\u5e8a\u8bca\u65ad\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u6784\u5efa\u4e86IMA++\u6570\u636e\u96c6\uff0c\u5206\u6790\u6ce8\u91ca\u8005\u3001\u6076\u6027\u7a0b\u5ea6\u7b49\u56e0\u7d20\u5bf9\u5206\u5272\u5dee\u5f02\u7684\u5f71\u54cd\uff0c\u5e76\u5229\u7528\u591a\u4efb\u52a1\u5b66\u4e60\u5c06\u6ce8\u91ca\u8005\u95f4\u4e00\u81f4\u6027\u4f5c\u4e3a\u8f6f\u7279\u5f81\u3002", "result": "\u53d1\u73b0\u6ce8\u91ca\u8005\u95f4\u4e00\u81f4\u6027\u4e0e\u6076\u6027\u7a0b\u5ea6\u663e\u8457\u76f8\u5173\uff08p<0.001\uff09\uff0c\u5e76\u6210\u529f\u9884\u6d4b\u4e00\u81f4\u6027\uff08MAE=0.108\uff09\uff0c\u591a\u4efb\u52a1\u5b66\u4e60\u4f7f\u6a21\u578b\u6027\u80fd\u63d0\u53474.2%\u3002", "conclusion": "\u6ce8\u91ca\u8005\u95f4\u4e00\u81f4\u6027\u53ef\u4f5c\u4e3a\u4e34\u5e8a\u7279\u5f81\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u533b\u5b66\u56fe\u50cf\u5206\u5272\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.09389", "pdf": "https://arxiv.org/pdf/2508.09389", "abs": "https://arxiv.org/abs/2508.09389", "authors": ["Eray Eren", "Qingju Liu", "Hyeongwoo Kim", "Pablo Garrido", "Abeer Alwan"], "title": "ProMode: A Speech Prosody Model Conditioned on Acoustic and Textual Inputs", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "comment": "Interspeech 2025; demo page at\n  https://promode8272.github.io/promode/index.html", "summary": "Prosody conveys rich emotional and semantic information of the speech signal\nas well as individual idiosyncrasies. We propose a stand-alone model that maps\ntext-to-prosodic features such as F0 and energy and can be used in downstream\ntasks such as TTS. The ProMode encoder takes as input acoustic features and\ntime-aligned textual content, both are partially masked, and obtains a\nfixed-length latent prosodic embedding. The decoder predicts acoustics in the\nmasked region using both the encoded prosody input and unmasked textual\ncontent. Trained on the GigaSpeech dataset, we compare our method with\nstate-of-the-art style encoders. For F0 and energy predictions, we show\nconsistent improvements for our model at different levels of granularity. We\nalso integrate these predicted prosodic features into a TTS system and conduct\nperceptual tests, which show higher prosody preference compared to the\nbaselines, demonstrating the model's potential in tasks where prosody modeling\nis important.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u72ec\u7acb\u6a21\u578bProMode\uff0c\u7528\u4e8e\u4ece\u6587\u672c\u751f\u6210\u97f5\u5f8b\u7279\u5f81\uff08\u5982F0\u548c\u80fd\u91cf\uff09\uff0c\u5e76\u5e94\u7528\u4e8eTTS\u7b49\u4e0b\u6e38\u4efb\u52a1\u3002\u901a\u8fc7\u90e8\u5206\u63a9\u7801\u7684\u58f0\u5b66\u7279\u5f81\u548c\u6587\u672c\u8f93\u5165\uff0c\u6a21\u578b\u751f\u6210\u56fa\u5b9a\u957f\u5ea6\u7684\u6f5c\u5728\u97f5\u5f8b\u5d4c\u5165\uff0c\u5e76\u5728\u63a9\u7801\u533a\u57df\u9884\u6d4b\u58f0\u5b66\u7279\u5f81\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728F0\u548c\u80fd\u91cf\u9884\u6d4b\u4e0a\u4f18\u4e8e\u73b0\u6709\u98ce\u683c\u7f16\u7801\u5668\uff0c\u4e14\u5728TTS\u7cfb\u7edf\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u97f5\u5f8b\u504f\u597d\u3002", "motivation": "\u97f5\u5f8b\u5305\u542b\u4e30\u5bcc\u7684\u60c5\u611f\u548c\u8bed\u4e49\u4fe1\u606f\uff0c\u4ee5\u53ca\u4e2a\u4f53\u7279\u5f81\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u97f5\u5f8b\u5efa\u6a21\u4e0a\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u72ec\u7acb\u6a21\u578b\u6765\u66f4\u597d\u5730\u751f\u6210\u97f5\u5f8b\u7279\u5f81\u3002", "method": "ProMode\u6a21\u578b\u901a\u8fc7\u90e8\u5206\u63a9\u7801\u7684\u58f0\u5b66\u7279\u5f81\u548c\u6587\u672c\u8f93\u5165\u751f\u6210\u56fa\u5b9a\u957f\u5ea6\u7684\u97f5\u5f8b\u5d4c\u5165\uff0c\u89e3\u7801\u5668\u5229\u7528\u8fd9\u4e9b\u5d4c\u5165\u548c\u672a\u63a9\u7801\u6587\u672c\u9884\u6d4b\u63a9\u7801\u533a\u57df\u7684\u58f0\u5b66\u7279\u5f81\u3002", "result": "\u5728GigaSpeech\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u540e\uff0c\u6a21\u578b\u5728F0\u548c\u80fd\u91cf\u9884\u6d4b\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5728TTS\u7cfb\u7edf\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u97f5\u5f8b\u504f\u597d\u3002", "conclusion": "ProMode\u6a21\u578b\u5728\u97f5\u5f8b\u5efa\u6a21\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u5c24\u5176\u5728\u9700\u8981\u9ad8\u8d28\u91cf\u97f5\u5f8b\u751f\u6210\u7684\u4e0b\u6e38\u5e94\u7528\u4e2d\u3002"}}
{"id": "2508.09412", "pdf": "https://arxiv.org/pdf/2508.09412", "abs": "https://arxiv.org/abs/2508.09412", "authors": ["Sevvandi Kandanaarachchi", "Philip Kilby", "Cheng Soon Ong"], "title": "A pseudo-inverse of a line graph", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": null, "summary": "Line graphs are an alternative representation of graphs where each vertex of\nthe original (root) graph becomes an edge. However not all graphs have a\ncorresponding root graph, hence the transformation from graphs to line graphs\nis not invertible. We investigate the case when there is a small perturbation\nin the space of line graphs, and try to recover the corresponding root graph,\nessentially defining the inverse of the line graph operation. We propose a\nlinear integer program that edits the smallest number of edges in the line\ngraph, that allow a root graph to be found. We use the spectral norm to\ntheoretically prove that such a pseudo-inverse operation is well behaved.\nIllustrative empirical experiments on Erd\\H{o}s-R\\'enyi graphs show that our\ntheoretical results work in practice.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u7ebf\u56fe\u7684\u5c0f\u6270\u52a8\u60c5\u51b5\u4e0b\u5982\u4f55\u6062\u590d\u5bf9\u5e94\u7684\u6839\u56fe\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ebf\u6027\u6574\u6570\u89c4\u5212\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u8c31\u8303\u6570\u8bc1\u660e\u4e86\u5176\u4f2a\u9006\u64cd\u4f5c\u7684\u5408\u7406\u6027\u3002", "motivation": "\u7ebf\u56fe\u53d8\u6362\u901a\u5e38\u4e0d\u53ef\u9006\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u7ebf\u56fe\u6270\u52a8\u540e\u6062\u590d\u6839\u56fe\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7ebf\u6027\u6574\u6570\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u7ebf\u56fe\u7684\u8fb9\u7f16\u8f91\u6570\u6765\u627e\u5230\u5bf9\u5e94\u7684\u6839\u56fe\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728Erd\u0151s-R\u00e9nyi\u56fe\u4e0a\u6709\u6548\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7ebf\u56fe\u7684\u4f2a\u9006\u64cd\u4f5c\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u652f\u6301\u3002"}}
{"id": "2508.09453", "pdf": "https://arxiv.org/pdf/2508.09453", "abs": "https://arxiv.org/abs/2508.09453", "authors": ["Abdul Matin", "Tanjim Bin Faruk", "Shrideep Pallickara", "Sangmi Lee Pallickara"], "title": "HyperKD: Distilling Cross-Spectral Knowledge in Masked Autoencoders via Inverse Domain Shift with Spatial-Aware Masking and Specialized Loss", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The proliferation of foundation models, pretrained on large-scale unlabeled\ndatasets, has emerged as an effective approach in creating adaptable and\nreusable architectures that can be leveraged for various downstream tasks using\nsatellite observations. However, their direct application to hyperspectral\nremote sensing remains challenging due to inherent spectral disparities and the\nscarcity of available observations. In this work, we present HyperKD, a novel\nknowledge distillation framework that enables transferring learned\nrepresentations from a teacher model into a student model for effective\ndevelopment of a foundation model on hyperspectral images. Unlike typical\nknowledge distillation frameworks, which use a complex teacher to guide a\nsimpler student, HyperKD enables an inverse form of knowledge transfer across\ndifferent types of spectral data, guided by a simpler teacher model. Building\nupon a Masked Autoencoder, HyperKD distills knowledge from the Prithvi\nfoundational model into a student tailored for EnMAP hyperspectral imagery.\nHyperKD addresses the inverse domain adaptation problem with spectral gaps by\nintroducing a feature-based strategy that includes spectral range-based channel\nalignment, spatial feature-guided masking, and an enhanced loss function\ntailored for hyperspectral images. HyperKD bridges the substantial spectral\ndomain gap, enabling the effective use of pretrained foundation models for\ngeospatial applications. Extensive experiments show that HyperKD significantly\nimproves representation learning in MAEs, leading to enhanced reconstruction\nfidelity and more robust performance on downstream tasks such as land cover\nclassification, crop type identification, and soil organic carbon prediction,\nunderpinning the potential of knowledge distillation frameworks in remote\nsensing analytics with hyperspectral imagery.", "AI": {"tldr": "HyperKD\u662f\u4e00\u79cd\u65b0\u9896\u7684\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u901a\u8fc7\u9006\u5411\u77e5\u8bc6\u8f6c\u79fb\u89e3\u51b3\u9ad8\u5149\u8c31\u9065\u611f\u4e2d\u57fa\u7840\u6a21\u578b\u5e94\u7528\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8868\u793a\u5b66\u4e60\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u9ad8\u5149\u8c31\u9065\u611f\u4e2d\u76f4\u63a5\u5e94\u7528\u5b58\u5728\u5149\u8c31\u5dee\u5f02\u548c\u6570\u636e\u7a00\u7f3a\u7684\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u8fc1\u79fb\u5b66\u4e60\u8868\u793a\u3002", "method": "HyperKD\u91c7\u7528\u57fa\u4e8e\u7279\u5f81\u7684\u77e5\u8bc6\u84b8\u998f\u7b56\u7565\uff0c\u5305\u62ec\u5149\u8c31\u8303\u56f4\u5bf9\u9f50\u3001\u7a7a\u95f4\u7279\u5f81\u5f15\u5bfc\u63a9\u7801\u548c\u589e\u5f3a\u635f\u5931\u51fd\u6570\uff0c\u4ece\u6559\u5e08\u6a21\u578b\u5411\u5b66\u751f\u6a21\u578b\u8fc1\u79fb\u77e5\u8bc6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cHyperKD\u663e\u8457\u63d0\u5347\u4e86\u8868\u793a\u5b66\u4e60\u6548\u679c\uff0c\u589e\u5f3a\u4e86\u91cd\u5efa\u4fdd\u771f\u5ea6\uff0c\u5e76\u5728\u571f\u5730\u8986\u76d6\u5206\u7c7b\u3001\u4f5c\u7269\u7c7b\u578b\u8bc6\u522b\u7b49\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u9c81\u68d2\u3002", "conclusion": "HyperKD\u6210\u529f\u89e3\u51b3\u4e86\u9ad8\u5149\u8c31\u9065\u611f\u4e2d\u7684\u9006\u5411\u57df\u9002\u5e94\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\u5728\u9065\u611f\u5206\u6790\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.09499", "pdf": "https://arxiv.org/pdf/2508.09499", "abs": "https://arxiv.org/abs/2508.09499", "authors": ["Liyan Jia", "Chuan-Xian Ren", "Hong Yan"], "title": "CWFBind: Geometry-Awareness for Fast and Accurate Protein-Ligand Docking", "categories": ["cs.CV", "cs.CG", "cs.LG"], "comment": null, "summary": "Accurately predicting the binding conformation of small-molecule ligands to\nprotein targets is a critical step in rational drug design. Although recent\ndeep learning-based docking surpasses traditional methods in speed and\naccuracy, many approaches rely on graph representations and language\nmodel-inspired encoders while neglecting critical geometric information,\nresulting in inaccurate pocket localization and unrealistic binding\nconformations. In this study, we introduce CWFBind, a weighted, fast, and\naccurate docking method based on local curvature features. Specifically, we\nintegrate local curvature descriptors during the feature extraction phase to\nenrich the geometric representation of both proteins and ligands, complementing\nexisting chemical, sequence, and structural features. Furthermore, we embed\ndegree-aware weighting mechanisms into the message passing process, enhancing\nthe model's ability to capture spatial structural distinctions and interaction\nstrengths. To address the class imbalance challenge in pocket prediction,\nCWFBind employs a ligand-aware dynamic radius strategy alongside an enhanced\nloss function, facilitating more precise identification of binding regions and\nkey residues. Comprehensive experimental evaluations demonstrate that CWFBind\nachieves competitive performance across multiple docking benchmarks, offering a\nbalanced trade-off between accuracy and efficiency.", "AI": {"tldr": "CWFBind\u662f\u4e00\u79cd\u57fa\u4e8e\u5c40\u90e8\u66f2\u7387\u7279\u5f81\u7684\u5feb\u901f\u3001\u51c6\u786e\u7684\u5206\u5b50\u5bf9\u63a5\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u51e0\u4f55\u4fe1\u606f\u6539\u8fdb\u4e86\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u5206\u5b50\u5bf9\u63a5\u4e2d\u5ffd\u7565\u4e86\u5173\u952e\u7684\u51e0\u4f55\u4fe1\u606f\uff0c\u5bfc\u81f4\u53e3\u888b\u5b9a\u4f4d\u548c\u7ed3\u5408\u6784\u8c61\u4e0d\u51c6\u786e\u3002", "method": "CWFBind\u7ed3\u5408\u5c40\u90e8\u66f2\u7387\u63cf\u8ff0\u7b26\u548c\u5ea6\u611f\u77e5\u6743\u91cd\u673a\u5236\uff0c\u6539\u8fdb\u4e86\u7279\u5f81\u63d0\u53d6\u548c\u6d88\u606f\u4f20\u9012\u8fc7\u7a0b\uff0c\u5e76\u91c7\u7528\u52a8\u6001\u534a\u5f84\u7b56\u7565\u548c\u589e\u5f3a\u635f\u5931\u51fd\u6570\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "CWFBind\u5728\u591a\u4e2a\u5bf9\u63a5\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u6027\u548c\u6548\u7387\u7684\u5e73\u8861\u3002", "conclusion": "CWFBind\u901a\u8fc7\u51e0\u4f55\u4fe1\u606f\u7684\u6574\u5408\u548c\u4f18\u5316\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u5b50\u5bf9\u63a5\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2508.09522", "pdf": "https://arxiv.org/pdf/2508.09522", "abs": "https://arxiv.org/abs/2508.09522", "authors": ["Ajeet Kumar Yadav", "Nishant Kumar", "Rathna G N"], "title": "Generation of Indian Sign Language Letters, Numbers, and Words", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "6 pages, 5 figures, 2024 International Conference on Intelligent\n  Algorithms for Computational Intelligence Systems (IACIS)", "summary": "Sign language, which contains hand movements, facial expressions and bodily\ngestures, is a significant medium for communicating with hard-of-hearing\npeople. A well-trained sign language community communicates easily, but those\nwho don't know sign language face significant challenges. Recognition and\ngeneration are basic communication methods between hearing and hard-of-hearing\nindividuals. Despite progress in recognition, sign language generation still\nneeds to be explored. The Progressive Growing of Generative Adversarial Network\n(ProGAN) excels at producing high-quality images, while the Self-Attention\nGenerative Adversarial Network (SAGAN) generates feature-rich images at medium\nresolutions. Balancing resolution and detail is crucial for sign language image\ngeneration. We are developing a Generative Adversarial Network (GAN) variant\nthat combines both models to generate feature-rich, high-resolution, and\nclass-conditional sign language images. Our modified Attention-based model\ngenerates high-quality images of Indian Sign Language letters, numbers, and\nwords, outperforming the traditional ProGAN in Inception Score (IS) and\nFr\\'echet Inception Distance (FID), with improvements of 3.2 and 30.12,\nrespectively. Additionally, we are publishing a large dataset incorporating\nhigh-quality images of Indian Sign Language alphabets, numbers, and 129 words.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408ProGAN\u548cSAGAN\u7684GAN\u53d8\u4f53\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u9ad8\u5206\u8fa8\u7387\u7684\u5370\u5ea6\u624b\u8bed\u56fe\u50cf\uff0c\u5e76\u5728IS\u548cFID\u6307\u6807\u4e0a\u4f18\u4e8e\u4f20\u7edfProGAN\u3002", "motivation": "\u624b\u8bed\u662f\u542c\u969c\u4eba\u58eb\u7684\u91cd\u8981\u4ea4\u6d41\u65b9\u5f0f\uff0c\u4f46\u76ee\u524d\u624b\u8bed\u751f\u6210\u9886\u57df\u4ecd\u9700\u63a2\u7d22\u3002\u73b0\u6709\u6a21\u578b\u5728\u5206\u8fa8\u7387\u548c\u7ec6\u8282\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u7ed3\u5408Progressive Growing GAN\u548cSelf-Attention GAN\u7684\u4f18\u70b9\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684GAN\u53d8\u4f53\uff0c\u7528\u4e8e\u751f\u6210\u7279\u5f81\u4e30\u5bcc\u3001\u9ad8\u5206\u8fa8\u7387\u7684\u5370\u5ea6\u624b\u8bed\u56fe\u50cf\u3002", "result": "\u65b0\u6a21\u578b\u5728IS\u548cFID\u6307\u6807\u4e0a\u5206\u522b\u63d0\u5347\u4e863.2\u548c30.12\uff0c\u5e76\u53d1\u5e03\u4e86\u5305\u542b\u5370\u5ea6\u624b\u8bed\u5b57\u6bcd\u3001\u6570\u5b57\u548c129\u4e2a\u5355\u8bcd\u7684\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u3002", "conclusion": "\u63d0\u51fa\u7684\u6a21\u578b\u5728\u624b\u8bed\u56fe\u50cf\u751f\u6210\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u542c\u969c\u4eba\u58eb\u7684\u4ea4\u6d41\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u5de5\u5177\u3002"}}
{"id": "2508.09529", "pdf": "https://arxiv.org/pdf/2508.09529", "abs": "https://arxiv.org/abs/2508.09529", "authors": ["Yao Li", "Yicheng Liu", "Shirou Wang"], "title": "DeepWKB: Learning WKB Expansions of Invariant Distributions for Stochastic Systems", "categories": ["math.DS", "cs.LG", "60F10, 60J25, 37M25"], "comment": "29 pages, 7 figures", "summary": "This paper introduces a novel deep learning method, called DeepWKB, for\nestimating the invariant distribution of randomly perturbed systems via its\nWentzel-Kramers-Brillouin (WKB) approximation $u_\\epsilon(x) = Q(\\epsilon)^{-1}\nZ_\\epsilon(x) \\exp\\{-V(x)/\\epsilon\\}$, where $V$ is known as the\nquasi-potential, $\\epsilon$ denotes the noise strength, and $Q(\\epsilon)$ is\nthe normalization factor. By utilizing both Monte Carlo data and the partial\ndifferential equations satisfied by $V$ and $Z_\\epsilon$, the DeepWKB method\ncomputes $V$ and $Z_\\epsilon$ separately. This enables an approximation of the\ninvariant distribution in the singular regime where $\\epsilon$ is sufficiently\nsmall, which remains a significant challenge for most existing methods.\nMoreover, the DeepWKB method is applicable to higher-dimensional stochastic\nsystems whose deterministic counterparts admit non-trivial attractors. In\nparticular, it provides a scalable and flexible alternative for computing the\nquasi-potential, which plays a key role in the analysis of rare events,\nmetastability, and the stochastic stability of complex systems.", "AI": {"tldr": "DeepWKB\u662f\u4e00\u79cd\u65b0\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f30\u8ba1\u968f\u673a\u6270\u52a8\u7cfb\u7edf\u7684\u7a33\u6001\u5206\u5e03\uff0c\u901a\u8fc7WKB\u8fd1\u4f3c\u8ba1\u7b97\u51c6\u52bf\u548c\u5f52\u4e00\u5316\u56e0\u5b50\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u566a\u58f0\u5f3a\u5ea6\u8f83\u5c0f\u65f6\u96be\u4ee5\u51c6\u786e\u4f30\u8ba1\u7a33\u6001\u5206\u5e03\uff0cDeepWKB\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u6570\u636e\u548c\u504f\u5fae\u5206\u65b9\u7a0b\uff0c\u5206\u522b\u8ba1\u7b97\u51c6\u52bf\u548c\u5f52\u4e00\u5316\u56e0\u5b50\uff0c\u5b9e\u73b0\u7a33\u6001\u5206\u5e03\u7684\u8fd1\u4f3c\u3002", "result": "DeepWKB\u5728\u5c0f\u566a\u58f0\u5f3a\u5ea6\u4e0b\u6709\u6548\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u7cfb\u7edf\uff0c\u4e3a\u590d\u6742\u7cfb\u7edf\u7684\u7f55\u89c1\u4e8b\u4ef6\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002", "conclusion": "DeepWKB\u4e3a\u89e3\u51b3\u9ad8\u7ef4\u968f\u673a\u7cfb\u7edf\u7684\u7a33\u6001\u5206\u5e03\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u7075\u6d3b\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.09541", "pdf": "https://arxiv.org/pdf/2508.09541", "abs": "https://arxiv.org/abs/2508.09541", "authors": ["Gang Chen", "Guoxin Wang", "Anton van Beek", "Zhenjun Ming", "Yan Yan"], "title": "Emergence of Hierarchies in Multi-Agent Self-Organizing Systems Pursuing a Joint Objective", "categories": ["cs.MA", "cs.LG"], "comment": "34 pages,17 figures", "summary": "Multi-agent self-organizing systems (MASOS) exhibit key characteristics\nincluding scalability, adaptability, flexibility, and robustness, which have\ncontributed to their extensive application across various fields. However, the\nself-organizing nature of MASOS also introduces elements of unpredictability in\ntheir emergent behaviors. This paper focuses on the emergence of dependency\nhierarchies during task execution, aiming to understand how such hierarchies\narise from agents' collective pursuit of the joint objective, how they evolve\ndynamically, and what factors govern their development. To investigate this\nphenomenon, multi-agent reinforcement learning (MARL) is employed to train\nMASOS for a collaborative box-pushing task. By calculating the gradients of\neach agent's actions in relation to the states of other agents, the inter-agent\ndependencies are quantified, and the emergence of hierarchies is analyzed\nthrough the aggregation of these dependencies. Our results demonstrate that\nhierarchies emerge dynamically as agents work towards a joint objective, with\nthese hierarchies evolving in response to changing task requirements. Notably,\nthese dependency hierarchies emerge organically in response to the shared\nobjective, rather than being a consequence of pre-configured rules or\nparameters that can be fine-tuned to achieve specific results. Furthermore, the\nemergence of hierarchies is influenced by the task environment and network\ninitialization conditions. Additionally, hierarchies in MASOS emerge from the\ndynamic interplay between agents' \"Talent\" and \"Effort\" within the\n\"Environment.\" \"Talent\" determines an agent's initial influence on collective\ndecision-making, while continuous \"Effort\" within the \"Environment\" enables\nagents to shift their roles and positions within the system.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u667a\u80fd\u4f53\u81ea\u7ec4\u7ec7\u7cfb\u7edf\uff08MASOS\uff09\u4e2d\u4f9d\u8d56\u5c42\u6b21\u7ed3\u6784\u7684\u52a8\u6001\u6d8c\u73b0\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u5206\u6790\u4efb\u52a1\u6267\u884c\u4e2d\u7684\u4f9d\u8d56\u5173\u7cfb\u53ca\u5176\u6f14\u5316\u3002", "motivation": "MASOS\u7684\u81ea\u7ec4\u7ec7\u7279\u6027\u5bfc\u81f4\u5176\u6d8c\u73b0\u884c\u4e3a\u5177\u6709\u4e0d\u53ef\u9884\u6d4b\u6027\uff0c\u672c\u6587\u65e8\u5728\u7406\u89e3\u4efb\u52a1\u6267\u884c\u4e2d\u4f9d\u8d56\u5c42\u6b21\u7ed3\u6784\u7684\u52a8\u6001\u5f62\u6210\u53ca\u5176\u5f71\u54cd\u56e0\u7d20\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u8bad\u7ec3MASOS\u5b8c\u6210\u534f\u4f5c\u63a8\u7bb1\u4efb\u52a1\uff0c\u901a\u8fc7\u8ba1\u7b97\u667a\u80fd\u4f53\u52a8\u4f5c\u5bf9\u5176\u4ed6\u667a\u80fd\u4f53\u72b6\u6001\u7684\u68af\u5ea6\u91cf\u5316\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u5206\u6790\u5c42\u6b21\u7ed3\u6784\u7684\u6d8c\u73b0\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u4f9d\u8d56\u5c42\u6b21\u7ed3\u6784\u968f\u4efb\u52a1\u9700\u6c42\u52a8\u6001\u6f14\u5316\uff0c\u4e14\u5176\u5f62\u6210\u53d7\u4efb\u52a1\u73af\u5883\u548c\u7f51\u7edc\u521d\u59cb\u5316\u6761\u4ef6\u5f71\u54cd\u3002\u5c42\u6b21\u7ed3\u6784\u6e90\u4e8e\u667a\u80fd\u4f53\u7684\u201c\u5929\u8d4b\u201d\u4e0e\u201c\u52aa\u529b\u201d\u5728\u201c\u73af\u5883\u201d\u4e2d\u7684\u52a8\u6001\u4ea4\u4e92\u3002", "conclusion": "\u4f9d\u8d56\u5c42\u6b21\u7ed3\u6784\u662f\u667a\u80fd\u4f53\u4e3a\u5171\u540c\u76ee\u6807\u81ea\u7136\u6d8c\u73b0\u7684\u7ed3\u679c\uff0c\u800c\u975e\u9884\u8bbe\u89c4\u5219\u6216\u53c2\u6570\u7684\u4ea7\u7269\uff0c\u5176\u52a8\u6001\u6027\u4e3aMASOS\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2508.09621", "pdf": "https://arxiv.org/pdf/2508.09621", "abs": "https://arxiv.org/abs/2508.09621", "authors": ["Ingrid Ma\u00e9va Chekam", "Ines Pastor-Martinez", "Ali Tourani", "Jose Andres Millan-Romera", "Laura Ribeiro", "Pedro Miguel Bastos Soares", "Holger Voos", "Jose Luis Sanchez-Lopez"], "title": "Interpretable Robot Control via Structured Behavior Trees and Large Language Models", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "15 pages, 5 figures, 3 tables", "summary": "As intelligent robots become more integrated into human environments, there\nis a growing need for intuitive and reliable Human-Robot Interaction (HRI)\ninterfaces that are adaptable and more natural to interact with. Traditional\nrobot control methods often require users to adapt to interfaces or memorize\npredefined commands, limiting usability in dynamic, unstructured environments.\nThis paper presents a novel framework that bridges natural language\nunderstanding and robotic execution by combining Large Language Models (LLMs)\nwith Behavior Trees. This integration enables robots to interpret natural\nlanguage instructions given by users and translate them into executable actions\nby activating domain-specific plugins. The system supports scalable and modular\nintegration, with a primary focus on perception-based functionalities, such as\nperson tracking and hand gesture recognition. To evaluate the system, a series\nof real-world experiments was conducted across diverse environments.\nExperimental results demonstrate that the proposed approach is practical in\nreal-world scenarios, with an average cognition-to-execution accuracy of\napproximately 94%, making a significant contribution to HRI systems and robots.\nThe complete source code of the framework is publicly available at\nhttps://github.com/snt-arg/robot_suite.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u884c\u4e3a\u6811\u7684\u65b0\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u5230\u673a\u5668\u4eba\u52a8\u4f5c\u7684\u8f6c\u6362\uff0c\u63d0\u5347\u4e86\u4eba\u673a\u4ea4\u4e92\u7684\u76f4\u89c2\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u673a\u5668\u4eba\u5728\u4eba\u7c7b\u73af\u5883\u4e2d\u7684\u666e\u53ca\uff0c\u9700\u8981\u66f4\u76f4\u89c2\u3001\u53ef\u9760\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u4eba\u673a\u4ea4\u4e92\uff08HRI\uff09\u754c\u9762\u3002\u4f20\u7edf\u65b9\u6cd5\u8981\u6c42\u7528\u6237\u9002\u5e94\u754c\u9762\u6216\u8bb0\u5fc6\u547d\u4ee4\uff0c\u9650\u5236\u4e86\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u53ef\u7528\u6027\u3002", "method": "\u901a\u8fc7\u5c06LLMs\u4e0e\u884c\u4e3a\u6811\u7ed3\u5408\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u7684\u89e3\u6790\u548c\u6267\u884c\uff0c\u5e76\u5229\u7528\u9886\u57df\u7279\u5b9a\u63d2\u4ef6\u5b9e\u73b0\u6a21\u5757\u5316\u6269\u5c55\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7cfb\u7edf\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8ba4\u77e5\u5230\u6267\u884c\u7684\u51c6\u786e\u7387\u5e73\u5747\u8fbe94%\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4eba\u673a\u4ea4\u4e92\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2508.09623", "pdf": "https://arxiv.org/pdf/2508.09623", "abs": "https://arxiv.org/abs/2508.09623", "authors": ["Akshay Thakur", "Sawan Kumar", "Matthew Zahr", "Souvik Chakraborty"], "title": "Scalable h-adaptive probabilistic solver for time-independent and time-dependent systems", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Solving partial differential equations (PDEs) within the framework of\nprobabilistic numerics offers a principled approach to quantifying epistemic\nuncertainty arising from discretization. By leveraging Gaussian process\nregression and imposing the governing PDE as a constraint at a finite set of\ncollocation points, probabilistic numerics delivers mesh-free solutions at\narbitrary locations. However, the high computational cost, which scales\ncubically with the number of collocation points, remains a critical bottleneck,\nparticularly for large-scale or high-dimensional problems. We propose a\nscalable enhancement to this paradigm through two key innovations. First, we\ndevelop a stochastic dual descent algorithm that reduces the per-iteration\ncomplexity from cubic to linear in the number of collocation points, enabling\ntractable inference. Second, we exploit a clustering-based active learning\nstrategy that adaptively selects collocation points to maximize information\ngain while minimizing computational expense. Together, these contributions\nresult in an $h$-adaptive probabilistic solver that can scale to a large number\nof collocation points. We demonstrate the efficacy of the proposed solver on\nbenchmark PDEs, including two- and three-dimensional steady-state elliptic\nproblems, as well as a time-dependent parabolic PDE formulated in a space-time\nsetting.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u6982\u7387\u6570\u503c\u65b9\u6cd5\uff0c\u901a\u8fc7\u968f\u673a\u5bf9\u5076\u4e0b\u964d\u7b97\u6cd5\u548c\u805a\u7c7b\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u6216\u9ad8\u7ef4PDE\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6982\u7387\u6570\u503c\u65b9\u6cd5\u5728\u6c42\u89e3PDE\u65f6\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u5904\u7406\u5927\u89c4\u6a21\u6216\u9ad8\u7ef4\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u968f\u673a\u5bf9\u5076\u4e0b\u964d\u7b97\u6cd5\uff08\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff09\u548c\u805a\u7c7b\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\uff08\u81ea\u9002\u5e94\u9009\u62e9\u91c7\u6837\u70b9\uff09\uff0c\u5b9e\u73b0\u9ad8\u6548\u6c42\u89e3\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4e8c\u7ef4\u3001\u4e09\u7ef4\u7a33\u6001\u692d\u5706\u95ee\u9898\u548c\u65f6\u7a7a\u629b\u7269PDE\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5927\u89c4\u6a21PDE\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u6982\u7387\u6570\u503c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09636", "pdf": "https://arxiv.org/pdf/2508.09636", "abs": "https://arxiv.org/abs/2508.09636", "authors": ["Lalitesh Morishetti", "Abhay Kumar", "Jonathan Scott", "Kaushiki Nag", "Gunjan Sharma", "Shanu Vashishtha", "Rahul Sridhar", "Rohit Chatter", "Kannan Achan"], "title": "Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data", "categories": ["cs.IR", "cs.LG"], "comment": "17 pages, 2 figures, The Pacific Rim International Conference on\n  Artificial Intelligence (PRICAI-2025) Conference", "summary": "In this paper, we present a novel model architecture for optimizing\npersonalized product search ranking using a multi-task learning (MTL)\nframework. Our approach uniquely integrates tabular and non-tabular data,\nleveraging a pre-trained TinyBERT model for semantic embeddings and a novel\nsampling technique to capture diverse customer behaviors. We evaluate our model\nagainst several baselines, including XGBoost, TabNet, FT-Transformer, DCN-V2,\nand MMoE, focusing on their ability to handle mixed data types and optimize\npersonalized ranking. Additionally, we propose a scalable relevance labeling\nmechanism based on click-through rates, click positions, and semantic\nsimilarity, offering an alternative to traditional human-annotated labels.\nExperimental results show that combining non-tabular data with advanced\nembedding techniques in multi-task learning paradigm significantly enhances\nmodel performance. Ablation studies further underscore the benefits of\nincorporating relevance labels, fine-tuning TinyBERT layers, and TinyBERT\nquery-product embedding interactions. These results demonstrate the\neffectiveness of our approach in achieving improved personalized product search\nranking.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\u7684\u4e2a\u6027\u5316\u4ea7\u54c1\u641c\u7d22\u6392\u5e8f\u4f18\u5316\u6a21\u578b\uff0c\u7ed3\u5408\u8868\u683c\u4e0e\u975e\u8868\u683c\u6570\u636e\uff0c\u5229\u7528TinyBERT\u548c\u65b0\u578b\u91c7\u6837\u6280\u672f\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u4e2a\u6027\u5316\u4ea7\u54c1\u641c\u7d22\u6392\u5e8f\u4e2d\u6df7\u5408\u6570\u636e\u7c7b\u578b\u5904\u7406\u7684\u6311\u6218\uff0c\u5e76\u4f18\u5316\u6a21\u578b\u6027\u80fd\u3002", "method": "\u6574\u5408\u8868\u683c\u4e0e\u975e\u8868\u683c\u6570\u636e\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3TinyBERT\u751f\u6210\u8bed\u4e49\u5d4c\u5165\uff0c\u7ed3\u5408\u65b0\u578b\u91c7\u6837\u6280\u672f\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff08\u5982XGBoost\u3001TabNet\u7b49\uff09\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u5404\u6a21\u5757\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4e2a\u6027\u5316\u4ea7\u54c1\u641c\u7d22\u6392\u5e8f\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8bc1\u660e\u4e86\u591a\u4efb\u52a1\u5b66\u4e60\u4e0e\u9ad8\u7ea7\u5d4c\u5165\u6280\u672f\u7684\u7ed3\u5408\u4f18\u52bf\u3002"}}
{"id": "2508.09654", "pdf": "https://arxiv.org/pdf/2508.09654", "abs": "https://arxiv.org/abs/2508.09654", "authors": ["Alexandre Verine", "Florian Le Bronnec", "Kunhao Zheng", "Alexandre Allauzen", "Yann Chevaleyre", "Benjamin Negrevergne"], "title": "Improving Diversity in Language Models: When Temperature Fails, Change the Loss", "categories": ["cs.CL", "cs.LG"], "comment": "Forty-Second International Conference on Machine Learning, ICML2025", "summary": "Increasing diversity in language models is a challenging yet essential\nobjective. A common approach is to raise the decoding temperature. In this\nwork, we investigate this approach through a simplistic yet common case to\nprovide insights into why decreasing temperature can improve quality\n(Precision), while increasing it often fails to boost coverage (Recall). Our\nanalysis reveals that for a model to be effectively tunable through temperature\nadjustments, it must be trained toward coverage. To address this, we propose\nrethinking loss functions in language models by leveraging the Precision-Recall\nframework. Our results demonstrate that this approach achieves a substantially\nbetter trade-off between Precision and Recall than merely combining negative\nlog-likelihood training with temperature scaling. These findings offer a\npathway toward more versatile and robust language modeling techniques.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u8c03\u6574\u89e3\u7801\u6e29\u5ea6\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u591a\u6837\u6027\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0\u964d\u4f4e\u6e29\u5ea6\u53ef\u63d0\u9ad8\u8d28\u91cf\uff08\u7cbe\u786e\u5ea6\uff09\uff0c\u800c\u63d0\u9ad8\u6e29\u5ea6\u672a\u5fc5\u80fd\u63d0\u5347\u8986\u76d6\u7387\uff08\u53ec\u56de\u7387\uff09\u3002\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8e\u7cbe\u786e\u5ea6-\u53ec\u56de\u7387\u6846\u67b6\u91cd\u65b0\u8bbe\u8ba1\u635f\u5931\u51fd\u6570\uff0c\u4ee5\u4f18\u5316\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u591a\u6837\u6027\u7684\u63d0\u5347\u662f\u4e00\u4e2a\u91cd\u8981\u4f46\u5177\u6311\u6218\u6027\u7684\u76ee\u6807\uff0c\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u8c03\u6574\u89e3\u7801\u6e29\u5ea6\uff09\u6548\u679c\u6709\u9650\uff0c\u9700\u63a2\u7d22\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6e29\u5ea6\u8c03\u6574\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u57fa\u4e8e\u7cbe\u786e\u5ea6-\u53ec\u56de\u7387\u6846\u67b6\u7684\u635f\u5931\u51fd\u6570\u8bbe\u8ba1\u65b9\u6cd5\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u7cbe\u786e\u5ea6\u4e0e\u53ec\u56de\u7387\u4e4b\u95f4\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5e73\u8861\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u8d1f\u5bf9\u6570\u4f3c\u7136\u8bad\u7ec3\u7ed3\u5408\u6e29\u5ea6\u8c03\u6574\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u9c81\u68d2\u7684\u4f18\u5316\u8def\u5f84\uff0c\u5f3a\u8c03\u4e86\u635f\u5931\u51fd\u6570\u8bbe\u8ba1\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2508.09665", "pdf": "https://arxiv.org/pdf/2508.09665", "abs": "https://arxiv.org/abs/2508.09665", "authors": ["Ahmed Alharbi", "Hai Dong", "Xun Yi"], "title": "Social-Sensor Identity Cloning Detection Using Weakly Supervised Deep Forest and Cryptographic Authentication", "categories": ["cs.CR", "cs.LG", "cs.SI", "H.3; E.3; I.2; I.7"], "comment": "23 pages", "summary": "Recent years have witnessed a rising trend in social-sensor cloud identity\ncloning incidents. However, existing approaches suffer from unsatisfactory\nperformance, a lack of solutions for detecting duplicated accounts, and a lack\nof large-scale evaluations on real-world datasets. We introduce a novel method\nfor detecting identity cloning in social-sensor cloud service providers. Our\nproposed technique consists of two primary components: 1) a similar identity\ndetection method and 2) a cryptography-based authentication protocol.\nInitially, we developed a weakly supervised deep forest model to identify\nsimilar identities using non-privacy-sensitive user profile features provided\nby the service. Subsequently, we designed a cryptography-based authentication\nprotocol to verify whether similar identities were generated by the same\nprovider. Our extensive experiments on a large real-world dataset demonstrate\nthe feasibility and superior performance of our technique compared to current\nstate-of-the-art identity clone detection methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u793e\u4ea4\u4f20\u611f\u5668\u4e91\u8eab\u4efd\u514b\u9686\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408\u76f8\u4f3c\u8eab\u4efd\u68c0\u6d4b\u548c\u52a0\u5bc6\u8ba4\u8bc1\u534f\u8bae\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8fd1\u5e74\u6765\u793e\u4ea4\u4f20\u611f\u5668\u4e91\u8eab\u4efd\u514b\u9686\u4e8b\u4ef6\u9891\u53d1\uff0c\u73b0\u6709\u65b9\u6cd5\u6027\u80fd\u4e0d\u8db3\u4e14\u7f3a\u4e4f\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6\u9a8c\u8bc1\u3002", "method": "1) \u4f7f\u7528\u5f31\u76d1\u7763\u6df1\u5ea6\u68ee\u6797\u6a21\u578b\u68c0\u6d4b\u76f8\u4f3c\u8eab\u4efd\uff1b2) \u8bbe\u8ba1\u52a0\u5bc6\u8ba4\u8bc1\u534f\u8bae\u9a8c\u8bc1\u8eab\u4efd\u6765\u6e90\u3002", "result": "\u5728\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u548c\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8eab\u4efd\u514b\u9686\u68c0\u6d4b\u95ee\u9898\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2508.09715", "pdf": "https://arxiv.org/pdf/2508.09715", "abs": "https://arxiv.org/abs/2508.09715", "authors": ["Devvrat Joshi", "Islem Rekik"], "title": "NEURAL: Attention-Guided Pruning for Unified Multimodal Resource-Constrained Clinical Evaluation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The rapid growth of multimodal medical imaging data presents significant\nstorage and transmission challenges, particularly in resource-constrained\nclinical settings. We propose NEURAL, a novel framework that addresses this by\nusing semantics-guided data compression. Our approach repurposes\ncross-attention scores between the image and its radiological report from a\nfine-tuned generative vision-language model to structurally prune chest X-rays,\npreserving only diagnostically critical regions. This process transforms the\nimage into a highly compressed, graph representation. This unified graph-based\nrepresentation fuses the pruned visual graph with a knowledge graph derived\nfrom the clinical report, creating a universal data structure that simplifies\ndownstream modeling. Validated on the MIMIC-CXR and CheXpert Plus dataset for\npneumonia detection, NEURAL achieves a 93.4-97.7\\% reduction in image data size\nwhile maintaining a high diagnostic performance of 0.88-0.95 AUC, outperforming\nother baseline models that use uncompressed data. By creating a persistent,\ntask-agnostic data asset, NEURAL resolves the trade-off between data size and\nclinical utility, enabling efficient workflows and teleradiology without\nsacrificing performance. Our NEURAL code is available at\nhttps://github.com/basiralab/NEURAL.", "AI": {"tldr": "NEURAL\u662f\u4e00\u4e2a\u5229\u7528\u8bed\u4e49\u5f15\u5bfc\u6570\u636e\u538b\u7f29\u7684\u65b0\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u4fee\u526a\u80f8\u90e8X\u5149\u7247\u5e76\u8f6c\u6362\u4e3a\u56fe\u8868\u793a\uff0c\u663e\u8457\u51cf\u5c11\u6570\u636e\u5927\u5c0f\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8bca\u65ad\u6027\u80fd\u3002", "motivation": "\u591a\u6a21\u6001\u533b\u5b66\u5f71\u50cf\u6570\u636e\u7684\u5feb\u901f\u589e\u957f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u4e34\u5e8a\u73af\u5883\u4e2d\u5e26\u6765\u4e86\u5b58\u50a8\u548c\u4f20\u8f93\u6311\u6218\u3002", "method": "\u5229\u7528\u751f\u6210\u5f0f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u5206\u6570\u5bf9\u80f8\u90e8X\u5149\u7247\u8fdb\u884c\u7ed3\u6784\u4fee\u526a\uff0c\u751f\u6210\u538b\u7f29\u7684\u56fe\u8868\u793a\uff0c\u5e76\u4e0e\u4e34\u5e8a\u62a5\u544a\u7684\u77e5\u8bc6\u56fe\u878d\u5408\u3002", "result": "\u5728MIMIC-CXR\u548cCheXpert Plus\u6570\u636e\u96c6\u4e0a\uff0cNEURAL\u5b9e\u73b0\u4e8693.4-97.7%\u7684\u6570\u636e\u538b\u7f29\uff0c\u8bca\u65ad\u6027\u80fdAUC\u4e3a0.88-0.95\uff0c\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "NEURAL\u89e3\u51b3\u4e86\u6570\u636e\u5927\u5c0f\u4e0e\u4e34\u5e8a\u6548\u7528\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u652f\u6301\u9ad8\u6548\u5de5\u4f5c\u6d41\u7a0b\u548c\u8fdc\u7a0b\u653e\u5c04\u5b66\uff0c\u4e14\u6027\u80fd\u4e0d\u964d\u4f4e\u3002"}}
{"id": "2508.09717", "pdf": "https://arxiv.org/pdf/2508.09717", "abs": "https://arxiv.org/abs/2508.09717", "authors": ["Shekhnaz Idrissova", "Islem Rekik"], "title": "Multimodal Sheaf-based Network for Glioblastoma Molecular Subtype Prediction", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Glioblastoma is a highly invasive brain tumor with rapid progression rates.\nRecent studies have shown that glioblastoma molecular subtype classification\nserves as a significant biomarker for effective targeted therapy selection.\nHowever, this classification currently requires invasive tissue extraction for\ncomprehensive histopathological analysis. Existing multimodal approaches\ncombining MRI and histopathology images are limited and lack robust mechanisms\nfor preserving shared structural information across modalities. In particular,\ngraph-based models often fail to retain discriminative features within\nheterogeneous graphs, and structural reconstruction mechanisms for handling\nmissing or incomplete modality data are largely underexplored. To address these\nlimitations, we propose a novel sheaf-based framework for structure-aware and\nconsistent fusion of MRI and histopathology data. Our model outperforms\nbaseline methods and demonstrates robustness in incomplete or missing data\nscenarios, contributing to the development of virtual biopsy tools for rapid\ndiagnostics. Our source code is available at\nhttps://github.com/basiralab/MMSN/.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8esheaf\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u878d\u5408MRI\u548c\u7ec4\u7ec7\u75c5\u7406\u5b66\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u6570\u636e\u7f3a\u5931\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u3002", "motivation": "\u80f6\u8d28\u6bcd\u7ec6\u80de\u7624\u7684\u5206\u5b50\u4e9a\u578b\u5206\u7c7b\u9700\u8981\u4fb5\u5165\u6027\u7ec4\u7ec7\u63d0\u53d6\uff0c\u73b0\u6709\u591a\u6a21\u6001\u65b9\u6cd5\u5728\u4fdd\u7559\u8de8\u6a21\u6001\u7ed3\u6784\u4fe1\u606f\u548c\u5904\u7406\u4e0d\u5b8c\u6574\u6570\u636e\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u91c7\u7528sheaf-based\u6846\u67b6\uff0c\u5b9e\u73b0MRI\u548c\u7ec4\u7ec7\u75c5\u7406\u5b66\u6570\u636e\u7684\u7ed3\u6784\u611f\u77e5\u548c\u4e00\u81f4\u6027\u878d\u5408\u3002", "result": "\u6a21\u578b\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u6570\u636e\u4e0d\u5b8c\u6574\u6216\u7f3a\u5931\u60c5\u51b5\u4e0b\u8868\u73b0\u9c81\u68d2\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5feb\u901f\u8bca\u65ad\u7684\u865a\u62df\u6d3b\u68c0\u5de5\u5177\u5f00\u53d1\u63d0\u4f9b\u4e86\u652f\u6301\u3002"}}
{"id": "2508.09721", "pdf": "https://arxiv.org/pdf/2508.09721", "abs": "https://arxiv.org/abs/2508.09721", "authors": ["Yuan-Hao Wei", "Fu-Hao Deng", "Lin-Yong Cui", "Yan-Jie Sun"], "title": "Structured Kernel Regression VAE: A Computationally Efficient Surrogate for GP-VAEs in ICA", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "The interpretability of generative models is considered a key factor in\ndemonstrating their effectiveness and controllability. The generated data are\nbelieved to be determined by latent variables that are not directly observable.\nTherefore, disentangling, decoupling, decomposing, causal inference, or\nperforming Independent Component Analysis (ICA) in the latent variable space\nhelps uncover the independent factors that influence the attributes or features\naffecting the generated outputs, thereby enhancing the interpretability of\ngenerative models. As a generative model, Variational Autoencoders (VAEs)\ncombine with variational Bayesian inference algorithms. Using VAEs, the inverse\nprocess of ICA can be equivalently framed as a variational inference process.\nIn some studies, Gaussian processes (GPs) have been introduced as priors for\neach dimension of latent variables in VAEs, structuring and separating each\ndimension from temporal or spatial perspectives, and encouraging different\ndimensions to control various attributes of the generated data. However, GPs\nimpose a significant computational burden, resulting in substantial resource\nconsumption when handling large datasets. Essentially, GPs model different\ntemporal or spatial structures through various kernel functions. Structuring\nthe priors of latent variables via kernel functions-so that different kernel\nfunctions model the correlations among sequence points within different latent\ndimensions-is at the core of achieving disentanglement in VAEs. The proposed\nStructured Kernel Regression VAE (SKR-VAE) leverages this core idea in a more\nefficient way, avoiding the costly kernel matrix inversion required in GPs.\nThis research demonstrates that, while maintaining ICA performance, SKR-VAE\nachieves greater computational efficiency and significantly reduced\ncomputational burden compared to GP-VAE.", "AI": {"tldr": "SKR-VAE\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6838\u56de\u5f52\u5728VAE\u4e2d\u5b9e\u73b0\u89e3\u8026\uff0c\u907f\u514d\u4e86\u9ad8\u65af\u8fc7\u7a0b\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86ICA\u6027\u80fd\u3002", "motivation": "\u63d0\u5347\u751f\u6210\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u63a7\u6027\uff0c\u540c\u65f6\u89e3\u51b3\u9ad8\u65af\u8fc7\u7a0b\u5728VAE\u4e2d\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u7ed3\u6784\u5316\u6838\u56de\u5f52\u66ff\u4ee3\u9ad8\u65af\u8fc7\u7a0b\uff0c\u5bf9VAE\u7684\u6f5c\u5728\u53d8\u91cf\u8fdb\u884c\u89e3\u8026\uff0c\u907f\u514d\u6838\u77e9\u9635\u6c42\u9006\u7684\u9ad8\u8ba1\u7b97\u8d1f\u62c5\u3002", "result": "SKR-VAE\u5728\u4fdd\u6301ICA\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u964d\u4f4e\u4e86\u8ba1\u7b97\u8d1f\u62c5\u3002", "conclusion": "SKR-VAE\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u751f\u6210\u6a21\u578b\u6539\u8fdb\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002"}}
{"id": "2508.09726", "pdf": "https://arxiv.org/pdf/2508.09726", "abs": "https://arxiv.org/abs/2508.09726", "authors": ["Vaishnavi Shrivastava", "Ahmed Awadallah", "Vidhisha Balachandran", "Shivam Garg", "Harkirat Behl", "Dimitris Papailiopoulos"], "title": "Sample More to Think Less: Group Filtered Policy Optimization for Concise Reasoning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models trained with reinforcement learning with verifiable\nrewards tend to trade accuracy for length--inflating response lengths to\nachieve gains in accuracy. While longer answers may be warranted for harder\nproblems, many tokens are merely \"filler\": repetitive, verbose text that makes\nno real progress. We introduce GFPO (Group Filtered Policy Optimization), which\ncurbs this length explosion by sampling larger groups per problem during\ntraining and filtering responses to train on based on two key metrics: (1)\nresponse length and (2) token efficiency: reward per token ratio. By sampling\nmore at training time, we teach models to think less at inference time. On the\nPhi-4-reasoning model, GFPO cuts GRPO's length inflation by 46-71% across\nchallenging STEM and coding benchmarks (AIME 24/25, GPQA, Omni-MATH,\nLiveCodeBench) while maintaining accuracy. Optimizing for reward per token\nfurther increases reductions in length inflation to 71-85%. We also propose\nAdaptive Difficulty GFPO, which dynamically allocates more training resources\nto harder problems based on real-time difficulty estimates, improving the\nbalance between computational efficiency and accuracy especially on difficult\nquestions. GFPO demonstrates that increased training-time compute directly\ntranslates to reduced test-time compute--a simple yet effective trade-off for\nefficient reasoning.", "AI": {"tldr": "GFPO\u901a\u8fc7\u8bad\u7ec3\u65f6\u91c7\u6837\u66f4\u591a\u7ec4\u5e76\u57fa\u4e8e\u957f\u5ea6\u548c\u5956\u52b1\u6548\u7387\u8fc7\u6ee4\u54cd\u5e94\uff0c\u6709\u6548\u51cf\u5c11\u8bed\u8a00\u6a21\u578b\u4e3a\u8ffd\u6c42\u51c6\u786e\u6027\u800c\u8fc7\u5ea6\u5ef6\u957f\u56de\u7b54\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u503e\u5411\u4e8e\u901a\u8fc7\u589e\u52a0\u56de\u7b54\u957f\u5ea6\u6765\u63d0\u5347\u51c6\u786e\u6027\uff0c\u5bfc\u81f4\u8bb8\u591a\u5197\u4f59\u5185\u5bb9\u3002", "method": "\u5f15\u5165GFPO\u65b9\u6cd5\uff0c\u8bad\u7ec3\u65f6\u91c7\u6837\u66f4\u591a\u7ec4\uff0c\u57fa\u4e8e\u957f\u5ea6\u548c\u5956\u52b1\u6548\u7387\u8fc7\u6ee4\u54cd\u5e94\uff0c\u5e76\u52a8\u6001\u5206\u914d\u8d44\u6e90\u5230\u96be\u9898\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGFPO\u5c06\u957f\u5ea6\u81a8\u80c0\u51cf\u5c1146-85%\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "conclusion": "GFPO\u8bc1\u660e\u589e\u52a0\u8bad\u7ec3\u8ba1\u7b97\u53ef\u76f4\u63a5\u51cf\u5c11\u6d4b\u8bd5\u8ba1\u7b97\uff0c\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u3002"}}
{"id": "2508.09765", "pdf": "https://arxiv.org/pdf/2508.09765", "abs": "https://arxiv.org/abs/2508.09765", "authors": ["Zijiang Yang"], "title": "Enhance the machine learning algorithm performance in phishing detection with keyword features", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.NE"], "comment": null, "summary": "Recently, we can observe a significant increase of the phishing attacks in\nthe Internet. In a typical phishing attack, the attacker sets up a malicious\nwebsite that looks similar to the legitimate website in order to obtain the\nend-users' information. This may cause the leakage of the sensitive information\nand the financial loss for the end-users. To avoid such attacks, the early\ndetection of these websites' URLs is vital and necessary. Previous researchers\nhave proposed many machine learning algorithms to distinguish the phishing URLs\nfrom the legitimate ones. In this paper, we would like to enhance these machine\nlearning algorithms from the perspective of feature selection. We propose a\nnovel method to incorporate the keyword features with the traditional features.\nThis method is applied on multiple traditional machine learning algorithms and\nthe experimental results have shown this method is useful and effective. On\naverage, this method can reduce the classification error by 30% for the large\ndataset. Moreover, its enhancement is more significant for the small dataset.\nIn addition, this method extracts the information from the URL and does not\nrely on the additional information provided by the third-part service. The best\nresult for the machine learning algorithm using our proposed method has\nachieved the accuracy of 99.68%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5173\u952e\u8bcd\u7279\u5f81\u4e0e\u4f20\u7edf\u7279\u5f81\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u589e\u5f3a\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u68c0\u6d4b\u9493\u9c7cURL\u7684\u80fd\u529b\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u5206\u7c7b\u9519\u8bef\u7387\u3002", "motivation": "\u9493\u9c7c\u653b\u51fb\u65e5\u76ca\u589e\u591a\uff0c\u5bfc\u81f4\u7528\u6237\u654f\u611f\u4fe1\u606f\u6cc4\u9732\u548c\u8d22\u52a1\u635f\u5931\uff0c\u65e9\u671f\u68c0\u6d4b\u9493\u9c7cURL\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5173\u952e\u8bcd\u7279\u5f81\u4e0e\u4f20\u7edf\u7279\u5f81\u7684\u65b0\u65b9\u6cd5\uff0c\u5e94\u7528\u4e8e\u591a\u79cd\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5927\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u51cf\u5c1130%\u7684\u5206\u7c7b\u9519\u8bef\uff0c\u5bf9\u5c0f\u6570\u636e\u96c6\u6548\u679c\u66f4\u663e\u8457\uff0c\u6700\u4f73\u51c6\u786e\u7387\u8fbe99.68%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u9493\u9c7cURL\u68c0\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u4e14\u4e0d\u4f9d\u8d56\u7b2c\u4e09\u65b9\u670d\u52a1\u63d0\u4f9b\u7684\u4fe1\u606f\u3002"}}
{"id": "2508.09803", "pdf": "https://arxiv.org/pdf/2508.09803", "abs": "https://arxiv.org/abs/2508.09803", "authors": ["Carlos Franzreb", "Arnab Das", "Tim Polzehl", "Sebastian M\u00f6ller"], "title": "Improving the Speaker Anonymization Evaluation's Robustness to Target Speakers with Adversarial Learning", "categories": ["eess.AS", "cs.LG"], "comment": null, "summary": "The current privacy evaluation for speaker anonymization often overestimates\nprivacy when a same-gender target selection algorithm (TSA) is used, although\nthis TSA leaks the speaker's gender and should hence be more vulnerable. We\nhypothesize that this occurs because the evaluation does not account for the\nfact that anonymized speech contains information from both the source and\ntarget speakers. To address this, we propose to add a target classifier that\nmeasures the influence of target speaker information in the evaluation, which\ncan also be removed with adversarial learning. Experiments demonstrate that\nthis approach is effective for multiple anonymizers, particularly when using a\nsame-gender TSA, leading to a more reliable assessment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u9690\u79c1\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u6dfb\u52a0\u76ee\u6807\u5206\u7c7b\u5668\u6765\u66f4\u51c6\u786e\u5730\u8861\u91cf\u8bf4\u8bdd\u4eba\u533f\u540d\u5316\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u8bf4\u8bdd\u4eba\u533f\u540d\u5316\u7684\u9690\u79c1\u8bc4\u4f30\u5728\u4f7f\u7528\u540c\u6027\u522b\u76ee\u6807\u9009\u62e9\u7b97\u6cd5\uff08TSA\uff09\u65f6\u9ad8\u4f30\u4e86\u9690\u79c1\u4fdd\u62a4\u6548\u679c\uff0c\u5ffd\u7565\u4e86\u533f\u540d\u5316\u8bed\u97f3\u4e2d\u540c\u65f6\u5305\u542b\u6e90\u8bf4\u8bdd\u4eba\u548c\u76ee\u6807\u8bf4\u8bdd\u4eba\u4fe1\u606f\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6dfb\u52a0\u76ee\u6807\u5206\u7c7b\u5668\u6765\u8bc4\u4f30\u76ee\u6807\u8bf4\u8bdd\u4eba\u4fe1\u606f\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u5bf9\u6297\u5b66\u4e60\u6d88\u9664\u8fd9\u79cd\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5bf9\u591a\u79cd\u533f\u540d\u5316\u5668\u6709\u6548\uff0c\u5c24\u5176\u662f\u5728\u4f7f\u7528\u540c\u6027\u522bTSA\u65f6\uff0c\u80fd\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u6539\u8fdb\u4e86\u9690\u79c1\u8bc4\u4f30\u7684\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728\u540c\u6027\u522bTSA\u573a\u666f\u4e0b\u3002"}}
{"id": "2508.09811", "pdf": "https://arxiv.org/pdf/2508.09811", "abs": "https://arxiv.org/abs/2508.09811", "authors": ["Jinxi Li", "Ziyang Song", "Bo Yang"], "title": "TRACE: Learning 3D Gaussian Physical Dynamics from Multi-view Videos", "categories": ["cs.CV", "cs.AI", "cs.CE", "cs.LG", "cs.RO"], "comment": "ICCV 2025. Code and data are available at:\n  https://github.com/vLAR-group/TRACE", "summary": "In this paper, we aim to model 3D scene geometry, appearance, and physical\ninformation just from dynamic multi-view videos in the absence of any human\nlabels. By leveraging physics-informed losses as soft constraints or\nintegrating simple physics models into neural nets, existing works often fail\nto learn complex motion physics, or doing so requires additional labels such as\nobject types or masks. We propose a new framework named TRACE to model the\nmotion physics of complex dynamic 3D scenes. The key novelty of our method is\nthat, by formulating each 3D point as a rigid particle with size and\norientation in space, we directly learn a translation rotation dynamics system\nfor each particle, explicitly estimating a complete set of physical parameters\nto govern the particle's motion over time. Extensive experiments on three\nexisting dynamic datasets and one newly created challenging synthetic datasets\ndemonstrate the extraordinary performance of our method over baselines in the\ntask of future frame extrapolation. A nice property of our framework is that\nmultiple objects or parts can be easily segmented just by clustering the\nlearned physical parameters.", "AI": {"tldr": "TRACE\u6846\u67b6\u901a\u8fc7\u5c063D\u70b9\u5efa\u6a21\u4e3a\u521a\u6027\u7c92\u5b50\uff0c\u76f4\u63a5\u5b66\u4e60\u5176\u5e73\u79fb\u65cb\u8f6c\u52a8\u529b\u5b66\u7cfb\u7edf\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u7b7e\u5373\u53ef\u5efa\u6a21\u590d\u6742\u52a8\u60013D\u573a\u666f\u7684\u7269\u7406\u8fd0\u52a8\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u7269\u7406\u6a21\u578b\u6216\u6807\u7b7e\uff0c\u96be\u4ee5\u5b66\u4e60\u590d\u6742\u8fd0\u52a8\u7269\u7406\u3002TRACE\u65e8\u5728\u65e0\u6807\u7b7e\u6761\u4ef6\u4e0b\u5efa\u6a213D\u573a\u666f\u7684\u51e0\u4f55\u3001\u5916\u89c2\u548c\u7269\u7406\u4fe1\u606f\u3002", "method": "\u5c063D\u70b9\u89c6\u4e3a\u521a\u6027\u7c92\u5b50\uff0c\u5b66\u4e60\u5176\u5e73\u79fb\u65cb\u8f6c\u52a8\u529b\u5b66\u7cfb\u7edf\uff0c\u663e\u5f0f\u4f30\u8ba1\u7269\u7406\u53c2\u6570\u4ee5\u63a7\u5236\u7c92\u5b50\u8fd0\u52a8\u3002", "result": "\u5728\u591a\u4e2a\u52a8\u6001\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u5728\u672a\u6765\u5e27\u5916\u63a8\u4efb\u52a1\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "TRACE\u4e0d\u4ec5\u80fd\u5efa\u6a21\u590d\u6742\u7269\u7406\u8fd0\u52a8\uff0c\u8fd8\u80fd\u901a\u8fc7\u805a\u7c7b\u7269\u7406\u53c2\u6570\u8f7b\u677e\u5206\u5272\u591a\u7269\u4f53\u6216\u90e8\u4ef6\u3002"}}
{"id": "2508.09830", "pdf": "https://arxiv.org/pdf/2508.09830", "abs": "https://arxiv.org/abs/2508.09830", "authors": ["Shenxing Wei", "Jinxi Li", "Yafei Yang", "Siyuan Zhou", "Bo Yang"], "title": "RayletDF: Raylet Distance Fields for Generalizable 3D Surface Reconstruction from Point Clouds or Gaussians", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG", "cs.RO"], "comment": "ICCV 2025 Highlight. Shenxing and Jinxi are co-first authors. Code\n  and data are available at: https://github.com/vLAR-group/RayletDF", "summary": "In this paper, we present a generalizable method for 3D surface\nreconstruction from raw point clouds or pre-estimated 3D Gaussians by 3DGS from\nRGB images. Unlike existing coordinate-based methods which are often\ncomputationally intensive when rendering explicit surfaces, our proposed\nmethod, named RayletDF, introduces a new technique called raylet distance\nfield, which aims to directly predict surface points from query rays. Our\npipeline consists of three key modules: a raylet feature extractor, a raylet\ndistance field predictor, and a multi-raylet blender. These components work\ntogether to extract fine-grained local geometric features, predict raylet\ndistances, and aggregate multiple predictions to reconstruct precise surface\npoints. We extensively evaluate our method on multiple public real-world\ndatasets, demonstrating superior performance in surface reconstruction from\npoint clouds or 3D Gaussians. Most notably, our method achieves exceptional\ngeneralization ability, successfully recovering 3D surfaces in a single-forward\npass across unseen datasets in testing.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRayletDF\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u70b9\u4e91\u62163D\u9ad8\u65af\u4e2d\u91cd\u5efa3D\u8868\u9762\uff0c\u901a\u8fc7\u5c04\u7ebf\u8ddd\u79bb\u573a\u76f4\u63a5\u9884\u6d4b\u8868\u9762\u70b9\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5750\u6807\u7684\u65b9\u6cd5\u5728\u6e32\u67d3\u663e\u5f0f\u8868\u9762\u65f6\u8ba1\u7b97\u91cf\u5927\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4e09\u4e2a\u5173\u952e\u6a21\u5757\uff1a\u5c04\u7ebf\u7279\u5f81\u63d0\u53d6\u5668\u3001\u5c04\u7ebf\u8ddd\u79bb\u573a\u9884\u6d4b\u5668\u548c\u591a\u5c04\u7ebf\u6df7\u5408\u5668\uff0c\u4ee5\u63d0\u53d6\u51e0\u4f55\u7279\u5f81\u3001\u9884\u6d4b\u8ddd\u79bb\u5e76\u805a\u5408\u7ed3\u679c\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u6709\u51fa\u8272\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u80fd\u5728\u672a\u89c1\u6570\u636e\u96c6\u4e0a\u5355\u6b21\u524d\u5411\u4f20\u64ad\u91cd\u5efa\u8868\u9762\u3002", "conclusion": "RayletDF\u65b9\u6cd5\u9ad8\u6548\u4e14\u6cdb\u5316\u80fd\u529b\u5f3a\uff0c\u9002\u7528\u4e8e3D\u8868\u9762\u91cd\u5efa\u3002"}}
{"id": "2508.09844", "pdf": "https://arxiv.org/pdf/2508.09844", "abs": "https://arxiv.org/abs/2508.09844", "authors": ["Jasmin Frkatovic", "Akash Malemath", "Ivan Kankeu", "Yannick Werner", "Matthias Tsch\u00f6pe", "Vitor Fortes Rey", "Sungho Suh", "Paul Lukowicz", "Nikolaos Palaiodimopoulos", "Maximilian Kiefer-Emmanouilidis"], "title": "On the Generalization Limits of Quantum Generative Adversarial Networks with Pure State Generators", "categories": ["quant-ph", "cs.LG"], "comment": "16 pages, 5 figures", "summary": "We investigate the capabilities of Quantum Generative Adversarial Networks\n(QGANs) in image generations tasks. Our analysis centers on fully quantum\nimplementations of both the generator and discriminator. Through extensive\nnumerical testing of current main architectures, we find that QGANs struggle to\ngeneralize across datasets, converging on merely the average representation of\nthe training data. When the output of the generator is a pure-state, we\nanalytically derive a lower bound for the discriminator quality given by the\nfidelity between the pure-state output of the generator and the target data\ndistribution, thereby providing a theoretical explanation for the limitations\nobserved in current models. Our findings reveal fundamental challenges in the\ngeneralization capabilities of existing quantum generative models. While our\nanalysis focuses on QGANs, the results carry broader implications for the\nperformance of related quantum generative models.", "AI": {"tldr": "QGANs\u5728\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u96be\u4ee5\u6cdb\u5316\u5230\u4e0d\u540c\u6570\u636e\u96c6\uff0c\u4ec5\u80fd\u6536\u655b\u4e8e\u8bad\u7ec3\u6570\u636e\u7684\u5e73\u5747\u8868\u793a\u3002\u7eaf\u6001\u8f93\u51fa\u65f6\uff0c\u751f\u6210\u5668\u4e0e\u76ee\u6807\u6570\u636e\u5206\u5e03\u4e4b\u95f4\u7684\u4fdd\u771f\u5ea6\u9650\u5236\u4e86\u5224\u522b\u5668\u8d28\u91cf\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08QGANs\uff09\u5728\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u63a2\u7d22\u5176\u5c40\u9650\u6027\u53ca\u5176\u5bf9\u76f8\u5173\u91cf\u5b50\u751f\u6210\u6a21\u578b\u7684\u5e7f\u6cdb\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u6570\u503c\u6d4b\u8bd5\u5f53\u524d\u4e3b\u8981\u67b6\u6784\uff0c\u5206\u6790\u7eaf\u6001\u8f93\u51fa\u65f6\u7684\u7406\u8bba\u4e0b\u9650\u3002", "result": "QGANs\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u751f\u6210\u5668\u8f93\u51fa\u4e0e\u76ee\u6807\u5206\u5e03\u7684\u4fdd\u771f\u5ea6\u9650\u5236\u4e86\u5224\u522b\u5668\u8d28\u91cf\u3002", "conclusion": "\u73b0\u6709\u91cf\u5b50\u751f\u6210\u6a21\u578b\u5728\u6cdb\u5316\u80fd\u529b\u4e0a\u5b58\u5728\u6839\u672c\u6027\u6311\u6218\uff0c\u7ed3\u679c\u5bf9\u76f8\u5173\u91cf\u5b50\u6a21\u578b\u5177\u6709\u5e7f\u6cdb\u610f\u4e49\u3002"}}
{"id": "2508.09937", "pdf": "https://arxiv.org/pdf/2508.09937", "abs": "https://arxiv.org/abs/2508.09937", "authors": ["Muneeza Azmat", "Momin Abbas", "Maysa Malfiza Garcia de Macedo", "Marcelo Carpinette Grave", "Luan Soares de Souza", "Tiago Machado", "Rogerio A de Paula", "Raya Horesh", "Yixin Chen", "Heloisa Caroline de Souza Pereira Candello", "Rebecka Nordenlow", "Aminat Adebiyi"], "title": "A Comprehensive Evaluation framework of Alignment Techniques for LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "In submission", "summary": "As Large Language Models (LLMs) become increasingly integrated into\nreal-world applications, ensuring their outputs align with human values and\nsafety standards has become critical. The field has developed diverse alignment\napproaches including traditional fine-tuning methods (RLHF, instruction\ntuning), post-hoc correction systems, and inference-time interventions, each\nwith distinct advantages and limitations. However, the lack of unified\nevaluation frameworks makes it difficult to systematically compare these\nparadigms and guide deployment decisions. This paper introduces a\nmulti-dimensional evaluation of alignment techniques for LLMs, a comprehensive\nevaluation framework that provides a systematic comparison across all major\nalignment paradigms. Our framework assesses methods along four key dimensions:\nalignment detection, alignment quality, computational efficiency, and\nrobustness. Through experiments across diverse base models and alignment\nstrategies, we demonstrate the utility of our framework in identifying\nstrengths and limitations of current state-of-the-art models, providing\nvaluable insights for future research directions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u6bd4\u8f83\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5bf9\u9f50\u6280\u672f\uff0c\u6db5\u76d6\u68c0\u6d4b\u3001\u8d28\u91cf\u3001\u8ba1\u7b97\u6548\u7387\u548c\u9c81\u68d2\u6027\u56db\u4e2a\u7ef4\u5ea6\u3002", "motivation": "\u968f\u7740LLM\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u666e\u53ca\uff0c\u786e\u4fdd\u5176\u8f93\u51fa\u7b26\u5408\u4eba\u7c7b\u4ef7\u503c\u89c2\u548c\u5b89\u5168\u6807\u51c6\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u7cfb\u7edf\u6bd4\u8f83\u4e0d\u540c\u5bf9\u9f50\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u4ece\u5bf9\u9f50\u68c0\u6d4b\u3001\u5bf9\u9f50\u8d28\u91cf\u3001\u8ba1\u7b97\u6548\u7387\u548c\u9c81\u68d2\u6027\u56db\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u4e3b\u6d41\u5bf9\u9f50\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u6709\u6548\u8bc6\u522b\u5f53\u524d\u5148\u8fdb\u6a21\u578b\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u65b9\u5411\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7cfb\u7edf\u8bc4\u4f30\u548c\u6bd4\u8f83LLM\u5bf9\u9f50\u6280\u672f\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u6307\u5bfc\u90e8\u7f72\u51b3\u7b56\u548c\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2508.09949", "pdf": "https://arxiv.org/pdf/2508.09949", "abs": "https://arxiv.org/abs/2508.09949", "authors": ["Trevine Oorloff", "Vishwanath Sindagi", "Wele Gedara Chaminda Bandara", "Ali Shafahi", "Amin Ghiasi", "Charan Prakash", "Reza Ardekani"], "title": "Stable Diffusion Models are Secretly Good at Visual In-Context Learning", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted to ICCV 2025", "summary": "Large language models (LLM) in natural language processing (NLP) have\ndemonstrated great potential for in-context learning (ICL) -- the ability to\nleverage a few sets of example prompts to adapt to various tasks without having\nto explicitly update the model weights. ICL has recently been explored for\ncomputer vision tasks with promising early outcomes. These approaches involve\nspecialized training and/or additional data that complicate the process and\nlimit its generalizability. In this work, we show that off-the-shelf Stable\nDiffusion models can be repurposed for visual in-context learning (V-ICL).\nSpecifically, we formulate an in-place attention re-computation within the\nself-attention layers of the Stable Diffusion architecture that explicitly\nincorporates context between the query and example prompts. Without any\nadditional fine-tuning, we show that this repurposed Stable Diffusion model is\nable to adapt to six different tasks: foreground segmentation, single object\ndetection, semantic segmentation, keypoint detection, edge detection, and\ncolorization. For example, the proposed approach improves the mean intersection\nover union (mIoU) for the foreground segmentation task on Pascal-5i dataset by\n8.9% and 3.2% over recent methods such as Visual Prompting and IMProv,\nrespectively. Additionally, we show that the proposed method is able to\neffectively leverage multiple prompts through ensembling to infer the task\nbetter and further improve the performance.", "AI": {"tldr": "Stable Diffusion\u6a21\u578b\u53ef\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u5c42\u6539\u9020\u5b9e\u73b0\u89c6\u89c9\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08V-ICL\uff09\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u9002\u5e94\u591a\u79cd\u89c6\u89c9\u4efb\u52a1\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u5229\u7528\u73b0\u6210\u7684Stable Diffusion\u6a21\u578b\u5b9e\u73b0\u89c6\u89c9\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u907f\u514d\u590d\u6742\u8bad\u7ec3\u548c\u6570\u636e\u9650\u5236\u3002", "method": "\u5728Stable Diffusion\u7684\u81ea\u6ce8\u610f\u529b\u5c42\u4e2d\u5f15\u5165\u4e0a\u4e0b\u6587\u91cd\u8ba1\u7b97\u673a\u5236\uff0c\u663e\u5f0f\u7ed3\u5408\u67e5\u8be2\u4e0e\u793a\u4f8b\u63d0\u793a\u3002", "result": "\u6a21\u578b\u5728\u516d\u79cd\u89c6\u89c9\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5982\u524d\u666f\u5206\u5272\u4efb\u52a1\u5728Pascal-5i\u6570\u636e\u96c6\u4e0amIoU\u63d0\u53478.9%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u9ad8\u6548\u9002\u5e94\u591a\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u96c6\u6210\u591a\u63d0\u793a\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2508.09952", "pdf": "https://arxiv.org/pdf/2508.09952", "abs": "https://arxiv.org/abs/2508.09952", "authors": ["Hermione Warr", "Wentian Xu", "Harry Anthony", "Yasin Ibrahim", "Daniel McGowan", "Konstantinos Kamnitsas"], "title": "Specialised or Generic? Tokenization Choices for Radiology Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to ELAMI@MICCAI2025", "summary": "The vocabulary used by language models (LM) - defined by the tokenizer -\nplays a key role in text generation quality. However, its impact remains\nunder-explored in radiology. In this work, we address this gap by\nsystematically comparing general, medical, and domain-specific tokenizers on\nthe task of radiology report summarisation across three imaging modalities. We\nalso investigate scenarios with and without LM pre-training on PubMed\nabstracts. Our findings demonstrate that medical and domain-specific\nvocabularies outperformed widely used natural language alternatives when models\nare trained from scratch. Pre-training partially mitigates performance\ndifferences between tokenizers, whilst the domain-specific tokenizers achieve\nthe most favourable results. Domain-specific tokenizers also reduce memory\nrequirements due to smaller vocabularies and shorter sequences. These results\ndemonstrate that adapting the vocabulary of LMs to the clinical domain provides\npractical benefits, including improved performance and reduced computational\ndemands, making such models more accessible and effective for both research and\nreal-world healthcare settings.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u901a\u7528\u3001\u533b\u5b66\u548c\u9886\u57df\u7279\u5b9a\u5206\u8bcd\u5668\u5728\u653e\u5c04\u5b66\u62a5\u544a\u6458\u8981\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u9886\u57df\u7279\u5b9a\u5206\u8bcd\u5668\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u63a2\u7d22\u5206\u8bcd\u5668\u5bf9\u8bed\u8a00\u6a21\u578b\u5728\u653e\u5c04\u5b66\u6587\u672c\u751f\u6210\u8d28\u91cf\u4e2d\u7684\u5f71\u54cd\uff0c\u586b\u8865\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u7cfb\u7edf\u6bd4\u8f83\u901a\u7528\u3001\u533b\u5b66\u548c\u9886\u57df\u7279\u5b9a\u5206\u8bcd\u5668\u5728\u4e09\u79cd\u6210\u50cf\u6a21\u6001\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u7814\u7a76\u6709\u65e0\u9884\u8bad\u7ec3\u7684\u5f71\u54cd\u3002", "result": "\u533b\u5b66\u548c\u9886\u57df\u7279\u5b9a\u5206\u8bcd\u5668\u5728\u4ece\u5934\u8bad\u7ec3\u65f6\u8868\u73b0\u4f18\u4e8e\u901a\u7528\u5206\u8bcd\u5668\uff0c\u9884\u8bad\u7ec3\u90e8\u5206\u7f29\u5c0f\u4e86\u6027\u80fd\u5dee\u8ddd\uff0c\u9886\u57df\u7279\u5b9a\u5206\u8bcd\u5668\u8868\u73b0\u6700\u4f18\u4e14\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "\u9002\u5e94\u4e34\u5e8a\u9886\u57df\u7684\u5206\u8bcd\u5668\u80fd\u63d0\u5347\u6027\u80fd\u5e76\u964d\u4f4e\u8ba1\u7b97\u9700\u6c42\uff0c\u6709\u52a9\u4e8e\u7814\u7a76\u548c\u5b9e\u9645\u533b\u7597\u5e94\u7528\u3002"}}
{"id": "2508.09958", "pdf": "https://arxiv.org/pdf/2508.09958", "abs": "https://arxiv.org/abs/2508.09958", "authors": ["Baran Atalar", "Eddie Zhang", "Carlee Joe-Wong"], "title": "Neural Bandit Based Optimal LLM Selection for a Pipeline of Tasks", "categories": ["cs.CL", "cs.LG"], "comment": "Submitted to AAAI 2026", "summary": "With the increasing popularity of large language models (LLMs) for a variety\nof tasks, there has been a growing interest in strategies that can predict\nwhich out of a set of LLMs will yield a successful answer at low cost. This\nproblem promises to become more and more relevant as providers like Microsoft\nallow users to easily create custom LLM \"assistants\" specialized to particular\ntypes of queries. However, some tasks (i.e., queries) may be too specialized\nand difficult for a single LLM to handle alone. These applications often\nbenefit from breaking down the task into smaller subtasks, each of which can\nthen be executed by a LLM expected to perform well on that specific subtask.\nFor example, in extracting a diagnosis from medical records, one can first\nselect an LLM to summarize the record, select another to validate the summary,\nand then select another, possibly different, LLM to extract the diagnosis from\nthe summarized record. Unlike existing LLM selection or routing algorithms,\nthis setting requires that we select a sequence of LLMs, with the output of\neach LLM feeding into the next and potentially influencing its success. Thus,\nunlike single LLM selection, the quality of each subtask's output directly\naffects the inputs, and hence the cost and success rate, of downstream LLMs,\ncreating complex performance dependencies that must be learned and accounted\nfor during selection. We propose a neural contextual bandit-based algorithm\nthat trains neural networks that model LLM success on each subtask in an online\nmanner, thus learning to guide the LLM selections for the different subtasks,\neven in the absence of historical LLM performance data. Experiments on\ntelecommunications question answering and medical diagnosis prediction datasets\nillustrate the effectiveness of our proposed approach compared to other LLM\nselection algorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u52a8\u6001\u9009\u62e9\u9002\u5408\u4e0d\u540c\u5b50\u4efb\u52a1\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5e8f\u5217\uff0c\u4ee5\u4f18\u5316\u4efb\u52a1\u5b8c\u6210\u6548\u679c\u548c\u6210\u672c\u3002", "motivation": "\u968f\u7740LLM\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5982\u4f55\u9ad8\u6548\u9009\u62e9\u9002\u5408\u7279\u5b9a\u5b50\u4efb\u52a1\u7684LLM\u5e8f\u5217\u6210\u4e3a\u5173\u952e\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u4efb\u52a1\u4e2d\uff0c\u5355\u4e2aLLM\u53ef\u80fd\u65e0\u6cd5\u80dc\u4efb\u3002", "method": "\u91c7\u7528\u795e\u7ecf\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u7b97\u6cd5\uff0c\u5728\u7ebf\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u52a8\u6001\u5b66\u4e60\u6bcf\u4e2a\u5b50\u4efb\u52a1\u7684LLM\u9009\u62e9\u7b56\u7565\u3002", "result": "\u5728\u7535\u4fe1\u95ee\u7b54\u548c\u533b\u7597\u8bca\u65ad\u9884\u6d4b\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4f18\u4e8e\u5176\u4ed6LLM\u9009\u62e9\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u80fd\u591f\u52a8\u6001\u4f18\u5316LLM\u5e8f\u5217\u9009\u62e9\uff0c\u9002\u5e94\u590d\u6742\u4efb\u52a1\u9700\u6c42\uff0c\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u548c\u6210\u672c\u6548\u7387\u3002"}}
{"id": "2508.09960", "pdf": "https://arxiv.org/pdf/2508.09960", "abs": "https://arxiv.org/abs/2508.09960", "authors": ["Yifei Yao", "Chengyuan Luo", "Jiaheng Du", "Wentao He", "Jun-Guo Lu"], "title": "GBC: Generalized Behavior-Cloning Framework for Whole-Body Humanoid Imitation", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "The creation of human-like humanoid robots is hindered by a fundamental\nfragmentation: data processing and learning algorithms are rarely universal\nacross different robot morphologies. This paper introduces the Generalized\nBehavior Cloning (GBC) framework, a comprehensive and unified solution designed\nto solve this end-to-end challenge. GBC establishes a complete pathway from\nhuman motion to robot action through three synergistic innovations. First, an\nadaptive data pipeline leverages a differentiable IK network to automatically\nretarget any human MoCap data to any humanoid. Building on this foundation, our\nnovel DAgger-MMPPO algorithm with its MMTransformer architecture learns robust,\nhigh-fidelity imitation policies. To complete the ecosystem, the entire\nframework is delivered as an efficient, open-source platform based on Isaac\nLab, empowering the community to deploy the full workflow via simple\nconfiguration scripts. We validate the power and generality of GBC by training\npolicies on multiple heterogeneous humanoids, demonstrating excellent\nperformance and transfer to novel motions. This work establishes the first\npractical and unified pathway for creating truly generalized humanoid\ncontrollers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u884c\u4e3a\u514b\u9686\uff08GBC\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6570\u636e\u7ba1\u9053\u3001DAgger-MMPPO\u7b97\u6cd5\u548c\u5f00\u6e90\u5e73\u53f0\uff0c\u89e3\u51b3\u4e86\u4eba\u5f62\u673a\u5668\u4eba\u6570\u636e\u5904\u7406\u7684\u788e\u7247\u5316\u95ee\u9898\u3002", "motivation": "\u4eba\u5f62\u673a\u5668\u4eba\u5f00\u53d1\u4e2d\u6570\u636e\u5904\u7406\u548c\u5b66\u4e60\u7b97\u6cd5\u7684\u788e\u7247\u5316\u95ee\u9898\u963b\u788d\u4e86\u901a\u7528\u6027\uff0cGBC\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\u3002", "method": "GBC\u901a\u8fc7\u81ea\u9002\u5e94\u6570\u636e\u7ba1\u9053\uff08\u5229\u7528\u53ef\u5fae\u5206IK\u7f51\u7edc\uff09\u3001DAgger-MMPPO\u7b97\u6cd5\u548c\u5f00\u6e90\u5e73\u53f0\uff08\u57fa\u4e8eIsaac Lab\uff09\u5b9e\u73b0\u4eba\u5f62\u673a\u5668\u4eba\u52a8\u4f5c\u7684\u901a\u7528\u5b66\u4e60\u3002", "result": "\u5728\u591a\u79cd\u5f02\u6784\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\u4e86GBC\u7684\u4f18\u5f02\u6027\u80fd\u548c\u52a8\u4f5c\u8fc1\u79fb\u80fd\u529b\u3002", "conclusion": "GBC\u9996\u6b21\u5b9e\u73b0\u4e86\u771f\u6b63\u901a\u7528\u7684\u4eba\u5f62\u673a\u5668\u4eba\u63a7\u5236\u5668\uff0c\u4e3a\u9886\u57df\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09983", "pdf": "https://arxiv.org/pdf/2508.09983", "abs": "https://arxiv.org/abs/2508.09983", "authors": ["David Dinkevich", "Matan Levy", "Omri Avrahami", "Dvir Samuel", "Dani Lischinski"], "title": "Story2Board: A Training-Free Approach for Expressive Storyboard Generation", "categories": ["cs.CV", "cs.GR", "cs.LG"], "comment": "Project page is available at\n  https://daviddinkevich.github.io/Story2Board/", "summary": "We present Story2Board, a training-free framework for expressive storyboard\ngeneration from natural language. Existing methods narrowly focus on subject\nidentity, overlooking key aspects of visual storytelling such as spatial\ncomposition, background evolution, and narrative pacing. To address this, we\nintroduce a lightweight consistency framework composed of two components:\nLatent Panel Anchoring, which preserves a shared character reference across\npanels, and Reciprocal Attention Value Mixing, which softly blends visual\nfeatures between token pairs with strong reciprocal attention. Together, these\nmechanisms enhance coherence without architectural changes or fine-tuning,\nenabling state-of-the-art diffusion models to generate visually diverse yet\nconsistent storyboards. To structure generation, we use an off-the-shelf\nlanguage model to convert free-form stories into grounded panel-level prompts.\nTo evaluate, we propose the Rich Storyboard Benchmark, a suite of open-domain\nnarratives designed to assess layout diversity and background-grounded\nstorytelling, in addition to consistency. We also introduce a new Scene\nDiversity metric that quantifies spatial and pose variation across storyboards.\nOur qualitative and quantitative results, as well as a user study, show that\nStory2Board produces more dynamic, coherent, and narratively engaging\nstoryboards than existing baselines.", "AI": {"tldr": "Story2Board\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210\u5bcc\u6709\u8868\u73b0\u529b\u7684\u6545\u4e8b\u677f\u3002\u5b83\u901a\u8fc7\u8f7b\u91cf\u7ea7\u4e00\u81f4\u6027\u6846\u67b6\uff08\u5305\u62ec\u6f5c\u5728\u9762\u677f\u951a\u5b9a\u548c\u4e92\u60e0\u6ce8\u610f\u529b\u503c\u6df7\u5408\uff09\u589e\u5f3a\u8fde\u8d2f\u6027\uff0c\u65e0\u9700\u67b6\u6784\u66f4\u6539\u6216\u5fae\u8c03\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8fc7\u4e8e\u5173\u6ce8\u4e3b\u9898\u8eab\u4efd\uff0c\u5ffd\u7565\u4e86\u89c6\u89c9\u53d9\u4e8b\u7684\u5173\u952e\u65b9\u9762\uff08\u5982\u7a7a\u95f4\u6784\u56fe\u3001\u80cc\u666f\u6f14\u53d8\u548c\u53d9\u4e8b\u8282\u594f\uff09\u3002", "method": "\u5f15\u5165\u8f7b\u91cf\u7ea7\u4e00\u81f4\u6027\u6846\u67b6\uff0c\u7ed3\u5408\u6f5c\u5728\u9762\u677f\u951a\u5b9a\u548c\u4e92\u60e0\u6ce8\u610f\u529b\u503c\u6df7\u5408\uff0c\u5229\u7528\u73b0\u6210\u8bed\u8a00\u6a21\u578b\u5c06\u81ea\u7531\u6545\u4e8b\u8f6c\u6362\u4e3a\u9762\u677f\u7ea7\u63d0\u793a\u3002", "result": "\u5728Rich Storyboard Benchmark\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u751f\u6210\u7684\u6545\u4e8b\u677f\u5728\u52a8\u6001\u6027\u3001\u8fde\u8d2f\u6027\u548c\u53d9\u4e8b\u5438\u5f15\u529b\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "Story2Board\u80fd\u591f\u751f\u6210\u89c6\u89c9\u591a\u6837\u4e14\u4e00\u81f4\u7684\u6545\u4e8b\u677f\uff0c\u4e3a\u89c6\u89c9\u53d9\u4e8b\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u5de5\u5177\u3002"}}
