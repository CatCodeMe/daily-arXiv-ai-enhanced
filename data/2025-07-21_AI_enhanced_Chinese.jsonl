{"id": "2507.13710", "pdf": "https://arxiv.org/pdf/2507.13710", "abs": "https://arxiv.org/abs/2507.13710", "authors": ["Jing Chang", "Chang Liu", "Jinbin Huang", "Rui Mao", "Jianbin Qin"], "title": "CogniQ-H: A Soft Hierarchical Reinforcement Learning Paradigm for Automated Data Preparation", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Data preparation is a foundational yet notoriously challenging component of\nthe machine learning lifecycle, characterized by a vast combinatorial search\nspace of potential operator sequences. While reinforcement learning (RL) offers\na promising direction, existing approaches are inefficient as they fail to\ncapture the structured, hierarchical nature of the problem. We argue that\nHierarchical Reinforcement Learning (HRL), a paradigm that has been successful\nin other domains, provides a conceptually ideal yet previously unexplored\nframework for this task. However, a naive HRL implementation with a `hard\nhierarchy' is prone to suboptimal, irreversible decisions. To address this, we\nintroduce CogniQ-H, the first framework to implement a soft hierarchical\nparadigm for robust, end-to-end automated data preparation. CogniQ-H formulates\naction selection as a Bayesian inference problem. A high-level strategic prior,\ngenerated by a Large Language Model (LLM), guides exploration\nprobabilistically. This prior is synergistically combined with a fine-grained\noperator quality score from a supervised Learning-to-Rank (LTR) model and a\nlong-term value estimate from the agent's own Q-function. This hybrid\narchitecture allows CogniQ-H to balance strategic guidance with adaptive,\nevidence-based decision-making. Through extensive experiments on 18 diverse\ndatasets spanning multiple domains, we demonstrate that CogniQ-H achieves up to\n13.9\\% improvement in pipeline quality and 2.8$\\times$ faster convergence\ncompared to state-of-the-art RL-based methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\uff08HRL\uff09\u7684\u6846\u67b6CogniQ-H\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u6570\u636e\u51c6\u5907\u4efb\u52a1\uff0c\u901a\u8fc7\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ba1\u9053\u8d28\u91cf\u548c\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u6570\u636e\u51c6\u5907\u662f\u673a\u5668\u5b66\u4e60\u751f\u547d\u5468\u671f\u4e2d\u57fa\u7840\u4f46\u590d\u6742\u7684\u73af\u8282\uff0c\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\uff0c\u672a\u80fd\u6355\u6349\u95ee\u9898\u7684\u5c42\u6b21\u7ed3\u6784\u3002", "method": "CogniQ-H\u91c7\u7528\u8f6f\u5206\u5c42\u8303\u5f0f\uff0c\u5c06\u52a8\u4f5c\u9009\u62e9\u5efa\u6a21\u4e3a\u8d1d\u53f6\u65af\u63a8\u65ad\u95ee\u9898\uff0c\u7ed3\u5408LLM\u7684\u6218\u7565\u5148\u9a8c\u3001\u5b66\u4e60\u6392\u5e8f\u6a21\u578b\u7684\u7ec6\u7c92\u5ea6\u8bc4\u5206\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u957f\u671f\u4ef7\u503c\u4f30\u8ba1\u3002", "result": "\u572818\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCogniQ-H\u5728\u7ba1\u9053\u8d28\u91cf\u4e0a\u63d0\u534713.9%\uff0c\u6536\u655b\u901f\u5ea6\u52a0\u5feb2.8\u500d\u3002", "conclusion": "CogniQ-H\u901a\u8fc7\u8f6f\u5206\u5c42\u8303\u5f0f\u6709\u6548\u89e3\u51b3\u4e86\u6570\u636e\u51c6\u5907\u4e2d\u7684\u5c42\u6b21\u7ed3\u6784\u95ee\u9898\uff0c\u4e3a\u81ea\u52a8\u5316\u6570\u636e\u51c6\u5907\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.13712", "pdf": "https://arxiv.org/pdf/2507.13712", "abs": "https://arxiv.org/abs/2507.13712", "authors": ["Jing Chang", "Chang Liu", "Jinbin Huang", "Rui Mao", "Jianbin Qin"], "title": "LLaPipe: LLM-Guided Reinforcement Learning for Automated Data Preparation Pipeline Construction", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Automated data preparation is crucial for democratizing machine learning, yet\nexisting reinforcement learning (RL) based approaches suffer from inefficient\nexploration in the vast space of possible preprocessing pipelines. We present\nLLaPipe, a novel framework that addresses this exploration bottleneck by\nintegrating Large Language Models (LLMs) as intelligent policy advisors. Unlike\ntraditional methods that rely solely on statistical features and blind\ntrial-and-error, LLaPipe leverages the semantic understanding capabilities of\nLLMs to provide contextually relevant exploration guidance. Our framework\nintroduces three key innovations: (1) an LLM Policy Advisor that analyzes\ndataset semantics and pipeline history to suggest promising preprocessing\noperations, (2) an Experience Distillation mechanism that mines successful\npatterns from past pipelines and transfers this knowledge to guide future\nexploration, and (3) an Adaptive Advisor Triggering strategy\n(Advisor\\textsuperscript{+}) that dynamically determines when LLM intervention\nis most beneficial, balancing exploration effectiveness with computational\ncost. Through extensive experiments on 18 diverse datasets spanning multiple\ndomains, we demonstrate that LLaPipe achieves up to 22.4\\% improvement in\npipeline quality and 2.3$\\times$ faster convergence compared to\nstate-of-the-art RL-based methods, while maintaining computational efficiency\nthrough selective LLM usage (averaging only 19.0\\% of total exploration steps).", "AI": {"tldr": "LLaPipe\u662f\u4e00\u4e2a\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u667a\u80fd\u7b56\u7565\u987e\u95ee\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u6570\u636e\u9884\u5904\u7406\u7ba1\u9053\u7684\u63a2\u7d22\u6548\u7387\uff0c\u663e\u8457\u63d0\u5347\u7ba1\u9053\u8d28\u91cf\u548c\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u6570\u636e\u9884\u5904\u7406\u65b9\u6cd5\u5728\u5e9e\u5927\u7684\u9884\u5904\u7406\u7ba1\u9053\u7a7a\u95f4\u4e2d\u63a2\u7d22\u6548\u7387\u4f4e\u4e0b\uff0cLLaPipe\u901a\u8fc7LLMs\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u89e3\u51b3\u8fd9\u4e00\u74f6\u9888\u3002", "method": "LLaPipe\u5f15\u5165\u4e09\u4e2a\u521b\u65b0\uff1aLLM\u7b56\u7565\u987e\u95ee\u3001\u7ecf\u9a8c\u84b8\u998f\u673a\u5236\u548c\u81ea\u9002\u5e94\u987e\u95ee\u89e6\u53d1\u7b56\u7565\uff0c\u7ed3\u5408LLMs\u7684\u8bed\u4e49\u5206\u6790\u548c\u5386\u53f2\u7ecf\u9a8c\u6307\u5bfc\u63a2\u7d22\u3002", "result": "\u572818\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLLaPipe\u7ba1\u9053\u8d28\u91cf\u63d0\u534722.4%\uff0c\u6536\u655b\u901f\u5ea6\u5feb2.3\u500d\uff0c\u4e14\u8ba1\u7b97\u6548\u7387\u9ad8\uff08LLM\u4ec5\u7528\u4e8e19.0%\u7684\u63a2\u7d22\u6b65\u9aa4\uff09\u3002", "conclusion": "LLaPipe\u901a\u8fc7\u667a\u80fdLLM\u5e72\u9884\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u9884\u5904\u7406\u7ba1\u9053\u7684\u63a2\u7d22\u6548\u7387\u548c\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2507.13757", "pdf": "https://arxiv.org/pdf/2507.13757", "abs": "https://arxiv.org/abs/2507.13757", "authors": ["Joydeep Chandra", "Prabal Manhas"], "title": "Efficient and Scalable Self-Healing Databases Using Meta-Learning and Dependency-Driven Recovery", "categories": ["cs.DB"], "comment": null, "summary": "This study explored the development of a novel self-healing framework for\ndatabases using meta-learning and reinforcement learning techniques. The\nprimary objective was to address the challenges of real-time adaptability and\nminimal retraining in dynamic workload environments. The proposed approach\nintegrated Model-Agnostic Meta-Learning (MAML) with reinforcement learning to\nenable anomaly detection and corrective actions that adapted swiftly to\nevolving database conditions. Multi-objective optimization was employed to\nbalance performance, resource utilization, and cost efficiency during the\nhealing process. Graph Neural Networks (GNNs) were incorporated to model\ninterdependencies within database components, ensuring holistic recovery\nstrategies. Data efficiency was enhanced through synthetic task augmentation\nand self-supervised learning, enabling effective training in sparse data\nregimes. To promote trust and transparency, explainable AI techniques were\nintegrated to provide interpretable insights into anomaly detection and healing\nactions. Federated meta-learning further enabled privacy-preserving\nadaptability in distributed database environments. The framework demonstrated\nsignificant improvements in adaptability, efficiency, and reliability,\ncontributing to advancements in database management and self-healing systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5143\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u6108\u6570\u636e\u5e93\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u9002\u5e94\u6027\u548c\u6700\u5c0f\u5316\u518d\u8bad\u7ec3\u95ee\u9898\u3002", "motivation": "\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u73af\u5883\u4e2d\u7684\u6570\u636e\u5e93\u9700\u8981\u5b9e\u65f6\u9002\u5e94\u6027\u548c\u9ad8\u6548\u7684\u81ea\u6108\u80fd\u529b\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u8fd9\u4e9b\u9700\u6c42\u3002", "method": "\u7ed3\u5408\u6a21\u578b\u65e0\u5173\u5143\u5b66\u4e60\uff08MAML\uff09\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u5229\u7528\u591a\u76ee\u6807\u4f18\u5316\u3001\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u3001\u5408\u6210\u4efb\u52a1\u589e\u5f3a\u548c\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u5e76\u6574\u5408\u53ef\u89e3\u91caAI\u6280\u672f\u548c\u8054\u90a6\u5143\u5b66\u4e60\u3002", "result": "\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u9002\u5e94\u6027\u3001\u6548\u7387\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6570\u636e\u5e93\u7ba1\u7406\u548c\u81ea\u6108\u7cfb\u7edf\u63d0\u4f9b\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.13892", "pdf": "https://arxiv.org/pdf/2507.13892", "abs": "https://arxiv.org/abs/2507.13892", "authors": ["Kevin M. Kramer", "Valerie Restat", "Sebastian Strasser", "Uta St\u00f6rl", "Meike Klettke"], "title": "Towards Next Generation Data Engineering Pipelines", "categories": ["cs.DB"], "comment": null, "summary": "Data engineering pipelines are a widespread way to provide high-quality data\nfor all kinds of data science applications. However, numerous challenges still\nremain in the composition and operation of such pipelines. Data engineering\npipelines do not always deliver high-quality data. By default, they are also\nnot reactive to changes. When new data is coming in which deviates from prior\ndata, the pipeline could crash or output undesired results. We therefore\nenvision three levels of next generation data engineering pipelines: optimized\ndata pipelines, self-aware data pipelines, and self-adapting data pipelines.\nPipeline optimization addresses the composition of operators and their\nparametrization in order to achieve the highest possible data quality.\nSelf-aware data engineering pipelines enable a continuous monitoring of its\ncurrent state, notifying data engineers on significant changes. Self-adapting\ndata engineering pipelines are then even able to automatically react to those\nchanges. We propose approaches to achieve each of these levels.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e0b\u4e00\u4ee3\u6570\u636e\u5de5\u7a0b\u7ba1\u9053\u7684\u4e09\u4e2a\u5c42\u6b21\uff1a\u4f18\u5316\u3001\u81ea\u611f\u77e5\u548c\u81ea\u9002\u5e94\uff0c\u4ee5\u89e3\u51b3\u6570\u636e\u8d28\u91cf\u548c\u53cd\u5e94\u6027\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u5de5\u7a0b\u7ba1\u9053\u5728\u6570\u636e\u8d28\u91cf\u548c\u53d8\u5316\u53cd\u5e94\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u53ef\u80fd\u5bfc\u81f4\u7ba1\u9053\u5d29\u6e83\u6216\u8f93\u51fa\u4e0d\u826f\u7ed3\u679c\u3002", "method": "\u63d0\u51fa\u4e09\u4e2a\u5c42\u6b21\u7684\u89e3\u51b3\u65b9\u6848\uff1a\u4f18\u5316\u7ba1\u9053\u7ec4\u6210\u548c\u53c2\u6570\u5316\u3001\u5b9e\u73b0\u81ea\u611f\u77e5\u76d1\u63a7\u3001\u5f00\u53d1\u81ea\u9002\u5e94\u53cd\u5e94\u673a\u5236\u3002", "result": "\u901a\u8fc7\u4f18\u5316\u3001\u81ea\u611f\u77e5\u548c\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u53ef\u4ee5\u63d0\u5347\u6570\u636e\u8d28\u91cf\u548c\u7ba1\u9053\u7684\u53cd\u5e94\u80fd\u529b\u3002", "conclusion": "\u4e0b\u4e00\u4ee3\u6570\u636e\u5de5\u7a0b\u7ba1\u9053\u5e94\u5177\u5907\u4f18\u5316\u3001\u81ea\u611f\u77e5\u548c\u81ea\u9002\u5e94\u80fd\u529b\uff0c\u4ee5\u5e94\u5bf9\u6570\u636e\u8d28\u91cf\u548c\u53d8\u5316\u6311\u6218\u3002"}}
{"id": "2507.13470", "pdf": "https://arxiv.org/pdf/2507.13470", "abs": "https://arxiv.org/abs/2507.13470", "authors": ["Michael Elkin", "Chhaya Trehan"], "title": "Faster Multi-Source Reachability and Approximate Distances via Shortcuts, Hopsets and Matrix Multiplication", "categories": ["cs.DS", "cs.DC"], "comment": null, "summary": "Given an $n$-vertex $m$-edge digraph $G = (V,E)$ and a subset $S \\subseteq V$\nof $|S| = n^{\\sigma}$ (for some $0 \\le \\sigma \\le 1$) designated sources, the\n$S \\times V$ reachability problem is to compute the sets $\\mathcal V_s$ of\nvertices reachable from $s$, for every $s \\in S$. Naive centralized algorithms\nrun BFS/DFS from each source in $O(m \\cdot n^{\\sigma})$ time or compute $G$'s\ntransitive closure in $\\hat O(n^{\\omega})$ time, where $\\omega \\le\n2.371552\\ldots$ is the matrix multiplication exponent. Thus, the best known\nbound is $\\hat O(n^{\\min \\{ 2 + \\sigma, \\omega\\}})$. Leveraging shortcut\nconstructions by Kogan and Parter [SODA 2022, ICALP 2022], we develop a\ncentralized algorithm with running time $\\hat O(n^{1 + \\frac{2}{3}\n\\omega(\\sigma)})$, where $\\omega(\\sigma)$ is the rectangular matrix\nmultiplication exponent. Using current estimates on $\\omega(\\sigma)$, our\nexponent improves upon $\\min \\{2 + \\sigma, \\omega \\}$ for $\\tilde \\sigma \\leq\n\\sigma \\leq 0.53$, where $1/3 < \\tilde \\sigma < 0.3336$ is a universal\nconstant.\n  In a classical result, Cohen [Journal of Algorithms, 1996] devised parallel\nalgorithms for $S \\times V$ reachability on graphs admitting balanced recursive\nseparators of size $n^{\\rho}$ for $\\rho < 1$, requiring polylogarithmic time\nand work $n^{\\max \\{\\omega \\rho, 2\\rho + \\sigma \\} + o(1)}$. We significantly\nimprove, extend, and generalize Cohen's result. First, our parallel algorithm\nfor graphs with small recursive separators has lower work complexity than\nCohen's in boraod paramater ranges. Second, we generalize our algorithm to\ngraphs of treewidth at most $n^{\\rho}$ ($\\rho < 1$) and provide a centralized\nalgorithm that outperforms existing bounds for $S \\times V$ reachability on\nsuch graphs. We also do this for some other graph familes with small\nseparators. Finally, we extend these results to $(1 + \\epsilon)$-approximate\ndistance computation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u96c6\u4e2d\u5f0f\u548c\u5e76\u884c\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u6709\u5411\u56fe\u4e2d\u4ece\u591a\u4e2a\u6e90\u70b9\u5230\u6240\u6709\u9876\u70b9\u7684\u53ef\u8fbe\u6027\u95ee\u9898\uff0c\u5e76\u5728\u7279\u5b9a\u53c2\u6570\u8303\u56f4\u5185\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u6709\u5411\u56fe\u4e2d\u591a\u6e90\u70b9\u53ef\u8fbe\u6027\u95ee\u9898\u7684\u73b0\u6709\u7b97\u6cd5\u5728\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e0a\u4ecd\u6709\u4f18\u5316\u7a7a\u95f4\uff0c\u5c24\u5176\u662f\u5728\u7279\u5b9a\u53c2\u6570\u8303\u56f4\u5185\u3002", "method": "\u5229\u7528Kogan\u548cParter\u7684\u5feb\u6377\u6784\u9020\u6280\u672f\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u96c6\u4e2d\u5f0f\u7b97\u6cd5\uff0c\u5e76\u6539\u8fdb\u4e86Cohen\u7684\u5e76\u884c\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u5177\u6709\u5c0f\u9012\u5f52\u5206\u5272\u5668\u6216\u6811\u5bbd\u5ea6\u7684\u56fe\u3002", "result": "\u65b0\u7b97\u6cd5\u5728\u7279\u5b9a\u53c2\u6570\u8303\u56f4\u5185\uff08\u5982\u03c3\u5728~\u03c3\u52300.53\u4e4b\u95f4\uff09\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5e76\u884c\u7b97\u6cd5\u5728\u66f4\u5e7f\u6cdb\u7684\u53c2\u6570\u8303\u56f4\u5185\u964d\u4f4e\u4e86\u5de5\u4f5c\u590d\u6742\u5ea6\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u591a\u6e90\u70b9\u53ef\u8fbe\u6027\u95ee\u9898\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u5e76\u6269\u5c55\u4e86\u9002\u7528\u8303\u56f4\uff0c\u5305\u62ec\u8fd1\u4f3c\u8ddd\u79bb\u8ba1\u7b97\u3002"}}
{"id": "2507.13481", "pdf": "https://arxiv.org/pdf/2507.13481", "abs": "https://arxiv.org/abs/2507.13481", "authors": ["Arthur Bueno", "Bruno Cafeo", "Maria Cagnin", "Awdren Font\u00e3o"], "title": "Socio-Technical Smell Dynamics in Code Samples: A Multivocal Review on Emergence, Evolution, and Co-Occurrence", "categories": ["cs.SE", "cs.CY"], "comment": "12 pages; 2 figures; Preprint with the original submission accepted\n  for publication at 39th Brazilian Symposium on Software Engineering (SBES)", "summary": "Code samples play a pivotal role in open-source ecosystems (OSSECO), serving\nas lightweight artifacts that support knowledge transfer, onboarding, and\nframework adoption. Despite their instructional relevance, these samples are\noften governed informally, with minimal review and unclear ownership, which\nincreases their exposure to socio-technical degradation. In this context, the\nco-occurrence and longitudinal interplay of code smells (e.g., large classes,\npoor modularity) and community smells (e.g., lone contributors, fragmented\ncommunication) become particularly critical. While each type of smell has been\nstudied in isolation, little is known about how community-level dysfunctions\nanticipate or exacerbate technical anomalies in code samples over time. This\nstudy investigates how code and community smells emerge, co-occur, and evolve\nwithin code samples maintained in OSSECOs. A Multivocal Literature Review\nprotocol was applied, encompassing 30 peer-reviewed papers and 17\npractitioner-oriented sources (2013-2024). Thematic synthesis was conducted to\nidentify recurring socio-technical patterns related to smell dynamics. Nine\npatterns were identified, showing that community smells often precede or\nreinforce technical degradation in code samples. Symptoms such as \"radio\nsilence\" and centralized ownership were frequently associated with persistent\nstructural anomalies. Additionally, limited onboarding, the absence of\ncontinuous refactoring, and informal collaboration emerged as recurring\nconditions for smell accumulation. Conclusion: In OSSECOs, particularly within\ncode samples, community-level dysfunctions not only correlate with but often\nsignal maintainability decay. These findings underscore the need for\nsocio-technical quality indicators and lightweight governance mechanisms\ntailored to shared instructional artifacts.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5f00\u6e90\u751f\u6001\u7cfb\u7edf\u4e2d\u4ee3\u7801\u6837\u672c\u7684\u6280\u672f\u5f02\u5473\uff08\u5982\u5927\u7c7b\u3001\u6a21\u5757\u5316\u5dee\uff09\u4e0e\u793e\u533a\u5f02\u5473\uff08\u5982\u5355\u4e00\u8d21\u732e\u8005\u3001\u6c9f\u901a\u788e\u7247\u5316\uff09\u7684\u5171\u73b0\u4e0e\u6f14\u5316\u5173\u7cfb\uff0c\u53d1\u73b0\u793e\u533a\u95ee\u9898\u5e38\u9884\u793a\u6216\u52a0\u5267\u6280\u672f\u9000\u5316\u3002", "motivation": "\u4ee3\u7801\u6837\u672c\u5728\u5f00\u6e90\u751f\u6001\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u7ba1\u7406\u677e\u6563\uff0c\u6613\u53d7\u6280\u672f\u548c\u793e\u4f1a\u95ee\u9898\u5f71\u54cd\uff0c\u800c\u4e24\u8005\u5173\u7cfb\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u91c7\u7528\u591a\u58f0\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u679030\u7bc7\u5b66\u672f\u8bba\u6587\u548c17\u7bc7\u5b9e\u8df5\u5bfc\u5411\u8d44\u6599\uff082013-2024\uff09\uff0c\u901a\u8fc7\u4e3b\u9898\u5408\u6210\u8bc6\u522b\u5f02\u5473\u52a8\u6001\u7684\u793e\u4f1a\u6280\u672f\u6a21\u5f0f\u3002", "result": "\u8bc6\u522b\u51fa9\u79cd\u6a21\u5f0f\uff0c\u663e\u793a\u793e\u533a\u5f02\u5473\u5e38\u5148\u4e8e\u6216\u5f3a\u5316\u6280\u672f\u9000\u5316\uff0c\u5982\u201c\u65e0\u7ebf\u7535\u9759\u9ed8\u201d\u548c\u96c6\u4e2d\u6240\u6709\u6743\u4e0e\u6301\u7eed\u7ed3\u6784\u95ee\u9898\u76f8\u5173\u3002", "conclusion": "\u5f00\u6e90\u751f\u6001\u4e2d\uff0c\u793e\u533a\u95ee\u9898\u4e0d\u4ec5\u4e0e\u6280\u672f\u9000\u5316\u76f8\u5173\uff0c\u8fd8\u53ef\u80fd\u662f\u5176\u4fe1\u53f7\uff0c\u9700\u9488\u5bf9\u5171\u4eab\u6559\u5b66\u5de5\u4ef6\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u6cbb\u7406\u673a\u5236\u3002"}}
{"id": "2507.13476", "pdf": "https://arxiv.org/pdf/2507.13476", "abs": "https://arxiv.org/abs/2507.13476", "authors": ["Jaber Daneshamooz", "Jessica Nguyen", "William Chen", "Sanjay Chandrasekaran", "Satyandra Guthula", "Ankit Gupta", "Arpit Gupta", "Walter Willinger"], "title": "Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica", "categories": ["cs.NI"], "comment": null, "summary": "Machine learning models in networking suffer from the domain adaptation\nproblem; models trained in one domain often fail when deployed in different\nproduction environments. This paper presents the design and implementation of\nNetReplica, a system that addresses this challenge by generating training\ndatasets with two critical properties: realism in protocol dynamics and\ncontrollability of network conditions. NetReplica models networks as\ncollections of bottleneck links with specific attributes, achieves realism by\nleveraging production network traces, and enables controllability through fine\ngrained control knobs for each link attribute. Our evaluation using Puffer\ndemonstrates that NetReplica not only matches existing data characteristics but\ngenerates realistic samples that are underrepresented in or absent from Puffer\ndata. Models trained on NetReplica augmented datasets show substantially\nimproved generalizability, reducing transmission time prediction error by up to\n47% for challenging network conditions compared to models trained solely on\nPuffer data. This work represents a significant step toward solving the domain\nadaptation problem that has limited the effectiveness of ML based networking\nsystems.", "AI": {"tldr": "NetReplica\u901a\u8fc7\u751f\u6210\u5177\u6709\u534f\u8bae\u52a8\u6001\u771f\u5b9e\u6027\u548c\u7f51\u7edc\u6761\u4ef6\u53ef\u63a7\u6027\u7684\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u7f51\u7edc\u4e2d\u7684\u9886\u57df\u9002\u5e94\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u4e0d\u540c\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u9886\u57df\u9002\u5e94\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u5728\u591a\u6837\u5316\u7f51\u7edc\u6761\u4ef6\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "NetReplica\u5c06\u7f51\u7edc\u5efa\u6a21\u4e3a\u5177\u6709\u7279\u5b9a\u5c5e\u6027\u7684\u74f6\u9888\u94fe\u8def\u96c6\u5408\uff0c\u5229\u7528\u751f\u4ea7\u7f51\u7edc\u75d5\u8ff9\u5b9e\u73b0\u771f\u5b9e\u6027\uff0c\u5e76\u901a\u8fc7\u7cbe\u7ec6\u63a7\u5236\u94fe\u8def\u5c5e\u6027\u5b9e\u73b0\u53ef\u63a7\u6027\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0cNetReplica\u751f\u6210\u7684\u6570\u636e\u4e0d\u4ec5\u5339\u914d\u73b0\u6709\u6570\u636e\u7279\u5f81\uff0c\u8fd8\u80fd\u8865\u5145Puffer\u6570\u636e\u4e2d\u7f3a\u5931\u6216\u4e0d\u8db3\u7684\u6837\u672c\u3002\u4f7f\u7528NetReplica\u589e\u5f3a\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6311\u6218\u6027\u7f51\u7edc\u6761\u4ef6\u4e0b\uff0c\u4f20\u8f93\u65f6\u95f4\u9884\u6d4b\u8bef\u5dee\u964d\u4f4e\u9ad8\u8fbe47%\u3002", "conclusion": "NetReplica\u4e3a\u89e3\u51b3\u9886\u57df\u9002\u5e94\u95ee\u9898\u63d0\u4f9b\u4e86\u91cd\u8981\u8fdb\u5c55\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u7f51\u7edc\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.13522", "pdf": "https://arxiv.org/pdf/2507.13522", "abs": "https://arxiv.org/abs/2507.13522", "authors": ["Ankit Bhardwaj", "Weiyang Wang", "Jeremy Carin", "Adam Belay", "Manya Ghobadi"], "title": "Checkmate: Zero-Overhead Model Checkpointing via Network Gradient Replication", "categories": ["cs.DC"], "comment": "18 pages, 11 figures", "summary": "This paper presents Checkmate, a system that enables per-iteration\ncheckpointing in DNN training without any training slowdown. The traditional\napproach to checkpointing requires a pause in training to copy model states to\na separate location, allowing the state to be restored in the event of failure.\nThis approach fundamentally has a tradeoff between the frequency of checkpoints\nand the cost of a failure. We avoid this tradeoff; our key insight is that in\ndata-parallel training, all information necessary to create a checkpoint\nalready exists in the network as gradients. Our core contribution is a new\nmulticast abstraction that simultaneously delivers gradients to a separate\nCPU-based shadow cluster. The shadow maintains a checkpoint by applying those\ngradients to a copy of the model. Our evaluation shows that Checkmate performs\nper-iteration checkpointing with training throughput comparable to an ideal\nno-checkpoint baseline. Checkmate achieves 5 to 34.5x more frequent\ncheckpointing compared to state-of-the-art checkpointing systems, resulting in\n80% to 97.1% reduction in repeated work per failure. At the same checkpointing\nfrequency, Checkmate delivers 1.3x to 6.5x throughput compared to other\nsystems.", "AI": {"tldr": "Checkmate\u7cfb\u7edf\u901a\u8fc7\u591a\u64ad\u62bd\u8c61\u5b9e\u73b0DNN\u8bad\u7ec3\u4e2d\u7684\u6bcf\u8fed\u4ee3\u68c0\u67e5\u70b9\uff0c\u907f\u514d\u4f20\u7edf\u68c0\u67e5\u70b9\u65b9\u6cd5\u7684\u8bad\u7ec3\u6682\u505c\uff0c\u663e\u8457\u63d0\u5347\u68c0\u67e5\u70b9\u9891\u7387\u548c\u541e\u5410\u91cf\u3002", "motivation": "\u4f20\u7edf\u68c0\u67e5\u70b9\u65b9\u6cd5\u9700\u8981\u5728\u8bad\u7ec3\u6682\u505c\u65f6\u590d\u5236\u6a21\u578b\u72b6\u6001\uff0c\u5b58\u5728\u68c0\u67e5\u70b9\u9891\u7387\u4e0e\u6545\u969c\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\u3002Checkmate\u65e8\u5728\u6d88\u9664\u8fd9\u4e00\u6743\u8861\u3002", "method": "\u5229\u7528\u6570\u636e\u5e76\u884c\u8bad\u7ec3\u4e2d\u7684\u68af\u5ea6\u4fe1\u606f\uff0c\u901a\u8fc7\u591a\u64ad\u62bd\u8c61\u5c06\u68af\u5ea6\u540c\u65f6\u4f20\u9012\u5230\u57fa\u4e8eCPU\u7684\u5f71\u5b50\u96c6\u7fa4\uff0c\u5f71\u5b50\u96c6\u7fa4\u901a\u8fc7\u5e94\u7528\u68af\u5ea6\u7ef4\u62a4\u68c0\u67e5\u70b9\u3002", "result": "Checkmate\u5b9e\u73b0\u6bcf\u8fed\u4ee3\u68c0\u67e5\u70b9\uff0c\u8bad\u7ec3\u541e\u5410\u91cf\u4e0e\u65e0\u68c0\u67e5\u70b9\u57fa\u7ebf\u76f8\u5f53\uff0c\u68c0\u67e5\u70b9\u9891\u7387\u63d0\u53475\u81f334.5\u500d\uff0c\u91cd\u590d\u5de5\u4f5c\u51cf\u5c1180%\u81f397.1%\u3002", "conclusion": "Checkmate\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u68c0\u67e5\u70b9\u7cfb\u7edf\uff0c\u63d0\u4f9b\u66f4\u9ad8\u7684\u68c0\u67e5\u70b9\u9891\u7387\u548c\u541e\u5410\u91cf\u3002"}}
{"id": "2507.13354", "pdf": "https://arxiv.org/pdf/2507.13354", "abs": "https://arxiv.org/abs/2507.13354", "authors": ["Zeqian Chen"], "title": "Physical models realizing the transformer architecture of large language models", "categories": ["cs.LG", "cs.AI", "cs.CL", "math-ph", "math.MP"], "comment": "6 pages", "summary": "The introduction of the transformer architecture in 2017 (cf.\\cite{VSP2017})\nmarked the most striking advancement in natural language processing. The\ntransformer is a model architecture relying entirely on an attention mechanism\nto draw global dependencies between input and output. However, we believe there\nis a gap in our theoretical understanding of what the transformer is, and why\nit works physically. In this paper, from a physical perspective on modern\nchips, we construct physical models in the Fock space over the Hilbert space of\ntokens realizing large language models based on a transformer architecture as\nopen quantum systems. Our physical models underlie the transformer architecture\nfor large language models.", "AI": {"tldr": "\u8bba\u6587\u4ece\u7269\u7406\u89d2\u5ea6\u5206\u6790Transformer\u67b6\u6784\uff0c\u63d0\u51fa\u57fa\u4e8e\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u7684\u7269\u7406\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7406\u8bba\u5bf9Transformer\u7684\u5de5\u4f5c\u539f\u7406\u7f3a\u4e4f\u7269\u7406\u5c42\u9762\u7684\u7406\u89e3\u3002", "method": "\u4ece\u73b0\u4ee3\u82af\u7247\u7684\u7269\u7406\u89c6\u89d2\uff0c\u5728Fock\u7a7a\u95f4\u6784\u5efaHilbert\u7a7a\u95f4\u4e2dtoken\u7684\u7269\u7406\u6a21\u578b\u3002", "result": "\u63d0\u51fa\u4e86\u652f\u6301Transformer\u67b6\u6784\u7684\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u7269\u7406\u6a21\u578b\u3002", "conclusion": "\u7269\u7406\u6a21\u578b\u4e3aTransformer\u67b6\u6784\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2507.14101", "pdf": "https://arxiv.org/pdf/2507.14101", "abs": "https://arxiv.org/abs/2507.14101", "authors": ["Diego Figueira", "Cibele Freire"], "title": "Project-connex Decompositions and Tractability of Aggregate Group-by Conjunctive Queries", "categories": ["cs.DB"], "comment": "34 pages, 5 figures", "summary": "We introduce 'project-connex' tree-width as a measure of tractability for\ncounting and aggregate conjunctive queries over semirings with 'group-by'\nprojection (also known as 'AJAR' or 'FAQ' queries). This elementary measure\nallows to obtain comparable complexity bounds to the ones obtained by previous\nstructural conditions tailored for efficient evaluation of semiring aggregate\nqueries, enumeration algorithms of conjunctive queries, and tractability of\ncounting answers to conjunctive queries.\n  Project-connex tree decompositions are defined as the natural extension of\nthe known notion of 'free-connex' decompositions. They allow for a unified,\nsimple and intuitive algorithmic manipulation for evaluation of aggregate\nqueries and explain some existing tractability results on conjunctive query\nenumeration, counting conjunctive query evaluation, and evaluation of semiring\naggregate queries. Using this measure we also recover results relating\ntractable classes of counting conjunctive queries and bounded free-connex\ntree-width, or the constant-time delay enumeration of semiring aggregate\nqueries over bounded project-connex classes. We further show that\nproject-connex tree decompositions can be obtained via algorithms for computing\nclassical tree decompositions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a'project-connex'\u6811\u5bbd\u7684\u65b0\u5ea6\u91cf\uff0c\u7528\u4e8e\u8861\u91cf\u5e26\u6709'group-by'\u6295\u5f71\u7684\u534a\u73af\u805a\u5408\u67e5\u8be2\u7684\u53ef\u5904\u7406\u6027\uff0c\u7edf\u4e00\u4e86\u591a\u79cd\u67e5\u8be2\u7c7b\u578b\u7684\u590d\u6742\u6027\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9488\u5bf9\u4e0d\u540c\u7c7b\u578b\u7684\u67e5\u8be2\uff08\u5982\u534a\u73af\u805a\u5408\u67e5\u8be2\u3001\u679a\u4e3e\u7b97\u6cd5\u548c\u8ba1\u6570\u67e5\u8be2\uff09\u63d0\u51fa\u4e86\u5404\u81ea\u7684\u7ed3\u6784\u6761\u4ef6\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u5ea6\u91cf\u6807\u51c6\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u6269\u5c55'free-connex'\u5206\u89e3\u7684\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e86'project-connex'\u6811\u5206\u89e3\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u7b97\u6cd5\u6846\u67b6\u3002", "result": "\u8bc1\u660e\u4e86'project-connex'\u6811\u5bbd\u80fd\u591f\u89e3\u91ca\u73b0\u6709\u7684\u53ef\u5904\u7406\u6027\u7ed3\u679c\uff0c\u5e76\u6062\u590d\u4e86\u4e0e\u8ba1\u6570\u67e5\u8be2\u548c\u679a\u4e3e\u67e5\u8be2\u76f8\u5173\u7684\u5df2\u77e5\u7ed3\u8bba\u3002", "conclusion": "'project-connex'\u6811\u5206\u89e3\u4e3a\u591a\u79cd\u67e5\u8be2\u7c7b\u578b\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u590d\u6742\u6027\u5206\u6790\u5de5\u5177\uff0c\u5e76\u901a\u8fc7\u7ecf\u5178\u6811\u5206\u89e3\u7b97\u6cd5\u5b9e\u73b0\u8ba1\u7b97\u3002"}}
{"id": "2507.13510", "pdf": "https://arxiv.org/pdf/2507.13510", "abs": "https://arxiv.org/abs/2507.13510", "authors": ["Benoit Jacob"], "title": "Strassen $2\\times2$ Matrix Multiplication from a 3-dimensional Volume Form", "categories": ["cs.DS", "cs.CC", "15A69 (Primary), 15A15, 14N07 (Secondary)"], "comment": "13 pages", "summary": "The Strassen $2\\times2$ matrix multiplication algorithm arises from the\nvolume form on the 3-dimensional quotient space of the $2\\times 2$ matrices by\nthe multiples of identity.", "AI": {"tldr": "Strassen\u76842\u00d72\u77e9\u9635\u4e58\u6cd5\u7b97\u6cd5\u6e90\u4e8e2\u00d72\u77e9\u9635\u9664\u4ee5\u5355\u4f4d\u77e9\u9635\u500d\u6570\u76843\u7ef4\u5546\u7a7a\u95f4\u4e0a\u7684\u4f53\u79ef\u5f62\u5f0f\u3002", "motivation": "\u63a2\u7d22\u77e9\u9635\u4e58\u6cd5\u7684\u66f4\u9ad8\u6548\u7b97\u6cd5\uff0c\u901a\u8fc7\u51e0\u4f55\u89c6\u89d2\u7406\u89e3\u5176\u6570\u5b66\u57fa\u7840\u3002", "method": "\u5229\u75283\u7ef4\u5546\u7a7a\u95f4\u4e0a\u7684\u4f53\u79ef\u5f62\u5f0f\u63a8\u5bfc\u51faStrassen\u76842\u00d72\u77e9\u9635\u4e58\u6cd5\u7b97\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86Strassen\u7b97\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u51e0\u4f55\u80cc\u666f\u3002", "conclusion": "Strassen\u7b97\u6cd5\u4e0d\u4ec5\u662f\u4e00\u79cd\u8ba1\u7b97\u5de5\u5177\uff0c\u8fd8\u5177\u6709\u6df1\u523b\u7684\u51e0\u4f55\u610f\u4e49\u3002"}}
{"id": "2507.13499", "pdf": "https://arxiv.org/pdf/2507.13499", "abs": "https://arxiv.org/abs/2507.13499", "authors": ["Chandra Maddila", "Negar Ghorbani", "James Saindon", "Parth Thakkar", "Vijayaraghavan Murali", "Rui Abreu", "Jingyue Shen", "Brian Zhou", "Nachiappan Nagappan", "Peter C. Rigby"], "title": "AI-Assisted Fixes to Code Review Comments at Scale", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "Aim. There are 10s of thousands of code review comments each week at Meta. We\ndeveloped Metamate for Code Review (MetaMateCR) that provides AI-assisted fixes\nfor reviewer comments in production at scale.\n  Method. We developed an internal benchmark of 64k <review comment, patch>\ndata points to fine-tune Llama models. Once our models achieve reasonable\noffline results, we roll them into production. To ensure that our AI-assisted\nfixes do not negatively impact the time it takes to do code reviews, we conduct\nrandomized controlled safety trials as well as full production experiments.\n  Offline Results. As a baseline, we compare GPT-4o to our small and large\nLlama models. In offline results, our LargeLSFT model creates an exact match\npatch 68% of the time outperforming GPT-4o by 9 percentage points (pp). The\ninternal models also use more modern Hack functions when compared to the PHP\nfunctions suggested by GPT-4o.\n  Safety Trial. When we roll MetaMateCR into production in a safety trial that\ncompares no AI patches with AI patch suggestions, we see a large regression\nwith reviewers taking over 5% longer to conduct reviews. After investigation,\nwe modify the UX to only show authors the AI patches, and see no regressions in\nthe time for reviews.\n  Production. When we roll LargeLSFT into production, we see an\nActionableToApplied rate of 19.7%, which is a 9.2pp improvement over GPT-4o.\nOur results illustrate the importance of safety trials in ensuring that AI does\nnot inadvertently slow down engineers, and a successful review comment to AI\npatch product running at scale.", "AI": {"tldr": "Meta\u5f00\u53d1\u4e86MetaMateCR\uff0c\u5229\u7528AI\u8f85\u52a9\u4fee\u590d\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\uff0c\u901a\u8fc7\u5fae\u8c03Llama\u6a21\u578b\u5e76\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8eGPT-4o\uff0c\u4e14\u901a\u8fc7\u5b89\u5168\u8bd5\u9a8c\u4f18\u5316\u4e86\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u89e3\u51b3Meta\u6bcf\u5468\u6570\u4e07\u6761\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u7684\u5904\u7406\u95ee\u9898\uff0c\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u752864k\u6570\u636e\u70b9\u5fae\u8c03Llama\u6a21\u578b\uff0c\u8fdb\u884c\u79bb\u7ebf\u6d4b\u8bd5\u3001\u5b89\u5168\u8bd5\u9a8c\u548c\u751f\u4ea7\u5b9e\u9a8c\u3002", "result": "LargeLSFT\u6a21\u578b\u79bb\u7ebf\u51c6\u786e\u738768%\uff0c\u4f18\u4e8eGPT-4o 9\u4e2a\u767e\u5206\u70b9\uff1b\u751f\u4ea7\u73af\u5883\u4e2dActionableToApplied\u7387\u63d0\u53479.2\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "MetaMateCR\u6210\u529f\u5c55\u793a\u4e86AI\u8f85\u52a9\u4fee\u590d\u7684\u6f5c\u529b\uff0c\u5e76\u901a\u8fc7\u5b89\u5168\u8bd5\u9a8c\u786e\u4fdd\u4e0d\u964d\u4f4e\u5de5\u7a0b\u5e08\u6548\u7387\u3002"}}
{"id": "2507.13676", "pdf": "https://arxiv.org/pdf/2507.13676", "abs": "https://arxiv.org/abs/2507.13676", "authors": ["Cheng Jiang", "Yihe Yan", "Yanxiang Wang", "Jiawei Hu", "Chun Tung Chou", "Wen Hu"], "title": "CARTS: Cooperative and Adaptive Resource Triggering and Stitching for 5G ISAC", "categories": ["cs.NI", "eess.SP"], "comment": null, "summary": "This paper presents CARTS, an adaptive 5G uplink sensing scheme designed to\nprovide Integrated Sensing and Communication (ISAC) services. The performance\nof both communication and sensing fundamentally depends on the availability of\naccurate and up-to-date channel state information (CSI). In modern 5G networks,\nuplink CSI is derived from two reference signals: the demodulation reference\nsignal (DMRS) and the sounding reference signal (SRS). However, current base\nstation implementations treat these CSI measurements as separate information\nstreams. The key innovation of CARTS is to fuse these two CSI streams, thereby\nincreasing the frequency of CSI updates and extending sensing opportunities to\nmore users. CARTS addresses two key challenges: (i) a novel channel stitching\nand compensation method that integrates asynchronous CSI estimates from DMRS\nand SRS, despite their different time and frequency allocations, and (ii) a\nreal-time SRS triggering algorithm that complements the inherently\nuncontrollable DMRS schedule, ensuring sufficient and non-redundant sensing\nopportunities for all users. Our trace-driven evaluation shows that CARTS\nsignificantly improves scalability, achieving a channel estimation error (NMSE)\nof 0.167 and UE tracking accuracy of 85 cm while supporting twice the number of\nusers as a periodic SRS-only baseline with similar performance. By\nopportunistically combining DMRS and SRS, CARTS therefore provides a practical,\nstandard-compliant solution to improve CSI availability for ISAC without\nrequiring additional radio resources.", "AI": {"tldr": "CARTS\u662f\u4e00\u79cd\u81ea\u9002\u5e945G\u4e0a\u884c\u94fe\u8def\u611f\u77e5\u65b9\u6848\uff0c\u901a\u8fc7\u878d\u5408DMRS\u548cSRS\u7684CSI\u6d41\uff0c\u63d0\u5347CSI\u66f4\u65b0\u9891\u7387\u548c\u611f\u77e5\u673a\u4f1a\u3002", "motivation": "\u73b0\u4ee35G\u7f51\u7edc\u4e2d\uff0c\u4e0a\u884c\u94fe\u8defCSI\u6765\u81eaDMRS\u548cSRS\uff0c\u4f46\u57fa\u7ad9\u5c06\u5176\u89c6\u4e3a\u72ec\u7acb\u4fe1\u606f\u6d41\uff0c\u9650\u5236\u4e86CSI\u7684\u51c6\u786e\u6027\u548c\u611f\u77e5\u673a\u4f1a\u3002", "method": "CARTS\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4fe1\u9053\u62fc\u63a5\u4e0e\u8865\u507f\u65b9\u6cd5\uff0c\u6574\u5408\u5f02\u6b65CSI\u4f30\u8ba1\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5b9e\u65f6SRS\u89e6\u53d1\u7b97\u6cd5\u3002", "result": "CARTS\u663e\u8457\u63d0\u5347\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u652f\u6301\u7528\u6237\u6570\u91cf\u7ffb\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u4fe1\u9053\u4f30\u8ba1\u8bef\u5dee\u548c\u9ad8\u8ddf\u8e2a\u7cbe\u5ea6\u3002", "conclusion": "CARTS\u901a\u8fc7\u7ed3\u5408DMRS\u548cSRS\uff0c\u65e0\u9700\u989d\u5916\u8d44\u6e90\u5373\u53ef\u63d0\u5347ISAC\u7684CSI\u53ef\u7528\u6027\u3002"}}
{"id": "2507.13601", "pdf": "https://arxiv.org/pdf/2507.13601", "abs": "https://arxiv.org/abs/2507.13601", "authors": ["Jorge Villarrubia", "Luis Costero", "Francisco D. Igual", "Katzalin Olcoz"], "title": "Leveraging Multi-Instance GPUs through moldable task scheduling", "categories": ["cs.DC", "cs.ET", "cs.PF", "90B36, 90C27, 68M14, 68W40", "C.1.2; C.1.4; C.3.1; D.1.3; G.1.6"], "comment": null, "summary": "NVIDIA MIG (Multi-Instance GPU) allows partitioning a physical GPU into\nmultiple logical instances with fully-isolated resources, which can be\ndynamically reconfigured. This work highlights the untapped potential of MIG\nthrough moldable task scheduling with dynamic reconfigurations. Specifically,\nwe propose a makespan minimization problem for multi-task execution under MIG\nconstraints. Our profiling shows that assuming monotonicity in task work with\nrespect to resources is not viable, as is usual in multicore scheduling.\nRelying on a state-of-the-art proposal that does not require such an\nassumption, we present FAR, a 3-phase algorithm to solve the problem. Phase 1\nof FAR builds on a classical task moldability method, phase 2 combines Longest\nProcessing Time First and List Scheduling with a novel repartitioning tree\nheuristic tailored to MIG constraints, and phase 3 employs local search via\ntask moves and swaps. FAR schedules tasks in batches offline, concatenating\ntheir schedules on the fly in an improved way that favors resource reuse.\nExcluding reconfiguration costs, the List Scheduling proof shows an\napproximation factor of 7/4 on the NVIDIA A30 model. We adapt the technique to\nthe particular constraints of an NVIDIA A100/H100 to obtain an approximation\nfactor of 2. Including the reconfiguration cost, our real-world experiments\nreveal a makespan with respect to the optimum no worse than 1.22x for a\nwell-known suite of benchmarks, and 1.10x for synthetic inputs inspired by real\nkernels. We obtain good experimental results for each batch of tasks, but also\nin the concatenation of batches, with large improvements over the\nstate-of-the-art and proposals without GPU reconfiguration. Beyond the\nalgorithm, the paper demonstrates the research potential of the MIG technology\nand suggests useful metrics, workload characterizations and evaluation\ntechniques for future work in this field.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFAR\u7684\u4e09\u9636\u6bb5\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728NVIDIA MIG\u6280\u672f\u4e0b\u4f18\u5316\u591a\u4efb\u52a1\u8c03\u5ea6\u7684\u5b8c\u6210\u65f6\u95f4\u3002\u901a\u8fc7\u52a8\u6001\u91cd\u65b0\u914d\u7f6eGPU\u8d44\u6e90\uff0cFAR\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u8c03\u5ea6\u7684\u6548\u7387\u3002", "motivation": "NVIDIA MIG\u6280\u672f\u5141\u8bb8\u5c06\u7269\u7406GPU\u5212\u5206\u4e3a\u591a\u4e2a\u903b\u8f91\u5b9e\u4f8b\uff0c\u4f46\u73b0\u6709\u8c03\u5ea6\u65b9\u6cd5\u672a\u5145\u5206\u5229\u7528\u5176\u52a8\u6001\u91cd\u65b0\u914d\u7f6e\u7684\u6f5c\u529b\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u4f18\u5316\u4efb\u52a1\u8c03\u5ea6\uff0c\u6700\u5c0f\u5316\u591a\u4efb\u52a1\u6267\u884c\u7684\u5b8c\u6210\u65f6\u95f4\u3002", "method": "FAR\u7b97\u6cd5\u5206\u4e3a\u4e09\u4e2a\u9636\u6bb5\uff1a1\uff09\u57fa\u4e8e\u7ecf\u5178\u4efb\u52a1\u53ef\u5851\u6027\u65b9\u6cd5\uff1b2\uff09\u7ed3\u5408\u6700\u957f\u5904\u7406\u65f6\u95f4\u4f18\u5148\u548c\u5217\u8868\u8c03\u5ea6\uff0c\u5e76\u5f15\u5165\u9488\u5bf9MIG\u7ea6\u675f\u7684\u65b0\u542f\u53d1\u5f0f\u65b9\u6cd5\uff1b3\uff09\u901a\u8fc7\u4efb\u52a1\u79fb\u52a8\u548c\u4ea4\u6362\u8fdb\u884c\u5c40\u90e8\u641c\u7d22\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cFAR\u5728\u4e0d\u8003\u8651\u91cd\u65b0\u914d\u7f6e\u6210\u672c\u65f6\uff0c\u8fd1\u4f3c\u56e0\u5b50\u4e3a7/4\uff08A30\u6a21\u578b\uff09\u548c2\uff08A100/H100\u6a21\u578b\uff09\uff1b\u8003\u8651\u91cd\u65b0\u914d\u7f6e\u6210\u672c\u540e\uff0c\u5b8c\u6210\u65f6\u95f4\u4e0e\u6700\u4f18\u89e3\u7684\u6bd4\u503c\u4e0d\u8d85\u8fc71.22x\uff08\u57fa\u51c6\u6d4b\u8bd5\uff09\u548c1.10x\uff08\u5408\u6210\u8f93\u5165\uff09\u3002", "conclusion": "FAR\u7b97\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5c55\u793a\u4e86MIG\u6280\u672f\u7684\u7814\u7a76\u6f5c\u529b\uff0c\u5e76\u4e3a\u672a\u6765\u5de5\u4f5c\u63d0\u4f9b\u4e86\u6709\u7528\u7684\u6307\u6807\u548c\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2507.13383", "pdf": "https://arxiv.org/pdf/2507.13383", "abs": "https://arxiv.org/abs/2507.13383", "authors": ["Charvi Rastogi", "Tian Huey Teh", "Pushkar Mishra", "Roma Patel", "Ding Wang", "Mark D\u00edaz", "Alicia Parrish", "Aida Mostafazadeh Davani", "Zoe Ashwood", "Michela Paganini", "Vinodkumar Prabhakaran", "Verena Rieser", "Lora Aroyo"], "title": "Whose View of Safety? A Deep DIVE Dataset for Pluralistic Alignment of Text-to-Image Models", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "28 pages, 16 figures", "summary": "Current text-to-image (T2I) models often fail to account for diverse human\nexperiences, leading to misaligned systems. We advocate for pluralistic\nalignment, where an AI understands and is steerable towards diverse, and often\nconflicting, human values. Our work provides three core contributions to\nachieve this in T2I models. First, we introduce a novel dataset for Diverse\nIntersectional Visual Evaluation (DIVE) -- the first multimodal dataset for\npluralistic alignment. It enable deep alignment to diverse safety perspectives\nthrough a large pool of demographically intersectional human raters who\nprovided extensive feedback across 1000 prompts, with high replication,\ncapturing nuanced safety perceptions. Second, we empirically confirm\ndemographics as a crucial proxy for diverse viewpoints in this domain,\nrevealing significant, context-dependent differences in harm perception that\ndiverge from conventional evaluations. Finally, we discuss implications for\nbuilding aligned T2I models, including efficient data collection strategies,\nLLM judgment capabilities, and model steerability towards diverse perspectives.\nThis research offers foundational tools for more equitable and aligned T2I\nsystems. Content Warning: The paper includes sensitive content that may be\nharmful.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5143\u5bf9\u9f50\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165DIVE\u6570\u636e\u96c6\u548c\u5b9e\u8bc1\u7814\u7a76\uff0c\u6539\u8fdb\u6587\u672c\u5230\u56fe\u50cf\uff08T2I\uff09\u6a21\u578b\u4ee5\u66f4\u597d\u5730\u53cd\u6620\u591a\u6837\u7684\u4eba\u7c7b\u4ef7\u503c\u89c2\u3002", "motivation": "\u89e3\u51b3\u5f53\u524dT2I\u6a21\u578b\u672a\u80fd\u6db5\u76d6\u591a\u6837\u4eba\u7c7b\u7ecf\u9a8c\u7684\u95ee\u9898\uff0c\u63a8\u52a8AI\u7cfb\u7edf\u5411\u591a\u5143\u4ef7\u503c\u89c2\u5bf9\u9f50\u3002", "method": "1. \u521b\u5efaDIVE\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u591a\u5143\u5bf9\u9f50\u8bc4\u4f30\uff1b2. \u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u9a8c\u8bc1\u4eba\u53e3\u7edf\u8ba1\u5b66\u4f5c\u4e3a\u591a\u5143\u89c2\u70b9\u7684\u4ee3\u7406\uff1b3. \u63a2\u8ba8T2I\u6a21\u578b\u5bf9\u9f50\u7684\u5b9e\u8df5\u610f\u4e49\u3002", "result": "DIVE\u6570\u636e\u96c6\u6210\u529f\u6355\u6349\u4e86\u591a\u6837\u5316\u7684\u5b89\u5168\u611f\u77e5\uff0c\u5b9e\u8bc1\u7814\u7a76\u63ed\u793a\u4e86\u4e0e\u4f20\u7edf\u8bc4\u4f30\u4e0d\u540c\u7684\u5371\u5bb3\u611f\u77e5\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6784\u5efa\u66f4\u516c\u5e73\u548c\u5bf9\u9f50\u7684T2I\u7cfb\u7edf\u63d0\u4f9b\u4e86\u57fa\u7840\u5de5\u5177\u3002"}}
{"id": "2507.13671", "pdf": "https://arxiv.org/pdf/2507.13671", "abs": "https://arxiv.org/abs/2507.13671", "authors": ["Michael Itzhaki"], "title": "Combinatorics of Palindromes", "categories": ["cs.DS"], "comment": "Full version, accepted to FCT25", "summary": "We investigate the structure and reconstruction complexity of Manacher\narrays. First, we establish a combinatorial lower bound, proving that the\nnumber of rooted tandem repeat trees with $n+1$ genes exceeds the number of\ndistinct Manacher arrays of length $n$. Second, we introduce a graph-theoretic\nframework that associates a graph to each Manacher array, where every proper\nvertex coloring yields a string consistent with the array. Finally, we analyze\na reconstruction algorithm by I et al. (SPIRE 2010), showing that it\nsimultaneously achieves a globally minimal alphabet size, uses at most\n$\\log_2(n{-}1) + 2$ distinct symbols, and can be adapted to produce\nreconstructions over arbitrary alphabets when possible. Our results also\nresolve an open problem posed by the original authors. Together, these findings\nadvance the combinatorial understanding of Manacher arrays and open new\ndirections for string reconstruction under structural constraints.", "AI": {"tldr": "\u7814\u7a76\u4e86Manacher\u6570\u7ec4\u7684\u7ed3\u6784\u548c\u91cd\u5efa\u590d\u6742\u6027\uff0c\u63d0\u51fa\u4e86\u7ec4\u5408\u4e0b\u754c\u3001\u56fe\u8bba\u6846\u67b6\uff0c\u5e76\u5206\u6790\u4e86\u91cd\u5efa\u7b97\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u6df1\u5165\u7406\u89e3Manacher\u6570\u7ec4\u7684\u7ec4\u5408\u6027\u8d28\uff0c\u5e76\u63a2\u7d22\u5176\u5728\u5b57\u7b26\u4e32\u91cd\u5efa\u4e2d\u7684\u5e94\u7528\u3002", "method": "1. \u5efa\u7acb\u7ec4\u5408\u4e0b\u754c\uff1b2. \u5f15\u5165\u56fe\u8bba\u6846\u67b6\uff1b3. \u5206\u6790\u91cd\u5efa\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u7ec4\u5408\u4e0b\u754c\uff0c\u63d0\u51fa\u4e86\u56fe\u8bba\u6846\u67b6\uff0c\u5e76\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u5168\u5c40\u6700\u4f18\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "\u7814\u7a76\u63a8\u8fdb\u4e86\u5bf9Manacher\u6570\u7ec4\u7684\u7406\u89e3\uff0c\u5e76\u4e3a\u7ed3\u6784\u7ea6\u675f\u4e0b\u7684\u5b57\u7b26\u4e32\u91cd\u5efa\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.13553", "pdf": "https://arxiv.org/pdf/2507.13553", "abs": "https://arxiv.org/abs/2507.13553", "authors": ["Pragyan K C", "Rambod Ghandiparsi", "Thomas Herron", "John Heaps", "Mitra Bokaei Hosseini"], "title": "Towards Better Requirements from the Crowd: Developer Engagement with Feature Requests in Open Source Software", "categories": ["cs.SE"], "comment": "Accepted at the 9th International Workshop on Crowd-Based\n  Requirements Engineering (CrowdRE'25)", "summary": "As user demands evolve, effectively incorporating feature requests is crucial\nfor maintaining software relevance and user satisfaction. Feature requests,\ntypically expressed in natural language, often suffer from ambiguity or\nincomplete information due to communication gaps or the requester's limited\ntechnical expertise. These issues can lead to misinterpretation, faulty\nimplementation, and reduced software quality. While seeking clarification from\nrequesters is a common strategy to mitigate these risks, little is known about\nhow developers engage in this clarification process in practice-how they\nformulate clarifying questions, seek technical or contextual details, align on\ngoals and use cases, or decide to close requests without attempting\nclarification. This study investigates how feature requests are prone to NL\ndefects (i.e. ambiguous or incomplete) and the conversational dynamics of\nclarification in open-source software (OSS) development, aiming to understand\nhow developers handle ambiguous or incomplete feature requests. Our findings\nsuggest that feature requests published on the OSS platforms do possess\nambiguity and incompleteness, and in some cases, both. We also find that\nexplicit clarification for the resolution of these defects is uncommon;\ndevelopers usually focus on aligning with project goals rather than resolving\nunclear text. When clarification occurs, it emphasizes understanding user\nintent/goal and feasibility, rather than technical details. By characterizing\nthe dynamics of clarification in open-source issue trackers, this work\nidentifies patterns that can improve user-developer collaboration and inform\nbest practices for handling feature requests effectively.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5f00\u6e90\u8f6f\u4ef6\u4e2d\u529f\u80fd\u8bf7\u6c42\u7684\u6a21\u7cca\u6027\u548c\u4e0d\u5b8c\u6574\u6027\uff0c\u4ee5\u53ca\u5f00\u53d1\u8005\u6f84\u6e05\u95ee\u9898\u7684\u52a8\u6001\u8fc7\u7a0b\uff0c\u53d1\u73b0\u5f00\u53d1\u8005\u66f4\u5173\u6ce8\u9879\u76ee\u76ee\u6807\u800c\u975e\u6587\u672c\u6f84\u6e05\u3002", "motivation": "\u529f\u80fd\u8bf7\u6c42\u5e38\u56e0\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u6a21\u7cca\u6216\u4e0d\u5b8c\u6574\u5bfc\u81f4\u8bef\u89e3\u548c\u5b9e\u65bd\u9519\u8bef\uff0c\u4f46\u5f00\u53d1\u8005\u6f84\u6e05\u95ee\u9898\u7684\u5b9e\u9645\u884c\u4e3a\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e86\u5f00\u6e90\u8f6f\u4ef6\u5e73\u53f0\u4e0a\u7684\u529f\u80fd\u8bf7\u6c42\u53ca\u5176\u6f84\u6e05\u8fc7\u7a0b\uff0c\u5173\u6ce8\u5f00\u53d1\u8005\u5982\u4f55\u5904\u7406\u6a21\u7cca\u6216\u4e0d\u5b8c\u6574\u7684\u8bf7\u6c42\u3002", "result": "\u529f\u80fd\u8bf7\u6c42\u666e\u904d\u5b58\u5728\u6a21\u7cca\u6027\u548c\u4e0d\u5b8c\u6574\u6027\uff0c\u4f46\u5f00\u53d1\u8005\u8f83\u5c11\u8fdb\u884c\u660e\u786e\u6f84\u6e05\uff0c\u66f4\u6ce8\u91cd\u4e0e\u9879\u76ee\u76ee\u6807\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u6f84\u6e05\u95ee\u9898\u7684\u52a8\u6001\u6a21\u5f0f\uff0c\u4e3a\u6539\u5584\u7528\u6237\u4e0e\u5f00\u53d1\u8005\u534f\u4f5c\u63d0\u4f9b\u4e86\u5b9e\u8df5\u5efa\u8bae\u3002"}}
{"id": "2507.13717", "pdf": "https://arxiv.org/pdf/2507.13717", "abs": "https://arxiv.org/abs/2507.13717", "authors": ["Yingming Mao", "Qiaozhu Zhai", "Zhen Yao", "Xia Zhu", "Ximeng Liu", "Xinchi Han"], "title": "ATRO: A Fast Solver-Free Algorithm for Topology and Routing Optimization of Reconfigurable Datacenter Networks", "categories": ["cs.NI", "C.2.3"], "comment": null, "summary": "The growing scale and complexity of reconfigurable data center networks\n(DCNs) demand more scalable and efficient algorithms for computing logical\ntopologies and routing. Reconfigurable DCNs typically operate in two modes:\none-hop configurations that require frequent topology optimization (TO), and\nmulti-hop scenarios that involve joint topology and routing optimization (TRO).\nIn both cases, the combinatorial nature of topology decisions makes it\ndifficult for existing methods to balance solution quality and runtime\nefficiency. To address this, we introduce Alternating Topology and Routing\nOptimization (ATRO), a solver-free framework that alternates between TO and\nrouting optimization (RO). This decomposition exploits two key insights: first,\neach alternating update step monotonically reduces maximum link utilization\n(MLU), ensuring consistent performance improvement across iterations; second,\nthe TO subproblem, equivalent to one-hop optimization, exhibits a monotonic\nstructure that enables optimal solutions via an efficient Accelerated Binary\nSearch Method (ABSM). To preserve the solver-free design, RO is solved using\nexisting Traffic Engineering accelerators. ATRO attains the global optimum in\none-hop scenarios and significantly outperforms baselines in multi-hop settings\nin terms of both runtime and solution quality. Evaluations confirm its\nscalability and robustness across diverse DCNs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aATRO\u7684\u65e0\u6c42\u89e3\u5668\u6846\u67b6\uff0c\u7528\u4e8e\u53ef\u91cd\u6784\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u7684\u62d3\u6251\u548c\u8def\u7531\u4f18\u5316\uff0c\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u6b65\u9aa4\u663e\u8457\u63d0\u5347\u6027\u80fd\u548c\u6548\u7387\u3002", "motivation": "\u53ef\u91cd\u6784\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u7684\u89c4\u6a21\u548c\u590d\u6742\u6027\u589e\u52a0\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u548c\u53ef\u6269\u5c55\u7684\u7b97\u6cd5\u6765\u4f18\u5316\u62d3\u6251\u548c\u8def\u7531\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u548c\u8fd0\u884c\u6548\u7387\u3002", "method": "ATRO\u6846\u67b6\u901a\u8fc7\u4ea4\u66ff\u8fdb\u884c\u62d3\u6251\u4f18\u5316\uff08TO\uff09\u548c\u8def\u7531\u4f18\u5316\uff08RO\uff09\uff0c\u5229\u7528\u5355\u8c03\u6027\u4fdd\u8bc1\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u4f7f\u7528\u52a0\u901f\u4e8c\u5206\u641c\u7d22\u65b9\u6cd5\uff08ABSM\uff09\u9ad8\u6548\u89e3\u51b3TO\u5b50\u95ee\u9898\u3002", "result": "ATRO\u5728\u4e00\u8df3\u573a\u666f\u4e2d\u8fbe\u5230\u5168\u5c40\u6700\u4f18\uff0c\u5728\u591a\u8df3\u573a\u666f\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5177\u6709\u8f83\u9ad8\u7684\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "ATRO\u4e3a\u53ef\u91cd\u6784\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u8fd0\u884c\u6548\u7387\u3002"}}
{"id": "2507.13833", "pdf": "https://arxiv.org/pdf/2507.13833", "abs": "https://arxiv.org/abs/2507.13833", "authors": ["Zhixin Wang", "Tianyi Zhou", "Liming Liu", "Ao Li", "Jiarui Hu", "Dian Yang", "Jinlong Hou", "Siyuan Feng", "Yuan Cheng", "Yuan Qi"], "title": "DistFlow: A Fully Distributed RL Framework for Scalable and Efficient LLM Post-Training", "categories": ["cs.DC"], "comment": null, "summary": "Reinforcement learning (RL) has become the pivotal post-training technique\nfor large language model. Effectively scaling reinforcement learning is now the\nkey to unlocking advanced reasoning capabilities and ensuring safe,\ngoal-aligned behavior in the most powerful LLMs. Mainstream frameworks usually\nemploy a hybrid-controller architecture where a single-controller dispatches\nthe overall execution logic and manages overall data transfer and the\nmulti-controller executes distributed computation. For large-scale\nreinforcement learning, minor load imbalances can introduce significant\nbottlenecks, ultimately constraining the scalability of the system. To address\nthis limitation, we introduce DistFlow, a novel, fully distributed RL framework\ndesigned to break scaling barrier. We adopt a multi-controller paradigm that\ndispatches data transfer and execution tasks to all workers, which eliminates\nthe centralized node. This allows each worker to operate independently, leading\nto near-linear scalability up to thousands of GPUs and dramatic efficiency\ngains. Furthermore, our architecture decouples resource configuration from\nexecution logic, allowing each worker to have a unique execution flow, offering\nsignificant flexibility for rapid and cost-effective algorithmic\nexperimentation. Extensive experiments show that DistFlow achieves excellent\nlinear scalability and up to a 7x end-to-end throughput improvement over\nstate-of-the-art (SOTA) frameworks.", "AI": {"tldr": "DistFlow\u662f\u4e00\u79cd\u65b0\u578b\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u63a7\u5236\u5668\u8303\u5f0f\u6d88\u9664\u4e2d\u5fc3\u8282\u70b9\uff0c\u5b9e\u73b0\u8fd1\u7ebf\u6027\u6269\u5c55\u548c\u9ad8\u6548\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u4e2d\u8d1f\u8f7d\u4e0d\u5e73\u8861\u5bfc\u81f4\u7684\u6269\u5c55\u74f6\u9888\u95ee\u9898\u3002", "method": "\u91c7\u7528\u591a\u63a7\u5236\u5668\u8303\u5f0f\uff0c\u5c06\u6570\u636e\u4f20\u8f93\u548c\u6267\u884c\u4efb\u52a1\u5206\u914d\u7ed9\u6240\u6709\u5de5\u4f5c\u8282\u70b9\uff0c\u5b9e\u73b0\u5b8c\u5168\u5206\u5e03\u5f0f\u3002", "result": "\u5b9e\u9a8c\u663e\u793aDistFlow\u5177\u6709\u4f18\u5f02\u7684\u7ebf\u6027\u6269\u5c55\u6027\uff0c\u541e\u5410\u91cf\u6bd4\u73b0\u6709\u6280\u672f\u63d0\u53477\u500d\u3002", "conclusion": "DistFlow\u7a81\u7834\u4e86\u5f3a\u5316\u5b66\u4e60\u7684\u6269\u5c55\u9650\u5236\uff0c\u4e3a\u9ad8\u6548\u7b97\u6cd5\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u7075\u6d3b\u6027\u3002"}}
{"id": "2507.13393", "pdf": "https://arxiv.org/pdf/2507.13393", "abs": "https://arxiv.org/abs/2507.13393", "authors": ["Jakub Strawa", "Jarek Duda"], "title": "Improving KAN with CDF normalization to quantiles", "categories": ["cs.LG"], "comment": "7 pages, 9 figures", "summary": "Data normalization is crucial in machine learning, usually performed by\nsubtracting the mean and dividing by standard deviation, or by rescaling to a\nfixed range. In copula theory, popular in finance, there is used normalization\nto approximately quantiles by transforming x to CDF(x) with estimated CDF\n(cumulative distribution function) to nearly uniform distribution in [0,1],\nallowing for simpler representations which are less likely to overfit. It seems\nnearly unknown in machine learning, therefore, we would like to present some\nits advantages on example of recently popular Kolmogorov-Arnold Networks\n(KANs), improving predictions from Legendre-KAN by just switching rescaling to\nCDF normalization. Additionally, in HCR interpretation, weights of such neurons\nare mixed moments providing local joint distribution models, allow to propagate\nalso probability distributions, and change propagation direction.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u4f7f\u7528CDF\u5f52\u4e00\u5316\u7684\u4f18\u52bf\uff0c\u901a\u8fc7KANs\u5c55\u793a\u4e86\u5176\u4f18\u4e8e\u4f20\u7edf\u5f52\u4e00\u5316\u65b9\u6cd5\u7684\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u4e2d\u5e38\u7528\u7684\u5f52\u4e00\u5316\u65b9\u6cd5\uff08\u5982\u5747\u503c\u6807\u51c6\u5dee\u6216\u56fa\u5b9a\u8303\u56f4\u7f29\u653e\uff09\u5728\u91d1\u878d\u9886\u57df\u7684copula\u7406\u8bba\u4e2d\u5e76\u4e0d\u5e38\u89c1\uff0c\u800cCDF\u5f52\u4e00\u5316\u80fd\u51cf\u5c11\u8fc7\u62df\u5408\u5e76\u63d0\u4f9b\u66f4\u7b80\u5355\u7684\u8868\u793a\u3002", "method": "\u901a\u8fc7\u5c06\u6570\u636e\u8f6c\u6362\u4e3aCDF(x)\u5b9e\u73b0\u5f52\u4e00\u5316\uff0c\u5e94\u7528\u4e8eKolmogorov-Arnold Networks (KANs)\uff0c\u5e76\u4e0e\u4f20\u7edf\u65b9\u6cd5\uff08\u5982Legendre-KAN\uff09\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "CDF\u5f52\u4e00\u5316\u663e\u8457\u63d0\u5347\u4e86KANs\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u795e\u7ecf\u5143\u6743\u91cd\u53ef\u4f5c\u4e3a\u6df7\u5408\u77e9\uff0c\u652f\u6301\u5c40\u90e8\u8054\u5408\u5206\u5e03\u5efa\u6a21\u548c\u6982\u7387\u5206\u5e03\u4f20\u64ad\u3002", "conclusion": "CDF\u5f52\u4e00\u5316\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u6539\u5584\u6a21\u578b\u6027\u80fd\u5e76\u63d0\u4f9b\u66f4\u7075\u6d3b\u7684\u5206\u5e03\u5efa\u6a21\u80fd\u529b\u3002"}}
{"id": "2507.13700", "pdf": "https://arxiv.org/pdf/2507.13700", "abs": "https://arxiv.org/abs/2507.13700", "authors": ["Emma Rapoport", "Edith Cohen", "Uri Stemmer"], "title": "Tight Bounds for Answering Adaptively Chosen Concentrated Queries", "categories": ["cs.DS", "cs.LG"], "comment": null, "summary": "Most work on adaptive data analysis assumes that samples in the dataset are\nindependent. When correlations are allowed, even the non-adaptive setting can\nbecome intractable, unless some structural constraints are imposed. To address\nthis, Bassily and Freund [2016] introduced the elegant framework of\nconcentrated queries, which requires the analyst to restrict itself to queries\nthat are concentrated around their expected value. While this assumption makes\nthe problem trivial in the non-adaptive setting, in the adaptive setting it\nremains quite challenging. In fact, all known algorithms in this framework\nsupport significantly fewer queries than in the independent case: At most\n$O(n)$ queries for a sample of size $n$, compared to $O(n^2)$ in the\nindependent setting.\n  In this work, we prove that this utility gap is inherent under the current\nformulation of the concentrated queries framework, assuming some natural\nconditions on the algorithm. Additionally, we present a simplified version of\nthe best-known algorithms that match our impossibility result.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u81ea\u9002\u5e94\u6570\u636e\u5206\u6790\u4e2d\u6570\u636e\u96c6\u6837\u672c\u76f8\u5173\u6027\u7684\u95ee\u9898\uff0c\u6307\u51fa\u5728\u76f8\u5173\u6837\u672c\u4e0b\uff0c\u5373\u4f7f\u662f\u975e\u81ea\u9002\u5e94\u8bbe\u7f6e\u4e5f\u53ef\u80fd\u96be\u4ee5\u5904\u7406\u3002Bassily\u548cFreund\u63d0\u51fa\u7684\u96c6\u4e2d\u67e5\u8be2\u6846\u67b6\u5728\u975e\u81ea\u9002\u5e94\u8bbe\u7f6e\u4e2d\u7b80\u5316\u4e86\u95ee\u9898\uff0c\u4f46\u5728\u81ea\u9002\u5e94\u8bbe\u7f6e\u4e2d\u4ecd\u5177\u6311\u6218\u6027\u3002\u672c\u6587\u8bc1\u660e\u4e86\u5728\u5f53\u524d\u6846\u67b6\u4e0b\uff0c\u67e5\u8be2\u6570\u91cf\u7684\u5dee\u8ddd\u662f\u56fa\u6709\u7684\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5316\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76\u5728\u6570\u636e\u96c6\u6837\u672c\u76f8\u5173\u7684\u60c5\u51b5\u4e0b\uff0c\u81ea\u9002\u5e94\u6570\u636e\u5206\u6790\u7684\u53ef\u884c\u6027\u548c\u6548\u7387\uff0c\u7279\u522b\u662f\u96c6\u4e2d\u67e5\u8be2\u6846\u67b6\u7684\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u548c\u7b97\u6cd5\u8bbe\u8ba1\uff0c\u5206\u6790\u4e86\u96c6\u4e2d\u67e5\u8be2\u6846\u67b6\u5728\u81ea\u9002\u5e94\u8bbe\u7f6e\u4e2d\u7684\u56fa\u6709\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5316\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u5f53\u524d\u6846\u67b6\u4e0b\uff0c\u67e5\u8be2\u6570\u91cf\u7684\u5dee\u8ddd\u662f\u56fa\u6709\u7684\uff0c\u4e14\u63d0\u51fa\u7684\u7b80\u5316\u7b97\u6cd5\u4e0e\u4e0d\u53ef\u80fd\u6027\u7ed3\u679c\u76f8\u5339\u914d\u3002", "conclusion": "\u96c6\u4e2d\u67e5\u8be2\u6846\u67b6\u5728\u81ea\u9002\u5e94\u8bbe\u7f6e\u4e2d\u5b58\u5728\u56fa\u6709\u5c40\u9650\u6027\uff0c\u672a\u6765\u7814\u7a76\u9700\u63a2\u7d22\u66f4\u6709\u6548\u7684\u6846\u67b6\u6216\u65b9\u6cd5\u3002"}}
{"id": "2507.13555", "pdf": "https://arxiv.org/pdf/2507.13555", "abs": "https://arxiv.org/abs/2507.13555", "authors": ["Pragyan K C", "Rambod Ghandiparsi", "Thomas Herron", "John Heaps", "Mitra Bokaei Hosseini"], "title": "Demystifying Feature Requests: Leveraging LLMs to Refine Feature Requests in Open-Source Software", "categories": ["cs.SE"], "comment": "Accepted at the 33rd IEEE International Requirements Engineering 2025", "summary": "The growing popularity and widespread use of software applications (apps)\nacross various domains have driven rapid industry growth. Along with this\ngrowth, fast-paced market changes have led to constantly evolving software\nrequirements. Such requirements are often grounded in feature requests and\nenhancement suggestions, typically provided by users in natural language (NL).\nHowever, these requests often suffer from defects such as ambiguity and\nincompleteness, making them challenging to interpret. Traditional validation\nmethods (e.g., interviews and workshops) help clarify such defects but are\nimpractical in decentralized environments like open-source software (OSS),\nwhere change requests originate from diverse users on platforms like GitHub.\nThis paper proposes a novel approach leveraging Large Language Models (LLMs) to\ndetect and refine NL defects in feature requests. Our approach automates the\nidentification of ambiguous and incomplete requests and generates clarification\nquestions (CQs) to enhance their usefulness for developers. To evaluate its\neffectiveness, we apply our method to real-world OSS feature requests and\ncompare its performance against human annotations. In addition, we conduct\ninterviews with GitHub developers to gain deeper insights into their\nperceptions of NL defects, the strategies they use to address these defects,\nand the impact of defects on downstream software engineering (SE) tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u81ea\u52a8\u68c0\u6d4b\u548c\u4f18\u5316\u81ea\u7136\u8bed\u8a00\uff08NL\uff09\u7279\u5f81\u8bf7\u6c42\u4e2d\u7684\u7f3a\u9677\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u5176\u5bf9\u5f00\u53d1\u8005\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u5e94\u7528\u7684\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5feb\u901f\u53d8\u5316\u7684\u5e02\u573a\u9700\u6c42\u5bfc\u81f4\u8f6f\u4ef6\u9700\u6c42\u4e0d\u65ad\u6f14\u53d8\uff0c\u4f46\u8fd9\u4e9b\u9700\u6c42\u5e38\u56e0\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u6a21\u7cca\u6027\u548c\u4e0d\u5b8c\u6574\u6027\u800c\u96be\u4ee5\u89e3\u8bfb\u3002\u4f20\u7edf\u9a8c\u8bc1\u65b9\u6cd5\u5728\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\uff08\u5982\u5f00\u6e90\u8f6f\u4ef6\uff09\u4e2d\u4e0d\u5207\u5b9e\u9645\u3002", "method": "\u5229\u7528LLMs\u81ea\u52a8\u8bc6\u522b\u6a21\u7cca\u548c\u4e0d\u5b8c\u6574\u7684\u8bf7\u6c42\uff0c\u5e76\u751f\u6210\u6f84\u6e05\u95ee\u9898\uff08CQs\uff09\u3002\u65b9\u6cd5\u5728\u771f\u5b9e\u5f00\u6e90\u9879\u76ee\u4e2d\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4e0e\u4eba\u5de5\u6807\u6ce8\u5bf9\u6bd4\u3002", "result": "\u65b9\u6cd5\u5728\u68c0\u6d4b\u548c\u4f18\u5316NL\u7f3a\u9677\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u901a\u8fc7\u5f00\u53d1\u8005\u8bbf\u8c08\u9a8c\u8bc1\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "LLMs\u80fd\u6709\u6548\u63d0\u5347\u7279\u5f81\u8bf7\u6c42\u7684\u8d28\u91cf\uff0c\u51cf\u5c11\u4e0b\u6e38\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u7684\u8d1f\u62c5\u3002"}}
{"id": "2507.13889", "pdf": "https://arxiv.org/pdf/2507.13889", "abs": "https://arxiv.org/abs/2507.13889", "authors": ["Bilal Karaman", "Ilhan Basturk", "Ferdi Kara", "Metin Ozturk", "Sezai Taskin", "Halil Yanikomeroglu"], "title": "On the Trade-Off Between Sum-Rate and Energy Efficiency through the Convergence of HAPS and Active RIS Technologies", "categories": ["cs.NI", "eess.SP"], "comment": "accepted in PIMRC2025", "summary": "This paper investigates the integration of active reconfigurable intelligent\nsurfaces (RIS) relay with high-altitude platform stations (HAPS) to enhance\nnon-terrestrial network (NTN) performance in next-generation wireless systems.\nWhile prior studies focused on passive RIS architectures, the severe path loss\nand double fading in long-distance HAPS links make active RIS a more suitable\nalternative due to its inherent signal amplification capabilities. We formulate\na sum-rate maximization problem to jointly optimize power allocation and RIS\nelement assignment for ground user equipments (UEs) supported by a HAPS-based\nactive RIS-assisted communication system. To reduce power consumption and\nhardware complexity, several sub-connected active RIS architectures are also\nexplored. Simulation results reveal that active RIS configurations\nsignificantly outperform passive RIS in terms of quality of service (QoS).\nMoreover, although fully-connected architectures achieve the highest\nthroughput, sub-connected schemes demonstrate superior energy efficiency under\npractical power constraints. These findings highlight the potential of active\nRIS-enabled HAPS systems to meet the growing demands of beyond-cellular\ncoverage and green networking.", "AI": {"tldr": "\u7814\u7a76\u5c06\u4e3b\u52a8\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u4e2d\u7ee7\u4e0e\u9ad8\u7a7a\u5e73\u53f0\u7ad9\uff08HAPS\uff09\u7ed3\u5408\uff0c\u63d0\u5347\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u975e\u5730\u9762\u7f51\u7edc\uff08NTN\uff09\u6027\u80fd\u3002\u4e3b\u52a8RIS\u56e0\u5176\u4fe1\u53f7\u653e\u5927\u80fd\u529b\u4f18\u4e8e\u88ab\u52a8RIS\uff0c\u5c24\u5176\u5728\u957f\u8ddd\u79bbHAPS\u94fe\u8def\u4e2d\u3002\u901a\u8fc7\u8054\u5408\u4f18\u5316\u529f\u7387\u5206\u914d\u548cRIS\u5355\u5143\u5206\u914d\uff0c\u5b9e\u73b0\u5730\u9762\u7528\u6237\u8bbe\u5907\uff08UEs\uff09\u7684\u901f\u7387\u6700\u5927\u5316\u3002\u4eff\u771f\u663e\u793a\u4e3b\u52a8RIS\u663e\u8457\u63d0\u5347\u670d\u52a1\u8d28\u91cf\uff08QoS\uff09\uff0c\u4e14\u5b50\u8fde\u63a5\u67b6\u6784\u5728\u80fd\u6548\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u957f\u8ddd\u79bbHAPS\u94fe\u8def\u5b58\u5728\u4e25\u91cd\u8def\u5f84\u635f\u8017\u548c\u53cc\u8870\u843d\u95ee\u9898\uff0c\u88ab\u52a8RIS\u67b6\u6784\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u63a2\u7d22\u4e3b\u52a8RIS\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u8054\u5408\u4f18\u5316\u529f\u7387\u5206\u914d\u548cRIS\u5355\u5143\u5206\u914d\u7684\u901f\u7387\u6700\u5927\u5316\u95ee\u9898\uff0c\u5e76\u7814\u7a76\u591a\u79cd\u5b50\u8fde\u63a5\u4e3b\u52a8RIS\u67b6\u6784\u4ee5\u964d\u4f4e\u529f\u8017\u548c\u786c\u4ef6\u590d\u6742\u5ea6\u3002", "result": "\u4e3b\u52a8RIS\u914d\u7f6e\u663e\u8457\u4f18\u4e8e\u88ab\u52a8RIS\uff0c\u5c24\u5176\u5728QoS\u65b9\u9762\uff1b\u5b8c\u5168\u8fde\u63a5\u67b6\u6784\u541e\u5410\u91cf\u6700\u9ad8\uff0c\u4f46\u5b50\u8fde\u63a5\u67b6\u6784\u5728\u80fd\u6548\u4e0a\u66f4\u4f18\u3002", "conclusion": "\u4e3b\u52a8RIS\u652f\u6301\u7684HAPS\u7cfb\u7edf\u6709\u671b\u6ee1\u8db3\u672a\u6765\u8d85\u8702\u7a9d\u8986\u76d6\u548c\u7eff\u8272\u7f51\u7edc\u7684\u9700\u6c42\u3002"}}
{"id": "2507.14069", "pdf": "https://arxiv.org/pdf/2507.14069", "abs": "https://arxiv.org/abs/2507.14069", "authors": ["Shuiguang Deng", "Di Yu", "Changze Lv", "Xin Du", "Linshan Jiang", "Xiaofan Zhao", "Wentao Tong", "Xiaoqing Zheng", "Weijia Fang", "Peng Zhao", "Gang Pan", "Schahram Dustdar", "Albert Y. Zomaya"], "title": "Edge Intelligence with Spiking Neural Networks", "categories": ["cs.DC", "cs.AI", "cs.ET", "cs.NE"], "comment": "This work has been submitted to Proceeding of IEEE for possible\n  publication", "summary": "The convergence of artificial intelligence and edge computing has spurred\ngrowing interest in enabling intelligent services directly on\nresource-constrained devices. While traditional deep learning models require\nsignificant computational resources and centralized data management, the\nresulting latency, bandwidth consumption, and privacy concerns have exposed\ncritical limitations in cloud-centric paradigms. Brain-inspired computing,\nparticularly Spiking Neural Networks (SNNs), offers a promising alternative by\nemulating biological neuronal dynamics to achieve low-power, event-driven\ncomputation. This survey provides a comprehensive overview of Edge Intelligence\nbased on SNNs (EdgeSNNs), examining their potential to address the challenges\nof on-device learning, inference, and security in edge scenarios. We present a\nsystematic taxonomy of EdgeSNN foundations, encompassing neuron models,\nlearning algorithms, and supporting hardware platforms. Three representative\npractical considerations of EdgeSNN are discussed in depth: on-device inference\nusing lightweight SNN models, resource-aware training and updating under\nnon-stationary data conditions, and secure and privacy-preserving issues.\nFurthermore, we highlight the limitations of evaluating EdgeSNNs on\nconventional hardware and introduce a dual-track benchmarking strategy to\nsupport fair comparisons and hardware-aware optimization. Through this study,\nwe aim to bridge the gap between brain-inspired learning and practical edge\ndeployment, offering insights into current advancements, open challenges, and\nfuture research directions. To the best of our knowledge, this is the first\ndedicated and comprehensive survey on EdgeSNNs, providing an essential\nreference for researchers and practitioners working at the intersection of\nneuromorphic computing and edge intelligence.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNNs\uff09\u7684\u8fb9\u7f18\u667a\u80fd\uff08EdgeSNNs\uff09\uff0c\u63a2\u8ba8\u5176\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u5b9e\u73b0\u4f4e\u529f\u8017\u3001\u4e8b\u4ef6\u9a71\u52a8\u8ba1\u7b97\u7684\u6f5c\u529b\uff0c\u5e76\u7cfb\u7edf\u5206\u7c7b\u4e86\u5176\u57fa\u7840\u3001\u5e94\u7528\u53ca\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u9762\u4e34\u5ef6\u8fdf\u3001\u5e26\u5bbd\u548c\u9690\u79c1\u95ee\u9898\uff0c\u800cSNNs\u901a\u8fc7\u6a21\u62df\u751f\u7269\u795e\u7ecf\u5143\u52a8\u6001\u63d0\u4f9b\u4e86\u4e00\u79cd\u4f4e\u529f\u8017\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86EdgeSNNs\u7684\u7cfb\u7edf\u5206\u7c7b\uff0c\u5305\u62ec\u795e\u7ecf\u5143\u6a21\u578b\u3001\u5b66\u4e60\u7b97\u6cd5\u548c\u786c\u4ef6\u5e73\u53f0\uff0c\u5e76\u6df1\u5165\u8ba8\u8bba\u4e86\u8f7b\u91cf\u7ea7\u63a8\u7406\u3001\u8d44\u6e90\u611f\u77e5\u8bad\u7ec3\u548c\u9690\u79c1\u4fdd\u62a4\u7b49\u5b9e\u9645\u95ee\u9898\u3002", "result": "\u8bba\u6587\u603b\u7ed3\u4e86EdgeSNNs\u7684\u5f53\u524d\u8fdb\u5c55\u548c\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u53cc\u8f68\u57fa\u51c6\u6d4b\u8bd5\u7b56\u7565\u4ee5\u652f\u6301\u516c\u5e73\u6bd4\u8f83\u548c\u786c\u4ef6\u4f18\u5316\u3002", "conclusion": "\u8be5\u7814\u7a76\u65e8\u5728\u586b\u8865\u8111\u542f\u53d1\u5b66\u4e60\u4e0e\u8fb9\u7f18\u90e8\u7f72\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u53c2\u8003\uff0c\u5e76\u63a8\u52a8\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.13399", "pdf": "https://arxiv.org/pdf/2507.13399", "abs": "https://arxiv.org/abs/2507.13399", "authors": ["Mert Sehri", "Zehui Hua", "Francisco de Assis Boldt", "Patrick Dumond"], "title": "Selective Embedding for Deep Learning", "categories": ["cs.LG"], "comment": null, "summary": "Deep learning has revolutionized many industries by enabling models to\nautomatically learn complex patterns from raw data, reducing dependence on\nmanual feature engineering. However, deep learning algorithms are sensitive to\ninput data, and performance often deteriorates under nonstationary conditions\nand across dissimilar domains, especially when using time-domain data.\nConventional single-channel or parallel multi-source data loading strategies\neither limit generalization or increase computational costs. This study\nintroduces selective embedding, a novel data loading strategy, which alternates\nshort segments of data from multiple sources within a single input channel.\nDrawing inspiration from cognitive psychology, selective embedding mimics\nhuman-like information processing to reduce model overfitting, enhance\ngeneralization, and improve computational efficiency. Validation is conducted\nusing six time-domain datasets, demonstrating that the proposed method\nconsistently achieves high classification accuracy across various deep learning\narchitectures while significantly reducing training times. The approach proves\nparticularly effective for complex systems with multiple data sources, offering\na scalable and resource-efficient solution for real-world applications in\nhealthcare, heavy machinery, marine, railway, and agriculture, where robustness\nand adaptability are critical.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u9009\u62e9\u6027\u5d4c\u5165\u7684\u65b0\u6570\u636e\u52a0\u8f7d\u7b56\u7565\uff0c\u901a\u8fc7\u4ea4\u66ff\u52a0\u8f7d\u591a\u6e90\u6570\u636e\u7684\u77ed\u7247\u6bb5\u6765\u63d0\u5347\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5bf9\u8f93\u5165\u6570\u636e\u654f\u611f\uff0c\u6027\u80fd\u5728\u975e\u5e73\u7a33\u6761\u4ef6\u4e0b\u548c\u591a\u57df\u6570\u636e\u4e2d\u4e0b\u964d\uff0c\u4f20\u7edf\u6570\u636e\u52a0\u8f7d\u7b56\u7565\u6cdb\u5316\u80fd\u529b\u6709\u9650\u6216\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u9009\u62e9\u6027\u5d4c\u5165\u7b56\u7565\uff0c\u6a21\u4eff\u4eba\u7c7b\u4fe1\u606f\u5904\u7406\u65b9\u5f0f\uff0c\u4ea4\u66ff\u52a0\u8f7d\u591a\u6e90\u6570\u636e\u7684\u77ed\u7247\u6bb5\u3002", "result": "\u5728\u516d\u4e2a\u65f6\u57df\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u6027\u5e76\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u591a\u6e90\u6570\u636e\u7684\u590d\u6742\u7cfb\u7edf\uff0c\u4e3a\u533b\u7597\u3001\u91cd\u5de5\u4e1a\u7b49\u9886\u57df\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.13869", "pdf": "https://arxiv.org/pdf/2507.13869", "abs": "https://arxiv.org/abs/2507.13869", "authors": ["Avi Kadria", "Liam Roditty", "Aaron Sidford", "Virginia Vassilevska Williams", "Uri Zwick"], "title": "Improved girth approximation in weighted undirected graphs", "categories": ["cs.DS"], "comment": null, "summary": "Let $G = (V,E,\\ell)$ be a $n$-node $m$-edge weighted undirected graph, where\n$\\ell: E \\rightarrow (0,\\infty)$ is a real \\emph{length} function defined on\nits edges, and let $g$ denote the girth of $G$, i.e., the length of its\nshortest cycle. We present an algorithm that, for any input, integer $k \\geq\n1$, in $O(kn^{1+1/k}\\log{n} + m(k+\\log{n}))$ expected time finds a cycle of\nlength at most $\\frac{4k}{3}g$. This algorithm nearly matches a\n$O(n^{1+1/k}\\log{n})$-time algorithm of \\cite{KadriaRSWZ22} which applied to\nunweighted graphs of girth $3$. For weighted graphs, this result also improves\nupon the previous state-of-the-art algorithm that in $O((n^{1+1/k}\\log n+m)\\log\n(nM))$ time, where $\\ell: E \\rightarrow [1, M]$ is an integral length function,\nfinds a cycle of length at most $2kg$~\\cite{KadriaRSWZ22}. For $k=1$ this\nresult improves upon the result of Roditty and Tov~\\cite{RodittyT13}.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.13661", "pdf": "https://arxiv.org/pdf/2507.13661", "abs": "https://arxiv.org/abs/2507.13661", "authors": ["Changwen Li", "Joseph Sifakis", "Rongjie Yan", "Jian Zhang"], "title": "Testing Autonomous Driving Systems -- What Really Matters and What Doesn't", "categories": ["cs.SE"], "comment": null, "summary": "Despite extensive research, the testing of autonomous driving systems (ADS)\nlandscape remains fragmented, and there is currently no basis for an informed\ntechnical assessment of the importance and contribution of the current state of\nthe art. This paper attempts to address this problem by exploring two\ncomplementary aspects.\n  First, it proposes a framework for comparing existing test methods in terms\nof their intrinsic effectiveness and validity. It shows that many methods do\nnot meet both of these requirements. Either because they are based on criteria\nthat do not allow for rapid, inexpensive, and comprehensive detection of\nfailures, or because the degree of validity of the properties tested cannot be\naccurately estimated. In particular, it is shown that most critical test\nmethods do not take into account the nominal operational capabilities of\nautopilots and generate scenarios that are impossible for the tested vehicles\nto handle, resulting in unjustified rejections.\n  Secondly, the paper shows that test effectiveness and validity are highly\ndependent on how autopilots are designed: how they choose between different\ncontrol policies to perform maneuvers, as well as on the reproducibility of the\nresults. In fact, most test methods take for granted two principles underlying\ntraditional methods, but do not generally apply to ADS. We maintain that the\nabsence of rationality and determinacy significantly impairs the effectiveness\nand validity of test methods, and provide test results on eight open\nautopilots, in which most do not satisfy these properties, thereby illustrating\nthis fact.\n  We conclude that under the current state of the art, it is impossible to\nobtain strong enough guarantees for essential autopilot properties and\nrecommend that autopilots be developed with a view to both rationality and\ndeterminacy.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff08ADS\uff09\u6d4b\u8bd5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u6709\u6548\u6027\uff0c\u6307\u51fa\u5f53\u524d\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u6d4b\u8bd5\u65b9\u6cd5\u7f3a\u4e4f\u7edf\u4e00\u6807\u51c6\uff0c\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u5176\u91cd\u8981\u6027\u53ca\u8d21\u732e\uff0c\u4e9f\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u7528\u4e8e\u6bd4\u8f83\u73b0\u6709\u6d4b\u8bd5\u65b9\u6cd5\u7684\u5185\u5728\u6709\u6548\u6027\u548c\u6709\u6548\u6027\uff0c\u5e76\u5206\u6790\u5176\u4f9d\u8d56\u7684\u8bbe\u8ba1\u539f\u5219\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u591a\u6570\u6d4b\u8bd5\u65b9\u6cd5\u672a\u80fd\u6ee1\u8db3\u6709\u6548\u6027\u548c\u6709\u6548\u6027\u8981\u6c42\uff0c\u4e14\u6d4b\u8bd5\u7ed3\u679c\u53d7\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u8bbe\u8ba1\u5f71\u54cd\u663e\u8457\u3002", "conclusion": "\u5f53\u524d\u6280\u672f\u4e0b\u65e0\u6cd5\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u63d0\u4f9b\u8db3\u591f\u5f3a\u7684\u4fdd\u969c\uff0c\u5efa\u8bae\u5f00\u53d1\u65f6\u6ce8\u91cd\u5408\u7406\u6027\u548c\u786e\u5b9a\u6027\u3002"}}
{"id": "2507.13933", "pdf": "https://arxiv.org/pdf/2507.13933", "abs": "https://arxiv.org/abs/2507.13933", "authors": ["Sichang \"Steven\" He", "Ramesh Govindan", "Harsha V. Madhyastha"], "title": "Preprint: Did I Just Browse A Website Written by LLMs?", "categories": ["cs.NI", "cs.AI", "cs.CL", "cs.IR"], "comment": "In submission. 2 pages. 3 figures", "summary": "Increasingly, web content is automatically generated by large language models\n(LLMs) with little human input. We call this \"LLM-dominant\" content. Since LLMs\nplagiarize and hallucinate, LLM-dominant content can be unreliable and\nunethical. Yet, websites rarely disclose such content, and human readers\nstruggle to distinguish it. Thus, we must develop reliable detectors for\nLLM-dominant content. However, state-of-the-art LLM detectors are insufficient,\nbecause they perform well mainly on clean, prose-like text, while web content\nhas complex markup and diverse genres.\n  We propose a highly reliable, scalable pipeline that classifies entire\nwebsites. Instead of naively classifying text extracted from each page, we\nclassify each site based on an LLM text detector's outputs of multiple\nprose-like pages. We train and evaluate our detector by collecting 2 distinct\nground truth datasets totaling 120 sites, and obtain 100% accuracies testing\nacross them. In the wild, we detect a sizable portion of sites as LLM-dominant\namong 10k sites in search engine results and 10k in Common Crawl archives. We\nfind LLM-dominant sites are growing in prevalence and rank highly in search\nresults, raising questions about their impact on end users and the overall Web\necosystem.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u53ef\u9760\u6027\u3001\u53ef\u6269\u5c55\u7684\u7ba1\u9053\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e3b\u5bfc\u7684\u7f51\u7ad9\u5185\u5bb9\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u68c0\u6d4b\u5668\u5728\u590d\u6742\u7f51\u9875\u5185\u5bb9\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u968f\u7740LLM\u751f\u6210\u5185\u5bb9\uff08LLM-dominant\uff09\u7684\u666e\u53ca\uff0c\u5176\u4e0d\u53ef\u9760\u6027\u548c\u4f26\u7406\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u4f46\u73b0\u6709\u68c0\u6d4b\u5668\u65e0\u6cd5\u6709\u6548\u8bc6\u522b\u590d\u6742\u7f51\u9875\u5185\u5bb9\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5206\u7c7b\u591a\u4e2a\u6563\u6587\u5f0f\u9875\u9762\u7684LLM\u6587\u672c\u68c0\u6d4b\u7ed3\u679c\uff0c\u800c\u975e\u5355\u72ec\u63d0\u53d6\u6587\u672c\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u9ad8\u51c6\u786e\u7387\u7684\u7f51\u7ad9\u5206\u7c7b\u7ba1\u9053\uff0c\u5e76\u4f7f\u7528\u4e24\u4e2a\u603b\u8ba1120\u4e2a\u7f51\u7ad9\u7684\u771f\u5b9e\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e2d\u5b9e\u73b0\u4e86100%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u5728\u641c\u7d22\u5f15\u64ce\u548cCommon Crawl\u5b58\u6863\u4e2d\u68c0\u6d4b\u5230\u5927\u91cfLLM\u4e3b\u5bfc\u7684\u7f51\u7ad9\uff0c\u53d1\u73b0\u8fd9\u4e9b\u7f51\u7ad9\u5728\u641c\u7d22\u7ed3\u679c\u4e2d\u6392\u540d\u8f83\u9ad8\u4e14\u6570\u91cf\u589e\u957f\u8fc5\u901f\u3002", "conclusion": "LLM\u4e3b\u5bfc\u7684\u7f51\u7ad9\u5bf9\u7528\u6237\u548c\u7f51\u7edc\u751f\u6001\u7cfb\u7edf\u53ef\u80fd\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u5173\u6ce8\u548c\u7814\u7a76\u3002"}}
{"id": "2507.14080", "pdf": "https://arxiv.org/pdf/2507.14080", "abs": "https://arxiv.org/abs/2507.14080", "authors": ["Derek Leung", "Nickolai Zeldovich", "Frans Kaashoek"], "title": "Shipwright: Proving liveness of distributed systems with Byzantine participants", "categories": ["cs.DC", "D.2.4; C.2.4"], "comment": "14 pages, 13 figures", "summary": "Ensuring liveness in a decentralized system, such as PBFT, is critical,\nbecause there may not be any single administrator that can restart the system\nif it encounters a liveness bug. At the same time, liveness is challenging to\nachieve because any single participant could be malicious, and yet the overall\nsystem must make forward progress. While verification is a promising approach\nfor ensuring the absence of bugs, no prior work has been able to verify\nliveness for an executable implementation of PBFT.\n  Shipwright is a verification framework for proving correctness and liveness\nof distributed systems where some participants might be malicious. Shipwright\nintroduces three techniques that enable formal reasoning about decentralized\nsettings with malicious participants, allow developers to decompose their\nsystem and proof in a modular fashion into sub-protocols and sub-proofs, and\nsupport sound reasoning about cryptographic signatures that may be embedded in\nmessages. We used Shipwright to implement and verify an initial prototype of\nagreement on a single log entry in PBFT (with a few limitations) and translate\nit to an executable implementation in Go. We experimentally demonstrate its\noperation and liveness both in the common case and in several failure\nscenarios.", "AI": {"tldr": "Shipwright\u662f\u4e00\u4e2a\u9a8c\u8bc1\u6846\u67b6\uff0c\u7528\u4e8e\u8bc1\u660e\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u6b63\u786e\u6027\u548c\u6d3b\u6027\uff0c\u7279\u522b\u662f\u9488\u5bf9\u6076\u610f\u53c2\u4e0e\u8005\u7684\u60c5\u51b5\u3002\u5b83\u901a\u8fc7\u6a21\u5757\u5316\u5206\u89e3\u548c\u5bc6\u7801\u5b66\u7b7e\u540d\u652f\u6301\uff0c\u6210\u529f\u9a8c\u8bc1\u4e86PBFT\u7684\u90e8\u5206\u5b9e\u73b0\u3002", "motivation": "\u5728\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u4e2d\uff08\u5982PBFT\uff09\uff0c\u786e\u4fdd\u6d3b\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u9a8c\u8bc1\u6d3b\u6027\uff0c\u5c24\u5176\u662f\u9762\u5bf9\u6076\u610f\u53c2\u4e0e\u8005\u65f6\u3002", "method": "Shipwright\u5f15\u5165\u4e09\u79cd\u6280\u672f\uff1a\u652f\u6301\u6076\u610f\u53c2\u4e0e\u8005\u7684\u5f62\u5f0f\u5316\u63a8\u7406\u3001\u6a21\u5757\u5316\u5206\u89e3\u7cfb\u7edf\u548c\u8bc1\u660e\u3001\u4ee5\u53ca\u5bc6\u7801\u5b66\u7b7e\u540d\u7684\u5408\u7406\u63a8\u7406\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u5e76\u9a8c\u8bc1\u4e86PBFT\u4e2d\u5355\u4e2a\u65e5\u5fd7\u6761\u76ee\u534f\u8bae\u7684\u521d\u59cb\u539f\u578b\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684Go\u4ee3\u7801\u3002\u5b9e\u9a8c\u5c55\u793a\u4e86\u5176\u5e38\u89c1\u60c5\u51b5\u548c\u6545\u969c\u573a\u666f\u4e0b\u7684\u6d3b\u6027\u548c\u8fd0\u884c\u3002", "conclusion": "Shipwright\u4e3a\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u6d3b\u6027\u548c\u6b63\u786e\u6027\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u884c\u6846\u67b6\uff0c\u5c24\u5176\u5728\u6076\u610f\u53c2\u4e0e\u8005\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2507.13413", "pdf": "https://arxiv.org/pdf/2507.13413", "abs": "https://arxiv.org/abs/2507.13413", "authors": ["Aleksey Lapin", "Igor Hromov", "Stanislav Chumakov", "Mile Mitrovic", "Dmitry Simakov", "Nikolay O. Nikitin", "Andrey V. Savchenko"], "title": "LightAutoDS-Tab: Multi-AutoML Agentic System for Tabular Data", "categories": ["cs.LG"], "comment": "11 pages, 2 figures", "summary": "AutoML has advanced in handling complex tasks using the integration of LLMs,\nyet its efficiency remains limited by dependence on specific underlying tools.\nIn this paper, we introduce LightAutoDS-Tab, a multi-AutoML agentic system for\ntasks with tabular data, which combines an LLM-based code generation with\nseveral AutoML tools. Our approach improves the flexibility and robustness of\npipeline design, outperforming state-of-the-art open-source solutions on\nseveral data science tasks from Kaggle. The code of LightAutoDS-Tab is\navailable in the open repository https://github.com/sb-ai-lab/LADS", "AI": {"tldr": "LightAutoDS-Tab\u662f\u4e00\u4e2a\u7ed3\u5408LLM\u4ee3\u7801\u751f\u6210\u548c\u591a\u4e2aAutoML\u5de5\u5177\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u7528\u4e8e\u8868\u683c\u6570\u636e\u4efb\u52a1\uff0c\u63d0\u9ad8\u4e86\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5e76\u5728Kaggle\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u5f00\u6e90\u65b9\u6848\u3002", "motivation": "\u5f53\u524dAutoML\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u65f6\u4f9d\u8d56\u7279\u5b9a\u5de5\u5177\uff0c\u6548\u7387\u53d7\u9650\u3002", "method": "\u7ed3\u5408LLM\u4ee3\u7801\u751f\u6210\u548c\u591a\u4e2aAutoML\u5de5\u5177\uff0c\u8bbe\u8ba1\u591a\u4ee3\u7406\u7cfb\u7edfLightAutoDS-Tab\u3002", "result": "\u5728\u591a\u4e2aKaggle\u6570\u636e\u79d1\u5b66\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u5f00\u6e90\u65b9\u6848\u3002", "conclusion": "LightAutoDS-Tab\u901a\u8fc7\u591a\u4ee3\u7406\u7cfb\u7edf\u63d0\u5347\u4e86AutoML\u7684\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.13885", "pdf": "https://arxiv.org/pdf/2507.13885", "abs": "https://arxiv.org/abs/2507.13885", "authors": ["Masoud Seddighin", "Saeed Seddighin"], "title": "Quantum Pattern Matching with Wildcards", "categories": ["cs.DS"], "comment": null, "summary": "Pattern matching is one of the fundamental problems in Computer Science. Both\nthe classic version of the problem as well as the more sophisticated version\nwhere wildcards can also appear in the input can be solved in almost linear\ntime $\\tilde O(n)$ using the KMP algorithm and Fast Fourier Transform,\nrespectively. In 2000, Ramesh and Vinay~\\cite{ramesh2003string} give a quantum\nalgorithm that solves classic pattern matching in sublinear time and asked\nwhether the wildcard problem can also be solved in sublinear time? In this\nwork, we give a quantum algorithm for pattern matching with wildcards that runs\nin time $\\tilde O(\\sqrt{n}\\sqrt{k})$ when the number of wildcards is bounded by\n$k$ for $k \\geq \\sqrt{n}$. This leads to an algorithm that runs in sublinear\ntime as long as the number of wildcards is sublinear.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.13505", "pdf": "https://arxiv.org/pdf/2507.13505", "abs": "https://arxiv.org/abs/2507.13505", "authors": ["Steven Lamp", "Jason D. Hiser", "Anh Nguyen-Tuong", "Jack W. Davidson"], "title": "PHASE: Passive Human Activity Simulation Evaluation", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.NI"], "comment": null, "summary": "Cybersecurity simulation environments, such as cyber ranges, honeypots, and\nsandboxes, require realistic human behavior to be effective, yet no\nquantitative method exists to assess the behavioral fidelity of synthetic user\npersonas. This paper presents PHASE (Passive Human Activity Simulation\nEvaluation), a machine learning framework that analyzes Zeek connection logs\nand distinguishes human from non-human activity with over 90\\% accuracy. PHASE\noperates entirely passively, relying on standard network monitoring without any\nuser-side instrumentation or visible signs of surveillance. All network\nactivity used for machine learning is collected via a Zeek network appliance to\navoid introducing unnecessary network traffic or artifacts that could disrupt\nthe fidelity of the simulation environment. The paper also proposes a novel\nlabeling approach that utilizes local DNS records to classify network traffic,\nthereby enabling machine learning analysis. Furthermore, we apply SHAP (SHapley\nAdditive exPlanations) analysis to uncover temporal and behavioral signatures\nindicative of genuine human users. In a case study, we evaluate a synthetic\nuser persona and identify distinct non-human patterns that undermine behavioral\nrealism. Based on these insights, we develop a revised behavioral configuration\nthat significantly improves the human-likeness of synthetic activity yielding a\nmore realistic and effective synthetic user persona.", "AI": {"tldr": "PHASE\u662f\u4e00\u4e2a\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790Zeek\u8fde\u63a5\u65e5\u5fd7\uff0c\u4ee5\u8d85\u8fc790%\u7684\u51c6\u786e\u7387\u533a\u5206\u4eba\u7c7b\u4e0e\u975e\u4eba\u7c7b\u6d3b\u52a8\uff0c\u63d0\u5347\u7f51\u7edc\u5b89\u5168\u6a21\u62df\u73af\u5883\u4e2d\u5408\u6210\u7528\u6237\u884c\u4e3a\u7684\u771f\u5b9e\u6027\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5b9a\u91cf\u65b9\u6cd5\u6765\u8bc4\u4f30\u5408\u6210\u7528\u6237\u884c\u4e3a\u7684\u771f\u5b9e\u6027\uff0c\u800c\u7f51\u7edc\u5b89\u5168\u6a21\u62df\u73af\u5883\u9700\u8981\u903c\u771f\u7684\u4eba\u7c7b\u884c\u4e3a\u4ee5\u63d0\u9ad8\u6709\u6548\u6027\u3002", "method": "PHASE\u6846\u67b6\u88ab\u52a8\u5206\u6790Zeek\u8fde\u63a5\u65e5\u5fd7\uff0c\u5229\u7528\u672c\u5730DNS\u8bb0\u5f55\u5206\u7c7b\u6d41\u91cf\uff0c\u5e76\u7ed3\u5408SHAP\u5206\u6790\u63ed\u793a\u4eba\u7c7b\u7528\u6237\u7684\u884c\u4e3a\u7279\u5f81\u3002", "result": "PHASE\u80fd\u51c6\u786e\u533a\u5206\u4eba\u7c7b\u4e0e\u975e\u4eba\u7c7b\u6d3b\u52a8\uff0c\u5e76\u901a\u8fc7\u6539\u8fdb\u5408\u6210\u7528\u6237\u914d\u7f6e\u663e\u8457\u63d0\u5347\u884c\u4e3a\u771f\u5b9e\u6027\u3002", "conclusion": "PHASE\u4e3a\u7f51\u7edc\u5b89\u5168\u6a21\u62df\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u88ab\u52a8\u7684\u884c\u4e3a\u771f\u5b9e\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5408\u6210\u7528\u6237\u884c\u4e3a\u7684\u903c\u771f\u5ea6\u3002"}}
{"id": "2507.13414", "pdf": "https://arxiv.org/pdf/2507.13414", "abs": "https://arxiv.org/abs/2507.13414", "authors": ["Alexander Strunk", "Roland Assam"], "title": "Gauge Flow Models", "categories": ["cs.LG", "cs.AI", "math.DG"], "comment": null, "summary": "This paper introduces Gauge Flow Models, a novel class of Generative Flow\nModels. These models incorporate a learnable Gauge Field within the Flow\nOrdinary Differential Equation (ODE). A comprehensive mathematical framework\nfor these models, detailing their construction and properties, is provided.\nExperiments using Flow Matching on Gaussian Mixture Models demonstrate that\nGauge Flow Models yields significantly better performance than traditional Flow\nModels of comparable or even larger size. Additionally, unpublished research\nindicates a potential for enhanced performance across a broader range of\ngenerative tasks.", "AI": {"tldr": "Gauge Flow Models\u662f\u4e00\u79cd\u65b0\u578b\u751f\u6210\u6d41\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5165\u53ef\u5b66\u4e60\u7684Gauge Field\u5728\u6d41ODE\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6d41\u6a21\u578b\u5728\u67d0\u4e9b\u4efb\u52a1\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u751f\u6210\u6a21\u578b\u3002", "method": "\u5728\u6d41ODE\u4e2d\u5f15\u5165\u53ef\u5b66\u4e60\u7684Gauge Field\uff0c\u6784\u5efa\u6570\u5b66\u6846\u67b6\u5e76\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5728Gaussian Mixture Models\u4e0a\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u6d41\u6a21\u578b\uff0c\u4e14\u53ef\u80fd\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u751f\u6210\u4efb\u52a1\u3002", "conclusion": "Gauge Flow Models\u5177\u6709\u6f5c\u529b\u6210\u4e3a\u66f4\u9ad8\u6548\u7684\u751f\u6210\u6a21\u578b\u3002"}}
{"id": "2507.13994", "pdf": "https://arxiv.org/pdf/2507.13994", "abs": "https://arxiv.org/abs/2507.13994", "authors": ["Benjamin Aram Berendsohn"], "title": "Optimal antimatroid sorting", "categories": ["cs.DS"], "comment": "Accepted to ESA 2025", "summary": "The classical comparison-based sorting problem asks us to find the underlying\ntotal order of a given set of elements, where we can only access the elements\nvia comparisons. In this paper, we study a restricted version, where, as a\nhint, a set $T$ of possible total orders is given, usually in some compressed\nform.\n  Recently, an algorithm called topological heapsort with optimal running time\nwas found for the case where $T$ is the set of topological orderings of a given\ndirected acyclic graph, or, equivalently, $T$ is the set of linear extensions\nof a given partial order [Haeupler et al. 2024]. We show that a simple\ngeneralization of topological heapsort is applicable to a much broader class of\nrestricted sorting problems, where $T$ corresponds to a given antimatroid.\n  As a consequence, we obtain optimal algorithms for the following restricted\nsorting problems, where the allowed total orders are restricted by: a given set\nof monotone precedence formulas; the perfect elimination orders of a given\nchordal graph; or the possible vertex search orders of a given connected rooted\ngraph.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u53d7\u9650\u6392\u5e8f\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7c7b\u522b\u7684\u62d3\u6251\u5806\u6392\u5e8f\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u591a\u79cd\u53d7\u9650\u6392\u5e8f\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u53d7\u9650\u6392\u5e8f\u95ee\u9898\uff0c\u63a2\u7d22\u5728\u7ed9\u5b9a\u63d0\u793a\u96c6T\u7684\u60c5\u51b5\u4e0b\u5982\u4f55\u9ad8\u6548\u627e\u5230\u603b\u987a\u5e8f\u3002", "method": "\u63a8\u5e7f\u62d3\u6251\u5806\u6392\u5e8f\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u7531\u53cd\u62df\u9635\u5b9a\u4e49\u7684\u53d7\u9650\u6392\u5e8f\u95ee\u9898\u3002", "result": "\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u591a\u79cd\u53d7\u9650\u6392\u5e8f\u95ee\u9898\u7684\u6700\u4f18\u7b97\u6cd5\uff0c\u5305\u62ec\u5355\u8c03\u4f18\u5148\u516c\u5f0f\u3001\u5f26\u56fe\u7684\u5b8c\u7f8e\u6d88\u9664\u987a\u5e8f\u548c\u8fde\u901a\u6709\u6839\u56fe\u7684\u9876\u70b9\u641c\u7d22\u987a\u5e8f\u3002", "conclusion": "\u63a8\u5e7f\u7684\u62d3\u6251\u5806\u6392\u5e8f\u7b97\u6cd5\u5728\u591a\u79cd\u53d7\u9650\u6392\u5e8f\u95ee\u9898\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u6269\u5c55\u4e86\u5176\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2507.13624", "pdf": "https://arxiv.org/pdf/2507.13624", "abs": "https://arxiv.org/abs/2507.13624", "authors": ["Daniel Commey", "Kamel Abbad", "Garth V. Crosby", "Lyes Khoukhi"], "title": "FedSkipTwin: Digital-Twin-Guided Client Skipping for Communication-Efficient Federated Learning", "categories": ["cs.LG", "cs.DC", "cs.NI"], "comment": null, "summary": "Communication overhead remains a primary bottleneck in federated learning\n(FL), particularly for applications involving mobile and IoT devices with\nconstrained bandwidth. This work introduces FedSkipTwin, a novel\nclient-skipping algorithm driven by lightweight, server-side digital twins.\nEach twin, implemented as a simple LSTM, observes a client's historical\nsequence of gradient norms to forecast both the magnitude and the epistemic\nuncertainty of its next update. The server leverages these predictions,\nrequesting communication only when either value exceeds a predefined threshold;\notherwise, it instructs the client to skip the round, thereby saving bandwidth.\nExperiments are conducted on the UCI-HAR and MNIST datasets with 10 clients\nunder a non-IID data distribution. The results demonstrate that FedSkipTwin\nreduces total communication by 12-15.5% across 20 rounds while simultaneously\nimproving final model accuracy by up to 0.5 percentage points compared to the\nstandard FedAvg algorithm. These findings establish that prediction-guided\nskipping is a practical and effective strategy for resource-aware FL in\nbandwidth-constrained edge environments.", "AI": {"tldr": "FedSkipTwin\u901a\u8fc7\u670d\u52a1\u5668\u7aef\u6570\u5b57\u5b6a\u751f\u9884\u6d4b\u5ba2\u6237\u7aef\u68af\u5ea6\u66f4\u65b0\uff0c\u52a8\u6001\u8df3\u8fc7\u901a\u4fe1\u8f6e\u6b21\uff0c\u51cf\u5c11\u5e26\u5bbd\u6d88\u8017\uff0c\u540c\u65f6\u63d0\u5347\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u901a\u4fe1\u5f00\u9500\u662f\u4e3b\u8981\u74f6\u9888\uff0c\u5c24\u5176\u662f\u79fb\u52a8\u548c\u7269\u8054\u7f51\u8bbe\u5907\u5e26\u5bbd\u53d7\u9650\u7684\u573a\u666f\u3002", "method": "\u4f7f\u7528LSTM\u5b9e\u73b0\u7684\u6570\u5b57\u5b6a\u751f\u9884\u6d4b\u5ba2\u6237\u7aef\u68af\u5ea6\u66f4\u65b0\u7684\u5e45\u5ea6\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u52a8\u6001\u51b3\u5b9a\u662f\u5426\u8df3\u8fc7\u901a\u4fe1\u8f6e\u6b21\u3002", "result": "\u5728\u975eIID\u6570\u636e\u5206\u5e03\u4e0b\uff0cFedSkipTwin\u51cf\u5c1112-15.5%\u901a\u4fe1\u91cf\uff0c\u6a21\u578b\u7cbe\u5ea6\u63d0\u53470.5\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u9884\u6d4b\u5f15\u5bfc\u7684\u8df3\u8fc7\u7b56\u7565\u5728\u5e26\u5bbd\u53d7\u9650\u7684\u8fb9\u7f18\u73af\u5883\u4e2d\u662f\u5b9e\u7528\u4e14\u6709\u6548\u7684\u3002"}}
{"id": "2507.13416", "pdf": "https://arxiv.org/pdf/2507.13416", "abs": "https://arxiv.org/abs/2507.13416", "authors": ["Jiaxiang Yi", "Bernardo P. Ferreira", "Miguel A. Bessa"], "title": "Single- to multi-fidelity history-dependent learning with uncertainty quantification and disentanglement: application to data-driven constitutive modeling", "categories": ["cs.LG", "cs.AI"], "comment": "40 pages, 32 figures", "summary": "Data-driven learning is generalized to consider history-dependent\nmulti-fidelity data, while quantifying epistemic uncertainty and disentangling\nit from data noise (aleatoric uncertainty). This generalization is hierarchical\nand adapts to different learning scenarios: from training the simplest\nsingle-fidelity deterministic neural networks up to the proposed multi-fidelity\nvariance estimation Bayesian recurrent neural networks. The versatility and\ngenerality of the proposed methodology are demonstrated by applying it to\ndifferent data-driven constitutive modeling scenarios that include multiple\nfidelities with and without aleatoric uncertainty (noise). The method\naccurately predicts the response and quantifies model error while also\ndiscovering the noise distribution (when present). This opens opportunities for\nfuture real-world applications in diverse scientific and engineering domains;\nespecially, the most challenging cases involving design and analysis under\nuncertainty.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c42\u6b21\u5316\u7684\u591a\u4fdd\u771f\u5ea6\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u591f\u91cf\u5316\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u5e76\u533a\u5206\u6570\u636e\u566a\u58f0\uff08\u968f\u673a\u4e0d\u786e\u5b9a\u6027\uff09\uff0c\u9002\u7528\u4e8e\u4ece\u5355\u4fdd\u771f\u5ea6\u786e\u5b9a\u6027\u795e\u7ecf\u7f51\u7edc\u5230\u591a\u4fdd\u771f\u5ea6\u8d1d\u53f6\u65af\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u591a\u79cd\u5b66\u4e60\u573a\u666f\u3002", "motivation": "\u89e3\u51b3\u591a\u4fdd\u771f\u5ea6\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u4e2d\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u6570\u636e\u566a\u58f0\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u5728\u79d1\u5b66\u548c\u5de5\u7a0b\u9886\u57df\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c42\u6b21\u5316\u7684\u591a\u4fdd\u771f\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0c\u91cf\u5316\u6a21\u578b\u8bef\u5dee\u5e76\u53d1\u73b0\u566a\u58f0\u5206\u5e03\u3002", "result": "\u65b9\u6cd5\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u54cd\u5e94\u3001\u91cf\u5316\u6a21\u578b\u8bef\u5dee\uff0c\u5e76\u5728\u5b58\u5728\u566a\u58f0\u65f6\u53d1\u73b0\u566a\u58f0\u5206\u5e03\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6d89\u53ca\u4e0d\u786e\u5b9a\u6027\u7684\u8bbe\u8ba1\u548c\u5206\u6790\u63d0\u4f9b\u4e86\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.14060", "pdf": "https://arxiv.org/pdf/2507.14060", "abs": "https://arxiv.org/abs/2507.14060", "authors": ["Sanjeev Khanna", "Ashwin Padaki", "Erik Waingarten"], "title": "Sparse Navigable Graphs for Nearest Neighbor Search: Algorithms and Hardness", "categories": ["cs.DS"], "comment": null, "summary": "We initiate the study of approximation algorithms and computational barriers\nfor constructing sparse $\\alpha$-navigable graphs [IX23, DGM+24], a core\nprimitive underlying recent advances in graph-based nearest neighbor search.\nGiven an $n$-point dataset $P$ with an associated metric $\\mathsf{d}$ and a\nparameter $\\alpha \\geq 1$, the goal is to efficiently build the sparsest graph\n$G=(P, E)$ that is $\\alpha$-navigable: for every distinct $s, t \\in P$, there\nexists an edge $(s, u) \\in E$ with $\\mathsf{d}(u, t) < \\mathsf{d}(s,\nt)/\\alpha$. We consider two natural sparsity objectives: minimizing the maximum\nout-degree and minimizing the total size.\n  We first show a strong negative result: the slow-preprocessing version of\nDiskANN (analyzed in [IX23] for low-doubling metrics) can yield solutions whose\nsparsity is $\\widetilde{\\Omega}(n)$ times larger than optimal, even on\nEuclidean instances. We then show a tight approximation-preserving equivalence\nbetween the Sparsest Navigable Graph problem and the classic Set Cover problem,\nobtaining an $O(n^3)$-time $(\\ln n + 1)$-approximation algorithm, as well as\nestablishing NP-hardness of achieving an $o(\\ln n)$-approximation. Building on\nthis equivalence, we develop faster $O(\\ln n)$-approximation algorithms. The\nfirst runs in $\\widetilde{O}(n \\cdot \\mathrm{OPT})$ time and is thus much\nfaster when the optimal solution is sparse. The second, based on fast matrix\nmultiplication, is a bicriteria algorithm that computes an $O(\\ln\nn)$-approximation to the sparsest $2\\alpha$-navigable graph, running in\n$\\widetilde{O}(n^{\\omega})$ time.\n  Finally, we complement our upper bounds with a query complexity lower bound,\nshowing that any $o(n)$-approximation requires examining $\\Omega(n^2)$\ndistances. This result shows that in the regime where $\\mathrm{OPT} =\n\\widetilde{O}(n)$, our $\\widetilde{O}(n \\cdot \\mathrm{OPT})$-time algorithm is\nessentially best possible.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u7a00\u758f\u03b1-\u5bfc\u822a\u56fe\u7684\u8fd1\u4f3c\u7b97\u6cd5\u548c\u8ba1\u7b97\u969c\u788d\uff0c\u63d0\u51fa\u4e86\u4e0e\u7ecf\u5178\u96c6\u5408\u8986\u76d6\u95ee\u9898\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u5feb\u901f\u8fd1\u4f3c\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76\u7a00\u758f\u03b1-\u5bfc\u822a\u56fe\u7684\u6784\u5efa\u95ee\u9898\uff0c\u4ee5\u652f\u6301\u57fa\u4e8e\u56fe\u7684\u6700\u8fd1\u90bb\u641c\u7d22\u7684\u8fdb\u5c55\u3002", "method": "\u901a\u8fc7\u7b49\u4ef7\u6027\u5206\u6790\uff0c\u63d0\u51fa\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8e\u5feb\u901f\u77e9\u9635\u4e58\u6cd5\u7684\u53cc\u6807\u51c6\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u6700\u4f18\u89e3\u7684\u7a00\u758f\u6027\u4e0b\u9650\uff0c\u5e76\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002", "conclusion": "\u5728\u7a00\u758f\u6027\u4f18\u5316\u65b9\u9762\u53d6\u5f97\u4e86\u7406\u8bba\u4e0a\u7684\u7a81\u7834\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u7b97\u6cd5\u652f\u6301\u3002"}}
{"id": "2507.13720", "pdf": "https://arxiv.org/pdf/2507.13720", "abs": "https://arxiv.org/abs/2507.13720", "authors": ["Saurav Ghosh"], "title": "Quantum Blockchain Survey: Foundations, Trends, and Gaps", "categories": ["cs.CR", "cs.DC", "cs.ET", "cs.NI", "68M10, 81P94, 94A60 68M10, 81P94, 94A60 68M10, 81P94, 94A60", "C.2.1; E.3; K.6.5"], "comment": "12 Pages, 4 figures", "summary": "Quantum computing poses fundamental risks to classical blockchain systems by\nundermining widely used cryptographic primitives. In response, two major\nresearch directions have emerged: post-quantum blockchains, which integrate\nquantum-resistant algorithms, and quantum blockchains, which leverage quantum\nproperties such as entanglement and quantum key distribution. This survey\nreviews key developments in both areas, analyzing their cryptographic\nfoundations, architectural designs, and implementation challenges. This work\nprovides a comparative overview of technical proposals, highlight trade-offs in\nsecurity, scalability, and deployment, and identify open research problems\nacross hardware, consensus, and network design. The goal is to offer a\nstructured and comprehensive reference for advancing secure blockchain systems\nin the quantum era.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u91cf\u5b50\u8ba1\u7b97\u5bf9\u533a\u5757\u94fe\u7684\u5a01\u80c1\u53ca\u5e94\u5bf9\u65b9\u5411\uff0c\u5305\u62ec\u540e\u91cf\u5b50\u533a\u5757\u94fe\u548c\u91cf\u5b50\u533a\u5757\u94fe\uff0c\u6bd4\u8f83\u4e86\u5176\u6280\u672f\u65b9\u6848\u3001\u5b89\u5168\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\u4f20\u7edf\u533a\u5757\u94fe\u7684\u52a0\u5bc6\u57fa\u7840\uff0c\u9700\u8981\u7814\u7a76\u91cf\u5b50\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7efc\u8ff0\u540e\u91cf\u5b50\u533a\u5757\u94fe\uff08\u91cf\u5b50\u6297\u6027\u7b97\u6cd5\uff09\u548c\u91cf\u5b50\u533a\u5757\u94fe\uff08\u91cf\u5b50\u7279\u6027\uff09\u7684\u6280\u672f\u53d1\u5c55\u3001\u67b6\u6784\u8bbe\u8ba1\u548c\u5b9e\u73b0\u6311\u6218\u3002", "result": "\u63d0\u4f9b\u4e86\u6280\u672f\u65b9\u6848\u7684\u6bd4\u8f83\uff0c\u5206\u6790\u4e86\u5b89\u5168\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u90e8\u7f72\u7684\u6743\u8861\uff0c\u5e76\u6307\u51fa\u4e86\u786c\u4ef6\u3001\u5171\u8bc6\u548c\u7f51\u7edc\u8bbe\u8ba1\u4e2d\u7684\u5f00\u653e\u95ee\u9898\u3002", "conclusion": "\u4e3a\u91cf\u5b50\u65f6\u4ee3\u63a8\u8fdb\u5b89\u5168\u533a\u5757\u94fe\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u3001\u5168\u9762\u7684\u53c2\u8003\u3002"}}
{"id": "2507.13417", "pdf": "https://arxiv.org/pdf/2507.13417", "abs": "https://arxiv.org/abs/2507.13417", "authors": ["Armel Soubeiga", "Thomas Guyet", "Violaine Antoine"], "title": "Soft-ECM: An extension of Evidential C-Means for complex data", "categories": ["cs.LG", "cs.AI", "cs.DM"], "comment": null, "summary": "Clustering based on belief functions has been gaining increasing attention in\nthe machine learning community due to its ability to effectively represent\nuncertainty and/or imprecision. However, none of the existing algorithms can be\napplied to complex data, such as mixed data (numerical and categorical) or\nnon-tabular data like time series. Indeed, these types of data are, in general,\nnot represented in a Euclidean space and the aforementioned algorithms make use\nof the properties of such spaces, in particular for the construction of\nbarycenters. In this paper, we reformulate the Evidential C-Means (ECM) problem\nfor clustering complex data. We propose a new algorithm, Soft-ECM, which\nconsistently positions the centroids of imprecise clusters requiring only a\nsemi-metric. Our experiments show that Soft-ECM present results comparable to\nconventional fuzzy clustering approaches on numerical data, and we demonstrate\nits ability to handle mixed data and its benefits when combining fuzzy\nclustering with semi-metrics such as DTW for time series data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u805a\u7c7b\u7b97\u6cd5Soft-ECM\uff0c\u7528\u4e8e\u5904\u7406\u590d\u6742\u6570\u636e\uff08\u5982\u6df7\u5408\u6570\u636e\u548c\u65f6\u95f4\u5e8f\u5217\uff09\uff0c\u901a\u8fc7\u534a\u5ea6\u91cf\u65b9\u6cd5\u89e3\u51b3\u4e86\u4f20\u7edf\u7b97\u6cd5\u5728\u975e\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7f6e\u4fe1\u51fd\u6570\u7684\u805a\u7c7b\u7b97\u6cd5\u65e0\u6cd5\u5904\u7406\u590d\u6742\u6570\u636e\uff08\u5982\u6df7\u5408\u6570\u636e\u6216\u65f6\u95f4\u5e8f\u5217\uff09\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u6570\u636e\u901a\u5e38\u4e0d\u5728\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u8868\u793a\u3002", "method": "\u63d0\u51faSoft-ECM\u7b97\u6cd5\uff0c\u4ec5\u9700\u534a\u5ea6\u91cf\u5373\u53ef\u5b9a\u4f4d\u4e0d\u7cbe\u786e\u7c07\u7684\u8d28\u5fc3\uff0c\u9002\u7528\u4e8e\u975e\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSoft-ECM\u5728\u6570\u503c\u6570\u636e\u4e0a\u4e0e\u6a21\u7cca\u805a\u7c7b\u65b9\u6cd5\u6548\u679c\u76f8\u5f53\uff0c\u5e76\u80fd\u6709\u6548\u5904\u7406\u6df7\u5408\u6570\u636e\u548c\u65f6\u95f4\u5e8f\u5217\u3002", "conclusion": "Soft-ECM\u6269\u5c55\u4e86\u57fa\u4e8e\u7f6e\u4fe1\u51fd\u6570\u7684\u805a\u7c7b\u7b97\u6cd5\u7684\u9002\u7528\u8303\u56f4\uff0c\u4e3a\u590d\u6742\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14089", "pdf": "https://arxiv.org/pdf/2507.14089", "abs": "https://arxiv.org/abs/2507.14089", "authors": ["Vincent Cohen-Addad", "Fabian Kuhn", "Zahra Parsaeian"], "title": "An Efficient Massively Parallel Constant-Factor Approximation Algorithm for the $k$-Means Problem", "categories": ["cs.DS"], "comment": null, "summary": "In this paper, we present an efficient massively parallel approximation\nalgorithm for the $k$-means problem. Specifically, we provide an MPC algorithm\nthat computes a constant-factor approximation to an arbitrary $k$-means\ninstance in $O(\\log\\log n \\cdot \\log\\log\\log n)$ rounds. The algorithm uses\n$O(n^\\sigma)$ bits of memory per machine, where $\\sigma > 0$ is a constant that\ncan be made arbitrarily small. The global memory usage is\n$O(n^{1+\\varepsilon})$ bits for an arbitrarily small constant $\\varepsilon >\n0$, and is thus only slightly superlinear. Recently, Czumaj, Gao, Jiang,\nKrauthgamer, and Vesel\\'{y} showed that a constant-factor bicriteria\napproximation can be computed in $O(1)$ rounds in the MPC model. However, our\nalgorithm is the first constant-factor approximation for the general $k$-means\nproblem that runs in $o(\\log n)$ rounds in the MPC model.\n  Our approach builds upon the foundational framework of Jain and Vazirani. The\ncore component of our algorithm is a constant-factor approximation for the\nrelated facility location problem. While such an approximation was already\nachieved in constant time in the work of Czumaj et al.\\ mentioned above, our\nversion additionally satisfies the so-called Lagrangian Multiplier Preserving\n(LMP) property. This property enables the transformation of a facility location\napproximation into a comparably good $k$-means approximation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5e76\u884c\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3$k$-means\u95ee\u9898\uff0c\u5728MPC\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e86$o(\\log n)$\u8f6e\u6b21\u7684\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u3002", "motivation": "\u89e3\u51b3$k$-means\u95ee\u9898\u7684\u9ad8\u6548\u5e76\u884c\u8ba1\u7b97\u9700\u6c42\uff0c\u5c24\u5176\u662f\u5728MPC\u6a21\u578b\u4e2d\u7684\u5feb\u901f\u8fd1\u4f3c\u7b97\u6cd5\u3002", "method": "\u57fa\u4e8eJain\u548cVazirani\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8bbe\u65bd\u4f4d\u7f6e\u95ee\u9898\u7684\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\uff08\u6ee1\u8db3LMP\u6027\u8d28\uff09\u8f6c\u5316\u4e3a$k$-means\u8fd1\u4f3c\u3002", "result": "\u7b97\u6cd5\u5728$O(\\log\\log n \\cdot \\log\\log\\log n)$\u8f6e\u6b21\u5185\u5b8c\u6210\uff0c\u6bcf\u53f0\u673a\u5668\u4f7f\u7528$O(n^\\sigma)$\u5185\u5b58\uff0c\u5168\u5c40\u5185\u5b58\u7565\u8d85\u7ebf\u6027\u3002", "conclusion": "\u9996\u6b21\u5728MPC\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e86$k$-means\u95ee\u9898\u7684\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\uff0c\u4e14\u8f6e\u6b21\u5c11\u4e8e$O(\\log n)$\u3002"}}
{"id": "2507.13999", "pdf": "https://arxiv.org/pdf/2507.13999", "abs": "https://arxiv.org/abs/2507.13999", "authors": ["Sanidhay Bhambay", "Siddarth Koduru Joshi", "Thirupathaiah Vasantam", "Neil Walton"], "title": "The Proportional Fair Scheduler in Wavelength-Multiplexed Quantum Networks", "categories": ["quant-ph", "cs.NI", "cs.PF"], "comment": null, "summary": "We address the problem of optimal pumping strategies in quantum networks.\nThese networks enable secure communication by distributing entangled photon\npairs to user (or node) pairs. Quantum Key Distribution (QKD) protocols, like\nBBM92, generate secret keys from entangled photons. While secure communication\nand error correction are essential for any quantum communication channel,\nresource contention, optimization, and fairness issues are critical for\nnetworks. In this article, we analyze the performance of quantum networks,\nproposing simple distributed algorithms for QKD networks generating secret\nkeys.\n  There are significant advantages of pumping entangled photons in QKD\nnetworks, but challenges arise in practical implementations. The underlying\nchannels are inherently time-varying, and thus data rates fluctuate between\nnodes. Moreover, multiple edges (node pairs) can be pumped simultaneously,\nalbeit at the cost of a reduced secret key rate (SKR). These temporal and\nspatial constraints yield a complex decision-making problem whose solutions may\nfavor a small set of user pairs to the detriment of overall, long-run network\nperformance.\n  We design adaptive pumping strategies that address these challenges in QKD\nnetworks. In particular, we find that a proportional fairness pumping strategy\n(PF-PS) stands out by dynamically prioritizing users with lower average secret\nkey rates and optimally balancing fairness with throughput. The proposed\nalgorithm is a natural extension to quantum networks of the Proportional Fair\nScheduler deployed in 4G LTE and 5G mobile networks. Both theoretical analysis\nand numerical simulations confirm that PF-PS is optimal for entangled state\ndistribution, and thus, when adapted appropriately, proportional fair pumping\nis a strong candidate for efficient resource allocation in quantum networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6bd4\u4f8b\u516c\u5e73\u6cf5\u6d66\u7b56\u7565\uff08PF-PS\uff09\uff0c\u7528\u4e8e\u4f18\u5316\u91cf\u5b50\u7f51\u7edc\u4e2d\u7684\u8d44\u6e90\u5206\u914d\uff0c\u5e73\u8861\u516c\u5e73\u6027\u548c\u541e\u5410\u91cf\u3002", "motivation": "\u91cf\u5b50\u7f51\u7edc\u4e2d\u7684\u8d44\u6e90\u7ade\u4e89\u3001\u4f18\u5316\u548c\u516c\u5e73\u6027\u95ee\u9898\u5bf9\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u7f51\u7edc\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u89e3\u51b3\u65f6\u95f4\u53d8\u5316\u4fe1\u9053\u548c\u591a\u7528\u6237\u540c\u65f6\u6cf5\u6d66\u7684\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u4e86\u81ea\u9002\u5e94\u6cf5\u6d66\u7b56\u7565\uff0c\u7279\u522b\u662f\u6bd4\u4f8b\u516c\u5e73\u6cf5\u6d66\u7b56\u7565\uff08PF-PS\uff09\uff0c\u52a8\u6001\u4f18\u5148\u5904\u7406\u5e73\u5747\u5bc6\u94a5\u7387\u8f83\u4f4e\u7684\u7528\u6237\uff0c\u5e76\u4f18\u5316\u516c\u5e73\u6027\u4e0e\u541e\u5410\u91cf\u7684\u5e73\u8861\u3002", "result": "\u7406\u8bba\u548c\u6570\u503c\u6a21\u62df\u8868\u660e\uff0cPF-PS\u5728\u7ea0\u7f20\u6001\u5206\u53d1\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u662f\u91cf\u5b50\u7f51\u7edc\u4e2d\u9ad8\u6548\u8d44\u6e90\u5206\u914d\u7684\u5f3a\u6709\u529b\u5019\u9009\u65b9\u6848\u3002", "conclusion": "\u6bd4\u4f8b\u516c\u5e73\u6cf5\u6d66\u7b56\u7565\uff08PF-PS\uff09\u662f\u91cf\u5b50\u7f51\u7edc\u4e2d\u8d44\u6e90\u5206\u914d\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u517c\u987e\u516c\u5e73\u6027\u548c\u7f51\u7edc\u6027\u80fd\u3002"}}
{"id": "2507.13736", "pdf": "https://arxiv.org/pdf/2507.13736", "abs": "https://arxiv.org/abs/2507.13736", "authors": ["Matthias Jobst", "Tim Langer", "Chen Liu", "Mehmet Alici", "Hector A. Gonzalez", "Christian Mayr"], "title": "An End-to-End DNN Inference Framework for the SpiNNaker2 Neuromorphic MPSoC", "categories": ["cs.LG", "cs.AR", "cs.DC"], "comment": "Poster at ACM ICONS 2025 - International Conference on Neuromorphic\n  Systems", "summary": "This work presents a multi-layer DNN scheduling framework as an extension of\nOctopuScheduler, providing an end-to-end flow from PyTorch models to inference\non a single SpiNNaker2 chip. Together with a front-end comprised of\nquantization and lowering steps, the proposed framework enables the edge-based\nexecution of large and complex DNNs up to transformer scale using the\nneuromorphic platform SpiNNaker2.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5c42DNN\u8c03\u5ea6\u6846\u67b6\uff0c\u6269\u5c55\u4e86OctopuScheduler\uff0c\u652f\u6301\u4ecePyTorch\u6a21\u578b\u5230SpiNNaker2\u82af\u7247\u7684\u7aef\u5230\u7aef\u63a8\u7406\u6d41\u7a0b\u3002", "motivation": "\u4e3a\u5728\u795e\u7ecf\u5f62\u6001\u5e73\u53f0SpiNNaker2\u4e0a\u5b9e\u73b0\u5927\u578b\u590d\u6742DNN\uff08\u5982Transformer\uff09\u7684\u8fb9\u7f18\u6267\u884c\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u91cf\u5316\u548c\u964d\u9636\u6b65\u9aa4\u7684\u524d\u7aef\uff0c\u6269\u5c55OctopuScheduler\u4e3a\u591a\u5c42DNN\u8c03\u5ea6\u6846\u67b6\u3002", "result": "\u5b9e\u73b0\u4e86\u5728SpiNNaker2\u82af\u7247\u4e0a\u9ad8\u6548\u8fd0\u884c\u590d\u6742DNN\u7684\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u4e0a\u7684DNN\u63a8\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.13423", "pdf": "https://arxiv.org/pdf/2507.13423", "abs": "https://arxiv.org/abs/2507.13423", "authors": ["Edward Henderson", "Dewi Gould", "Richard Everson", "George De Ath", "Nick Pepper"], "title": "Air Traffic Controller Task Demand via Graph Neural Networks: An Interpretable Approach to Airspace Complexity", "categories": ["cs.LG", "cs.AI"], "comment": "Author Accepted Manuscript version of paper at the AIAA AVIATION\n  Forum 2025", "summary": "Real-time assessment of near-term Air Traffic Controller (ATCO) task demand\nis a critical challenge in an increasingly crowded airspace, as existing\ncomplexity metrics often fail to capture nuanced operational drivers beyond\nsimple aircraft counts. This work introduces an interpretable Graph Neural\nNetwork (GNN) framework to address this gap. Our attention-based model predicts\nthe number of upcoming clearances, the instructions issued to aircraft by\nATCOs, from interactions within static traffic scenarios. Crucially, we derive\nan interpretable, per-aircraft task demand score by systematically ablating\naircraft and measuring the impact on the model's predictions. Our framework\nsignificantly outperforms an ATCO-inspired heuristic and is a more reliable\nestimator of scenario complexity than established baselines. The resulting tool\ncan attribute task demand to specific aircraft, offering a new way to analyse\nand understand the drivers of complexity for applications in controller\ntraining and airspace redesign.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u7684\u53ef\u89e3\u91ca\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u65f6\u8bc4\u4f30\u7a7a\u4e2d\u4ea4\u901a\u7ba1\u5236\u5458\uff08ATCO\uff09\u7684\u4efb\u52a1\u9700\u6c42\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u590d\u6742\u6027\u6307\u6807\u65e0\u6cd5\u6355\u6349\u64cd\u4f5c\u4e2d\u7684\u7ec6\u5fae\u9a71\u52a8\u56e0\u7d20\uff0c\u9700\u8981\u66f4\u7cbe\u51c6\u7684\u4efb\u52a1\u9700\u6c42\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6ce8\u610f\u529b\u673a\u5236\u7684GNN\u6a21\u578b\uff0c\u901a\u8fc7\u9759\u6001\u4ea4\u901a\u573a\u666f\u4e2d\u7684\u4ea4\u4e92\u9884\u6d4bATCO\u5373\u5c06\u53d1\u5e03\u7684\u6307\u4ee4\u6570\u91cf\uff0c\u5e76\u901a\u8fc7\u7cfb\u7edf\u6d88\u878d\u98de\u673a\u6765\u83b7\u5f97\u4efb\u52a1\u9700\u6c42\u8bc4\u5206\u3002", "result": "\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u662f\u66f4\u53ef\u9760\u7684\u590d\u6742\u6027\u8bc4\u4f30\u5de5\u5177\uff0c\u5e76\u80fd\u5c06\u4efb\u52a1\u9700\u6c42\u5f52\u56e0\u4e8e\u7279\u5b9a\u98de\u673a\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aATCO\u57f9\u8bad\u548c\u7a7a\u57df\u91cd\u65b0\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u590d\u6742\u6027\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2507.14114", "pdf": "https://arxiv.org/pdf/2507.14114", "abs": "https://arxiv.org/abs/2507.14114", "authors": ["Ahammed Ullah", "S. M. Ferdous", "Alex Pothen"], "title": "Weighted Matching in a Poly-Streaming Model", "categories": ["cs.DS", "cs.DC"], "comment": "40 pages, ESA 2025", "summary": "We introduce the poly-streaming model, a generalization of streaming models\nof computation in which $k$ processors process $k$ data streams containing a\ntotal of $N$ items. The algorithm is allowed $O\\left(f(k)\\cdot M_1\\right)$\nspace, where $M_1$ is either $o\\left(N\\right)$ or the space bound for a\nsequential streaming algorithm. Processors may communicate as needed.\nAlgorithms are assessed by the number of passes, per-item processing time,\ntotal runtime, space usage, communication cost, and solution quality.\n  We design a single-pass algorithm in this model for approximating the maximum\nweight matching (MWM) problem. Given $k$ edge streams and a parameter\n$\\varepsilon > 0$, the algorithm computes a\n$\\left(2+\\epsilon\\right)$-approximate MWM. We analyze its performance in a\nshared-memory parallel setting: for any constant $\\varepsilon > 0$, it runs in\ntime $\\widetilde{O}\\left(L_{\\max}+n\\right)$, where $n$ is the number of\nvertices and $L_{\\max}$ is the maximum stream length. It supports\n$O\\left(1\\right)$ per-edge processing time using $\\widetilde{O}\\left(k\\cdot\nn\\right)$ space. We further generalize the design to hierarchical\narchitectures, in which $k$ processors are partitioned into $r$ groups, each\nwith its own shared local memory. The total intergroup communication is\n$\\widetilde{O}\\left(r \\cdot n\\right)$ bits, while all other performance\nguarantees are preserved.\n  We evaluate the algorithm on a shared-memory system using graphs with\ntrillions of edges. It achieves substantial speedups as $k$ increases and\nproduces matchings with weights significantly exceeding the theoretical\nguarantee. On our largest test graph, it reduces runtime by nearly two orders\nof magnitude and memory usage by five orders of magnitude compared to an\noffline algorithm.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6d41\u5e76\u884c\u8ba1\u7b97\u6a21\u578b\uff08poly-streaming\uff09\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5355\u904d\u7b97\u6cd5\u6765\u8fd1\u4f3c\u89e3\u51b3\u6700\u5927\u6743\u91cd\u5339\u914d\u95ee\u9898\uff08MWM\uff09\uff0c\u5728\u5171\u4eab\u5185\u5b58\u5e76\u884c\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4f20\u7edf\u7684\u6d41\u5f0f\u8ba1\u7b97\u6a21\u578b\u5728\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u65f6\u6548\u7387\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u5e76\u884c\u8ba1\u7b97\u6a21\u578b\u6765\u63d0\u5347\u5904\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u591a\u6d41\u5e76\u884c\u6a21\u578b\uff08poly-streaming\uff09\uff0c\u8bbe\u8ba1\u5355\u904d\u7b97\u6cd5\u8fd1\u4f3cMWM\uff0c\u652f\u6301\u5171\u4eab\u5185\u5b58\u5e76\u884c\u548c\u5206\u5c42\u67b6\u6784\u3002", "result": "\u7b97\u6cd5\u5728\u5171\u4eab\u5185\u5b58\u7cfb\u7edf\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5904\u7406\u4e07\u4ebf\u7ea7\u8fb9\u56fe\u65f6\u663e\u8457\u63d0\u5347\u901f\u5ea6\u548c\u5185\u5b58\u6548\u7387\uff0c\u5339\u914d\u6743\u91cd\u8fdc\u8d85\u7406\u8bba\u4fdd\u8bc1\u3002", "conclusion": "\u591a\u6d41\u5e76\u884c\u6a21\u578b\u548c\u7b97\u6cd5\u5728\u5927\u89c4\u6a21\u6570\u636e\u5904\u7406\u4e2d\u5177\u6709\u9ad8\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u590d\u6742\u67b6\u6784\u3002"}}
{"id": "2507.13895", "pdf": "https://arxiv.org/pdf/2507.13895", "abs": "https://arxiv.org/abs/2507.13895", "authors": ["Damiano Azzolini", "Marco Duca", "Stefano Forti", "Francesco Gallo", "Antonio Ielo"], "title": "Application Placement with Constraint Relaxation", "categories": ["cs.LO", "cs.DC"], "comment": null, "summary": "Novel utility computing paradigms rely upon the deployment of multi-service\napplications to pervasive and highly distributed cloud-edge infrastructure\nresources. Deciding onto which computational nodes to place services in\ncloud-edge networks, as per their functional and non-functional constraints,\ncan be formulated as a combinatorial optimisation problem. Most existing\nsolutions in this space are not able to deal with \\emph{unsatisfiable} problem\ninstances, nor preferences, i.e. requirements that DevOps may agree to relax to\nobtain a solution. In this article, we exploit Answer Set Programming\noptimisation capabilities to tackle this problem. Experimental results in\nsimulated settings show that our approach is effective on lifelike networks and\napplications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u4e91\u8fb9\u7f51\u7edc\u4e2d\u670d\u52a1\u90e8\u7f72\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u7279\u522b\u662f\u5904\u7406\u4e0d\u53ef\u6ee1\u8db3\u95ee\u9898\u5b9e\u4f8b\u548c\u504f\u597d\u9700\u6c42\u3002", "motivation": "\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u65e0\u6cd5\u5904\u7406\u4e0d\u53ef\u6ee1\u8db3\u95ee\u9898\u5b9e\u4f8b\u548c\u504f\u597d\u9700\u6c42\uff0c\u800c\u4e91\u8fb9\u7f51\u7edc\u4e2d\u7684\u670d\u52a1\u90e8\u7f72\u9700\u8981\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u7684\u4f18\u5316\u80fd\u529b\uff0c\u7ed3\u5408\u529f\u80fd\u548c\u975e\u529f\u80fd\u7ea6\u675f\uff0c\u89e3\u51b3\u670d\u52a1\u90e8\u7f72\u95ee\u9898\u3002", "result": "\u5728\u6a21\u62df\u73af\u5883\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u771f\u5b9e\u7f51\u7edc\u548c\u5e94\u7528\u4e2d\u8868\u73b0\u6709\u6548\u3002", "conclusion": "ASP\u65b9\u6cd5\u4e3a\u89e3\u51b3\u4e91\u8fb9\u7f51\u7edc\u4e2d\u7684\u670d\u52a1\u90e8\u7f72\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.13482", "pdf": "https://arxiv.org/pdf/2507.13482", "abs": "https://arxiv.org/abs/2507.13482", "authors": ["Seyyed Saeid Cheshmi", "Buyao Lyu", "Thomas Lisko", "Rajesh Rajamani", "Robert A. McGovern", "Yogatheesan Varatharajah"], "title": "Improving Out-of-distribution Human Activity Recognition via IMU-Video Cross-modal Representation Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Human Activity Recognition (HAR) based on wearable inertial sensors plays a\ncritical role in remote health monitoring. In patients with movement disorders,\nthe ability to detect abnormal patient movements in their home environments can\nenable continuous optimization of treatments and help alert caretakers as\nneeded. Machine learning approaches have been proposed for HAR tasks using\nInertial Measurement Unit (IMU) data; however, most rely on\napplication-specific labels and lack generalizability to data collected in\ndifferent environments or populations. To address this limitation, we propose a\nnew cross-modal self-supervised pretraining approach to learn representations\nfrom large-sale unlabeled IMU-video data and demonstrate improved\ngeneralizability in HAR tasks on out of distribution (OOD) IMU datasets,\nincluding a dataset collected from patients with Parkinson's disease.\nSpecifically, our results indicate that the proposed cross-modal pretraining\napproach outperforms the current state-of-the-art IMU-video pretraining\napproach and IMU-only pretraining under zero-shot and few-shot evaluations.\nBroadly, our study provides evidence that in highly dynamic data modalities,\nsuch as IMU signals, cross-modal pretraining may be a useful tool to learn\ngeneralizable data representations. Our software is available at\nhttps://github.com/scheshmi/IMU-Video-OOD-HAR.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u6a21\u6001\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u5927\u89c4\u6a21\u672a\u6807\u8bb0\u7684IMU-\u89c6\u9891\u6570\u636e\u4e2d\u5b66\u4e60\u8868\u793a\uff0c\u63d0\u9ad8\u4e86\u5728\u5206\u5e03\u5916IMU\u6570\u636e\u96c6\u4e0a\u7684HAR\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u57fa\u4e8eIMU\u7684HAR\u65b9\u6cd5\u4f9d\u8d56\u7279\u5b9a\u5e94\u7528\u6807\u7b7e\u3001\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8de8\u6a21\u6001\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5229\u7528IMU-\u89c6\u9891\u6570\u636e\u5b66\u4e60\u901a\u7528\u8868\u793a\u3002", "result": "\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u8bc4\u4f30\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684IMU-\u89c6\u9891\u9884\u8bad\u7ec3\u548c\u4ec5IMU\u9884\u8bad\u7ec3\u65b9\u6cd5\u3002", "conclusion": "\u8de8\u6a21\u6001\u9884\u8bad\u7ec3\u662f\u5b66\u4e60\u52a8\u6001\u6570\u636e\u6a21\u6001\uff08\u5982IMU\u4fe1\u53f7\uff09\u901a\u7528\u8868\u793a\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2507.13818", "pdf": "https://arxiv.org/pdf/2507.13818", "abs": "https://arxiv.org/abs/2507.13818", "authors": ["\u00c9douard Bonnet", "Daniel Neuen", "Marek Soko\u0142owski"], "title": "Treedepth Inapproximability and Exponential ETH Lower Bound", "categories": ["cs.CC", "cs.DS"], "comment": "10 pages", "summary": "Treedepth is a central parameter to algorithmic graph theory. The current\nstate-of-the-art in computing and approximating treedepth consists of a\n$2^{O(k^2)} n$-time exact algorithm and a polynomial-time $O(\\text{OPT}\n\\log^{3/2} \\text{OPT})$-approximation algorithm, where the former algorithm\nreturns an elimination forest of height $k$ (witnessing that treedepth is at\nmost $k$) for the $n$-vertex input graph $G$, or correctly reports that $G$ has\ntreedepth larger than $k$, and $\\text{OPT}$ is the actual value of the\ntreedepth. On the complexity side, exactly computing treedepth is NP-complete,\nbut the known reductions do not rule out a polynomial-time approximation scheme\n(PTAS), and under the Exponential Time Hypothesis (ETH) only exclude a running\ntime of $2^{o(\\sqrt n)}$ for exact algorithms.\n  We show that 1.0003-approximating treedepth is NP-hard, and that exactly\ncomputing the treedepth of an $n$-vertex graph requires time $2^{\\Omega(n)}$,\nunless the ETH fails. We further derive that there exist absolute constants\n$\\delta, c > 0$ such that any $(1+\\delta)$-approximation algorithm requires\ntime $2^{\\Omega(n / \\log^c n)}$. We do so via a simple direct reduction from\nSatisfiability to Treedepth, inspired by a reduction recently designed for\nTreewidth [STOC '25].", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6811\u6df1\u5ea6\u7684\u8ba1\u7b97\u548c\u8fd1\u4f3c\u95ee\u9898\uff0c\u8bc1\u660e\u4e861.0003-\u8fd1\u4f3c\u662fNP\u96be\u7684\uff0c\u4e14\u7cbe\u786e\u8ba1\u7b97\u9700\u8981\u6307\u6570\u65f6\u95f4\uff0c\u9664\u975eETH\u4e0d\u6210\u7acb\u3002", "motivation": "\u6811\u6df1\u5ea6\u662f\u7b97\u6cd5\u56fe\u8bba\u4e2d\u7684\u6838\u5fc3\u53c2\u6570\uff0c\u5f53\u524d\u6700\u4f18\u7b97\u6cd5\u548c\u8fd1\u4f3c\u7b97\u6cd5\u7684\u6027\u80fd\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u7814\u7a76\u5176\u8ba1\u7b97\u590d\u6742\u6027\u548c\u8fd1\u4f3c\u96be\u5ea6\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u901a\u8fc7\u4eceSatisfiability\u5230Treedepth\u7684\u76f4\u63a5\u7b80\u5316\uff0c\u7c7b\u4f3c\u4e8eTreewidth\u7684\u7b80\u5316\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u8fd1\u4f3c\u548c\u7cbe\u786e\u8ba1\u7b97\u7684\u590d\u6742\u6027\u3002", "result": "\u8bc1\u660e\u4e861.0003-\u8fd1\u4f3c\u662fNP\u96be\u7684\uff0c\u7cbe\u786e\u8ba1\u7b97\u9700\u89812^\u03a9(n)\u65f6\u95f4\uff0c\u4e14\u5b58\u5728\u5e38\u6570\u03b4,c\u4f7f\u5f97(1+\u03b4)-\u8fd1\u4f3c\u9700\u89812^\u03a9(n/log^c n)\u65f6\u95f4\u3002", "conclusion": "\u6811\u6df1\u5ea6\u7684\u8fd1\u4f3c\u548c\u7cbe\u786e\u8ba1\u7b97\u5177\u6709\u6781\u9ad8\u7684\u590d\u6742\u6027\uff0c\u9664\u975eETH\u4e0d\u6210\u7acb\uff0c\u5426\u5219\u96be\u4ee5\u663e\u8457\u6539\u8fdb\u5f53\u524d\u7b97\u6cd5\u6027\u80fd\u3002"}}
{"id": "2507.14111", "pdf": "https://arxiv.org/pdf/2507.14111", "abs": "https://arxiv.org/abs/2507.14111", "authors": ["Xiaoya Li", "Xiaofei Sun", "Albert Wang", "Jiwei Li", "Chris Shum"], "title": "CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning", "categories": ["cs.AI", "cs.DC", "cs.LG"], "comment": "Preprint Version", "summary": "The exponential growth in demand for GPU computing resources, driven by the\nrapid advancement of Large Language Models, has created an urgent need for\nautomated CUDA optimization strategies. While recent advances in LLMs show\npromise for code generation, current SOTA models (e.g. R1, o1) achieve low\nsuccess rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an\nautomated reinforcement learning framework for CUDA optimization.\n  CUDA-L1 achieves performance improvements on the CUDA optimization task:\ntrained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250\nCUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the\nmodel also demonstrates excellent portability across GPU architectures,\nachieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40,\nx14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100.\nBeyond these benchmark results, CUDA-L1 demonstrates several remarkable\nproperties: 1) Discovers a variety of CUDA optimization techniques and learns\nto combine them strategically to achieve optimal performance; 2) Uncovers\nfundamental principles of CUDA optimization; 3) Identifies non-obvious\nperformance bottlenecks and rejects seemingly beneficial optimizations that\nharm performance.\n  The capabilities of CUDA-L1 demonstrate that reinforcement learning can\ntransform an initially poor-performing LLM into an effective CUDA optimizer\nthrough speedup-based reward signals alone, without human expertise or domain\nknowledge. More importantly, the trained RL model extend the acquired reasoning\nabilities to new kernels. This paradigm opens possibilities for automated\noptimization of CUDA operations, and holds promise to substantially promote GPU\nefficiency and alleviate the rising pressure on GPU computing resources.", "AI": {"tldr": "CUDA-L1\u662f\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u52a8\u5316CUDA\u4f18\u5316\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86CUDA\u5185\u6838\u7684\u6027\u80fd\uff0c\u5e76\u5728\u591a\u79cdGPU\u67b6\u6784\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u7531\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9GPU\u8ba1\u7b97\u8d44\u6e90\u7684\u9700\u6c42\u6fc0\u589e\uff0c\u4e9f\u9700\u81ea\u52a8\u5316CUDA\u4f18\u5316\u7b56\u7565\uff0c\u800c\u73b0\u6709\u6a21\u578b\u4f18\u5316\u6210\u529f\u7387\u4f4e\u3002", "method": "\u63d0\u51faCUDA-L1\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316CUDA\u5185\u6838\u6027\u80fd\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3002", "result": "\u5728A100\u4e0a\u5e73\u5747\u52a0\u901f17.7\u500d\uff0c\u5cf0\u503c\u8fbe449\u500d\uff0c\u4e14\u5728\u5176\u4ed6GPU\u67b6\u6784\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "CUDA-L1\u5c55\u793a\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u81ea\u52a8\u5316CUDA\u4f18\u5316\u4e2d\u7684\u6f5c\u529b\uff0c\u6709\u671b\u63d0\u5347GPU\u6548\u7387\u5e76\u7f13\u89e3\u8d44\u6e90\u538b\u529b\u3002"}}
{"id": "2507.13491", "pdf": "https://arxiv.org/pdf/2507.13491", "abs": "https://arxiv.org/abs/2507.13491", "authors": ["Thomas Banker", "Ali Mesbah"], "title": "Model-free Reinforcement Learning for Model-based Control: Towards Safe, Interpretable and Sample-efficient Agents", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Training sophisticated agents for optimal decision-making under uncertainty\nhas been key to the rapid development of modern autonomous systems across\nfields. Notably, model-free reinforcement learning (RL) has enabled\ndecision-making agents to improve their performance directly through system\ninteractions, with minimal prior knowledge about the system. Yet, model-free RL\nhas generally relied on agents equipped with deep neural network function\napproximators, appealing to the networks' expressivity to capture the agent's\npolicy and value function for complex systems. However, neural networks amplify\nthe issues of sample inefficiency, unsafe learning, and limited\ninterpretability in model-free RL. To this end, this work introduces\nmodel-based agents as a compelling alternative for control policy\napproximation, leveraging adaptable models of system dynamics, cost, and\nconstraints for safe policy learning. These models can encode prior system\nknowledge to inform, constrain, and aid in explaining the agent's decisions,\nwhile deficiencies due to model mismatch can be remedied with model-free RL. We\noutline the benefits and challenges of learning model-based agents --\nexemplified by model predictive control -- and detail the primary learning\napproaches: Bayesian optimization, policy search RL, and offline strategies,\nalong with their respective strengths. While model-free RL has long been\nestablished, its interplay with model-based agents remains largely unexplored,\nmotivating our perspective on their combined potentials for sample-efficient\nlearning of safe and interpretable decision-making agents.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u7684\u667a\u80fd\u4f53\u4f5c\u4e3a\u6a21\u578b\u65e0\u5173\u5f3a\u5316\u5b66\u4e60\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4ee5\u63d0\u9ad8\u6837\u672c\u6548\u7387\u3001\u5b89\u5168\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6a21\u578b\u65e0\u5173\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5b58\u5728\u6837\u672c\u6548\u7387\u4f4e\u3001\u5b66\u4e60\u4e0d\u5b89\u5168\u53ca\u53ef\u89e3\u91ca\u6027\u5dee\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u6a21\u578b\u7684\u667a\u80fd\u4f53\uff0c\u5229\u7528\u7cfb\u7edf\u52a8\u529b\u5b66\u3001\u6210\u672c\u548c\u7ea6\u675f\u7684\u53ef\u9002\u5e94\u6a21\u578b\u8fdb\u884c\u5b89\u5168\u7b56\u7565\u5b66\u4e60\uff0c\u5e76\u7ed3\u5408\u6a21\u578b\u65e0\u5173RL\u5f25\u8865\u6a21\u578b\u4e0d\u5339\u914d\u7684\u7f3a\u9677\u3002", "result": "\u57fa\u4e8e\u6a21\u578b\u7684\u667a\u80fd\u4f53\uff08\u5982\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff09\u5728\u6837\u672c\u6548\u7387\u3001\u5b89\u5168\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u7ed3\u5408\u57fa\u4e8e\u6a21\u578b\u548c\u6a21\u578b\u65e0\u5173RL\u7684\u65b9\u6cd5\uff0c\u6709\u671b\u5b9e\u73b0\u6837\u672c\u9ad8\u6548\u3001\u5b89\u5168\u4e14\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u667a\u80fd\u4f53\u3002"}}
{"id": "2507.13508", "pdf": "https://arxiv.org/pdf/2507.13508", "abs": "https://arxiv.org/abs/2507.13508", "authors": ["Agata Kaczmarek", "Dawid P\u0142udowski", "Piotr Wilczy\u0144ski", "Przemys\u0142aw Biecek", "Krzysztof Kotowski", "Ramez Shendy", "Jakub Nalepa", "Artur Janicki", "Evridiki Ntagiou"], "title": "Fake or Real: The Impostor Hunt in Texts for Space Operations", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "The \"Fake or Real\" competition hosted on Kaggle\n(\\href{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt}{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt})\nis the second part of a series of follow-up competitions and hackathons related\nto the \"Assurance for Space Domain AI Applications\" project funded by the\nEuropean Space Agency\n(\\href{https://assurance-ai.space-codev.org/}{https://assurance-ai.space-codev.org/}).\nThe competition idea is based on two real-life AI security threats identified\nwithin the project -- data poisoning and overreliance in Large Language Models.\nThe task is to distinguish between the proper output from LLM and the output\ngenerated under malicious modification of the LLM. As this problem was not\nextensively researched, participants are required to develop new techniques to\naddress this issue or adjust already existing ones to this problem's statement.", "AI": {"tldr": "Kaggle\u7ade\u8d5b\u201cFake or Real\u201d\u65e8\u5728\u89e3\u51b3AI\u5b89\u5168\u5a01\u80c1\uff0c\u8981\u6c42\u53c2\u4e0e\u8005\u533a\u5206\u6b63\u5e38\u4e0e\u6076\u610f\u4fee\u6539\u7684LLM\u8f93\u51fa\u3002", "motivation": "\u57fa\u4e8e\u6b27\u6d32\u822a\u5929\u5c40\u8d44\u52a9\u7684\u9879\u76ee\uff0c\u8bc6\u522b\u4e86\u6570\u636e\u6bd2\u5316\u548c\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8fc7\u5ea6\u4f9d\u8d56\u4e24\u5927\u5a01\u80c1\uff0c\u9700\u7814\u7a76\u65b0\u65b9\u6cd5\u5e94\u5bf9\u3002", "method": "\u53c2\u4e0e\u8005\u9700\u5f00\u53d1\u65b0\u6280\u672f\u6216\u8c03\u6574\u73b0\u6709\u65b9\u6cd5\uff0c\u4ee5\u533a\u5206\u6b63\u5e38\u4e0e\u6076\u610f\u4fee\u6539\u7684LLM\u8f93\u51fa\u3002", "result": "\u7ade\u8d5b\u65e8\u5728\u586b\u8865\u8be5\u95ee\u9898\u7814\u7a76\u7a7a\u767d\uff0c\u63a8\u52a8\u76f8\u5173\u6280\u672f\u8fdb\u6b65\u3002", "conclusion": "\u8be5\u7ade\u8d5b\u4e3aAI\u5b89\u5168\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u548c\u5b9e\u8df5\u5e73\u53f0\u3002"}}
{"id": "2507.13540", "pdf": "https://arxiv.org/pdf/2507.13540", "abs": "https://arxiv.org/abs/2507.13540", "authors": ["Yongyi Yang", "Hidenori Tanaka", "Wei Hu"], "title": "Provable Low-Frequency Bias of In-Context Learning of Representations", "categories": ["cs.LG"], "comment": null, "summary": "In-context learning (ICL) enables large language models (LLMs) to acquire new\nbehaviors from the input sequence alone without any parameter updates. Recent\nstudies have shown that ICL can surpass the original meaning learned in\npretraining stage through internalizing the structure the data-generating\nprocess (DGP) of the prompt into the hidden representations. However, the\nmechanisms by which LLMs achieve this ability is left open. In this paper, we\npresent the first rigorous explanation of such phenomena by introducing a\nunified framework of double convergence, where hidden representations converge\nboth over context and across layers. This double convergence process leads to\nan implicit bias towards smooth (low-frequency) representations, which we prove\nanalytically and verify empirically. Our theory explains several open empirical\nobservations, including why learned representations exhibit globally structured\nbut locally distorted geometry, and why their total energy decays without\nvanishing. Moreover, our theory predicts that ICL has an intrinsic robustness\ntowards high-frequency noise, which we empirically confirm. These results\nprovide new insights into the underlying mechanisms of ICL, and a theoretical\nfoundation to study it that hopefully extends to more general data\ndistributions and settings.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5f15\u5165\u53cc\u6536\u655b\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u9996\u6b21\u4e25\u683c\u89e3\u91ca\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5982\u4f55\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u4ece\u8f93\u5165\u5e8f\u5217\u4e2d\u5b66\u4e60\u65b0\u884c\u4e3a\uff0c\u800c\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u3002", "motivation": "\u7814\u7a76LLMs\u5982\u4f55\u901a\u8fc7ICL\u4ece\u8f93\u5165\u5e8f\u5217\u4e2d\u5b66\u4e60\u65b0\u884c\u4e3a\uff0c\u5e76\u89e3\u91ca\u5176\u80cc\u540e\u7684\u673a\u5236\u3002", "method": "\u63d0\u51fa\u53cc\u6536\u655b\u6846\u67b6\uff0c\u5206\u6790\u9690\u85cf\u8868\u793a\u5728\u4e0a\u4e0b\u6587\u548c\u5c42\u95f4\u7684\u6536\u655b\u8fc7\u7a0b\uff0c\u8bc1\u660e\u5176\u5bf9\u5e73\u6ed1\uff08\u4f4e\u9891\uff09\u8868\u793a\u7684\u9690\u5f0f\u504f\u597d\u3002", "result": "\u7406\u8bba\u89e3\u91ca\u4e86ICL\u7684\u591a\u4e2a\u7ecf\u9a8c\u89c2\u5bdf\uff0c\u5982\u8868\u793a\u51e0\u4f55\u7684\u5168\u5c40\u7ed3\u6784\u4e0e\u5c40\u90e8\u626d\u66f2\uff0c\u4ee5\u53ca\u603b\u80fd\u91cf\u8870\u51cf\u4f46\u4e0d\u6d88\u5931\u7684\u73b0\u8c61\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3aICL\u7684\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u5e76\u4e3a\u5176\u7406\u8bba\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u6709\u671b\u6269\u5c55\u5230\u66f4\u4e00\u822c\u7684\u6570\u636e\u5206\u5e03\u548c\u8bbe\u7f6e\u3002"}}
{"id": "2507.13542", "pdf": "https://arxiv.org/pdf/2507.13542", "abs": "https://arxiv.org/abs/2507.13542", "authors": ["Beka Begiashvili", "Carlos J. Fernandez-Candel", "Mat\u00edas P\u00e9rez Paredes"], "title": "Acoustic Index: A Novel AI-Driven Parameter for Cardiac Disease Risk Stratification Using Echocardiography", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional echocardiographic parameters such as ejection fraction (EF) and\nglobal longitudinal strain (GLS) have limitations in the early detection of\ncardiac dysfunction. EF often remains normal despite underlying pathology, and\nGLS is influenced by load conditions and vendor variability. There is a growing\nneed for reproducible, interpretable, and operator-independent parameters that\ncapture subtle and global cardiac functional alterations.\n  We introduce the Acoustic Index, a novel AI-derived echocardiographic\nparameter designed to quantify cardiac dysfunction from standard ultrasound\nviews. The model combines Extended Dynamic Mode Decomposition (EDMD) based on\nKoopman operator theory with a hybrid neural network that incorporates clinical\nmetadata. Spatiotemporal dynamics are extracted from echocardiographic\nsequences to identify coherent motion patterns. These are weighted via\nattention mechanisms and fused with clinical data using manifold learning,\nresulting in a continuous score from 0 (low risk) to 1 (high risk).\n  In a prospective cohort of 736 patients, encompassing various cardiac\npathologies and normal controls, the Acoustic Index achieved an area under the\ncurve (AUC) of 0.89 in an independent test set. Cross-validation across five\nfolds confirmed the robustness of the model, showing that both sensitivity and\nspecificity exceeded 0.8 when evaluated on independent data. Threshold-based\nanalysis demonstrated stable trade-offs between sensitivity and specificity,\nwith optimal discrimination near this threshold.\n  The Acoustic Index represents a physics-informed, interpretable AI biomarker\nfor cardiac function. It shows promise as a scalable, vendor-independent tool\nfor early detection, triage, and longitudinal monitoring. Future directions\ninclude external validation, longitudinal studies, and adaptation to\ndisease-specific classifiers.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAcoustic Index\u7684\u65b0\u578bAI\u884d\u751f\u8d85\u58f0\u5fc3\u52a8\u56fe\u53c2\u6570\uff0c\u7528\u4e8e\u91cf\u5316\u5fc3\u810f\u529f\u80fd\u969c\u788d\uff0c\u7ed3\u5408\u4e86EDMD\u548c\u6df7\u5408\u795e\u7ecf\u7f51\u7edc\uff0c\u5728\u72ec\u7acb\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4f20\u7edf\u8d85\u58f0\u5fc3\u52a8\u56fe\u53c2\u6570\uff08\u5982EF\u548cGLS\uff09\u5728\u65e9\u671f\u68c0\u6d4b\u5fc3\u810f\u529f\u80fd\u969c\u788d\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u91cd\u590d\u3001\u53ef\u89e3\u91ca\u4e14\u64cd\u4f5c\u8005\u72ec\u7acb\u7684\u53c2\u6570\u3002", "method": "\u7ed3\u5408EDMD\u548c\u6df7\u5408\u795e\u7ecf\u7f51\u7edc\uff0c\u63d0\u53d6\u8d85\u58f0\u5fc3\u52a8\u56fe\u5e8f\u5217\u7684\u65f6\u7a7a\u52a8\u6001\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u548c\u6d41\u5f62\u5b66\u4e60\u878d\u5408\u4e34\u5e8a\u6570\u636e\uff0c\u751f\u62100\u52301\u7684\u8fde\u7eed\u8bc4\u5206\u3002", "result": "\u5728736\u540d\u60a3\u8005\u7684\u961f\u5217\u4e2d\uff0cAcoustic Index\u7684AUC\u4e3a0.89\uff0c\u4ea4\u53c9\u9a8c\u8bc1\u663e\u793a\u654f\u611f\u6027\u548c\u7279\u5f02\u6027\u5747\u8d85\u8fc70.8\u3002", "conclusion": "Acoustic Index\u662f\u4e00\u79cd\u7269\u7406\u9a71\u52a8\u7684\u53ef\u89e3\u91caAI\u751f\u7269\u6807\u5fd7\u7269\uff0c\u6709\u671b\u6210\u4e3a\u65e9\u671f\u68c0\u6d4b\u548c\u76d1\u6d4b\u5fc3\u810f\u529f\u80fd\u7684\u5de5\u5177\uff0c\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u548c\u6269\u5c55\u3002"}}
{"id": "2507.13556", "pdf": "https://arxiv.org/pdf/2507.13556", "abs": "https://arxiv.org/abs/2507.13556", "authors": ["Rui Wang", "Steven Klee", "Alexis Roos"], "title": "Time Series Forecastability Measures", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper proposes using two metrics to quantify the forecastability of time\nseries prior to model development: the spectral predictability score and the\nlargest Lyapunov exponent. Unlike traditional model evaluation metrics, these\nmeasures assess the inherent forecastability characteristics of the data before\nany forecast attempts. The spectral predictability score evaluates the strength\nand regularity of frequency components in the time series, whereas the Lyapunov\nexponents quantify the chaos and stability of the system generating the data.\nWe evaluated the effectiveness of these metrics on both synthetic and\nreal-world time series from the M5 forecast competition dataset. Our results\ndemonstrate that these two metrics can correctly reflect the inherent\nforecastability of a time series and have a strong correlation with the actual\nforecast performance of various models. By understanding the inherent\nforecastability of time series before model training, practitioners can focus\ntheir planning efforts on products and supply chain levels that are more\nforecastable, while setting appropriate expectations or seeking alternative\nstrategies for products with limited forecastability.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u6307\u6807\uff08\u8c31\u53ef\u9884\u6d4b\u6027\u8bc4\u5206\u548c\u6700\u5927Lyapunov\u6307\u6570\uff09\u6765\u91cf\u5316\u65f6\u95f4\u5e8f\u5217\u7684\u9884\u6d4b\u6027\uff0c\u907f\u514d\u4f20\u7edf\u6a21\u578b\u8bc4\u4f30\u7684\u4e8b\u540e\u6027\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u8bc4\u4f30\u6307\u6807\u5728\u6a21\u578b\u5f00\u53d1\u540e\u624d\u8bc4\u4f30\u9884\u6d4b\u6027\u80fd\uff0c\u800c\u8fd9\u4e24\u79cd\u6307\u6807\u80fd\u5728\u6a21\u578b\u5f00\u53d1\u524d\u8bc4\u4f30\u6570\u636e\u7684\u56fa\u6709\u9884\u6d4b\u6027\uff0c\u5e2e\u52a9\u4f18\u5316\u8d44\u6e90\u5206\u914d\u3002", "method": "\u4f7f\u7528\u8c31\u53ef\u9884\u6d4b\u6027\u8bc4\u5206\u8bc4\u4f30\u65f6\u95f4\u5e8f\u5217\u9891\u7387\u6210\u5206\u7684\u5f3a\u5ea6\u548c\u89c4\u5f8b\u6027\uff0cLyapunov\u6307\u6570\u91cf\u5316\u7cfb\u7edf\u6df7\u6c8c\u6027\u3002\u5728\u5408\u6210\u548cM5\u7ade\u8d5b\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u3002", "result": "\u4e24\u79cd\u6307\u6807\u80fd\u51c6\u786e\u53cd\u6620\u65f6\u95f4\u5e8f\u5217\u7684\u56fa\u6709\u9884\u6d4b\u6027\uff0c\u5e76\u4e0e\u5b9e\u9645\u6a21\u578b\u9884\u6d4b\u6027\u80fd\u5f3a\u76f8\u5173\u3002", "conclusion": "\u63d0\u524d\u4e86\u89e3\u65f6\u95f4\u5e8f\u5217\u7684\u9884\u6d4b\u6027\u6709\u52a9\u4e8e\u4f18\u5316\u8d44\u6e90\u5206\u914d\uff0c\u4e3a\u9884\u6d4b\u6027\u5dee\u7684\u4ea7\u54c1\u5236\u5b9a\u66ff\u4ee3\u7b56\u7565\u3002"}}
{"id": "2507.13569", "pdf": "https://arxiv.org/pdf/2507.13569", "abs": "https://arxiv.org/abs/2507.13569", "authors": ["Mrinal Mathur", "Mike Doan", "Barak Pearlmutter", "Sergey Plis"], "title": "Change of Thought: Adaptive Test-Time Computation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Transformers evaluated in a single, fixed-depth pass are provably limited in\nexpressive power to the constant-depth circuit class TC0. Running a Transformer\nautoregressively removes that ceiling -- first in next-token prediction and,\nmore recently, in chain-of-thought reasoning. Both regimes rely on feedback\nloops that decode internal states into tokens only to re-encode them in\nsubsequent steps. While this \"thinking aloud\" mirrors human reasoning,\nbiological brains iterate without externalising intermediate states as\nlanguage. To boost the expressive power of encoder Transformers without\nresorting to token-level autoregression, we introduce the SELF-Transformer: an\nencoder layer that iteratively refines its own attention weights to a fixed\npoint. Instead of producing -- in one pass -- the alignment matrix that remixes\nthe input sequence, the SELF-Transformer iteratively updates that matrix\ninternally, scaling test-time computation with input difficulty. This\nadaptivity yields up to 20\\% accuracy gains on encoder-style benchmarks without\nincreasing parameter count, demonstrating that input-adaptive alignment at test\ntime offers substantial benefits for only a modest extra compute budget.\nSelf-Transformers thus recover much of the expressive power of iterative\nreasoning while preserving the simplicity of pure encoder architectures.", "AI": {"tldr": "SELF-Transformer\u901a\u8fc7\u5185\u90e8\u8fed\u4ee3\u66f4\u65b0\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u63d0\u5347\u7f16\u7801\u5668Transformer\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u65e0\u9700\u4f9d\u8d56\u81ea\u56de\u5f52\u3002", "motivation": "\u63d0\u5347\u7f16\u7801\u5668Transformer\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u907f\u514d\u4f9d\u8d56\u5916\u90e8\u5316\u7684\u4e2d\u95f4\u72b6\u6001\uff08\u5982\u81ea\u56de\u5f52\uff09\u3002", "method": "\u5f15\u5165SELF-Transformer\uff0c\u901a\u8fc7\u8fed\u4ee3\u66f4\u65b0\u6ce8\u610f\u529b\u6743\u91cd\u81f3\u56fa\u5b9a\u70b9\uff0c\u52a8\u6001\u8c03\u6574\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u5728\u7f16\u7801\u5668\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe20%\uff0c\u4e14\u4e0d\u589e\u52a0\u53c2\u6570\u91cf\u3002", "conclusion": "SELF-Transformer\u901a\u8fc7\u5185\u90e8\u8fed\u4ee3\u5b9e\u73b0\u4e86\u63a5\u8fd1\u81ea\u56de\u5f52\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7f16\u7801\u5668\u7684\u7b80\u6d01\u6027\u3002"}}
{"id": "2507.13575", "pdf": "https://arxiv.org/pdf/2507.13575", "abs": "https://arxiv.org/abs/2507.13575", "authors": ["Hanzhi Zhou", "Erik Hornberger", "Pengsheng Guo", "Xiyou Zhou", "Saiwen Wang", "Xin Wang", "Yifei He", "Xuankai Chang", "Rene Rauch", "Louis D'hauwe", "John Peebles", "Alec Doane", "Kohen Chia", "Jenna Thibodeau", "Zi-Yi Dou", "Yuanyang Zhang", "Ruoming Pang", "Reed Li", "Zhifeng Chen", "Jeremy Warner", "Zhaoyang Xu", "Sophy Lee", "David Mizrahi", "Ramsey Tantawi", "Chris Chaney", "Kelsey Peterson", "Jun Qin", "Alex Dombrowski", "Mira Chiang", "Aiswarya Raghavan", "Gerard Casamayor", "Qibin Chen", "Aonan Zhang", "Nathalie Tran", "Jianyu Wang", "Hang Su", "Thomas Voice", "Alessandro Pappalardo", "Brycen Wershing", "Prasanth Yadla", "Rui Li", "Priyal Chhatrapati", "Ismael Fernandez", "Yusuf Goren", "Xin Zheng", "Forrest Huang", "Tao Lei", "Eray Yildiz", "Alper Kokmen", "Gokul Santhanam", "Areeba Kamal", "Kaan Elgin", "Dian Ang Yap", "Jeremy Liu", "Peter Gray", "Howard Xing", "Kieran Liu", "Matteo Ronchi", "Moritz Schwarzer-Becker", "Yun Zhu", "Mandana Saebi", "Jeremy Snow", "David Griffiths", "Guillaume Tartavel", "Erin Feldman", "Simon Lehnerer", "Fernando Berm\u00fadez-Medina", "Hans Han", "Joe Zhou", "Xiaoyi Ren", "Sujeeth Reddy", "Zirui Wang", "Tom Gunter", "Albert Antony", "Yuanzhi Li", "John Dennison", "Tony Sun", "Yena Han", "Yi Qin", "Sam Davarnia", "Jeffrey Bigham", "Wayne Shan", "Hannah Gillis Coleman", "Guillaume Klein", "Peng Liu", "Muyang Yu", "Jack Cackler", "Yuan Gao", "Crystal Xiao", "Binazir Karimzadeh", "Zhengdong Zhang", "Felix Bai", "Albin Madappally Jose", "Feng Nan", "Nazir Kamaldin", "Dong Yin", "Hans Hao", "Yanchao Sun", "Yi Hua", "Charles Maalouf", "Alex Guillen Garcia", "Guoli Yin", "Lezhi Li", "Mohana Prasad Sathya Moorthy", "Hongbin Gao", "Jay Tang", "Joanna Arreaza-Taylor", "Faye Lao", "Carina Peng", "Josh Shaffer", "Dan Masi", "Sushma Rao", "Tommi Vehvilainen", "Senyu Tong", "Dongcai Shen", "Yang Zhao", "Chris Bartels", "Peter Fu", "Qingqing Cao", "Christopher Neubauer", "Ethan Li", "Mingfei Gao", "Rebecca Callahan", "Richard Wei", "Patrick Dong", "Alex Braunstein", "Sachin Ravi", "Adolfo Lopez Mendez", "Kaiwei Huang", "Kun Duan", "Haoshuo Huang", "Rui Qian", "Stefano Ligas", "Jordan Huffaker", "Dongxu Li", "Bailin Wang", "Nanzhu Wang", "Anuva Agarwal", "Tait Madsen", "Josh Newnham", "Abhishek Sharma", "Zhile Ren", "Deepak Gopinath", "Erik Daxberger", "Saptarshi Guha", "Oron Levy", "Jing Lu", "Nan Dun", "Marc Kirchner", "Yinfei Yang", "Manjot Bilkhu", "Dave Nelson", "Anthony Spalvieri-Kruse", "Juan Lao Tebar", "Yang Xu", "Phani Mutyala", "Gabriel Jacoby-Cooper", "Yingbo Wang", "Karla Vega", "Vishaal Mahtani", "Darren Botten", "Eric Wang", "Hanli Li", "Matthias Paulik", "Haoran Yan", "Navid Shiee", "Yihao Qian", "Bugu Wu", "Qi Zhu", "Ob Adaranijo", "Bhuwan Dhingra", "Zhe Gan", "Nicholas Seidl", "Grace Duanmu", "Rong Situ", "Yiping Ma", "Yin Xia", "David Riazati", "Vasileios Saveris", "Anh Nguyen", "Michael", "Lee", "Patrick Sonnenberg", "Chinguun Erdenebileg", "Yanghao Li", "Vivian Ma", "James Chou", "Isha Garg", "Mark Lee", "Keen You", "Yuhong Li", "Ransen Niu", "Nandhitha Raghuram", "Pulkit Agrawal", "Henry Mason", "Sumeet Singh", "Keyu He", "Hong-You Chen", "Lucas Guibert", "Shiyu Li", "Varsha Paidi", "Narendran Raghavan", "Mingze Xu", "Yuli Yang", "Sergiu Sima", "Irina Belousova", "Sprite Chu", "Afshin Dehghan", "Philipp Dufter", "David Haldimann", "Zhen Yang", "Margit Bowler", "Chang Liu", "Ying-Chang Cheng", "Vivek Rathod", "Syd Evans", "Wilson Tsao", "Dustin Withers", "Haitian Sun", "Biyao Wang", "Peter Grasch", "Walker Cheng", "Yihao Feng", "Vivek Kumar", "Frank Chu", "Victoria M\u00f6nchJuan Haladjian", "Doug Kang", "Jiarui Lu", "Ciro Sannino", "Max Lam", "Floris Weers", "Bowen Pan", "Kenneth Jung", "Dhaval Doshi", "Fangping Shi", "Olli Saarikivi", "Alp Aygar", "Josh Elman", "Cheng Leong", "Eshan Verma", "Matthew Lei", "Jeff Nichols", "Jiulong Shan", "Donald Zhang", "Lawrence Zhou", "Stephen Murphy", "Xianzhi Du", "Chang Lan", "Ankur Jain", "Elmira Amirloo", "Marcin Eichner", "Naomy Sabo", "Anupama Mann Anupama", "David Qiu", "Zhao Meng", "Michael FitzMaurice", "Peng Zhang", "Simon Yeung", "Chen Chen", "Marco Zuliani", "Andrew Hansen", "Yang Lu", "Brent Ramerth", "Ziyi Zhong", "Parsa Mazaheri", "Matthew Hopkins", "Mengyu Li", "Simon Wang", "David Chen", "Farzin Rasteh", "Chong Wang", "Josh Gardner", "Asaf Liberman", "Haoxuan You", "Andrew Walkingshaw", "Xingyu Zhou", "Jinhao Lei", "Yan Meng", "Quentin Keunebroek", "Sam Wiseman", "Anders Boesen Lindbo Larsen", "Yi Zhang", "Zaid Ahmed", "Haiming Gang", "Aaron Franklin", "Kelvin Zou", "Guillaume Seguin", "Jonathan Janke", "Rachel Burger", "Co Giang", "Cheng Shen", "Jen Liu", "Sanskruti Shah", "Xiang Kong", "Yiran Fei", "TJ Collins", "Chen Zhang", "Zhiyun Lu", "Michael Booker", "Qin Ba", "Yasutaka Tanaka", "Andres Romero Mier Y Teran", "Federico Scozzafava", "Regan Poston", "Jane Li", "Eduardo Jimenez", "Bas Straathof", "Karanjeet Singh", "Lindsay Hislop", "Rajat Arora", "Deepa Seshadri", "Boyue Li", "Colorado Reed", "Zhen Li", "TJ Lu", "Yi Wang", "Kaelen Haag", "Nicholas Lusskin", "Raunak Sinha", "Rahul Nair", "Eldon Schoop", "Mary Beth Kery", "Mehrdad Farajtbar", "Brenda Yang", "George Horrell", "Shiwen Zhao", "Dhruti Shah", "Cha Chen", "Bowen Zhang", "Chang Gao", "Devi Krishna", "Jennifer Mallalieu", "Javier Movellan", "Di Feng", "Emily Zhang", "Sam Xu", "Junting Pan", "Dominik Moritz", "Suma Jayaram", "Kevin Smith", "Dongseong Hwang", "Daniel Parilla", "Jiaming Hu", "You-Cyuan Jhang", "Emad Soroush", "Fred Hohman", "Nan Du", "Emma Wang", "Sam Dodge", "Pragnya Sridhar", "Joris Pelemans", "Wei Fang", "Nina Wenzel", "Joseph Yitan Cheng", "Hadas Kotek", "Chung-Cheng Chiu", "Meng Cao", "Haijing Fu", "Ruixuan Hou", "Ke Ye", "Diane Zhu", "Nikhil Bhendawade", "Joseph Astrauskas", "Jian Liu", "Sai Aitharaju", "Wentao Wu", "Artsiom Peshko", "Hyunjik Kim", "Nilesh Shahdadpuri", "Andy De Wang", "Qi Shan", "Piotr Maj", "Raul Rea Menacho", "Justin Lazarow", "Eric Liang Yang", "Arsalan Farooq", "Donghan Yu", "David G\u00fcera", "Minsik Cho", "Kavya Nerella", "Yongqiang Wang", "Tao Jia", "John Park", "Jeff Lai", "Haotian Zhang", "Futang Peng", "Daniele Molinari", "Aparna Rajamani", "Tyler Johnson", "Lauren Gardiner", "Chao Jia", "Violet Yao", "Wojciech Kryscinski", "Xiujun Li", "Shang-Chen Wu"], "title": "Apple Intelligence Foundation Language Models: Tech Report 2025", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce two multilingual, multimodal foundation language models that\npower Apple Intelligence features across Apple devices and services: i a\n3B-parameter on-device model optimized for Apple silicon through architectural\ninnovations such as KV-cache sharing and 2-bit quantization-aware training; and\nii a scalable server model built on a novel Parallel-Track Mixture-of-Experts\nPT-MoE transformer that combines track parallelism, mixture-of-experts sparse\ncomputation, and interleaved global-local attention to deliver high quality\nwith competitive cost on Apple's Private Cloud Compute platform. Both models\nare trained on large-scale multilingual and multimodal datasets sourced via\nresponsible web crawling, licensed corpora, and high-quality synthetic data,\nthen further refined with supervised fine-tuning and reinforcement learning on\na new asynchronous platform. The resulting models support several additional\nlanguages while understanding images and executing tool calls. In public\nbenchmarks and human evaluations, both the server model and the on-device model\nmatch or surpass comparably sized open baselines.\n  A new Swift-centric Foundation Models framework exposes guided generation,\nconstrained tool calling, and LoRA adapter fine-tuning, allowing developers to\nintegrate these capabilities with a few lines of code. The latest advancements\nin Apple Intelligence models are grounded in our Responsible AI approach with\nsafeguards like content filtering and locale-specific evaluation, as well as\nour commitment to protecting our users' privacy with innovations like Private\nCloud Compute.", "AI": {"tldr": "\u82f9\u679c\u63a8\u51fa\u4e86\u4e24\u79cd\u591a\u8bed\u8a00\u3001\u591a\u6a21\u6001\u7684\u57fa\u7840\u8bed\u8a00\u6a21\u578b\uff0c\u5206\u522b\u7528\u4e8e\u8bbe\u5907\u7aef\u548c\u670d\u52a1\u5668\u7aef\uff0c\u652f\u6301\u591a\u79cd\u8bed\u8a00\u548c\u56fe\u50cf\u7406\u89e3\uff0c\u6027\u80fd\u4f18\u4e8e\u540c\u7c7b\u5f00\u6e90\u6a21\u578b\u3002", "motivation": "\u4e3a\u82f9\u679c\u8bbe\u5907\u548c\u670d\u52a1\u63d0\u4f9b\u667a\u80fd\u529f\u80fd\uff0c\u540c\u65f6\u517c\u987e\u6027\u80fd\u3001\u6210\u672c\u3001\u9690\u79c1\u548c\u8d1f\u8d23\u4efb\u7684\u4eba\u5de5\u667a\u80fd\u5f00\u53d1\u3002", "method": "\u8bbe\u5907\u7aef\u6a21\u578b\u91c7\u7528KV\u7f13\u5b58\u5171\u4eab\u548c2\u4f4d\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\uff1b\u670d\u52a1\u5668\u6a21\u578b\u91c7\u7528\u5e76\u884c\u8f68\u9053\u6df7\u5408\u4e13\u5bb6\uff08PT-MoE\uff09\u67b6\u6784\uff0c\u7ed3\u5408\u7a00\u758f\u8ba1\u7b97\u548c\u5168\u5c40-\u5c40\u90e8\u6ce8\u610f\u529b\u3002", "result": "\u6a21\u578b\u5728\u516c\u5f00\u57fa\u51c6\u548c\u4eba\u5de5\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u652f\u6301\u591a\u8bed\u8a00\u548c\u5de5\u5177\u8c03\u7528\u3002", "conclusion": "\u82f9\u679c\u901a\u8fc7\u6280\u672f\u521b\u65b0\u548c\u8d1f\u8d23\u4efb\u7684\u4eba\u5de5\u667a\u80fd\u5b9e\u8df5\uff0c\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u667a\u80fd\u6a21\u578b\u3002"}}
{"id": "2507.13579", "pdf": "https://arxiv.org/pdf/2507.13579", "abs": "https://arxiv.org/abs/2507.13579", "authors": ["Hyunji Nam", "Yanming Wan", "Mickel Liu", "Jianxun Lian", "Natasha Jaques"], "title": "Learning Pluralistic User Preferences through Reinforcement Learning Fine-tuned Summaries", "categories": ["cs.LG", "cs.AI"], "comment": "20 pages", "summary": "As everyday use cases of large language model (LLM) AI assistants have\nexpanded, it is becoming increasingly important to personalize responses to\nalign to different users' preferences and goals. While reinforcement learning\nfrom human feedback (RLHF) is effective at improving LLMs to be generally more\nhelpful and fluent, it does not account for variability across users, as it\nmodels the entire user population with a single reward model. We present a\nnovel framework, Preference Learning Using Summarization (PLUS), that learns\ntext-based summaries of each user's preferences, characteristics, and past\nconversations. These summaries condition the reward model, enabling it to make\npersonalized predictions about the types of responses valued by each user. We\ntrain the user-summarization model with reinforcement learning, and update the\nreward model simultaneously, creating an online co-adaptation loop. We show\nthat in contrast with prior personalized RLHF techniques or with in-context\nlearning of user information, summaries produced by PLUS capture meaningful\naspects of a user's preferences. Across different pluralistic user datasets, we\nshow that our method is robust to new users and diverse conversation topics.\nAdditionally, we demonstrate that the textual summaries generated about users\ncan be transferred for zero-shot personalization of stronger, proprietary\nmodels like GPT-4. The resulting user summaries are not only concise and\nportable, they are easy for users to interpret and modify, allowing for more\ntransparency and user control in LLM alignment.", "AI": {"tldr": "PLUS\u6846\u67b6\u901a\u8fc7\u751f\u6210\u7528\u6237\u504f\u597d\u6458\u8981\uff0c\u5b9e\u73b0\u4e2a\u6027\u5316LLM\u54cd\u5e94\uff0c\u4f18\u4e8e\u4f20\u7edfRLHF\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfRLHF\u65e0\u6cd5\u533a\u5206\u7528\u6237\u5dee\u5f02\uff0c\u9700\u5f00\u53d1\u4e2a\u6027\u5316\u54cd\u5e94\u65b9\u6cd5\u3002", "method": "\u63d0\u51faPLUS\u6846\u67b6\uff0c\u901a\u8fc7\u6587\u672c\u6458\u8981\u5b66\u4e60\u7528\u6237\u504f\u597d\uff0c\u5e76\u52a8\u6001\u66f4\u65b0\u5956\u52b1\u6a21\u578b\u3002", "result": "PLUS\u80fd\u6709\u6548\u6355\u6349\u7528\u6237\u504f\u597d\uff0c\u9002\u5e94\u65b0\u7528\u6237\u548c\u591a\u6837\u8bdd\u9898\uff0c\u5e76\u53ef\u8fc1\u79fb\u81f3GPT-4\u3002", "conclusion": "PLUS\u63d0\u4f9b\u900f\u660e\u3001\u53ef\u63a7\u5236\u7684\u4e2a\u6027\u5316LLM\u5bf9\u9f50\u65b9\u6848\u3002"}}
{"id": "2507.13608", "pdf": "https://arxiv.org/pdf/2507.13608", "abs": "https://arxiv.org/abs/2507.13608", "authors": ["Yudai Hayashi", "Shuhei Goda", "Yuta Saito"], "title": "Off-Policy Evaluation and Learning for Matching Markets", "categories": ["cs.LG", "cs.IR"], "comment": "RecSys'25", "summary": "Matching users based on mutual preferences is a fundamental aspect of\nservices driven by reciprocal recommendations, such as job search and dating\napplications. Although A/B tests remain the gold standard for evaluating new\npolicies in recommender systems for matching markets, it is costly and\nimpractical for frequent policy updates. Off-Policy Evaluation (OPE) thus plays\na crucial role by enabling the evaluation of recommendation policies using only\noffline logged data naturally collected on the platform. However, unlike\nconventional recommendation settings, the large scale and bidirectional nature\nof user interactions in matching platforms introduce variance issues and\nexacerbate reward sparsity, making standard OPE methods unreliable. To address\nthese challenges and facilitate effective offline evaluation, we propose novel\nOPE estimators, \\textit{DiPS} and \\textit{DPR}, specifically designed for\nmatching markets. Our methods combine elements of the Direct Method (DM),\nInverse Propensity Score (IPS), and Doubly Robust (DR) estimators while\nincorporating intermediate labels, such as initial engagement signals, to\nachieve better bias-variance control in matching markets. Theoretically, we\nderive the bias and variance of the proposed estimators and demonstrate their\nadvantages over conventional methods. Furthermore, we show that these\nestimators can be seamlessly extended to offline policy learning methods for\nimproving recommendation policies for making more matches. We empirically\nevaluate our methods through experiments on both synthetic data and A/B testing\nlogs from a real job-matching platform. The empirical results highlight the\nsuperiority of our approach over existing methods in off-policy evaluation and\nlearning tasks for a variety of configurations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u65b0\u7684\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\uff08OPE\uff09\u65b9\u6cd5DiPS\u548cDPR\uff0c\u9488\u5bf9\u5339\u914d\u5e02\u573a\u7684\u53cc\u5411\u6027\u548c\u6570\u636e\u7a00\u758f\u6027\u95ee\u9898\uff0c\u7ed3\u5408DM\u3001IPS\u548cDR\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u4e2d\u95f4\u4fe1\u53f7\u4f18\u5316\u504f\u5dee-\u65b9\u5dee\u5e73\u8861\uff0c\u5e76\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u5339\u914d\u5e02\u573a\uff08\u5982\u6c42\u804c\u548c\u7ea6\u4f1a\u5e73\u53f0\uff09\u7684\u63a8\u8350\u7cfb\u7edf\u9700\u8981\u9891\u7e41\u66f4\u65b0\u7b56\u7565\uff0c\u4f46A/B\u6d4b\u8bd5\u6210\u672c\u9ad8\u4e14\u4e0d\u5b9e\u7528\u3002\u4f20\u7edfOPE\u65b9\u6cd5\u56e0\u6570\u636e\u7a00\u758f\u6027\u548c\u53cc\u5411\u4ea4\u4e92\u95ee\u9898\u6548\u679c\u4e0d\u4f73\uff0c\u56e0\u6b64\u9700\u8981\u4e13\u95e8\u8bbe\u8ba1\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51faDiPS\u548cDPR\u4e24\u79cd\u65b0OPE\u65b9\u6cd5\uff0c\u7ed3\u5408DM\u3001IPS\u548cDR\u4f30\u8ba1\u5668\uff0c\u5e76\u5229\u7528\u521d\u59cb\u53c2\u4e0e\u4fe1\u53f7\u7b49\u4e2d\u95f4\u6807\u7b7e\u4f18\u5316\u504f\u5dee-\u65b9\u5dee\u63a7\u5236\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u65b0\u65b9\u6cd5\u5728\u504f\u5dee\u548c\u65b9\u5dee\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u6c42\u804c\u5e73\u53f0\u6570\u636e\u4e0a\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "DiPS\u548cDPR\u4e3a\u5339\u914d\u5e02\u573a\u7684\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\u548c\u5b66\u4e60\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.13620", "pdf": "https://arxiv.org/pdf/2507.13620", "abs": "https://arxiv.org/abs/2507.13620", "authors": ["Binxiong Li", "Yuefei Wang", "Xu Xiang", "Xue Li", "Binyu Zhao", "Heyang Gao", "Qinyu Zhao", "Xi Yu"], "title": "Tri-Learn Graph Fusion Network for Attributed Graph Clustering", "categories": ["cs.LG"], "comment": "The source code for this study is available at\n  https://github.com/YF-W/Tri-GFN", "summary": "In recent years, models based on Graph Convolutional Networks (GCN) have made\nsignificant strides in the field of graph data analysis. However, challenges\nsuch as over-smoothing and over-compression remain when handling large-scale\nand complex graph datasets, leading to a decline in clustering quality.\nAlthough the Graph Transformer architecture has mitigated some of these issues,\nits performance is still limited when processing heterogeneous graph data. To\naddress these challenges, this study proposes a novel deep clustering framework\nthat comprising GCN, Autoencoder (AE), and Graph Transformer, termed the\nTri-Learn Graph Fusion Network (Tri-GFN). This framework enhances the\ndifferentiation and consistency of global and local information through a\nunique tri-learning mechanism and feature fusion enhancement strategy. The\nframework integrates GCN, AE, and Graph Transformer modules. These components\nare meticulously fused by a triple-channel enhancement module, which maximizes\nthe use of both node attributes and topological structures, ensuring robust\nclustering representation. The tri-learning mechanism allows mutual learning\namong these modules, while the feature fusion strategy enables the model to\ncapture complex relationships, yielding highly discriminative representations\nfor graph clustering. It surpasses many state-of-the-art methods, achieving an\naccuracy improvement of approximately 0.87% on the ACM dataset, 14.14 % on the\nReuters dataset, and 7.58 % on the USPS dataset. Due to its outstanding\nperformance on the Reuters dataset, Tri-GFN can be applied to automatic news\nclassification, topic retrieval, and related fields.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408GCN\u3001AE\u548cGraph Transformer\u7684Tri-GFN\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u91cd\u5b66\u4e60\u673a\u5236\u548c\u7279\u5f81\u878d\u5408\u7b56\u7565\u63d0\u5347\u56fe\u805a\u7c7b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3GCN\u5728\u5927\u89c4\u6a21\u590d\u6742\u56fe\u6570\u636e\u4e2d\u8fc7\u5e73\u6ed1\u548c\u8fc7\u538b\u7f29\u7684\u95ee\u9898\uff0c\u4ee5\u53caGraph Transformer\u5728\u5f02\u6784\u56fe\u6570\u636e\u4e2d\u7684\u6027\u80fd\u9650\u5236\u3002", "method": "\u63d0\u51faTri-GFN\u6846\u67b6\uff0c\u6574\u5408GCN\u3001AE\u548cGraph Transformer\uff0c\u901a\u8fc7\u4e09\u91cd\u5b66\u4e60\u673a\u5236\u548c\u7279\u5f81\u878d\u5408\u7b56\u7565\u589e\u5f3a\u5168\u5c40\u4e0e\u5c40\u90e8\u4fe1\u606f\u3002", "result": "\u5728ACM\u3001Reuters\u548cUSPS\u6570\u636e\u96c6\u4e0a\u5206\u522b\u63d0\u53470.87%\u300114.14%\u548c7.58%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "Tri-GFN\u5728\u5f02\u6784\u56fe\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u65b0\u95fb\u5206\u7c7b\u548c\u4e3b\u9898\u68c0\u7d22\u7b49\u9886\u57df\u3002"}}
{"id": "2507.13646", "pdf": "https://arxiv.org/pdf/2507.13646", "abs": "https://arxiv.org/abs/2507.13646", "authors": ["Nimisha Ghosh", "Daniele Santoni", "Debaleena Nawn", "Eleonora Ottaviani", "Giovanni Felici"], "title": "A Comprehensive Review of Transformer-based language models for Protein Sequence Analysis and Design", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "The impact of Transformer-based language models has been unprecedented in\nNatural Language Processing (NLP). The success of such models has also led to\ntheir adoption in other fields including bioinformatics. Taking this into\naccount, this paper discusses recent advances in Transformer-based models for\nprotein sequence analysis and design. In this review, we have discussed and\nanalysed a significant number of works pertaining to such applications. These\napplications encompass gene ontology, functional and structural protein\nidentification, generation of de novo proteins and binding of proteins. We\nattempt to shed light on the strength and weaknesses of the discussed works to\nprovide a comprehensive insight to readers. Finally, we highlight shortcomings\nin existing research and explore potential avenues for future developments. We\nbelieve that this review will help researchers working in this field to have an\noverall idea of the state of the art in this field, and to orient their future\nstudies.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578b\u5728\u86cb\u767d\u8d28\u5e8f\u5217\u5206\u6790\u4e0e\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\uff0c\u603b\u7ed3\u4e86\u76f8\u5173\u7814\u7a76\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u63a2\u8ba8Transformer\u6a21\u578b\u5728\u751f\u7269\u4fe1\u606f\u5b66\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u86cb\u767d\u8d28\u5e8f\u5217\u5206\u6790\u4e0e\u8bbe\u8ba1\u7684\u6700\u65b0\u8fdb\u5c55\u3002", "method": "\u7efc\u8ff0\u5e76\u5206\u6790\u4e86\u5927\u91cf\u5173\u4e8eTransformer\u6a21\u578b\u5728\u57fa\u56e0\u672c\u4f53\u3001\u86cb\u767d\u8d28\u529f\u80fd\u4e0e\u7ed3\u6784\u8bc6\u522b\u3001\u86cb\u767d\u8d28\u751f\u6210\u53ca\u7ed3\u5408\u7b49\u65b9\u9762\u7684\u7814\u7a76\u3002", "result": "\u603b\u7ed3\u4e86\u73b0\u6709\u7814\u7a76\u7684\u4f18\u7f3a\u70b9\uff0c\u4e3a\u8bfb\u8005\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u89c6\u89d2\u3002", "conclusion": "\u6307\u51fa\u4e86\u73b0\u6709\u7814\u7a76\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u53d1\u5c55\u7684\u6f5c\u5728\u65b9\u5411\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u7684\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2507.13685", "pdf": "https://arxiv.org/pdf/2507.13685", "abs": "https://arxiv.org/abs/2507.13685", "authors": ["Yue Yang", "Zihan Su", "Ying Zhang", "Chang Chuan Goh", "Yuxiang Lin", "Anthony Graham Bellotti", "Boon Giin Lee"], "title": "Kolmogorov-Arnold Networks-based GRU and LSTM for Loan Default Early Prediction", "categories": ["cs.LG"], "comment": null, "summary": "This study addresses a critical challenge in time series anomaly detection:\nenhancing the predictive capability of loan default models more than three\nmonths in advance to enable early identification of default events, helping\nfinancial institutions implement preventive measures before risk events\nmaterialize. Existing methods have significant drawbacks, such as their lack of\naccuracy in early predictions and their dependence on training and testing\nwithin the same year and specific time frames. These issues limit their\npractical use, particularly with out-of-time data. To address these, the study\nintroduces two innovative architectures, GRU-KAN and LSTM-KAN, which merge\nKolmogorov-Arnold Networks (KAN) with Gated Recurrent Units (GRU) and Long\nShort-Term Memory (LSTM) networks. The proposed models were evaluated against\nthe baseline models (LSTM, GRU, LSTM-Attention, and LSTM-Transformer) in terms\nof accuracy, precision, recall, F1 and AUC in different lengths of feature\nwindow, sample sizes, and early prediction intervals. The results demonstrate\nthat the proposed model achieves a prediction accuracy of over 92% three months\nin advance and over 88% eight months in advance, significantly outperforming\nexisting baselines.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faGRU-KAN\u548cLSTM-KAN\u4e24\u79cd\u65b0\u67b6\u6784\uff0c\u7528\u4e8e\u63d0\u524d\u9884\u6d4b\u8d37\u6b3e\u8fdd\u7ea6\u4e8b\u4ef6\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u8d37\u6b3e\u8fdd\u7ea6\u9884\u6d4b\u6a21\u578b\u5728\u65e9\u671f\u9884\u6d4b\u7cbe\u5ea6\u4e0d\u8db3\u548c\u4f9d\u8d56\u7279\u5b9a\u65f6\u95f4\u6846\u67b6\u7684\u95ee\u9898\uff0c\u4ee5\u5e2e\u52a9\u91d1\u878d\u673a\u6784\u63d0\u524d\u91c7\u53d6\u9884\u9632\u63aa\u65bd\u3002", "method": "\u7ed3\u5408Kolmogorov-Arnold Networks (KAN)\u4e0eGRU\u548cLSTM\u7f51\u7edc\uff0c\u63d0\u51faGRU-KAN\u548cLSTM-KAN\u6a21\u578b\u3002", "result": "\u65b0\u6a21\u578b\u5728\u63d0\u524d\u4e09\u4e2a\u6708\u548c\u516b\u4e2a\u6708\u7684\u9884\u6d4b\u4e2d\u5206\u522b\u8fbe\u523092%\u548c88%\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "GRU-KAN\u548cLSTM-KAN\u5728\u8d37\u6b3e\u8fdd\u7ea6\u65e9\u671f\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.13703", "pdf": "https://arxiv.org/pdf/2507.13703", "abs": "https://arxiv.org/abs/2507.13703", "authors": ["Martin Krutsk\u00fd", "Gustav \u0160\u00edr", "Vyacheslav Kungurtsev", "Georgios Korpas"], "title": "Binarizing Physics-Inspired GNNs for Combinatorial Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to the 28th European Conference on Artificial Intelligence\n  (ECAI 2025). This archival version includes supplementary appendices", "summary": "Physics-inspired graph neural networks (PI-GNNs) have been utilized as an\nefficient unsupervised framework for relaxing combinatorial optimization\nproblems encoded through a specific graph structure and loss, reflecting\ndependencies between the problem's variables. While the framework has yielded\npromising results in various combinatorial problems, we show that the\nperformance of PI-GNNs systematically plummets with an increasing density of\nthe combinatorial problem graphs. Our analysis reveals an interesting phase\ntransition in the PI-GNNs' training dynamics, associated with degenerate\nsolutions for the denser problems, highlighting a discrepancy between the\nrelaxed, real-valued model outputs and the binary-valued problem solutions. To\naddress the discrepancy, we propose principled alternatives to the naive\nstrategy used in PI-GNNs by building on insights from fuzzy logic and binarized\nneural networks. Our experiments demonstrate that the portfolio of proposed\nmethods significantly improves the performance of PI-GNNs in increasingly dense\nsettings.", "AI": {"tldr": "PI-GNNs\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u968f\u7740\u95ee\u9898\u56fe\u5bc6\u5ea6\u589e\u52a0\uff0c\u6027\u80fd\u4e0b\u964d\u3002\u7814\u7a76\u53d1\u73b0\u8bad\u7ec3\u52a8\u6001\u4e2d\u5b58\u5728\u76f8\u53d8\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u548c\u4e8c\u503c\u5316\u795e\u7ecf\u7f51\u7edc\u7684\u6539\u8fdb\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u7814\u7a76PI-GNNs\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u6027\u80fd\u968f\u56fe\u5bc6\u5ea6\u53d8\u5316\u7684\u89c4\u5f8b\uff0c\u5e76\u89e3\u51b3\u5176\u5728\u9ad8\u5bc6\u5ea6\u95ee\u9898\u4e2d\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "method": "\u5206\u6790\u4e86PI-GNNs\u7684\u8bad\u7ec3\u52a8\u6001\uff0c\u53d1\u73b0\u76f8\u53d8\u73b0\u8c61\uff0c\u63d0\u51fa\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u548c\u4e8c\u503c\u5316\u795e\u7ecf\u7f51\u7edc\u7684\u6539\u8fdb\u7b56\u7565\u3002", "result": "\u6539\u8fdb\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86PI-GNNs\u5728\u9ad8\u5bc6\u5ea6\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u6a21\u7cca\u903b\u8f91\u548c\u4e8c\u503c\u5316\u795e\u7ecf\u7f51\u7edc\u7684\u6539\u8fdb\uff0cPI-GNNs\u5728\u9ad8\u5bc6\u5ea6\u95ee\u9898\u4e2d\u7684\u6027\u80fd\u5f97\u5230\u6709\u6548\u63d0\u5347\u3002"}}
{"id": "2507.13704", "pdf": "https://arxiv.org/pdf/2507.13704", "abs": "https://arxiv.org/abs/2507.13704", "authors": ["Anabel Yong", "Austin Tripp", "Layla Hosseini-Gerami", "Brooks Paige"], "title": "Bayesian Optimization for Molecules Should Be Pareto-Aware", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multi-objective Bayesian optimization (MOBO) provides a principled framework\nfor navigating trade-offs in molecular design. However, its empirical\nadvantages over scalarized alternatives remain underexplored. We benchmark a\nsimple Pareto-based MOBO strategy -- Expected Hypervolume Improvement (EHVI) --\nagainst a simple fixed-weight scalarized baseline using Expected Improvement\n(EI), under a tightly controlled setup with identical Gaussian Process\nsurrogates and molecular representations. Across three molecular optimization\ntasks, EHVI consistently outperforms scalarized EI in terms of Pareto front\ncoverage, convergence speed, and chemical diversity. While scalarization\nencompasses flexible variants -- including random or adaptive schemes -- our\nresults show that even strong deterministic instantiations can underperform in\nlow-data regimes. These findings offer concrete evidence for the practical\nadvantages of Pareto-aware acquisition in de novo molecular optimization,\nespecially when evaluation budgets are limited and trade-offs are nontrivial.", "AI": {"tldr": "\u591a\u76ee\u6807\u8d1d\u53f6\u65af\u4f18\u5316\uff08MOBO\uff09\u5728\u5206\u5b50\u8bbe\u8ba1\u4e2d\u4f18\u4e8e\u6807\u91cf\u5316\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u4f4e\u6570\u636e\u91cf\u4e0b\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u63a2\u7d22MOBO\u5728\u5206\u5b50\u8bbe\u8ba1\u4e2d\u7684\u5b9e\u9645\u4f18\u52bf\uff0c\u5c24\u5176\u662f\u4e0e\u6807\u91cf\u5316\u65b9\u6cd5\u76f8\u6bd4\u3002", "method": "\u4f7f\u7528\u57fa\u4e8ePareto\u7684MOBO\u7b56\u7565\uff08EHVI\uff09\u4e0e\u56fa\u5b9a\u6743\u91cd\u7684\u6807\u91cf\u5316\u65b9\u6cd5\uff08EI\uff09\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "EHVI\u5728Pareto\u524d\u6cbf\u8986\u76d6\u3001\u6536\u655b\u901f\u5ea6\u548c\u5316\u5b66\u591a\u6837\u6027\u4e0a\u5747\u4f18\u4e8eEI\u3002", "conclusion": "Pareto\u611f\u77e5\u7684\u83b7\u53d6\u7b56\u7565\u5728\u5206\u5b50\u4f18\u5316\u4e2d\u5177\u6709\u5b9e\u9645\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u4f4e\u6570\u636e\u91cf\u548c\u590d\u6742\u6743\u8861\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2507.13707", "pdf": "https://arxiv.org/pdf/2507.13707", "abs": "https://arxiv.org/abs/2507.13707", "authors": ["Hao Wang", "Yu Liu", "Daniel Biggs", "Haoru Wang", "Jiandong Yu", "Ping Huang"], "title": "Learning Deformable Body Interactions With Adaptive Spatial Tokenization", "categories": ["cs.LG"], "comment": "21 pages, 15 figures", "summary": "Simulating interactions between deformable bodies is vital in fields like\nmaterial science, mechanical design, and robotics. While learning-based methods\nwith Graph Neural Networks (GNNs) are effective at solving complex physical\nsystems, they encounter scalability issues when modeling deformable body\ninteractions. To model interactions between objects, pairwise global edges have\nto be created dynamically, which is computationally intensive and impractical\nfor large-scale meshes. To overcome these challenges, drawing on insights from\ngeometric representations, we propose an Adaptive Spatial Tokenization (AST)\nmethod for efficient representation of physical states. By dividing the\nsimulation space into a grid of cells and mapping unstructured meshes onto this\nstructured grid, our approach naturally groups adjacent mesh nodes. We then\napply a cross-attention module to map the sparse cells into a compact,\nfixed-length embedding, serving as tokens for the entire physical state.\nSelf-attention modules are employed to predict the next state over these tokens\nin latent space. This framework leverages the efficiency of tokenization and\nthe expressive power of attention mechanisms to achieve accurate and scalable\nsimulation results. Extensive experiments demonstrate that our method\nsignificantly outperforms state-of-the-art approaches in modeling deformable\nbody interactions. Notably, it remains effective on large-scale simulations\nwith meshes exceeding 100,000 nodes, where existing methods are hindered by\ncomputational limitations. Additionally, we contribute a novel large-scale\ndataset encompassing a wide range of deformable body interactions to support\nfuture research in this area.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u7a7a\u95f4\u6807\u8bb0\u5316\uff08AST\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f51\u683c\u5212\u5206\u548c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u9ad8\u6548\u6a21\u62df\u53ef\u53d8\u5f62\u4f53\u4ea4\u4e92\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6269\u5c55\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u7684\u65b9\u6cd5\u5728\u6a21\u62df\u53ef\u53d8\u5f62\u4f53\u4ea4\u4e92\u65f6\u5b58\u5728\u6269\u5c55\u6027\u95ee\u9898\uff0c\u52a8\u6001\u521b\u5efa\u5168\u5c40\u8fb9\u8ba1\u7b97\u91cf\u5927\u3002", "method": "\u5c06\u6a21\u62df\u7a7a\u95f4\u5212\u5206\u4e3a\u7f51\u683c\u5355\u5143\uff0c\u5c06\u975e\u7ed3\u6784\u5316\u7f51\u683c\u6620\u5c04\u5230\u7ed3\u6784\u5316\u7f51\u683c\u4e0a\uff0c\u5229\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757\u751f\u6210\u7d27\u51d1\u7684\u56fa\u5b9a\u957f\u5ea6\u5d4c\u5165\u4f5c\u4e3a\u6807\u8bb0\uff0c\u5e76\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u9884\u6d4b\u4e0b\u4e00\u72b6\u6001\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u7f51\u683c\uff08\u8d85\u8fc710\u4e07\u4e2a\u8282\u70b9\uff09\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u8ba1\u7b97\u9ad8\u6548\u3002", "conclusion": "AST\u65b9\u6cd5\u7ed3\u5408\u6807\u8bb0\u5316\u6548\u7387\u548c\u6ce8\u610f\u529b\u673a\u5236\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u4e3a\u53ef\u53d8\u5f62\u4f53\u4ea4\u4e92\u6a21\u62df\u63d0\u4f9b\u4e86\u51c6\u786e\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.13716", "pdf": "https://arxiv.org/pdf/2507.13716", "abs": "https://arxiv.org/abs/2507.13716", "authors": ["Danilo Avola", "Andrea Bernardini", "Giancarlo Crocetti", "Andrea Ladogana", "Mario Lezoche", "Maurizio Mancini", "Daniele Pannone", "Amedeo Ranaldi"], "title": "Benchmarking of EEG Analysis Techniques for Parkinson's Disease Diagnosis: A Comparison between Traditional ML Methods and Foundation DL Methods", "categories": ["cs.LG"], "comment": null, "summary": "Parkinson's Disease PD is a progressive neurodegenerative disorder that\naffects motor and cognitive functions with early diagnosis being critical for\neffective clinical intervention Electroencephalography EEG offers a noninvasive\nand costeffective means of detecting PDrelated neural alterations yet the\ndevelopment of reliable automated diagnostic models remains a challenge In this\nstudy we conduct a systematic benchmark of traditional machine learning ML and\ndeep learning DL models for classifying PD using a publicly available oddball\ntask dataset Our aim is to lay the groundwork for developing an effective\nlearning system and to determine which approach produces the best results We\nimplement a unified sevenstep preprocessing pipeline and apply consistent\nsubjectwise crossvalidation and evaluation criteria to ensure comparability\nacross models Our results demonstrate that while baseline deep learning\narchitectures particularly CNNLSTM models achieve the best performance compared\nto other deep learning architectures underlining the importance of capturing\nlongrange temporal dependencies several traditional classifiers such as XGBoost\nalso offer strong predictive accuracy and calibrated decision boundaries By\nrigorously comparing these baselines our work provides a solid reference\nframework for future studies aiming to develop and evaluate more complex or\nspecialized architectures Establishing a reliable set of baseline results is\nessential to contextualize improvements introduced by novel methods ensuring\nscientific rigor and reproducibility in the evolving field of EEGbased\nneurodiagnostics", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u6bd4\u8f83\u4e86\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5e15\u91d1\u68ee\u75c5\u5206\u7c7b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0CNN-LSTM\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u540c\u65f6XGBoost\u7b49\u4f20\u7edf\u65b9\u6cd5\u4e5f\u6709\u7ade\u4e89\u529b\u3002", "motivation": "\u5e15\u91d1\u68ee\u75c5\uff08PD\uff09\u7684\u65e9\u671f\u8bca\u65ad\u5bf9\u4e34\u5e8a\u5e72\u9884\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5f00\u53d1\u53ef\u9760\u7684\u81ea\u52a8\u5316\u8bca\u65ad\u6a21\u578b\u4ecd\u5177\u6311\u6218\u6027\u3002EEG\u4f5c\u4e3a\u4e00\u79cd\u975e\u4fb5\u5165\u6027\u65b9\u6cd5\uff0c\u4e3aPD\u76f8\u5173\u795e\u7ecf\u53d8\u5316\u68c0\u6d4b\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "method": "\u7814\u7a76\u91c7\u7528\u7edf\u4e00\u7684\u4e03\u6b65\u9884\u5904\u7406\u6d41\u7a0b\uff0c\u5e76\u5e94\u7528\u4e00\u81f4\u7684\u4e3b\u4f53\u4ea4\u53c9\u9a8c\u8bc1\u548c\u8bc4\u4f30\u6807\u51c6\uff0c\u6bd4\u8f83\u4e86\u4f20\u7edfML\u548cDL\u6a21\u578b\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0cCNN-LSTM\u6a21\u578b\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u5176\u4ed6\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u800cXGBoost\u7b49\u4f20\u7edf\u5206\u7c7b\u5668\u4e5f\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u7814\u7a76\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u590d\u6742\u6216\u4e13\u7528\u67b6\u6784\u63d0\u4f9b\u4e86\u57fa\u51c6\u6846\u67b6\uff0c\u5f3a\u8c03\u4e86\u79d1\u5b66\u4e25\u8c28\u6027\u548c\u53ef\u91cd\u590d\u6027\u5728EEG\u795e\u7ecf\u8bca\u65ad\u9886\u57df\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.13718", "pdf": "https://arxiv.org/pdf/2507.13718", "abs": "https://arxiv.org/abs/2507.13718", "authors": ["Danilo Avola", "Muhammad Yasir Bilal", "Emad Emam", "Cristina Lakasz", "Daniele Pannone", "Amedeo Ranaldi"], "title": "Bi-GRU Based Deception Detection using EEG Signals", "categories": ["cs.LG"], "comment": null, "summary": "Deception detection is a significant challenge in fields such as security,\npsychology, and forensics. This study presents a deep learning approach for\nclassifying deceptive and truthful behavior using ElectroEncephaloGram (EEG)\nsignals from the Bag-of-Lies dataset, a multimodal corpus designed for\nnaturalistic, casual deception scenarios. A Bidirectional Gated Recurrent Unit\n(Bi-GRU) neural network was trained to perform binary classification of EEG\nsamples. The model achieved a test accuracy of 97\\%, along with high precision,\nrecall, and F1-scores across both classes. These results demonstrate the\neffectiveness of using bidirectional temporal modeling for EEG-based deception\ndetection and suggest potential for real-time applications and future\nexploration of advanced neural architectures.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684EEG\u4fe1\u53f7\u5206\u7c7b\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u6b3a\u9a97\u884c\u4e3a\uff0c\u6d4b\u8bd5\u51c6\u786e\u7387\u8fbe97%\u3002", "motivation": "\u6b3a\u9a97\u68c0\u6d4b\u5728\u5b89\u5168\u3001\u5fc3\u7406\u5b66\u548c\u6cd5\u533b\u5b66\u7b49\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528\u53cc\u5411\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08Bi-GRU\uff09\u795e\u7ecf\u7f51\u7edc\u5bf9Bag-of-Lies\u6570\u636e\u96c6\u4e2d\u7684EEG\u4fe1\u53f7\u8fdb\u884c\u4e8c\u5206\u7c7b\u3002", "result": "\u6a21\u578b\u6d4b\u8bd5\u51c6\u786e\u7387\u4e3a97%\uff0c\u4e14\u5728\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u53cc\u5411\u65f6\u5e8f\u5efa\u6a21\u5728EEG\u6b3a\u9a97\u68c0\u6d4b\u4e2d\u6548\u679c\u663e\u8457\uff0c\u5177\u6709\u5b9e\u65f6\u5e94\u7528\u6f5c\u529b\uff0c\u672a\u6765\u53ef\u63a2\u7d22\u66f4\u5148\u8fdb\u7684\u795e\u7ecf\u67b6\u6784\u3002"}}
{"id": "2507.13721", "pdf": "https://arxiv.org/pdf/2507.13721", "abs": "https://arxiv.org/abs/2507.13721", "authors": ["Zizhao Zhang", "Tianxiang Zhao", "Yu Sun", "Liping Sun", "Jichuan Kang"], "title": "Graph-Structured Data Analysis of Component Failure in Autonomous Cargo Ships Based on Feature Fusion", "categories": ["cs.LG", "cs.DB"], "comment": null, "summary": "To address the challenges posed by cascading reactions caused by component\nfailures in autonomous cargo ships (ACS) and the uncertainties in emergency\ndecision-making, this paper proposes a novel hybrid feature fusion framework\nfor constructing a graph-structured dataset of failure modes. By employing an\nimproved cuckoo search algorithm (HN-CSA), the literature retrieval efficiency\nis significantly enhanced, achieving improvements of 7.1% and 3.4% compared to\nthe NSGA-II and CSA search algorithms, respectively. A hierarchical feature\nfusion framework is constructed, using Word2Vec encoding to encode\nsubsystem/component features, BERT-KPCA to process failure modes/reasons, and\nSentence-BERT to quantify the semantic association between failure impact and\nemergency decision-making. The dataset covers 12 systems, 1,262 failure modes,\nand 6,150 propagation paths. Validation results show that the GATE-GNN model\nachieves a classification accuracy of 0.735, comparable to existing benchmarks.\nAdditionally, a silhouette coefficient of 0.641 indicates that the features are\nhighly distinguishable. In the label prediction results, the Shore-based\nMeteorological Service System achieved an F1 score of 0.93, demonstrating high\nprediction accuracy. This paper not only provides a solid foundation for\nfailure analysis in autonomous cargo ships but also offers reliable support for\nfault diagnosis, risk assessment, and intelligent decision-making systems. The\nlink to the dataset is\nhttps://github.com/wojiufukele/Graph-Structured-about-CSA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u7279\u5f81\u878d\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u81ea\u4e3b\u8d27\u8239\uff08ACS\uff09\u6545\u969c\u6a21\u5f0f\u7684\u56fe\u7ed3\u6784\u6570\u636e\u96c6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6587\u732e\u68c0\u7d22\u6548\u7387\u548c\u5206\u7c7b\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u81ea\u4e3b\u8d27\u8239\u4e2d\u7ec4\u4ef6\u6545\u969c\u5f15\u53d1\u7684\u7ea7\u8054\u53cd\u5e94\u548c\u5e94\u6025\u51b3\u7b56\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u91c7\u7528\u6539\u8fdb\u7684\u5e03\u8c37\u9e1f\u641c\u7d22\u7b97\u6cd5\uff08HN-CSA\uff09\u63d0\u9ad8\u68c0\u7d22\u6548\u7387\uff0c\u6784\u5efa\u5206\u5c42\u7279\u5f81\u878d\u5408\u6846\u67b6\uff0c\u7ed3\u5408Word2Vec\u3001BERT-KPCA\u548cSentence-BERT\u5904\u7406\u7279\u5f81\u548c\u8bed\u4e49\u5173\u8054\u3002", "result": "\u6570\u636e\u96c6\u8986\u76d612\u4e2a\u7cfb\u7edf\u30011262\u79cd\u6545\u969c\u6a21\u5f0f\u548c6150\u6761\u4f20\u64ad\u8def\u5f84\uff0cGATE-GNN\u6a21\u578b\u5206\u7c7b\u51c6\u786e\u7387\u4e3a0.735\uff0c\u7279\u5f81\u533a\u5206\u5ea6\u9ad8\uff08\u8f6e\u5ed3\u7cfb\u65700.641\uff09\u3002", "conclusion": "\u4e3a\u81ea\u4e3b\u8d27\u8239\u7684\u6545\u969c\u5206\u6790\u3001\u98ce\u9669\u8bc4\u4f30\u548c\u667a\u80fd\u51b3\u7b56\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u9760\u652f\u6301\u3002"}}
{"id": "2507.13727", "pdf": "https://arxiv.org/pdf/2507.13727", "abs": "https://arxiv.org/abs/2507.13727", "authors": ["Ren\u00e9 Heinrich", "Lukas Rauch", "Bernhard Sick", "Christoph Scholz"], "title": "Adversarial Training Improves Generalization Under Distribution Shifts in Bioacoustics", "categories": ["cs.LG"], "comment": "Work in progress", "summary": "Adversarial training is a promising strategy for enhancing model robustness\nagainst adversarial attacks. However, its impact on generalization under\nsubstantial data distribution shifts in audio classification remains largely\nunexplored. To address this gap, this work investigates how different\nadversarial training strategies improve generalization performance and\nadversarial robustness in audio classification. The study focuses on two model\narchitectures: a conventional convolutional neural network (ConvNeXt) and an\ninherently interpretable prototype-based model (AudioProtoPNet). The approach\nis evaluated using a challenging bird sound classification benchmark. This\nbenchmark is characterized by pronounced distribution shifts between training\nand test data due to varying environmental conditions and recording methods, a\ncommon real-world challenge. The investigation explores two adversarial\ntraining strategies: one based on output-space attacks that maximize the\nclassification loss function, and another based on embedding-space attacks\ndesigned to maximize embedding dissimilarity. These attack types are also used\nfor robustness evaluation. Additionally, for AudioProtoPNet, the study assesses\nthe stability of its learned prototypes under targeted embedding-space attacks.\nResults show that adversarial training, particularly using output-space\nattacks, improves clean test data performance by an average of 10.5% relative\nand simultaneously strengthens the adversarial robustness of the models. These\nfindings, although derived from the bird sound domain, suggest that adversarial\ntraining holds potential to enhance robustness against both strong distribution\nshifts and adversarial attacks in challenging audio classification settings.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5bf9\u6297\u8bad\u7ec3\u5728\u97f3\u9891\u5206\u7c7b\u4e2d\u5bf9\u6cdb\u5316\u6027\u80fd\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u8f93\u51fa\u7a7a\u95f4\u653b\u51fb\u7b56\u7565\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5bf9\u6297\u8bad\u7ec3\u5728\u97f3\u9891\u5206\u7c7b\u4e2d\u5bf9\u6570\u636e\u5206\u5e03\u53d8\u5316\u7684\u6cdb\u5316\u80fd\u529b\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u5bf9\u6297\u8bad\u7ec3\u7b56\u7565\uff08\u8f93\u51fa\u7a7a\u95f4\u653b\u51fb\u548c\u5d4c\u5165\u7a7a\u95f4\u653b\u51fb\uff09\uff0c\u8bc4\u4f30\u5176\u5728\u4e24\u79cd\u6a21\u578b\u67b6\u6784\uff08ConvNeXt\u548cAudioProtoPNet\uff09\u4e0a\u7684\u6548\u679c\u3002", "result": "\u8f93\u51fa\u7a7a\u95f4\u653b\u51fb\u7b56\u7565\u5e73\u5747\u63d0\u5347\u5e72\u51c0\u6d4b\u8bd5\u6570\u636e\u6027\u80fd10.5%\uff0c\u540c\u65f6\u589e\u5f3a\u6a21\u578b\u5bf9\u6297\u9c81\u68d2\u6027\u3002", "conclusion": "\u5bf9\u6297\u8bad\u7ec3\u5728\u97f3\u9891\u5206\u7c7b\u4e2d\u80fd\u6709\u6548\u5e94\u5bf9\u6570\u636e\u5206\u5e03\u53d8\u5316\u548c\u5bf9\u6297\u653b\u51fb\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.13741", "pdf": "https://arxiv.org/pdf/2507.13741", "abs": "https://arxiv.org/abs/2507.13741", "authors": ["Shangyou Wang", "Zezhong Ding", "Xike Xie"], "title": "SamGoG: A Sampling-Based Graph-of-Graphs Framework for Imbalanced Graph Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have shown remarkable success in graph\nclassification tasks by capturing both structural and feature-based\nrepresentations. However, real-world graphs often exhibit two critical forms of\nimbalance: class imbalance and graph size imbalance. These imbalances can bias\nthe learning process and degrade model performance. Existing methods typically\naddress only one type of imbalance or incur high computational costs. In this\nwork, we propose SamGoG, a sampling-based Graph-of-Graphs (GoG) learning\nframework that effectively mitigates both class and graph size imbalance.\nSamGoG constructs multiple GoGs through an efficient importance-based sampling\nmechanism and trains on them sequentially. This sampling mechanism incorporates\nthe learnable pairwise similarity and adaptive GoG node degree to enhance edge\nhomophily, thus improving downstream model quality. SamGoG can seamlessly\nintegrate with various downstream GNNs, enabling their efficient adaptation for\ngraph classification tasks. Extensive experiments on benchmark datasets\ndemonstrate that SamGoG achieves state-of-the-art performance with up to a\n15.66% accuracy improvement with 6.7$\\times$ training acceleration.", "AI": {"tldr": "SamGoG\u6846\u67b6\u901a\u8fc7\u91c7\u6837\u673a\u5236\u89e3\u51b3\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u7c7b\u522b\u548c\u5927\u5c0f\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u56fe\u4e2d\u7684\u7c7b\u522b\u548c\u5927\u5c0f\u4e0d\u5e73\u8861\u4f1a\u504f\u7f6e\u5b66\u4e60\u8fc7\u7a0b\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u53ea\u89e3\u51b3\u4e00\u79cd\u4e0d\u5e73\u8861\u6216\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "SamGoG\u901a\u8fc7\u91cd\u8981\u6027\u91c7\u6837\u6784\u5efa\u591a\u4e2a\u56fe\u4e4b\u56fe\uff08GoG\uff09\uff0c\u5e76\u987a\u5e8f\u8bad\u7ec3\uff0c\u7ed3\u5408\u53ef\u5b66\u4e60\u76f8\u4f3c\u6027\u548c\u81ea\u9002\u5e94\u8282\u70b9\u5ea6\u63d0\u5347\u8fb9\u540c\u8d28\u6027\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cSamGoG\u5b9e\u73b0\u4e8615.66%\u7684\u51c6\u786e\u7387\u63d0\u5347\u548c6.7\u500d\u7684\u8bad\u7ec3\u52a0\u901f\u3002", "conclusion": "SamGoG\u80fd\u6709\u6548\u89e3\u51b3\u56fe\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u53cc\u91cd\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5e76\u4e0e\u591a\u79cdGNN\u65e0\u7f1d\u96c6\u6210\u3002"}}
{"id": "2507.13742", "pdf": "https://arxiv.org/pdf/2507.13742", "abs": "https://arxiv.org/abs/2507.13742", "authors": ["Oussama Bouaggad", "Natalia Grabar"], "title": "Search-Optimized Quantization in Biomedical Ontology Alignment", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "In the fast-moving world of AI, as organizations and researchers develop more\nadvanced models, they face challenges due to their sheer size and computational\ndemands. Deploying such models on edge devices or in resource-constrained\nenvironments adds further challenges related to energy consumption, memory\nusage and latency. To address these challenges, emerging trends are shaping the\nfuture of efficient model optimization techniques. From this premise, by\nemploying supervised state-of-the-art transformer-based models, this research\nintroduces a systematic method for ontology alignment, grounded in cosine-based\nsemantic similarity between a biomedical layman vocabulary and the Unified\nMedical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to\nsearch for target optimizations among different Execution Providers (EPs) using\nthe ONNX Runtime backend, followed by an assembled process of dynamic\nquantization employing Intel Neural Compressor and IPEX (Intel Extension for\nPyTorch). Through our optimization process, we conduct extensive assessments on\nthe two tasks from the DEFT 2020 Evaluation Campaign, achieving a new\nstate-of-the-art in both. We retain performance metrics intact, while attaining\nan average inference speed-up of 20x and reducing memory usage by approximately\n70%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u76d1\u7763\u5b66\u4e60\u7684\u53d8\u538b\u5668\u6a21\u578b\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u91cf\u5316\u548c\u6267\u884c\u63d0\u4f9b\u8005\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u901f\u5ea6\u548c\u5185\u5b58\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u5927\u578bAI\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u6311\u6218\uff0c\u5982\u80fd\u8017\u3001\u5185\u5b58\u4f7f\u7528\u548c\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "\u4f7f\u7528Microsoft Olive\u641c\u7d22\u4f18\u5316\u76ee\u6807\uff0c\u7ed3\u5408\u52a8\u6001\u91cf\u5316\u548cIntel\u5de5\u5177\u94fe\uff08Neural Compressor\u548cIPEX\uff09\u8fdb\u884c\u6a21\u578b\u4f18\u5316\u3002", "result": "\u5728DEFT 2020\u4efb\u52a1\u4e2d\u8fbe\u5230\u65b0SOTA\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u534720\u500d\uff0c\u5185\u5b58\u4f7f\u7528\u51cf\u5c11\u7ea670%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u4f18\u5316\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u573a\u666f\u3002"}}
{"id": "2507.13762", "pdf": "https://arxiv.org/pdf/2507.13762", "abs": "https://arxiv.org/abs/2507.13762", "authors": ["Yaowei Jin", "Junjie Wang", "Wenkai Xiang", "Duanhua Cao", "Dan Teng", "Zhehuan Fan", "Jiacheng Xiong", "Xia Sheng", "Chuanlong Zeng", "Mingyue Zheng", "Qian Shi"], "title": "MolPIF: A Parameter Interpolation Flow Model for Molecule Generation", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Advances in deep learning for molecular generation show promise in\naccelerating drug discovery. Bayesian Flow Networks (BFNs) have recently shown\nimpressive performance across diverse chemical tasks, with their success often\nascribed to the paradigm of modeling in a low-variance parameter space.\nHowever, the Bayesian inference-based strategy imposes limitations on designing\nmore flexible distribution transformation pathways, making it challenging to\nadapt to diverse data distributions and varied task requirements. Furthermore,\nthe potential for simpler, more efficient parameter-space-based models is\nunexplored. To address this, we propose a novel Parameter Interpolation Flow\nmodel (named PIF) with detailed theoretical foundation, training, and inference\nprocedures. We then develop MolPIF for structure-based drug design,\ndemonstrating its superior performance across diverse metrics compared to\nbaselines. This work validates the effectiveness of parameter-space-based\ngenerative modeling paradigm for molecules and offers new perspectives for\nmodel design.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53c2\u6570\u63d2\u503c\u6d41\u6a21\u578b\uff08PIF\uff09\uff0c\u7528\u4e8e\u5206\u5b50\u751f\u6210\uff0c\u89e3\u51b3\u4e86\u8d1d\u53f6\u65af\u6d41\u7f51\u7edc\u5728\u7075\u6d3b\u6027\u548c\u9002\u5e94\u6027\u4e0a\u7684\u4e0d\u8db3\uff0c\u5e76\u5728\u836f\u7269\u8bbe\u8ba1\u4e2d\u5c55\u793a\u4e86\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u8d1d\u53f6\u65af\u6d41\u7f51\u7edc\uff08BFNs\uff09\u5728\u5206\u5b50\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u57fa\u4e8e\u8d1d\u53f6\u65af\u63a8\u65ad\u7684\u7b56\u7565\u9650\u5236\u4e86\u5206\u5e03\u53d8\u6362\u8def\u5f84\u7684\u7075\u6d3b\u6027\uff0c\u96be\u4ee5\u9002\u5e94\u591a\u6837\u5316\u6570\u636e\u5206\u5e03\u548c\u4efb\u52a1\u9700\u6c42\u3002\u6b64\u5916\uff0c\u53c2\u6570\u7a7a\u95f4\u6a21\u578b\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPIF\u7684\u53c2\u6570\u63d2\u503c\u6d41\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u7406\u8bba\u57fa\u7840\u3001\u8bad\u7ec3\u548c\u63a8\u65ad\u6d41\u7a0b\uff0c\u5e76\u5f00\u53d1\u4e86MolPIF\u7528\u4e8e\u57fa\u4e8e\u7ed3\u6784\u7684\u836f\u7269\u8bbe\u8ba1\u3002", "result": "MolPIF\u5728\u591a\u79cd\u6307\u6807\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u53c2\u6570\u7a7a\u95f4\u751f\u6210\u6a21\u578b\u5728\u5206\u5b50\u8bbe\u8ba1\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "PIF\u6a21\u578b\u4e3a\u5206\u5b50\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u7684\u8bbe\u8ba1\u89c6\u89d2\uff0c\u5c55\u793a\u4e86\u53c2\u6570\u7a7a\u95f4\u6a21\u578b\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.13765", "pdf": "https://arxiv.org/pdf/2507.13765", "abs": "https://arxiv.org/abs/2507.13765", "authors": ["Enhao Cheng", "Shoujia Zhang", "Jianhua Yin", "Li Jin", "Liqiang Nie"], "title": "Dual-Center Graph Clustering with Neighbor Distribution", "categories": ["cs.LG"], "comment": "ECAI-2025", "summary": "Graph clustering is crucial for unraveling intricate data structures, yet it\npresents significant challenges due to its unsupervised nature. Recently,\ngoal-directed clustering techniques have yielded impressive results, with\ncontrastive learning methods leveraging pseudo-label garnering considerable\nattention. Nonetheless, pseudo-label as a supervision signal is unreliable and\nexisting goal-directed approaches utilize only features to construct a\nsingle-target distribution for single-center optimization, which lead to\nincomplete and less dependable guidance. In our work, we propose a novel\nDual-Center Graph Clustering (DCGC) approach based on neighbor distribution\nproperties, which includes representation learning with neighbor distribution\nand dual-center optimization. Specifically, we utilize neighbor distribution as\na supervision signal to mine hard negative samples in contrastive learning,\nwhich is reliable and enhances the effectiveness of representation learning.\nFurthermore, neighbor distribution center is introduced alongside feature\ncenter to jointly construct a dual-target distribution for dual-center\noptimization. Extensive experiments and analysis demonstrate superior\nperformance and effectiveness of our proposed method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u90bb\u5c45\u5206\u5e03\u7279\u6027\u7684\u53cc\u4e2d\u5fc3\u56fe\u805a\u7c7b\u65b9\u6cd5\uff08DCGC\uff09\uff0c\u901a\u8fc7\u90bb\u5c45\u5206\u5e03\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\u63d0\u5347\u5bf9\u6bd4\u5b66\u4e60\u6548\u679c\uff0c\u5e76\u5f15\u5165\u53cc\u4e2d\u5fc3\u4f18\u5316\u3002", "motivation": "\u4f20\u7edf\u76ee\u6807\u5bfc\u5411\u805a\u7c7b\u65b9\u6cd5\u4ec5\u5229\u7528\u7279\u5f81\u6784\u5efa\u5355\u76ee\u6807\u5206\u5e03\uff0c\u5bfc\u81f4\u76d1\u7763\u4fe1\u53f7\u4e0d\u53ef\u9760\u4e14\u4f18\u5316\u4e0d\u5b8c\u6574\u3002", "method": "\u5229\u7528\u90bb\u5c45\u5206\u5e03\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\u6316\u6398\u786c\u8d1f\u6837\u672c\uff0c\u5e76\u5f15\u5165\u90bb\u5c45\u5206\u5e03\u4e2d\u5fc3\u4e0e\u7279\u5f81\u4e2d\u5fc3\u5171\u540c\u6784\u5efa\u53cc\u76ee\u6807\u5206\u5e03\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u548c\u6548\u679c\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "DCGC\u901a\u8fc7\u53ef\u9760\u7684\u90bb\u5c45\u5206\u5e03\u76d1\u7763\u548c\u53cc\u4e2d\u5fc3\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u805a\u7c7b\u7684\u6548\u679c\u3002"}}
{"id": "2507.13805", "pdf": "https://arxiv.org/pdf/2507.13805", "abs": "https://arxiv.org/abs/2507.13805", "authors": ["Tim Rensmeyer", "Denis Kramer", "Oliver Niggemann"], "title": "On-the-Fly Fine-Tuning of Foundational Neural Network Potentials: A Bayesian Neural Network Approach", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Due to the computational complexity of evaluating interatomic forces from\nfirst principles, the creation of interatomic machine learning force fields has\nbecome a highly active field of research. However, the generation of training\ndatasets of sufficient size and sample diversity itself comes with a\ncomputational burden that can make this approach impractical for modeling rare\nevents or systems with a large configuration space. Fine-tuning foundation\nmodels that have been pre-trained on large-scale material or molecular\ndatabases offers a promising opportunity to reduce the amount of training data\nnecessary to reach a desired level of accuracy. However, even if this approach\nrequires less training data overall, creating a suitable training dataset can\nstill be a very challenging problem, especially for systems with rare events\nand for end-users who don't have an extensive background in machine learning.\nIn on-the-fly learning, the creation of a training dataset can be largely\nautomated by using model uncertainty during the simulation to decide if the\nmodel is accurate enough or if a structure should be recalculated with\nclassical methods and used to update the model. A key challenge for applying\nthis form of active learning to the fine-tuning of foundation models is how to\nassess the uncertainty of those models during the fine-tuning process, even\nthough most foundation models lack any form of uncertainty quantification. In\nthis paper, we overcome this challenge by introducing a fine-tuning approach\nbased on Bayesian neural network methods and a subsequent on-the-fly workflow\nthat automatically fine-tunes the model while maintaining a pre-specified\naccuracy and can detect rare events such as transition states and sample them\nat an increased rate relative to their occurrence.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5fae\u8c03\u9884\u8bad\u7ec3\u7684\u57fa\u7840\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5b9e\u65f6\u5b66\u4e60\u5de5\u4f5c\u6d41\u7a0b\u81ea\u52a8\u68c0\u6d4b\u548c\u91c7\u6837\u7f55\u89c1\u4e8b\u4ef6\u3002", "motivation": "\u7531\u4e8e\u4ece\u5934\u8ba1\u7b97\u539f\u5b50\u95f4\u529b\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u673a\u5668\u5b66\u4e60\u529b\u573a\u7684\u7814\u7a76\u53d8\u5f97\u6d3b\u8dc3\uff0c\u4f46\u751f\u6210\u8db3\u591f\u591a\u6837\u5316\u7684\u8bad\u7ec3\u6570\u636e\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u7f55\u89c1\u4e8b\u4ef6\u6216\u5927\u6784\u578b\u7a7a\u95f4\u7684\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u5fae\u8c03\u9884\u8bad\u7ec3\u7684\u57fa\u7840\u6a21\u578b\uff0c\u7ed3\u5408\u5b9e\u65f6\u5b66\u4e60\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5229\u7528\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u81ea\u52a8\u66f4\u65b0\u6a21\u578b\u5e76\u68c0\u6d4b\u7f55\u89c1\u4e8b\u4ef6\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u6301\u9884\u8bbe\u7cbe\u5ea6\u7684\u540c\u65f6\u81ea\u52a8\u5fae\u8c03\u6a21\u578b\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u5bf9\u7f55\u89c1\u4e8b\u4ef6\uff08\u5982\u8fc7\u6e21\u6001\uff09\u7684\u91c7\u6837\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u57fa\u7840\u6a21\u578b\u5fae\u8c03\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u95ee\u9898\uff0c\u4e3a\u5904\u7406\u7f55\u89c1\u4e8b\u4ef6\u548c\u5927\u6784\u578b\u7a7a\u95f4\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.13834", "pdf": "https://arxiv.org/pdf/2507.13834", "abs": "https://arxiv.org/abs/2507.13834", "authors": ["Aditi Anand", "Suman Banerjee", "Dildar Ali"], "title": "Scalable Submodular Policy Optimization via Pruned Submodularity Graph", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": "16 Pages", "summary": "In Reinforcement Learning (abbreviated as RL), an agent interacts with the\nenvironment via a set of possible actions, and a reward is generated from some\nunknown distribution. The task here is to find an optimal set of actions such\nthat the reward after a certain time step gets maximized. In a traditional\nsetup, the reward function in an RL Problem is considered additive. However, in\nreality, there exist many problems, including path planning, coverage control,\netc., the reward function follows the diminishing return, which can be modeled\nas a submodular function. In this paper, we study a variant of the RL Problem\nwhere the reward function is submodular, and our objective is to find an\noptimal policy such that this reward function gets maximized. We have proposed\na pruned submodularity graph-based approach that provides a provably\napproximate solution in a feasible computation time. The proposed approach has\nbeen analyzed to understand its time and space requirements as well as a\nperformance guarantee. We have experimented with a benchmark agent-environment\nsetup, which has been used for similar previous studies, and the results are\nreported. From the results, we observe that the policy obtained by our proposed\napproach leads to more reward than the baseline methods.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5f3a\u5316\u5b66\u4e60\u4e2d\u5956\u52b1\u51fd\u6570\u4e3a\u6b21\u6a21\u51fd\u6570\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u526a\u679d\u6b21\u6a21\u56fe\u7684\u65b9\u6cd5\uff0c\u4ee5\u5728\u53ef\u884c\u65f6\u95f4\u5185\u63d0\u4f9b\u8fd1\u4f3c\u6700\u4f18\u89e3\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4e2d\u5956\u52b1\u51fd\u6570\u901a\u5e38\u4e3a\u52a0\u6cd5\u5f62\u5f0f\uff0c\u4f46\u73b0\u5b9e\u4e2d\u8bb8\u591a\u95ee\u9898\uff08\u5982\u8def\u5f84\u89c4\u5212\u3001\u8986\u76d6\u63a7\u5236\uff09\u7684\u5956\u52b1\u51fd\u6570\u8868\u73b0\u4e3a\u6536\u76ca\u9012\u51cf\uff0c\u53ef\u7528\u6b21\u6a21\u51fd\u6570\u5efa\u6a21\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u6b21\u6a21\u5956\u52b1\u51fd\u6570\u7684\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u526a\u679d\u6b21\u6a21\u56fe\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u8ba1\u7b97\u65f6\u95f4\u548c\u7a7a\u95f4\u4e0a\u53ef\u884c\uff0c\u5e76\u63d0\u4f9b\u6027\u80fd\u4fdd\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u83b7\u5f97\u7684\u7b56\u7565\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u4ea7\u751f\u66f4\u9ad8\u7684\u5956\u52b1\u3002", "conclusion": "\u672c\u6587\u65b9\u6cd5\u5728\u6b21\u6a21\u5956\u52b1\u51fd\u6570\u7684\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u4e3a\u7c7b\u4f3c\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.13912", "pdf": "https://arxiv.org/pdf/2507.13912", "abs": "https://arxiv.org/abs/2507.13912", "authors": ["Kevin Dradjat", "Massinissa Hamidi", "Pierre Bartet", "Blaise Hanczar"], "title": "Self-supervised learning on gene expression data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Predicting phenotypes from gene expression data is a crucial task in\nbiomedical research, enabling insights into disease mechanisms, drug responses,\nand personalized medicine. Traditional machine learning and deep learning rely\non supervised learning, which requires large quantities of labeled data that\nare costly and time-consuming to obtain in the case of gene expression data.\nSelf-supervised learning has recently emerged as a promising approach to\novercome these limitations by extracting information directly from the\nstructure of unlabeled data. In this study, we investigate the application of\nstate-of-the-art self-supervised learning methods to bulk gene expression data\nfor phenotype prediction. We selected three self-supervised methods, based on\ndifferent approaches, to assess their ability to exploit the inherent structure\nof the data and to generate qualitative representations which can be used for\ndownstream predictive tasks. By using several publicly available gene\nexpression datasets, we demonstrate how the selected methods can effectively\ncapture complex information and improve phenotype prediction accuracy. The\nresults obtained show that self-supervised learning methods can outperform\ntraditional supervised models besides offering significant advantage by\nreducing the dependency on annotated data. We provide a comprehensive analysis\nof the performance of each method by highlighting their strengths and\nlimitations. We also provide recommendations for using these methods depending\non the case under study. Finally, we outline future research directions to\nenhance the application of self-supervised learning in the field of gene\nexpression data analysis. This study is the first work that deals with bulk\nRNA-Seq data and self-supervised learning.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u5728\u57fa\u56e0\u8868\u8fbe\u6570\u636e\u8868\u578b\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u5c55\u793a\u4e86\u5176\u4f18\u4e8e\u4f20\u7edf\u76d1\u7763\u6a21\u578b\u7684\u6f5c\u529b\uff0c\u5e76\u51cf\u5c11\u4e86\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\u3002", "motivation": "\u57fa\u56e0\u8868\u8fbe\u6570\u636e\u7684\u8868\u578b\u9884\u6d4b\u5bf9\u75be\u75c5\u673a\u5236\u3001\u836f\u7269\u53cd\u5e94\u548c\u4e2a\u6027\u5316\u533b\u7597\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u6210\u672c\u9ad8\u3002\u81ea\u76d1\u7763\u5b66\u4e60\u80fd\u76f4\u63a5\u4ece\u65e0\u6807\u6ce8\u6570\u636e\u4e2d\u63d0\u53d6\u4fe1\u606f\uff0c\u514b\u670d\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u7814\u7a76\u9009\u62e9\u4e86\u4e09\u79cd\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u8bc4\u4f30\u5176\u5728\u57fa\u56e0\u8868\u8fbe\u6570\u636e\u4e2d\u63d0\u53d6\u590d\u6742\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u5e76\u7528\u4e8e\u4e0b\u6e38\u9884\u6d4b\u4efb\u52a1\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u5728\u8868\u578b\u9884\u6d4b\u4e2d\u4f18\u4e8e\u4f20\u7edf\u76d1\u7763\u6a21\u578b\uff0c\u4e14\u51cf\u5c11\u4e86\u5bf9\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\u3002", "conclusion": "\u7814\u7a76\u9996\u6b21\u5c06\u81ea\u76d1\u7763\u5b66\u4e60\u5e94\u7528\u4e8e\u6279\u91cfRNA-Seq\u6570\u636e\uff0c\u63d0\u4f9b\u4e86\u65b9\u6cd5\u6027\u80fd\u5206\u6790\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.13920", "pdf": "https://arxiv.org/pdf/2507.13920", "abs": "https://arxiv.org/abs/2507.13920", "authors": ["Turan Orujlu", "Christian Gumbsch", "Martin V. Butz", "Charley M Wu"], "title": "Reframing attention as a reinforcement learning problem for causal discovery", "categories": ["cs.LG"], "comment": null, "summary": "Formal frameworks of causality have operated largely parallel to modern\ntrends in deep reinforcement learning (RL). However, there has been a revival\nof interest in formally grounding the representations learned by neural\nnetworks in causal concepts. Yet, most attempts at neural models of causality\nassume static causal graphs and ignore the dynamic nature of causal\ninteractions. In this work, we introduce Causal Process framework as a novel\ntheory for representing dynamic hypotheses about causal structure. Furthermore,\nwe present Causal Process Model as an implementation of this framework. This\nallows us to reformulate the attention mechanism popularized by Transformer\nnetworks within an RL setting with the goal to infer interpretable causal\nprocesses from visual observations. Here, causal inference corresponds to\nconstructing a causal graph hypothesis which itself becomes an RL task nested\nwithin the original RL problem. To create an instance of such hypothesis, we\nemploy RL agents. These agents establish links between units similar to the\noriginal Transformer attention mechanism. We demonstrate the effectiveness of\nour approach in an RL environment where we outperform current alternatives in\ncausal representation learning and agent performance, and uniquely recover\ngraphs of dynamic causal processes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCausal Process\u7684\u65b0\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u8868\u793a\u52a8\u6001\u56e0\u679c\u7ed3\u6784\u5047\u8bbe\uff0c\u5e76\u5b9e\u73b0\u4e86Causal Process Model\u3002\u8be5\u65b9\u6cd5\u5c06Transformer\u7684\u6ce8\u610f\u529b\u673a\u5236\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\uff0c\u4ece\u89c6\u89c9\u89c2\u5bdf\u4e2d\u63a8\u65ad\u53ef\u89e3\u91ca\u7684\u56e0\u679c\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u56e0\u679c\u6a21\u578b\u591a\u5047\u8bbe\u9759\u6001\u56e0\u679c\u56fe\uff0c\u5ffd\u7565\u4e86\u56e0\u679c\u4ea4\u4e92\u7684\u52a8\u6001\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7406\u8bba\u6846\u67b6\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51faCausal Process\u6846\u67b6\uff0c\u5e76\u5b9e\u73b0Causal Process Model\uff0c\u5c06Transformer\u7684\u6ce8\u610f\u529b\u673a\u5236\u878d\u5165\u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u5d4c\u5957RL\u4efb\u52a1\u63a8\u65ad\u52a8\u6001\u56e0\u679c\u56fe\u3002", "result": "\u5728\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u56e0\u679c\u8868\u793a\u5b66\u4e60\u548c\u667a\u80fd\u4f53\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u80fd\u6062\u590d\u52a8\u6001\u56e0\u679c\u8fc7\u7a0b\u56fe\u3002", "conclusion": "Causal Process\u6846\u67b6\u4e3a\u52a8\u6001\u56e0\u679c\u7ed3\u6784\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u7ed3\u5408Transformer\u6ce8\u610f\u529b\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56e0\u679c\u63a8\u65ad\u80fd\u529b\u3002"}}
{"id": "2507.13950", "pdf": "https://arxiv.org/pdf/2507.13950", "abs": "https://arxiv.org/abs/2507.13950", "authors": ["Jingbo Liang", "Bruna Jacobson"], "title": "MoDyGAN: Combining Molecular Dynamics With GANs to Investigate Protein Conformational Space", "categories": ["cs.LG", "physics.bio-ph", "q-bio.BM"], "comment": null, "summary": "Extensively exploring protein conformational landscapes remains a major\nchallenge in computational biology due to the high computational cost involved\nin dynamic physics-based simulations. In this work, we propose a novel\npipeline, MoDyGAN, that leverages molecular dynamics (MD) simulations and\ngenerative adversarial networks (GANs) to explore protein conformational\nspaces. MoDyGAN contains a generator that maps Gaussian distributions into\nMD-derived protein trajectories, and a refinement module that combines ensemble\nlearning with a dual-discriminator to further improve the plausibility of\ngenerated conformations. Central to our approach is an innovative\nrepresentation technique that reversibly transforms 3D protein structures into\n2D matrices, enabling the use of advanced image-based GAN architectures. We use\nthree rigid proteins to demonstrate that MoDyGAN can generate plausible new\nconformations. We also use deca-alanine as a case study to show that\ninterpolations within the latent space closely align with trajectories obtained\nfrom steered molecular dynamics (SMD) simulations. Our results suggest that\nrepresenting proteins as image-like data unlocks new possibilities for applying\nadvanced deep learning techniques to biomolecular simulation, leading to an\nefficient sampling of conformational states. Additionally, the proposed\nframework holds strong potential for extension to other complex 3D structures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMoDyGAN\u7684\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u548c\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff0c\u7528\u4e8e\u9ad8\u6548\u63a2\u7d22\u86cb\u767d\u8d28\u6784\u8c61\u7a7a\u95f4\u3002", "motivation": "\u7531\u4e8e\u57fa\u4e8e\u7269\u7406\u7684\u52a8\u6001\u6a21\u62df\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u63a2\u7d22\u86cb\u767d\u8d28\u6784\u8c61\u7a7a\u95f4\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "\u5229\u7528\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u548c\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff0c\u901a\u8fc7\u751f\u6210\u5668\u5c06\u9ad8\u65af\u5206\u5e03\u6620\u5c04\u5230\u86cb\u767d\u8d28\u8f68\u8ff9\uff0c\u5e76\u7ed3\u5408\u53cc\u5224\u522b\u5668\u63d0\u5347\u6784\u8c61\u5408\u7406\u6027\u3002\u521b\u65b0\u6027\u5730\u5c063D\u86cb\u767d\u8d28\u7ed3\u6784\u8f6c\u6362\u4e3a2D\u77e9\u9635\uff0c\u4ee5\u4fbf\u4f7f\u7528\u56fe\u50cfGAN\u67b6\u6784\u3002", "result": "\u5728\u4e09\u79cd\u521a\u6027\u86cb\u767d\u8d28\u4e0a\u9a8c\u8bc1\u4e86MoDyGAN\u751f\u6210\u65b0\u6784\u8c61\u7684\u80fd\u529b\uff0c\u5e76\u5728\u5341\u4e19\u6c28\u9178\u6848\u4f8b\u4e2d\u5c55\u793a\u4e86\u4e0e\u5f15\u5bfc\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u8f68\u8ff9\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "\u5c06\u86cb\u767d\u8d28\u8868\u793a\u4e3a\u56fe\u50cf\u6570\u636e\u4e3a\u6df1\u5ea6\u5b66\u4e60\u5728\u751f\u7269\u5206\u5b50\u6a21\u62df\u4e2d\u7684\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u6846\u67b6\u53ef\u6269\u5c55\u81f3\u5176\u4ed6\u590d\u67423D\u7ed3\u6784\u3002"}}
{"id": "2507.13954", "pdf": "https://arxiv.org/pdf/2507.13954", "abs": "https://arxiv.org/abs/2507.13954", "authors": ["Yifan Wei", "Anwar Said", "Waseem Abbas", "Xenofon Koutsoukos"], "title": "Robust Anomaly Detection with Graph Neural Networks using Controllability", "categories": ["cs.LG"], "comment": "conference paper published in IEEE CAI 2025", "summary": "Anomaly detection in complex domains poses significant challenges due to the\nneed for extensive labeled data and the inherently imbalanced nature of\nanomalous versus benign samples. Graph-based machine learning models have\nemerged as a promising solution that combines attribute and relational data to\nuncover intricate patterns. However, the scarcity of anomalous data exacerbates\nthe challenge, which requires innovative strategies to enhance model learning\nwith limited information. In this paper, we hypothesize that the incorporation\nof the influence of the nodes, quantified through average controllability, can\nsignificantly improve the performance of anomaly detection. We propose two\nnovel approaches to integrate average controllability into graph-based\nframeworks: (1) using average controllability as an edge weight and (2)\nencoding it as a one-hot edge attribute vector. Through rigorous evaluation on\nreal-world and synthetic networks with six state-of-the-art baselines, our\nproposed methods demonstrate improved performance in identifying anomalies,\nhighlighting the critical role of controllability measures in enhancing the\nperformance of graph machine learning models. This work underscores the\npotential of integrating average controllability as additional metrics to\naddress the challenges of anomaly detection in sparse and imbalanced datasets.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e73\u5747\u53ef\u63a7\u6027\u6539\u8fdb\u56fe\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u590d\u6742\u9886\u57df\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u56e0\u6807\u8bb0\u6570\u636e\u7a00\u7f3a\u548c\u6837\u672c\u4e0d\u5e73\u8861\u800c\u5177\u6709\u6311\u6218\u6027\uff0c\u56fe\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7ed3\u5408\u5c5e\u6027\u548c\u5173\u7cfb\u6570\u636e\u53ef\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u65b9\u6cd5\uff1a1) \u5c06\u5e73\u5747\u53ef\u63a7\u6027\u4f5c\u4e3a\u8fb9\u6743\u91cd\uff1b2) \u5c06\u5176\u7f16\u7801\u4e3a\u72ec\u70ed\u8fb9\u5c5e\u6027\u5411\u91cf\u3002", "result": "\u5728\u771f\u5b9e\u548c\u5408\u6210\u7f51\u7edc\u4e2d\u9a8c\u8bc1\uff0c\u65b0\u65b9\u6cd5\u5728\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u4e0a\u4f18\u4e8e\u516d\u79cd\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u5e73\u5747\u53ef\u63a7\u6027\u4f5c\u4e3a\u989d\u5916\u6307\u6807\u53ef\u6709\u6548\u63d0\u5347\u7a00\u758f\u548c\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2507.13959", "pdf": "https://arxiv.org/pdf/2507.13959", "abs": "https://arxiv.org/abs/2507.13959", "authors": ["Eli Verwimp", "Gustav Ryberg Smidt", "Hendrik Hameeuw", "Katrien De Graef"], "title": "Signs of the Past, Patterns of the Present: On the Automatic Classification of Old Babylonian Cuneiform Signs", "categories": ["cs.LG"], "comment": "Paper under review at JOCCH", "summary": "The work in this paper describes the training and evaluation of machine\nlearning (ML) techniques for the classification of cuneiform signs. There is a\nlot of variability in cuneiform signs, depending on where they come from, for\nwhat and by whom they were written, but also how they were digitized. This\nvariability makes it unlikely that an ML model trained on one dataset will\nperform successfully on another dataset. This contribution studies how such\ndifferences impact that performance. Based on our results and insights, we aim\nto influence future data acquisition standards and provide a solid foundation\nfor future cuneiform sign classification tasks. The ML model has been trained\nand tested on handwritten Old Babylonian (c. 2000-1600 B.C.E.) documentary\ntexts inscribed on clay tablets originating from three Mesopotamian cities\n(Nippur, D\\=ur-Abie\\v{s}uh and Sippar). The presented and analysed model is\nResNet50, which achieves a top-1 score of 87.1% and a top-5 score of 96.5% for\nsigns with at least 20 instances. As these automatic classification results are\nthe first on Old Babylonian texts, there are currently no comparable results.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u673a\u5668\u5b66\u4e60\u5728\u6954\u5f62\u6587\u5b57\u5206\u7c7b\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u8ba8\u4e86\u6570\u636e\u5dee\u5f02\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u6570\u636e\u91c7\u96c6\u6807\u51c6\u7684\u5efa\u8bae\u3002", "motivation": "\u6954\u5f62\u6587\u5b57\u56e0\u6765\u6e90\u3001\u7528\u9014\u3001\u4e66\u5199\u8005\u548c\u6570\u5b57\u5316\u65b9\u5f0f\u7684\u4e0d\u540c\u800c\u5b58\u5728\u5f88\u5927\u53d8\u5f02\u6027\uff0c\u5bfc\u81f4\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u8fd9\u79cd\u5dee\u5f02\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528ResNet50\u6a21\u578b\uff0c\u57fa\u4e8e\u6765\u81ea\u4e09\u4e2a\u7f8e\u7d22\u4e0d\u8fbe\u7c73\u4e9a\u57ce\u5e02\u7684\u624b\u5199\u53e4\u5df4\u6bd4\u4f26\u6587\u672c\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002", "result": "\u6a21\u578b\u5728\u81f3\u5c1120\u4e2a\u5b9e\u4f8b\u7684\u7b26\u53f7\u4e0a\u53d6\u5f97\u4e8687.1%\u7684top-1\u51c6\u786e\u7387\u548c96.5%\u7684top-5\u51c6\u786e\u7387\u3002", "conclusion": "\u672c\u6587\u4e3a\u6954\u5f62\u6587\u5b57\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5e76\u5efa\u8bae\u672a\u6765\u6539\u8fdb\u6570\u636e\u91c7\u96c6\u6807\u51c6\u3002"}}
{"id": "2507.13992", "pdf": "https://arxiv.org/pdf/2507.13992", "abs": "https://arxiv.org/abs/2507.13992", "authors": ["Jagruti Patel", "Thomas A. W. Bolton", "Mikkel Sch\u00f6ttner", "Anjali Tarun", "Sebastien Tourbier", "Yasser Alem\u00e0n-G\u00f2mez", "Jonas Richiardi", "Patric Hagmann"], "title": "Structural Connectome Harmonization Using Deep Learning: The Strength of Graph Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Small sample sizes in neuroimaging in general, and in structural connectome\n(SC) studies in particular limit the development of reliable biomarkers for\nneurological and psychiatric disorders - such as Alzheimer's disease and\nschizophrenia - by reducing statistical power, reliability, and\ngeneralizability. Large-scale multi-site studies have exist, but they have\nacquisition-related biases due to scanner heterogeneity, compromising imaging\nconsistency and downstream analyses. While existing SC harmonization methods -\nsuch as linear regression (LR), ComBat, and deep learning techniques - mitigate\nthese biases, they often rely on detailed metadata, traveling subjects (TS), or\noverlook the graph-topology of SCs. To address these limitations, we propose a\nsite-conditioned deep harmonization framework that harmonizes SCs across\ndiverse acquisition sites without requiring metadata or TS that we test in a\nsimulated scenario based on the Human Connectome Dataset. Within this\nframework, we benchmark three deep architectures - a fully connected\nautoencoder (AE), a convolutional AE, and a graph convolutional AE - against a\ntop-performing LR baseline. While non-graph models excel in edge-weight\nprediction and edge existence detection, the graph AE demonstrates superior\npreservation of topological structure and subject-level individuality, as\nreflected by graph metrics and fingerprinting accuracy, respectively. Although\nthe LR baseline achieves the highest numerical performance by explicitly\nmodeling acquisition parameters, it lacks applicability to real-world\nmulti-site use cases as detailed acquisition metadata is often unavailable. Our\nresults highlight the critical role of model architecture in SC harmonization\nperformance and demonstrate that graph-based approaches are particularly\nwell-suited for structure-aware, domain-generalizable SC harmonization in\nlarge-scale multi-site SC studies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u7ed3\u6784\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u7ad9\u70b9\u795e\u7ecf\u5f71\u50cf\u7814\u7a76\u4e2d\u7ed3\u6784\u8fde\u63a5\u7ec4\uff08SC\uff09\u7684\u6807\u51c6\u5316\u95ee\u9898\uff0c\u65e0\u9700\u4f9d\u8d56\u8be6\u7ec6\u5143\u6570\u636e\u6216\u65c5\u884c\u53d7\u8bd5\u8005\u3002", "motivation": "\u5c0f\u6837\u672c\u91cf\u548c\u591a\u7ad9\u70b9\u91c7\u96c6\u504f\u5dee\u9650\u5236\u4e86\u795e\u7ecf\u5f71\u50cf\u751f\u7269\u6807\u5fd7\u7269\u7684\u53ef\u9760\u6027\u548c\u6cdb\u5316\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5143\u6570\u636e\u6216\u5ffd\u7565\u56fe\u62d3\u6251\u7ed3\u6784\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ad9\u70b9\u6761\u4ef6\u5316\u7684\u6df1\u5ea6\u6807\u51c6\u5316\u6846\u67b6\uff0c\u6d4b\u8bd5\u4e86\u4e09\u79cd\u6df1\u5ea6\u67b6\u6784\uff08\u5168\u8fde\u63a5\u81ea\u7f16\u7801\u5668\u3001\u5377\u79ef\u81ea\u7f16\u7801\u5668\u548c\u56fe\u5377\u79ef\u81ea\u7f16\u7801\u5668\uff09\u4e0e\u7ebf\u6027\u56de\u5f52\u57fa\u7ebf\u7684\u6027\u80fd\u3002", "result": "\u975e\u56fe\u6a21\u578b\u5728\u8fb9\u6743\u91cd\u9884\u6d4b\u548c\u8fb9\u5b58\u5728\u68c0\u6d4b\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u800c\u56fe\u81ea\u7f16\u7801\u5668\u5728\u4fdd\u7559\u62d3\u6251\u7ed3\u6784\u548c\u4e2a\u4f53\u7279\u5f81\u4e0a\u66f4\u4f18\u3002\u7ebf\u6027\u56de\u5f52\u57fa\u7ebf\u6027\u80fd\u6700\u9ad8\u4f46\u4f9d\u8d56\u5143\u6570\u636e\uff0c\u5b9e\u7528\u6027\u53d7\u9650\u3002", "conclusion": "\u56fe\u7ed3\u6784\u65b9\u6cd5\u5728\u591a\u7ad9\u70b9SC\u7814\u7a76\u4e2d\u66f4\u9002\u5408\u7ed3\u6784\u611f\u77e5\u548c\u9886\u57df\u6cdb\u5316\u7684\u6807\u51c6\u5316\u4efb\u52a1\u3002"}}
{"id": "2507.13998", "pdf": "https://arxiv.org/pdf/2507.13998", "abs": "https://arxiv.org/abs/2507.13998", "authors": ["Itay Katav", "Aryeh Kontorovich"], "title": "ParallelTime: Dynamically Weighting the Balance of Short- and Long-Term Temporal Dependencies", "categories": ["cs.LG"], "comment": null, "summary": "Modern multivariate time series forecasting primarily relies on two\narchitectures: the Transformer with attention mechanism and Mamba. In natural\nlanguage processing, an approach has been used that combines local window\nattention for capturing short-term dependencies and Mamba for capturing\nlong-term dependencies, with their outputs averaged to assign equal weight to\nboth. We find that for time-series forecasting tasks, assigning equal weight to\nlong-term and short-term dependencies is not optimal. To mitigate this, we\npropose a dynamic weighting mechanism, ParallelTime Weighter, which calculates\ninterdependent weights for long-term and short-term dependencies for each token\nbased on the input and the model's knowledge. Furthermore, we introduce the\nParallelTime architecture, which incorporates the ParallelTime Weighter\nmechanism to deliver state-of-the-art performance across diverse benchmarks.\nOur architecture demonstrates robustness, achieves lower FLOPs, requires fewer\nparameters, scales effectively to longer prediction horizons, and significantly\noutperforms existing methods. These advances highlight a promising path for\nfuture developments of parallel Attention-Mamba in time series forecasting. The\nimplementation is readily available at:\n\\href{https://github.com/itay1551/ParallelTime}{ParallelTime GitHub", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u52a0\u6743\u673a\u5236ParallelTime Weighter\uff0c\u7ed3\u5408\u5c40\u90e8\u7a97\u53e3\u6ce8\u610f\u529b\u548cMamba\uff0c\u4f18\u5316\u4e86\u957f\u77ed\u671f\u4f9d\u8d56\u7684\u6743\u91cd\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5bf9\u957f\u77ed\u671f\u4f9d\u8d56\u8d4b\u4e88\u76f8\u7b49\u6743\u91cd\uff0c\u4f46\u8fd9\u5bf9\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5e76\u975e\u6700\u4f18\u3002", "method": "\u63d0\u51faParallelTime Weighter\u52a8\u6001\u8ba1\u7b97\u6743\u91cd\uff0c\u5e76\u8bbe\u8ba1ParallelTime\u67b6\u6784\uff0c\u7ed3\u5408\u5c40\u90e8\u7a97\u53e3\u6ce8\u610f\u529b\u548cMamba\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u53c2\u6570\u5c11\uff0c\u4e14\u9002\u5e94\u66f4\u957f\u7684\u9884\u6d4b\u8303\u56f4\u3002", "conclusion": "ParallelTime\u4e3a\u5e76\u884cAttention-Mamba\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.14005", "pdf": "https://arxiv.org/pdf/2507.14005", "abs": "https://arxiv.org/abs/2507.14005", "authors": ["Mathieu Godbout", "Audrey Durand"], "title": "On the Fundamental Limitations of Dual Static CVaR Decompositions in Markov Decision Processes", "categories": ["cs.LG"], "comment": null, "summary": "Recent work has shown that dynamic programming (DP) methods for finding\nstatic CVaR-optimal policies in Markov Decision Processes (MDPs) can fail when\nbased on the dual formulation, yet the root cause for the failure has remained\nunclear. We expand on these findings by shifting focus from policy optimization\nto the seemingly simpler task of policy evaluation. We show that evaluating the\nstatic CVaR of a given policy can be framed as two distinct minimization\nproblems. For their solutions to match, a set of ``risk-assignment consistency\nconstraints'' must be satisfied, and we demonstrate that the intersection of\nthe constraints being empty is the source of previously observed evaluation\nerrors. Quantifying the evaluation error as the CVaR evaluation gap, we then\ndemonstrate that the issues observed when optimizing over the dual-based CVaR\nDP are explained by the returned policy having a non-zero CVaR evaluation gap.\nWe then leverage our proposed risk-assignment perspective to prove that the\nsearch for a single, uniformly optimal policy via on the dual CVaR\ndecomposition is fundamentally limited, identifying an MDP where no single\npolicy can be optimal across all initial risk levels.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4e86\u52a8\u6001\u89c4\u5212\u65b9\u6cd5\u5728MDP\u4e2d\u5bfb\u627e\u9759\u6001CVaR\u6700\u4f18\u7b56\u7565\u65f6\u5931\u8d25\u7684\u539f\u56e0\uff0c\u5e76\u63d0\u51fa\u98ce\u9669\u5206\u914d\u4e00\u81f4\u6027\u7ea6\u675f\u7684\u6982\u5ff5\u3002", "motivation": "\u89e3\u51b3\u52a8\u6001\u89c4\u5212\u65b9\u6cd5\u5728CVaR\u4f18\u5316\u4e2d\u7684\u5931\u8d25\u95ee\u9898\uff0c\u5e76\u63a2\u7a76\u5176\u6839\u672c\u539f\u56e0\u3002", "method": "\u901a\u8fc7\u653f\u7b56\u8bc4\u4f30\u4efb\u52a1\uff0c\u5c06\u9759\u6001CVaR\u8bc4\u4f30\u95ee\u9898\u8f6c\u5316\u4e3a\u4e24\u4e2a\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u98ce\u9669\u5206\u914d\u4e00\u81f4\u6027\u7ea6\u675f\u3002", "result": "\u53d1\u73b0\u7ea6\u675f\u6761\u4ef6\u4e0d\u6ee1\u8db3\u662f\u5bfc\u81f4\u8bc4\u4f30\u9519\u8bef\u7684\u6839\u6e90\uff0c\u5e76\u8bc1\u660e\u53ccCVaR\u5206\u89e3\u65b9\u6cd5\u5b58\u5728\u56fa\u6709\u5c40\u9650\u6027\u3002", "conclusion": "\u53ccCVaR\u5206\u89e3\u65b9\u6cd5\u65e0\u6cd5\u5728\u6240\u6709\u521d\u59cb\u98ce\u9669\u6c34\u5e73\u4e0b\u627e\u5230\u5355\u4e00\u6700\u4f18\u7b56\u7565\u3002"}}
{"id": "2507.14021", "pdf": "https://arxiv.org/pdf/2507.14021", "abs": "https://arxiv.org/abs/2507.14021", "authors": ["Xu Zhang", "Zhenyuan Yuan", "Minghui Zhu"], "title": "Byzantine-resilient federated online learning for Gaussian process regression", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "In this paper, we study Byzantine-resilient federated online learning for\nGaussian process regression (GPR). We develop a Byzantine-resilient federated\nGPR algorithm that allows a cloud and a group of agents to collaboratively\nlearn a latent function and improve the learning performances where some agents\nexhibit Byzantine failures, i.e., arbitrary and potentially adversarial\nbehavior. Each agent-based local GPR sends potentially compromised local\npredictions to the cloud, and the cloud-based aggregated GPR computes a global\nmodel by a Byzantine-resilient product of experts aggregation rule. Then the\ncloud broadcasts the current global model to all the agents. Agent-based fused\nGPR refines local predictions by fusing the received global model with that of\nthe agent-based local GPR. Moreover, we quantify the learning accuracy\nimprovements of the agent-based fused GPR over the agent-based local GPR.\nExperiments on a toy example and two medium-scale real-world datasets are\nconducted to demonstrate the performances of the proposed algorithm.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u62dc\u5360\u5ead\u5bb9\u9519\u7684\u8054\u90a6\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u90e8\u5206\u4ee3\u7406\u5b58\u5728\u62dc\u5360\u5ead\u6545\u969c\u65f6\u63d0\u5347\u5b66\u4e60\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u62dc\u5360\u5ead\u5bb9\u9519\u7684\u8054\u90a6\u5728\u7ebf\u5b66\u4e60\uff0c\u89e3\u51b3\u4ee3\u7406\u53ef\u80fd\u5b58\u5728\u7684\u4efb\u610f\u6216\u5bf9\u6297\u884c\u4e3a\u5bf9\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u62dc\u5360\u5ead\u5bb9\u9519\u7684\u4ea7\u54c1\u4e13\u5bb6\u805a\u5408\u89c4\u5219\uff0c\u4e91\u7aef\u4e0e\u4ee3\u7406\u534f\u4f5c\u5b66\u4e60\u6f5c\u5728\u51fd\u6570\uff0c\u4ee3\u7406\u878d\u5408\u5168\u5c40\u6a21\u578b\u4f18\u5316\u672c\u5730\u9884\u6d4b\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u5728\u73a9\u5177\u793a\u4f8b\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\uff0c\u91cf\u5316\u4e86\u878d\u5408GPR\u5bf9\u672c\u5730GPR\u7684\u7cbe\u5ea6\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u62dc\u5360\u5ead\u6545\u969c\u4ee3\u7406\u73af\u5883\u4e0b\u7684\u5b66\u4e60\u6027\u80fd\u3002"}}
{"id": "2507.14038", "pdf": "https://arxiv.org/pdf/2507.14038", "abs": "https://arxiv.org/abs/2507.14038", "authors": ["Aileen Luo", "Tao Zhou", "Ming Du", "Martin V. Holt", "Andrej Singer", "Mathew J. Cherukara"], "title": "DONUT: Physics-aware Machine Learning for Real-time X-ray Nanodiffraction Analysis", "categories": ["cs.LG"], "comment": null, "summary": "Coherent X-ray scattering techniques are critical for investigating the\nfundamental structural properties of materials at the nanoscale. While\nadvancements have made these experiments more accessible, real-time analysis\nremains a significant bottleneck, often hindered by artifacts and computational\ndemands. In scanning X-ray nanodiffraction microscopy, which is widely used to\nspatially resolve structural heterogeneities, this challenge is compounded by\nthe convolution of the divergent beam with the sample's local structure. To\naddress this, we introduce DONUT (Diffraction with Optics for Nanobeam by\nUnsupervised Training), a physics-aware neural network designed for the rapid\nand automated analysis of nanobeam diffraction data. By incorporating a\ndifferentiable geometric diffraction model directly into its architecture,\nDONUT learns to predict crystal lattice strain and orientation in real-time.\nCrucially, this is achieved without reliance on labeled datasets or\npre-training, overcoming a fundamental limitation for supervised machine\nlearning in X-ray science. We demonstrate experimentally that DONUT accurately\nextracts all features within the data over 200 times more efficiently than\nconventional fitting methods.", "AI": {"tldr": "DONUT\u662f\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u611f\u77e5\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u4e8e\u5feb\u901f\u81ea\u52a8\u5316\u5206\u6790\u7eb3\u7c73\u675f\u884d\u5c04\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u5b9e\u65f6\u5206\u6790\u7684\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u5b9e\u65f6\u5206\u6790\u7eb3\u7c73\u675f\u884d\u5c04\u6570\u636e\u7684\u6311\u6218\uff0c\u5305\u62ec\u8ba1\u7b97\u9700\u6c42\u9ad8\u548c\u4f2a\u5f71\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u6807\u8bb0\u6570\u636e\u6216\u9884\u8bad\u7ec3\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "DONUT\u7ed3\u5408\u4e86\u53ef\u5fae\u5206\u7684\u51e0\u4f55\u884d\u5c04\u6a21\u578b\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u8bad\u7ec3\u9884\u6d4b\u6676\u683c\u5e94\u53d8\u548c\u53d6\u5411\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cDONUT\u6bd4\u4f20\u7edf\u62df\u5408\u65b9\u6cd5\u6548\u7387\u9ad8200\u500d\u4ee5\u4e0a\uff0c\u4e14\u80fd\u51c6\u786e\u63d0\u53d6\u6570\u636e\u7279\u5f81\u3002", "conclusion": "DONUT\u4e3aX\u5c04\u7ebf\u79d1\u5b66\u4e2d\u7684\u5b9e\u65f6\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u65e0\u9700\u76d1\u7763\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.14056", "pdf": "https://arxiv.org/pdf/2507.14056", "abs": "https://arxiv.org/abs/2507.14056", "authors": ["Alejandro Rodriguez-Garcia", "Anindya Ghosh", "Srikanth Ramaswamy"], "title": "Noradrenergic-inspired gain modulation attenuates the stability gap in joint training", "categories": ["cs.LG", "cs.AI", "q-bio.NC", "68T05"], "comment": "18 pages, 5 figures, 1 table, 1 pseudo-code", "summary": "Recent studies in continual learning have identified a transient drop in\nperformance on mastered tasks when assimilating new ones, known as the\nstability gap. Such dynamics contradict the objectives of continual learning,\nrevealing a lack of robustness in mitigating forgetting, and notably,\npersisting even under an ideal joint-loss regime. Examining this gap within\nthis idealized joint training context is critical to isolate it from other\nsources of forgetting. We argue that it reflects an imbalance between rapid\nadaptation and robust retention at task boundaries, underscoring the need to\ninvestigate mechanisms that reconcile plasticity and stability within continual\nlearning frameworks. Biological brains navigate a similar dilemma by operating\nconcurrently on multiple timescales, leveraging neuromodulatory signals to\nmodulate synaptic plasticity. However, artificial networks lack native\nmultitimescale dynamics, and although optimizers like momentum-SGD and Adam\nintroduce implicit timescale regularization, they still exhibit stability gaps.\nInspired by locus coeruleus mediated noradrenergic bursts, which transiently\nenhance neuronal gain under uncertainty to facilitate sensory assimilation, we\npropose uncertainty-modulated gain dynamics - an adaptive mechanism that\napproximates a two-timescale optimizer and dynamically balances integration of\nknowledge with minimal interference on previously consolidated information. We\nevaluate our mechanism on domain-incremental and class-incremental variants of\nthe MNIST and CIFAR benchmarks under joint training, demonstrating that\nuncertainty-modulated gain dynamics effectively attenuate the stability gap.\nFinally, our analysis elucidates how gain modulation replicates noradrenergic\nfunctions in cortical circuits, offering mechanistic insights into reducing\nstability gaps and enhance performance in continual learning tasks.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u7a33\u5b9a\u6027\u95f4\u9699\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u8c03\u5236\u7684\u589e\u76ca\u52a8\u6001\u673a\u5236\u6765\u5e73\u8861\u77e5\u8bc6\u6574\u5408\u4e0e\u5e72\u6270\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u6301\u7eed\u5b66\u4e60\u4e2d\u5b58\u5728\u7a33\u5b9a\u6027\u95f4\u9699\uff0c\u5373\u5728\u638c\u63e1\u65b0\u4efb\u52a1\u65f6\u5bf9\u5df2\u638c\u63e1\u4efb\u52a1\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u8fd9\u4e0e\u6301\u7eed\u5b66\u4e60\u7684\u76ee\u6807\u76f8\u77db\u76fe\u3002\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u7406\u60f3\u8054\u5408\u8bad\u7ec3\u80cc\u666f\u4e0b\u3002", "method": "\u53d7\u751f\u7269\u5927\u8111\u591a\u65f6\u95f4\u5c3a\u5ea6\u52a8\u6001\u542f\u53d1\uff0c\u63d0\u51fa\u4e0d\u786e\u5b9a\u6027\u8c03\u5236\u7684\u589e\u76ca\u52a8\u6001\u673a\u5236\uff0c\u6a21\u62df\u4e24\u65f6\u95f4\u5c3a\u5ea6\u4f18\u5316\u5668\uff0c\u52a8\u6001\u5e73\u8861\u77e5\u8bc6\u6574\u5408\u4e0e\u5e72\u6270\u3002", "result": "\u5728MNIST\u548cCIFAR\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u673a\u5236\u6709\u6548\u51cf\u5c11\u4e86\u7a33\u5b9a\u6027\u95f4\u9699\u3002", "conclusion": "\u4e0d\u786e\u5b9a\u6027\u8c03\u5236\u7684\u589e\u76ca\u52a8\u6001\u673a\u5236\u4e0d\u4ec5\u89e3\u51b3\u4e86\u7a33\u5b9a\u6027\u95f4\u9699\u95ee\u9898\uff0c\u8fd8\u4e3a\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u4f18\u5316\u601d\u8def\uff0c\u5e76\u63ed\u793a\u4e86\u5176\u4e0e\u751f\u7269\u795e\u7ecf\u673a\u5236\u7684\u76f8\u4f3c\u6027\u3002"}}
{"id": "2507.14066", "pdf": "https://arxiv.org/pdf/2507.14066", "abs": "https://arxiv.org/abs/2507.14066", "authors": ["Ni Mu", "Yao Luan", "Qing-Shan Jia"], "title": "Preference-based Multi-Objective Reinforcement Learning", "categories": ["cs.LG"], "comment": "This article has been accepted for publication in IEEE Transactions\n  on Automation Science and Engineering. This is the author's version, which\n  has not been fully edited, and the content may change prior to final\n  publication. \\c{opyright} 2025 IEEE. All rights reserved, including rights\n  for text and data mining and training of artificial intelligence and similar\n  technologies", "summary": "Multi-objective reinforcement learning (MORL) is a structured approach for\noptimizing tasks with multiple objectives. However, it often relies on\npre-defined reward functions, which can be hard to design for balancing\nconflicting goals and may lead to oversimplification. Preferences can serve as\nmore flexible and intuitive decision-making guidance, eliminating the need for\ncomplicated reward design. This paper introduces preference-based MORL\n(Pb-MORL), which formalizes the integration of preferences into the MORL\nframework. We theoretically prove that preferences can derive policies across\nthe entire Pareto frontier. To guide policy optimization using preferences, our\nmethod constructs a multi-objective reward model that aligns with the given\npreferences. We further provide theoretical proof to show that optimizing this\nreward model is equivalent to training the Pareto optimal policy. Extensive\nexperiments in benchmark multi-objective tasks, a multi-energy management task,\nand an autonomous driving task on a multi-line highway show that our method\nperforms competitively, surpassing the oracle method, which uses the ground\ntruth reward function. This highlights its potential for practical applications\nin complex real-world systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u504f\u597d\u7684\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08Pb-MORL\uff09\uff0c\u901a\u8fc7\u504f\u597d\u6307\u5bfc\u7b56\u7565\u4f18\u5316\uff0c\u907f\u514d\u4e86\u590d\u6742\u7684\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\uff08MORL\uff09\u901a\u5e38\u4f9d\u8d56\u9884\u5b9a\u4e49\u7684\u5956\u52b1\u51fd\u6570\uff0c\u96be\u4ee5\u5e73\u8861\u51b2\u7a81\u76ee\u6807\u4e14\u6613\u7b80\u5316\u95ee\u9898\u3002\u504f\u597d\u80fd\u63d0\u4f9b\u66f4\u7075\u6d3b\u76f4\u89c2\u7684\u51b3\u7b56\u6307\u5bfc\u3002", "method": "\u5f15\u5165Pb-MORL\uff0c\u5c06\u504f\u597d\u6574\u5408\u5230MORL\u6846\u67b6\u4e2d\uff0c\u6784\u5efa\u4e0e\u504f\u597d\u4e00\u81f4\u7684\u591a\u76ee\u6807\u5956\u52b1\u6a21\u578b\uff0c\u5e76\u8bc1\u660e\u4f18\u5316\u8be5\u6a21\u578b\u7b49\u540c\u4e8e\u8bad\u7ec3\u5e15\u7d2f\u6258\u6700\u4f18\u7b56\u7565\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u4efb\u52a1\u3001\u80fd\u6e90\u7ba1\u7406\u4efb\u52a1\u548c\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u4e2d\uff0cPb-MORL\u8868\u73b0\u4f18\u4e8e\u4f7f\u7528\u771f\u5b9e\u5956\u52b1\u51fd\u6570\u7684\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "Pb-MORL\u5728\u590d\u6742\u73b0\u5b9e\u7cfb\u7edf\u4e2d\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0c\u907f\u514d\u4e86\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\u7684\u590d\u6742\u6027\u3002"}}
{"id": "2507.14088", "pdf": "https://arxiv.org/pdf/2507.14088", "abs": "https://arxiv.org/abs/2507.14088", "authors": ["Xiyun Li", "Yining Ding", "Yuhua Jiang", "Yunlong Zhao", "Runpeng Xie", "Shuang Xu", "Yuanhua Ni", "Yiqin Yang", "Bo Xu"], "title": "DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration", "categories": ["cs.LG"], "comment": null, "summary": "Real-time human-artificial intelligence (AI) collaboration is crucial yet\nchallenging, especially when AI agents must adapt to diverse and unseen human\nbehaviors in dynamic scenarios. Existing large language model (LLM) agents\noften fail to accurately model the complex human mental characteristics such as\ndomain intentions, especially in the absence of direct communication. To\naddress this limitation, we propose a novel dual process multi-scale theory of\nmind (DPMT) framework, drawing inspiration from cognitive science dual process\ntheory. Our DPMT framework incorporates a multi-scale theory of mind (ToM)\nmodule to facilitate robust human partner modeling through mental\ncharacteristic reasoning. Experimental results demonstrate that DPMT\nsignificantly enhances human-AI collaboration, and ablation studies further\nvalidate the contributions of our multi-scale ToM in the slow system.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cc\u8fc7\u7a0b\u591a\u5c3a\u5ea6\u5fc3\u667a\u7406\u8bba\uff08DPMT\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u4eba\u7c7b\u4e0eAI\u5728\u52a8\u6001\u573a\u666f\u4e2d\u7684\u534f\u4f5c\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u96be\u4ee5\u51c6\u786e\u5efa\u6a21\u590d\u6742\u7684\u4eba\u7c7b\u5fc3\u7406\u7279\u5f81\uff08\u5982\u9886\u57df\u610f\u56fe\uff09\uff0c\u5c24\u5176\u662f\u5728\u7f3a\u4e4f\u76f4\u63a5\u6c9f\u901a\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u7ed3\u5408\u8ba4\u77e5\u79d1\u5b66\u4e2d\u7684\u53cc\u8fc7\u7a0b\u7406\u8bba\uff0c\u63d0\u51faDPMT\u6846\u67b6\uff0c\u5305\u542b\u591a\u5c3a\u5ea6\u5fc3\u667a\u7406\u8bba\uff08ToM\uff09\u6a21\u5757\uff0c\u7528\u4e8e\u901a\u8fc7\u5fc3\u7406\u7279\u5f81\u63a8\u7406\u5efa\u6a21\u4eba\u7c7b\u4f19\u4f34\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDPMT\u663e\u8457\u63d0\u5347\u4e86\u4eba\u7c7b\u4e0eAI\u7684\u534f\u4f5c\u6548\u679c\uff0c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u591a\u5c3a\u5ea6ToM\u5728\u6162\u7cfb\u7edf\u4e2d\u7684\u8d21\u732e\u3002", "conclusion": "DPMT\u6846\u67b6\u4e3a\u89e3\u51b3\u4eba\u7c7b\u4e0eAI\u534f\u4f5c\u4e2d\u7684\u5fc3\u7406\u5efa\u6a21\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2507.14121", "pdf": "https://arxiv.org/pdf/2507.14121", "abs": "https://arxiv.org/abs/2507.14121", "authors": ["Pankaj Yadav", "Vivek Vijay"], "title": "Kolmogorov Arnold Networks (KANs) for Imbalanced Data -- An Empirical Perspective", "categories": ["cs.LG", "cs.AI"], "comment": "9 Pages, 4 figures", "summary": "Kolmogorov Arnold Networks (KANs) are recent architectural advancement in\nneural computation that offer a mathematically grounded alternative to standard\nneural networks. This study presents an empirical evaluation of KANs in context\nof class imbalanced classification, using ten benchmark datasets. We observe\nthat KANs can inherently perform well on raw imbalanced data more effectively\nthan Multi-Layer Perceptrons (MLPs) without any resampling strategy. However,\nconventional imbalance strategies fundamentally conflict with KANs mathematical\nstructure as resampling and focal loss implementations significantly degrade\nKANs performance, while marginally benefiting MLPs. Crucially, KANs suffer from\nprohibitive computational costs without proportional performance gains.\nStatistical validation confirms that MLPs with imbalance techniques achieve\nequivalence with KANs (|d| < 0.08 across metrics) at minimal resource costs.\nThese findings reveal that KANs represent a specialized solution for raw\nimbalanced data where resources permit. But their severe performance-resource\ntradeoffs and incompatibility with standard resampling techniques currently\nlimits practical deployment. We identify critical research priorities as\ndeveloping KAN specific architectural modifications for imbalance learning,\noptimizing computational efficiency, and theoretical reconciling their conflict\nwith data augmentation. This work establishes foundational insights for next\ngeneration KAN architectures in imbalanced classification scenarios.", "AI": {"tldr": "Kolmogorov Arnold Networks (KANs) \u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u5206\u7c7b\u4e2d\u8868\u73b0\u4f18\u4e8e\u6807\u51c6\u795e\u7ecf\u7f51\u7edc\uff08MLPs\uff09\uff0c\u4f46\u4f20\u7edf\u4e0d\u5e73\u8861\u7b56\u7565\u4e0eKANs\u51b2\u7a81\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\u3002MLPs\u7ed3\u5408\u4e0d\u5e73\u8861\u6280\u672f\u53ef\u8fbe\u5230\u4e0eKANs\u76f8\u5f53\u7684\u6548\u679c\uff0c\u4f46\u8d44\u6e90\u6d88\u8017\u66f4\u4f4e\u3002", "motivation": "\u7814\u7a76KANs\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u5206\u7c7b\u4e2d\u7684\u8868\u73b0\uff0c\u63a2\u7d22\u5176\u4e0e\u4f20\u7edf\u4e0d\u5e73\u8861\u7b56\u7565\u7684\u517c\u5bb9\u6027\u53ca\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u5728\u5341\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5bf9KANs\u548cMLPs\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u6bd4\u8f83\u5176\u5728\u539f\u59cb\u4e0d\u5e73\u8861\u6570\u636e\u548c\u4f7f\u7528\u4e0d\u5e73\u8861\u7b56\u7565\u540e\u7684\u8868\u73b0\u3002", "result": "KANs\u5728\u539f\u59cb\u4e0d\u5e73\u8861\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u4e8eMLPs\uff0c\u4f46\u4f20\u7edf\u4e0d\u5e73\u8861\u7b56\u7565\u663e\u8457\u964d\u4f4e\u5176\u6027\u80fd\u3002MLPs\u7ed3\u5408\u4e0d\u5e73\u8861\u6280\u672f\u53ef\u8fbe\u5230\u4e0eKANs\u76f8\u5f53\u7684\u6548\u679c\uff0c\u4e14\u8d44\u6e90\u6d88\u8017\u66f4\u4f4e\u3002", "conclusion": "KANs\u9002\u7528\u4e8e\u8d44\u6e90\u5145\u8db3\u7684\u539f\u59cb\u4e0d\u5e73\u8861\u6570\u636e\u573a\u666f\uff0c\u4f46\u5176\u6027\u80fd\u4e0e\u8d44\u6e90\u6d88\u8017\u7684\u6743\u8861\u53ca\u4e0e\u4f20\u7edf\u7b56\u7565\u7684\u51b2\u7a81\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u672a\u6765\u9700\u4f18\u5316KANs\u7684\u67b6\u6784\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2507.14126", "pdf": "https://arxiv.org/pdf/2507.14126", "abs": "https://arxiv.org/abs/2507.14126", "authors": ["Jianhong Chen", "Meng Zhao", "Mostafa Reisi Gahrooei", "Xubo Yue"], "title": "Toward Temporal Causal Representation Learning with Tensor Decomposition", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Temporal causal representation learning is a powerful tool for uncovering\ncomplex patterns in observational studies, which are often represented as\nlow-dimensional time series. However, in many real-world applications, data are\nhigh-dimensional with varying input lengths and naturally take the form of\nirregular tensors. To analyze such data, irregular tensor decomposition is\ncritical for extracting meaningful clusters that capture essential information.\nIn this paper, we focus on modeling causal representation learning based on the\ntransformed information. First, we present a novel causal formulation for a set\nof latent clusters. We then propose CaRTeD, a joint learning framework that\nintegrates temporal causal representation learning with irregular tensor\ndecomposition. Notably, our framework provides a blueprint for downstream tasks\nusing the learned tensor factors, such as modeling latent structures and\nextracting causal information, and offers a more flexible regularization design\nto enhance tensor decomposition. Theoretically, we show that our algorithm\nconverges to a stationary point. More importantly, our results fill the gap in\ntheoretical guarantees for the convergence of state-of-the-art irregular tensor\ndecomposition. Experimental results on synthetic and real-world electronic\nhealth record (EHR) datasets (MIMIC-III), with extensive benchmarks from both\nphenotyping and network recovery perspectives, demonstrate that our proposed\nmethod outperforms state-of-the-art techniques and enhances the explainability\nof causal representations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u65f6\u95f4\u56e0\u679c\u8868\u793a\u5b66\u4e60\u4e0e\u975e\u89c4\u5219\u5f20\u91cf\u5206\u89e3\u7684\u6846\u67b6CaRTeD\uff0c\u7528\u4e8e\u5904\u7406\u9ad8\u7ef4\u4e0d\u89c4\u5219\u6570\u636e\uff0c\u5e76\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u6570\u636e\u5e38\u4e3a\u9ad8\u7ef4\u4e14\u4e0d\u89c4\u5219\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u63d0\u53d6\u56e0\u679c\u8868\u793a\u548c\u5206\u89e3\u4e0d\u89c4\u5219\u5f20\u91cf\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faCaRTeD\u6846\u67b6\uff0c\u7ed3\u5408\u65f6\u95f4\u56e0\u679c\u8868\u793a\u5b66\u4e60\u4e0e\u975e\u89c4\u5219\u5f20\u91cf\u5206\u89e3\uff0c\u63d0\u4f9b\u7075\u6d3b\u7684\u6b63\u5219\u5316\u8bbe\u8ba1\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u7b97\u6cd5\u6536\u655b\uff0c\u5b9e\u9a8c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\uff08\u5982MIMIC-III\uff09\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "CaRTeD\u586b\u8865\u4e86\u7406\u8bba\u7a7a\u767d\uff0c\u63d0\u5347\u4e86\u56e0\u679c\u8868\u793a\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u9002\u7528\u4e8e\u4e0b\u6e38\u4efb\u52a1\u3002"}}
{"id": "2507.12182", "pdf": "https://arxiv.org/pdf/2507.12182", "abs": "https://arxiv.org/abs/2507.12182", "authors": ["Ievgenii Afanasiev", "Leonid Berlyand", "Mariia Kiyashko"], "title": "Asymptotic behavior of eigenvalues of large rank perturbations of large random matrices", "categories": ["math-ph", "cs.LG", "math.MP", "math.PR", "60B20, 15B52"], "comment": "14 pages, 3 figures", "summary": "The paper is concerned with deformed Wigner random matrices. These matrices\nare closely connected with Deep Neural Networks (DNNs): weight matrices of\ntrained DNNs could be represented in the form $R + S$, where $R$ is random and\n$S$ is highly correlated. The spectrum of such matrices plays a key role in\nrigorous underpinning of the novel pruning technique based on Random Matrix\nTheory. Mathematics has been done only for finite-rank matrix $S$. However, in\npractice rank may grow. In this paper we develop asymptotic analysis for the\ncase of growing rank.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u53d8\u5f62Wigner\u968f\u673a\u77e9\u9635\u53ca\u5176\u4e0e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNNs\uff09\u7684\u8054\u7cfb\uff0c\u63d0\u51fa\u4e86\u9488\u5bf9\u79e9\u589e\u957f\u60c5\u51b5\u7684\u6e10\u8fd1\u5206\u6790\u65b9\u6cd5\u3002", "motivation": "DNNs\u7684\u6743\u91cd\u77e9\u9635\u53ef\u8868\u793a\u4e3a\u968f\u673a\u90e8\u5206\u4e0e\u9ad8\u5ea6\u76f8\u5173\u90e8\u5206\u7684\u7ec4\u5408\uff0c\u5176\u8c31\u7279\u6027\u5bf9\u57fa\u4e8e\u968f\u673a\u77e9\u9635\u7406\u8bba\u7684\u526a\u679d\u6280\u672f\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6b64\u524d\u7814\u7a76\u4ec5\u9650\u4e8e\u6709\u9650\u79e9\u60c5\u51b5\u3002", "method": "\u5f00\u53d1\u4e86\u9488\u5bf9\u79e9\u589e\u957f\u60c5\u51b5\u7684\u6e10\u8fd1\u5206\u6790\u65b9\u6cd5\u3002", "result": "\u4e3a\u79e9\u589e\u957f\u60c5\u51b5\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aDNNs\u526a\u679d\u6280\u672f\u7684\u7406\u8bba\u57fa\u7840\u63d0\u4f9b\u4e86\u6269\u5c55\u3002"}}
{"id": "2507.13355", "pdf": "https://arxiv.org/pdf/2507.13355", "abs": "https://arxiv.org/abs/2507.13355", "authors": ["Riadul Islam", "Dhandeep Challagundla"], "title": "PGR-DRC: Pre-Global Routing DRC Violation Prediction Using Unsupervised Learning", "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Leveraging artificial intelligence (AI)-driven electronic design and\nautomation (EDA) tools, high-performance computing, and parallelized algorithms\nare essential for next-generation microprocessor innovation, ensuring continued\nprogress in computing, AI, and semiconductor technology. Machine learning-based\ndesign rule checking (DRC) and lithography hotspot detection can improve\nfirst-pass silicon success. However, conventional ML and neural network\n(NN)-based models use supervised learning and require a large balanced dataset\n(in terms of positive and negative classes) and training time. This research\naddresses those key challenges by proposing the first-ever unsupervised DRC\nviolation prediction methodology. The proposed model can be built using any\nunbalanced dataset using only one class and set a threshold for it, then\nfitting any new data querying if they are within the boundary of the model for\nclassification. This research verified the proposed model by implementing\ndifferent computational cores using CMOS 28 nm technology and Synopsys Design\nCompiler and IC Compiler II tools. Then, layouts were divided into virtual\ngrids to collect about 60k data for analysis and verification. The proposed\nmethod has 99.95% prediction test accuracy, while the existing support vector\nmachine (SVM) and neural network (NN) models have 85.44\\% and 98.74\\% accuracy,\nrespectively. In addition, the proposed methodology has about 26.3x and up to\n6003x lower training times compared to SVM and NN-models, respectively.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u76d1\u7763\u7684DRC\u8fdd\u89c4\u9884\u6d4b\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u5e73\u8861\u6570\u636e\u96c6\u548c\u8bad\u7ec3\u65f6\u95f4\u7684\u95ee\u9898\uff0c\u9a8c\u8bc1\u4e86\u9ad8\u51c6\u786e\u6027\u548c\u9ad8\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u548c\u795e\u7ecf\u7f51\u7edc\u7684DRC\u68c0\u6d4b\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u5e73\u8861\u6570\u636e\u96c6\u548c\u8bad\u7ec3\u65f6\u95f4\uff0c\u9650\u5236\u4e86\u5176\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u65e0\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ec5\u9700\u5355\u7c7b\u4e0d\u5e73\u8861\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u8bbe\u5b9a\u9608\u503c\u5bf9\u65b0\u6570\u636e\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u572828\u7eb3\u7c73CMOS\u6280\u672f\u4e0b\u9a8c\u8bc1\uff0c\u9884\u6d4b\u51c6\u786e\u7387\u8fbe99.95%\uff0c\u8bad\u7ec3\u65f6\u95f4\u663e\u8457\u4f4e\u4e8eSVM\u548cNN\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86DRC\u68c0\u6d4b\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u4e0b\u4e00\u4ee3EDA\u5de5\u5177\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.13369", "pdf": "https://arxiv.org/pdf/2507.13369", "abs": "https://arxiv.org/abs/2507.13369", "authors": ["Paul E. Calzada", "Zahin Ibnat", "Tanvir Rahman", "Kamal Kandula", "Danyu Lu", "Sujan Kumar Saha", "Farimah Farahmandi", "Mark Tehranipoor"], "title": "VerilogDB: The Largest, Highest-Quality Dataset with a Preprocessing Framework for LLM-based RTL Generation", "categories": ["cs.AR", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) are gaining popularity for hardware design\nautomation, particularly through Register Transfer Level (RTL) code generation.\nIn this work, we examine the current literature on RTL generation using LLMs\nand identify key requirements for training and fine-tuning datasets. We\nconstruct a robust Verilog dataset through an automated three-pronged process\ninvolving database (DB) creation and management with PostgreSQL, data\ncollection from code hosting sites like OpenCores and GitHub, and data\npreprocessing to verify the codes' syntax, run logic synthesis, and extract\nrelevant module metadata. We implement a scalable and efficient DB\ninfrastructure to support analysis and detail our preprocessing pipeline to\nenforce high-quality data before DB insertion. The resulting dataset comprises\n20,392 Verilog samples, 751 MB of Verilog code data, which is the largest\nhigh-quality Verilog dataset for LLM fine-tuning to our knowledge. We further\nevaluate the dataset, address associated challenges, and explore potential\napplications for future research and development in LLM-based hardware\ngeneration.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u786c\u4ef6\u8bbe\u8ba1RTL\u4ee3\u7801\u7684\u73b0\u72b6\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u9ad8\u8d28\u91cfVerilog\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u5176\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u5f53\u524dLLM\u5728\u786c\u4ef6\u8bbe\u8ba1\u81ea\u52a8\u5316\u4e2d\u7684\u5e94\u7528\u9700\u6c42\u589e\u957f\uff0c\u4f46\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u3002", "method": "\u901a\u8fc7\u81ea\u52a8\u5316\u4e09\u6b65\u9aa4\u6d41\u7a0b\uff08\u6570\u636e\u5e93\u521b\u5efa\u3001\u6570\u636e\u6536\u96c6\u3001\u9884\u5904\u7406\uff09\u6784\u5efaVerilog\u6570\u636e\u96c6\uff0c\u5e76\u5b9e\u73b0\u9ad8\u6548\u6570\u636e\u5e93\u57fa\u7840\u8bbe\u65bd\u3002", "result": "\u751f\u6210\u4e8620,392\u4e2aVerilog\u6837\u672c\uff08751 MB\uff09\uff0c\u662f\u76ee\u524d\u6700\u5927\u7684\u9ad8\u8d28\u91cfVerilog\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3aLLM\u5728\u786c\u4ef6\u751f\u6210\u4e2d\u7684\u672a\u6765\u7814\u7a76\u548c\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\u3002"}}
{"id": "2507.13376", "pdf": "https://arxiv.org/pdf/2507.13376", "abs": "https://arxiv.org/abs/2507.13376", "authors": ["Dong Xiao", "Zahra Sharif-Khodaei", "M. H. Aliabadi"], "title": "Physics-guided impact localisation and force estimation in composite plates with uncertainty quantification", "categories": ["physics.data-an", "cond-mat.mtrl-sci", "cs.LG", "physics.app-ph"], "comment": "37 pages (including the appendix and references), 16 figures", "summary": "Physics-guided approaches offer a promising path toward accurate and\ngeneralisable impact identification in composite structures, especially when\nexperimental data are sparse. This paper presents a hybrid framework for impact\nlocalisation and force estimation in composite plates, combining a data-driven\nimplementation of First-Order Shear Deformation Theory (FSDT) with machine\nlearning and uncertainty quantification. The structural configuration and\nmaterial properties are inferred from dispersion relations, while boundary\nconditions are identified via modal characteristics to construct a low-fidelity\nbut physically consistent FSDT model. This model enables physics-informed data\naugmentation for extrapolative localisation using supervised learning.\nSimultaneously, an adaptive regularisation scheme derived from the same model\nimproves the robustness of impact force reconstruction. The framework also\naccounts for uncertainty by propagating localisation uncertainty through the\nforce estimation process, producing probabilistic outputs. Validation on\ncomposite plate experiments confirms the framework's accuracy, robustness, and\nefficiency in reducing dependence on large training datasets. The proposed\nmethod offers a scalable and transferable solution for impact monitoring and\nstructural health management in composite aerostructures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7269\u7406\u6a21\u578b\u548c\u673a\u5668\u5b66\u4e60\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u590d\u5408\u6750\u6599\u677f\u7684\u51b2\u51fb\u5b9a\u4f4d\u548c\u529b\u4f30\u8ba1\uff0c\u51cf\u5c11\u4e86\u5b9e\u9a8c\u6570\u636e\u9700\u6c42\u3002", "motivation": "\u89e3\u51b3\u590d\u5408\u6750\u6599\u7ed3\u6784\u4e2d\u51b2\u51fb\u8bc6\u522b\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u5b9e\u9a8c\u6570\u636e\u7a00\u7f3a\u65f6\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u7ed3\u5408\u4e00\u9636\u526a\u5207\u53d8\u5f62\u7406\u8bba\uff08FSDT\uff09\u3001\u673a\u5668\u5b66\u4e60\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u901a\u8fc7\u7269\u7406\u6a21\u578b\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u548c\u81ea\u9002\u5e94\u6b63\u5219\u5316\u3002", "result": "\u5728\u590d\u5408\u6750\u6599\u677f\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u5bf9\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u7684\u4f9d\u8d56\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u590d\u5408\u6750\u6599\u822a\u7a7a\u7ed3\u6784\u7684\u51b2\u51fb\u76d1\u6d4b\u548c\u5065\u5eb7\u7ba1\u7406\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u548c\u53ef\u8f6c\u79fb\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.13381", "pdf": "https://arxiv.org/pdf/2507.13381", "abs": "https://arxiv.org/abs/2507.13381", "authors": ["Rafiq Kamel", "Filippo Guerranti", "Simon Geisler", "Stephan G\u00fcnnemann"], "title": "SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted at the KDD2025 Workshop on Structured Knowledge for LLMs", "summary": "Large Language Models (LLMs) are increasingly applied to tasks involving\nstructured inputs such as graphs. Abstract Meaning Representations (AMRs),\nwhich encode rich semantics as directed graphs, offer a rigorous testbed for\nevaluating LLMs on text generation from such structures. Yet, current methods\noften arbitrarily linearize AMRs, discarding key structural cues, or rely on\narchitectures incompatible with standard LLMs. We introduce SAFT, a\nstructure-aware fine-tuning approach that injects graph topology into\npretrained LLMs without architectural changes. We compute direction-sensitive\npositional encodings from the magnetic Laplacian of transformed AMRs and\nproject them into the embedding space of the LLM. While possibly applicable to\nany graph-structured inputs, we focus on AMR-to-text generation as a\nrepresentative and challenging benchmark. SAFT sets a new state-of-the-art on\nAMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph\ncomplexity, highlighting the value of structure-aware representations in\nenhancing LLM performance. SAFT offers a general and effective pathway for\nbridging structured data and language models.", "AI": {"tldr": "SAFT\u662f\u4e00\u79cd\u7ed3\u6784\u611f\u77e5\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u6ce8\u5165\u56fe\u62d3\u6251\u4fe1\u606f\u5230\u9884\u8bad\u7ec3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u4e86AMR\u5230\u6587\u672c\u751f\u6210\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u5728\u5904\u7406\u62bd\u8c61\u610f\u4e49\u8868\u793a\uff08AMRs\uff09\u65f6\uff0c\u5e38\u5ffd\u7565\u7ed3\u6784\u4fe1\u606f\u6216\u4f7f\u7528\u4e0e\u6807\u51c6LLMs\u4e0d\u517c\u5bb9\u7684\u67b6\u6784\uff0c\u9650\u5236\u4e86\u6027\u80fd\u3002", "method": "SAFT\u5229\u7528\u78c1\u62c9\u666e\u62c9\u65af\u53d8\u6362\u8ba1\u7b97\u65b9\u5411\u654f\u611f\u7684\u4f4d\u7f6e\u7f16\u7801\uff0c\u5e76\u5c06\u5176\u6295\u5f71\u5230LLM\u7684\u5d4c\u5165\u7a7a\u95f4\u4e2d\uff0c\u65e0\u9700\u6539\u53d8\u6a21\u578b\u67b6\u6784\u3002", "result": "\u5728AMR 3.0\u4e0a\uff0cSAFT\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u4e863.5 BLEU\u5206\u6570\uff0c\u4e14\u6027\u80fd\u63d0\u5347\u968f\u56fe\u590d\u6742\u5ea6\u589e\u52a0\u800c\u663e\u8457\u3002", "conclusion": "SAFT\u4e3a\u7ed3\u6784\u5316\u6570\u636e\u4e0e\u8bed\u8a00\u6a21\u578b\u7684\u7ed3\u5408\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u4e14\u9ad8\u6548\u7684\u9014\u5f84\u3002"}}
{"id": "2507.13382", "pdf": "https://arxiv.org/pdf/2507.13382", "abs": "https://arxiv.org/abs/2507.13382", "authors": ["Chandrashekar Muniyappa", "Sirisha Velampalli"], "title": "Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case", "categories": ["cs.CL", "cs.LG", "05-05C12"], "comment": "CSAIDE '25: Proceedings of the 2025 4th International Conference on\n  Cyber Security, Artificial Intelligence and the Digital Economy", "summary": "In today\\'s digital world, fake news is spreading with immense speed. Its a\nsignificant concern to address. In this work, we addressed that challenge using\nnovel graph based approach. We took dataset from Kaggle that contains real and\nfake news articles. To test our approach we incorporated recent covid-19\nrelated news articles that contains both genuine and fake news that are\nrelevant to this problem. This further enhances the dataset as well instead of\nrelying completely on the original dataset. We propose a contextual graph-based\napproach to detect fake news articles. We need to convert news articles into\nappropriate schema, so we leverage Natural Language Processing (NLP) techniques\nto transform news articles into contextual graph structures. We then apply the\nMinimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD)\nalgorithm for graph mining. Graph-based methods are particularly effective for\nhandling rich contextual data, as they enable the discovery of complex patterns\nthat traditional query-based or statistical techniques might overlook. Our\nproposed approach identifies normative patterns within the dataset and\nsubsequently uncovers anomalous patterns that deviate from these established\nnorms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u4e0a\u4e0b\u6587\u65b9\u6cd5\uff0c\u7ed3\u5408NLP\u548cMDL-GBAD\u7b97\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u5047\u65b0\u95fb\u3002", "motivation": "\u89e3\u51b3\u6570\u5b57\u4e16\u754c\u4e2d\u5047\u65b0\u95fb\u5feb\u901f\u4f20\u64ad\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528NLP\u5c06\u65b0\u95fb\u6587\u7ae0\u8f6c\u6362\u4e3a\u56fe\u7ed3\u6784\uff0c\u5e76\u5e94\u7528MDL-GBAD\u7b97\u6cd5\u8fdb\u884c\u56fe\u6316\u6398\u548c\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u65b9\u6cd5\u80fd\u591f\u8bc6\u522b\u6570\u636e\u96c6\u4e2d\u7684\u89c4\u8303\u6a21\u5f0f\u5e76\u53d1\u73b0\u5f02\u5e38\u6a21\u5f0f\u3002", "conclusion": "\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\u5728\u68c0\u6d4b\u5047\u65b0\u95fb\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u53d1\u73b0\u590d\u6742\u6a21\u5f0f\u3002"}}
{"id": "2507.13384", "pdf": "https://arxiv.org/pdf/2507.13384", "abs": "https://arxiv.org/abs/2507.13384", "authors": ["Osama Hardan", "Omar Elshenhabi", "Tamer Khattab", "Mohamed Mabrok"], "title": "Flatten Wisely: How Patch Order Shapes Mamba-Powered Vision for MRI Segmentation", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "Submitted to the 2025 IEEE International Conference on Future Machine\n  Learning and Data Science (FMLDS)", "summary": "Vision Mamba models promise transformer-level performance at linear\ncomputational cost, but their reliance on serializing 2D images into 1D\nsequences introduces a critical, yet overlooked, design choice: the patch scan\norder. In medical imaging, where modalities like brain MRI contain strong\nanatomical priors, this choice is non-trivial. This paper presents the first\nsystematic study of how scan order impacts MRI segmentation. We introduce\nMulti-Scan 2D (MS2D), a parameter-free module for Mamba-based architectures\nthat facilitates exploring diverse scan paths without additional computational\ncost. We conduct a large-scale benchmark of 21 scan strategies on three public\ndatasets (BraTS 2020, ISLES 2022, LGG), covering over 70,000 slices. Our\nanalysis shows conclusively that scan order is a statistically significant\nfactor (Friedman test: $\\chi^{2}_{20}=43.9, p=0.0016$), with performance\nvarying by as much as 27 Dice points. Spatially contiguous paths -- simple\nhorizontal and vertical rasters -- consistently outperform disjointed diagonal\nscans. We conclude that scan order is a powerful, cost-free hyperparameter, and\nprovide an evidence-based shortlist of optimal paths to maximize the\nperformance of Mamba models in medical imaging.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Vision Mamba\u6a21\u578b\u4e2d\u56fe\u50cf\u626b\u63cf\u987a\u5e8f\u5bf9MRI\u5206\u5272\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u53c2\u6570\u6a21\u5757MS2D\uff0c\u5e76\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u9a8c\u8bc1\u660e\u626b\u63cf\u987a\u5e8f\u662f\u663e\u8457\u5f71\u54cd\u6027\u80fd\u7684\u56e0\u7d20\u3002", "motivation": "Vision Mamba\u6a21\u578b\u5728\u533b\u5b66\u56fe\u50cf\u5904\u7406\u4e2d\u4f9d\u8d561D\u5e8f\u5217\u53162D\u56fe\u50cf\uff0c\u4f46\u626b\u63cf\u987a\u5e8f\u7684\u8bbe\u8ba1\u9009\u62e9\u672a\u88ab\u5145\u5206\u7814\u7a76\uff0c\u5c24\u5176\u5728\u5177\u6709\u5f3a\u89e3\u5256\u5148\u9a8c\u7684MRI\u4e2d\u3002", "method": "\u5f15\u5165MS2D\u6a21\u5757\uff0c\u652f\u6301\u591a\u79cd\u626b\u63cf\u8def\u5f84\u7684\u63a2\u7d22\uff0c\u5e76\u5728\u4e09\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u5bf921\u79cd\u626b\u63cf\u7b56\u7565\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u9a8c\u3002", "result": "\u626b\u63cf\u987a\u5e8f\u5bf9\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff08Friedman\u68c0\u9a8c\uff1a\u03c7\u00b2=43.9, p=0.0016\uff09\uff0c\u6027\u80fd\u5dee\u5f02\u53ef\u8fbe27 Dice\u70b9\uff0c\u8fde\u7eed\u626b\u63cf\u8def\u5f84\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u626b\u63cf\u987a\u5e8f\u662f\u65e0\u9700\u989d\u5916\u6210\u672c\u7684\u9ad8\u6548\u8d85\u53c2\u6570\uff0c\u7814\u7a76\u63d0\u4f9b\u4e86\u4f18\u5316\u8def\u5f84\u7684\u5b9e\u8bc1\u5efa\u8bae\u3002"}}
{"id": "2507.13385", "pdf": "https://arxiv.org/pdf/2507.13385", "abs": "https://arxiv.org/abs/2507.13385", "authors": ["Arjun Rao", "Esther Rolf"], "title": "Using Multiple Input Modalities Can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery", "categories": ["cs.CV", "cs.LG"], "comment": "17 pages, 9 figures, 7 tables. Accepted to TerraBytes@ICML 2025", "summary": "A large variety of geospatial data layers is available around the world\nranging from remotely-sensed raster data like satellite imagery, digital\nelevation models, predicted land cover maps, and human-annotated data, to data\nderived from environmental sensors such as air temperature or wind speed data.\nA large majority of machine learning models trained on satellite imagery\n(SatML), however, are designed primarily for optical input modalities such as\nmulti-spectral satellite imagery. To better understand the value of using other\ninput modalities alongside optical imagery in supervised learning settings, we\ngenerate augmented versions of SatML benchmark tasks by appending additional\ngeographic data layers to datasets spanning classification, regression, and\nsegmentation. Using these augmented datasets, we find that fusing additional\ngeographic inputs with optical imagery can significantly improve SatML model\nperformance. Benefits are largest in settings where labeled data are limited\nand in geographic out-of-sample settings, suggesting that multi-modal inputs\nmay be especially valuable for data-efficiency and out-of-sample performance of\nSatML models. Surprisingly, we find that hard-coded fusion strategies\noutperform learned variants, with interesting implications for future work.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u536b\u661f\u56fe\u50cf\u673a\u5668\u5b66\u4e60\uff08SatML\uff09\u4e2d\u7ed3\u5408\u5176\u4ed6\u5730\u7406\u6570\u636e\u5c42\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u591a\u6a21\u6001\u8f93\u5165\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5c24\u5176\u5728\u6570\u636e\u6709\u9650\u548c\u8de8\u533a\u57df\u6d4b\u8bd5\u65f6\u3002", "motivation": "\u7814\u7a76\u5176\u4ed6\u5730\u7406\u6570\u636e\u5c42\uff08\u5982\u9ad8\u7a0b\u6a21\u578b\u3001\u4f20\u611f\u5668\u6570\u636e\u7b49\uff09\u4e0e\u5149\u5b66\u536b\u661f\u56fe\u50cf\u7ed3\u5408\u5728\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u4ef7\u503c\uff0c\u4ee5\u63d0\u5347SatML\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u751f\u6210\u589e\u5f3a\u7248\u7684SatML\u57fa\u51c6\u4efb\u52a1\u6570\u636e\u96c6\uff0c\u5c06\u989d\u5916\u5730\u7406\u6570\u636e\u5c42\u4e0e\u5149\u5b66\u56fe\u50cf\u7ed3\u5408\uff0c\u7528\u4e8e\u5206\u7c7b\u3001\u56de\u5f52\u548c\u5206\u5272\u4efb\u52a1\u3002", "result": "\u591a\u6a21\u6001\u8f93\u5165\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u5c24\u5176\u5728\u6570\u636e\u6709\u9650\u548c\u8de8\u533a\u57df\u6d4b\u8bd5\u65f6\uff1b\u786c\u7f16\u7801\u878d\u5408\u7b56\u7565\u4f18\u4e8e\u5b66\u4e60\u578b\u7b56\u7565\u3002", "conclusion": "\u591a\u6a21\u6001\u8f93\u5165\u5bf9SatML\u7684\u6570\u636e\u6548\u7387\u548c\u8de8\u533a\u57df\u6027\u80fd\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u786c\u7f16\u7801\u878d\u5408\u7b56\u7565\u503c\u5f97\u672a\u6765\u7814\u7a76\u5173\u6ce8\u3002"}}
{"id": "2507.13386", "pdf": "https://arxiv.org/pdf/2507.13386", "abs": "https://arxiv.org/abs/2507.13386", "authors": ["Yang Zhang", "Er Jin", "Yanfei Dong", "Yixuan Wu", "Philip Torr", "Ashkan Khakzar", "Johannes Stegmaier", "Kenji Kawaguchi"], "title": "Minimalist Concept Erasure in Generative Models", "categories": ["cs.CV", "cs.LG"], "comment": "ICML2025", "summary": "Recent advances in generative models have demonstrated remarkable\ncapabilities in producing high-quality images, but their reliance on\nlarge-scale unlabeled data has raised significant safety and copyright\nconcerns. Efforts to address these issues by erasing unwanted concepts have\nshown promise. However, many existing erasure methods involve excessive\nmodifications that compromise the overall utility of the model. In this work,\nwe address these issues by formulating a novel minimalist concept erasure\nobjective based \\emph{only} on the distributional distance of final generation\noutputs. Building on our formulation, we derive a tractable loss for\ndifferentiable optimization that leverages backpropagation through all\ngeneration steps in an end-to-end manner. We also conduct extensive analysis to\nshow theoretical connections with other models and methods. To improve the\nrobustness of the erasure, we incorporate neuron masking as an alternative to\nmodel fine-tuning. Empirical evaluations on state-of-the-art flow-matching\nmodels demonstrate that our method robustly erases concepts without degrading\noverall model performance, paving the way for safer and more responsible\ngenerative models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u8f93\u51fa\u5206\u5e03\u8ddd\u79bb\u7684\u6700\u5c0f\u5316\u6982\u5ff5\u64e6\u9664\u65b9\u6cd5\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u4f18\u5316\u548c\u795e\u7ecf\u5143\u63a9\u7801\u6280\u672f\uff0c\u5728\u4e0d\u635f\u5bb3\u6a21\u578b\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u64e6\u9664\u6982\u5ff5\u3002", "motivation": "\u751f\u6210\u6a21\u578b\u4f9d\u8d56\u5927\u89c4\u6a21\u65e0\u6807\u7b7e\u6570\u636e\u5f15\u53d1\u5b89\u5168\u548c\u7248\u6743\u95ee\u9898\uff0c\u73b0\u6709\u64e6\u9664\u65b9\u6cd5\u8fc7\u5ea6\u4fee\u6539\u6a21\u578b\uff0c\u635f\u5bb3\u5176\u6574\u4f53\u6548\u7528\u3002", "method": "\u57fa\u4e8e\u751f\u6210\u8f93\u51fa\u5206\u5e03\u8ddd\u79bb\u8bbe\u8ba1\u76ee\u6807\u51fd\u6570\uff0c\u5229\u7528\u53cd\u5411\u4f20\u64ad\u8fdb\u884c\u7aef\u5230\u7aef\u4f18\u5316\uff0c\u5e76\u5f15\u5165\u795e\u7ecf\u5143\u63a9\u7801\u589e\u5f3a\u9c81\u68d2\u6027\u3002", "result": "\u5728\u5148\u8fdb\u6d41\u5339\u914d\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u64e6\u9664\u6982\u5ff5\u4e14\u4e0d\u964d\u4f4e\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u66f4\u5b89\u5168\u3001\u8d1f\u8d23\u4efb\u7684\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2507.13390", "pdf": "https://arxiv.org/pdf/2507.13390", "abs": "https://arxiv.org/abs/2507.13390", "authors": ["Kundeshwar Pundalik", "Piyush Sawarkar", "Nihar Sahoo", "Abhishek Shinde", "Prateek Chanda", "Vedant Goswami", "Ajay Nagpal", "Atul Singh", "Viraj Thakur", "Vijay Dewane", "Aamod Thakur", "Bhargav Patel", "Smita Gautam", "Bhagwan Panditi", "Shyam Pawar", "Madhav Kotcha", "Suraj Racha", "Saral Sureka", "Pankaj Singh", "Rishi Bal", "Rohit Saluja", "Ganesh Ramakrishnan"], "title": "PARAM-1 BharatGen 2.9B Model", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have emerged as powerful general-purpose\nreasoning systems, yet their development remains dominated by English-centric\ndata, architectures, and optimization paradigms. This exclusionary design\nresults in structural under-representation of linguistically diverse regions\nsuch as India, where over 20 official languages and 100+ dialects coexist\nalongside phenomena like code-switching and diglossia. We introduce PARAM-1, a\n2.9B parameter decoder-only, text-only language model trained from scratch with\nan explicit architectural and linguistic focus on Indian diversity. PARAM-1 is\ntrained on a bilingual dataset consisting of only Hindi and English,\nconstructed with a strong focus on fact-rich, high-quality content. It is\nguided by three core principles: equitable representation of Indic languages\nthrough a 25% corpus allocation; tokenization fairness via a SentencePiece\ntokenizer adapted to Indian morphological structures; and culturally aligned\nevaluation benchmarks across IndicQA, code-mixed reasoning, and\nsocio-linguistic robustness tasks. By embedding diversity at the pretraining\nlevel-rather than deferring it to post-hoc alignment-PARAM-1 offers a\ndesign-first blueprint for equitable foundation modeling. Our results\ndemonstrate that it serves as both a competent general-purpose model and a\nrobust baseline for India-centric applications.", "AI": {"tldr": "PARAM-1\u662f\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u5370\u5ea6\u8bed\u8a00\u591a\u6837\u6027\u76842.9B\u53c2\u6570\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u516c\u5e73\u7684\u6570\u636e\u5206\u914d\u3001\u9002\u5e94\u5370\u5ea6\u5f62\u6001\u7684\u6807\u8bb0\u5316\u548c\u6587\u5316\u5bf9\u9f50\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u516c\u5e73\u7684\u57fa\u7840\u6a21\u578b\u8bbe\u8ba1\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5f00\u53d1\u4ee5\u82f1\u8bed\u4e3a\u4e2d\u5fc3\uff0c\u5bfc\u81f4\u5370\u5ea6\u7b49\u591a\u8bed\u8a00\u5730\u533a\u7684\u8bed\u8a00\u591a\u6837\u6027\u88ab\u5ffd\u89c6\u3002PARAM-1\u65e8\u5728\u901a\u8fc7\u4e13\u6ce8\u4e8e\u5370\u5ea6\u8bed\u8a00\u591a\u6837\u6027\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "PARAM-1\u662f\u4e00\u4e2a\u4ec5\u89e3\u7801\u5668\u3001\u4ec5\u6587\u672c\u7684\u6a21\u578b\uff0c\u8bad\u7ec3\u4e8e\u5370\u5730\u8bed\u548c\u82f1\u8bed\u7684\u53cc\u8bed\u6570\u636e\u96c6\uff0c\u91c7\u7528\u516c\u5e73\u7684\u8bed\u6599\u5206\u914d\u3001\u9002\u5e94\u5370\u5ea6\u5f62\u6001\u7684\u6807\u8bb0\u5316\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u6587\u5316\u5bf9\u9f50\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "result": "PARAM-1\u65e2\u662f\u4e00\u4e2a\u901a\u7528\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u4e5f\u662f\u5370\u5ea6\u4e2d\u5fc3\u5e94\u7528\u7684\u5f3a\u5927\u57fa\u7ebf\u3002", "conclusion": "PARAM-1\u901a\u8fc7\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u5d4c\u5165\u591a\u6837\u6027\uff0c\u4e3a\u516c\u5e73\u7684\u57fa\u7840\u6a21\u578b\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u84dd\u56fe\u3002"}}
{"id": "2507.13401", "pdf": "https://arxiv.org/pdf/2507.13401", "abs": "https://arxiv.org/abs/2507.13401", "authors": ["Shreya Kadambi", "Risheek Garrepalli", "Shubhankar Borse", "Munawar Hyatt", "Fatih Porikli"], "title": "MADI: Masking-Augmented Diffusion with Inference-Time Scaling for Visual Editing", "categories": ["cs.CV", "cs.LG"], "comment": "26 pages", "summary": "Despite the remarkable success of diffusion models in text-to-image\ngeneration, their effectiveness in grounded visual editing and compositional\ncontrol remains challenging. Motivated by advances in self-supervised learning\nand in-context generative modeling, we propose a series of simple yet powerful\ndesign choices that significantly enhance diffusion model capacity for\nstructured, controllable generation and editing. We introduce Masking-Augmented\nDiffusion with Inference-Time Scaling (MADI), a framework that improves the\neditability, compositionality and controllability of diffusion models through\ntwo core innovations. First, we introduce Masking-Augmented gaussian Diffusion\n(MAgD), a novel training strategy with dual corruption process which combines\nstandard denoising score matching and masked reconstruction by masking noisy\ninput from forward process. MAgD encourages the model to learn discriminative\nand compositional visual representations, thus enabling localized and\nstructure-aware editing. Second, we introduce an inference-time capacity\nscaling mechanism based on Pause Tokens, which act as special placeholders\ninserted into the prompt for increasing computational capacity at inference\ntime. Our findings show that adopting expressive and dense prompts during\ntraining further enhances performance, particularly for MAgD. Together, these\ncontributions in MADI substantially enhance the editability of diffusion\nmodels, paving the way toward their integration into more general-purpose,\nin-context generative diffusion architectures.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMADI\u7684\u6846\u67b6\uff0c\u901a\u8fc7Masking-Augmented gaussian Diffusion (MAgD)\u548c\u63a8\u7406\u65f6\u5bb9\u91cf\u6269\u5c55\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6269\u6563\u6a21\u578b\u7684\u53ef\u7f16\u8f91\u6027\u3001\u7ec4\u5408\u6027\u548c\u53ef\u63a7\u6027\u3002", "motivation": "\u5c3d\u7ba1\u6269\u6563\u6a21\u578b\u5728\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u5728\u57fa\u4e8e\u89c6\u89c9\u7684\u7f16\u8f91\u548c\u7ec4\u5408\u63a7\u5236\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86MADI\u6846\u67b6\uff0c\u5305\u62ecMAgD\u8bad\u7ec3\u7b56\u7565\u548c\u57fa\u4e8ePause Tokens\u7684\u63a8\u7406\u65f6\u5bb9\u91cf\u6269\u5c55\u673a\u5236\u3002", "result": "MADI\u663e\u8457\u63d0\u5347\u4e86\u6269\u6563\u6a21\u578b\u7684\u53ef\u7f16\u8f91\u6027\u548c\u7ec4\u5408\u6027\uff0c\u7279\u522b\u662f\u5728\u5c40\u90e8\u548c\u7ed3\u6784\u5316\u7f16\u8f91\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "MADI\u4e3a\u6269\u6563\u6a21\u578b\u5728\u66f4\u901a\u7528\u7684\u4e0a\u4e0b\u6587\u751f\u6210\u67b6\u6784\u4e2d\u7684\u96c6\u6210\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.13403", "pdf": "https://arxiv.org/pdf/2507.13403", "abs": "https://arxiv.org/abs/2507.13403", "authors": ["Morteza Bodaghi", "Majid Hosseini", "Raju Gottumukkala", "Ravi Teja Bhupatiraju", "Iftikhar Ahmad", "Moncef Gabbouj"], "title": "UL-DD: A Multimodal Drowsiness Dataset Using Video, Biometric Signals, and Behavioral Data", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "In this study, we present a comprehensive public dataset for driver\ndrowsiness detection, integrating multimodal signals of facial, behavioral, and\nbiometric indicators. Our dataset includes 3D facial video using a depth\ncamera, IR camera footage, posterior videos, and biometric signals such as\nheart rate, electrodermal activity, blood oxygen saturation, skin temperature,\nand accelerometer data. This data set provides grip sensor data from the\nsteering wheel and telemetry data from the American truck simulator game to\nprovide more information about drivers' behavior while they are alert and\ndrowsy. Drowsiness levels were self-reported every four minutes using the\nKarolinska Sleepiness Scale (KSS). The simulation environment consists of three\nmonitor setups, and the driving condition is completely like a car. Data were\ncollected from 19 subjects (15 M, 4 F) in two conditions: when they were fully\nalert and when they exhibited signs of sleepiness. Unlike other datasets, our\nmultimodal dataset has a continuous duration of 40 minutes for each data\ncollection session per subject, contributing to a total length of 1,400\nminutes, and we recorded gradual changes in the driver state rather than\ndiscrete alert/drowsy labels. This study aims to create a comprehensive\nmultimodal dataset of driver drowsiness that captures a wider range of\nphysiological, behavioral, and driving-related signals. The dataset will be\navailable upon request to the corresponding author.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u591a\u6a21\u6001\u9a7e\u9a76\u5458 drowsiness \u68c0\u6d4b\u6570\u636e\u96c6\uff0c\u5305\u542b\u9762\u90e8\u3001\u884c\u4e3a\u548c\u751f\u7269\u7279\u5f81\u4fe1\u53f7\uff0c\u6570\u636e\u6765\u81ea19\u540d\u53d7\u8bd5\u8005\uff0c\u603b\u65f6\u957f1400\u5206\u949f\u3002", "motivation": "\u521b\u5efa\u66f4\u5168\u9762\u7684\u9a7e\u9a76\u5458 drowsiness \u6570\u636e\u96c6\uff0c\u6355\u6349\u751f\u7406\u3001\u884c\u4e3a\u548c\u9a7e\u9a76\u76f8\u5173\u4fe1\u53f7\u7684\u8fde\u7eed\u53d8\u5316\u3002", "method": "\u6574\u54083D\u9762\u90e8\u89c6\u9891\u3001\u7ea2\u5916\u6444\u50cf\u3001\u540e\u89c6\u89c6\u9891\u3001\u751f\u7269\u7279\u5f81\u4fe1\u53f7\uff08\u5fc3\u7387\u3001\u76ae\u80a4\u7535\u6d3b\u52a8\u7b49\uff09\u53ca\u9a7e\u9a76\u6a21\u62df\u5668\u6570\u636e\uff0c\u53d7\u8bd5\u8005\u6bcf4\u5206\u949f\u81ea\u8bc4 drowsiness \u6c34\u5e73\u3002", "result": "\u751f\u6210\u4e86\u4e00\u4e2a\u5305\u542b\u8fde\u7eed40\u5206\u949f\u6570\u636e\u91c7\u96c6\u4f1a\u8bdd\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u8bb0\u5f55\u4e86\u9a7e\u9a76\u5458\u72b6\u6001\u7684\u9010\u6e10\u53d8\u5316\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3a\u9a7e\u9a76\u5458 drowsiness \u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u591a\u6a21\u6001\u6570\u636e\u652f\u6301\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u7528\u4e8e\u7b97\u6cd5\u5f00\u53d1\u548c\u9a8c\u8bc1\u3002"}}
{"id": "2507.13405", "pdf": "https://arxiv.org/pdf/2507.13405", "abs": "https://arxiv.org/abs/2507.13405", "authors": ["Ishant Chintapatla", "Kazuma Choji", "Naaisha Agarwal", "Andrew Lin", "Hannah You", "Charles Duong", "Kevin Zhu", "Sean O'Brien", "Vasu Sharma"], "title": "COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recently, many benchmarks and datasets have been developed to evaluate\nVision-Language Models (VLMs) using visual question answering (VQA) pairs, and\nmodels have shown significant accuracy improvements. However, these benchmarks\nrarely test the model's ability to accurately complete visual entailment, for\ninstance, accepting or refuting a hypothesis based on the image. To address\nthis, we propose COREVQA (Crowd Observations and Reasoning Entailment), a\nbenchmark of 5608 image and synthetically generated true/false statement pairs,\nwith images derived from the CrowdHuman dataset, to provoke visual entailment\nreasoning on challenging crowded images. Our results show that even the\ntop-performing VLMs achieve accuracy below 80%, with other models performing\nsubstantially worse (39.98%-69.95%). This significant performance gap reveals\nkey limitations in VLMs' ability to reason over certain types of image-question\npairs in crowded scenes.", "AI": {"tldr": "COREVQA\u662f\u4e00\u4e2a\u65b0\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u57fa\u51c6\uff0c\u4e13\u6ce8\u4e8e\u62e5\u6324\u573a\u666f\u4e2d\u7684\u89c6\u89c9\u8574\u542b\u4efb\u52a1\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5f88\u5c11\u6d4b\u8bd5\u6a21\u578b\u5728\u89c6\u89c9\u8574\u542b\u4efb\u52a1\uff08\u5982\u57fa\u4e8e\u56fe\u50cf\u63a5\u53d7\u6216\u53cd\u9a73\u5047\u8bbe\uff09\u4e0a\u7684\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u62e5\u6324\u573a\u666f\u4e2d\u3002", "method": "\u63d0\u51fa\u4e86COREVQA\u57fa\u51c6\uff0c\u5305\u542b5608\u5f20\u56fe\u50cf\u548c\u5408\u6210\u7684\u771f\u5047\u9648\u8ff0\u5bf9\uff0c\u56fe\u50cf\u6765\u81eaCrowdHuman\u6570\u636e\u96c6\u3002", "result": "\u5373\u4f7f\u8868\u73b0\u6700\u597d\u7684\u6a21\u578b\u51c6\u786e\u7387\u4e5f\u4f4e\u4e8e80%\uff0c\u5176\u4ed6\u6a21\u578b\u8868\u73b0\u66f4\u5dee\uff0839.98%-69.95%\uff09\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u62e5\u6324\u573a\u666f\u7684\u89c6\u89c9\u8574\u542b\u63a8\u7406\u80fd\u529b\u5b58\u5728\u663e\u8457\u4e0d\u8db3\u3002"}}
{"id": "2507.13420", "pdf": "https://arxiv.org/pdf/2507.13420", "abs": "https://arxiv.org/abs/2507.13420", "authors": ["Alessandro Pistola", "Valentina Orru'", "Nicolo' Marchetti", "Marco Roccetti"], "title": "AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "25 pages, 9 Figures", "summary": "By upgrading an existing deep learning model with the knowledge provided by\none of the oldest sets of grayscale satellite imagery, known as CORONA, we\nimproved the AI model attitude towards the automatic identification of\narchaeological sites in an environment which has been completely transformed in\nthe last five decades, including the complete destruction of many of those same\nsites. The initial Bing based convolutional network model was retrained using\nCORONA satellite imagery for the district of Abu Ghraib, west of Baghdad,\ncentral Mesopotamian floodplain. The results were twofold and surprising.\nFirst, the detection precision obtained on the area of interest increased\nsensibly: in particular, the Intersection over Union (IoU) values, at the image\nsegmentation level, surpassed 85 percent, while the general accuracy in\ndetecting archeological sites reached 90 percent. Second, our retrained model\nallowed the identification of four new sites of archaeological interest\n(confirmed through field verification), previously not identified by\narchaeologists with traditional techniques. This has confirmed the efficacy of\nusing AI techniques and the CORONA imagery from the 1960 to discover\narchaeological sites currently no longer visible, a concrete breakthrough with\nsignificant consequences for the study of landscapes with vanishing\narchaeological evidence induced by anthropization", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u53e4\u8001\u7684CORONA\u536b\u661f\u5f71\u50cf\u5347\u7ea7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8003\u53e4\u9057\u5740\u81ea\u52a8\u8bc6\u522b\u7684\u7cbe\u5ea6\uff0c\u5e76\u5728\u4f0a\u62c9\u514b\u963f\u5e03\u683c\u83b1\u5e03\u5730\u533a\u53d1\u73b0\u4e86\u56db\u4e2a\u65b0\u9057\u5740\u3002", "motivation": "\u5229\u7528CORONA\u5f71\u50cf\u5f25\u8865\u73b0\u4ee3\u73af\u5883\u53d8\u5316\u5bfc\u81f4\u7684\u8003\u53e4\u9057\u5740\u6d88\u5931\u95ee\u9898\uff0c\u9a8c\u8bc1AI\u6280\u672f\u5728\u8003\u53e4\u9886\u57df\u7684\u6f5c\u529b\u3002", "method": "\u57fa\u4e8eBing\u5377\u79ef\u7f51\u7edc\u6a21\u578b\uff0c\u4f7f\u7528CORONA\u5f71\u50cf\u5bf9\u6a21\u578b\u8fdb\u884c\u91cd\u65b0\u8bad\u7ec3\uff0c\u5e94\u7528\u4e8e\u7f8e\u7d22\u4e0d\u8fbe\u7c73\u4e9a\u5e73\u539f\u7684\u963f\u5e03\u683c\u83b1\u5e03\u5730\u533a\u3002", "result": "\u68c0\u6d4b\u7cbe\u5ea6\u663e\u8457\u63d0\u5347\uff08IoU\u8d85\u8fc785%\uff0c\u6574\u4f53\u51c6\u786e\u7387\u8fbe90%\uff09\uff0c\u5e76\u53d1\u73b0\u56db\u4e2a\u65b0\u9057\u5740\u3002", "conclusion": "AI\u6280\u672f\u4e0e\u5386\u53f2\u5f71\u50cf\u7ed3\u5408\u662f\u53d1\u73b0\u5df2\u6d88\u5931\u8003\u53e4\u9057\u5740\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5bf9\u8003\u53e4\u7814\u7a76\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2507.13458", "pdf": "https://arxiv.org/pdf/2507.13458", "abs": "https://arxiv.org/abs/2507.13458", "authors": ["Malte Hoffmann"], "title": "Domain-randomized deep learning for neuroimage analysis", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "12 pages, 6 figures, 2 tables, deep learning, domain generalization,\n  domain randomization, neuroimaging, medical image analysis, accepted for\n  publication in IEEE Signal Processing Magazine", "summary": "Deep learning has revolutionized neuroimage analysis by delivering\nunprecedented speed and accuracy. However, the narrow scope of many training\ndatasets constrains model robustness and generalizability. This challenge is\nparticularly acute in magnetic resonance imaging (MRI), where image appearance\nvaries widely across pulse sequences and scanner hardware. A recent\ndomain-randomization strategy addresses the generalization problem by training\ndeep neural networks on synthetic images with randomized intensities and\nanatomical content. By generating diverse data from anatomical segmentation\nmaps, the approach enables models to accurately process image types unseen\nduring training, without retraining or fine-tuning. It has demonstrated\neffectiveness across modalities including MRI, computed tomography, positron\nemission tomography, and optical coherence tomography, as well as beyond\nneuroimaging in ultrasound, electron and fluorescence microscopy, and X-ray\nmicrotomography. This tutorial paper reviews the principles, implementation,\nand potential of the synthesis-driven training paradigm. It highlights key\nbenefits, such as improved generalization and resistance to overfitting, while\ndiscussing trade-offs such as increased computational demands. Finally, the\narticle explores practical considerations for adopting the technique, aiming to\naccelerate the development of generalizable tools that make deep learning more\naccessible to domain experts without extensive computational resources or\nmachine learning knowledge.", "AI": {"tldr": "\u6df1\u5ea6\u5b66\u4e60\u901a\u8fc7\u5408\u6210\u56fe\u50cf\u8bad\u7ec3\u63d0\u5347\u4e86\u795e\u7ecf\u5f71\u50cf\u5206\u6790\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u8ba1\u7b97\u9700\u6c42\u589e\u52a0\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u795e\u7ecf\u5f71\u50cf\u5206\u6790\u4e2d\u56e0\u8bad\u7ec3\u6570\u636e\u8303\u56f4\u72ed\u7a84\u5bfc\u81f4\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u95ee\u9898\u3002", "method": "\u91c7\u7528\u57df\u968f\u673a\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u5408\u6210\u968f\u673a\u5f3a\u5ea6\u548c\u5185\u5bb9\u7684\u56fe\u50cf\u8bad\u7ec3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u3002", "result": "\u6a21\u578b\u80fd\u591f\u5904\u7406\u672a\u89c1\u8fc7\u7684\u56fe\u50cf\u7c7b\u578b\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u5fae\u8c03\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5f71\u50cf\u6a21\u6001\u3002", "conclusion": "\u5408\u6210\u9a71\u52a8\u8bad\u7ec3\u8303\u5f0f\u6709\u671b\u63d0\u5347\u6df1\u5ea6\u5b66\u4e60\u5de5\u5177\u7684\u901a\u7528\u6027\uff0c\u4f46\u9700\u6743\u8861\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2507.13459", "pdf": "https://arxiv.org/pdf/2507.13459", "abs": "https://arxiv.org/abs/2507.13459", "authors": ["Vijay K. Dubey", "Collin E. Haese", "Osman G\u00fcltekin", "David Dalton", "Manuel K. Rausch", "Jan N. Fuhg"], "title": "Graph Neural Network Surrogates for Contacting Deformable Bodies with Necessary and Sufficient Contact Detection", "categories": ["cs.CE", "cs.AI", "cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Surrogate models for the rapid inference of nonlinear boundary value problems\nin mechanics are helpful in a broad range of engineering applications. However,\neffective surrogate modeling of applications involving the contact of\ndeformable bodies, especially in the context of varying geometries, is still an\nopen issue. In particular, existing methods are confined to rigid body contact\nor, at best, contact between rigid and soft objects with well-defined contact\nplanes. Furthermore, they employ contact or collision detection filters that\nserve as a rapid test but use only the necessary and not sufficient conditions\nfor detection. In this work, we present a graph neural network architecture\nthat utilizes continuous collision detection and, for the first time,\nincorporates sufficient conditions designed for contact between soft deformable\nbodies. We test its performance on two benchmarks, including a problem in soft\ntissue mechanics of predicting the closed state of a bioprosthetic aortic\nvalve. We find a regularizing effect on adding additional contact terms to the\nloss function, leading to better generalization of the network. These benefits\nhold for simple contact at similar planes and element normal angles, and\ncomplex contact at differing planes and element normal angles. We also\ndemonstrate that the framework can handle varying reference geometries.\nHowever, such benefits come with high computational costs during training,\nresulting in a trade-off that may not always be favorable. We quantify the\ntraining cost and the resulting inference speedups on various hardware\narchitectures. Importantly, our graph neural network implementation results in\nup to a thousand-fold speedup for our benchmark problems at inference.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u7528\u4e8e\u5feb\u901f\u63a8\u65ad\u975e\u7ebf\u6027\u8fb9\u754c\u503c\u95ee\u9898\u4e2d\u7684\u8f6f\u4f53\u63a5\u89e6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u4e8e\u521a\u6027\u63a5\u89e6\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u8f6f\u4f53\u63a5\u89e6\u65f6\u5b58\u5728\u5c40\u9650\uff0c\u5c24\u5176\u662f\u5728\u51e0\u4f55\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5145\u5206\u6761\u4ef6\u3002", "method": "\u91c7\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u7ed3\u5408\u8fde\u7eed\u78b0\u649e\u68c0\u6d4b\u548c\u5145\u5206\u63a5\u89e6\u6761\u4ef6\uff0c\u4f18\u5316\u635f\u5931\u51fd\u6570\u4e2d\u7684\u63a5\u89e6\u9879\u3002", "result": "\u5728\u751f\u7269\u5047\u4f53\u4e3b\u52a8\u8109\u74e3\u7684\u8f6f\u7ec4\u7ec7\u529b\u5b66\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5b9e\u73b0\u4e86\u5343\u500d\u7684\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u8f6f\u4f53\u63a5\u89e6\u95ee\u9898\u4e0a\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u8bad\u7ec3\u6210\u672c\u8f83\u9ad8\uff0c\u9700\u6743\u8861\u8ba1\u7b97\u5f00\u9500\u4e0e\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2507.13480", "pdf": "https://arxiv.org/pdf/2507.13480", "abs": "https://arxiv.org/abs/2507.13480", "authors": ["Sara Avesani", "Gianluca Giacchi", "Michael Multerer"], "title": "Multiresolution local smoothness detection in non-uniformly sampled multivariate signals", "categories": ["math.NA", "cs.CV", "cs.LG", "cs.NA"], "comment": null, "summary": "Inspired by edge detection based on the decay behavior of wavelet\ncoefficients, we introduce a (near) linear-time algorithm for detecting the\nlocal regularity in non-uniformly sampled multivariate signals. Our approach\nquantifies regularity within the framework of microlocal spaces introduced by\nJaffard. The central tool in our analysis is the fast samplet transform, a\ndistributional wavelet transform tailored to scattered data. We establish a\nconnection between the decay of samplet coefficients and the pointwise\nregularity of multivariate signals. As a by product, we derive decay estimates\nfor functions belonging to classical H\\\"older spaces and Sobolev-Slobodeckij\nspaces. While traditional wavelets are effective for regularity detection in\nlow-dimensional structured data, samplets demonstrate robust performance even\nfor higher dimensional and scattered data. To illustrate our theoretical\nfindings, we present extensive numerical studies detecting local regularity of\none-, two- and three-dimensional signals, ranging from non-uniformly sampled\ntime series over image segmentation to edge detection in point clouds.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c0f\u6ce2\u7cfb\u6570\u8870\u51cf\u884c\u4e3a\u7684\uff08\u8fd1\uff09\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u975e\u5747\u5300\u91c7\u6837\u591a\u5143\u4fe1\u53f7\u7684\u5c40\u90e8\u89c4\u5f8b\u6027\u3002", "motivation": "\u53d7\u5c0f\u6ce2\u7cfb\u6570\u8870\u51cf\u884c\u4e3a\u7684\u542f\u53d1\uff0c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u9ad8\u7ef4\u548c\u975e\u5747\u5300\u6570\u636e\u4e2d\u7684\u5c40\u90e8\u89c4\u5f8b\u6027\u68c0\u6d4b\u95ee\u9898\u3002", "method": "\u5229\u7528\u5feb\u901f\u6837\u672c\u53d8\u6362\uff08\u4e00\u79cd\u9488\u5bf9\u5206\u6563\u6570\u636e\u7684\u5c0f\u6ce2\u53d8\u6362\uff09\u5206\u6790\u6837\u672c\u7cfb\u6570\u7684\u8870\u51cf\u4e0e\u4fe1\u53f7\u70b9\u89c4\u5f8b\u6027\u7684\u5173\u7cfb\u3002", "result": "\u5efa\u7acb\u4e86\u6837\u672c\u7cfb\u6570\u8870\u51cf\u4e0e\u591a\u5143\u4fe1\u53f7\u70b9\u89c4\u5f8b\u6027\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u5e76\u5728\u6570\u503c\u7814\u7a76\u4e2d\u9a8c\u8bc1\u4e86\u5176\u5728\u4e00\u7ef4\u3001\u4e8c\u7ef4\u548c\u4e09\u7ef4\u4fe1\u53f7\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6837\u672c\u53d8\u6362\u5728\u9ad8\u7ef4\u548c\u5206\u6563\u6570\u636e\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u4f20\u7edf\u5c0f\u6ce2\u65b9\u6cd5\u3002"}}
{"id": "2507.13485", "pdf": "https://arxiv.org/pdf/2507.13485", "abs": "https://arxiv.org/abs/2507.13485", "authors": ["Imane Hamzaoui", "Riyadh Baghdadi"], "title": "Neural Architecture Search with Mixed Bio-inspired Learning Rules", "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.LG"], "comment": "ECAI 2025", "summary": "Bio-inspired neural networks are attractive for their adversarial robustness,\nenergy frugality, and closer alignment with cortical physiology, yet they often\nlag behind back-propagation (BP) based models in accuracy and ability to scale.\nWe show that allowing the use of different bio-inspired learning rules in\ndifferent layers, discovered automatically by a tailored\nneural-architecture-search (NAS) procedure, bridges this gap. Starting from\nstandard NAS baselines, we enlarge the search space to include bio-inspired\nlearning rules and use NAS to find the best architecture and learning rule to\nuse in each layer. We show that neural networks that use different bio-inspired\nlearning rules for different layers have better accuracy than those that use a\nsingle rule across all the layers. The resulting NN that uses a mix of\nbio-inspired learning rules sets new records for bio-inspired models: 95.16% on\nCIFAR-10, 76.48% on CIFAR-100, 43.42% on ImageNet16-120, and 60.51% top-1 on\nImageNet. In some regimes, they even surpass comparable BP-based networks while\nretaining their robustness advantages. Our results suggest that layer-wise\ndiversity in learning rules allows better scalability and accuracy, and\nmotivates further research on mixing multiple bio-inspired learning rules in\nthe same network.", "AI": {"tldr": "\u901a\u8fc7\u795e\u7ecf\u67b6\u6784\u641c\u7d22\uff08NAS\uff09\u81ea\u52a8\u53d1\u73b0\u4e0d\u540c\u5c42\u7684\u751f\u7269\u542f\u53d1\u5b66\u4e60\u89c4\u5219\uff0c\u6df7\u5408\u4f7f\u7528\u8fd9\u4e9b\u89c4\u5219\u53ef\u4ee5\u63d0\u5347\u751f\u7269\u542f\u53d1\u795e\u7ecf\u7f51\u7edc\u7684\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u751a\u81f3\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u8d85\u8d8a\u57fa\u4e8e\u53cd\u5411\u4f20\u64ad\u7684\u6a21\u578b\u3002", "motivation": "\u751f\u7269\u542f\u53d1\u795e\u7ecf\u7f51\u7edc\u5728\u5bf9\u6297\u9c81\u68d2\u6027\u3001\u80fd\u6548\u548c\u751f\u7406\u5b66\u5bf9\u9f50\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5728\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u843d\u540e\u4e8e\u57fa\u4e8e\u53cd\u5411\u4f20\u64ad\u7684\u6a21\u578b\u3002", "method": "\u6269\u5c55NAS\u641c\u7d22\u7a7a\u95f4\u4ee5\u5305\u542b\u751f\u7269\u542f\u53d1\u5b66\u4e60\u89c4\u5219\uff0c\u81ea\u52a8\u53d1\u73b0\u6bcf\u5c42\u7684\u6700\u4f73\u67b6\u6784\u548c\u5b66\u4e60\u89c4\u5219\u3002", "result": "\u6df7\u5408\u4f7f\u7528\u4e0d\u540c\u751f\u7269\u542f\u53d1\u5b66\u4e60\u89c4\u5219\u7684\u795e\u7ecf\u7f51\u7edc\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u521b\u4e0b\u65b0\u8bb0\u5f55\uff0c\u751a\u81f3\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u8d85\u8d8a\u57fa\u4e8e\u53cd\u5411\u4f20\u64ad\u7684\u6a21\u578b\u3002", "conclusion": "\u5c42\u95f4\u5b66\u4e60\u89c4\u5219\u7684\u591a\u6837\u6027\u6709\u52a9\u4e8e\u63d0\u5347\u751f\u7269\u542f\u53d1\u795e\u7ecf\u7f51\u7edc\u7684\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\uff0c\u503c\u5f97\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2507.13514", "pdf": "https://arxiv.org/pdf/2507.13514", "abs": "https://arxiv.org/abs/2507.13514", "authors": ["Bhumika Laxman Sadbhave", "Philipp Vaeth", "Denise Dejon", "Gunther Schorcht", "Magda Gregorov\u00e1"], "title": "Sugar-Beet Stress Detection using Satellite Image Time Series", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Satellite Image Time Series (SITS) data has proven effective for agricultural\ntasks due to its rich spectral and temporal nature. In this study, we tackle\nthe task of stress detection in sugar-beet fields using a fully unsupervised\napproach. We propose a 3D convolutional autoencoder model to extract meaningful\nfeatures from Sentinel-2 image sequences, combined with\nacquisition-date-specific temporal encodings to better capture the growth\ndynamics of sugar-beets. The learned representations are used in a downstream\nclustering task to separate stressed from healthy fields. The resulting stress\ndetection system can be directly applied to data from different years, offering\na practical and accessible tool for stress detection in sugar-beets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e3D\u5377\u79ef\u81ea\u7f16\u7801\u5668\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u7528\u4e8e\u4eceSentinel-2\u536b\u661f\u56fe\u50cf\u5e8f\u5217\u4e2d\u68c0\u6d4b\u751c\u83dc\u7530\u7684\u538b\u529b\u72b6\u6001\u3002", "motivation": "\u536b\u661f\u56fe\u50cf\u65f6\u95f4\u5e8f\u5217\uff08SITS\uff09\u6570\u636e\u56e0\u5176\u4e30\u5bcc\u7684\u9891\u8c31\u548c\u65f6\u95f4\u7279\u6027\uff0c\u5728\u519c\u4e1a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u65e0\u76d1\u7763\u65b9\u6cd5\u89e3\u51b3\u751c\u83dc\u7530\u538b\u529b\u68c0\u6d4b\u95ee\u9898\u3002", "method": "\u4f7f\u75283D\u5377\u79ef\u81ea\u7f16\u7801\u5668\u4eceSentinel-2\u56fe\u50cf\u5e8f\u5217\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u5e76\u7ed3\u5408\u7279\u5b9a\u91c7\u96c6\u65e5\u671f\u7684\u65f6\u95f4\u7f16\u7801\u4ee5\u6355\u6349\u751c\u83dc\u751f\u957f\u52a8\u6001\u3002", "result": "\u5b66\u4e60\u5230\u7684\u7279\u5f81\u7528\u4e8e\u4e0b\u6e38\u805a\u7c7b\u4efb\u52a1\uff0c\u6210\u529f\u533a\u5206\u538b\u529b\u7530\u548c\u5065\u5eb7\u7530\uff0c\u4e14\u7cfb\u7edf\u53ef\u76f4\u63a5\u5e94\u7528\u4e8e\u4e0d\u540c\u5e74\u4efd\u7684\u6570\u636e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u751c\u83dc\u7530\u538b\u529b\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u6613\u7528\u7684\u5de5\u5177\u3002"}}
{"id": "2507.13543", "pdf": "https://arxiv.org/pdf/2507.13543", "abs": "https://arxiv.org/abs/2507.13543", "authors": ["Alexander Kolpakov"], "title": "Loss-Complexity Landscape and Model Structure Functions", "categories": ["cs.IT", "cs.AI", "cs.LG", "math-ph", "math.IT", "math.MP", "I.2.2; I.2.6"], "comment": "18 pages, 3 figures; GitHub repository at\n  https://github.com/sashakolpakov/structure-functions", "summary": "We develop a framework for dualizing the Kolmogorov structure function\n$h_x(\\alpha)$, which then allows using computable complexity proxies. We\nestablish a mathematical analogy between information-theoretic constructs and\nstatistical mechanics, introducing a suitable partition function and free\nenergy functional. We explicitly prove the Legendre-Fenchel duality between the\nstructure function and free energy, showing detailed balance of the Metropolis\nkernel, and interpret acceptance probabilities as information-theoretic\nscattering amplitudes. A susceptibility-like variance of model complexity is\nshown to peak precisely at loss-complexity trade-offs interpreted as phase\ntransitions. Practical experiments with linear and tree-based regression models\nverify these theoretical predictions, explicitly demonstrating the interplay\nbetween the model complexity, generalization, and overfitting threshold.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u7528\u4e8e\u5bf9\u5076\u5316Kolmogorov\u7ed3\u6784\u51fd\u6570\uff0c\u5e76\u5f15\u5165\u7edf\u8ba1\u529b\u5b66\u4e2d\u7684\u6982\u5ff5\uff0c\u8bc1\u660e\u4e86Legendre-Fenchel\u5bf9\u5076\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u9884\u6d4b\u3002", "motivation": "\u7814\u7a76\u4fe1\u606f\u8bba\u6784\u9020\u4e0e\u7edf\u8ba1\u529b\u5b66\u4e4b\u95f4\u7684\u6570\u5b66\u7c7b\u6bd4\uff0c\u63a2\u7d22\u6a21\u578b\u590d\u6742\u5ea6\u4e0e\u6cdb\u5316\u80fd\u529b\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u5f00\u53d1\u4e86\u5bf9\u5076\u5316Kolmogorov\u7ed3\u6784\u51fd\u6570\u7684\u6846\u67b6\uff0c\u5f15\u5165\u5206\u533a\u51fd\u6570\u548c\u81ea\u7531\u80fd\u6cdb\u51fd\uff0c\u8bc1\u660eLegendre-Fenchel\u5bf9\u5076\u6027\uff0c\u5e76\u901a\u8fc7\u7ebf\u6027\u56de\u5f52\u548c\u6811\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u7406\u8bba\u9884\u6d4b\u5f97\u5230\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u590d\u6742\u5ea6\u3001\u6cdb\u5316\u80fd\u529b\u548c\u8fc7\u62df\u5408\u9608\u503c\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5730\u5c06\u4fe1\u606f\u8bba\u4e0e\u7edf\u8ba1\u529b\u5b66\u8054\u7cfb\u8d77\u6765\uff0c\u4e3a\u7406\u89e3\u6a21\u578b\u590d\u6742\u5ea6\u548c\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2507.13558", "pdf": "https://arxiv.org/pdf/2507.13558", "abs": "https://arxiv.org/abs/2507.13558", "authors": ["David Poole"], "title": "Why Isn't Relational Learning Taking Over the World?", "categories": ["cs.AI", "cs.DB", "cs.LG"], "comment": "10 pages (6 pages + references + appendices)", "summary": "AI seems to be taking over the world with systems that model pixels, words,\nand phonemes. The world is arguably made up, not of pixels, words, and phonemes\nbut of entities (objects, things, including events) with properties and\nrelations among them. Surely we should model these, not the perception or\ndescription of them. You might suspect that concentrating on modeling words and\npixels is because all of the (valuable) data in the world is in terms of text\nand images. If you look into almost any company you will find their most\nvaluable data is in spreadsheets, databases and other relational formats. These\nare not the form that are studied in introductory machine learning, but are\nfull of product numbers, student numbers, transaction numbers and other\nidentifiers that can't be interpreted naively as numbers. The field that\nstudies this sort of data has various names including relational learning,\nstatistical relational AI, and many others. This paper explains why relational\nlearning is not taking over the world -- except in a few cases with restricted\nrelations -- and what needs to be done to bring it to it's rightful prominence.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\u5e94\u5efa\u6a21\u5b9e\u4f53\u800c\u975e\u611f\u77e5\u6216\u63cf\u8ff0\uff0c\u6307\u51fa\u5173\u7cfb\u5b66\u4e60\u672a\u666e\u53ca\u7684\u539f\u56e0\u53ca\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u5f53\u524dAI\u4e3b\u8981\u5efa\u6a21\u50cf\u7d20\u548c\u6587\u5b57\uff0c\u4f46\u4e16\u754c\u7531\u5b9e\u4f53\u53ca\u5176\u5173\u7cfb\u6784\u6210\uff0c\u5e94\u76f4\u63a5\u5efa\u6a21\u8fd9\u4e9b\u5b9e\u4f53\u3002", "method": "\u5206\u6790\u5173\u7cfb\u5b66\u4e60\uff08\u5982\u7edf\u8ba1\u5173\u7cfbAI\uff09\u7684\u73b0\u72b6\u53ca\u5176\u53d7\u9650\u539f\u56e0\u3002", "result": "\u5173\u7cfb\u5b66\u4e60\u4ec5\u5728\u5c11\u6570\u53d7\u9650\u5173\u7cfb\u4e2d\u6210\u529f\uff0c\u672a\u5e7f\u6cdb\u666e\u53ca\u3002", "conclusion": "\u9700\u6539\u8fdb\u65b9\u6cd5\u4ee5\u4f7f\u5173\u7cfb\u5b66\u4e60\u53d1\u6325\u5176\u6f5c\u529b\u3002"}}
{"id": "2507.13580", "pdf": "https://arxiv.org/pdf/2507.13580", "abs": "https://arxiv.org/abs/2507.13580", "authors": ["Hao Tuo", "Yan Li", "Xuanning Hu", "Haishi Zhao", "Xueyan Liu", "Bo Yang"], "title": "A Collaborative Framework Integrating Large Language Model and Chemical Fragment Space: Mutual Inspiration for Lead Design", "categories": ["q-bio.BM", "cs.LG"], "comment": null, "summary": "Combinatorial optimization algorithm is essential in computer-aided drug\ndesign by progressively exploring chemical space to design lead compounds with\nhigh affinity to target protein. However current methods face inherent\nchallenges in integrating domain knowledge, limiting their performance in\nidentifying lead compounds with novel and valid binding mode. Here, we propose\nAutoLeadDesign, a lead compounds design framework that inspires extensive\ndomain knowledge encoded in large language models with chemical fragments to\nprogressively implement efficient exploration of vast chemical space. The\ncomprehensive experiments indicate that AutoLeadDesign outperforms baseline\nmethods. Significantly, empirical lead design campaigns targeting two\nclinically relevant targets (PRMT5 and SARS-CoV-2 PLpro) demonstrate\nAutoLeadDesign's competence in de novo generation of lead compounds achieving\nexpert-competitive design efficacy. Structural analysis further confirms their\nmechanism-validated inhibitory patterns. By tracing the process of design, we\nfind that AutoLeadDesign shares analogous mechanisms with fragment-based drug\ndesign which traditionally rely on the expert decision-making, further\nrevealing why it works. Overall, AutoLeadDesign offers an efficient approach\nfor lead compounds design, suggesting its potential utility in drug design.", "AI": {"tldr": "AutoLeadDesign\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5316\u5b66\u7247\u6bb5\u7684\u5148\u5bfc\u5316\u5408\u7269\u8bbe\u8ba1\u6846\u67b6\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5728\u9488\u5bf9PRMT5\u548cSARS-CoV-2 PLpro\u7684\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u4e13\u5bb6\u7ea7\u8bbe\u8ba1\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u5728\u6574\u5408\u9886\u57df\u77e5\u8bc6\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u9650\u5236\u4e86\u5176\u8bbe\u8ba1\u65b0\u9896\u4e14\u6709\u6548\u7ed3\u5408\u6a21\u5f0f\u7684\u5148\u5bfc\u5316\u5408\u7269\u7684\u80fd\u529b\u3002", "method": "AutoLeadDesign\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7f16\u7801\u7684\u9886\u57df\u77e5\u8bc6\u548c\u5316\u5b66\u7247\u6bb5\uff0c\u9010\u6b65\u63a2\u7d22\u5316\u5b66\u7a7a\u95f4\u3002", "result": "\u5b9e\u9a8c\u8868\u660eAutoLeadDesign\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5728\u9488\u5bf9PRMT5\u548cSARS-CoV-2 PLpro\u7684\u5b9e\u9a8c\u4e2d\u751f\u6210\u4e13\u5bb6\u7ea7\u5148\u5bfc\u5316\u5408\u7269\u3002", "conclusion": "AutoLeadDesign\u4e3a\u836f\u7269\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u65b9\u6cd5\uff0c\u5177\u6709\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.13591", "pdf": "https://arxiv.org/pdf/2507.13591", "abs": "https://arxiv.org/abs/2507.13591", "authors": ["Sahar Ghoflsaz Ghinani", "Elaheh Sadredini"], "title": "FuSeFL: Fully Secure and Scalable Cross-Silo Federated Learning", "categories": ["cs.CR", "cs.LG"], "comment": "15 Pages, 12 Figures", "summary": "Federated Learning (FL) enables collaborative model training without\ncentralizing client data, making it attractive for privacy-sensitive domains.\nWhile existing approaches employ cryptographic techniques such as homomorphic\nencryption, differential privacy, or secure multiparty computation to mitigate\ninference attacks-including model inversion, membership inference, and gradient\nleakage-they often suffer from high computational, communication, or memory\noverheads. Moreover, many methods overlook the confidentiality of the global\nmodel itself, which may be proprietary and sensitive. These challenges limit\nthe practicality of secure FL, especially in cross-silo deployments involving\nlarge datasets and strict compliance requirements.\n  We present FuSeFL, a fully secure and scalable FL scheme designed for\ncross-silo settings. FuSeFL decentralizes training across client pairs using\nlightweight secure multiparty computation (MPC), while confining the server's\nrole to secure aggregation. This design eliminates server bottlenecks, avoids\ndata offloading, and preserves full confidentiality of data, model, and updates\nthroughout training. FuSeFL defends against inference threats, achieves up to\n95% lower communication latency and 50% lower server memory usage, and improves\naccuracy over prior secure FL solutions, demonstrating strong security and\nefficiency at scale.", "AI": {"tldr": "FuSeFL\u662f\u4e00\u79cd\u5b8c\u5168\u5b89\u5168\u4e14\u53ef\u6269\u5c55\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6848\uff0c\u4e13\u4e3a\u8de8\u673a\u6784\u8bbe\u7f6e\u8bbe\u8ba1\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\uff08MPC\uff09\u5b9e\u73b0\u9ad8\u6548\u8bad\u7ec3\uff0c\u540c\u65f6\u4fdd\u62a4\u6570\u636e\u548c\u6a21\u578b\u7684\u9690\u79c1\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5728\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u5b58\u5728\u9ad8\u8ba1\u7b97\u3001\u901a\u4fe1\u6216\u5185\u5b58\u5f00\u9500\u7684\u95ee\u9898\uff0c\u4e14\u5ffd\u7565\u4e86\u5168\u5c40\u6a21\u578b\u7684\u4fdd\u5bc6\u6027\uff0c\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\u3002", "method": "FuSeFL\u91c7\u7528\u8f7b\u91cf\u7ea7MPC\u5728\u5ba2\u6237\u7aef\u5bf9\u4e4b\u95f4\u5206\u6563\u8bad\u7ec3\uff0c\u670d\u52a1\u5668\u4ec5\u8d1f\u8d23\u5b89\u5168\u805a\u5408\uff0c\u907f\u514d\u4e86\u6570\u636e\u5378\u8f7d\u548c\u670d\u52a1\u5668\u74f6\u9888\u3002", "result": "FuSeFL\u663e\u8457\u964d\u4f4e\u4e86\u901a\u4fe1\u5ef6\u8fdf\uff08\u9ad8\u8fbe95%\uff09\u548c\u670d\u52a1\u5668\u5185\u5b58\u4f7f\u7528\uff0850%\uff09\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u5e76\u6709\u6548\u9632\u5fa1\u63a8\u7406\u653b\u51fb\u3002", "conclusion": "FuSeFL\u5728\u5b89\u5168\u6027\u548c\u6548\u7387\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u8de8\u673a\u6784\u8054\u90a6\u5b66\u4e60\u573a\u666f\u3002"}}
{"id": "2507.13598", "pdf": "https://arxiv.org/pdf/2507.13598", "abs": "https://arxiv.org/abs/2507.13598", "authors": ["Amro Abdalla", "Ismail Shaheen", "Dan DeGenaro", "Rupayan Mallick", "Bogdan Raita", "Sarah Adel Bargal"], "title": "GIFT: Gradient-aware Immunization of diffusion models against malicious Fine-Tuning with safe concepts retention", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "comment": "Warning: This paper contains NSFW content. Reader discretion is\n  advised", "summary": "We present GIFT: a {G}radient-aware {I}mmunization technique to defend\ndiffusion models against malicious {F}ine-{T}uning while preserving their\nability to generate safe content. Existing safety mechanisms like safety\ncheckers are easily bypassed, and concept erasure methods fail under\nadversarial fine-tuning. GIFT addresses this by framing immunization as a\nbi-level optimization problem: the upper-level objective degrades the model's\nability to represent harmful concepts using representation noising and\nmaximization, while the lower-level objective preserves performance on safe\ndata. GIFT achieves robust resistance to malicious fine-tuning while\nmaintaining safe generative quality. Experimental results show that our method\nsignificantly impairs the model's ability to re-learn harmful concepts while\nmaintaining performance on safe content, offering a promising direction for\ncreating inherently safer generative models resistant to adversarial\nfine-tuning attacks.", "AI": {"tldr": "GIFT\u662f\u4e00\u79cd\u68af\u5ea6\u611f\u77e5\u514d\u75ab\u6280\u672f\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u95ee\u9898\u9632\u5fa1\u6269\u6563\u6a21\u578b\u514d\u53d7\u6076\u610f\u5fae\u8c03\uff0c\u540c\u65f6\u4fdd\u6301\u5b89\u5168\u5185\u5bb9\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u673a\u5236\uff08\u5982\u5b89\u5168\u68c0\u67e5\u5668\uff09\u5bb9\u6613\u88ab\u7ed5\u8fc7\uff0c\u6982\u5ff5\u64e6\u9664\u65b9\u6cd5\u5728\u5bf9\u6297\u6027\u5fae\u8c03\u4e0b\u5931\u6548\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "GIFT\u5c06\u514d\u75ab\u95ee\u9898\u5efa\u6a21\u4e3a\u53cc\u5c42\u4f18\u5316\uff1a\u4e0a\u5c42\u76ee\u6807\u901a\u8fc7\u8868\u793a\u566a\u58f0\u548c\u6700\u5927\u5316\u964d\u4f4e\u6709\u5bb3\u6982\u5ff5\u8868\u8fbe\u80fd\u529b\uff0c\u4e0b\u5c42\u76ee\u6807\u4fdd\u6301\u5b89\u5168\u6570\u636e\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGIFT\u663e\u8457\u524a\u5f31\u6a21\u578b\u91cd\u65b0\u5b66\u4e60\u6709\u5bb3\u6982\u5ff5\u7684\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u5b89\u5168\u5185\u5bb9\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "GIFT\u4e3a\u521b\u5efa\u6297\u5bf9\u6297\u6027\u5fae\u8c03\u653b\u51fb\u7684\u5b89\u5168\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2507.13602", "pdf": "https://arxiv.org/pdf/2507.13602", "abs": "https://arxiv.org/abs/2507.13602", "authors": ["Shivakanth Sujit", "Luca Nunziante", "Dan Ogawa Lillrank", "Rousslan Fernand Julien Dossa", "Kai Arulkumaran"], "title": "Improving Low-Cost Teleoperation: Augmenting GELLO with Force", "categories": ["cs.RO", "cs.HC", "cs.LG"], "comment": "Accepted at the 2025 IEEE/SICE International Symposium on System\n  Integration", "summary": "In this work we extend the low-cost GELLO teleoperation system, initially\ndesigned for joint position control, with additional force information. Our\nfirst extension is to implement force feedback, allowing users to feel\nresistance when interacting with the environment. Our second extension is to\nadd force information into the data collection process and training of\nimitation learning models. We validate our additions by implementing these on a\nGELLO system with a Franka Panda arm as the follower robot, performing a user\nstudy, and comparing the performance of policies trained with and without force\ninformation on a range of simulated and real dexterous manipulation tasks.\nQualitatively, users with robotics experience preferred our controller, and the\naddition of force inputs improved task success on the majority of tasks.", "AI": {"tldr": "\u6269\u5c55\u4e86\u4f4e\u6210\u672cGELLO\u9065\u64cd\u4f5c\u7cfb\u7edf\uff0c\u52a0\u5165\u529b\u53cd\u9988\u548c\u529b\u4fe1\u606f\u7528\u4e8e\u6a21\u4eff\u5b66\u4e60\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u63d0\u5347\u9065\u64cd\u4f5c\u7cfb\u7edf\u7684\u7528\u6237\u4f53\u9a8c\u548c\u4efb\u52a1\u6210\u529f\u7387\uff0c\u901a\u8fc7\u529b\u53cd\u9988\u548c\u529b\u4fe1\u606f\u589e\u5f3a\u6a21\u4eff\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u5728GELLO\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u529b\u53cd\u9988\uff0c\u5e76\u5c06\u529b\u4fe1\u606f\u7528\u4e8e\u6570\u636e\u6536\u96c6\u548c\u6a21\u4eff\u5b66\u4e60\u8bad\u7ec3\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\u548c\u4efb\u52a1\u6027\u80fd\u5bf9\u6bd4\u9a8c\u8bc1\u3002", "result": "\u6709\u673a\u5668\u4eba\u7ecf\u9a8c\u7684\u7528\u6237\u504f\u597d\u65b0\u63a7\u5236\u5668\uff0c\u529b\u4fe1\u606f\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u6570\u4efb\u52a1\u7684\u5b8c\u6210\u7387\u3002", "conclusion": "\u529b\u53cd\u9988\u548c\u529b\u4fe1\u606f\u7684\u52a0\u5165\u63d0\u5347\u4e86\u9065\u64cd\u4f5c\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u3002"}}
{"id": "2507.13629", "pdf": "https://arxiv.org/pdf/2507.13629", "abs": "https://arxiv.org/abs/2507.13629", "authors": ["Niveen O. Jaffal", "Mohammed Alkhanafseh", "David Mohaisen"], "title": "Large Language Models in Cybersecurity: Applications, Vulnerabilities, and Defense Techniques", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "21 pages", "summary": "Large Language Models (LLMs) are transforming cybersecurity by enabling\nintelligent, adaptive, and automated approaches to threat detection,\nvulnerability assessment, and incident response. With their advanced language\nunderstanding and contextual reasoning, LLMs surpass traditional methods in\ntackling challenges across domains such as IoT, blockchain, and hardware\nsecurity. This survey provides a comprehensive overview of LLM applications in\ncybersecurity, focusing on two core areas: (1) the integration of LLMs into key\ncybersecurity domains, and (2) the vulnerabilities of LLMs themselves, along\nwith mitigation strategies. By synthesizing recent advancements and identifying\nkey limitations, this work offers practical insights and strategic\nrecommendations for leveraging LLMs to build secure, scalable, and future-ready\ncyber defense systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7f51\u7edc\u5b89\u5168\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u5a01\u80c1\u68c0\u6d4b\u3001\u6f0f\u6d1e\u8bc4\u4f30\u548c\u4e8b\u4ef6\u54cd\u5e94\uff0c\u5e76\u63a2\u8ba8\u4e86LLMs\u81ea\u8eab\u7684\u6f0f\u6d1e\u53ca\u7f13\u89e3\u7b56\u7565\u3002", "motivation": "LLMs\u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\u7684\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u5176\u81ea\u8eab\u4e5f\u5b58\u5728\u6f0f\u6d1e\uff0c\u9700\u8981\u5168\u9762\u7814\u7a76\u548c\u7b56\u7565\u5e94\u5bf9\u3002", "method": "\u901a\u8fc7\u7efc\u5408\u8fd1\u671f\u7814\u7a76\uff0c\u5206\u6790LLMs\u5728\u5173\u952e\u7f51\u7edc\u5b89\u5168\u9886\u57df\u7684\u5e94\u7528\u53ca\u5176\u81ea\u8eab\u6f0f\u6d1e\u3002", "result": "LLMs\u5728\u7f51\u7edc\u5b89\u5168\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u9700\u5173\u6ce8\u5176\u6f0f\u6d1e\u548c\u98ce\u9669\u3002", "conclusion": "\u8bba\u6587\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u548c\u6218\u7565\u5efa\u8bae\uff0c\u4ee5\u5229\u7528LLMs\u6784\u5efa\u5b89\u5168\u3001\u53ef\u6269\u5c55\u7684\u672a\u6765\u7f51\u7edc\u9632\u5fa1\u7cfb\u7edf\u3002"}}
{"id": "2507.13638", "pdf": "https://arxiv.org/pdf/2507.13638", "abs": "https://arxiv.org/abs/2507.13638", "authors": ["Sen Lu", "Xiaoyu Zhang", "Mingtao Hu", "Eric Yeu-Jer Lee", "Soohyeon Kim", "Wei D. Lu"], "title": "State Space Models Naturally Produce Traveling Waves, Time Cells, and Scale to Abstract Cognitive Functions", "categories": ["q-bio.NC", "cs.LG"], "comment": "Sen Lu and Xiaoyu Zhang contributed equally. Wei D. Lu is the\n  corresponding author. 4 figures are included in 15 pages", "summary": "A grand challenge in modern neuroscience is to bridge the gap between the\ndetailed mapping of microscale neural circuits and a mechanistic understanding\nof cognitive functions. While extensive knowledge exists about neuronal\nconnectivity and biophysics, a significant gap remains in how these elements\ncombine to produce flexible, learned behaviors. Here, we propose that a\nframework based on State-Space Models (SSMs), an emerging class of deep\nlearning architectures, can bridge this gap. We argue that the differential\nequations governing elements in an SSM are conceptually consistent with the\nbiophysical dynamics of neurons, while the combined dynamics in the model lead\nto emergent behaviors observed in experimental neuroscience. We test this\nframework by training an S5 model--a specific SSM variant employing a diagonal\nstate transition matrix--on temporal discrimination tasks with reinforcement\nlearning (RL). We demonstrate that the model spontaneously develops neural\nrepresentations that strikingly mimic biological 'time cells'. We reveal that\nthese cells emerge from a simple generative principle: learned rotational\ndynamics of hidden state vectors in the complex plane. This single mechanism\nunifies the emergence of time cells, ramping activity, and\noscillations/traveling waves observed in numerous experiments. Furthermore, we\nshow that this rotational dynamics generalizes beyond interval discriminative\ntasks to abstract event-counting tasks that were considered foundational for\nperforming complex cognitive tasks. Our findings position SSMs as a compelling\nframework that connects single-neuron dynamics to cognitive phenomena, offering\na unifying and computationally tractable theoretical ground for temporal\nlearning in the brain.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u57fa\u4e8e\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSM\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8fde\u63a5\u5fae\u89c2\u795e\u7ecf\u56de\u8def\u4e0e\u8ba4\u77e5\u529f\u80fd\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u80fd\u81ea\u53d1\u4ea7\u751f\u7c7b\u4f3c\u751f\u7269\u65f6\u95f4\u7ec6\u80de\u7684\u795e\u7ecf\u8868\u5f81\u3002", "motivation": "\u73b0\u4ee3\u795e\u7ecf\u79d1\u5b66\u9762\u4e34\u7684\u6838\u5fc3\u6311\u6218\u662f\u5982\u4f55\u5c06\u5fae\u89c2\u795e\u7ecf\u56de\u8def\u7684\u8be6\u7ec6\u6620\u5c04\u4e0e\u8ba4\u77e5\u529f\u80fd\u7684\u673a\u5236\u7406\u89e3\u8054\u7cfb\u8d77\u6765\u3002", "method": "\u91c7\u7528\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSM\uff09\uff0c\u7279\u522b\u662fS5\u53d8\u4f53\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u65f6\u95f4\u8fa8\u522b\u4efb\u52a1\uff0c\u5206\u6790\u5176\u52a8\u6001\u7279\u6027\u3002", "result": "\u6a21\u578b\u81ea\u53d1\u4ea7\u751f\u7c7b\u4f3c\u751f\u7269\u65f6\u95f4\u7ec6\u80de\u7684\u795e\u7ecf\u8868\u5f81\uff0c\u5e76\u63ed\u793a\u8fd9\u4e9b\u7ec6\u80de\u6e90\u4e8e\u9690\u85cf\u72b6\u6001\u5411\u91cf\u5728\u590d\u5e73\u9762\u4e2d\u7684\u65cb\u8f6c\u52a8\u6001\u3002", "conclusion": "SSM\u6846\u67b6\u4e3a\u8fde\u63a5\u5355\u795e\u7ecf\u5143\u52a8\u6001\u4e0e\u8ba4\u77e5\u73b0\u8c61\u63d0\u4f9b\u4e86\u7edf\u4e00\u4e14\u8ba1\u7b97\u53ef\u884c\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2507.13639", "pdf": "https://arxiv.org/pdf/2507.13639", "abs": "https://arxiv.org/abs/2507.13639", "authors": ["Nikola Pavlovic", "Sudeep Salgia", "Qing Zhao"], "title": "Differential Privacy in Kernelized Contextual Bandits via Random Projections", "categories": ["stat.ML", "cs.CR", "cs.LG"], "comment": null, "summary": "We consider the problem of contextual kernel bandits with stochastic\ncontexts, where the underlying reward function belongs to a known Reproducing\nKernel Hilbert Space. We study this problem under an additional constraint of\nDifferential Privacy, where the agent needs to ensure that the sequence of\nquery points is differentially private with respect to both the sequence of\ncontexts and rewards. We propose a novel algorithm that achieves the\nstate-of-the-art cumulative regret of\n$\\widetilde{\\mathcal{O}}(\\sqrt{\\gamma_TT}+\\frac{\\gamma_T}{\\varepsilon_{\\mathrm{DP}}})$\nand\n$\\widetilde{\\mathcal{O}}(\\sqrt{\\gamma_TT}+\\frac{\\gamma_T\\sqrt{T}}{\\varepsilon_{\\mathrm{DP}}})$\nover a time horizon of $T$ in the joint and local models of differential\nprivacy, respectively, where $\\gamma_T$ is the effective dimension of the\nkernel and $\\varepsilon_{\\mathrm{DP}} > 0$ is the privacy parameter. The key\ningredient of the proposed algorithm is a novel private kernel-ridge regression\nestimator which is based on a combination of private covariance estimation and\nprivate random projections. It offers a significantly reduced sensitivity\ncompared to its classical counterpart while maintaining a high prediction\naccuracy, allowing our algorithm to achieve the state-of-the-art performance\nguarantees.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5dee\u5206\u9690\u79c1\u7ea6\u675f\u4e0b\u7684\u4e0a\u4e0b\u6587\u6838\u8d4c\u535a\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6700\u4f18\u7684\u7d2f\u79ef\u9057\u61be\u3002", "motivation": "\u7814\u7a76\u5728\u5dee\u5206\u9690\u79c1\u7ea6\u675f\u4e0b\uff0c\u4e0a\u4e0b\u6587\u6838\u8d4c\u535a\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u786e\u4fdd\u67e5\u8be2\u5e8f\u5217\u5bf9\u4e0a\u4e0b\u6587\u548c\u5956\u52b1\u5e8f\u5217\u7684\u9690\u79c1\u4fdd\u62a4\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u79c1\u6709\u6838\u5cad\u56de\u5f52\u4f30\u8ba1\u5668\u7684\u65b0\u7b97\u6cd5\uff0c\u7ed3\u5408\u79c1\u6709\u534f\u65b9\u5dee\u4f30\u8ba1\u548c\u79c1\u6709\u968f\u673a\u6295\u5f71\u3002", "result": "\u7b97\u6cd5\u5728\u8054\u5408\u548c\u5c40\u90e8\u5dee\u5206\u9690\u79c1\u6a21\u578b\u4e0b\u5206\u522b\u5b9e\u73b0\u4e86\u6700\u4f18\u7684\u7d2f\u79ef\u9057\u61be\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u901a\u8fc7\u964d\u4f4e\u654f\u611f\u6027\u5e76\u4fdd\u6301\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5b9e\u73b0\u4e86\u6700\u4f18\u6027\u80fd\u3002"}}
{"id": "2507.13659", "pdf": "https://arxiv.org/pdf/2507.13659", "abs": "https://arxiv.org/abs/2507.13659", "authors": ["Xiao Wang", "Qian Zhu", "Shujuan Wu", "Bo Jiang", "Shiliang Zhang", "Yaowei Wang", "Yonghong Tian", "Bin Luo"], "title": "When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.NE"], "comment": null, "summary": "Recent researchers have proposed using event cameras for person\nre-identification (ReID) due to their promising performance and better balance\nin terms of privacy protection, event camera-based person ReID has attracted\nsignificant attention. Currently, mainstream event-based person ReID algorithms\nprimarily focus on fusing visible light and event stream, as well as preserving\nprivacy. Although significant progress has been made, these methods are\ntypically trained and evaluated on small-scale or simulated event camera\ndatasets, making it difficult to assess their real identification performance\nand generalization ability. To address the issue of data scarcity, this paper\nintroduces a large-scale RGB-event based person ReID dataset, called EvReID.\nThe dataset contains 118,988 image pairs and covers 1200 pedestrian identities,\nwith data collected across multiple seasons, scenes, and lighting conditions.\nWe also evaluate 15 state-of-the-art person ReID algorithms, laying a solid\nfoundation for future research in terms of both data and benchmarking. Based on\nour newly constructed dataset, this paper further proposes a pedestrian\nattribute-guided contrastive learning framework to enhance feature learning for\nperson re-identification, termed TriPro-ReID. This framework not only\neffectively explores the visual features from both RGB frames and event\nstreams, but also fully utilizes pedestrian attributes as mid-level semantic\nfeatures. Extensive experiments on the EvReID dataset and MARS datasets fully\nvalidated the effectiveness of our proposed RGB-Event person ReID framework.\nThe benchmark dataset and source code will be released on\nhttps://github.com/Event-AHU/Neuromorphic_ReID", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5927\u89c4\u6a21RGB-\u4e8b\u4ef6\u6570\u636e\u96c6EvReID\uff0c\u5e76\u63d0\u51fa\u4e86TriPro-ReID\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u884c\u4eba\u91cd\u8bc6\u522b\u7684\u7279\u5f81\u5b66\u4e60\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u4e8b\u4ef6\u76f8\u673a\u884c\u4eba\u91cd\u8bc6\u522b\u65b9\u6cd5\u56e0\u6570\u636e\u7a00\u7f3a\u800c\u96be\u4ee5\u8bc4\u4f30\u771f\u5b9e\u6027\u80fd\u7684\u95ee\u9898\u3002", "method": "\u6784\u5efaEvReID\u6570\u636e\u96c6\u5e76\u8bbe\u8ba1TriPro-ReID\u6846\u67b6\uff0c\u7ed3\u5408RGB\u548c\u4e8b\u4ef6\u6d41\u6570\u636e\uff0c\u5229\u7528\u884c\u4eba\u5c5e\u6027\u8fdb\u884c\u5bf9\u6bd4\u5b66\u4e60\u3002", "result": "\u5728EvReID\u548cMARS\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "EvReID\u6570\u636e\u96c6\u548cTriPro-ReID\u6846\u67b6\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6570\u636e\u548c\u57fa\u51c6\u652f\u6301\u3002"}}
{"id": "2507.13677", "pdf": "https://arxiv.org/pdf/2507.13677", "abs": "https://arxiv.org/abs/2507.13677", "authors": ["Chuheng Wei", "Ziye Qin", "Walter Zimmer", "Guoyuan Wu", "Matthew J. Barth"], "title": "HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "comment": "Ranked first in CVPR DriveX workshop TUM-Traf V2X challenge. Accepted\n  by ITSC2025", "summary": "Real-world Vehicle-to-Everything (V2X) cooperative perception systems often\noperate under heterogeneous sensor configurations due to cost constraints and\ndeployment variability across vehicles and infrastructure. This heterogeneity\nposes significant challenges for feature fusion and perception reliability. To\naddress these issues, we propose HeCoFuse, a unified framework designed for\ncooperative perception across mixed sensor setups where nodes may carry Cameras\n(C), LiDARs (L), or both. By introducing a hierarchical fusion mechanism that\nadaptively weights features through a combination of channel-wise and spatial\nattention, HeCoFuse can tackle critical challenges such as cross-modality\nfeature misalignment and imbalanced representation quality. In addition, an\nadaptive spatial resolution adjustment module is employed to balance\ncomputational cost and fusion effectiveness. To enhance robustness across\ndifferent configurations, we further implement a cooperative learning strategy\nthat dynamically adjusts fusion type based on available modalities. Experiments\non the real-world TUMTraf-V2X dataset demonstrate that HeCoFuse achieves 43.22%\n3D mAP under the full sensor configuration (LC+LC), outperforming the CoopDet3D\nbaseline by 1.17%, and reaches an even higher 43.38% 3D mAP in the L+LC\nscenario, while maintaining 3D mAP in the range of 21.74% to 43.38% across nine\nheterogeneous sensor configurations. These results, validated by our\nfirst-place finish in the CVPR 2025 DriveX challenge, establish HeCoFuse as the\ncurrent state-of-the-art on TUM-Traf V2X dataset while demonstrating robust\nperformance across diverse sensor deployments.", "AI": {"tldr": "HeCoFuse\u662f\u4e00\u4e2a\u7edf\u4e00\u7684V2X\u534f\u540c\u611f\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u878d\u5408\u673a\u5236\u548c\u81ea\u9002\u5e94\u7a7a\u95f4\u5206\u8fa8\u7387\u8c03\u6574\uff0c\u89e3\u51b3\u4e86\u5f02\u6784\u4f20\u611f\u5668\u914d\u7f6e\u4e0b\u7684\u7279\u5f81\u878d\u5408\u95ee\u9898\uff0c\u5e76\u5728TUMTraf-V2X\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u7684V2X\u534f\u540c\u611f\u77e5\u7cfb\u7edf\u5e38\u56e0\u5f02\u6784\u4f20\u611f\u5668\u914d\u7f6e\u5bfc\u81f4\u7279\u5f81\u878d\u5408\u548c\u611f\u77e5\u53ef\u9760\u6027\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faHeCoFuse\u6846\u67b6\uff0c\u91c7\u7528\u5206\u5c42\u878d\u5408\u673a\u5236\uff08\u901a\u9053\u548c\u7a7a\u95f4\u6ce8\u610f\u529b\uff09\u548c\u81ea\u9002\u5e94\u7a7a\u95f4\u5206\u8fa8\u7387\u8c03\u6574\u6a21\u5757\uff0c\u5e76\u7ed3\u5408\u52a8\u6001\u8c03\u6574\u878d\u5408\u7c7b\u578b\u7684\u534f\u540c\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u5728TUMTraf-V2X\u6570\u636e\u96c6\u4e0a\uff0cHeCoFuse\u5728LC+LC\u914d\u7f6e\u4e0b\u8fbe\u523043.22% 3D mAP\uff0cL+LC\u914d\u7f6e\u4e0b\u8fbe\u523043.38%\uff0c\u5e76\u5728CVPR 2025 DriveX\u6311\u6218\u8d5b\u4e2d\u6392\u540d\u7b2c\u4e00\u3002", "conclusion": "HeCoFuse\u5728\u5f02\u6784\u4f20\u611f\u5668\u914d\u7f6e\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u6210\u4e3a\u5f53\u524dTUM-Traf V2X\u6570\u636e\u96c6\u4e0a\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2507.13722", "pdf": "https://arxiv.org/pdf/2507.13722", "abs": "https://arxiv.org/abs/2507.13722", "authors": ["Julia Laubmann", "Johannes Reschke"], "title": "Tackling fake images in cybersecurity -- Interpretation of a StyleGAN and lifting its black-box", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": null, "summary": "In today's digital age, concerns about the dangers of AI-generated images are\nincreasingly common. One powerful tool in this domain is StyleGAN (style-based\ngenerative adversarial networks), a generative adversarial network capable of\nproducing highly realistic synthetic faces. To gain a deeper understanding of\nhow such a model operates, this work focuses on analyzing the inner workings of\nStyleGAN's generator component. Key architectural elements and techniques, such\nas the Equalized Learning Rate, are explored in detail to shed light on the\nmodel's behavior. A StyleGAN model is trained using the PyTorch framework,\nenabling direct inspection of its learned weights. Through pruning, it is\nrevealed that a significant number of these weights can be removed without\ndrastically affecting the output, leading to reduced computational\nrequirements. Moreover, the role of the latent vector -- which heavily\ninfluences the appearance of the generated faces -- is closely examined. Global\nalterations to this vector primarily affect aspects like color tones, while\ntargeted changes to individual dimensions allow for precise manipulation of\nspecific facial features. This ability to finetune visual traits is not only of\nacademic interest but also highlights a serious ethical concern: the potential\nmisuse of such technology. Malicious actors could exploit this capability to\nfabricate convincing fake identities, posing significant risks in the context\nof digital deception and cybercrime.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86StyleGAN\u751f\u6210\u5668\u7684\u5185\u90e8\u673a\u5236\uff0c\u63a2\u8ba8\u4e86\u5176\u5173\u952e\u67b6\u6784\u548c\u6280\u672f\uff0c\u5982\u5747\u8861\u5b66\u4e60\u7387\uff0c\u5e76\u901a\u8fc7\u4fee\u526a\u6743\u91cd\u51cf\u5c11\u8ba1\u7b97\u9700\u6c42\u3002\u540c\u65f6\u7814\u7a76\u4e86\u6f5c\u5728\u5411\u91cf\u5bf9\u751f\u6210\u4eba\u8138\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u4e86\u5176\u7cbe\u786e\u64cd\u63a7\u80fd\u529b\u53ca\u6f5c\u5728\u7684\u4f26\u7406\u98ce\u9669\u3002", "motivation": "\u968f\u7740AI\u751f\u6210\u56fe\u50cf\u6280\u672f\u7684\u666e\u53ca\uff0c\u7406\u89e3StyleGAN\u7684\u5de5\u4f5c\u539f\u7406\u53ca\u5176\u6f5c\u5728\u98ce\u9669\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\u3002", "method": "\u4f7f\u7528PyTorch\u6846\u67b6\u8bad\u7ec3StyleGAN\u6a21\u578b\uff0c\u901a\u8fc7\u4fee\u526a\u6743\u91cd\u548c\u8be6\u7ec6\u5206\u6790\u6f5c\u5728\u5411\u91cf\u6765\u7814\u7a76\u5176\u884c\u4e3a\u3002", "result": "\u53d1\u73b0\u5927\u91cf\u6743\u91cd\u53ef\u88ab\u4fee\u526a\u800c\u4e0d\u663e\u8457\u5f71\u54cd\u8f93\u51fa\uff0c\u4e14\u6f5c\u5728\u5411\u91cf\u53ef\u7cbe\u786e\u64cd\u63a7\u4eba\u8138\u7279\u5f81\u3002", "conclusion": "StyleGAN\u7684\u7cbe\u786e\u64cd\u63a7\u80fd\u529b\u867d\u5177\u5b66\u672f\u4ef7\u503c\uff0c\u4f46\u4e5f\u53ef\u80fd\u88ab\u6076\u610f\u5229\u7528\uff0c\u5f15\u53d1\u4e25\u91cd\u7684\u4f26\u7406\u95ee\u9898\u3002"}}
{"id": "2507.13732", "pdf": "https://arxiv.org/pdf/2507.13732", "abs": "https://arxiv.org/abs/2507.13732", "authors": ["Guillaume Zambrano"], "title": "The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction", "categories": ["cs.CL", "cs.LG", "J.1; I.2.7"], "comment": "23 pages, 24 figures shorter version submitted to JURIX 2025", "summary": "This study examines the role of human judges in legal decision-making by\nusing machine learning to predict child physical custody outcomes in French\nappellate courts. Building on the legal realism-formalism debate, we test\nwhether individual judges' decision-making patterns significantly influence\ncase outcomes, challenging the assumption that judges are neutral variables\nthat apply the law uniformly. To ensure compliance with French privacy laws, we\nimplement a strict pseudonymization process. Our analysis uses 18,937 living\narrangements rulings extracted from 10,306 cases. We compare models trained on\nindividual judges' past rulings (specialist models) with a judge-agnostic model\ntrained on aggregated data (generalist models). The prediction pipeline is a\nhybrid approach combining large language models (LLMs) for structured feature\nextraction and ML models for outcome prediction (RF, XGB and SVC). Our results\nshow that specialist models consistently achieve higher predictive accuracy\nthan the general model, with top-performing models reaching F1 scores as high\nas 92.85%, compared to the generalist model's 82.63% trained on 20x to 100x\nmore samples. Specialist models capture stable individual patterns that are not\ntransferable to other judges. In-Domain and Cross-Domain validity tests provide\nempirical support for legal realism, demonstrating that judicial identity plays\na measurable role in legal outcomes. All data and code used will be made\navailable.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u6cd5\u56fd\u4e0a\u8bc9\u6cd5\u9662\u7684\u513f\u7ae5\u629a\u517b\u6743\u5224\u51b3\uff0c\u53d1\u73b0\u6cd5\u5b98\u4e2a\u4f53\u51b3\u7b56\u6a21\u5f0f\u663e\u8457\u5f71\u54cd\u7ed3\u679c\uff0c\u652f\u6301\u6cd5\u5f8b\u73b0\u5b9e\u4e3b\u4e49\u89c2\u70b9\u3002", "motivation": "\u6311\u6218\u6cd5\u5b98\u4f5c\u4e3a\u4e2d\u7acb\u53d8\u91cf\u7edf\u4e00\u9002\u7528\u6cd5\u5f8b\u7684\u5047\u8bbe\uff0c\u63a2\u8ba8\u6cd5\u5b98\u4e2a\u4f53\u51b3\u7b56\u5bf9\u6848\u4ef6\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63d0\u53d6\u7ed3\u6784\u5316\u7279\u5f81\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08RF\u3001XGB\u3001SVC\uff09\u9884\u6d4b\u7ed3\u679c\uff0c\u6bd4\u8f83\u4e2a\u4f53\u6cd5\u5b98\u6a21\u578b\u4e0e\u901a\u7528\u6a21\u578b\u3002", "result": "\u4e2a\u4f53\u6cd5\u5b98\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u7387\u663e\u8457\u9ad8\u4e8e\u901a\u7528\u6a21\u578b\uff08F1\u5206\u657092.85% vs 82.63%\uff09\uff0c\u652f\u6301\u6cd5\u5b98\u4e2a\u4f53\u6a21\u5f0f\u5bf9\u5224\u51b3\u7684\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u652f\u6301\u6cd5\u5f8b\u73b0\u5b9e\u4e3b\u4e49\uff0c\u6cd5\u5b98\u8eab\u4efd\u5bf9\u6cd5\u5f8b\u7ed3\u679c\u6709\u53ef\u6d4b\u91cf\u5f71\u54cd\uff0c\u6570\u636e\u4e0e\u4ee3\u7801\u5c06\u516c\u5f00\u3002"}}
{"id": "2507.13772", "pdf": "https://arxiv.org/pdf/2507.13772", "abs": "https://arxiv.org/abs/2507.13772", "authors": ["Abhijit Sen", "Giridas Maiti", "Bikram K. Parida", "Bhanu P. Mishra", "Mahima Arya", "Denys I. Bondar"], "title": "Feature Engineering is Not Dead: Reviving Classical Machine Learning with Entropy, HOG, and LBP Feature Fusion for Image Classification", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Feature engineering continues to play a critical role in image\nclassification, particularly when interpretability and computational efficiency\nare prioritized over deep learning models with millions of parameters. In this\nstudy, we revisit classical machine learning based image classification through\na novel approach centered on Permutation Entropy (PE), a robust and\ncomputationally lightweight measure traditionally used in time series analysis\nbut rarely applied to image data. We extend PE to two-dimensional images and\npropose a multiscale, multi-orientation entropy-based feature extraction\napproach that characterizes spatial order and complexity along rows, columns,\ndiagonals, anti-diagonals, and local patches of the image. To enhance the\ndiscriminatory power of the entropy features, we integrate two classic image\ndescriptors: the Histogram of Oriented Gradients (HOG) to capture shape and\nedge structure, and Local Binary Patterns (LBP) to encode micro-texture of an\nimage. The resulting hand-crafted feature set, comprising of 780 dimensions, is\nused to train Support Vector Machine (SVM) classifiers optimized through grid\nsearch. The proposed approach is evaluated on multiple benchmark datasets,\nincluding Fashion-MNIST, KMNIST, EMNIST, and CIFAR-10, where it delivers\ncompetitive classification performance without relying on deep architectures.\nOur results demonstrate that the fusion of PE with HOG and LBP provides a\ncompact, interpretable, and effective alternative to computationally expensive\nand limited interpretable deep learning models. This shows a potential of\nentropy-based descriptors in image classification and contributes a lightweight\nand generalizable solution to interpretable machine learning in image\nclassification and computer vision.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6392\u5217\u71b5\uff08PE\uff09\u7684\u65b0\u578b\u56fe\u50cf\u5206\u7c7b\u65b9\u6cd5\uff0c\u7ed3\u5408HOG\u548cLBP\u7279\u5f81\uff0c\u8bad\u7ec3SVM\u5206\u7c7b\u5668\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5728\u56fe\u50cf\u5206\u7c7b\u4e2d\uff0c\u7279\u5f81\u5de5\u7a0b\u5728\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u4ecd\u5177\u4f18\u52bf\uff0c\u5c24\u5176\u662f\u4e0e\u53c2\u6570\u5e9e\u5927\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u76f8\u6bd4\u3002", "method": "\u6269\u5c55PE\u81f3\u4e8c\u7ef4\u56fe\u50cf\uff0c\u7ed3\u5408HOG\u548cLBP\u63d0\u53d6\u591a\u5c3a\u5ea6\u3001\u591a\u65b9\u5411\u71b5\u7279\u5f81\uff0c\u8bad\u7ec3SVM\u5206\u7c7b\u5668\u3002", "result": "\u5728Fashion-MNIST\u7b49\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5c55\u793a\u4e86PE\u4e0eHOG\u3001LBP\u878d\u5408\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u56fe\u50cf\u5206\u7c7b\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u3001\u53ef\u89e3\u91ca\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u71b5\u63cf\u8ff0\u7b26\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.13827", "pdf": "https://arxiv.org/pdf/2507.13827", "abs": "https://arxiv.org/abs/2507.13827", "authors": ["Hosein Azarbonyad", "Zi Long Zhu", "Georgios Cheirmpos", "Zubair Afzal", "Vikrant Yadav", "Georgios Tsatsaronis"], "title": "Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models", "categories": ["cs.CL", "cs.IR", "cs.LG"], "comment": "SIGIR 2025", "summary": "When deciding to read an article or incorporate it into their research,\nscholars often seek to quickly identify and understand its main ideas. In this\npaper, we aim to extract these key concepts and contributions from scientific\narticles in the form of Question and Answer (QA) pairs. We propose two distinct\napproaches for generating QAs. The first approach involves selecting salient\nparagraphs, using a Large Language Model (LLM) to generate questions, ranking\nthese questions by the likelihood of obtaining meaningful answers, and\nsubsequently generating answers. This method relies exclusively on the content\nof the articles. However, assessing an article's novelty typically requires\ncomparison with the existing literature. Therefore, our second approach\nleverages a Knowledge Graph (KG) for QA generation. We construct a KG by\nfine-tuning an Entity Relationship (ER) extraction model on scientific articles\nand using it to build the graph. We then employ a salient triplet extraction\nmethod to select the most pertinent ERs per article, utilizing metrics such as\nthe centrality of entities based on a triplet TF-IDF-like measure. This measure\nassesses the saliency of a triplet based on its importance within the article\ncompared to its prevalence in the literature. For evaluation, we generate QAs\nusing both approaches and have them assessed by Subject Matter Experts (SMEs)\nthrough a set of predefined metrics to evaluate the quality of both questions\nand answers. Our evaluations demonstrate that the KG-based approach effectively\ncaptures the main ideas discussed in the articles. Furthermore, our findings\nindicate that fine-tuning the ER extraction model on our scientific corpus is\ncrucial for extracting high-quality triplets from such documents.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u751f\u6210\u95ee\u7b54\u5bf9\u7684\u65b9\u6cd5\uff1a\u4e00\u79cd\u57fa\u4e8e\u6587\u7ae0\u5185\u5bb9\uff0c\u53e6\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\uff0c\u7528\u4e8e\u5feb\u901f\u63d0\u53d6\u79d1\u5b66\u6587\u7ae0\u7684\u6838\u5fc3\u601d\u60f3\u3002", "motivation": "\u5b66\u8005\u9700\u8981\u5feb\u901f\u7406\u89e3\u6587\u7ae0\u6838\u5fc3\u601d\u60f3\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u65b0\u9896\u6027\u7684\u8bc4\u4f30\u3002", "method": "\u65b9\u6cd5\u4e00\uff1a\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u6587\u7ae0\u6bb5\u843d\u751f\u6210\u95ee\u7b54\u5bf9\uff1b\u65b9\u6cd5\u4e8c\uff1a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\uff0c\u901a\u8fc7\u5b9e\u4f53\u5173\u7cfb\u63d0\u53d6\u548c\u4e09\u5143\u7ec4\u7b5b\u9009\u751f\u6210\u95ee\u7b54\u5bf9\u3002", "result": "\u77e5\u8bc6\u56fe\u8c31\u65b9\u6cd5\u80fd\u6709\u6548\u6355\u6349\u6587\u7ae0\u6838\u5fc3\u601d\u60f3\uff0c\u4e14\u5b9e\u4f53\u5173\u7cfb\u6a21\u578b\u7684\u5fae\u8c03\u5bf9\u9ad8\u8d28\u91cf\u4e09\u5143\u7ec4\u63d0\u53d6\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u77e5\u8bc6\u56fe\u8c31\u65b9\u6cd5\u4f18\u4e8e\u7eaf\u5185\u5bb9\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u79d1\u5b66\u6587\u7ae0\u7684\u6838\u5fc3\u601d\u60f3\u63d0\u53d6\u3002"}}
{"id": "2507.13835", "pdf": "https://arxiv.org/pdf/2507.13835", "abs": "https://arxiv.org/abs/2507.13835", "authors": ["Martin V. Vejling", "Shashi Raj Pandey", "Christophe A. N. Biscio", "Petar Popovski"], "title": "Conformal Data Contamination Tests for Trading or Sharing of Data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "The amount of quality data in many machine learning tasks is limited to what\nis available locally to data owners. The set of quality data can be expanded\nthrough trading or sharing with external data agents. However, data buyers need\nquality guarantees before purchasing, as external data may be contaminated or\nirrelevant to their specific learning task. Previous works primarily rely on\ndistributional assumptions about data from different agents, relegating quality\nchecks to post-hoc steps involving costly data valuation procedures. We propose\na distribution-free, contamination-aware data-sharing framework that identifies\nexternal data agents whose data is most valuable for model personalization. To\nachieve this, we introduce novel two-sample testing procedures, grounded in\nrigorous theoretical foundations for conformal outlier detection, to determine\nwhether an agent's data exceeds a contamination threshold. The proposed tests,\ntermed conformal data contamination tests, remain valid under arbitrary\ncontamination levels while enabling false discovery rate control via the\nBenjamini-Hochberg procedure. Empirical evaluations across diverse\ncollaborative learning scenarios demonstrate the robustness and effectiveness\nof our approach. Overall, the conformal data contamination test distinguishes\nitself as a generic procedure for aggregating data with statistically rigorous\nquality guarantees.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u65e0\u5173\u3001\u6c61\u67d3\u611f\u77e5\u7684\u6570\u636e\u5171\u4eab\u6846\u67b6\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u4e24\u6837\u672c\u6d4b\u8bd5\u65b9\u6cd5\u8bc6\u522b\u5bf9\u6a21\u578b\u4e2a\u6027\u5316\u6700\u6709\u4ef7\u503c\u7684\u5916\u90e8\u6570\u636e\u4ee3\u7406\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4e2d\u672c\u5730\u6570\u636e\u6709\u9650\u7684\u95ee\u9898\uff0c\u540c\u65f6\u786e\u4fdd\u5916\u90e8\u6570\u636e\u7684\u8d28\u91cf\uff0c\u907f\u514d\u6c61\u67d3\u6216\u4e0d\u76f8\u5173\u6570\u636e\u7684\u5f71\u54cd\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u4e25\u683c\u7406\u8bba\u57fa\u7840\u7684\u5171\u5f62\u5f02\u5e38\u68c0\u6d4b\u7684\u4e24\u6837\u672c\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u79f0\u4e3a\u5171\u5f62\u6570\u636e\u6c61\u67d3\u6d4b\u8bd5\uff0c\u7528\u4e8e\u5224\u65ad\u6570\u636e\u662f\u5426\u8d85\u8fc7\u6c61\u67d3\u9608\u503c\u3002", "result": "\u5728\u591a\u79cd\u534f\u4f5c\u5b66\u4e60\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\uff0c\u80fd\u591f\u63a7\u5236\u9519\u8bef\u53d1\u73b0\u7387\u3002", "conclusion": "\u5171\u5f62\u6570\u636e\u6c61\u67d3\u6d4b\u8bd5\u662f\u4e00\u79cd\u901a\u7528\u7684\u6570\u636e\u805a\u5408\u65b9\u6cd5\uff0c\u63d0\u4f9b\u7edf\u8ba1\u4e0a\u4e25\u683c\u7684\u8d28\u91cf\u4fdd\u8bc1\u3002"}}
{"id": "2507.13871", "pdf": "https://arxiv.org/pdf/2507.13871", "abs": "https://arxiv.org/abs/2507.13871", "authors": ["Mehul Anand", "Shishir Kolathaya"], "title": "Safety Certification in the Latent space using Control Barrier Functions and World Models", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": "6 pages, 6 figures. arXiv admin note: text overlap with\n  arXiv:2409.12616", "summary": "Synthesising safe controllers from visual data typically requires extensive\nsupervised labelling of safety-critical data, which is often impractical in\nreal-world settings. Recent advances in world models enable reliable prediction\nin latent spaces, opening new avenues for scalable and data-efficient safe\ncontrol. In this work, we introduce a semi-supervised framework that leverages\ncontrol barrier certificates (CBCs) learned in the latent space of a world\nmodel to synthesise safe visuomotor policies. Our approach jointly learns a\nneural barrier function and a safe controller using limited labelled data,\nwhile exploiting the predictive power of modern vision transformers for latent\ndynamics modelling.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u76d1\u7763\u6846\u67b6\uff0c\u5229\u7528\u4e16\u754c\u6a21\u578b\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u63a7\u5236\u5c4f\u969c\u8bc1\u4e66\uff08CBCs\uff09\u5408\u6210\u5b89\u5168\u7684\u89c6\u89c9\u8fd0\u52a8\u7b56\u7565\u3002", "motivation": "\u4ece\u89c6\u89c9\u6570\u636e\u5408\u6210\u5b89\u5168\u63a7\u5236\u5668\u901a\u5e38\u9700\u8981\u5927\u91cf\u6807\u8bb0\u5b89\u5168\u5173\u952e\u6570\u636e\uff0c\u8fd9\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u4e0d\u5207\u5b9e\u9645\u3002", "method": "\u7ed3\u5408\u5b66\u4e60\u795e\u7ecf\u5c4f\u969c\u51fd\u6570\u548c\u5b89\u5168\u63a7\u5236\u5668\uff0c\u5229\u7528\u73b0\u4ee3\u89c6\u89c9\u53d8\u6362\u5668\u7684\u9884\u6d4b\u80fd\u529b\u8fdb\u884c\u6f5c\u5728\u52a8\u529b\u5b66\u5efa\u6a21\u3002", "result": "\u901a\u8fc7\u6709\u9650\u7684\u6807\u8bb0\u6570\u636e\u5b9e\u73b0\u4e86\u5b89\u5168\u7684\u89c6\u89c9\u8fd0\u52a8\u7b56\u7565\u5408\u6210\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u53ef\u6269\u5c55\u4e14\u6570\u636e\u9ad8\u6548\u7684\u5b89\u5168\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2507.13887", "pdf": "https://arxiv.org/pdf/2507.13887", "abs": "https://arxiv.org/abs/2507.13887", "authors": ["James A. D. Binnie", "Pawe\u0142 D\u0142otko", "John Harvey", "Jakub Malinowski", "Ka Man Yim"], "title": "A Survey of Dimension Estimation Methods", "categories": ["stat.ML", "cs.LG", "math.DG", "math.MG", "math.ST", "stat.TH", "62R40 (Primary) 62R30, 62R07, 62G05, 53Z50 (Secondary)"], "comment": "45 pages + appendices, 24 figures", "summary": "It is a standard assumption that datasets in high dimension have an internal\nstructure which means that they in fact lie on, or near, subsets of a lower\ndimension. In many instances it is important to understand the real dimension\nof the data, hence the complexity of the dataset at hand. A great variety of\ndimension estimators have been developed to find the intrinsic dimension of the\ndata but there is little guidance on how to reliably use these estimators.\n  This survey reviews a wide range of dimension estimation methods,\ncategorising them by the geometric information they exploit: tangential\nestimators which detect a local affine structure; parametric estimators which\nrely on dimension-dependent probability distributions; and estimators which use\ntopological or metric invariants.\n  The paper evaluates the performance of these methods, as well as\ninvestigating varying responses to curvature and noise. Key issues addressed\ninclude robustness to hyperparameter selection, sample size requirements,\naccuracy in high dimensions, precision, and performance on non-linear\ngeometries. In identifying the best hyperparameters for benchmark datasets,\noverfitting is frequent, indicating that many estimators may not generalise\nwell beyond the datasets on which they have been tested.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u591a\u79cd\u9ad8\u7ef4\u6570\u636e\u96c6\u5185\u5728\u7ef4\u5ea6\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5206\u7c7b\u5e76\u8bc4\u4f30\u4e86\u5176\u6027\u80fd\uff0c\u6307\u51fa\u4e86\u8fc7\u62df\u5408\u548c\u6cdb\u5316\u95ee\u9898\u3002", "motivation": "\u9ad8\u7ef4\u6570\u636e\u96c6\u901a\u5e38\u5177\u6709\u4f4e\u7ef4\u5185\u5728\u7ed3\u6784\uff0c\u4f46\u7f3a\u4e4f\u53ef\u9760\u7684\u7ef4\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u6307\u5bfc\u3002", "method": "\u5c06\u7ef4\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u5206\u4e3a\u4e09\u7c7b\uff1a\u57fa\u4e8e\u5c40\u90e8\u4eff\u5c04\u7ed3\u6784\u7684\u5207\u7ebf\u4f30\u8ba1\u3001\u4f9d\u8d56\u7ef4\u5ea6\u6982\u7387\u5206\u5e03\u7684\u53c2\u6570\u4f30\u8ba1\uff0c\u4ee5\u53ca\u5229\u7528\u62d3\u6251\u6216\u5ea6\u91cf\u4e0d\u53d8\u6027\u7684\u4f30\u8ba1\u3002", "result": "\u8bc4\u4f30\u4e86\u65b9\u6cd5\u5728\u66f2\u7387\u3001\u566a\u58f0\u3001\u8d85\u53c2\u6570\u9009\u62e9\u3001\u6837\u672c\u91cf\u7b49\u65b9\u9762\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u8bb8\u591a\u65b9\u6cd5\u5b58\u5728\u8fc7\u62df\u5408\u95ee\u9898\u3002", "conclusion": "\u8bb8\u591a\u7ef4\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002"}}
{"id": "2507.13942", "pdf": "https://arxiv.org/pdf/2507.13942", "abs": "https://arxiv.org/abs/2507.13942", "authors": ["Jacob C Walker", "Pedro V\u00e9lez", "Luisa Polania Cabrera", "Guangyao Zhou", "Rishabh Kabra", "Carl Doersch", "Maks Ovsjanikov", "Jo\u00e3o Carreira", "Shiry Ginosar"], "title": "Generalist Forecasting with Frozen Video Models via Latent Diffusion", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Forecasting what will happen next is a critical skill for general-purpose\nsystems that plan or act in the world at different levels of abstraction. In\nthis paper, we identify a strong correlation between a vision model's\nperceptual ability and its generalist forecasting performance over short time\nhorizons. This trend holds across a diverse set of pretrained models-including\nthose trained generatively-and across multiple levels of abstraction, from raw\npixels to depth, point tracks, and object motion. The result is made possible\nby a novel generalist forecasting framework that operates on any frozen vision\nbackbone: we train latent diffusion models to forecast future features in the\nfrozen representation space, which are then decoded via lightweight,\ntask-specific readouts. To enable consistent evaluation across tasks, we\nintroduce distributional metrics that compare distributional properties\ndirectly in the space of downstream tasks and apply this framework to nine\nmodels and four tasks. Our results highlight the value of bridging\nrepresentation learning and generative modeling for temporally grounded video\nunderstanding.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u89c6\u89c9\u6a21\u578b\u7684\u611f\u77e5\u80fd\u529b\u4e0e\u5176\u77ed\u671f\u9884\u6d4b\u6027\u80fd\u5f3a\u76f8\u5173\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u9884\u6d4b\u6846\u67b6\uff0c\u5229\u7528\u6f5c\u5728\u6269\u6563\u6a21\u578b\u5728\u51bb\u7ed3\u8868\u793a\u7a7a\u95f4\u9884\u6d4b\u672a\u6765\u7279\u5f81\u3002", "motivation": "\u63a2\u7d22\u89c6\u89c9\u6a21\u578b\u7684\u611f\u77e5\u80fd\u529b\u5982\u4f55\u5f71\u54cd\u5176\u9884\u6d4b\u6027\u80fd\uff0c\u4ee5\u63d0\u5347\u89c6\u9891\u7406\u89e3\u7684\u65f6\u7a7a\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u901a\u7528\u9884\u6d4b\u6846\u67b6\uff0c\u8bad\u7ec3\u6f5c\u5728\u6269\u6563\u6a21\u578b\u9884\u6d4b\u51bb\u7ed3\u89c6\u89c9\u9aa8\u5e72\u7684\u672a\u6765\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u4efb\u52a1\u7279\u5b9a\u89e3\u7801\u5668\u89e3\u7801\u3002", "result": "\u5728\u4e5d\u79cd\u6a21\u578b\u548c\u56db\u9879\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u663e\u793a\u611f\u77e5\u80fd\u529b\u4e0e\u9884\u6d4b\u6027\u80fd\u5f3a\u76f8\u5173\u3002", "conclusion": "\u7ed3\u5408\u8868\u793a\u5b66\u4e60\u548c\u751f\u6210\u6a21\u578b\u5bf9\u65f6\u7a7a\u89c6\u9891\u7406\u89e3\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2507.13957", "pdf": "https://arxiv.org/pdf/2507.13957", "abs": "https://arxiv.org/abs/2507.13957", "authors": ["Yitong Li", "Raoul Grasman"], "title": "DUALRec: A Hybrid Sequential and Language Model Framework for Context-Aware Movie Recommendation", "categories": ["cs.IR", "cs.AI", "cs.LG", "68T05, 68T50, 62M45", "H.3.3; I.2.6; H.3.4; I.2.7"], "comment": "10 pages, 5 figures", "summary": "The modern recommender systems are facing an increasing challenge of\nmodelling and predicting the dynamic and context-rich user preferences.\nTraditional collaborative filtering and content-based methods often struggle to\ncapture the temporal patternings and evolving user intentions. While Large\nLanguage Models (LLMs) have gained gradual attention in recent years, by their\nstrong semantic understanding and reasoning abilities, they are not inherently\ndesigned to model chronologically evolving user preference and intentions. On\nthe other hand, for sequential models like LSTM (Long-Short-Term-Memory) which\nis good at capturing the temporal dynamics of user behaviour and evolving user\npreference over time, but still lacks a rich semantic understanding for\ncomprehensive recommendation generation. In this study, we propose DUALRec\n(Dynamic User-Aware Language-based Recommender), a novel recommender that\nleverages the complementary strength of both models, which combines the\ntemporal modelling abilities of LSTM networks with semantic reasoning power of\nthe fine-tuned Large Language Models. The LSTM component will capture users\nevolving preference through their viewing history, while the fine-tuned LLM\nvariants will leverage these temporal user insights to generate next movies\nthat users might enjoy. Experimental results on MovieLens-1M dataset shows that\nthe DUALRec model outperforms a wide range of baseline models, with\ncomprehensive evaluation matrices of Hit Rate (HR@k), Normalized Discounted\nCumulative Gain (NDCG@k), and genre similarity metrics. This research proposes\na novel architecture that bridges the gap between temporal sequence modeling\nand semantic reasoning, and offers a promising direction for developing more\nintelligent and context-aware recommenders.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDUALRec\u6a21\u578b\uff0c\u7ed3\u5408LSTM\u7684\u65f6\u95f4\u52a8\u6001\u5efa\u6a21\u80fd\u529b\u548cLLM\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\uff0c\u4ee5\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u4e2d\u52a8\u6001\u7528\u6237\u504f\u597d\u7684\u5efa\u6a21\u95ee\u9898\u3002", "motivation": "\u73b0\u4ee3\u63a8\u8350\u7cfb\u7edf\u96be\u4ee5\u6355\u6349\u52a8\u6001\u548c\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u7528\u6237\u504f\u597d\uff0c\u4f20\u7edf\u65b9\u6cd5\u5982\u534f\u540c\u8fc7\u6ee4\u548c\u57fa\u4e8e\u5185\u5bb9\u7684\u65b9\u6cd5\u5728\u65f6\u95f4\u6a21\u5f0f\u548c\u7528\u6237\u610f\u56fe\u6f14\u5316\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\u3002", "method": "\u63d0\u51faDUALRec\u6a21\u578b\uff0c\u7ed3\u5408LSTM\u7684\u65f6\u95f4\u5efa\u6a21\u80fd\u529b\u548c\u5fae\u8c03LLM\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u7528\u6237\u5386\u53f2\u884c\u4e3a\u751f\u6210\u63a8\u8350\u3002", "result": "\u5728MovieLens-1M\u6570\u636e\u96c6\u4e0a\uff0cDUALRec\u5728HR@k\u3001NDCG@k\u548c\u7c7b\u578b\u76f8\u4f3c\u6027\u6307\u6807\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "DUALRec\u586b\u8865\u4e86\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u4e0e\u8bed\u4e49\u63a8\u7406\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u4e3a\u5f00\u53d1\u66f4\u667a\u80fd\u7684\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.14017", "pdf": "https://arxiv.org/pdf/2507.14017", "abs": "https://arxiv.org/abs/2507.14017", "authors": ["Haoyu He", "Haozheng Luo", "Yan Chen", "Qi R. Wang"], "title": "Efficient Temporal Tokenization for Mobility Prediction with Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for\nHuman Mobility), a framework that leverages large language models (LLMs) as\nspatio-temporal predictors and trajectory reasoners. RHYTHM partitions\ntrajectories into daily segments encoded as discrete tokens with hierarchical\nattention, capturing both daily and weekly dependencies while substantially\nreducing the sequence length. Token representations are enriched with\npre-computed prompt embeddings via a frozen LLM, enhancing the model's ability\nto capture interdependencies without extensive computational overhead. By\nfreezing the LLM backbone, RHYTHM achieves significant computational\nefficiency. Evaluation on three real-world datasets demonstrates a 2.4%\nimprovement in accuracy, 5.0% increase on weekends, and 24.6% reduction in\ntraining time compared to state-of-the-art methods.", "AI": {"tldr": "RHYTHM\u662f\u4e00\u4e2a\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u65f6\u7a7a\u9884\u6d4b\u548c\u8f68\u8ff9\u63a8\u7406\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u65f6\u95f4\u6807\u8bb0\u5316\u548c\u51bb\u7ed3LLM\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u3002", "motivation": "\u89e3\u51b3\u8f68\u8ff9\u9884\u6d4b\u4e2d\u5e8f\u5217\u957f\u5ea6\u8fc7\u957f\u548c\u8ba1\u7b97\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u5c06\u8f68\u8ff9\u5206\u5272\u4e3a\u6bcf\u65e5\u6bb5\u5e76\u7f16\u7801\u4e3a\u79bb\u6563\u6807\u8bb0\uff0c\u5229\u7528\u5206\u5c42\u6ce8\u610f\u529b\u6355\u83b7\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u9884\u8ba1\u7b97\u63d0\u793a\u5d4c\u5165\u589e\u5f3a\u6a21\u578b\u80fd\u529b\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u51c6\u786e\u7387\u63d0\u53472.4%\uff0c\u5468\u672b\u63d0\u53475.0%\uff0c\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c1124.6%\u3002", "conclusion": "RHYTHM\u5728\u8ba1\u7b97\u6548\u7387\u548c\u9884\u6d4b\u6027\u80fd\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.14022", "pdf": "https://arxiv.org/pdf/2507.14022", "abs": "https://arxiv.org/abs/2507.14022", "authors": ["Jianfei Li", "Kevin Kam Fung Yuen"], "title": "CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis", "categories": ["cs.CL", "cs.LG"], "comment": "35 pages, 33 tables, 6 Figures", "summary": "This study proposes the Cognitive Pairwise Comparison Classification Model\nSelection (CPC-CMS) framework for document-level sentiment analysis. The CPC,\nbased on expert knowledge judgment, is used to calculate the weights of\nevaluation criteria, including accuracy, precision, recall, F1-score,\nspecificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and\nefficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random\nForest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long\nShort-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from\nTransformers (ALBERT) are chosen as classification baseline models. A weighted\ndecision matrix consisting of classification evaluation scores with respect to\ncriteria weights, is formed to select the best classification model for a\nclassification problem. Three open datasets of social media are used to\ndemonstrate the feasibility of the proposed CPC-CMS. Based on our simulation,\nfor evaluation results excluding the time factor, ALBERT is the best for the\nthree datasets; if time consumption is included, no single model always\nperforms better than the other models. The CPC-CMS can be applied to the other\nclassification applications in different areas.", "AI": {"tldr": "\u63d0\u51faCPC-CMS\u6846\u67b6\u7528\u4e8e\u6587\u6863\u7ea7\u60c5\u611f\u5206\u6790\uff0c\u901a\u8fc7\u4e13\u5bb6\u77e5\u8bc6\u8ba1\u7b97\u6743\u91cd\uff0c\u9009\u62e9\u6700\u4f73\u5206\u7c7b\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u6587\u6863\u7ea7\u60c5\u611f\u5206\u6790\u4e2d\u6a21\u578b\u9009\u62e9\u95ee\u9898\uff0c\u7ed3\u5408\u591a\u8bc4\u4ef7\u6807\u51c6\u4f18\u5316\u9009\u62e9\u3002", "method": "\u57fa\u4e8e\u4e13\u5bb6\u77e5\u8bc6\u8ba1\u7b97\u6743\u91cd\uff0c\u6784\u5efa\u52a0\u6743\u51b3\u7b56\u77e9\u9635\uff0c\u6bd4\u8f83\u591a\u79cd\u57fa\u7ebf\u6a21\u578b\u3002", "result": "ALBERT\u5728\u6392\u9664\u65f6\u95f4\u56e0\u7d20\u65f6\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u8003\u8651\u65f6\u95f4\u6d88\u8017\u65f6\u65e0\u5355\u4e00\u6a21\u578b\u59cb\u7ec8\u6700\u4f18\u3002", "conclusion": "CPC-CMS\u53ef\u6269\u5c55\u81f3\u5176\u4ed6\u5206\u7c7b\u5e94\u7528\u9886\u57df\u3002"}}
{"id": "2507.14023", "pdf": "https://arxiv.org/pdf/2507.14023", "abs": "https://arxiv.org/abs/2507.14023", "authors": ["Zhanli Wu", "Fabrizio Leisen", "F. Javier Rubio"], "title": "Conformalized Regression for Continuous Bounded Outcomes", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "R code and data can be found at: https://github.com/ZWU-001/CPBounded", "summary": "Regression problems with bounded continuous outcomes frequently arise in\nreal-world statistical and machine learning applications, such as the analysis\nof rates and proportions. A central challenge in this setting is predicting a\nresponse associated with a new covariate value. Most of the existing\nstatistical and machine learning literature has focused either on point\nprediction of bounded outcomes or on interval prediction based on asymptotic\napproximations. We develop conformal prediction intervals for bounded outcomes\nbased on transformation models and beta regression. We introduce tailored\nnon-conformity measures based on residuals that are aligned with the underlying\nmodels, and account for the inherent heteroscedasticity in regression settings\nwith bounded outcomes. We present a theoretical result on asymptotic marginal\nand conditional validity in the context of full conformal prediction, which\nremains valid under model misspecification. For split conformal prediction, we\nprovide an empirical coverage analysis based on a comprehensive simulation\nstudy. The simulation study demonstrates that both methods provide valid\nfinite-sample predictive coverage, including settings with model\nmisspecification. Finally, we demonstrate the practical performance of the\nproposed conformal prediction intervals on real data and compare them with\nbootstrap-based alternatives.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8f6c\u6362\u6a21\u578b\u548cBeta\u56de\u5f52\u7684\u4fdd\u5f62\u9884\u6d4b\u533a\u95f4\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u6709\u754c\u8fde\u7eed\u7ed3\u679c\u7684\u56de\u5f52\u95ee\u9898\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u70b9\u9884\u6d4b\u6216\u6e10\u8fd1\u533a\u95f4\u9884\u6d4b\u4e0a\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u89e3\u51b3\u6709\u754c\u8fde\u7eed\u7ed3\u679c\u56de\u5f52\u95ee\u9898\u4e2d\u7684\u9884\u6d4b\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u70b9\u9884\u6d4b\u548c\u6e10\u8fd1\u533a\u95f4\u9884\u6d4b\u4e4b\u5916\u7684\u66f4\u6709\u6548\u65b9\u6cd5\u7684\u9700\u6c42\u3002", "method": "\u57fa\u4e8e\u8f6c\u6362\u6a21\u578b\u548cBeta\u56de\u5f52\uff0c\u8bbe\u8ba1\u975e\u4e00\u81f4\u6027\u5ea6\u91cf\uff0c\u8003\u8651\u5f02\u65b9\u5dee\u6027\uff0c\u5e76\u9a8c\u8bc1\u4fdd\u5f62\u9884\u6d4b\u7684\u6e10\u8fd1\u6709\u6548\u6027\u3002", "result": "\u7406\u8bba\u548c\u6a21\u62df\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6709\u9650\u6837\u672c\u548c\u6a21\u578b\u8bef\u8bbe\u60c5\u51b5\u4e0b\u5747\u80fd\u63d0\u4f9b\u6709\u6548\u7684\u9884\u6d4b\u8986\u76d6\u3002", "conclusion": "\u63d0\u51fa\u7684\u4fdd\u5f62\u9884\u6d4b\u533a\u95f4\u5728\u5b9e\u9645\u6570\u636e\u548c\u6a21\u62df\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u57fa\u4e8eBootstrap\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002"}}
{"id": "2507.14031", "pdf": "https://arxiv.org/pdf/2507.14031", "abs": "https://arxiv.org/abs/2507.14031", "authors": ["Hao Fang", "Sihao Teng", "Hao Yu", "Siyi Yuan", "Huaiwu He", "Zhe Liu", "Yunjie Yang"], "title": "QuantEIT: Ultra-Lightweight Quantum-Assisted Inference for Chest Electrical Impedance Tomography", "categories": ["cs.CV", "cs.ET", "cs.LG"], "comment": "10 pages, 12 figures", "summary": "Electrical Impedance Tomography (EIT) is a non-invasive, low-cost bedside\nimaging modality with high temporal resolution, making it suitable for bedside\nmonitoring. However, its inherently ill-posed inverse problem poses significant\nchallenges for accurate image reconstruction. Deep learning (DL)-based\napproaches have shown promise but often rely on complex network architectures\nwith a large number of parameters, limiting efficiency and scalability. Here,\nwe propose an Ultra-Lightweight Quantum-Assisted Inference (QuantEIT) framework\nfor EIT image reconstruction. QuantEIT leverages a Quantum-Assisted Network\n(QA-Net), combining parallel 2-qubit quantum circuits to generate expressive\nlatent representations that serve as implicit nonlinear priors, followed by a\nsingle linear layer for conductivity reconstruction. This design drastically\nreduces model complexity and parameter number. Uniquely, QuantEIT operates in\nan unsupervised, training-data-free manner and represents the first integration\nof quantum circuits into EIT image reconstruction. Extensive experiments on\nsimulated and real-world 2D and 3D EIT lung imaging data demonstrate that\nQuantEIT outperforms conventional methods, achieving comparable or superior\nreconstruction accuracy using only 0.2% of the parameters, with enhanced\nrobustness to noise.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cf\u5b50\u8f85\u52a9\u63a8\u7406\u7684\u8d85\u8f7b\u91cf\u7ea7EIT\u56fe\u50cf\u91cd\u5efa\u6846\u67b6QuantEIT\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6a21\u578b\u590d\u6742\u6027\u548c\u53c2\u6570\u6570\u91cf\uff0c\u5e76\u5728\u65e0\u76d1\u7763\u3001\u65e0\u9700\u8bad\u7ec3\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u91cd\u5efa\u3002", "motivation": "EIT\u4f5c\u4e3a\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u9ad8\u65f6\u95f4\u5206\u8fa8\u7387\u7684\u5e8a\u8fb9\u6210\u50cf\u6280\u672f\uff0c\u5176\u9006\u95ee\u9898\u7684\u75c5\u6001\u6027\u9650\u5236\u4e86\u56fe\u50cf\u91cd\u5efa\u7684\u51c6\u786e\u6027\u3002\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u7f51\u7edc\u7ed3\u6784\uff0c\u6548\u7387\u4f4e\u4e14\u96be\u4ee5\u6269\u5c55\u3002", "method": "QuantEIT\u91c7\u7528\u91cf\u5b50\u8f85\u52a9\u7f51\u7edc\uff08QA-Net\uff09\uff0c\u7ed3\u5408\u5e76\u884c2\u91cf\u5b50\u6bd4\u7279\u7535\u8def\u751f\u6210\u9690\u5f0f\u975e\u7ebf\u6027\u5148\u9a8c\u7684\u6f5c\u5728\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u5355\u5c42\u7ebf\u6027\u7f51\u7edc\u91cd\u5efa\u7535\u5bfc\u7387\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e2D/3D\u80ba\u90e8EIT\u6570\u636e\u4e0a\uff0cQuantEIT\u4ec5\u75280.2%\u7684\u53c2\u6570\u5373\u8fbe\u5230\u6216\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u7cbe\u5ea6\uff0c\u4e14\u5bf9\u566a\u58f0\u66f4\u5177\u9c81\u68d2\u6027\u3002", "conclusion": "QuantEIT\u9996\u6b21\u5c06\u91cf\u5b50\u7535\u8def\u5f15\u5165EIT\u56fe\u50cf\u91cd\u5efa\uff0c\u4e3a\u9ad8\u6548\u3001\u8f7b\u91cf\u5316\u7684\u5e8a\u8fb9\u76d1\u6d4b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.14046", "pdf": "https://arxiv.org/pdf/2507.14046", "abs": "https://arxiv.org/abs/2507.14046", "authors": ["Hao Fang", "Hao Yu", "Sihao Teng", "Tao Zhang", "Siyi Yuan", "Huaiwu He", "Zhe Liu", "Yunjie Yang"], "title": "D2IP: Deep Dynamic Image Prior for 3D Time-sequence Pulmonary Impedance Imaging", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "11 pages, 9 figures", "summary": "Unsupervised learning methods, such as Deep Image Prior (DIP), have shown\ngreat potential in tomographic imaging due to their training-data-free nature\nand high generalization capability. However, their reliance on numerous network\nparameter iterations results in high computational costs, limiting their\npractical application, particularly in complex 3D or time-sequence tomographic\nimaging tasks. To overcome these challenges, we propose Deep Dynamic Image\nPrior (D2IP), a novel framework for 3D time-sequence imaging. D2IP introduces\nthree key strategies - Unsupervised Parameter Warm-Start (UPWS), Temporal\nParameter Propagation (TPP), and a customized lightweight reconstruction\nbackbone, 3D-FastResUNet - to accelerate convergence, enforce temporal\ncoherence, and improve computational efficiency. Experimental results on both\nsimulated and clinical pulmonary datasets demonstrate that D2IP enables fast\nand accurate 3D time-sequence Electrical Impedance Tomography (tsEIT)\nreconstruction. Compared to state-of-the-art baselines, D2IP delivers superior\nimage quality, with a 24.8% increase in average MSSIM and an 8.1% reduction in\nERR, alongside significantly reduced computational time (7.1x faster),\nhighlighting its promise for clinical dynamic pulmonary imaging.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aD2IP\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e3D\u65f6\u95f4\u5e8f\u5217\u6210\u50cf\uff0c\u901a\u8fc7\u4e09\u79cd\u7b56\u7565\uff08UPWS\u3001TPP\u548c\u8f7b\u91cf\u7ea7\u91cd\u5efa\u9aa8\u5e72\u7f51\u7edc\uff09\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u56fe\u50cf\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65e0\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff08\u5982DIP\uff09\u5728\u590d\u67423D\u6216\u65f6\u95f4\u5e8f\u5217\u6210\u50cf\u4efb\u52a1\u4e2d\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165UPWS\u3001TPP\u548c3D-FastResUNet\u4e09\u79cd\u7b56\u7565\uff0c\u52a0\u901f\u6536\u655b\u3001\u589e\u5f3a\u65f6\u95f4\u4e00\u81f4\u6027\u5e76\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5728\u6a21\u62df\u548c\u4e34\u5e8a\u6570\u636e\u96c6\u4e0a\uff0cD2IP\u5b9e\u73b0\u4e86\u5feb\u901f\u4e14\u51c6\u786e\u76843D\u65f6\u95f4\u5e8f\u5217EIT\u91cd\u5efa\uff0c\u56fe\u50cf\u8d28\u91cf\u63d0\u5347\uff08MSSIM\u589e\u52a024.8%\uff0cERR\u964d\u4f4e8.1%\uff09\uff0c\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c117.1\u500d\u3002", "conclusion": "D2IP\u5728\u4e34\u5e8a\u52a8\u6001\u80ba\u90e8\u6210\u50cf\u4e2d\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0c\u80fd\u591f\u9ad8\u6548\u4e14\u9ad8\u8d28\u91cf\u5730\u5b8c\u6210\u4efb\u52a1\u3002"}}
{"id": "2507.14057", "pdf": "https://arxiv.org/pdf/2507.14057", "abs": "https://arxiv.org/abs/2507.14057", "authors": ["Marcel Hedman", "Desi R. Ivanova", "Cong Guan", "Tom Rainforth"], "title": "Step-DAD: Semi-Amortized Policy-Based Bayesian Experimental Design", "categories": ["stat.ML", "cs.LG"], "comment": "Accepted at Proceedings of the 42nd International Conference on\n  Machine Learning, Vancouver, Canada. PMLR 267, 2025", "summary": "We develop a semi-amortized, policy-based, approach to Bayesian experimental\ndesign (BED) called Stepwise Deep Adaptive Design (Step-DAD). Like existing,\nfully amortized, policy-based BED approaches, Step-DAD trains a design policy\nupfront before the experiment. However, rather than keeping this policy fixed,\nStep-DAD periodically updates it as data is gathered, refining it to the\nparticular experimental instance. This test-time adaptation improves both the\nflexibility and the robustness of the design strategy compared with existing\napproaches. Empirically, Step-DAD consistently demonstrates superior\ndecision-making and robustness compared with current state-of-the-art BED\nmethods.", "AI": {"tldr": "Step-DAD\u662f\u4e00\u79cd\u534a\u644a\u9500\u3001\u57fa\u4e8e\u7b56\u7565\u7684\u8d1d\u53f6\u65af\u5b9e\u9a8c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u66f4\u65b0\u7b56\u7565\u63d0\u5347\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5b8c\u5168\u644a\u9500\u7b56\u7565\u5728\u5b9e\u9a8c\u8fc7\u7a0b\u4e2d\u56fa\u5b9a\u4e0d\u53d8\u7684\u95ee\u9898\uff0c\u63d0\u5347\u5b9e\u9a8c\u8bbe\u8ba1\u7684\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "Step-DAD\u5728\u5b9e\u9a8c\u524d\u8bad\u7ec3\u8bbe\u8ba1\u7b56\u7565\uff0c\u5e76\u5728\u5b9e\u9a8c\u8fc7\u7a0b\u4e2d\u52a8\u6001\u66f4\u65b0\u7b56\u7565\u4ee5\u9002\u5e94\u5177\u4f53\u5b9e\u9a8c\u5b9e\u4f8b\u3002", "result": "Step-DAD\u5728\u51b3\u7b56\u80fd\u529b\u548c\u9c81\u68d2\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u8d1d\u53f6\u65af\u5b9e\u9a8c\u8bbe\u8ba1\u65b9\u6cd5\u3002", "conclusion": "Step-DAD\u901a\u8fc7\u52a8\u6001\u7b56\u7565\u66f4\u65b0\u663e\u8457\u63d0\u5347\u4e86\u5b9e\u9a8c\u8bbe\u8ba1\u7684\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.14077", "pdf": "https://arxiv.org/pdf/2507.14077", "abs": "https://arxiv.org/abs/2507.14077", "authors": ["Temiloluwa Prioleau", "Baiying Lu", "Yanjun Cui"], "title": "Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions", "categories": ["cs.AI", "cs.LG"], "comment": "19 pages, 3 figures, 6 tables", "summary": "Artificial intelligence (AI) algorithms are a critical part of\nstate-of-the-art digital health technology for diabetes management. Yet, access\nto large high-quality datasets is creating barriers that impede development of\nrobust AI solutions. To accelerate development of transparent, reproducible,\nand robust AI solutions, we present Glucose-ML, a collection of 10 publicly\navailable diabetes datasets, released within the last 7 years (i.e., 2018 -\n2025). The Glucose-ML collection comprises over 300,000 days of continuous\nglucose monitor (CGM) data with a total of 38 million glucose samples collected\nfrom 2500+ people across 4 countries. Participants include persons living with\ntype 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support\nresearchers and innovators with using this rich collection of diabetes\ndatasets, we present a comparative analysis to guide algorithm developers with\ndata selection. Additionally, we conduct a case study for the task of blood\nglucose prediction - one of the most common AI tasks within the field. Through\nthis case study, we provide a benchmark for short-term blood glucose prediction\nacross all 10 publicly available diabetes datasets within the Glucose-ML\ncollection. We show that the same algorithm can have significantly different\nprediction results when developed/evaluated with different datasets. Findings\nfrom this study are then used to inform recommendations for developing robust\nAI solutions within the diabetes or broader health domain. We provide direct\nlinks to each longitudinal diabetes dataset in the Glucose-ML collection and\nopenly provide our code.", "AI": {"tldr": "Glucose-ML\u662f\u4e00\u4e2a\u5305\u542b10\u4e2a\u516c\u5f00\u7cd6\u5c3f\u75c5\u6570\u636e\u96c6\u7684\u96c6\u5408\uff0c\u65e8\u5728\u52a0\u901f\u900f\u660e\u3001\u53ef\u91cd\u590d\u548c\u7a33\u5065\u7684AI\u89e3\u51b3\u65b9\u6848\u5f00\u53d1\u3002", "motivation": "\u89e3\u51b3\u9ad8\u8d28\u91cf\u7cd6\u5c3f\u75c5\u6570\u636e\u96c6\u83b7\u53d6\u56f0\u96be\u7684\u95ee\u9898\uff0c\u63a8\u52a8AI\u5728\u7cd6\u5c3f\u75c5\u7ba1\u7406\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u6536\u96c6\u5e76\u6574\u540810\u4e2a\u516c\u5f00\u6570\u636e\u96c6\uff0c\u63d0\u4f9b\u6bd4\u8f83\u5206\u6790\u548c\u8840\u7cd6\u9884\u6d4b\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u540c\u4e00\u7b97\u6cd5\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u9884\u6d4b\u7ed3\u679c\u5dee\u5f02\u663e\u8457\uff0c\u4e3a\u5f00\u53d1\u7a33\u5065AI\u63d0\u4f9b\u5efa\u8bae\u3002", "conclusion": "Glucose-ML\u4e3a\u7cd6\u5c3f\u75c5AI\u7814\u7a76\u63d0\u4f9b\u4e30\u5bcc\u6570\u636e\u548c\u57fa\u51c6\uff0c\u4fc3\u8fdb\u5065\u5eb7\u9886\u57dfAI\u53d1\u5c55\u3002"}}
{"id": "2507.14079", "pdf": "https://arxiv.org/pdf/2507.14079", "abs": "https://arxiv.org/abs/2507.14079", "authors": ["Garapati Keerthana", "Manik Gupta"], "title": "DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "Progress notes are among the most clinically meaningful artifacts in an\nElectronic Health Record (EHR), offering temporally grounded insights into a\npatient's evolving condition, treatments, and care decisions. Despite their\nimportance, they are severely underrepresented in large-scale EHR datasets. For\ninstance, in the widely used Medical Information Mart for Intensive Care III\n(MIMIC-III) dataset, only about $8.56\\%$ of hospital visits include progress\nnotes, leaving gaps in longitudinal patient narratives. In contrast, the\ndataset contains a diverse array of other note types, each capturing different\naspects of care.\n  We present DENSE (Documenting Evolving Progress Notes from Scattered\nEvidence), a system designed to align with clinical documentation workflows by\nsimulating how physicians reference past encounters while drafting progress\nnotes. The system introduces a fine-grained note categorization and a temporal\nalignment mechanism that organizes heterogeneous notes across visits into\nstructured, chronological inputs. At its core, DENSE leverages a clinically\ninformed retrieval strategy to identify temporally and semantically relevant\ncontent from both current and prior visits. This retrieved evidence is used to\nprompt a large language model (LLM) to generate clinically coherent and\ntemporally aware progress notes.\n  We evaluate DENSE on a curated cohort of patients with multiple visits and\ncomplete progress note documentation. The generated notes demonstrate strong\nlongitudinal fidelity, achieving a temporal alignment ratio of $1.089$,\nsurpassing the continuity observed in original notes. By restoring narrative\ncoherence across fragmented documentation, our system supports improved\ndownstream tasks such as summarization, predictive modeling, and clinical\ndecision support, offering a scalable solution for LLM-driven note synthesis in\nreal-world healthcare settings.", "AI": {"tldr": "DENSE\u7cfb\u7edf\u901a\u8fc7\u6a21\u62df\u533b\u751f\u53c2\u8003\u5386\u53f2\u8bb0\u5f55\u7684\u65b9\u5f0f\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4e34\u5e8a\u8fde\u8d2f\u4e14\u65f6\u95f4\u654f\u611f\u7684\u8fdb\u5c55\u7b14\u8bb0\uff0c\u586b\u8865\u4e86\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u8fdb\u5c55\u7b14\u8bb0\u7684\u7f3a\u5931\u3002", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u4e2d\u8fdb\u5c55\u7b14\u8bb0\u7684\u4e25\u91cd\u7f3a\u5931\uff08\u5982MIMIC-III\u6570\u636e\u96c6\u4e2d\u4ec58.56%\u7684\u533b\u9662\u8bbf\u95ee\u5305\u542b\u8fdb\u5c55\u7b14\u8bb0\uff09\u5bfc\u81f4\u60a3\u8005\u7eb5\u5411\u53d9\u4e8b\u7684\u65ad\u88c2\uff0c\u5f71\u54cd\u4e86\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7b49\u4e0b\u6e38\u4efb\u52a1\u3002", "method": "DENSE\u7cfb\u7edf\u901a\u8fc7\u7ec6\u7c92\u5ea6\u7b14\u8bb0\u5206\u7c7b\u548c\u65f6\u95f4\u5bf9\u9f50\u673a\u5236\uff0c\u4ece\u5f53\u524d\u548c\u65e2\u5f80\u8bbf\u95ee\u4e2d\u68c0\u7d22\u76f8\u5173\u8bc1\u636e\uff0c\u5e76\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8fde\u8d2f\u7684\u8fdb\u5c55\u7b14\u8bb0\u3002", "result": "\u751f\u6210\u7684\u7b14\u8bb0\u5728\u65f6\u95f4\u5bf9\u9f50\u6bd4\u4e0a\u8fbe\u52301.089\uff0c\u4f18\u4e8e\u539f\u59cb\u7b14\u8bb0\u7684\u8fde\u7eed\u6027\uff0c\u652f\u6301\u4e86\u603b\u7ed3\u3001\u9884\u6d4b\u5efa\u6a21\u548c\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7b49\u4efb\u52a1\u3002", "conclusion": "DENSE\u7cfb\u7edf\u4e3a\u73b0\u5b9e\u533b\u7597\u73af\u5883\u4e2d\u57fa\u4e8eLLM\u7684\u7b14\u8bb0\u5408\u6210\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6062\u590d\u4e86\u788e\u7247\u5316\u6587\u6863\u7684\u53d9\u4e8b\u8fde\u8d2f\u6027\u3002"}}
{"id": "2507.14093", "pdf": "https://arxiv.org/pdf/2507.14093", "abs": "https://arxiv.org/abs/2507.14093", "authors": ["\u0160imon Kubov", "Simon Kl\u00ed\u010dn\u00edk", "Jakub Dand\u00e1r", "Zden\u011bk Straka", "Karol\u00edna Kvakov\u00e1", "Daniel Kvak"], "title": "Multi-Centre Validation of a Deep Learning Model for Scoliosis Assessment", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Scoliosis affects roughly 2 to 4 percent of adolescents, and treatment\ndecisions depend on precise Cobb angle measurement. Manual assessment is time\nconsuming and subject to inter observer variation. We conducted a\nretrospective, multi centre evaluation of a fully automated deep learning\nsoftware (Carebot AI Bones, Spine Measurement functionality; Carebot s.r.o.) on\n103 standing anteroposterior whole spine radiographs collected from ten\nhospitals. Two musculoskeletal radiologists independently measured each study\nand served as reference readers. Agreement between the AI and each radiologist\nwas assessed with Bland Altman analysis, mean absolute error (MAE), root mean\nsquared error (RMSE), Pearson correlation coefficient, and Cohen kappa for four\ngrade severity classification. Against Radiologist 1 the AI achieved an MAE of\n3.89 degrees (RMSE 4.77 degrees) with a bias of 0.70 degrees and limits of\nagreement from minus 8.59 to plus 9.99 degrees. Against Radiologist 2 the AI\nachieved an MAE of 3.90 degrees (RMSE 5.68 degrees) with a bias of 2.14 degrees\nand limits from minus 8.23 to plus 12.50 degrees. Pearson correlations were r\nequals 0.906 and r equals 0.880 (inter reader r equals 0.928), while Cohen\nkappa for severity grading reached 0.51 and 0.64 (inter reader kappa 0.59).\nThese results demonstrate that the proposed software reproduces expert level\nCobb angle measurements and categorical grading across multiple centres,\nsuggesting its utility for streamlining scoliosis reporting and triage in\nclinical workflows.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u81ea\u52a8\u5316\u8f6f\u4ef6\uff08Carebot AI Bones\uff09\u7528\u4e8e\u6d4b\u91cf\u810a\u67f1\u4fa7\u5f2f\u7684Cobb\u89d2\uff0c\u7ed3\u679c\u663e\u793a\u5176\u4e0e\u653e\u5c04\u79d1\u533b\u751f\u7684\u6d4b\u91cf\u7ed3\u679c\u5177\u6709\u9ad8\u5ea6\u4e00\u81f4\u6027\uff0c\u53ef\u7528\u4e8e\u4e34\u5e8a\u5de5\u4f5c\u6d41\u3002", "motivation": "\u810a\u67f1\u4fa7\u5f2f\u5f71\u54cd2-4%\u7684\u9752\u5c11\u5e74\uff0c\u4f20\u7edf\u624b\u52a8\u6d4b\u91cfCobb\u89d2\u8017\u65f6\u4e14\u5b58\u5728\u89c2\u5bdf\u8005\u95f4\u5dee\u5f02\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7814\u7a76\u56de\u987e\u6027\u8bc4\u4f30\u4e86Carebot AI Bones\u8f6f\u4ef6\u5728103\u5f20\u7ad9\u7acb\u4f4d\u5168\u810a\u67f1X\u5149\u7247\u4e0a\u7684\u8868\u73b0\uff0c\u4ee5\u4e24\u4f4d\u653e\u5c04\u79d1\u533b\u751f\u7684\u72ec\u7acb\u6d4b\u91cf\u4e3a\u53c2\u8003\u3002", "result": "AI\u4e0e\u653e\u5c04\u79d1\u533b\u751f\u7684\u6d4b\u91cf\u7ed3\u679c\u9ad8\u5ea6\u4e00\u81f4\uff08MAE\u7ea63.9\u5ea6\uff0cPearson\u76f8\u5173\u7cfb\u65700.88-0.91\uff09\uff0c\u4e14\u80fd\u51c6\u786e\u5206\u7c7b\u4e25\u91cd\u7a0b\u5ea6\uff08Cohen kappa 0.51-0.64\uff09\u3002", "conclusion": "\u8be5\u8f6f\u4ef6\u80fd\u590d\u73b0\u4e13\u5bb6\u6c34\u5e73\u7684Cobb\u89d2\u6d4b\u91cf\u548c\u5206\u7c7b\uff0c\u53ef\u7528\u4e8e\u4f18\u5316\u810a\u67f1\u4fa7\u5f2f\u7684\u4e34\u5e8a\u62a5\u544a\u548c\u5206\u8bca\u6d41\u7a0b\u3002"}}
{"id": "2507.14102", "pdf": "https://arxiv.org/pdf/2507.14102", "abs": "https://arxiv.org/abs/2507.14102", "authors": ["Shravan Venkatraman", "Pavan Kumar S", "Rakesh Raj Madavan", "Chandrakala S"], "title": "UGPL: Uncertainty-Guided Progressive Learning for Evidence-Based Classification in Computed Tomography", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "18 pages, 10 figures, 5 tables, 2025 ICCV Workshops", "summary": "Accurate classification of computed tomography (CT) images is essential for\ndiagnosis and treatment planning, but existing methods often struggle with the\nsubtle and spatially diverse nature of pathological features. Current\napproaches typically process images uniformly, limiting their ability to detect\nlocalized abnormalities that require focused analysis. We introduce UGPL, an\nuncertainty-guided progressive learning framework that performs a\nglobal-to-local analysis by first identifying regions of diagnostic ambiguity\nand then conducting detailed examination of these critical areas. Our approach\nemploys evidential deep learning to quantify predictive uncertainty, guiding\nthe extraction of informative patches through a non-maximum suppression\nmechanism that maintains spatial diversity. This progressive refinement\nstrategy, combined with an adaptive fusion mechanism, enables UGPL to integrate\nboth contextual information and fine-grained details. Experiments across three\nCT datasets demonstrate that UGPL consistently outperforms state-of-the-art\nmethods, achieving improvements of 3.29%, 2.46%, and 8.08% in accuracy for\nkidney abnormality, lung cancer, and COVID-19 detection, respectively. Our\nanalysis shows that the uncertainty-guided component provides substantial\nbenefits, with performance dramatically increasing when the full progressive\nlearning pipeline is implemented. Our code is available at:\nhttps://github.com/shravan-18/UGPL", "AI": {"tldr": "UGPL\u662f\u4e00\u79cd\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u7684\u6e10\u8fdb\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5168\u5c40\u5230\u5c40\u90e8\u5206\u6790\u63d0\u5347CT\u56fe\u50cf\u5206\u7c7b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u75c5\u7406\u7279\u5f81\u7684\u7ec6\u5fae\u548c\u7a7a\u95f4\u591a\u6837\u6027\uff0cUGPL\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8bc1\u636e\u6df1\u5ea6\u5b66\u4e60\u91cf\u5316\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff0c\u901a\u8fc7\u975e\u6781\u5927\u503c\u6291\u5236\u673a\u5236\u63d0\u53d6\u4fe1\u606f\u4e30\u5bcc\u7684\u533a\u57df\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u878d\u5408\u673a\u5236\u3002", "result": "\u5728\u4e09\u4e2aCT\u6570\u636e\u96c6\u4e0a\uff0cUGPL\u5728\u80be\u810f\u5f02\u5e38\u3001\u80ba\u764c\u548cCOVID-19\u68c0\u6d4b\u4e2d\u7684\u51c6\u786e\u7387\u5206\u522b\u63d0\u9ad8\u4e863.29%\u30012.46%\u548c8.08%\u3002", "conclusion": "UGPL\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u548c\u6e10\u8fdb\u5b66\u4e60\u663e\u8457\u63d0\u5347\u4e86CT\u56fe\u50cf\u5206\u7c7b\u6027\u80fd\u3002"}}
{"id": "2507.14109", "pdf": "https://arxiv.org/pdf/2507.14109", "abs": "https://arxiv.org/abs/2507.14109", "authors": ["Xinyu Cao", "Bimal Adhikari", "Shangqing Zhao", "Jingxian Wu", "Yanjun Pan"], "title": "An Adversarial-Driven Experimental Study on Deep Learning for RF Fingerprinting", "categories": ["cs.CR", "cs.LG", "eess.SP"], "comment": null, "summary": "Radio frequency (RF) fingerprinting, which extracts unique hardware\nimperfections of radio devices, has emerged as a promising physical-layer\ndevice identification mechanism in zero trust architectures and beyond 5G\nnetworks. In particular, deep learning (DL) methods have demonstrated\nstate-of-the-art performance in this domain. However, existing approaches have\nprimarily focused on enhancing system robustness against temporal and spatial\nvariations in wireless environments, while the security vulnerabilities of\nthese DL-based approaches have often been overlooked. In this work, we\nsystematically investigate the security risks of DL-based RF fingerprinting\nsystems through an adversarial-driven experimental analysis. We observe a\nconsistent misclassification behavior for DL models under domain shifts, where\na device is frequently misclassified as another specific one. Our analysis\nbased on extensive real-world experiments demonstrates that this behavior can\nbe exploited as an effective backdoor to enable external attackers to intrude\ninto the system. Furthermore, we show that training DL models on raw received\nsignals causes the models to entangle RF fingerprints with environmental and\nsignal-pattern features, creating additional attack vectors that cannot be\nmitigated solely through post-processing security methods such as confidence\nthresholds.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5c04\u9891\u6307\u7eb9\u8bc6\u522b\u7cfb\u7edf\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u53d1\u73b0\u57df\u504f\u79fb\u4f1a\u5bfc\u81f4\u8bbe\u5907\u88ab\u8bef\u5206\u7c7b\u4e3a\u7279\u5b9a\u8bbe\u5907\uff0c\u53ef\u80fd\u88ab\u7528\u4f5c\u540e\u95e8\u653b\u51fb\u3002\u6b64\u5916\uff0c\u8bad\u7ec3\u6a21\u578b\u65f6\u4f7f\u7528\u539f\u59cb\u4fe1\u53f7\u4f1a\u5bfc\u81f4\u6307\u7eb9\u4e0e\u73af\u5883\u7279\u5f81\u7ea0\u7f20\uff0c\u589e\u52a0\u653b\u51fb\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7cfb\u7edf\u5728\u65e0\u7ebf\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u800c\u5ffd\u7565\u4e86\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u5b89\u5168\u6f0f\u6d1e\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u5206\u6790\u8fd9\u4e9b\u6f0f\u6d1e\u53ca\u5176\u6f5c\u5728\u5a01\u80c1\u3002", "method": "\u901a\u8fc7\u5bf9\u6297\u6027\u5b9e\u9a8c\u5206\u6790\uff0c\u7814\u7a76\u4e86\u57df\u504f\u79fb\u5bf9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u5f71\u54cd\uff0c\u5e76\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u6570\u636e\u9a8c\u8bc1\u4e86\u653b\u51fb\u7684\u53ef\u884c\u6027\u3002", "result": "\u53d1\u73b0\u57df\u504f\u79fb\u4f1a\u5bfc\u81f4\u8bbe\u5907\u88ab\u8bef\u5206\u7c7b\u4e3a\u7279\u5b9a\u8bbe\u5907\uff0c\u5f62\u6210\u540e\u95e8\u653b\u51fb\u673a\u4f1a\uff1b\u540c\u65f6\uff0c\u4f7f\u7528\u539f\u59cb\u4fe1\u53f7\u8bad\u7ec3\u7684\u6a21\u578b\u4f1a\u7ea0\u7f20\u6307\u7eb9\u4e0e\u73af\u5883\u7279\u5f81\uff0c\u589e\u52a0\u653b\u51fb\u9762\u3002", "conclusion": "\u9700\u91cd\u65b0\u8bbe\u8ba1\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4ee5\u5206\u79bb\u6307\u7eb9\u4e0e\u73af\u5883\u7279\u5f81\uff0c\u5e76\u5f00\u53d1\u66f4\u5168\u9762\u7684\u5b89\u5168\u63aa\u65bd\uff0c\u800c\u975e\u4ec5\u4f9d\u8d56\u540e\u5904\u7406\u6280\u672f\u3002"}}
{"id": "2507.14116", "pdf": "https://arxiv.org/pdf/2507.14116", "abs": "https://arxiv.org/abs/2507.14116", "authors": ["Dani\u00eblle Schuman", "Mark V. Seebode", "Tobias Rohe", "Maximilian Balthasar Mansky", "Michael Schroedl-Baumann", "Jonas Stein", "Claudia Linnhoff-Popien", "Florian Krellner"], "title": "Quantum Boltzmann Machines using Parallel Annealing for Medical Image Classification", "categories": ["quant-ph", "cs.ET", "cs.LG"], "comment": "12 pages, 5 figures (10 if counting subfigures), 2 tables. To be\n  published in the proceedings of the 2025 IEEE International Conference on\n  Quantum Computing and Engineering (QCE)", "summary": "Exploiting the fact that samples drawn from a quantum annealer inherently\nfollow a Boltzmann-like distribution, annealing-based Quantum Boltzmann\nMachines (QBMs) have gained increasing popularity in the quantum research\ncommunity. While they harbor great promises for quantum speed-up, their usage\ncurrently stays a costly endeavor, as large amounts of QPU time are required to\ntrain them. This limits their applicability in the NISQ era. Following the idea\nof No\\`e et al. (2024), who tried to alleviate this cost by incorporating\nparallel quantum annealing into their unsupervised training of QBMs, this paper\npresents an improved version of parallel quantum annealing that we employ to\ntrain QBMs in a supervised setting. Saving qubits to encode the inputs, the\nlatter setting allows us to test our approach on medical images from the\nMedMNIST data set (Yang et al., 2023), thereby moving closer to real-world\napplicability of the technology. Our experiments show that QBMs using our\napproach already achieve reasonable results, comparable to those of\nsimilarly-sized Convolutional Neural Networks (CNNs), with markedly smaller\nnumbers of epochs than these classical models. Our parallel annealing technique\nleads to a speed-up of almost 70 % compared to regular annealing-based BM\nexecutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u5e76\u884c\u91cf\u5b50\u9000\u706b\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u76d1\u7763\u5b66\u4e60\u8bbe\u7f6e\u4e2d\u8bad\u7ec3\u91cf\u5b50\u73bb\u5c14\u5179\u66fc\u673a\uff08QBMs\uff09\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8bad\u7ec3\u65f6\u95f4\u548c\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u91cf\u5b50\u9000\u706b\u5668\u751f\u6210\u7684\u6837\u672c\u9075\u5faa\u73bb\u5c14\u5179\u66fc\u5206\u5e03\uff0c\u4f46\u8bad\u7ec3QBMs\u9700\u8981\u5927\u91cf\u91cf\u5b50\u5904\u7406\u5355\u5143\uff08QPU\uff09\u65f6\u95f4\uff0c\u9650\u5236\u4e86\u5176\u5728NISQ\u65f6\u4ee3\u7684\u5e94\u7528\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6539\u8fdb\u7684\u5e76\u884c\u91cf\u5b50\u9000\u706b\u6280\u672f\u964d\u4f4e\u6210\u672c\u3002", "method": "\u91c7\u7528\u6539\u8fdb\u7684\u5e76\u884c\u91cf\u5b50\u9000\u706b\u65b9\u6cd5\uff0c\u5728\u76d1\u7763\u5b66\u4e60\u8bbe\u7f6e\u4e2d\u8bad\u7ec3QBMs\uff0c\u8282\u7701\u4e86\u7f16\u7801\u8f93\u5165\u7684\u91cf\u5b50\u6bd4\u7279\uff0c\u5e76\u5728MedMNIST\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6539\u8fdb\u7684QBMs\u5728\u8f83\u5c11\u8bad\u7ec3\u5468\u671f\u5185\u53d6\u5f97\u4e86\u4e0e\u7c7b\u4f3c\u89c4\u6a21\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNNs\uff09\u76f8\u5f53\u7684\u7ed3\u679c\uff0c\u5e76\u884c\u9000\u706b\u6280\u672f\u6bd4\u5e38\u89c4\u65b9\u6cd5\u63d0\u901f\u8fd170%\u3002", "conclusion": "\u6539\u8fdb\u7684\u5e76\u884c\u91cf\u5b50\u9000\u706b\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86QBMs\u7684\u8bad\u7ec3\u6548\u7387\uff0c\u4f7f\u5176\u66f4\u63a5\u8fd1\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2507.14119", "pdf": "https://arxiv.org/pdf/2507.14119", "abs": "https://arxiv.org/abs/2507.14119", "authors": ["Maksim Kuprashevich", "Grigorii Alekseenko", "Irina Tolstykh", "Georgii Fedorov", "Bulat Suleimanov", "Vladimir Dokholyan", "Aleksandr Gordeev"], "title": "NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Recent advances in generative modeling enable image editing assistants that\nfollow natural language instructions without additional user input. Their\nsupervised training requires millions of triplets: original image, instruction,\nedited image. Yet mining pixel-accurate examples is hard. Each edit must affect\nonly prompt-specified regions, preserve stylistic coherence, respect physical\nplausibility, and retain visual appeal. The lack of robust automated\nedit-quality metrics hinders reliable automation at scale. We present an\nautomated, modular pipeline that mines high-fidelity triplets across domains,\nresolutions, instruction complexities, and styles. Built on public generative\nmodels and running without human intervention, our system uses a task-tuned\nGemini validator to score instruction adherence and aesthetics directly,\nremoving any need for segmentation or grounding models. Inversion and\ncompositional bootstrapping enlarge the mined set by approximately 2.2x,\nenabling large-scale high-fidelity training data. By automating the most\nrepetitive annotation steps, the approach allows a new scale of training\nwithout human labeling effort. To democratize research in this\nresource-intensive area, we release NHR-Edit: an open dataset of 358k\nhigh-quality triplets. In the largest cross-dataset evaluation, it surpasses\nall public alternatives. We also release Bagel-NHR-Edit, an open-source\nfine-tuned Bagel model, which achieves state-of-the-art metrics in our\nexperiments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u3001\u6a21\u5757\u5316\u7684\u6d41\u7a0b\uff0c\u7528\u4e8e\u6316\u6398\u9ad8\u8d28\u91cf\u7684\u4e09\u5143\u7ec4\u6570\u636e\uff08\u539f\u59cb\u56fe\u50cf\u3001\u6307\u4ee4\u3001\u7f16\u8f91\u56fe\u50cf\uff09\uff0c\u4ee5\u652f\u6301\u751f\u6210\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u5e76\u53d1\u5e03\u4e86\u5f00\u6e90\u6570\u636e\u96c6\u548c\u6a21\u578b\u3002", "motivation": "\u751f\u6210\u6a21\u578b\u9700\u8981\u5927\u91cf\u9ad8\u8d28\u91cf\u7684\u4e09\u5143\u7ec4\u6570\u636e\uff0c\u4f46\u624b\u52a8\u6807\u6ce8\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6ee1\u8db3\u8981\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u516c\u5171\u751f\u6210\u6a21\u578b\u548cGemini\u9a8c\u8bc1\u5668\u81ea\u52a8\u8bc4\u5206\uff0c\u901a\u8fc7\u53cd\u8f6c\u548c\u7ec4\u5408\u81ea\u4e3e\u6269\u5c55\u6570\u636e\u96c6\u3002", "result": "\u53d1\u5e03\u4e86NHR-Edit\u6570\u636e\u96c6\uff08358k\u4e09\u5143\u7ec4\uff09\u548cBagel-NHR-Edit\u6a21\u578b\uff0c\u5728\u8de8\u6570\u636e\u96c6\u8bc4\u4f30\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u7684\u81ea\u52a8\u5316\u751f\u6210\uff0c\u63a8\u52a8\u4e86\u751f\u6210\u6a21\u578b\u7814\u7a76\u7684\u53d1\u5c55\u3002"}}
