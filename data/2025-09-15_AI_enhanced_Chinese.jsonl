{"id": "2509.10050", "pdf": "https://arxiv.org/pdf/2509.10050", "abs": "https://arxiv.org/abs/2509.10050", "authors": ["Aryan Esmailpour", "Xiao Hu", "Stavros Sintos"], "title": "Space-Time Tradeoffs for Spatial Conjunctive Queries", "categories": ["cs.DB"], "comment": null, "summary": "Given a conjunctive query and a database instance, we aim to develop an index\nthat can efficiently answer spatial queries on the results of a conjunctive\nquery. We are interested in some commonly used spatial queries, such as range\nemptiness, range count, and nearest neighbor queries. These queries have\nessential applications in data analytics, such as filtering relational data\nbased on attribute ranges and temporal graph analysis for counting graph\nstructures like stars, paths, and cliques. Furthermore, this line of research\ncan accelerate relational algorithms that incorporate spatial queries in their\nworkflow, such as relational clustering. Known approaches either have to spend\n$\\tilde{O}(N)$ query time or use space as large as the number of query results,\nwhich are inefficient or unrealistic to employ in practice. Hence, we aim to\nconstruct an index that answers spatial conjunctive queries in both time- and\nspace-efficient ways.\n  In this paper, we establish lower bounds on the tradeoff between answering\ntime and space usage. For $k$-star (resp. $k$-path) queries, we show that any\nindex for range emptiness, range counting or nearest neighbor queries with $T$\nanswering time requires $\\Omega\\left(N+\\frac{N^k}{T^k}\\right)$ (resp.\n$\\Omega\\left(N+\\frac{N^2}{T^{2/(k-1)}}\\right)$) space. Then, we construct\noptimal indexes for answering range emptiness and range counting problems over\n$k$-star and $k$-path queries. Extending this result, we build an index for\nhierarchical queries. By resorting to the generalized hypertree decomposition,\nwe can extend our index to arbitrary conjunctive queries for supporting spatial\nconjunctive queries. Finally, we show how our new indexes can be used to\nimprove the running time of known algorithms in the relational setting.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u7a7a\u95f4\u8fde\u63a5\u67e5\u8be2\u7684\u7d22\u5f15\u95ee\u9898\uff0c\u5efa\u7acb\u4e86\u67e5\u8be2\u65f6\u95f4\u4e0e\u7a7a\u95f4\u4f7f\u7528\u4e4b\u95f4\u7684\u4e0b\u754c\uff0c\u5e76\u6784\u5efa\u4e86\u6700\u4f18\u7d22\u5f15\u7ed3\u6784\uff0c\u652f\u6301\u8303\u56f4\u7a7a\u503c\u67e5\u8be2\u3001\u8303\u56f4\u8ba1\u6570\u67e5\u8be2\u548c\u6700\u8fd1\u90bb\u67e5\u8be2\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u9700\u8981O(N)\u67e5\u8be2\u65f6\u95f4\uff0c\u8981\u4e48\u4f7f\u7528\u4e0e\u67e5\u8be2\u7ed3\u679c\u6570\u91cf\u76f8\u540c\u7684\u7a7a\u95f4\uff0c\u8fd9\u5728\u5b9e\u8df5\u4e2d\u6548\u7387\u4f4e\u4e0b\u6216\u4e0d\u73b0\u5b9e\u3002\u56e0\u6b64\u9700\u8981\u6784\u5efa\u65f6\u95f4\u548c\u7a7a\u95f4\u90fd\u9ad8\u6548\u7684\u7d22\u5f15\u6765\u56de\u7b54\u7a7a\u95f4\u8fde\u63a5\u67e5\u8be2\u3002", "method": "\u5efa\u7acbk-star\u548ck-path\u67e5\u8be2\u7684\u65f6\u95f4-\u7a7a\u95f4\u6743\u8861\u4e0b\u754c\uff0c\u6784\u5efa\u6700\u4f18\u7d22\u5f15\u5904\u7406\u8303\u56f4\u7a7a\u503c\u67e5\u8be2\u548c\u8303\u56f4\u8ba1\u6570\u67e5\u8be2\uff0c\u6269\u5c55\u5230\u5206\u5c42\u67e5\u8be2\uff0c\u5229\u7528\u5e7f\u4e49\u8d85\u6811\u5206\u89e3\u6269\u5c55\u5230\u4efb\u610f\u8fde\u63a5\u67e5\u8be2\u3002", "result": "\u8bc1\u660e\u4e86k-star\u67e5\u8be2\u9700\u8981\u03a9(N+N^k/T^k)\u7a7a\u95f4\uff0ck-path\u67e5\u8be2\u9700\u8981\u03a9(N+N^2/T^{2/(k-1)})\u7a7a\u95f4\uff0c\u5e76\u6784\u5efa\u4e86\u76f8\u5e94\u7684\u6700\u4f18\u7d22\u5f15\u3002", "conclusion": "\u63d0\u51fa\u7684\u7d22\u5f15\u7ed3\u6784\u80fd\u591f\u9ad8\u6548\u652f\u6301\u7a7a\u95f4\u8fde\u63a5\u67e5\u8be2\uff0c\u5e76\u53ef\u4ee5\u6539\u8fdb\u5173\u7cfb\u7b97\u6cd5\u4e2d\u5df2\u77e5\u7b97\u6cd5\u7684\u8fd0\u884c\u65f6\u95f4\u3002"}}
{"id": "2509.10138", "pdf": "https://arxiv.org/pdf/2509.10138", "abs": "https://arxiv.org/abs/2509.10138", "authors": ["Foto N. Afrati", "Matthew Damigos"], "title": "Semi-interval Comparison Constraints in Query Containment and Their Impact on Certain Answer Computation", "categories": ["cs.DB", "H.2.3, F.2.0"], "comment": "71 pages 2 figures", "summary": "We consider conjunctive queries with arithmetic comparisons (CQAC) and\ninvestigate the computational complexity of the problem: Given two CQAC\nqueries, $Q$ and $Q'$, is $Q'$ contained in $Q$? We know that, for CQAC\nqueries, the problem of testing containment is $\\Pi_2 ^p$ -complete. However,\nthere are broad classes of queries with semi-interval arithmetic comparisons in\nthe containing query that render the problem solvable in NP. In all cases\nexamined the contained query is allowed to be any CQAC. Interestingly, we also\nprove that there are simple cases where the problem remains $\\Pi_2 ^p$\n-complete.\n  We also investigate the complexity of computing certain answers in the\nframework of answering CQAC queries with semi-interval comparisons using any\nCQAC views. We prove that maximally contained rewritings in the language of\nunion of CQACs always compute exactly all certain answers. We find cases where\nwe can compute certain answers in polynomial time using maximally contained\nrewritings.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5305\u542b\u7b97\u672f\u6bd4\u8f83\u7684\u8fde\u63a5\u67e5\u8be2(CQAC)\u7684\u5305\u542b\u6027\u6d4b\u8bd5\u548c\u786e\u5b9a\u7b54\u6848\u8ba1\u7b97\u7684\u590d\u6742\u5ea6\u95ee\u9898", "motivation": "\u7814\u7a76CQAC\u67e5\u8be2\u7684\u5305\u542b\u6027\u6d4b\u8bd5\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5305\u542b\u534a\u533a\u95f4\u7b97\u672f\u6bd4\u8f83\u7684\u67e5\u8be2\u7c7b\uff0c\u4ee5\u53ca\u5728\u8fd9\u4e9b\u67e5\u8be2\u6846\u67b6\u4e0b\u8ba1\u7b97\u786e\u5b9a\u7b54\u6848\u7684\u590d\u6742\u5ea6", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u590d\u6742\u5ea6\u8bc1\u660e\uff0c\u7814\u7a76\u4e86\u4e0d\u540cCQAC\u67e5\u8be2\u7c7b\u522b\u7684\u5305\u542b\u6027\u6d4b\u8bd5\u95ee\u9898\uff0c\u5e76\u63a2\u8ba8\u4e86\u4f7f\u7528CQAC\u89c6\u56fe\u8ba1\u7b97\u786e\u5b9a\u7b54\u6848\u7684\u65b9\u6cd5", "result": "\u53d1\u73b0\u5bf9\u4e8e\u5305\u542b\u534a\u533a\u95f4\u7b97\u672f\u6bd4\u8f83\u7684\u67e5\u8be2\uff0c\u5305\u542b\u6027\u6d4b\u8bd5\u95ee\u9898\u53ef\u5728NP\u5185\u89e3\u51b3\uff1b\u540c\u65f6\u8bc1\u660e\u5728\u67d0\u4e9b\u7b80\u5355\u60c5\u51b5\u4e0b\u95ee\u9898\u4ecd\u4fdd\u6301\u03a0\u2082^p\u5b8c\u5168\u6027\uff1b\u8bc1\u660e\u4e86\u5728CQAC\u5e76\u96c6\u8bed\u8a00\u4e2d\u6700\u5927\u5305\u542b\u91cd\u5199\u80fd\u7cbe\u786e\u8ba1\u7b97\u6240\u6709\u786e\u5b9a\u7b54\u6848", "conclusion": "CQAC\u67e5\u8be2\u7684\u5305\u542b\u6027\u6d4b\u8bd5\u5177\u6709\u4e0d\u540c\u7684\u590d\u6742\u5ea6\u7279\u5f81\uff0c\u53d6\u51b3\u4e8e\u67e5\u8be2\u4e2d\u7b97\u672f\u6bd4\u8f83\u7684\u7c7b\u578b\uff1b\u6700\u5927\u5305\u542b\u91cd\u5199\u662f\u8ba1\u7b97\u786e\u5b9a\u7b54\u6848\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u5b8c\u6210"}}
{"id": "2509.09684", "pdf": "https://arxiv.org/pdf/2509.09684", "abs": "https://arxiv.org/abs/2509.09684", "authors": ["Bruno Yui Yamate", "Thais Rodrigues Neubauer", "Marcelo Fantinato", "Sarajane Marques Peres"], "title": "Text-to-SQL Oriented to the Process Mining Domain: A PT-EN Dataset for Query Translation", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.DB"], "comment": "33 pages", "summary": "This paper introduces text-2-SQL-4-PM, a bilingual (Portuguese-English)\nbenchmark dataset designed for the text-to-SQL task in the process mining\ndomain. Text-to-SQL conversion facilitates natural language querying of\ndatabases, increasing accessibility for users without SQL expertise and\nproductivity for those that are experts. The text-2-SQL-4-PM dataset is\ncustomized to address the unique challenges of process mining, including\nspecialized vocabularies and single-table relational structures derived from\nevent logs. The dataset comprises 1,655 natural language utterances, including\nhuman-generated paraphrases, 205 SQL statements, and ten qualifiers. Methods\ninclude manual curation by experts, professional translations, and a detailed\nannotation process to enable nuanced analyses of task complexity. Additionally,\na baseline study using GPT-3.5 Turbo demonstrates the feasibility and utility\nof the dataset for text-to-SQL applications. The results show that\ntext-2-SQL-4-PM supports evaluation of text-to-SQL implementations, offering\nbroader applicability for semantic parsing and other natural language\nprocessing tasks.", "AI": {"tldr": "text-2-SQL-4-PM\u662f\u4e00\u4e2a\u4e3a\u6d41\u7a0b\u6316\u6398\u9886\u57df\u8bbe\u8ba1\u7684\u53cc\u8bed\uff08\u8461\u8404\u7259\u8bed-\u82f1\u8bed\uff09\u6587\u672c\u5230SQL\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b1,655\u4e2a\u81ea\u7136\u8bed\u8a00\u8bed\u53e5\u548c205\u4e2aSQL\u8bed\u53e5\uff0c\u652f\u6301\u65e0SQL\u4e13\u4e1a\u77e5\u8bc6\u7684\u7528\u6237\u8fdb\u884c\u81ea\u7136\u8bed\u8a00\u6570\u636e\u5e93\u67e5\u8be2\u3002", "motivation": "\u4fc3\u8fdb\u81ea\u7136\u8bed\u8a00\u6570\u636e\u5e93\u67e5\u8be2\uff0c\u63d0\u9ad8\u975eSQL\u4e13\u5bb6\u7528\u6237\u7684\u53ef\u8bbf\u95ee\u6027\u548c\u4e13\u5bb6\u7528\u6237\u7684\u751f\u4ea7\u529b\uff0c\u89e3\u51b3\u6d41\u7a0b\u6316\u6398\u9886\u57df\u7279\u6709\u7684\u6311\u6218\uff0c\u5982\u4e13\u4e1a\u8bcd\u6c47\u548c\u57fa\u4e8e\u4e8b\u4ef6\u65e5\u5fd7\u7684\u5355\u8868\u5173\u7cfb\u7ed3\u6784\u3002", "method": "\u901a\u8fc7\u4e13\u5bb6\u624b\u52a8\u6574\u7406\u3001\u4e13\u4e1a\u7ffb\u8bd1\u548c\u8be6\u7ec6\u6ce8\u91ca\u8fc7\u7a0b\u521b\u5efa\u6570\u636e\u96c6\uff0c\u5305\u62ec\u4eba\u5de5\u751f\u6210\u7684\u91ca\u4e49\uff0c\u5e76\u4f7f\u7528GPT-3.5 Turbo\u8fdb\u884c\u57fa\u7ebf\u7814\u7a76\u4ee5\u9a8c\u8bc1\u6570\u636e\u96c6\u7684\u53ef\u884c\u6027\u3002", "result": "\u6570\u636e\u96c6\u652f\u6301\u6587\u672c\u5230SQL\u5b9e\u73b0\u7684\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u5728\u6d41\u7a0b\u6316\u6398\u9886\u57df\u7684\u5e94\u7528\u53ef\u884c\u6027\uff0c\u5e76\u4e3a\u8bed\u4e49\u89e3\u6790\u548c\u5176\u4ed6\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002", "conclusion": "text-2-SQL-4-PM\u6570\u636e\u96c6\u4e3a\u6d41\u7a0b\u6316\u6398\u9886\u57df\u7684\u6587\u672c\u5230SQL\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u57fa\u51c6\u5de5\u5177\uff0c\u4fc3\u8fdb\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u5728\u6570\u636e\u5e93\u67e5\u8be2\u4e2d\u7684\u5e94\u7528\u548c\u53d1\u5c55\u3002"}}
{"id": "2509.09691", "pdf": "https://arxiv.org/pdf/2509.09691", "abs": "https://arxiv.org/abs/2509.09691", "authors": ["Aleksandr Listopad"], "title": "Wave-Based Semantic Memory with Resonance-Based Retrieval: A Phase-Aware Alternative to Vector Embedding Stores", "categories": ["cs.IR", "cs.AI", "cs.DB", "68T05 (Primary), 42C10, 94A12 (Secondary)", "I.2.6; H.2.4; H.3.3"], "comment": "9 pages, 6 figures", "summary": "Conventional vector-based memory systems rely on cosine or inner product\nsimilarity within real-valued embedding spaces. While computationally\nefficient, such approaches are inherently phase-insensitive and limited in\ntheir ability to capture resonance phenomena crucial for meaning\nrepresentation. We propose Wave-Based Semantic Memory, a novel framework that\nmodels knowledge as wave patterns $\\psi(x) = A(x) e^{i\\phi(x)}$ and retrieves\nit through resonance-based interference. This approach preserves both amplitude\nand phase information, enabling more expressive and robust semantic similarity.\nWe demonstrate that resonance-based retrieval achieves higher discriminative\npower in cases where vector methods fail, including phase shifts, negations,\nand compositional queries. Our implementation, ResonanceDB, shows scalability\nto millions of patterns with millisecond latency, positioning wave-based memory\nas a viable alternative to vector stores for AGI-oriented reasoning and\nknowledge representation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6ce2\u7684\u8bed\u4e49\u8bb0\u5fc6\u6846\u67b6\uff0c\u7528\u6ce2\u6a21\u5f0f\u8868\u793a\u77e5\u8bc6\u5e76\u901a\u8fc7\u5171\u632f\u5e72\u6d89\u8fdb\u884c\u68c0\u7d22\uff0c\u76f8\u6bd4\u4f20\u7edf\u5411\u91cf\u65b9\u6cd5\u80fd\u66f4\u597d\u5730\u4fdd\u7559\u632f\u5e45\u548c\u76f8\u4f4d\u4fe1\u606f\uff0c\u5b9e\u73b0\u66f4\u5f3a\u7684\u8bed\u4e49\u533a\u5206\u80fd\u529b", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5411\u91cf\u7684\u8bb0\u5fc6\u7cfb\u7edf\u4f9d\u8d56\u4e8e\u4f59\u5f26\u6216\u5185\u79ef\u76f8\u4f3c\u5ea6\uff0c\u867d\u7136\u8ba1\u7b97\u9ad8\u6548\u4f46\u672c\u8d28\u4e0a\u662f\u76f8\u4f4d\u4e0d\u654f\u611f\u7684\uff0c\u65e0\u6cd5\u6355\u6349\u5bf9\u610f\u4e49\u8868\u793a\u81f3\u5173\u91cd\u8981\u7684\u5171\u632f\u73b0\u8c61", "method": "\u5c06\u77e5\u8bc6\u5efa\u6a21\u4e3a\u6ce2\u6a21\u5f0f\u03c8(x)=A(x)e^{i\u03c6(x)}\uff0c\u901a\u8fc7\u57fa\u4e8e\u5171\u632f\u7684\u5e72\u6d89\u8fdb\u884c\u68c0\u7d22\uff0c\u4fdd\u7559\u632f\u5e45\u548c\u76f8\u4f4d\u4fe1\u606f", "result": "\u5171\u632f\u68c0\u7d22\u5728\u5411\u91cf\u65b9\u6cd5\u5931\u8d25\u7684\u573a\u666f\uff08\u5982\u76f8\u4f4d\u504f\u79fb\u3001\u5426\u5b9a\u548c\u7ec4\u5408\u67e5\u8be2\uff09\u4e2d\u5c55\u73b0\u51fa\u66f4\u9ad8\u7684\u533a\u5206\u80fd\u529b\uff0cResonanceDB\u5b9e\u73b0\u767e\u4e07\u7ea7\u6a21\u5f0f\u7684\u53ef\u6269\u5c55\u6027\u548c\u6beb\u79d2\u7ea7\u5ef6\u8fdf", "conclusion": "\u57fa\u4e8e\u6ce2\u7684\u8bb0\u5fc6\u53ef\u4f5c\u4e3a\u5411\u91cf\u5b58\u50a8\u7684\u53ef\u884c\u66ff\u4ee3\u65b9\u6848\uff0c\u9002\u7528\u4e8eAGI\u5bfc\u5411\u7684\u63a8\u7406\u548c\u77e5\u8bc6\u8868\u793a"}}
{"id": "2509.10036", "pdf": "https://arxiv.org/pdf/2509.10036", "abs": "https://arxiv.org/abs/2509.10036", "authors": ["Zhuowei Zhao", "Zhuo Zhang", "Hanzhi Wang", "Junhao Gan", "Zhifeng Bao", "Jianzhong Qi"], "title": "Approximate Graph Propagation Revisited: Dynamic Parameterized Queries, Tighter Bounds and Dynamic Updates", "categories": ["cs.DS"], "comment": null, "summary": "We revisit Approximate Graph Propagation (AGP), a unified framework which\ncaptures various graph propagation tasks, such as PageRank, feature propagation\nin Graph Neural Networks (GNNs), and graph-based Retrieval-Augmented Generation\n(RAG). Our work focuses on the settings of dynamic graphs and dynamic\nparameterized queries, where the underlying graphs evolve over time (updated by\nedge insertions or deletions) and the input query parameters are specified on\nthe fly to fit application needs. Our first contribution is an interesting\nobservation that the SOTA solution, AGP-Static, can be adapted to support\ndynamic parameterized queries; however several challenges remain unresolved.\nFirstly, the query time complexity of AGP-Static is based on an assumption of\nusing an optimal algorithm for subset sampling in its query algorithm.\nUnfortunately, back to that time, such an algorithm did not exist; without such\nan optimal algorithm, an extra $O(\\log^2 n)$ factor is required in the query\ncomplexity, where $n$ is the number of vertices in the graphs. Secondly,\nAGP-Static performs poorly on dynamic graphs, taking $O(n\\log n)$ time to\nprocess each update. To address these challenges, we propose a new algorithm,\nAGP-Static++, which is simpler yet reduces roughly a factor of $O(\\log^2 n)$ in\nthe query complexity while preserving the approximation guarantees of\nAGP-Static. However, AGP-Static++ still requires $O(n)$ time to process each\nupdate. To better support dynamic graphs, we further propose AGP-Dynamic, which\nachieves $O(1)$ amortized time per update, significantly improving the\naforementioned $O(n)$ per-update bound, while still preserving the query\ncomplexity and approximation guarantees. Last, our comprehensive experiments\nvalidate the theoretical improvements: compared to the baselines, our algorithm\nachieves speedups of up to $177\\times$ on update time and $10\\times$ on query\nefficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AGP-Static++\u548cAGP-Dynamic\u4e24\u79cd\u65b0\u7b97\u6cd5\uff0c\u6539\u8fdb\u4e86\u8fd1\u4f3c\u56fe\u4f20\u64ad\u6846\u67b6\u5728\u52a8\u6001\u56fe\u548c\u52a8\u6001\u53c2\u6570\u5316\u67e5\u8be2\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u663e\u8457\u63d0\u5347\u4e86\u66f4\u65b0\u65f6\u95f4\u548c\u67e5\u8be2\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684AGP-Static\u7b97\u6cd5\u5728\u52a8\u6001\u56fe\u548c\u52a8\u6001\u53c2\u6570\u5316\u67e5\u8be2\u573a\u666f\u4e0b\u5b58\u5728\u6027\u80fd\u74f6\u9888\uff1a\u67e5\u8be2\u590d\u6742\u5ea6\u4f9d\u8d56\u4e0d\u5b58\u5728\u7684\u7406\u60f3\u5b50\u96c6\u91c7\u6837\u7b97\u6cd5\uff0c\u4e14\u52a8\u6001\u56fe\u66f4\u65b0\u5904\u7406\u65f6\u95f4\u9ad8\u8fbeO(n log n)\u3002", "method": "\u63d0\u51faAGP-Static++\u7b97\u6cd5\u7b80\u5316\u67e5\u8be2\u8fc7\u7a0b\uff0c\u964d\u4f4eO(log\u00b2 n)\u7684\u67e5\u8be2\u590d\u6742\u5ea6\u56e0\u5b50\uff1b\u8fdb\u4e00\u6b65\u63d0\u51faAGP-Dynamic\u7b97\u6cd5\u5b9e\u73b0O(1)\u644a\u9500\u65f6\u95f4\u7684\u52a8\u6001\u56fe\u66f4\u65b0\u5904\u7406\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff0c\u65b0\u7b97\u6cd5\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5728\u66f4\u65b0\u65f6\u95f4\u4e0a\u8fbe\u5230177\u500d\u52a0\u901f\uff0c\u5728\u67e5\u8be2\u6548\u7387\u4e0a\u8fbe\u523010\u500d\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8fd1\u4f3c\u4fdd\u8bc1\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684AGP-Static++\u548cAGP-Dynamic\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u56fe\u548c\u52a8\u6001\u53c2\u6570\u5316\u67e5\u8be2\u573a\u666f\u4e0b\u7684\u6027\u80fd\u95ee\u9898\uff0c\u4e3a\u56fe\u4f20\u64ad\u4efb\u52a1\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.09795", "pdf": "https://arxiv.org/pdf/2509.09795", "abs": "https://arxiv.org/abs/2509.09795", "authors": ["Arivarasan Karmegam", "Gabina Luz Bianchi", "Margarita Capretto", "Mart\u00edn Ceresa", "Antonio Fern\u00e1ndez Anta", "C\u00e9sar S\u00e1nchez"], "title": "Setchain Algorithms for Blockchain Scalability", "categories": ["cs.DC", "cs.DB", "cs.DS", "cs.PF"], "comment": null, "summary": "Setchain has been proposed to increase blockchain scalability by relaxing the\nstrict total order requirement among transactions. Setchain organizes elements\ninto a sequence of sets, referred to as epochs, so that elements within each\nepoch are unordered. In this paper, we propose and evaluate three distinct\nSetchain algorithms, that leverage an underlying block-based ledger. Vanilla is\na basic implementation that serves as a reference point. Compresschain\naggregates elements into batches, and compresses these batches before appending\nthem as epochs in the ledger. Hashchain converts batches into fixed-length\nhashes which are appended as epochs in the ledger. This requires Hashchain to\nuse a distributed service to obtain the batch contents from its hash. To allow\nlight clients to safely interact with only one server, the proposed algorithms\nmaintain, as part of the Setchain, proofs for the epochs. An epoch-proof is the\nhash of the epoch, cryptographically signed by a server. A client can verify\nthe correctness of an epoch with $f+1$ epoch-proofs (where $f$ is the maximum\nnumber of Byzantine servers assumed). All three Setchain algorithms are\nimplemented on top of the CometBFT blockchain application platform. We\nconducted performance evaluations across various configurations, using clusters\nof four, seven, and ten servers. Our results show that the Setchain algorithms\nreach orders of magnitude higher throughput than the underlying blockchain, and\nachieve finality with latency below 4 seconds.", "AI": {"tldr": "Setchain\u901a\u8fc7\u653e\u5bbd\u4ea4\u6613\u4e25\u683c\u5168\u5e8f\u8981\u6c42\u63d0\u5347\u533a\u5757\u94fe\u53ef\u6269\u5c55\u6027\uff0c\u63d0\u51fa\u4e09\u79cd\u57fa\u4e8e\u5e95\u5c42\u533a\u5757\u94fe\u7684\u7b97\u6cd5\uff1aVanilla\u57fa\u7840\u5b9e\u73b0\u3001Compresschain\u6279\u91cf\u538b\u7f29\u3001Hashchain\u54c8\u5e0c\u5b58\u50a8\uff0c\u5b9e\u73b0\u6bd4\u5e95\u5c42\u533a\u5757\u94fe\u9ad8\u6570\u4e2a\u6570\u91cf\u7ea7\u7684\u541e\u5410\u91cf\uff0c\u6700\u7ec8\u6027\u5ef6\u8fdf\u4f4e\u4e8e4\u79d2\u3002", "motivation": "\u4f20\u7edf\u533a\u5757\u94fe\u7684\u4e25\u683c\u5168\u5e8f\u4ea4\u6613\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\uff0cSetchain\u901a\u8fc7\u5c06\u4ea4\u6613\u7ec4\u7ec7\u6210\u65e0\u5e8f\u96c6\u5408\uff08epochs\uff09\u6765\u653e\u677e\u6392\u5e8f\u8981\u6c42\uff0c\u4ece\u800c\u63d0\u9ad8\u541e\u5410\u91cf\u548c\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e09\u79cdSetchain\u7b97\u6cd5\uff1a1) Vanilla\u57fa\u7840\u5b9e\u73b0\u4f5c\u4e3a\u53c2\u8003\uff1b2) Compresschain\u5c06\u5143\u7d20\u6279\u91cf\u538b\u7f29\u540e\u4f5c\u4e3aepochs\u6dfb\u52a0\u5230\u8d26\u672c\uff1b3) Hashchain\u5c06\u6279\u6b21\u8f6c\u6362\u4e3a\u56fa\u5b9a\u957f\u5ea6\u54c8\u5e0c\uff0c\u9700\u8981\u5206\u5e03\u5f0f\u670d\u52a1\u83b7\u53d6\u6279\u6b21\u5185\u5bb9\u3002\u6240\u6709\u7b97\u6cd5\u90fd\u7ef4\u62a4epoch-proof\uff08\u670d\u52a1\u5668\u7b7e\u540d\u7684epoch\u54c8\u5e0c\uff09\u4ee5\u786e\u4fdd\u5b89\u5168\u6027\u3002", "result": "\u57284\u30017\u300110\u4e2a\u670d\u52a1\u5668\u7684\u96c6\u7fa4\u914d\u7f6e\u4e0b\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\uff0cSetchain\u7b97\u6cd5\u8fbe\u5230\u6bd4\u5e95\u5c42\u533a\u5757\u94fe\u9ad8\u6570\u4e2a\u6570\u91cf\u7ea7\u7684\u541e\u5410\u91cf\uff0c\u6700\u7ec8\u6027\u5ef6\u8fdf\u4f4e\u4e8e4\u79d2\u3002\u5ba2\u6237\u7aef\u53ef\u901a\u8fc7f+1\u4e2aepoch-proof\uff08f\u4e3a\u62dc\u5360\u5ead\u670d\u52a1\u5668\u6700\u5927\u6570\u91cf\uff09\u5b89\u5168\u9a8c\u8bc1epoch\u6b63\u786e\u6027\u3002", "conclusion": "Setchain\u901a\u8fc7\u653e\u677e\u4ea4\u6613\u6392\u5e8f\u8981\u6c42\u6709\u6548\u63d0\u5347\u4e86\u533a\u5757\u94fe\u53ef\u6269\u5c55\u6027\uff0c\u4e09\u79cd\u7b97\u6cd5\u5747\u80fd\u5b9e\u73b0\u9ad8\u6027\u80fd\u548c\u9ad8\u541e\u5410\u91cf\uff0c\u4e3a\u533a\u5757\u94fe\u6269\u5bb9\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.09898", "pdf": "https://arxiv.org/pdf/2509.09898", "abs": "https://arxiv.org/abs/2509.09898", "authors": ["Sophia Lockton", "Jeremy Kepner", "Michael Stonebraker", "Hayden Jananthan", "LaToya Anderson", "William Arcand", "David Bestor", "William Bergeron", "Alex Bonn", "Daniel Burrill", "Chansup Byun", "Timothy Davis", "Vijay Gadepally", "Michael Houle", "Matthew Hubbell", "Michael Jones", "Piotr Luszczek", "Peter Michaleas", "Lauren Milechin", "Chasen Milner", "Guillermo Morales", "Julie Mullen", "Michel Pelletier", "Alex Poliakov", "Andrew Prout", "Albert Reuther", "Antonio Rosa", "Charles Yee", "Alex Pentland"], "title": "DBOS Network Sensing: A Web Services Approach to Collaborative Awareness", "categories": ["cs.NI", "cs.CR", "cs.DB", "cs.DC", "cs.OS"], "comment": "8 pages, 10 figures, 37 references, accepted to IEEE HPEC 2025", "summary": "DBOS (DataBase Operating System) is a novel capability that integrates web\nservices, operating system functions, and database features to significantly\nreduce web-deployment effort while increasing resilience. Integration of high\nperformance network sensing enables DBOS web services to collaboratively create\na shared awareness of their network environments to enhance their collective\nresilience and security. Network sensing is added to DBOS using GraphBLAS\nhypersparse traffic matrices via two approaches: (1) Python-GraphBLAS and (2)\nOneSparse PostgreSQL. These capabilities are demonstrated using the workflow\nand analytics from the IEEE/MIT/Amazon Anonymized Network Sensing Graph\nChallenge. The system was parallelized using pPython and benchmarked using 64\ncompute nodes on the MIT SuperCloud. The web request rate sustained by a single\nDBOS instance was ${>}10^5$, well above the required maximum, indicating that\nnetwork sensing can be added to DBOS with negligible overhead. For\ncollaborative awareness, many DBOS instances were connected to a single DBOS\naggregator. The Python-GraphBLAS and OneSparse PostgreSQL implementations\nscaled linearly up to 64 and 32 nodes respectively. These results suggest that\nDBOS collaborative network awareness can be achieved with a negligible increase\nin computing resources.", "AI": {"tldr": "DBOS\u662f\u4e00\u4e2a\u96c6\u6210\u4e86\u7f51\u7edc\u670d\u52a1\u3001\u64cd\u4f5c\u7cfb\u7edf\u529f\u80fd\u548c\u6570\u636e\u5e93\u7279\u6027\u7684\u65b0\u578b\u7cfb\u7edf\uff0c\u901a\u8fc7GraphBLAS\u8d85\u7a00\u758f\u6d41\u91cf\u77e9\u9635\u5b9e\u73b0\u7f51\u7edc\u611f\u77e5\uff0c\u663e\u8457\u964d\u4f4e\u4e86web\u90e8\u7f72\u5de5\u4f5c\u91cf\u5e76\u63d0\u9ad8\u4e86\u5f39\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3web\u90e8\u7f72\u5de5\u4f5c\u91cf\u5927\u4e14\u7cfb\u7edf\u5f39\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5f00\u53d1\u4e00\u4e2a\u96c6\u6210\u4e86\u64cd\u4f5c\u7cfb\u7edf\u3001\u6570\u636e\u5e93\u548c\u7f51\u7edc\u670d\u52a1\u7684\u7edf\u4e00\u5e73\u53f0\uff0c\u901a\u8fc7\u534f\u540c\u7f51\u7edc\u611f\u77e5\u6765\u589e\u5f3a\u96c6\u4f53\u5f39\u6027\u548c\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u65b9\u6cd5\u5b9e\u73b0\u7f51\u7edc\u611f\u77e5\uff1a(1) Python-GraphBLAS\u65b9\u6cd5\uff0c(2) OneSparse PostgreSQL\u65b9\u6cd5\u3002\u4f7f\u7528pPython\u8fdb\u884c\u5e76\u884c\u5316\uff0c\u5728MIT SuperCloud\u768464\u4e2a\u8ba1\u7b97\u8282\u70b9\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5355\u4e2aDBOS\u5b9e\u4f8b\u53ef\u7ef4\u6301>10^5\u7684web\u8bf7\u6c42\u7387\uff0c\u8fdc\u8d85\u9700\u6c42\u6700\u5927\u503c\u3002Python-GraphBLAS\u5b9e\u73b0\u53ef\u7ebf\u6027\u6269\u5c55\u523064\u4e2a\u8282\u70b9\uff0cOneSparse PostgreSQL\u53ef\u6269\u5c55\u523032\u4e2a\u8282\u70b9\uff0c\u8ba1\u7b97\u8d44\u6e90\u5f00\u9500\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "DBOS\u80fd\u591f\u4ee5\u53ef\u5ffd\u7565\u7684\u5f00\u9500\u5b9e\u73b0\u534f\u540c\u7f51\u7edc\u611f\u77e5\uff0c\u4e3a\u6784\u5efa\u66f4\u5177\u5f39\u6027\u548c\u5b89\u5168\u6027\u7684web\u670d\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.09853", "pdf": "https://arxiv.org/pdf/2509.09853", "abs": "https://arxiv.org/abs/2509.09853", "authors": ["Zhiyu Fan", "Kirill Vasilevski", "Dayi Lin", "Boyuan Chen", "Yihao Chen", "Zhiqing Zhong", "Jie M. Zhang", "Pinjia He", "Ahmed E. Hassan"], "title": "SWE-Effi: Re-Evaluating Software AI Agent System Effectiveness Under Resource Constraints", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The advancement of large language models (LLMs) and code agents has\ndemonstrated significant potential to assist software engineering (SWE) tasks,\nsuch as autonomous issue resolution and feature addition. Existing AI for\nsoftware engineering leaderboards (e.g., SWE-bench) focus solely on solution\naccuracy, ignoring the crucial factor of effectiveness in a\nresource-constrained world. This is a universal problem that also exists beyond\nsoftware engineering tasks: any AI system should be more than correct - it must\nalso be cost-effective. To address this gap, we introduce SWE-Effi, a set of\nnew metrics to re-evaluate AI systems in terms of holistic effectiveness\nscores. We define effectiveness as the balance between the accuracy of outcome\n(e.g., issue resolve rate) and the resources consumed (e.g., token and time).\nIn this paper, we specifically focus on the software engineering scenario by\nre-ranking popular AI systems for issue resolution on a subset of the SWE-bench\nbenchmark using our new multi-dimensional metrics. We found that AI system's\neffectiveness depends not just on the scaffold itself, but on how well it\nintegrates with the base model, which is key to achieving strong performance in\na resource-efficient manner. We also identified systematic challenges such as\nthe \"token snowball\" effect and, more significantly, a pattern of \"expensive\nfailures\". In these cases, agents consume excessive resources while stuck on\nunsolvable tasks - an issue that not only limits practical deployment but also\ndrives up the cost of failed rollouts during RL training. Lastly, we observed a\nclear trade-off between effectiveness under the token budget and effectiveness\nunder the time budget, which plays a crucial role in managing project budgets\nand enabling scalable reinforcement learning, where fast responses are\nessential.", "AI": {"tldr": "SWE-Effi\u63d0\u51fa\u4e86\u65b0\u7684\u591a\u7ef4\u5ea6\u6307\u6807\u6765\u8bc4\u4f30AI\u7cfb\u7edf\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u6574\u4f53\u6548\u80fd\uff0c\u4e0d\u4ec5\u8003\u8651\u51c6\u786e\u6027\u8fd8\u8003\u8651\u8d44\u6e90\u6d88\u8017\uff08token\u548c\u65f6\u95f4\uff09\uff0c\u53d1\u73b0\u5728SWE-bench\u57fa\u51c6\u6d4b\u8bd5\u4e2dAI\u7cfb\u7edf\u7684\u6548\u80fd\u53d6\u51b3\u4e8e\u811a\u624b\u67b6\u4e0e\u57fa\u7840\u6a21\u578b\u7684\u6574\u5408\u8d28\u91cf\uff0c\u5e76\u8bc6\u522b\u51fa\"token\u96ea\u7403\u6548\u5e94\"\u548c\"\u6602\u8d35\u5931\u8d25\"\u7b49\u7cfb\u7edf\u6027\u6311\u6218\u3002", "motivation": "\u73b0\u6709AI\u8f6f\u4ef6\u5de5\u7a0b\u6392\u884c\u699c\uff08\u5982SWE-bench\uff09\u53ea\u5173\u6ce8\u89e3\u51b3\u65b9\u6848\u51c6\u786e\u6027\uff0c\u5ffd\u7565\u4e86\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u6548\u80fd\u56e0\u7d20\u3002\u4efb\u4f55AI\u7cfb\u7edf\u4e0d\u4ec5\u9700\u8981\u6b63\u786e\uff0c\u8fd8\u5fc5\u987b\u5177\u6709\u6210\u672c\u6548\u76ca\u3002", "method": "\u5f15\u5165SWE-Effi\u6307\u6807\u96c6\uff0c\u5728SWE-bench\u57fa\u51c6\u7684\u5b50\u96c6\u4e0a\u91cd\u65b0\u8bc4\u4f30\u6d41\u884c\u7684AI\u95ee\u9898\u89e3\u51b3\u7cfb\u7edf\uff0c\u4f7f\u7528\u65b0\u7684\u591a\u7ef4\u5ea6\u6307\u6807\uff08\u7ed3\u679c\u51c6\u786e\u6027\u4e0e\u8d44\u6e90\u6d88\u8017\u7684\u5e73\u8861\uff09\u8fdb\u884c\u91cd\u65b0\u6392\u540d\u3002", "result": "\u53d1\u73b0AI\u7cfb\u7edf\u6548\u80fd\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u811a\u624b\u67b6\u672c\u8eab\uff0c\u8fd8\u53d6\u51b3\u4e8e\u5176\u4e0e\u57fa\u7840\u6a21\u578b\u7684\u6574\u5408\u8d28\u91cf\uff1b\u8bc6\u522b\u51fa\"token\u96ea\u7403\u6548\u5e94\"\u548c\"\u6602\u8d35\u5931\u8d25\"\u6a21\u5f0f\uff1b\u89c2\u5bdf\u5230token\u9884\u7b97\u548c\u65f6\u95f4\u9884\u7b97\u4e0b\u7684\u6548\u80fd\u5b58\u5728\u660e\u663e\u6743\u8861\u3002", "conclusion": "\u9700\u8981\u7efc\u5408\u8003\u8651\u51c6\u786e\u6027\u548c\u8d44\u6e90\u6d88\u8017\u6765\u8bc4\u4f30AI\u7cfb\u7edf\u6548\u80fd\uff0c\u7cfb\u7edf\u6574\u5408\u8d28\u91cf\u5bf9\u8d44\u6e90\u9ad8\u6548\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u8bc6\u522b\u51fa\u7684\u7cfb\u7edf\u6027\u6311\u6218\u5bf9\u5b9e\u9645\u90e8\u7f72\u548cRL\u8bad\u7ec3\u6210\u672c\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2509.09744", "pdf": "https://arxiv.org/pdf/2509.09744", "abs": "https://arxiv.org/abs/2509.09744", "authors": ["Mujie Liu", "Chenze Wang", "Liping Chen", "Nguyen Linh Dan Le", "Niharika Tewari", "Ting Dang", "Jiangang Ma", "Feng Xia"], "title": "Structure Matters: Brain Graph Augmentation via Learnable Edge Masking for Data-efficient Psychiatric Diagnosis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The limited availability of labeled brain network data makes it challenging\nto achieve accurate and interpretable psychiatric diagnoses. While\nself-supervised learning (SSL) offers a promising solution, existing methods\noften rely on augmentation strategies that can disrupt crucial structural\nsemantics in brain graphs. To address this, we propose SAM-BG, a two-stage\nframework for learning brain graph representations with structural semantic\npreservation. In the pre-training stage, an edge masker is trained on a small\nlabeled subset to capture key structural semantics. In the SSL stage, the\nextracted structural priors guide a structure-aware augmentation process,\nenabling the model to learn more semantically meaningful and robust\nrepresentations. Experiments on two real-world psychiatric datasets demonstrate\nthat SAM-BG outperforms state-of-the-art methods, particularly in small-labeled\ndata settings, and uncovers clinically relevant connectivity patterns that\nenhance interpretability. Our code is available at\nhttps://github.com/mjliu99/SAM-BG.", "AI": {"tldr": "SAM-BG\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u8bed\u4e49\u4fdd\u62a4\u6765\u5b66\u4e60\u8111\u56fe\u8868\u793a\uff0c\u5728\u7cbe\u795e\u75be\u75c5\u8bca\u65ad\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u7279\u522b\u662f\u5728\u5c0f\u6837\u672c\u6807\u6ce8\u6570\u636e\u573a\u666f\u4e0b\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u5728\u8111\u56fe\u6570\u636e\u4e0a\u5f80\u5f80\u4f9d\u8d56\u53ef\u80fd\u7834\u574f\u5173\u952e\u7ed3\u6784\u8bed\u4e49\u7684\u6570\u636e\u589e\u5f3a\u7b56\u7565\uff0c\u800c\u6807\u6ce8\u8111\u7f51\u7edc\u6570\u636e\u7684\u7a00\u7f3a\u6027\u4f7f\u5f97\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u7cbe\u795e\u75be\u75c5\u8bca\u65ad\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1\uff09\u9884\u8bad\u7ec3\u9636\u6bb5\u5728\u5c0f\u6807\u6ce8\u5b50\u96c6\u4e0a\u8bad\u7ec3\u8fb9\u7f18\u63a9\u7801\u5668\u6355\u6349\u5173\u952e\u7ed3\u6784\u8bed\u4e49\uff1b2\uff09\u81ea\u76d1\u7763\u5b66\u4e60\u9636\u6bb5\u5229\u7528\u63d0\u53d6\u7684\u7ed3\u6784\u5148\u9a8c\u6307\u5bfc\u7ed3\u6784\u611f\u77e5\u7684\u6570\u636e\u589e\u5f3a\u8fc7\u7a0b\uff0c\u5b66\u4e60\u66f4\u5177\u8bed\u4e49\u610f\u4e49\u548c\u9c81\u68d2\u6027\u7684\u8868\u793a\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u7cbe\u795e\u75be\u75c5\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSAM-BG\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5c0f\u6807\u6ce8\u6570\u636e\u8bbe\u7f6e\u4e0b\uff0c\u5e76\u80fd\u53d1\u73b0\u5177\u6709\u4e34\u5e8a\u76f8\u5173\u6027\u7684\u8fde\u63a5\u6a21\u5f0f\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "SAM-BG\u901a\u8fc7\u7ed3\u6784\u8bed\u4e49\u4fdd\u62a4\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8111\u56fe\u6570\u636e\u6807\u6ce8\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u5728\u7cbe\u795e\u75be\u75c5\u8bca\u65ad\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2509.10188", "pdf": "https://arxiv.org/pdf/2509.10188", "abs": "https://arxiv.org/abs/2509.10188", "authors": ["\u00c9tienne Grandjean", "Louis Jachiet"], "title": "Constant Time with Minimal Preprocessing, a Robust and Extensive Complexity Class", "categories": ["cs.DS", "cs.CC"], "comment": "In Honor of Yuri Gurevich on the occasion of his 85th Birthday", "summary": "In this paper, we study the class $\\mathtt{cstPP}$ of operations\n$\\mathtt{op}: \\mathbb{N}^k\\to\\mathbb{N}$, of any fixed arity $k\\ge 1$,\nsatisfying the following property: for each fixed integer $d\\ge 1$, there\nexists an algorithm for a RAM machine which, for any input integer $N\\ge 2$, -\npre-computes some tables in $O(N)$ time, - then reads $k$ operands\n$x_1,\\ldots,x_k<N^d$ and computes $\\mathtt{op}(x_1,\\dots,x_k)$ in constant\ntime.\n  We show that the $\\mathtt{cstPP}$ class is robust and extensive and satisfies\nseveral closure properties. It is invariant depending on whether the set of\nprimitive operations of the RAM is $\\{+\\}$, or\n$\\{+,-,\\times,\\mathtt{div},\\mathtt{mod}\\}$, or any set of operations in\n$\\mathtt{cstPP}$ provided it includes $+$. We prove that the $\\mathtt{cstPP}$\nclass is closed under composition and, for fast-growing functions, is closed\nunder inverse. We also show that in the definition of $\\mathtt{cstPP}$ the\nconstant-time procedure can be reduced to a single return instruction. Finally,\nwe establish that linear preprocessing time is not essential in the definition\nof the $\\mathtt{cstPP}$ class: this class is not modified if the preprocessing\ntime is increased to $O(N^c)$, for any fixed $c>1$, or conversely, is reduced\nto $N^{\\varepsilon}$, for any positive $\\varepsilon<1$ (provided the set of\nprimitive operation includes $+$, $\\mathtt{div}$ and $\\mathtt{mod}$). To\ncomplete the picture, we demonstrate that the $\\mathtt{cstPP}$ class\ndegenerates if the preprocessing time reduces to $N^{o(1)}$.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76cstPP\u7c7b\u8fd0\u7b97\uff0c\u8fd9\u7c7b\u8fd0\u7b97\u5728O(N)\u9884\u5904\u7406\u65f6\u95f4\u540e\u80fd\u5728\u5e38\u6570\u65f6\u95f4\u5185\u8ba1\u7b97\u4efb\u610f\u64cd\u4f5c\u6570\uff0c\u8bc1\u660e\u4e86\u8be5\u7c7b\u7684\u9c81\u68d2\u6027\u3001\u95ed\u5305\u6027\u548c\u5bf9\u9884\u5904\u7406\u65f6\u95f4\u53d8\u5316\u7684\u7a33\u5b9a\u6027\u3002", "motivation": "\u7814\u7a76\u5728RAM\u6a21\u578b\u4e2d\u5177\u6709\u5e38\u6570\u65f6\u95f4\u8ba1\u7b97\u80fd\u529b\u7684\u8fd0\u7b97\u7c7b\uff0c\u63a2\u7d22\u5176\u6570\u5b66\u6027\u8d28\u548c\u8ba1\u7b97\u7279\u6027\uff0c\u4e3a\u9ad8\u6548\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u901a\u8fc7\u5f62\u5f0f\u5316\u5b9a\u4e49cstPP\u7c7b\u8fd0\u7b97\uff0c\u5206\u6790\u5176\u5728\u4e0d\u540c\u539f\u59cb\u64cd\u4f5c\u96c6\u4e0b\u7684\u4e0d\u53d8\u6027\uff0c\u8bc1\u660e\u95ed\u5305\u6027\u8d28\uff08\u590d\u5408\u548c\u9006\u8fd0\u7b97\uff09\uff0c\u5e76\u7814\u7a76\u9884\u5904\u7406\u65f6\u95f4\u53d8\u5316\u5bf9\u7c7b\u5b9a\u4e49\u7684\u5f71\u54cd\u3002", "result": "\u8bc1\u660ecstPP\u7c7b\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5728\u4e0d\u540c\u539f\u59cb\u64cd\u4f5c\u96c6\u4e0b\u4fdd\u6301\u4e0d\u53d8\uff1b\u6ee1\u8db3\u590d\u5408\u548c\u9006\u8fd0\u7b97\u95ed\u5305\uff1b\u9884\u5904\u7406\u65f6\u95f4\u5728O(N^c)\u6216N^\u03b5\u8303\u56f4\u5185\u4e0d\u5f71\u54cd\u7c7b\u5b9a\u4e49\uff1b\u4f46\u9884\u5904\u7406\u65f6\u95f4\u4e3aN^{o(1)}\u65f6\u7c7b\u4f1a\u9000\u5316\u3002", "conclusion": "cstPP\u7c7b\u662f\u4e00\u4e2a\u5f3a\u5927\u4e14\u7a33\u5b9a\u7684\u8ba1\u7b97\u7c7b\uff0c\u5bf9\u9884\u5904\u7406\u65f6\u95f4\u5177\u6709\u4e00\u5b9a\u5bb9\u5fcd\u5ea6\uff0c\u4e3a\u7406\u89e3\u5e38\u6570\u65f6\u95f4\u53ef\u8ba1\u7b97\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2509.09868", "pdf": "https://arxiv.org/pdf/2509.09868", "abs": "https://arxiv.org/abs/2509.09868", "authors": ["Yunhao Zhang", "Haobin Ni", "Soumya Basu", "Shir Cohen", "Maofan Yin", "Lorenzo Alvisi", "Robbert van Renesse", "Qi Chen", "Lidong Zhou"], "title": "Ordered Consensus with Equal Opportunity", "categories": ["cs.DC", "cs.CR", "cs.MA"], "comment": null, "summary": "The specification of state machine replication (SMR) has no requirement on\nthe final total order of commands. In blockchains based on SMR, however, order\nmatters, since different orders could provide their clients with different\nfinancial rewards. Ordered consensus augments the specification of SMR to\ninclude specific guarantees on such order, with a focus on limiting the\ninfluence of Byzantine nodes. Real-world ordering manipulations, however, can\nand do happen even without Byzantine replicas, typically because of factors,\nsuch as faster networks or closer proximity to the blockchain infrastructure,\nthat give some clients an unfair advantage. To address this challenge, this\npaper proceeds to extend ordered consensus by requiring it to also support\nequal opportunity, a concrete notion of fairness, widely adopted in social\nsciences. Informally, equal opportunity requires that two candidates who,\naccording to a set of criteria deemed to be relevant, are equally qualified for\na position (in our case, a specific slot in the SMR total order), should have\nan equal chance of landing it. We show how randomness can be leveraged to keep\nbias in check, and, to this end, introduce the secret random oracle (SRO), a\nsystem component that generates randomness in a fault-tolerant manner. We\ndescribe two SRO designs based, respectively, on trusted hardware and threshold\nverifiable random functions, and instantiate them in Bercow, a new ordered\nconsensus protocol that, by approximating equal opportunity up to within a\nconfigurable factor, can effectively mitigate well-known ordering attacks in\nSMR-based blockchains.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u72b6\u6001\u673a\u590d\u5236(SMR)\u7684\u6709\u5e8f\u5171\u8bc6\uff0c\u5f15\u5165\u4e86\u5e73\u7b49\u673a\u4f1a\u7684\u516c\u5e73\u6027\u6982\u5ff5\uff0c\u901a\u8fc7\u79d8\u5bc6\u968f\u673a\u9884\u8a00\u673a(SRO)\u751f\u6210\u968f\u673a\u6027\u6765\u51cf\u5c11\u6392\u5e8f\u504f\u89c1\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u53ef\u4fe1\u786c\u4ef6\u548c\u9608\u503c\u53ef\u9a8c\u8bc1\u968f\u673a\u51fd\u6570\u7684Bercow\u534f\u8bae\u6765\u7f13\u89e3\u533a\u5757\u94fe\u4e2d\u7684\u6392\u5e8f\u653b\u51fb\u3002", "motivation": "\u5728\u57fa\u4e8eSMR\u7684\u533a\u5757\u94fe\u4e2d\uff0c\u4e0d\u540c\u7684\u547d\u4ee4\u6392\u5e8f\u4f1a\u7ed9\u5ba2\u6237\u7aef\u5e26\u6765\u4e0d\u540c\u7684\u8d22\u52a1\u5956\u52b1\uff0c\u73b0\u6709\u6709\u5e8f\u5171\u8bc6\u4e3b\u8981\u5173\u6ce8\u9650\u5236\u62dc\u5360\u5ead\u8282\u70b9\u7684\u5f71\u54cd\uff0c\u4f46\u73b0\u5b9e\u4e2d\u7684\u6392\u5e8f\u64cd\u7eb5\u5373\u4f7f\u6ca1\u6709\u62dc\u5360\u5ead\u8282\u70b9\u4e5f\u4f1a\u53d1\u751f\uff0c\u56e0\u4e3a\u7f51\u7edc\u901f\u5ea6\u3001\u57fa\u7840\u8bbe\u65bd\u8ddd\u79bb\u7b49\u56e0\u7d20\u7ed9\u67d0\u4e9b\u5ba2\u6237\u7aef\u5e26\u6765\u4e86\u4e0d\u516c\u5e73\u4f18\u52bf\u3002", "method": "\u63d0\u51fa\u5e73\u7b49\u673a\u4f1a\u7684\u516c\u5e73\u6027\u6982\u5ff5\uff0c\u8981\u6c42\u540c\u7b49\u8d44\u683c\u7684\u5019\u9009\u4eba\u5728\u6392\u5e8f\u4e2d\u5e94\u6709\u5e73\u7b49\u673a\u4f1a\uff1b\u5f15\u5165\u79d8\u5bc6\u968f\u673a\u9884\u8a00\u673a(SRO)\u6765\u4ee5\u5bb9\u9519\u65b9\u5f0f\u751f\u6210\u968f\u673a\u6027\uff1b\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u53ef\u4fe1\u786c\u4ef6\u548c\u9608\u503c\u53ef\u9a8c\u8bc1\u968f\u673a\u51fd\u6570\u7684\u4e24\u79cdSRO\u65b9\u6848\uff1b\u5b9e\u4f8b\u5316\u4e3aBercow\u6709\u5e8f\u5171\u8bc6\u534f\u8bae\uff0c\u901a\u8fc7\u53ef\u914d\u7f6e\u56e0\u5b50\u8fd1\u4f3c\u5b9e\u73b0\u5e73\u7b49\u673a\u4f1a\u3002", "result": "\u5f00\u53d1\u4e86Bercow\u534f\u8bae\uff0c\u80fd\u591f\u6709\u6548\u7f13\u89e3SMR\u57fa\u533a\u5757\u94fe\u4e2d\u5df2\u77e5\u7684\u6392\u5e8f\u653b\u51fb\uff0c\u901a\u8fc7\u968f\u673a\u6027\u63a7\u5236\u504f\u89c1\uff0c\u5728\u53ef\u914d\u7f6e\u8303\u56f4\u5185\u8fd1\u4f3c\u5b9e\u73b0\u5e73\u7b49\u673a\u4f1a\u7684\u516c\u5e73\u6027\u8981\u6c42\u3002", "conclusion": "\u901a\u8fc7\u5c06\u5e73\u7b49\u673a\u4f1a\u7684\u516c\u5e73\u6027\u6982\u5ff5\u5f15\u5165\u6709\u5e8f\u5171\u8bc6\uff0c\u5e76\u5229\u7528\u968f\u673a\u6027\u6280\u672f\u6765\u51cf\u5c11\u6392\u5e8f\u504f\u89c1\uff0cBercow\u534f\u8bae\u4e3a\u89e3\u51b3\u533a\u5757\u94fe\u4e2d\u7684\u6392\u5e8f\u64cd\u7eb5\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u589e\u5f3a\u4e86\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2509.09997", "pdf": "https://arxiv.org/pdf/2509.09997", "abs": "https://arxiv.org/abs/2509.09997", "authors": ["Richard Jozsa", "Karel Hynek", "Adrian Pekar"], "title": "Taming Volatility: Stable and Private QUIC Classification with Federated Learning", "categories": ["cs.NI"], "comment": "Accepted for presentation at CNSM2025", "summary": "Federated Learning (FL) is a promising approach for privacy-preserving\nnetwork traffic analysis, but its practical deployment is challenged by the\nnon-IID nature of real-world data. While prior work has addressed statistical\nheterogeneity, the impact of temporal traffic volatility-the natural daily ebb\nand flow of network activity-on model stability remains largely unexplored.\nThis volatility can lead to inconsistent data availability at clients,\ndestabilizing the entire training process. In this paper, we systematically\naddress the problem of temporal volatility in federated QUIC classification. We\nfirst demonstrate the instability of standard FL in this dynamic setting. We\nthen propose and evaluate a client-side data buffer as a practical mechanism to\nensure stable and consistent local training, decoupling it from real-time\ntraffic fluctuations. Using the real-world CESNET-QUIC22 dataset partitioned\ninto 14 autonomous clients, we then demonstrate that this approach enables\nrobust convergence. Our results show that a stable federated system achieves a\n95.2% F1 score, a mere 2.3 percentage points below a non-private centralized\nmodel. This work establishes a blueprint for building operationally stable FL\nsystems for network management, proving that the challenges of dynamic network\nenvironments can be overcome with targeted architectural choices.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u8054\u90a6\u5b66\u4e60\u4e2d\u7f51\u7edc\u6d41\u91cf\u65f6\u95f4\u6ce2\u52a8\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u5ba2\u6237\u7aef\u6570\u636e\u7f13\u51b2\u673a\u5236\uff0c\u5728QUIC\u5206\u7c7b\u4efb\u52a1\u4e2d\u5b9e\u73b095.2%\u7684F1\u5206\u6570\uff0c\u4ec5\u6bd4\u975e\u79c1\u6709\u96c6\u4e2d\u5f0f\u6a21\u578b\u4f4e2.3\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u9690\u79c1\u4fdd\u62a4\u7684\u7f51\u7edc\u6d41\u91cf\u5206\u6790\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u9762\u4e34\u975eIID\u6570\u636e\u7684\u6311\u6218\u3002\u5148\u524d\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u7edf\u8ba1\u5f02\u8d28\u6027\uff0c\u800c\u65f6\u95f4\u6ce2\u52a8\u6027\uff08\u7f51\u7edc\u6d3b\u52a8\u7684\u65e5\u5e38\u8d77\u4f0f\uff09\u5bf9\u6a21\u578b\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u8fd9\u79cd\u6ce2\u52a8\u4f1a\u5bfc\u81f4\u5ba2\u6237\u7aef\u6570\u636e\u53ef\u7528\u6027\u4e0d\u4e00\u81f4\uff0c\u7834\u574f\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u7684\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u5ba2\u6237\u7aef\u6570\u636e\u7f13\u51b2\u673a\u5236\u4f5c\u4e3a\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5c06\u672c\u5730\u8bad\u7ec3\u4e0e\u5b9e\u65f6\u6d41\u91cf\u6ce2\u52a8\u89e3\u8026\uff0c\u786e\u4fdd\u7a33\u5b9a\u4e00\u81f4\u7684\u672c\u5730\u8bad\u7ec3\u3002\u4f7f\u7528\u771f\u5b9e\u4e16\u754c\u7684CESNET-QUIC22\u6570\u636e\u96c6\uff0c\u5212\u5206\u4e3a14\u4e2a\u81ea\u6cbb\u5ba2\u6237\u7aef\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u7a33\u5065\u6536\u655b\uff0c\u7a33\u5b9a\u8054\u90a6\u7cfb\u7edf\u8fbe\u523095.2%\u7684F1\u5206\u6570\uff0c\u4ec5\u6bd4\u975e\u79c1\u6709\u96c6\u4e2d\u5f0f\u6a21\u578b\u4f4e2.3\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u6784\u5efa\u64cd\u4f5c\u7a33\u5b9a\u7684\u7f51\u7edc\u7ba1\u7406\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u84dd\u56fe\uff0c\u8bc1\u660e\u901a\u8fc7\u6709\u9488\u5bf9\u6027\u7684\u67b6\u6784\u9009\u62e9\u53ef\u4ee5\u514b\u670d\u52a8\u6001\u7f51\u7edc\u73af\u5883\u7684\u6311\u6218\u3002"}}
{"id": "2509.09873", "pdf": "https://arxiv.org/pdf/2509.09873", "abs": "https://arxiv.org/abs/2509.09873", "authors": ["James Jewitt", "Hao Li", "Bram Adams", "Gopi Krishnan Rajbahadur", "Ahmed E. Hassan"], "title": "From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem", "categories": ["cs.SE", "cs.AI"], "comment": "9 pages, 4 figures, 5 tables, pre-print", "summary": "Hidden license conflicts in the open-source AI ecosystem pose serious legal\nand ethical risks, exposing organizations to potential litigation and users to\nundisclosed risk. However, the field lacks a data-driven understanding of how\nfrequently these conflicts occur, where they originate, and which communities\nare most affected. We present the first end-to-end audit of licenses for\ndatasets and models on Hugging Face, as well as their downstream integration\ninto open-source software applications, covering 364 thousand datasets, 1.6\nmillion models, and 140 thousand GitHub projects. Our empirical analysis\nreveals systemic non-compliance in which 35.5% of model-to-application\ntransitions eliminate restrictive license clauses by relicensing under\npermissive terms. In addition, we prototype an extensible rule engine that\nencodes almost 200 SPDX and model-specific clauses for detecting license\nconflicts, which can solve 86.4% of license conflicts in software applications.\nTo support future research, we release our dataset and the prototype engine.\nOur study highlights license compliance as a critical governance challenge in\nopen-source AI and provides both the data and tools necessary to enable\nautomated, AI-aware compliance at scale.", "AI": {"tldr": "\u9996\u4e2a\u5bf9Hugging Face\u6570\u636e\u96c6\u548c\u6a21\u578b\u8bb8\u53ef\u8bc1\u7684\u7aef\u5230\u7aef\u5ba1\u8ba1\uff0c\u53d1\u73b035.5%\u7684\u6a21\u578b\u5230\u5e94\u7528\u8f6c\u6362\u4e2d\u901a\u8fc7\u91cd\u65b0\u8bb8\u53ef\u6d88\u9664\u4e86\u9650\u5236\u6027\u6761\u6b3e\uff0c\u5e76\u5f00\u53d1\u4e86\u53ef\u68c0\u6d4b86.4%\u8bb8\u53ef\u8bc1\u51b2\u7a81\u7684\u89c4\u5219\u5f15\u64ce", "motivation": "\u5f00\u6e90AI\u751f\u6001\u7cfb\u7edf\u4e2d\u9690\u85cf\u7684\u8bb8\u53ef\u8bc1\u51b2\u7a81\u5b58\u5728\u4e25\u91cd\u7684\u6cd5\u5f8b\u548c\u4f26\u7406\u98ce\u9669\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u51b2\u7a81\u53d1\u751f\u9891\u7387\u3001\u6765\u6e90\u548c\u53d7\u5f71\u54cd\u793e\u533a\u7684\u6570\u636e\u9a71\u52a8\u7406\u89e3", "method": "\u5bf9Hugging Face\u4e0a36.4\u4e07\u4e2a\u6570\u636e\u96c6\u3001160\u4e07\u4e2a\u6a21\u578b\u4ee5\u53ca14\u4e07\u4e2aGitHub\u9879\u76ee\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u5e76\u5f00\u53d1\u4e86\u53ef\u7f16\u7801\u8fd1200\u4e2aSPDX\u548c\u6a21\u578b\u7279\u5b9a\u6761\u6b3e\u7684\u53ef\u6269\u5c55\u89c4\u5219\u5f15\u64ce", "result": "\u53d1\u73b035.5%\u7684\u6a21\u578b\u5230\u5e94\u7528\u8f6c\u6362\u901a\u8fc7\u91cd\u65b0\u8bb8\u53ef\u6d88\u9664\u4e86\u9650\u5236\u6027\u6761\u6b3e\uff0c\u539f\u578b\u89c4\u5219\u5f15\u64ce\u53ef\u4ee5\u89e3\u51b386.4%\u7684\u8f6f\u4ef6\u5e94\u7528\u8bb8\u53ef\u8bc1\u51b2\u7a81", "conclusion": "\u8bb8\u53ef\u8bc1\u5408\u89c4\u6027\u662f\u5f00\u6e90AI\u4e2d\u7684\u5173\u952e\u6cbb\u7406\u6311\u6218\uff0c\u7814\u7a76\u63d0\u4f9b\u4e86\u652f\u6301\u81ea\u52a8\u5316\u3001AI\u611f\u77e5\u5927\u89c4\u6a21\u5408\u89c4\u6027\u6240\u9700\u7684\u6570\u636e\u548c\u5de5\u5177"}}
{"id": "2509.09747", "pdf": "https://arxiv.org/pdf/2509.09747", "abs": "https://arxiv.org/abs/2509.09747", "authors": ["Leen Daher", "Zhaobo Wang", "Malcolm Mielle"], "title": "D-CAT: Decoupled Cross-Attention Transfer between Sensor Modalities for Unimodal Inference", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Cross-modal transfer learning is used to improve multi-modal classification\nmodels (e.g., for human activity recognition in human-robot collaboration).\nHowever, existing methods require paired sensor data at both training and\ninference, limiting deployment in resource-constrained environments where full\nsensor suites are not economically and technically usable. To address this, we\npropose Decoupled Cross-Attention Transfer (D-CAT), a framework that aligns\nmodality-specific representations without requiring joint sensor modality\nduring inference. Our approach combines a self-attention module for feature\nextraction with a novel cross-attention alignment loss, which enforces the\nalignment of sensors' feature spaces without requiring the coupling of the\nclassification pipelines of both modalities. We evaluate D-CAT on three\nmulti-modal human activity datasets (IMU, video, and audio) under both\nin-distribution and out-of-distribution scenarios, comparing against uni-modal\nmodels. Results show that in in-distribution scenarios, transferring from\nhigh-performing modalities (e.g., video to IMU) yields up to 10% F1-score gains\nover uni-modal training. In out-of-distribution scenarios, even weaker source\nmodalities (e.g., IMU to video) improve target performance, as long as the\ntarget model isn't overfitted on the training data. By enabling single-sensor\ninference with cross-modal knowledge, D-CAT reduces hardware redundancy for\nperception systems while maintaining accuracy, which is critical for\ncost-sensitive or adaptive deployments (e.g., assistive robots in homes with\nvariable sensor availability). Code is available at\nhttps://github.com/Schindler-EPFL-Lab/D-CAT.", "AI": {"tldr": "\u63d0\u51fa\u4e86D-CAT\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u7684\u8de8\u6ce8\u610f\u529b\u8f6c\u79fb\u5b9e\u73b0\u8de8\u6a21\u6001\u77e5\u8bc6\u8fc1\u79fb\uff0c\u5728\u63a8\u7406\u65f6\u53ea\u9700\u5355\u4e00\u4f20\u611f\u5668\uff0c\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5206\u7c7b\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u8de8\u6a21\u6001\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u90fd\u9700\u8981\u6210\u5bf9\u7684\u4f20\u611f\u5668\u6570\u636e\uff0c\u9650\u5236\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u90e8\u7f72\uff0c\u56e0\u4e3a\u5b8c\u6574\u4f20\u611f\u5668\u5957\u4ef6\u5728\u7ecf\u6d4e\u548c\u6280\u672f\u4e0a\u4e0d\u53ef\u884c\u3002", "method": "D-CAT\u6846\u67b6\u7ed3\u5408\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u4f7f\u7528\u65b0\u9896\u7684\u8de8\u6ce8\u610f\u529b\u5bf9\u9f50\u635f\u5931\u6765\u5bf9\u9f50\u4e0d\u540c\u6a21\u6001\u7684\u7279\u5f81\u7a7a\u95f4\uff0c\u65e0\u9700\u8026\u5408\u4e24\u79cd\u6a21\u6001\u7684\u5206\u7c7b\u6d41\u7a0b\u3002", "result": "\u5728\u4e09\u4e2a\u591a\u6a21\u6001\u4eba\u7c7b\u6d3b\u52a8\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u5728\u5206\u5e03\u5185\u573a\u666f\u4e2d\u4ece\u9ad8\u6027\u80fd\u6a21\u6001\uff08\u5982\u89c6\u9891\u5230IMU\uff09\u8f6c\u79fb\u53ef\u83b7\u5f9710%\u7684F1\u5206\u6570\u63d0\u5347\uff1b\u5728\u5206\u5e03\u5916\u573a\u666f\u4e2d\uff0c\u5373\u4f7f\u8f83\u5f31\u7684\u6e90\u6a21\u6001\u4e5f\u80fd\u6539\u5584\u76ee\u6807\u6027\u80fd\u3002", "conclusion": "D-CAT\u901a\u8fc7\u8de8\u6a21\u6001\u77e5\u8bc6\u5b9e\u73b0\u5355\u4f20\u611f\u5668\u63a8\u7406\uff0c\u51cf\u5c11\u4e86\u611f\u77e5\u7cfb\u7edf\u7684\u786c\u4ef6\u5197\u4f59\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u5bf9\u6210\u672c\u654f\u611f\u6216\u81ea\u9002\u5e94\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2509.10450", "pdf": "https://arxiv.org/pdf/2509.10450", "abs": "https://arxiv.org/abs/2509.10450", "authors": ["Alexander Taveira Blomenhofer", "Benjamin Lovitz"], "title": "A linear-time algorithm for Chow decompositions", "categories": ["cs.DS", "math.AG", "quant-ph", "14Q15, 15A69"], "comment": "21 pages. Comments welcome", "summary": "We propose a linear-time algorithm to compute low-rank Chow decompositions.\nOur algorithm can decompose concise symmetric 3-tensors in n variables of Chow\nrank n/3. The algorithm is pencil based, hence it relies on generalized\neigenvalue computations. We also develop sub-quadratic time algorithms for\nhigher order Chow decompositions, and Chow decompositions of 3-tensors into\nproducts of linear forms which do not lie on the generic orbit. In particular,\nwe obtain a sub-quadratic-time algorithm for decomposing a symmetric 3-tensor\ninto a linear combination of W-tensors.", "AI": {"tldr": "\u63d0\u51fa\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\u8ba1\u7b97\u4f4e\u79e9Chow\u5206\u89e3\uff0c\u53ef\u5206\u89e3\u5bf9\u79f03-\u5f20\u91cf\uff0c\u5e76\u5f00\u53d1\u6b21\u4e8c\u6b21\u65f6\u95f4\u7b97\u6cd5\u5904\u7406\u9ad8\u9636Chow\u5206\u89e3\u548c\u7279\u6b8a\u8f68\u9053\u5206\u89e3", "motivation": "\u9700\u8981\u9ad8\u6548\u7b97\u6cd5\u6765\u5206\u89e3\u5bf9\u79f0\u5f20\u91cf\uff0c\u7279\u522b\u662f\u5904\u7406Chow\u5206\u89e3\u95ee\u9898\uff0c\u4ee5\u89e3\u51b3\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u65f6\u95f4\u6548\u7387\u7684\u6311\u6218", "method": "\u57fa\u4e8e\u94c5\u7b14(pencil-based)\u7684\u7b97\u6cd5\uff0c\u4f9d\u8d56\u5e7f\u4e49\u7279\u5f81\u503c\u8ba1\u7b97\uff0c\u5f00\u53d1\u7ebf\u6027\u65f6\u95f4\u548c\u6b21\u4e8c\u6b21\u65f6\u95f4\u7b97\u6cd5\u5904\u7406\u4e0d\u540c\u9636\u6570\u7684Chow\u5206\u89e3", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\u5206\u89e3\u79e9\u4e3an/3\u7684\u5bf9\u79f03-\u5f20\u91cf\uff0c\u5e76\u5f00\u53d1\u4e86\u5904\u7406\u9ad8\u9636\u5206\u89e3\u548c\u7279\u6b8a\u8f68\u9053\u5206\u89e3\u7684\u6b21\u4e8c\u6b21\u65f6\u95f4\u7b97\u6cd5", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684Chow\u5206\u89e3\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u79f0\u5f20\u91cf\u5206\u89e3\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8ba1\u7b97\u5de5\u5177"}}
{"id": "2509.10371", "pdf": "https://arxiv.org/pdf/2509.10371", "abs": "https://arxiv.org/abs/2509.10371", "authors": ["Seokjin Go", "Joongun Park", "Spandan More", "Hanjiang Wu", "Irene Wang", "Aaron Jezghani", "Tushar Krishna", "Divya Mahajan"], "title": "Characterizing the Efficiency of Distributed Training: A Power, Performance, and Thermal Perspective", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "The rapid scaling of Large Language Models (LLMs) has pushed training\nworkloads far beyond the limits of single-node analysis, demanding a deeper\nunderstanding of how these models behave across large-scale, multi-GPU systems.\nIn this paper, we present a comprehensive characterization of LLM training\nacross diverse real-world workloads and hardware platforms, including NVIDIA\nH100/H200 and AMD MI250 GPUs. We analyze dense and sparse models under various\nparallelism strategies -- tensor, pipeline, data, and expert -- and evaluate\ntheir effects on hardware utilization, power consumption, and thermal behavior.\nWe further evaluate the effectiveness of optimizations such as activation\nrecomputation and compute-communication overlap. Our findings show that\nperformance is not determined solely by scaling hardware capacity. Scale-up\nsystems with fewer, higher-memory GPUs can outperform scale-out systems in\ncommunication-bound regimes, but only under carefully tuned configurations; in\nother cases, scale-out deployments achieve superior throughput. We also show\nthat certain parallelism combinations, such as tensor with pipeline, lead to\nbandwidth underutilization due to inefficient data chunking, while increasing\nmicrobatch sizes beyond a certain point induces bursty execution and peak power\nexcursions that worsen thermal throttling. These insights reveal how training\nperformance is shaped by complex interactions between hardware, system\ntopology, and model execution. We conclude by offering recommendations for\nsystem and hardware design to improve the scalability and reliability of future\nLLM systems and workloads. The source code of this project is available at\nhttps://github.com/sitar-lab/CharLLM-PPT.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5927\u89c4\u6a21\u591aGPU\u7cfb\u7edf\u4e2dLLM\u8bad\u7ec3\u8fdb\u884c\u4e86\u5168\u9762\u6027\u80fd\u5206\u6790\uff0c\u63ed\u793a\u4e86\u786c\u4ef6\u914d\u7f6e\u3001\u5e76\u884c\u7b56\u7565\u548c\u4f18\u5316\u6280\u672f\u4e4b\u95f4\u7684\u590d\u6742\u4ea4\u4e92\u5173\u7cfb\uff0c\u4e3a\u672a\u6765\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u6307\u5bfc", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u5feb\u901f\u589e\u957f\uff0c\u8bad\u7ec3\u5de5\u4f5c\u8d1f\u8f7d\u5df2\u8fdc\u8d85\u5355\u8282\u70b9\u5206\u6790\u80fd\u529b\uff0c\u9700\u8981\u6df1\u5165\u7406\u89e3\u8fd9\u4e9b\u6a21\u578b\u5728\u5927\u89c4\u6a21\u591aGPU\u7cfb\u7edf\u4e2d\u7684\u884c\u4e3a\u8868\u73b0", "method": "\u5728NVIDIA H100/H200\u548cAMD MI250 GPU\u5e73\u53f0\u4e0a\uff0c\u5206\u6790\u5bc6\u96c6\u548c\u7a00\u758f\u6a21\u578b\u5728\u4e0d\u540c\u5e76\u884c\u7b56\u7565\uff08\u5f20\u91cf\u3001\u6d41\u6c34\u7ebf\u3001\u6570\u636e\u548c\u4e13\u5bb6\u5e76\u884c\uff09\u4e0b\u7684\u786c\u4ef6\u5229\u7528\u7387\u3001\u529f\u8017\u548c\u70ed\u884c\u4e3a\uff0c\u5e76\u8bc4\u4f30\u6fc0\u6d3b\u91cd\u8ba1\u7b97\u548c\u8ba1\u7b97-\u901a\u4fe1\u91cd\u53e0\u7b49\u4f18\u5316\u6548\u679c", "result": "\u7814\u7a76\u53d1\u73b0\u6027\u80fd\u4e0d\u4ec5\u7531\u786c\u4ef6\u5bb9\u91cf\u51b3\u5b9a\uff1a\u5728\u901a\u4fe1\u53d7\u9650\u573a\u666f\u4e2d\uff0c\u8f83\u5c11\u4f46\u9ad8\u5185\u5b58GPU\u7684\u7eb5\u5411\u6269\u5c55\u7cfb\u7edf\u53ef\u80fd\u4f18\u4e8e\u6a2a\u5411\u6269\u5c55\u7cfb\u7edf\uff0c\u4f46\u9700\u8981\u7cbe\u7ec6\u8c03\u4f18\uff1b\u67d0\u4e9b\u5e76\u884c\u7ec4\u5408\uff08\u5982\u5f20\u91cf\u4e0e\u6d41\u6c34\u7ebf\u5e76\u884c\uff09\u4f1a\u5bfc\u81f4\u5e26\u5bbd\u5229\u7528\u4e0d\u8db3\uff0c\u800c\u8fc7\u5927\u7684\u5fae\u6279\u6b21\u5927\u5c0f\u4f1a\u5f15\u8d77\u7a81\u53d1\u6267\u884c\u548c\u5cf0\u503c\u529f\u8017\u95ee\u9898", "conclusion": "\u8bad\u7ec3\u6027\u80fd\u7531\u786c\u4ef6\u3001\u7cfb\u7edf\u62d3\u6251\u548c\u6a21\u578b\u6267\u884c\u4e4b\u95f4\u7684\u590d\u6742\u4ea4\u4e92\u51b3\u5b9a\uff0c\u7814\u7a76\u4e3a\u6539\u8fdb\u672a\u6765LLM\u7cfb\u7edf\u53ef\u6269\u5c55\u6027\u548c\u53ef\u9760\u6027\u7684\u7cfb\u7edf\u548c\u786c\u4ef6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5177\u4f53\u5efa\u8bae"}}
{"id": "2509.10001", "pdf": "https://arxiv.org/pdf/2509.10001", "abs": "https://arxiv.org/abs/2509.10001", "authors": ["Takanori Hara", "Masahiro Sasabe"], "title": "Service Function Chaining Architecture for Multi-hop Split Inference and Learning", "categories": ["cs.NI"], "comment": "11 pages, 12 figures", "summary": "Service Function Chaining (SFC) is a networking technique that ensures\ntraffic traverses a predefined sequence of service functions, realizing\narbitrary network services through dynamic and efficient communication paths.\nInspired by this concept, we propose an SFC-based architecture for Multi-hop\nSplit Inference (MSI), where split sub-models are interpreted as service\nfunctions and their composition forms a service chain representing the global\nmodel. By leveraging SFC, the proposed architecture dynamically establishes\ncommunication paths for split sub-models, ensuring efficient and adaptive\nexecution. Furthermore, we extend this architecture to Multi-hop Split Learning\n(MSL) by applying SFC to the bidirectional communication required for training\ntasks. To realize the proposed architecture, we design Neural Service Functions\n(NSFs) to execute split sub-models as transparent TCP proxies and integrate\nthem with Segment Routing over IPv6 (SRv6) and the extended Berkeley Packet\nFilter (eBPF)-based SFC proxy. This integration ensures efficient ML processing\nover dynamic routing while maintaining compatibility with existing\napplications. Evaluation results demonstrate that (1) the proposed architecture\nis feasible for both MSI and MSL; (2) it is particularly suitable for real-time\ninference in MSI scenarios with small mini-batch sizes; (3) it supports dynamic\npath reconfiguration, enabling adaptive responses to changing network\nconditions while minimizing the impact of control mechanisms on inference and\nlearning processes.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u670d\u52a1\u529f\u80fd\u94fe(SFC)\u7684\u591a\u8df3\u5206\u5272\u63a8\u7406/\u5b66\u4e60\u67b6\u6784\uff0c\u5c06\u5206\u5272\u5b50\u6a21\u578b\u89c6\u4e3a\u670d\u52a1\u529f\u80fd\uff0c\u901a\u8fc7SFC\u52a8\u6001\u5efa\u7acb\u901a\u4fe1\u8def\u5f84\uff0c\u5b9e\u73b0\u9ad8\u6548\u81ea\u9002\u5e94\u6267\u884c", "motivation": "\u53d7\u7f51\u7edc\u670d\u52a1\u529f\u80fd\u94fe\u6280\u672f\u542f\u53d1\uff0c\u5e0c\u671b\u4e3a\u591a\u8df3\u5206\u5272\u63a8\u7406\u548c\u5b66\u4e60\u63d0\u4f9b\u52a8\u6001\u3001\u9ad8\u6548\u7684\u901a\u4fe1\u8def\u5f84\u7ba1\u7406\u65b9\u6848", "method": "\u8bbe\u8ba1\u795e\u7ecf\u670d\u52a1\u529f\u80fd(NSF)\u4f5c\u4e3a\u900f\u660eTCP\u4ee3\u7406\u6267\u884c\u5206\u5272\u5b50\u6a21\u578b\uff0c\u4e0eSRv6\u548ceBPF-based SFC\u4ee3\u7406\u96c6\u6210\uff0c\u5b9e\u73b0\u52a8\u6001\u8def\u7531\u4e0a\u7684\u9ad8\u6548ML\u5904\u7406", "result": "\u67b6\u6784\u5bf9MSI\u548cMSL\u90fd\u53ef\u884c\uff0c\u7279\u522b\u9002\u5408\u5c0f\u6279\u91cf\u5b9e\u65f6\u63a8\u7406\u573a\u666f\uff0c\u652f\u6301\u52a8\u6001\u8def\u5f84\u91cd\u914d\u7f6e\u4ee5\u9002\u5e94\u7f51\u7edc\u53d8\u5316", "conclusion": "SFC-based\u67b6\u6784\u4e3a\u591a\u8df3\u5206\u5272\u63a8\u7406\u548c\u5b66\u4e60\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u52a8\u6001\u901a\u4fe1\u8def\u5f84\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u826f\u597d\u7684\u517c\u5bb9\u6027\u548c\u9002\u5e94\u6027"}}
{"id": "2509.09917", "pdf": "https://arxiv.org/pdf/2509.09917", "abs": "https://arxiv.org/abs/2509.09917", "authors": ["Zehan Chen", "Long Zhang", "Zhiwei Zhang", "JingJing Zhang", "Ruoyu Zhou", "Yulong Shen", "JianFeng Ma", "Lin Yang"], "title": "SLD-Spec: Enhancement LLM-assisted Specification Generation for Complex Loop Functions via Program Slicing and Logical Deletion", "categories": ["cs.SE", "D.2.4"], "comment": "22 pages, 2 figures, conference", "summary": "Automatically generating formal specifications from program code can greatly\nenhance the efficiency of program verification and enable end-to-end automation\nfrom requirements to reliable software. However, existing LLM-based approaches\noften struggle with programs that include complex loop structures, leading to\nirrelevant specifications. Moreover, the rigorous proof obligations and design\nconstraints imposed by verification tools can further result in incomplete and\nambiguous specifications. To address these challenges, we propose SLD-Spec, an\nLLM-assisted specification generation method tailored for programs with complex\nloop constructs. SLD-Spec introduces two novel phases into the traditional\nspecification generation framework: (1) A slicing phase, which decomposes each\nfunction into code fragments containing independent loop structures, thereby\nreducing the complexity of specification generation; and (2) A logical deletion\nphase, which applies LLM-based reasoning to filter out incorrect candidate\nspecifications--especially those not easily identified by verification\ntool--while retaining valid ones. Experimental results show that on the simple\ndataset, SLD-Spec successfully verifies five more programs than the\nstate-of-the-art AutoSpec and reduces runtime by 23.73%. To address the\nlimitations of existing research, we manually construct a dataset comprising\nfour categories of complex loop programs. On this dataset, SLD-Spec\nsignificantly improves the correctness, relevance, and completeness of\ngenerated specifications compared to baseline methods, enabling 95.1% of\nassertions and 90.91% of programs to pass verification. Ablation studies\nfurther reveal that logical deletion is critical for enhancing specification\ncorrectness and relevance, while program slicing contributes significantly to\nspecification completeness. Our code and data are publicly available.", "AI": {"tldr": "SLD-Spec\u662f\u4e00\u79cd\u9488\u5bf9\u590d\u6742\u5faa\u73af\u7a0b\u5e8f\u7684LLM\u8f85\u52a9\u89c4\u8303\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a0b\u5e8f\u5207\u7247\u548c\u903b\u8f91\u5220\u9664\u4e24\u4e2a\u65b0\u9636\u6bb5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u89c4\u8303\u7684\u6b63\u786e\u6027\u3001\u76f8\u5173\u6027\u548c\u5b8c\u6574\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u5728\u5904\u7406\u5305\u542b\u590d\u6742\u5faa\u73af\u7ed3\u6784\u7684\u7a0b\u5e8f\u65f6\u5f80\u5f80\u751f\u6210\u4e0d\u76f8\u5173\u7684\u89c4\u8303\uff0c\u4e14\u9a8c\u8bc1\u5de5\u5177\u7684\u4e25\u683c\u8bc1\u660e\u4e49\u52a1\u548c\u8bbe\u8ba1\u7ea6\u675f\u4f1a\u5bfc\u81f4\u4e0d\u5b8c\u6574\u548c\u6a21\u7cca\u7684\u89c4\u8303\u3002", "method": "\u63d0\u51faSLD-Spec\u65b9\u6cd5\uff0c\u5305\u542b\u4e24\u4e2a\u65b0\u9636\u6bb5\uff1a(1)\u5207\u7247\u9636\u6bb5-\u5c06\u51fd\u6570\u5206\u89e3\u4e3a\u5305\u542b\u72ec\u7acb\u5faa\u73af\u7ed3\u6784\u7684\u4ee3\u7801\u7247\u6bb5\uff1b(2)\u903b\u8f91\u5220\u9664\u9636\u6bb5-\u4f7f\u7528LLM\u63a8\u7406\u8fc7\u6ee4\u9519\u8bef\u5019\u9009\u89c4\u8303\u3002", "result": "\u5728\u7b80\u5355\u6570\u636e\u96c6\u4e0a\u6bd4\u6700\u5148\u8fdb\u7684AutoSpec\u591a\u9a8c\u8bc15\u4e2a\u7a0b\u5e8f\uff0c\u8fd0\u884c\u65f6\u95f4\u51cf\u5c1123.73%\u3002\u5728\u590d\u6742\u5faa\u73af\u6570\u636e\u96c6\u4e0a\uff0c95.1%\u7684\u65ad\u8a00\u548c90.91%\u7684\u7a0b\u5e8f\u901a\u8fc7\u9a8c\u8bc1\u3002", "conclusion": "\u903b\u8f91\u5220\u9664\u5bf9\u63d0\u5347\u89c4\u8303\u6b63\u786e\u6027\u548c\u76f8\u5173\u6027\u81f3\u5173\u91cd\u8981\uff0c\u7a0b\u5e8f\u5207\u7247\u5bf9\u89c4\u8303\u5b8c\u6574\u6027\u8d21\u732e\u663e\u8457\uff0cSLD-Spec\u80fd\u6709\u6548\u5904\u7406\u590d\u6742\u5faa\u73af\u7a0b\u5e8f\u7684\u89c4\u8303\u751f\u6210\u95ee\u9898\u3002"}}
{"id": "2509.09751", "pdf": "https://arxiv.org/pdf/2509.09751", "abs": "https://arxiv.org/abs/2509.09751", "authors": ["Junqiao Wang", "Zhaoyang Guan", "Guanyu Liu", "Tianze Xia", "Xianzhi Li", "Shuo Yin", "Xinyuan Song", "Chuhan Cheng", "Tianyu Shi", "Alex Lee"], "title": "Meta-Learning Reinforcement Learning for Crypto-Return Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Predicting cryptocurrency returns is notoriously difficult: price movements\nare driven by a fast-shifting blend of on-chain activity, news flow, and social\nsentiment, while labeled training data are scarce and expensive. In this paper,\nwe present Meta-RL-Crypto, a unified transformer-based architecture that\nunifies meta-learning and reinforcement learning (RL) to create a fully\nself-improving trading agent. Starting from a vanilla instruction-tuned LLM,\nthe agent iteratively alternates between three roles-actor, judge, and\nmeta-judge-in a closed-loop architecture. This learning process requires no\nadditional human supervision. It can leverage multimodal market inputs and\ninternal preference feedback. The agent in the system continuously refines both\nthe trading policy and evaluation criteria. Experiments across diverse market\nregimes demonstrate that Meta-RL-Crypto shows good performance on the technical\nindicators of the real market and outperforming other LLM-based baselines.", "AI": {"tldr": "Meta-RL-Crypto\u662f\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u7edf\u4e00\u67b6\u6784\uff0c\u7ed3\u5408\u5143\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u521b\u5efa\u4e86\u4e00\u4e2a\u5b8c\u5168\u81ea\u6211\u6539\u8fdb\u7684\u52a0\u5bc6\u8d27\u5e01\u4ea4\u6613\u4ee3\u7406\uff0c\u65e0\u9700\u4eba\u5de5\u76d1\u7763\uff0c\u5728\u591a\u79cd\u5e02\u573a\u73af\u5883\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u9884\u6d4b\u52a0\u5bc6\u8d27\u5e01\u56de\u62a5\u6781\u5176\u56f0\u96be\uff0c\u4ef7\u683c\u53d8\u52a8\u7531\u5feb\u901f\u53d8\u5316\u7684\u94fe\u4e0a\u6d3b\u52a8\u3001\u65b0\u95fb\u6d41\u548c\u793e\u4ea4\u60c5\u7eea\u9a71\u52a8\uff0c\u4e14\u6807\u8bb0\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u6602\u8d35\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u81ea\u6211\u6539\u8fdb\u7684\u4ea4\u6613\u4ee3\u7406\u3002", "method": "\u4ece\u57fa\u7840\u6307\u4ee4\u8c03\u4f18\u7684LLM\u5f00\u59cb\uff0c\u4ee3\u7406\u5728\u95ed\u73af\u67b6\u6784\u4e2d\u8fed\u4ee3\u4ea4\u66ff\u626e\u6f14\u4e09\u4e2a\u89d2\u8272\uff08\u6267\u884c\u8005\u3001\u8bc4\u5224\u8005\u548c\u5143\u8bc4\u5224\u8005\uff09\uff0c\u5229\u7528\u591a\u6a21\u6001\u5e02\u573a\u8f93\u5165\u548c\u5185\u90e8\u504f\u597d\u53cd\u9988\uff0c\u6301\u7eed\u6539\u8fdb\u4ea4\u6613\u7b56\u7565\u548c\u8bc4\u4f30\u6807\u51c6\u3002", "result": "\u5728\u591a\u6837\u5316\u5e02\u573a\u73af\u5883\u4e0b\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMeta-RL-Crypto\u5728\u771f\u5b9e\u5e02\u573a\u7684\u6280\u672f\u6307\u6807\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5e76\u4e14\u4f18\u4e8e\u5176\u4ed6\u57fa\u4e8eLLM\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5143\u5b66\u4e60-\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u591f\u521b\u5efa\u5b8c\u5168\u81ea\u6211\u6539\u8fdb\u7684\u4ea4\u6613\u4ee3\u7406\uff0c\u5728\u52a0\u5bc6\u8d27\u5e01\u9884\u6d4b\u8fd9\u4e00\u56f0\u96be\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a\u81ea\u52a8\u5316\u4ea4\u6613\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2509.10097", "pdf": "https://arxiv.org/pdf/2509.10097", "abs": "https://arxiv.org/abs/2509.10097", "authors": ["Ahmed Al-Tahmeesschi", "Yi Chu", "Gurdeep Singh", "Charles Turyagyenda", "Dritan Kaleshi", "David Grace", "Hamed Ahmadi"], "title": "Maximising Energy Efficiency in Large-Scale Open RAN: Hybrid xApps and Digital Twin Integration", "categories": ["cs.NI", "eess.SP"], "comment": "Accepted in GLOBECOM WS 2025", "summary": "The growing demand for high-speed, ultra-reliable, and low-latency\ncommunications in 5G and beyond networks has significantly driven up power\nconsumption, particularly within the Radio Access Network (RAN). This surge in\nenergy demand poses critical operational and sustainability challenges for\nmobile network operators, necessitating innovative solutions that enhance\nenergy efficiency without compromising Quality of Service (QoS). Open Radio\nAccess Network (O-RAN), spearheaded by the O-RAN Alliance, offers\ndisaggregated, programmable, and intelligent architectures, promoting\nflexibility, interoperability, and cost-effectiveness. However, this\ndisaggregated approach adds complexity, particularly in managing power\nconsumption across diverse network components such as Open Radio Units (RUs).\nIn this paper, we propose a hybrid xApp leveraging heuristic methods and\nunsupervised machine learning, integrated with digital twin technology through\nthe TeraVM AI RAN Scenario Generator (AI-RSG). This approach dynamically\nmanages RU sleep modes to effectively reduce energy consumption. Our\nexperimental evaluation in a realistic, large-scale emulated Open RAN scenario\ndemonstrates that the hybrid xApp achieves approximately 13% energy savings,\nhighlighting its practicality and significant potential for real-world\ndeployments without compromising user QoS.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u7684\u6df7\u5408xApp\uff0c\u7ed3\u5408\u6570\u5b57\u5b6a\u751f\u6280\u672f\u52a8\u6001\u7ba1\u7406RU\u7761\u7720\u6a21\u5f0f\uff0c\u5728Open RAN\u4e2d\u5b9e\u73b0\u7ea613%\u7684\u8282\u80fd\u6548\u679c\u4e14\u4e0d\u5f71\u54cd\u670d\u52a1\u8d28\u91cf", "motivation": "5G\u53ca\u540e\u7eed\u7f51\u7edc\u7684\u9ad8\u901f\u3001\u8d85\u53ef\u9760\u3001\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u9700\u6c42\u5bfc\u81f4RAN\u529f\u8017\u5927\u5e45\u589e\u52a0\uff0c\u5e26\u6765\u8fd0\u8425\u548c\u53ef\u6301\u7eed\u6027\u6311\u6218\uff0c\u9700\u8981\u5728\u4e0d\u5f71\u54cdQoS\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u80fd\u6548", "method": "\u91c7\u7528\u6df7\u5408xApp\u7ed3\u5408\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\uff0c\u901a\u8fc7TeraVM AI RAN\u573a\u666f\u751f\u6210\u5668\u96c6\u6210\u6570\u5b57\u5b6a\u751f\u6280\u672f\uff0c\u52a8\u6001\u7ba1\u7406\u5f00\u653e\u65e0\u7ebf\u7535\u5355\u5143(RU)\u7684\u7761\u7720\u6a21\u5f0f", "result": "\u5728\u771f\u5b9e\u5927\u89c4\u6a21\u4eff\u771fOpen RAN\u573a\u666f\u4e2d\uff0c\u6df7\u5408xApp\u5b9e\u73b0\u4e86\u7ea613%\u7684\u8282\u80fd\u6548\u679c\uff0c\u8bc1\u660e\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u6f5c\u529b", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86O-RAN\u67b6\u6784\u4e2d\u529f\u8017\u7ba1\u7406\u7684\u590d\u6742\u6027\uff0c\u5c55\u793a\u4e86\u5728\u4e0d\u5f71\u54cd\u7528\u6237QoS\u7684\u524d\u63d0\u4e0b\u663e\u8457\u964d\u4f4e\u80fd\u8017\u7684\u53ef\u884c\u6027"}}
{"id": "2509.09918", "pdf": "https://arxiv.org/pdf/2509.09918", "abs": "https://arxiv.org/abs/2509.09918", "authors": ["Seyed Moein Abtahi", "Akramul Azim"], "title": "WALL: A Web Application for Automated Quality Assurance using Large Language Models", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "As software projects become increasingly complex, the volume and variety of\nissues in code files have grown substantially. Addressing this challenge\nrequires efficient issue detection, resolution, and evaluation tools. This\npaper presents WALL, a web application that integrates SonarQube and large\nlanguage models (LLMs) such as GPT-3.5 Turbo and GPT-4o to automate these\ntasks. WALL comprises three modules: an issue extraction tool, code issues\nreviser, and code comparison tool. Together, they enable a seamless pipeline\nfor detecting software issues, generating automated code revisions, and\nevaluating the accuracy of revisions. Our experiments, conducted on 563 files\nwith over 7,599 issues, demonstrate WALL's effectiveness in reducing human\neffort while maintaining high-quality revisions. Results show that employing a\nhybrid approach of cost-effective and advanced LLMs can significantly lower\ncosts and improve revision rates. Future work aims to enhance WALL's\ncapabilities by integrating open-source LLMs and eliminating human\nintervention, paving the way for fully automated code quality management.", "AI": {"tldr": "WALL\u662f\u4e00\u4e2a\u96c6\u6210SonarQube\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684Web\u5e94\u7528\uff0c\u901a\u8fc7\u4e09\u4e2a\u6a21\u5757\u81ea\u52a8\u5316\u4ee3\u7801\u95ee\u9898\u68c0\u6d4b\u3001\u4fee\u590d\u548c\u8bc4\u4f30\uff0c\u5728563\u4e2a\u6587\u4ef67599\u4e2a\u95ee\u9898\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u9879\u76ee\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u4ee3\u7801\u95ee\u9898\u6570\u91cf\u548c\u79cd\u7c7b\u5927\u5e45\u589e\u957f\uff0c\u9700\u8981\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u5de5\u5177\u6765\u68c0\u6d4b\u3001\u89e3\u51b3\u548c\u8bc4\u4f30\u4ee3\u7801\u95ee\u9898\u3002", "method": "\u5f00\u53d1WALL Web\u5e94\u7528\uff0c\u96c6\u6210SonarQube\u548cLLMs\uff08GPT-3.5 Turbo\u548cGPT-4o\uff09\uff0c\u5305\u542b\u95ee\u9898\u63d0\u53d6\u5de5\u5177\u3001\u4ee3\u7801\u95ee\u9898\u4fee\u8ba2\u5668\u548c\u4ee3\u7801\u6bd4\u8f83\u5de5\u5177\u4e09\u4e2a\u6a21\u5757\u3002", "result": "\u5728563\u4e2a\u6587\u4ef67599\u4e2a\u95ee\u9898\u4e0a\u5b9e\u9a8c\u8bc1\u660e\uff0cWALL\u80fd\u6709\u6548\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\u5e76\u4fdd\u6301\u9ad8\u8d28\u91cf\u4fee\u8ba2\uff0c\u6df7\u5408\u4f7f\u7528\u6210\u672c\u6548\u76ca\u578b\u548c\u5148\u8fdbLLMs\u53ef\u663e\u8457\u964d\u4f4e\u6210\u672c\u5e76\u63d0\u9ad8\u4fee\u8ba2\u7387\u3002", "conclusion": "WALL\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u4ee3\u7801\u8d28\u91cf\u7ba1\u7406\u7684\u53ef\u884c\u6027\uff0c\u672a\u6765\u5de5\u4f5c\u5c06\u96c6\u6210\u5f00\u6e90LLMs\u5e76\u6d88\u9664\u4eba\u5de5\u5e72\u9884\uff0c\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u4ee3\u7801\u8d28\u91cf\u7ba1\u7406\u3002"}}
{"id": "2509.09754", "pdf": "https://arxiv.org/pdf/2509.09754", "abs": "https://arxiv.org/abs/2509.09754", "authors": ["Yiqun Shen", "Song Yuan", "Zhengze Zhang", "Xiaoliang Wang", "Daxin Jiang", "Nguyen Cam-Tu"], "title": "LAVa: Layer-wise KV Cache Eviction with Dynamic Budget Allocation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "KV Cache is commonly used to accelerate LLM inference with long contexts, yet\nits high memory demand drives the need for cache compression. Existing\ncompression methods, however, are largely heuristic and lack dynamic budget\nallocation. To address this limitation, we introduce a unified framework for\ncache compression by minimizing information loss in Transformer residual\nstreams. Building on it, we analyze the layer attention output loss and derive\na new metric to compare cache entries across heads, enabling layer-wise\ncompression with dynamic head budgets. Additionally, by contrasting cross-layer\ninformation, we also achieve dynamic layer budgets. LAVa is the first unified\nstrategy for cache eviction and dynamic budget allocation that, unlike prior\nmethods, does not rely on training or the combination of multiple strategies.\nExperiments with benchmarks (LongBench, Needle-In-A-Haystack, Ruler, and\nInfiniteBench) demonstrate its superiority. Moreover, our experiments reveal a\nnew insight: dynamic layer budgets are crucial for generation tasks (e.g., code\ncompletion), while dynamic head budgets play a key role in extraction tasks\n(e.g., extractive QA). As a fully dynamic compression method, LAVa consistently\nmaintains top performance across task types. Our code is available at\nhttps://github.com/MGDDestiny/Lava.", "AI": {"tldr": "LAVa\u662f\u4e00\u4e2a\u7edf\u4e00\u7684KV\u7f13\u5b58\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u5316Transformer\u6b8b\u5dee\u6d41\u4fe1\u606f\u635f\u5931\u5b9e\u73b0\u52a8\u6001\u9884\u7b97\u5206\u914d\uff0c\u5728\u591a\u79cd\u957f\u6587\u672c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\u5927\u591a\u662f\u542f\u53d1\u5f0f\u7684\uff0c\u7f3a\u4e4f\u52a8\u6001\u9884\u7b97\u5206\u914d\u673a\u5236\uff0c\u65e0\u6cd5\u6839\u636e\u4efb\u52a1\u9700\u6c42\u4f18\u5316\u7f13\u5b58\u4f7f\u7528\u6548\u7387\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5c42\u6ce8\u610f\u529b\u8f93\u51fa\u635f\u5931\uff0c\u63d0\u51fa\u65b0\u7684\u5ea6\u91cf\u6807\u51c6\u6765\u6bd4\u8f83\u4e0d\u540c\u5934\u7684\u7f13\u5b58\u6761\u76ee\uff0c\u5b9e\u73b0\u5c42\u7ea7\u538b\u7f29\u548c\u52a8\u6001\u5934\u9884\u7b97\u5206\u914d\uff1b\u901a\u8fc7\u8de8\u5c42\u4fe1\u606f\u5bf9\u6bd4\u5b9e\u73b0\u52a8\u6001\u5c42\u9884\u7b97\u5206\u914d\u3002", "result": "\u5728LongBench\u3001Needle-In-A-Haystack\u3001Ruler\u548cInfiniteBench\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u65e0\u9700\u8bad\u7ec3\u6216\u591a\u7b56\u7565\u7ec4\u5408\u3002", "conclusion": "LAVa\u662f\u9996\u4e2a\u7edf\u4e00\u7684\u7f13\u5b58\u6dd8\u6c70\u548c\u52a8\u6001\u9884\u7b97\u5206\u914d\u7b56\u7565\uff0c\u52a8\u6001\u5c42\u9884\u7b97\u5bf9\u751f\u6210\u4efb\u52a1\u5173\u952e\uff0c\u52a8\u6001\u5934\u9884\u7b97\u5bf9\u62bd\u53d6\u4efb\u52a1\u91cd\u8981\uff0c\u5728\u5404\u79cd\u4efb\u52a1\u7c7b\u578b\u4e2d\u4fdd\u6301\u9876\u7ea7\u6027\u80fd\u3002"}}
{"id": "2509.09813", "pdf": "https://arxiv.org/pdf/2509.09813", "abs": "https://arxiv.org/abs/2509.09813", "authors": ["Amira Abbas", "Nunzia Cerrato", "Francisco Escudero Guti\u00e9rrez", "Dmitry Grinko", "Francesco Anna Mele", "Pulkit Sinha"], "title": "Nearly optimal algorithms to learn sparse quantum Hamiltonians in physically motivated distances", "categories": ["quant-ph", "cs.CC", "cs.DS"], "comment": "35 pages, 1 figure", "summary": "We study the problem of learning Hamiltonians $H$ that are $s$-sparse in the\nPauli basis, given access to their time evolution. Although Hamiltonian\nlearning has been extensively investigated, two issues recur in much of the\nexisting literature: the absence of matching lower bounds and the use of\nmathematically convenient but physically opaque error measures.\n  We address both challenges by introducing two physically motivated distances\nbetween Hamiltonians and designing a nearly optimal algorithm with respect to\none of these metrics. The first, time-constrained distance, quantifies\ndistinguishability through dynamical evolution up to a bounded time. The\nsecond, temperature-constrained distance, captures distinguishability through\nthermal states at bounded inverse temperatures.\n  We show that $s$-sparse Hamiltonians with bounded operator norm can be\nlearned in both distances with $O(s \\log(1/\\epsilon))$ experiments and\n$O(s^2/\\epsilon)$ evolution time. For the time-constrained distance, we further\nestablish lower bounds of $\\Omega((s/n)\\log(1/\\epsilon) + s)$ experiments and\n$\\Omega(\\sqrt{s}/\\epsilon)$ evolution time, demonstrating near-optimality in\nthe number of experiments.\n  As an intermediate result, we obtain an algorithm that learns every Pauli\ncoefficient of $s$-sparse Hamiltonians up to error $\\epsilon$ in\n$O(s\\log(1/\\epsilon))$ experiments and $O(s/\\epsilon)$ evolution time,\nimproving upon several recent results.\n  The source of this improvement is a new isolation technique, inspired by the\nValiant-Vazirani theorem (STOC'85), which shows that NP is as easy as detecting\nunique solutions. This isolation technique allows us to query the time\nevolution of a single Pauli coefficient of a sparse Hamiltonian--even when the\nPauli support of the Hamiltonian is unknown--ultimately enabling us to recover\nthe Pauli support itself.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u7269\u7406\u52a8\u673a\u7684\u8ddd\u79bb\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u8fd1\u4e4e\u6700\u4f18\u7684\u7b97\u6cd5\u6765\u5b66\u4e60s-\u7a00\u758f\u54c8\u5bc6\u987f\u91cf\uff0c\u5728\u5b9e\u9a8c\u6b21\u6570\u548c\u65f6\u95f4\u590d\u6742\u5ea6\u4e0a\u90fd\u6709\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u54c8\u5bc6\u987f\u91cf\u5b66\u4e60\u7814\u7a76\u4e2d\u7f3a\u4e4f\u5339\u914d\u4e0b\u754c\u548c\u4f7f\u7528\u6570\u5b66\u65b9\u4fbf\u4f46\u7269\u7406\u4e0d\u900f\u660e\u7684\u8bef\u5dee\u5ea6\u91cf\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u65f6\u95f4\u7ea6\u675f\u8ddd\u79bb\u548c\u6e29\u5ea6\u7ea6\u675f\u8ddd\u79bb\u4e24\u79cd\u7269\u7406\u8ddd\u79bb\u5ea6\u91cf\uff0c\u8bbe\u8ba1\u57fa\u4e8eValiant-Vazirani\u5b9a\u7406\u9694\u79bb\u6280\u672f\u7684\u65b0\u7b97\u6cd5\uff0c\u901a\u8fc7\u67e5\u8be2\u5355\u4e2a\u6ce1\u5229\u7cfb\u6570\u7684\u65f6\u95f4\u6f14\u5316\u6765\u6062\u590d\u54c8\u5bc6\u987f\u91cf\u7684\u6ce1\u5229\u652f\u6491\u3002", "result": "\u5b9e\u73b0\u4e86O(s log(1/\u03b5))\u6b21\u5b9e\u9a8c\u548cO(s\u00b2/\u03b5)\u6f14\u5316\u65f6\u95f4\u7684\u5b66\u4e60\u590d\u6742\u5ea6\uff0c\u5728\u65f6\u95f4\u7ea6\u675f\u8ddd\u79bb\u4e0b\u5efa\u7acb\u4e86\u03a9((s/n)log(1/\u03b5) + s)\u5b9e\u9a8c\u6b21\u6570\u548c\u03a9(\u221as/\u03b5)\u6f14\u5316\u65f6\u95f4\u7684\u4e0b\u754c\uff0c\u8bc1\u660e\u4e86\u5b9e\u9a8c\u6b21\u6570\u7684\u8fd1\u4e4e\u6700\u4f18\u6027\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684\u9694\u79bb\u6280\u672f\u663e\u8457\u6539\u8fdb\u4e86\u7a00\u758f\u54c8\u5bc6\u987f\u91cf\u5b66\u4e60\u6548\u7387\uff0c\u4e3a\u91cf\u5b50\u7cfb\u7edf\u8868\u5f81\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u7406\u8bba\u6846\u67b6\u548c\u7b97\u6cd5\u5de5\u5177\u3002"}}
{"id": "2509.09915", "pdf": "https://arxiv.org/pdf/2509.09915", "abs": "https://arxiv.org/abs/2509.09915", "authors": ["Woong Shin", "Renan Souza", "Daniel Rosendo", "Fr\u00e9d\u00e9ric Suter", "Feiyi Wang", "Prasanna Balaprakash", "Rafael Ferreira da Silva"], "title": "The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science", "categories": ["cs.AI", "cs.DC"], "comment": null, "summary": "Modern scientific discovery increasingly requires coordinating distributed\nfacilities and heterogeneous resources, forcing researchers to act as manual\nworkflow coordinators rather than scientists. Advances in AI leading to AI\nagents show exciting new opportunities that can accelerate scientific discovery\nby providing intelligence as a component in the ecosystem. However, it is\nunclear how this new capability would materialize and integrate in the real\nworld. To address this, we propose a conceptual framework where workflows\nevolve along two dimensions which are intelligence (from static to intelligent)\nand composition (from single to swarm) to chart an evolutionary path from\ncurrent workflow management systems to fully autonomous, distributed scientific\nlaboratories. With these trajectories in mind, we present an architectural\nblueprint that can help the community take the next steps towards harnessing\nthe opportunities in autonomous science with the potential for 100x discovery\nacceleration and transformational scientific workflows.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ece\u5f53\u524d\u5de5\u4f5c\u6d41\u7ba1\u7406\u7cfb\u7edf\u5411\u5b8c\u5168\u81ea\u4e3b\u3001\u5206\u5e03\u5f0f\u79d1\u5b66\u5b9e\u9a8c\u5ba4\u6f14\u5316\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u901a\u8fc7\u667a\u80fd\u5316\u548c\u7fa4\u4f53\u5316\u4e24\u4e2a\u7ef4\u5ea6\u6765\u52a0\u901f\u79d1\u5b66\u53d1\u73b0", "motivation": "\u73b0\u4ee3\u79d1\u5b66\u53d1\u73b0\u9700\u8981\u534f\u8c03\u5206\u5e03\u5f0f\u8bbe\u65bd\u548c\u5f02\u6784\u8d44\u6e90\uff0c\u7814\u7a76\u4eba\u5458\u88ab\u8feb\u6210\u4e3a\u624b\u52a8\u5de5\u4f5c\u6d41\u534f\u8c03\u5458\u800c\u975e\u79d1\u5b66\u5bb6\u3002AI\u667a\u80fd\u4f53\u6280\u672f\u4e3a\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u673a\u9047\uff0c\u4f46\u9700\u8981\u660e\u786e\u5982\u4f55\u5728\u5b9e\u9645\u4e2d\u5b9e\u73b0\u548c\u96c6\u6210", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6982\u5ff5\u6846\u67b6\uff0c\u5de5\u4f5c\u6d41\u6cbf\u7740\u4e24\u4e2a\u7ef4\u5ea6\u6f14\u5316\uff1a\u667a\u80fd\u5316\uff08\u4ece\u9759\u6001\u5230\u667a\u80fd\uff09\u548c\u7ec4\u5408\u5316\uff08\u4ece\u5355\u4e00\u5230\u7fa4\u4f53\uff09\uff0c\u5e76\u63d0\u4f9b\u4e86\u67b6\u6784\u84dd\u56fe", "result": "\u8be5\u6846\u67b6\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u5411\u81ea\u4e3b\u79d1\u5b66\u53d1\u5c55\u7684\u91cd\u8981\u6b65\u9aa4\uff0c\u6709\u671b\u5b9e\u73b0100\u500d\u7684\u79d1\u5b66\u53d1\u73b0\u52a0\u901f\u548c\u53d8\u9769\u6027\u79d1\u5b66\u5de5\u4f5c\u6d41", "conclusion": "\u901a\u8fc7\u667a\u80fd\u5316\u548c\u7fa4\u4f53\u5316\u7684\u6f14\u5316\u8def\u5f84\uff0c\u53ef\u4ee5\u6784\u5efa\u5b8c\u5168\u81ea\u4e3b\u7684\u5206\u5e03\u5f0f\u79d1\u5b66\u5b9e\u9a8c\u5ba4\uff0c\u663e\u8457\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u8fdb\u7a0b\uff0c\u6539\u53d8\u79d1\u7814\u5de5\u4f5c\u65b9\u5f0f"}}
{"id": "2509.10173", "pdf": "https://arxiv.org/pdf/2509.10173", "abs": "https://arxiv.org/abs/2509.10173", "authors": ["Lyubomir Yanev", "Pietro Ronchetti", "Joshua Smailes", "Martin Strohmeier"], "title": "Secure and Scalable Rerouting in LEO Satellite Networks", "categories": ["cs.NI"], "comment": null, "summary": "Resilient routing in large-scale Low Earth Orbit (LEO) satellite networks\nremains a key challenge due to frequent and unpredictable link and node\nfailures, potentially in response to cybersecurity breaches. While prior work\nhas explored rerouting strategies with various levels of network awareness,\ntheir relative tradeoffs under dynamic failure conditions remain underexplored.\nIn this work, we extend the Deep Space Network Simulator (DSNS) to\nsystematically compare three rerouting paradigms, each differing in the scope\nof failure knowledge available to each node. We compare local neighbor-based,\nsegment-based and global-knowledge-based rerouting as well as a naive source\nrouting solution that is unaware of failures. Our main goal is to evaluate how\nthe breadth of failure awareness impacts routing performance and resilience\nunder failures, both random and targeted. We measure delivery ratio, latency,\nrerouting overhead, and loop occurrence. Our findings show the potential of\nsegment-based rerouting to achieve a favorable tradeoff between local\nresponsiveness and global coordination, offering resilience benefits with\nminimal overhead--insights that can inform future fault-tolerant satellite\nnetwork design.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86LEO\u536b\u661f\u7f51\u7edc\u4e2d\u4e09\u79cd\u91cd\u8def\u7531\u7b56\u7565\uff08\u672c\u5730\u90bb\u5c45\u3001\u5206\u6bb5\u548c\u5168\u5c40\u77e5\u8bc6\uff09\u5728\u52a8\u6001\u6545\u969c\u4e0b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u53d1\u73b0\u5206\u6bb5\u91cd\u8def\u7531\u5728\u54cd\u5e94\u6027\u548c\u534f\u8c03\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u6700\u4f73\u5e73\u8861\u3002", "motivation": "LEO\u536b\u661f\u7f51\u7edc\u9762\u4e34\u9891\u7e41\u4e0d\u53ef\u9884\u6d4b\u7684\u94fe\u8def\u548c\u8282\u70b9\u6545\u969c\uff0c\u73b0\u6709\u91cd\u8def\u7531\u7b56\u7565\u5728\u4e0d\u540c\u7f51\u7edc\u611f\u77e5\u7a0b\u5ea6\u4e0b\u7684\u6027\u80fd\u6743\u8861\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u6269\u5c55Deep Space Network Simulator\uff0c\u6bd4\u8f83\u672c\u5730\u90bb\u5c45\u3001\u5206\u6bb5\u548c\u5168\u5c40\u77e5\u8bc6\u4e09\u79cd\u91cd\u8def\u7531\u8303\u5f0f\uff0c\u4ee5\u53ca\u65e0\u6545\u969c\u611f\u77e5\u7684\u6e90\u8def\u7531\u65b9\u6848\uff0c\u8bc4\u4f30\u968f\u673a\u548c\u5b9a\u5411\u6545\u969c\u4e0b\u7684\u6027\u80fd\u6307\u6807\u3002", "result": "\u5206\u6bb5\u91cd\u8def\u7531\u5728\u672c\u5730\u54cd\u5e94\u6027\u548c\u5168\u5c40\u534f\u8c03\u6027\u4e4b\u95f4\u5b9e\u73b0\u4e86\u6709\u5229\u7684\u6743\u8861\uff0c\u4ee5\u6700\u5c0f\u5f00\u9500\u63d0\u4f9b\u5f39\u6027\u4f18\u52bf\u3002", "conclusion": "\u5206\u6bb5\u91cd\u8def\u7531\u7b56\u7565\u4e3a\u672a\u6765\u5bb9\u9519\u536b\u661f\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u80fd\u591f\u5728\u6545\u969c\u6761\u4ef6\u4e0b\u5b9e\u73b0\u826f\u597d\u7684\u8def\u7531\u6027\u80fd\u548c\u5f39\u6027\u3002"}}
{"id": "2509.09947", "pdf": "https://arxiv.org/pdf/2509.09947", "abs": "https://arxiv.org/abs/2509.09947", "authors": ["Humza Ashraf", "Syed Muhammad Danish", "Zeeshan Sattar"], "title": "Toward Green Code: Prompting Small Language Models for Energy-Efficient Code Generation", "categories": ["cs.SE"], "comment": null, "summary": "There is a growing concern about the environmental impact of large language\nmodels (LLMs) in software development, particularly due to their high energy\nuse and carbon footprint. Small Language Models (SLMs) offer a more sustainable\nalternative, requiring fewer computational resources while remaining effective\nfor fundamental programming tasks. In this study, we investigate whether prompt\nengineering can improve the energy efficiency of SLMs in code generation. We\nevaluate four open-source SLMs, StableCode-Instruct-3B,\nQwen2.5-Coder-3B-Instruct, CodeLlama-7B-Instruct, and Phi-3-Mini-4K-Instruct,\nacross 150 Python problems from LeetCode, evenly distributed into easy, medium,\nand hard categories. Each model is tested under four prompting strategies: role\nprompting, zero-shot, few-shot, and chain-of-thought (CoT). For every generated\nsolution, we measure runtime, memory usage, and energy consumption, comparing\nthe results with a human-written baseline. Our findings show that CoT prompting\nprovides consistent energy savings for Qwen2.5-Coder and StableCode-3B, while\nCodeLlama-7B and Phi-3-Mini-4K fail to outperform the baseline under any\nprompting strategy. These results highlight that the benefits of prompting are\nmodel-dependent and that carefully designed prompts can guide SLMs toward\ngreener software development.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u63d0\u793a\u5de5\u7a0b\u53ef\u4ee5\u63d0\u5347\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u80fd\u6548\uff0c\u5176\u4e2dCoT\u63d0\u793a\u5bf9Qwen2.5-Coder\u548cStableCode-3B\u6a21\u578b\u6548\u679c\u663e\u8457\uff0c\u4f46\u6548\u679c\u5177\u6709\u6a21\u578b\u4f9d\u8d56\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u9ad8\u80fd\u8017\u548c\u78b3\u8db3\u8ff9\u95ee\u9898\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\uff0c\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u66f4\u53ef\u6301\u7eed\u7684\u66ff\u4ee3\u65b9\u6848\u9700\u8981\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u63d0\u9ad8\u5176\u80fd\u6548\u3002", "method": "\u8bc4\u4f304\u4e2a\u5f00\u6e90SLM\u6a21\u578b\u5728150\u4e2aLeetCode Python\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u6d4b\u8bd54\u79cd\u63d0\u793a\u7b56\u7565\uff08\u89d2\u8272\u63d0\u793a\u3001\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u3001\u601d\u7ef4\u94fe\uff09\uff0c\u6d4b\u91cf\u8fd0\u884c\u65f6\u3001\u5185\u5b58\u4f7f\u7528\u548c\u80fd\u8017\uff0c\u5e76\u4e0e\u4eba\u5de5\u7f16\u5199\u57fa\u51c6\u5bf9\u6bd4\u3002", "result": "CoT\u63d0\u793a\u4e3aQwen2.5-Coder\u548cStableCode-3B\u5e26\u6765\u6301\u7eed\u8282\u80fd\u6548\u679c\uff0c\u4f46CodeLlama-7B\u548cPhi-3-Mini-4K\u5728\u6240\u6709\u63d0\u793a\u7b56\u7565\u4e0b\u5747\u672a\u80fd\u8d85\u8d8a\u57fa\u51c6\u3002", "conclusion": "\u63d0\u793a\u5de5\u7a0b\u7684\u6548\u76ca\u5177\u6709\u6a21\u578b\u4f9d\u8d56\u6027\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u53ef\u4ee5\u5f15\u5bfcSLM\u5b9e\u73b0\u66f4\u73af\u4fdd\u7684\u8f6f\u4ef6\u5f00\u53d1\u3002"}}
{"id": "2509.09772", "pdf": "https://arxiv.org/pdf/2509.09772", "abs": "https://arxiv.org/abs/2509.09772", "authors": ["Sanjay Basu", "Sadiq Y. Patel", "Parth Sheth", "Bhairavi Muralidharan", "Namrata Elamaran", "Aakriti Kinra", "Rajaie Batniji"], "title": "Hybrid Adaptive Conformal Offline Reinforcement Learning for Fair Population Health Management", "categories": ["cs.LG", "stat.AP"], "comment": "10 pages, 5 figures, 4 tables", "summary": "Population health management programs for Medicaid populations coordinate\nlongitudinal outreach and services (e.g., benefits navigation, behavioral\nhealth, social needs support, and clinical scheduling) and must be safe, fair,\nand auditable. We present a Hybrid Adaptive Conformal Offline Reinforcement\nLearning (HACO) framework that separates risk calibration from preference\noptimization to generate conservative action recommendations at scale. In our\nsetting, each step involves choosing among common coordination actions (e.g.,\nwhich member to contact, by which modality, and whether to route to a\nspecialized service) while controlling the near-term risk of adverse\nutilization events (e.g., unplanned emergency department visits or\nhospitalizations). Using a de-identified operational dataset from Waymark\ncomprising 2.77 million sequential decisions across 168,126 patients, HACO (i)\ntrains a lightweight risk model for adverse events, (ii) derives a conformal\nthreshold to mask unsafe actions at a target risk level, and (iii) learns a\npreference policy on the resulting safe subset. We evaluate policies with a\nversion-agnostic fitted Q evaluation (FQE) on stratified subsets and audit\nsubgroup performance across age, sex, and race. HACO achieves strong risk\ndiscrimination (AUC ~0.81) with a calibrated threshold ( {\\tau} ~0.038 at\n{\\alpha} = 0.10), while maintaining high safe coverage. Subgroup analyses\nreveal systematic differences in estimated value across demographics,\nunderscoring the importance of fairness auditing. Our results show that\nconformal risk gating integrates cleanly with offline RL to deliver\nconservative, auditable decision support for population health management\nteams.", "AI": {"tldr": "\u63d0\u51faHACO\u6846\u67b6\uff0c\u7ed3\u5408\u98ce\u9669\u6821\u51c6\u548c\u504f\u597d\u4f18\u5316\uff0c\u4e3a\u533b\u7597\u8865\u52a9\u4eba\u7fa4\u63d0\u4f9b\u5b89\u5168\u3001\u516c\u5e73\u3001\u53ef\u5ba1\u8ba1\u7684\u51b3\u7b56\u652f\u6301\uff0c\u5728270\u4e07\u6b21\u51b3\u7b56\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u98ce\u9669\u63a7\u5236\u548c\u516c\u5e73\u6027", "motivation": "\u533b\u7597\u8865\u52a9\u4eba\u7fa4\u7684\u5065\u5eb7\u7ba1\u7406\u9879\u76ee\u9700\u8981\u534f\u8c03\u7eb5\u5411\u670d\u52a1\uff0c\u5fc5\u987b\u786e\u4fdd\u5b89\u5168\u3001\u516c\u5e73\u548c\u53ef\u5ba1\u8ba1\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u63a7\u5236\u4e0d\u826f\u4e8b\u4ef6\u98ce\u9669\u5e76\u63d0\u4f9b\u4fdd\u5b88\u884c\u52a8\u5efa\u8bae\u7684\u6846\u67b6", "method": "\u6df7\u5408\u81ea\u9002\u5e94\u7b26\u5408\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60(HACO)\u6846\u67b6\uff1a1)\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u98ce\u9669\u6a21\u578b\u9884\u6d4b\u4e0d\u826f\u4e8b\u4ef6\uff1b2)\u63a8\u5bfc\u7b26\u5408\u9608\u503c\u4ee5\u5c4f\u853d\u4e0d\u5b89\u5168\u884c\u52a8\uff1b3)\u5728\u5b89\u5168\u5b50\u96c6\u4e0a\u5b66\u4e60\u504f\u597d\u7b56\u7565\u3002\u4f7f\u7528\u7248\u672c\u65e0\u5173\u7684FQE\u8bc4\u4f30\u548c\u4e9a\u7ec4\u5ba1\u8ba1", "result": "HACO\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u98ce\u9669\u533a\u5206\u80fd\u529b(AUC\u7ea60.81)\uff0c\u6821\u51c6\u9608\u503c\u5728\u03b1=0.10\u65f6\u4e3a\u03c4\u22480.038\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u5b89\u5168\u8986\u76d6\u7387\u3002\u4e9a\u7ec4\u5206\u6790\u663e\u793a\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u4ef7\u503c\u5dee\u5f02", "conclusion": "\u7b26\u5408\u98ce\u9669\u95e8\u63a7\u4e0e\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u826f\u597d\uff0c\u80fd\u591f\u4e3a\u4eba\u7fa4\u5065\u5eb7\u7ba1\u7406\u56e2\u961f\u63d0\u4f9b\u4fdd\u5b88\u3001\u53ef\u5ba1\u8ba1\u7684\u51b3\u7b56\u652f\u6301\uff0c\u5f3a\u8c03\u4e86\u516c\u5e73\u6027\u5ba1\u8ba1\u7684\u91cd\u8981\u6027"}}
{"id": "2509.09904", "pdf": "https://arxiv.org/pdf/2509.09904", "abs": "https://arxiv.org/abs/2509.09904", "authors": ["Zhangsong Li"], "title": "A Smooth Computational Transition in Tensor PCA", "categories": ["math.ST", "cs.DS", "math.PR", "stat.ML", "stat.TH", "68Q87, 90C35"], "comment": "49 pages, 2 figures", "summary": "We propose an efficient algorithm for tensor PCA based on counting a specific\nfamily of weighted hypergraphs. For the order-$p$ tensor PCA problem where $p\n\\geq 3$ is a fixed integer, we show that when the signal-to-noise ratio is\n$\\lambda n^{-\\frac{p}{4}}$ where $\\lambda=\\Omega(1)$, our algorithm succeeds\nand runs in time $n^{C+o(1)}$ where $C=C(\\lambda)$ is a constant depending on\n$\\lambda$. This algorithm improves a poly-logarithmic factor compared to\nprevious algorithms based on the Sum-of-Squares hierarchy \\cite{HSS15} or based\non the Kikuchi hierarchy in statistical physics \\cite{WEM19}. Furthermore, our\nresult shows a smooth tradeoff between the signal-to-noise ratio and the\ncomputational cost in this problem, thereby confirming a conjecture posed in\n\\cite{KWB22}.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a0\u6743\u8d85\u56fe\u8ba1\u6570\u7684\u9ad8\u6548\u5f20\u91cfPCA\u7b97\u6cd5\uff0c\u5728\u56fa\u5b9a\u9636\u6570p\u22653\u65f6\uff0c\u5f53\u4fe1\u566a\u6bd4\u4e3a\u03bbn^{-p/4}\u4e14\u03bb=\u03a9(1)\u65f6\uff0c\u7b97\u6cd5\u6210\u529f\u8fd0\u884c\u4e14\u65f6\u95f4\u590d\u6742\u5ea6\u4e3an^{C+o(1)}\uff0c\u5176\u4e2dC\u662f\u4f9d\u8d56\u4e8e\u03bb\u7684\u5e38\u6570\u3002", "motivation": "\u6539\u8fdb\u73b0\u6709\u7684\u5f20\u91cfPCA\u7b97\u6cd5\u6027\u80fd\uff0c\u89e3\u51b3Sum-of-Squares\u5c42\u6b21\u548cKikuchi\u5c42\u6b21\u65b9\u6cd5\u5b58\u5728\u7684\u591a\u5bf9\u6570\u56e0\u5b50\u5f00\u9500\u95ee\u9898\uff0c\u9a8c\u8bc1\u5173\u4e8e\u4fe1\u566a\u6bd4\u4e0e\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u5e73\u6ed1\u6743\u8861\u7684\u731c\u60f3\u3002", "method": "\u57fa\u4e8e\u7279\u5b9a\u52a0\u6743\u8d85\u56fe\u65cf\u7684\u8ba1\u6570\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u8d85\u56fe\u7ed3\u6784\u6765\u8bbe\u8ba1\u9ad8\u6548\u7684\u5f20\u91cf\u4e3b\u6210\u5206\u5206\u6790\u7b97\u6cd5\u3002", "result": "\u7b97\u6cd5\u5728\u4fe1\u566a\u6bd4\u03bbn^{-p/4}\u6761\u4ef6\u4e0b\u6210\u529f\u8fd0\u884c\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u4e3an^{C+o(1)}\uff0c\u76f8\u6bd4\u5148\u524d\u65b9\u6cd5\u6539\u8fdb\u4e86\u591a\u5bf9\u6570\u56e0\u5b50\uff0c\u5e76\u8bc1\u5b9e\u4e86\u4fe1\u566a\u6bd4\u4e0e\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u7684\u5e73\u6ed1\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u63d0\u51fa\u7684\u52a0\u6743\u8d85\u56fe\u8ba1\u6570\u65b9\u6cd5\u4e3a\u5f20\u91cfPCA\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9a8c\u8bc1\u4e86\u7406\u8bba\u731c\u60f3\uff0c\u5c55\u793a\u4e86\u7b97\u6cd5\u6027\u80fd\u4e0e\u4fe1\u566a\u6bd4\u53c2\u6570\u4e4b\u95f4\u7684\u5b9a\u91cf\u5173\u7cfb\u3002"}}
{"id": "2509.10161", "pdf": "https://arxiv.org/pdf/2509.10161", "abs": "https://arxiv.org/abs/2509.10161", "authors": ["Shiwei Li", "Qunwei Li", "Haozhao Wang", "Ruixuan Li", "Jianbin Lin", "Wenliang Zhong"], "title": "FedBiF: Communication-Efficient Federated Learning via Bits Freezing", "categories": ["cs.LG", "cs.DC"], "comment": "Accepted by TPDS", "summary": "Federated learning (FL) is an emerging distributed machine learning paradigm\nthat enables collaborative model training without sharing local data. Despite\nits advantages, FL suffers from substantial communication overhead, which can\naffect training efficiency. Recent efforts have mitigated this issue by\nquantizing model updates to reduce communication costs. However, most existing\nmethods apply quantization only after local training, introducing quantization\nerrors into the trained parameters and potentially degrading model accuracy. In\nthis paper, we propose Federated Bit Freezing (FedBiF), a novel FL framework\nthat directly learns quantized model parameters during local training. In each\ncommunication round, the server first quantizes the model parameters and\ntransmits them to the clients. FedBiF then allows each client to update only a\nsingle bit of the multi-bit parameter representation, freezing the remaining\nbits. This bit-by-bit update strategy reduces each parameter update to one bit\nwhile maintaining high precision in parameter representation. Extensive\nexperiments are conducted on five widely used datasets under both IID and\nNon-IID settings. The results demonstrate that FedBiF not only achieves\nsuperior communication compression but also promotes sparsity in the resulting\nmodels. Notably, FedBiF attains accuracy comparable to FedAvg, even when using\nonly 1 bit-per-parameter (bpp) for uplink and 3 bpp for downlink communication.\nThe code is available at https://github.com/Leopold1423/fedbif-tpds25.", "AI": {"tldr": "FedBiF\u662f\u4e00\u79cd\u65b0\u9896\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u672c\u5730\u8bad\u7ec3\u671f\u95f4\u76f4\u63a5\u5b66\u4e60\u91cf\u5316\u6a21\u578b\u53c2\u6570\uff0c\u9010\u6bd4\u7279\u66f4\u65b0\u53c2\u6570\u6765\u5927\u5e45\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u7136\u80fd\u4fdd\u62a4\u6570\u636e\u9690\u79c1\uff0c\u4f46\u5b58\u5728\u663e\u8457\u7684\u901a\u4fe1\u5f00\u9500\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5728\u672c\u5730\u8bad\u7ec3\u540e\u8fdb\u884c\u91cf\u5316\uff0c\u8fd9\u4f1a\u5c06\u91cf\u5316\u8bef\u5dee\u5f15\u5165\u8bad\u7ec3\u53c2\u6570\u5e76\u53ef\u80fd\u964d\u4f4e\u6a21\u578b\u7cbe\u5ea6\u3002", "method": "\u63d0\u51faFederated Bit Freezing (FedBiF)\u6846\u67b6\uff1a\u670d\u52a1\u5668\u5148\u91cf\u5316\u6a21\u578b\u53c2\u6570\u5e76\u4f20\u8f93\u7ed9\u5ba2\u6237\u7aef\uff1b\u6bcf\u4e2a\u5ba2\u6237\u7aef\u6bcf\u6b21\u53ea\u66f4\u65b0\u591a\u6bd4\u7279\u53c2\u6570\u8868\u793a\u4e2d\u7684\u5355\u4e2a\u6bd4\u7279\uff0c\u51bb\u7ed3\u5176\u4f59\u6bd4\u7279\uff1b\u8fd9\u79cd\u9010\u6bd4\u7279\u66f4\u65b0\u7b56\u7565\u5c06\u6bcf\u4e2a\u53c2\u6570\u66f4\u65b0\u51cf\u5c11\u52301\u6bd4\u7279\u3002", "result": "\u57285\u4e2a\u5e38\u7528\u6570\u636e\u96c6\u4e0a\u7684IID\u548c\u975eIID\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u5b9e\u9a8c\uff0cFedBiF\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u901a\u4fe1\u538b\u7f29\uff0c\u8fd8\u4fc3\u8fdb\u4e86\u6a21\u578b\u7684\u7a00\u758f\u6027\u3002\u5728\u4f7f\u7528\u4ec51bpp\u4e0a\u884c\u548c3bpp\u4e0b\u884c\u901a\u4fe1\u65f6\uff0c\u4ecd\u80fd\u8fbe\u5230\u4e0eFedAvg\u76f8\u5f53\u7684\u7cbe\u5ea6\u3002", "conclusion": "FedBiF\u901a\u8fc7\u76f4\u63a5\u5728\u672c\u5730\u8bad\u7ec3\u671f\u95f4\u5b66\u4e60\u91cf\u5316\u53c2\u6570\u548c\u9010\u6bd4\u7279\u66f4\u65b0\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u7684\u901a\u4fe1\u5f00\u9500\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u901a\u4fe1\u538b\u7f29\u3002"}}
{"id": "2509.10214", "pdf": "https://arxiv.org/pdf/2509.10214", "abs": "https://arxiv.org/abs/2509.10214", "authors": ["Yannik Kopyciok", "Stefan Schmid", "Friedhelm Victor"], "title": "Friend or Foe? Identifying Anomalous Peers in Moneros P2P Network", "categories": ["cs.NI"], "comment": null, "summary": "Monero, the leading privacy-focused cryptocurrency, relies on a peer-to-peer\n(P2P) network to propagate transactions and blocks. Growing evidence suggests\nthat non-standard nodes exist in the network, posing as honest nodes but are\nperhaps intended for monitoring the network and spying on other nodes. However,\nour understanding of the detection and analysis of anomalous peer behavior\nremains limited. This paper presents a first comprehensive study of anomalous\nbehavior in Monero's P2P network. To this end, we collected and analyzed over\n240 hours of network traffic captured from five distinct vantage points\nworldwide. We further present a formal framework which allows us to\nanalytically define and classify anomalous patterns in P2P cryptocurrency\nnetworks. Our detection methodology, implemented as an offline analysis,\nprovides a foundation for real-time monitoring systems. Our analysis reveals\nthe presence of non-standard peers in the network where approximately 14.74%\n(13.19%) of (reachable) peers in the network exhibit non-standard behavior.\nThese peers exhibit distinct behavioral patterns that might suggest multiple\nconcurrent attacks, pointing to substantial shortcomings in Monero's privacy\nguarantees and network decentralization. To support reproducibility and enable\nnetwork operators to protect themselves, we release our examination pipeline to\nidentify and block suspicious peers based on newly captured network traffic.", "AI": {"tldr": "\u5bf9Monero P2P\u7f51\u7edc\u4e2d\u5f02\u5e38\u8282\u70b9\u884c\u4e3a\u7684\u9996\u6b21\u5168\u9762\u7814\u7a76\uff0c\u53d1\u73b0\u7ea614.74%\u7684\u8282\u70b9\u8868\u73b0\u51fa\u975e\u6807\u51c6\u884c\u4e3a\uff0c\u53ef\u80fd\u5a01\u80c1\u9690\u79c1\u4fdd\u62a4\u548c\u7f51\u7edc\u53bb\u4e2d\u5fc3\u5316", "motivation": "Monero\u4f5c\u4e3a\u9886\u5148\u7684\u9690\u79c1\u52a0\u5bc6\u8d27\u5e01\uff0c\u5176P2P\u7f51\u7edc\u4e2d\u5b58\u5728\u4f2a\u88c5\u6210\u8bda\u5b9e\u8282\u70b9\u7684\u975e\u6807\u51c6\u8282\u70b9\uff0c\u53ef\u80fd\u7528\u4e8e\u7f51\u7edc\u76d1\u63a7\u548c\u95f4\u8c0d\u6d3b\u52a8\uff0c\u4f46\u76ee\u524d\u5bf9\u5f02\u5e38\u8282\u70b9\u884c\u4e3a\u7684\u68c0\u6d4b\u548c\u5206\u6790\u7406\u89e3\u6709\u9650", "method": "\u4ece\u5168\u74035\u4e2a\u4e0d\u540c\u89c2\u6d4b\u70b9\u6536\u96c6\u8d85\u8fc7240\u5c0f\u65f6\u7684\u7f51\u7edc\u6d41\u91cf\u6570\u636e\uff0c\u5efa\u7acb\u5f62\u5f0f\u5316\u6846\u67b6\u6765\u5206\u6790\u548c\u5206\u7c7bP2P\u52a0\u5bc6\u8d27\u5e01\u7f51\u7edc\u4e2d\u7684\u5f02\u5e38\u6a21\u5f0f\uff0c\u5b9e\u73b0\u79bb\u7ebf\u5206\u6790\u68c0\u6d4b\u65b9\u6cd5", "result": "\u53d1\u73b0\u7f51\u7edc\u4e2d\u7ea614.74%\uff08\u53ef\u8fbe\u8282\u70b9\u4e2d13.19%\uff09\u7684\u8282\u70b9\u8868\u73b0\u51fa\u975e\u6807\u51c6\u884c\u4e3a\uff0c\u8fd9\u4e9b\u8282\u70b9\u663e\u793a\u51fa\u53ef\u80fd\u8868\u660e\u591a\u79cd\u5e76\u53d1\u653b\u51fb\u7684\u72ec\u7279\u884c\u4e3a\u6a21\u5f0f\uff0c\u63ed\u793a\u4e86Monero\u9690\u79c1\u4fdd\u8bc1\u548c\u7f51\u7edc\u53bb\u4e2d\u5fc3\u5316\u7684\u91cd\u5927\u7f3a\u9677", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86Monero\u7f51\u7edc\u4e2d\u5b58\u5728\u7684\u4e25\u91cd\u5b89\u5168\u95ee\u9898\uff0c\u53d1\u5e03\u4e86\u68c0\u6d4b\u7ba1\u9053\u4ee5\u5e2e\u52a9\u7f51\u7edc\u8fd0\u8425\u5546\u8bc6\u522b\u548c\u963b\u6b62\u53ef\u7591\u8282\u70b9\uff0c\u4e3a\u5b9e\u65f6\u76d1\u63a7\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840"}}
{"id": "2509.09975", "pdf": "https://arxiv.org/pdf/2509.09975", "abs": "https://arxiv.org/abs/2509.09975", "authors": ["Takasaburo Fukuda", "Takao Nakagawa", "Keisuke Miyazaki", "Susumu Tokumoto"], "title": "Development of Automated Software Design Document Review Methods Using Large Language Models", "categories": ["cs.SE"], "comment": "SANER 2025", "summary": "In this study, we explored an approach to automate the review process of\nsoftware design documents by using LLM. We first analyzed the review methods of\ndesign documents and organized 11 review perspectives. Additionally, we\nanalyzed the issues of utilizing LLMs for these 11 review perspectives and\ndetermined which perspectives can be reviewed by current general-purpose LLMs\ninstead of humans. For the reviewable perspectives, we specifically developed\nnew techniques to enable LLMs to comprehend complex design documents that\ninclude table data. For evaluation, we conducted experiments using GPT to\nassess the consistency of design items and descriptions across different design\ndocuments in the design process used in actual business operations. Our results\nconfirmed that LLMs can be utilized to identify inconsistencies in software\ndesign documents during the review process.", "AI": {"tldr": "\u4f7f\u7528LLM\u81ea\u52a8\u5316\u8f6f\u4ef6\u8bbe\u8ba1\u6587\u6863\u8bc4\u5ba1\u8fc7\u7a0b\u7684\u7814\u7a76\uff0c\u901a\u8fc7\u5206\u679011\u4e2a\u8bc4\u5ba1\u89c6\u89d2\u5e76\u5f00\u53d1\u65b0\u6280\u672f\uff0c\u9a8c\u8bc1\u4e86LLM\u80fd\u591f\u8bc6\u522b\u8bbe\u8ba1\u6587\u6863\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898", "motivation": "\u63a2\u7d22\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u81ea\u52a8\u5316\u8f6f\u4ef6\u8bbe\u8ba1\u6587\u6863\u8bc4\u5ba1\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u8bc4\u5ba1\u6548\u7387\u548c\u51c6\u786e\u6027", "method": "\u5206\u6790\u8bbe\u8ba1\u6587\u6863\u8bc4\u5ba1\u65b9\u6cd5\u5e76\u7ec4\u7ec711\u4e2a\u8bc4\u5ba1\u89c6\u89d2\uff0c\u5f00\u53d1\u65b0\u6280\u672f\u4f7fLLM\u80fd\u591f\u7406\u89e3\u5305\u542b\u8868\u683c\u6570\u636e\u7684\u590d\u6742\u8bbe\u8ba1\u6587\u6863\uff0c\u4f7f\u7528GPT\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u8bbe\u8ba1\u9879\u548c\u63cf\u8ff0\u5728\u4e0d\u540c\u8bbe\u8ba1\u6587\u6863\u4e2d\u7684\u4e00\u81f4\u6027", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eLLM\u80fd\u591f\u5728\u8bc4\u5ba1\u8fc7\u7a0b\u4e2d\u6709\u6548\u8bc6\u522b\u8f6f\u4ef6\u8bbe\u8ba1\u6587\u6863\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898", "conclusion": "LLM\u53ef\u4ee5\u66ff\u4ee3\u4eba\u7c7b\u5b8c\u6210\u8f6f\u4ef6\u8bbe\u8ba1\u6587\u6863\u7684\u67d0\u4e9b\u8bc4\u5ba1\u4efb\u52a1\uff0c\u7279\u522b\u662f\u5728\u8bc6\u522b\u8bbe\u8ba1\u4e0d\u4e00\u81f4\u6027\u65b9\u9762\u5177\u6709\u5b9e\u7528\u4ef7\u503c"}}
{"id": "2509.09782", "pdf": "https://arxiv.org/pdf/2509.09782", "abs": "https://arxiv.org/abs/2509.09782", "authors": ["Roshini Pulishetty", "Mani Kishan Ghantasala", "Keerthy Kaushik Dasoju", "Niti Mangwani", "Vishal Garimella", "Aditya Mate", "Somya Chatterjee", "Yue Kang", "Ehi Nosakhare", "Sadid Hasan", "Soundar Srinivasan"], "title": "One Head, Many Models: Cross-Attention Routing for Cost-Aware LLM Selection", "categories": ["cs.LG"], "comment": null, "summary": "The proliferation of large language models (LLMs) with varying computational\ncosts and performance profiles presents a critical challenge for scalable,\ncost-effective deployment in real-world applications. We introduce a unified\nrouting framework that leverages a single-head cross-attention mechanism to\njointly model query and model embeddings, enabling dynamic selection of the\noptimal LLM for each input query. Our approach is evaluated on RouterBench, a\nlarge-scale, publicly available benchmark encompassing diverse LLM pools and\ndomains. By explicitly capturing fine-grained query-model interactions, our\nrouter predicts both response quality and generation cost, achieving up to 6.6%\nimprovement in Average Improvement in Quality (AIQ) and 2.9% in maximum\nperformance over existing routers. To robustly balance performance and cost, we\npropose an exponential reward function that enhances stability across user\npreferences. The resulting architecture is lightweight, generalizes effectively\nacross domains, and demonstrates improved efficiency compared to prior methods,\nestablishing a new standard for cost-aware LLM routing.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5355\u5934\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u7684\u7edf\u4e00\u8def\u7531\u6846\u67b6\uff0c\u52a8\u6001\u9009\u62e9\u6700\u4f18LLM\uff0c\u5728RouterBench\u57fa\u51c6\u4e0a\u5b9e\u73b06.6%\u7684\u8d28\u91cf\u63d0\u5347\u548c2.9%\u7684\u6700\u5927\u6027\u80fd\u63d0\u5347", "motivation": "\u89e3\u51b3\u4e0d\u540c\u8ba1\u7b97\u6210\u672c\u548c\u6027\u80fd\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u89c4\u6a21\u5316\u3001\u6210\u672c\u6548\u76ca\u90e8\u7f72\u7684\u6311\u6218", "method": "\u4f7f\u7528\u5355\u5934\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u8054\u5408\u5efa\u6a21\u67e5\u8be2\u548c\u6a21\u578b\u5d4c\u5165\uff0c\u663e\u5f0f\u6355\u83b7\u7ec6\u7c92\u5ea6\u67e5\u8be2-\u6a21\u578b\u4ea4\u4e92\uff0c\u9884\u6d4b\u54cd\u5e94\u8d28\u91cf\u548c\u751f\u6210\u6210\u672c", "result": "\u5728RouterBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5e73\u5747\u8d28\u91cf\u63d0\u53476.6%\uff0c\u6700\u5927\u6027\u80fd\u63d0\u53472.9%\uff0c\u67b6\u6784\u8f7b\u91cf\u4e14\u8de8\u57df\u6cdb\u5316\u6548\u679c\u597d", "conclusion": "\u5efa\u7acb\u4e86\u6210\u672c\u611f\u77e5LLM\u8def\u7531\u7684\u65b0\u6807\u51c6\uff0c\u901a\u8fc7\u6307\u6570\u5956\u52b1\u51fd\u6570\u5728\u6027\u80fd\u548c\u6210\u672c\u95f4\u5b9e\u73b0\u7a33\u5065\u5e73\u8861\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u6548\u7387\u66f4\u9ad8"}}
{"id": "2509.10070", "pdf": "https://arxiv.org/pdf/2509.10070", "abs": "https://arxiv.org/abs/2509.10070", "authors": ["Yixin Cao", "Yiren Lu", "Junhong Nie", "Xiaoming Sun", "Guojing Tian"], "title": "Toward Minimum Graphic Parity Networks", "categories": ["quant-ph", "cs.DM", "cs.DS", "math.CO"], "comment": null, "summary": "Quantum circuits composed of CNOT and $R_z$ are fundamental building blocks\nof many quantum algorithms, so optimizing the synthesis of such quantum\ncircuits is crucial. We address this problem from a theoretical perspective by\nstudying the graphic parity network synthesis problem. A graphic parity network\nfor a graph $G$ is a quantum circuit composed solely of CNOT gates where each\nedge of $G$ is represented in the circuit, and the final state of the wires\nmatches the original input. We aim to synthesize graphic parity networks with\nthe minimum number of gates, specifically for quantum algorithms addressing\ncombinatorial optimization problems with Ising formulations. We demonstrate\nthat a graphic parity network for a connected graph with $n$ vertices and $m$\nedges requires at least $m+n-1$ gates. This lower bound can be improved to\n$m+\\Omega(m) = m+\\Omega(n^{1.5})$ when the shortest cycle in the graph has a\nlength of at least five. We complement this result with a simple randomized\nalgorithm that synthesizes a graphic parity network with expected $m +\nO(n^{1.5}\\sqrt{\\log n})$ gates. Additionally, we begin exploring connected\ngraphs that allow for graphic parity networks with exactly $m+n-1$ gates. We\nconjecture that all such graphs belong to a newly defined graph class.\nFurthermore, we present a linear-time algorithm for synthesizing minimum\ngraphic parity networks for graphs within this class. However, this graph class\nis not closed under taking induced subgraphs, and we show that recognizing it\nis $\\textsf{NP}$-complete, which is complemented with a fixed-parameter\ntractable algorithm parameterized by the treewidth.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u56fe\u5f62\u5947\u5076\u7f51\u7edc\u5408\u6210\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u91cf\u5b50\u7535\u8def\u4e2dCNOT\u548cRz\u95e8\u7684\u6700\u5c0f\u6570\u91cf\u4e0b\u754c\uff0c\u5e76\u7ed9\u51fa\u4e86\u968f\u673a\u7b97\u6cd5\u548c\u7279\u5b9a\u56fe\u7c7b\u7684\u6700\u5c0f\u5408\u6210\u65b9\u6cd5\u3002", "motivation": "\u4f18\u5316\u7531CNOT\u548cRz\u95e8\u7ec4\u6210\u7684\u91cf\u5b50\u7535\u8def\u5408\u6210\u5bf9\u91cf\u5b50\u7b97\u6cd5\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u89e3\u51b3\u5177\u6709Ising\u516c\u5f0f\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u65f6\u3002", "method": "\u7814\u7a76\u56fe\u5f62\u5947\u5076\u7f51\u7edc\u5408\u6210\u95ee\u9898\uff0c\u5efa\u7acb\u7406\u8bba\u4e0b\u754c\uff0c\u63d0\u51fa\u968f\u673a\u7b97\u6cd5\uff0c\u5b9a\u4e49\u65b0\u7684\u56fe\u7c7b\u5e76\u8bbe\u8ba1\u7ebf\u6027\u65f6\u95f4\u5408\u6210\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u8fde\u901a\u56fe\u9700\u8981\u81f3\u5c11m+n-1\u4e2a\u95e8\uff0c\u5f53\u6700\u77ed\u73af\u957f\u5ea6\u22655\u65f6\u53ef\u6539\u8fdb\u4e3am+\u03a9(n^1.5)\uff1b\u63d0\u51fa\u4e86\u671f\u671bm+O(n^1.5\u221alog n)\u7684\u968f\u673a\u7b97\u6cd5\uff1b\u8bc1\u660e\u4e86\u8bc6\u522b\u7279\u5b9a\u56fe\u7c7b\u662fNP\u5b8c\u5168\u7684\u3002", "conclusion": "\u4e3a\u91cf\u5b50\u7535\u8def\u5408\u6210\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0b\u754c\u548c\u5b9e\u7528\u7b97\u6cd5\uff0c\u5b9a\u4e49\u4e86\u65b0\u7684\u56fe\u7c7b\u5e76\u5206\u6790\u4e86\u5176\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u4e3a\u91cf\u5b50\u7b97\u6cd5\u4f18\u5316\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2509.10216", "pdf": "https://arxiv.org/pdf/2509.10216", "abs": "https://arxiv.org/abs/2509.10216", "authors": ["Noga H. Rotman", "Tiago Ferreira", "Hila Peleg", "Mark Silberstein", "Alexandra Silva"], "title": "RFSeek and Ye Shall Find", "categories": ["cs.NI", "cs.HC", "cs.LG"], "comment": "7 pages", "summary": "Requests for Comments (RFCs) are extensive specification documents for\nnetwork protocols, but their prose-based format and their considerable length\noften impede precise operational understanding. We present RFSeek, an\ninteractive tool that automatically extracts visual summaries of protocol logic\nfrom RFCs. RFSeek leverages large language models (LLMs) to generate\nprovenance-linked, explorable diagrams, surfacing both official state machines\nand additional logic found only in the RFC text. Compared to existing RFC\nvisualizations, RFSeek's visual summaries are more transparent and easier to\naudit against their textual source. We showcase the tool's potential through a\nseries of use cases, including guided knowledge extraction and semantic\ndiffing, applied to protocols such as TCP, QUIC, PPTP, and DCCP.\n  In practice, RFSeek not only reconstructs the RFC diagrams included in some\nspecifications, but, more interestingly, also uncovers important logic such as\nnodes or edges described in the text but missing from those diagrams. RFSeek\nfurther derives new visualization diagrams for complex RFCs, with QUIC as a\nrepresentative case. Our approach, which we term \\emph{Summary Visualization},\nhighlights a promising direction: combining LLMs with formal, user-customized\nvisualizations to enhance protocol comprehension and support robust\nimplementations.", "AI": {"tldr": "RFSeek\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u4ea4\u4e92\u5f0f\u5de5\u5177\uff0c\u80fd\u591f\u4eceRFC\u6587\u6863\u4e2d\u81ea\u52a8\u63d0\u53d6\u534f\u8bae\u903b\u8f91\u7684\u53ef\u89c6\u5316\u6458\u8981\uff0c\u751f\u6210\u53ef\u8ffd\u6eaf\u6765\u6e90\u7684\u72b6\u6001\u673a\u56fe\uff0c\u5e2e\u52a9\u7406\u89e3\u590d\u6742\u7684\u7f51\u7edc\u534f\u8bae\u89c4\u8303\u3002", "motivation": "RFC\u6587\u6863\u5197\u957f\u4e14\u57fa\u4e8e\u6587\u672c\uff0c\u963b\u788d\u4e86\u5bf9\u534f\u8bae\u64cd\u4f5c\u903b\u8f91\u7684\u7cbe\u786e\u7406\u89e3\uff0c\u9700\u8981\u5de5\u5177\u6765\u81ea\u52a8\u63d0\u53d6\u548c\u53ef\u89c6\u5316\u534f\u8bae\u903b\u8f91\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u4eceRFC\u6587\u672c\u4e2d\u751f\u6210\u53ef\u8ffd\u6eaf\u6765\u6e90\u7684\u53ef\u63a2\u7d22\u56fe\u8868\uff0c\u63d0\u53d6\u5b98\u65b9\u72b6\u6001\u673a\u548c\u6587\u672c\u4e2d\u9690\u542b\u7684\u903b\u8f91\u3002", "result": "RFSeek\u4e0d\u4ec5\u91cd\u5efa\u4e86RFC\u4e2d\u7684\u73b0\u6709\u56fe\u8868\uff0c\u8fd8\u53d1\u73b0\u4e86\u6587\u672c\u4e2d\u63cf\u8ff0\u4f46\u56fe\u8868\u4e2d\u7f3a\u5931\u7684\u91cd\u8981\u903b\u8f91\u8282\u70b9\u548c\u8fb9\uff0c\u5e76\u4e3a\u590d\u6742\u534f\u8bae\u5982QUIC\u751f\u6210\u4e86\u65b0\u7684\u53ef\u89c6\u5316\u56fe\u8868\u3002", "conclusion": "\u7ed3\u5408LLMs\u548c\u5f62\u5f0f\u5316\u3001\u7528\u6237\u5b9a\u5236\u5316\u53ef\u89c6\u5316\u7684\u6458\u8981\u53ef\u89c6\u5316\u65b9\u6cd5\uff0c\u662f\u589e\u5f3a\u534f\u8bae\u7406\u89e3\u548c\u652f\u6301\u5065\u58ee\u5b9e\u73b0\u7684\u6709\u524d\u666f\u65b9\u5411\u3002"}}
{"id": "2509.10085", "pdf": "https://arxiv.org/pdf/2509.10085", "abs": "https://arxiv.org/abs/2509.10085", "authors": ["Philipp Zech", "Irdin Pekaric"], "title": "Sustaining Research Software: A Fitness Function Approach", "categories": ["cs.SE"], "comment": null, "summary": "The long-term sustainability of research software is a critical challenge, as\nit usually suffers from poor maintainability, lack of adaptability, and\neventual obsolescence. This paper proposes a novel approach to addressing this\nissue by leveraging the concept of fitness functions from evolutionary\narchitecture. Fitness functions are automated, continuously evaluated metrics\ndesigned to ensure that software systems meet desired non-functional,\narchitectural qualities over time. We define a set of fitness functions\ntailored to the unique requirements of research software, focusing on\nfindability, accessibility, interoperability and reusability (FAIR). These\nfitness functions act as proactive safeguards, promoting practices such as\nmodular design, comprehensive documentation, version control, and compatibility\nwith evolving technological ecosystems. By integrating these metrics into the\ndevelopment life cycle, we aim to foster a culture of sustainability within the\nresearch community. Case studies and experimental results demonstrate the\npotential of this approach to enhance the long-term FAIR of research software,\nbridging the gap between ephemeral project-based development and enduring\nscientific impact.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u8fdb\u5316\u67b6\u6784\u4e2d\u7684\u9002\u5e94\u5ea6\u51fd\u6570\u6982\u5ff5\uff0c\u4e3a\u7814\u7a76\u8f6f\u4ef6\u5b9a\u4e49\u4e13\u95e8\u7684FAIR\uff08\u53ef\u53d1\u73b0\u3001\u53ef\u8bbf\u95ee\u3001\u53ef\u4e92\u64cd\u4f5c\u3001\u53ef\u91cd\u7528\uff09\u9002\u5e94\u5ea6\u51fd\u6570\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6301\u7eed\u8bc4\u4f30\u6765\u63d0\u5347\u7814\u7a76\u8f6f\u4ef6\u7684\u957f\u671f\u53ef\u6301\u7eed\u6027\u3002", "motivation": "\u7814\u7a76\u8f6f\u4ef6\u901a\u5e38\u9762\u4e34\u53ef\u7ef4\u62a4\u6027\u5dee\u3001\u7f3a\u4e4f\u9002\u5e94\u6027\u3001\u6700\u7ec8\u8fc7\u65f6\u7b49\u53ef\u6301\u7eed\u6027\u6311\u6218\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u6765\u786e\u4fdd\u5176\u957f\u671f\u53ef\u7528\u6027\u548c\u79d1\u5b66\u5f71\u54cd\u529b\u3002", "method": "\u91c7\u7528\u8fdb\u5316\u67b6\u6784\u4e2d\u7684\u9002\u5e94\u5ea6\u51fd\u6570\u6982\u5ff5\uff0c\u4e3a\u7814\u7a76\u8f6f\u4ef6\u5b9a\u5236\u4e13\u95e8\u7684FAIR\u9002\u5e94\u5ea6\u51fd\u6570\uff0c\u96c6\u6210\u5230\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\uff0c\u4fc3\u8fdb\u6a21\u5757\u5316\u8bbe\u8ba1\u3001\u5168\u9762\u6587\u6863\u5316\u3001\u7248\u672c\u63a7\u5236\u548c\u4e0e\u4e0d\u65ad\u53d1\u5c55\u7684\u6280\u672f\u751f\u6001\u7cfb\u7edf\u7684\u517c\u5bb9\u6027\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u548c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u7814\u7a76\u8f6f\u4ef6\u7684\u957f\u671fFAIR\u7279\u6027\uff0c\u5f25\u5408\u77ed\u671f\u9879\u76ee\u5f00\u53d1\u4e0e\u6301\u4e45\u79d1\u5b66\u5f71\u54cd\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u901a\u8fc7\u5b9a\u4e49\u548c\u5b9e\u65bd\u9488\u5bf9\u7814\u7a76\u8f6f\u4ef6\u7684\u9002\u5e94\u5ea6\u51fd\u6570\uff0c\u53ef\u4ee5\u57f9\u517b\u7814\u7a76\u793e\u533a\u7684\u53ef\u6301\u7eed\u6027\u6587\u5316\uff0c\u786e\u4fdd\u7814\u7a76\u8f6f\u4ef6\u7684\u957f\u4e45\u4ef7\u503c\u548c\u79d1\u5b66\u8d21\u732e\u3002"}}
{"id": "2509.09793", "pdf": "https://arxiv.org/pdf/2509.09793", "abs": "https://arxiv.org/abs/2509.09793", "authors": ["Vincent Herfeld", "Baudouin Denis de Senneville", "Arthur Leclaire", "Nicolas Papadakis"], "title": "From the Gradient-Step Denoiser to the Proximal Denoiser and their associated convergent Plug-and-Play algorithms", "categories": ["cs.LG"], "comment": null, "summary": "In this paper we analyze the Gradient-Step Denoiser and its usage in\nPlug-and-Play algorithms. The Plug-and-Play paradigm of optimization algorithms\nuses off the shelf denoisers to replace a proximity operator or a gradient\ndescent operator of an image prior. Usually this image prior is implicit and\ncannot be expressed, but the Gradient-Step Denoiser is trained to be exactly\nthe gradient descent operator or the proximity operator of an explicit\nfunctional while preserving state-of-the-art denoising capabilities.", "AI": {"tldr": "\u5206\u6790\u68af\u5ea6\u6b65\u957f\u53bb\u566a\u5668\u53ca\u5176\u5728\u5373\u63d2\u5373\u7528\u7b97\u6cd5\u4e2d\u7684\u5e94\u7528\uff0c\u8be5\u53bb\u566a\u5668\u88ab\u8bad\u7ec3\u4e3a\u663e\u5f0f\u51fd\u6570\u7684\u529f\u80fd\u68af\u5ea6\u4e0b\u964d\u7b97\u5b50\u6216\u90bb\u8fd1\u7b97\u5b50\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u5148\u8fdb\u7684\u53bb\u566a\u80fd\u529b", "motivation": "\u5373\u63d2\u5373\u7528\u4f18\u5316\u7b97\u6cd5\u4f7f\u7528\u73b0\u6210\u7684\u53bb\u566a\u5668\u6765\u66ff\u4ee3\u56fe\u50cf\u5148\u9a8c\u7684\u90bb\u8fd1\u7b97\u5b50\u6216\u68af\u5ea6\u4e0b\u964d\u7b97\u5b50\uff0c\u4f46\u901a\u5e38\u8fd9\u79cd\u56fe\u50cf\u5148\u9a8c\u662f\u9690\u5f0f\u7684\u3002\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u540c\u65f6\u4f5c\u4e3a\u663e\u5f0f\u51fd\u6570\u7b97\u5b50\u7684\u9ad8\u6027\u80fd\u53bb\u566a\u5668", "method": "\u8bad\u7ec3\u68af\u5ea6\u6b65\u957f\u53bb\u566a\u5668\uff0c\u4f7f\u5176\u7cbe\u786e\u5730\u6210\u4e3a\u663e\u5f0f\u51fd\u6570\u7684\u529f\u80fd\u68af\u5ea6\u4e0b\u964d\u7b97\u5b50\u6216\u90bb\u8fd1\u7b97\u5b50", "result": "\u68af\u5ea6\u6b65\u957f\u53bb\u566a\u5668\u5728\u4fdd\u6301\u6700\u5148\u8fdb\u53bb\u566a\u6027\u80fd\u7684\u540c\u65f6\uff0c\u80fd\u591f\u4f5c\u4e3a\u663e\u5f0f\u51fd\u6570\u7684\u6570\u5b66\u7b97\u5b50\u4f7f\u7528", "conclusion": "\u68af\u5ea6\u6b65\u957f\u53bb\u566a\u5668\u6210\u529f\u5730\u5c06\u663e\u5f0f\u51fd\u6570\u5efa\u6a21\u4e0e\u9ad8\u6027\u80fd\u53bb\u566a\u80fd\u529b\u76f8\u7ed3\u5408\uff0c\u4e3a\u5373\u63d2\u5373\u7528\u7b97\u6cd5\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u6570\u5b66\u57fa\u7840"}}
{"id": "2509.10077", "pdf": "https://arxiv.org/pdf/2509.10077", "abs": "https://arxiv.org/abs/2509.10077", "authors": ["Simen Storesund", "Kristian Valset Aars", "Robin Dietrich", "Nicolai Waniek"], "title": "Predictive Spike Timing Enables Distributed Shortest Path Computation in Spiking Neural Networks", "categories": ["cs.NE", "cs.AI", "cs.DS", "cs.LG"], "comment": null, "summary": "Efficient planning and sequence selection are central to intelligence, yet\ncurrent approaches remain largely incompatible with biological computation.\nClassical graph algorithms like Dijkstra's or A* require global state and\nbiologically implausible operations such as backtracing, while reinforcement\nlearning methods rely on slow gradient-based policy updates that appear\ninconsistent with rapid behavioral adaptation observed in natural systems.\n  We propose a biologically plausible algorithm for shortest-path computation\nthat operates through local spike-based message-passing with realistic\nprocessing delays. The algorithm exploits spike-timing coincidences to identify\nnodes on optimal paths: Neurons that receive inhibitory-excitatory message\npairs earlier than predicted reduce their response delays, creating a temporal\ncompression that propagates backwards from target to source. Through analytical\nproof and simulations on random spatial networks, we demonstrate that the\nalgorithm converges and discovers all shortest paths using purely timing-based\nmechanisms. By showing how short-term timing dynamics alone can compute\nshortest paths, this work provides new insights into how biological networks\nmight solve complex computational problems through purely local computation and\nrelative spike-time prediction. These findings open new directions for\nunderstanding distributed computation in biological and artificial systems,\nwith possible implications for computational neuroscience, AI, reinforcement\nlearning, and neuromorphic systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c40\u90e8\u8109\u51b2\u65f6\u5e8f\u7684\u751f\u7269\u5b66\u5408\u7406\u6700\u77ed\u8def\u5f84\u7b97\u6cd5\uff0c\u901a\u8fc7\u8109\u51b2\u65f6\u95f4\u5de7\u5408\u548c\u6291\u5236-\u5174\u594b\u6d88\u606f\u5bf9\u6765\u8bc6\u522b\u6700\u4f18\u8def\u5f84\u8282\u70b9\uff0c\u65e0\u9700\u5168\u5c40\u72b6\u6001\u6216\u53cd\u5411\u8ffd\u8e2a", "motivation": "\u73b0\u6709\u56fe\u7b97\u6cd5\u9700\u8981\u5168\u5c40\u72b6\u6001\u548c\u751f\u7269\u5b66\u4e0a\u4e0d\u53ef\u4fe1\u7684\u64cd\u4f5c\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u7f13\u6162\u7684\u68af\u5ea6\u66f4\u65b0\uff0c\u4e0e\u751f\u7269\u7cfb\u7edf\u7684\u5feb\u901f\u884c\u4e3a\u9002\u5e94\u4e0d\u7b26", "method": "\u5229\u7528\u5c40\u90e8\u8109\u51b2\u6d88\u606f\u4f20\u9012\u548c\u5b9e\u9645\u5904\u7406\u5ef6\u8fdf\uff0c\u901a\u8fc7\u8109\u51b2\u65f6\u95f4\u5de7\u5408\u8bc6\u522b\u6700\u4f18\u8def\u5f84\u8282\u70b9\uff0c\u65e9\u671f\u6536\u5230\u6291\u5236-\u5174\u594b\u6d88\u606f\u5bf9\u7684\u795e\u7ecf\u5143\u51cf\u5c11\u54cd\u5e94\u5ef6\u8fdf\uff0c\u5f62\u6210\u4ece\u76ee\u6807\u5230\u6e90\u7684\u65f6\u95f4\u538b\u7f29", "result": "\u7b97\u6cd5\u6536\u655b\u5e76\u53d1\u73b0\u6240\u6709\u6700\u77ed\u8def\u5f84\uff0c\u901a\u8fc7\u7eaf\u65f6\u5e8f\u673a\u5236\u5728\u968f\u673a\u7a7a\u95f4\u7f51\u7edc\u4e0a\u9a8c\u8bc1", "conclusion": "\u5c55\u793a\u4e86\u77ed\u671f\u65f6\u5e8f\u52a8\u6001\u5982\u4f55\u5355\u72ec\u8ba1\u7b97\u6700\u77ed\u8def\u5f84\uff0c\u4e3a\u7406\u89e3\u751f\u7269\u7f51\u7edc\u5982\u4f55\u901a\u8fc7\u5c40\u90e8\u8ba1\u7b97\u548c\u76f8\u5bf9\u8109\u51b2\u65f6\u95f4\u9884\u6d4b\u89e3\u51b3\u590d\u6742\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3"}}
{"id": "2509.10338", "pdf": "https://arxiv.org/pdf/2509.10338", "abs": "https://arxiv.org/abs/2509.10338", "authors": ["Arup Kumar Marik", "Basabdatta Palit", "Sadananda Behera"], "title": "Trusted Repeater Placement in QKD-enabled Optical Networks", "categories": ["cs.NI"], "comment": "Paper accepted for the IEEE Global Communications Conference Workshop\n  on Quantum Computing for Communications and Learning", "summary": "Quantum Key Distribution (QKD) provides information-theoretic security, but\nis limited by distance in optical networks, thereby requiring repeater nodes to\nextend coverage. Existing works usually assume all repeater nodes and\nassociated Key Management Servers (KMSs) to be Trusted Repeater Nodes (TRNs),\nwhile ignoring risks from software exploits and insider threats. In this paper,\nwe propose a reliability-aware TRN placement framework for metro optical\nnetworks, which assigns each node a trust score and integrates it into the\nDijkstra algorithm via weighted links. We then rank the nodes using a composite\nscore, which is a weighted combination of betweenness centrality and\neigenvector centrality to enable a secure and scalable TRN deployment.\nSimulation results on a reference topology show that our method covers 10.77%\nmore shortest paths compared to traditional metrics like degree centrality,\nusing the same number (around eight) of TRNs, making it suitable for TRN\nselection to maximize secure connectivity.", "AI": {"tldr": "\u91cf\u5b50\u5bc6\u94a5\u5206\u914d\u7f51\u7edc\u4e2d\u7684\u53ef\u9760\u6027\u611f\u77e5\u4e2d\u7ee7\u8282\u70b9\u5e03\u7f6e\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u4efb\u8bc4\u5206\u548c\u4e2d\u5fc3\u6027\u6307\u6807\u4f18\u5316TRN\u9009\u62e9\uff0c\u5728\u540c\u6837\u6570\u91cf\u4e2d\u7ee7\u8282\u70b9\u4e0b\u8986\u76d6\u4e86\u66f4\u591a\u6700\u77ed\u8def\u5f84\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50\u4e2d\u7ee7\u7f51\u7edc\u5047\u8bbe\u6240\u6709\u4e2d\u7ee7\u8282\u70b9\u90fd\u53ef\u4fe1\uff0c\u5ffd\u89c6\u4e86\u8f6f\u4ef6\u6f0f\u6d1e\u548c\u5185\u90e8\u5a01\u80c1\u5e26\u6765\u7684\u98ce\u9669\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u53ef\u9760\u7684\u4e2d\u7ee7\u8282\u70b9\u5e03\u7f6e\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u53ef\u9760\u6027\u611f\u77e5TRN\u5e03\u7f6e\u6846\u67b6\uff0c\u7ed9\u6bcf\u4e2a\u8282\u70b9\u8d4b\u4e88\u4fe1\u4efb\u8bc4\u5206\uff0c\u901a\u8fc7\u6743\u91cd\u94fe\u8def\u96c6\u6210\u5230Dijkstra\u7b97\u6cd5\u4e2d\uff0c\u7136\u540e\u4f7f\u7528\u4e2d\u95f4\u5ea6\u4e2d\u5fc3\u6027\u548c\u7279\u5f81\u5411\u91cf\u4e2d\u5fc3\u6027\u7684\u7efc\u5408\u8bc4\u5206\u5bf9\u8282\u70b9\u8fdb\u884c\u6392\u540d\u3002", "result": "\u5728\u53c2\u8003\u62d3\u6251\u7ed3\u6784\u4e0a\u7684\u6a21\u62df\u663e\u793a\uff0c\u5728\u4f7f\u7528\u7ea68\u4e2aTRN\u7684\u60c5\u51b5\u4e0b\uff0c\u65b0\u65b9\u6cd5\u76f8\u6bd4\u4f20\u7edf\u7684\u5ea6\u4e2d\u5fc3\u6027\u6307\u6807\u8986\u76d6\u4e86\u591a10.77%\u7684\u6700\u77ed\u8def\u5f84\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u5408\u4e8eTRN\u9009\u62e9\uff0c\u80fd\u591f\u6700\u5927\u5316\u5b89\u5168\u8fde\u63a5\u6027\uff0c\u63d0\u9ad8\u91cf\u5b50\u5bc6\u94a5\u5206\u914d\u7f51\u7edc\u7684\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2509.10099", "pdf": "https://arxiv.org/pdf/2509.10099", "abs": "https://arxiv.org/abs/2509.10099", "authors": ["Radu Apsan", "Vincenzo Stoico", "Michel Albonico", "Rudra Dhar", "Karthik Vaidhyanathan", "Ivano Malavolta"], "title": "Generating Energy-Efficient Code via Large-Language Models -- Where are we now?", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Context. The rise of Large Language Models (LLMs) has led to their widespread\nadoption in development pipelines. Goal. We empirically assess the energy\nefficiency of Python code generated by LLMs against human-written code and code\ndeveloped by a Green software expert. Method. We test 363 solutions to 9 coding\nproblems from the EvoEval benchmark using 6 widespread LLMs with 4 prompting\ntechniques, and comparing them to human-developed solutions. Energy consumption\nis measured on three different hardware platforms: a server, a PC, and a\nRaspberry Pi for a total of ~881h (36.7 days). Results. Human solutions are 16%\nmore energy-efficient on the server and 3% on the Raspberry Pi, while LLMs\noutperform human developers by 25% on the PC. Prompting does not consistently\nlead to energy savings, where the most energy-efficient prompts vary by\nhardware platform. The code developed by a Green software expert is\nconsistently more energy-efficient by at least 17% to 30% against all LLMs on\nall hardware platforms. Conclusions. Even though LLMs exhibit relatively good\ncode generation capabilities, no LLM-generated code was more energy-efficient\nthan that of an experienced Green software developer, suggesting that as of\ntoday there is still a great need of human expertise for developing\nenergy-efficient Python code.", "AI": {"tldr": "LLM\u751f\u6210\u7684Python\u4ee3\u7801\u5728\u80fd\u6e90\u6548\u7387\u65b9\u9762\u8868\u73b0\u4e0d\u4e00\uff0c\u5728\u670d\u52a1\u5668\u4e0a\u6bd4\u4eba\u7c7b\u4ee3\u7801\u4f4e\u654816%\uff0c\u5728\u6811\u8393\u6d3e\u4e0a\u4f4e\u65483%\uff0c\u4f46\u5728PC\u4e0a\u9ad8\u654825%\u3002\u7eff\u8272\u8f6f\u4ef6\u4e13\u5bb6\u7f16\u5199\u7684\u4ee3\u7801\u5728\u6240\u6709\u786c\u4ef6\u5e73\u53f0\u4e0a\u90fd\u6bd4LLM\u4ee3\u7801\u8282\u80fd17-30%\u3002", "motivation": "\u8bc4\u4f30LLM\u751f\u6210\u7684Python\u4ee3\u7801\u4e0e\u4eba\u7c7b\u7f16\u5199\u4ee3\u7801\u5728\u80fd\u6e90\u6548\u7387\u65b9\u9762\u7684\u5bf9\u6bd4\uff0c\u7279\u522b\u662f\u5728\u7eff\u8272\u8f6f\u4ef6\u5f00\u53d1\u80cc\u666f\u4e0b\uff0c\u4e86\u89e3LLM\u662f\u5426\u80fd\u66ff\u4ee3\u4eba\u7c7b\u4e13\u5bb6\u7f16\u5199\u8282\u80fd\u4ee3\u7801\u3002", "method": "\u4f7f\u7528EvoEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u76849\u4e2a\u7f16\u7a0b\u95ee\u9898\u7684363\u4e2a\u89e3\u51b3\u65b9\u6848\uff0c\u6d4b\u8bd56\u4e2a\u4e3b\u6d41LLM\u548c4\u79cd\u63d0\u793a\u6280\u672f\uff0c\u5e76\u4e0e\u4eba\u7c7b\u5f00\u53d1\u7684\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u6bd4\u8f83\u3002\u5728\u4e09\u79cd\u786c\u4ef6\u5e73\u53f0\uff08\u670d\u52a1\u5668\u3001PC\u3001\u6811\u8393\u6d3e\uff09\u4e0a\u6d4b\u91cf\u80fd\u6e90\u6d88\u8017\uff0c\u603b\u6d4b\u8bd5\u65f6\u95f4\u7ea6881\u5c0f\u65f6\u3002", "result": "\u4eba\u7c7b\u89e3\u51b3\u65b9\u6848\u5728\u670d\u52a1\u5668\u4e0a\u8282\u80fd16%\uff0c\u5728\u6811\u8393\u6d3e\u4e0a\u8282\u80fd3%\uff1bLLM\u5728PC\u4e0a\u6bd4\u4eba\u7c7b\u5f00\u53d1\u8005\u8282\u80fd25%\u3002\u63d0\u793a\u6280\u672f\u4e0d\u80fd\u6301\u7eed\u5e26\u6765\u8282\u80fd\u6548\u679c\uff0c\u6700\u8282\u80fd\u7684\u63d0\u793a\u56e0\u786c\u4ef6\u5e73\u53f0\u800c\u5f02\u3002\u7eff\u8272\u8f6f\u4ef6\u4e13\u5bb6\u7684\u4ee3\u7801\u5728\u6240\u6709\u786c\u4ef6\u5e73\u53f0\u4e0a\u90fd\u6bd4\u6240\u6709LLM\u8282\u80fd\u81f3\u5c1117-30%\u3002", "conclusion": "\u5c3d\u7ba1LLM\u5c55\u73b0\u51fa\u76f8\u5bf9\u826f\u597d\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u4f46\u6ca1\u6709\u4e00\u4e2aLLM\u751f\u6210\u7684\u4ee3\u7801\u6bd4\u7ecf\u9a8c\u4e30\u5bcc\u7684\u7eff\u8272\u8f6f\u4ef6\u5f00\u53d1\u8005\u66f4\u8282\u80fd\uff0c\u8868\u660e\u76ee\u524d\u5f00\u53d1\u8282\u80fdPython\u4ee3\u7801\u4ecd\u7136\u975e\u5e38\u9700\u8981\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u3002"}}
{"id": "2509.09799", "pdf": "https://arxiv.org/pdf/2509.09799", "abs": "https://arxiv.org/abs/2509.09799", "authors": ["Mansi Sharma", "Alexandre Duchevet", "Florian Daiber", "Jean-Paul Imbert", "Maurice Rekrut"], "title": "Distinguishing Startle from Surprise Events Based on Physiological Signals", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "Unexpected events can impair attention and delay decision-making, posing\nserious safety risks in high-risk environments such as aviation. In particular,\nreactions like startle and surprise can impact pilot performance in different\nways, yet are often hard to distinguish in practice. Existing research has\nlargely studied these reactions separately, with limited focus on their\ncombined effects or how to differentiate them using physiological data. In this\nwork, we address this gap by distinguishing between startle and surprise events\nbased on physiological signals using machine learning and multi-modal fusion\nstrategies. Our results demonstrate that these events can be reliably\npredicted, achieving a highest mean accuracy of 85.7% with SVM and Late Fusion.\nTo further validate the robustness of our model, we extended the evaluation to\ninclude a baseline condition, successfully differentiating between Startle,\nSurprise, and Baseline states with a highest mean accuracy of 74.9% with\nXGBoost and Late Fusion.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u548c\u591a\u6a21\u6001\u878d\u5408\u7b56\u7565\uff0c\u57fa\u4e8e\u751f\u7406\u4fe1\u53f7\u533a\u5206\u60ca\u5413\u548c\u60ca\u8bb6\u4e8b\u4ef6\uff0c\u6700\u9ad8\u51c6\u786e\u7387\u8fbe\u523085.7%\uff0c\u5e76\u80fd\u6709\u6548\u533a\u5206\u60ca\u5413\u3001\u60ca\u8bb6\u548c\u57fa\u7ebf\u72b6\u6001\uff0c\u51c6\u786e\u738774.9%\u3002", "motivation": "\u610f\u5916\u4e8b\u4ef6\u4f1a\u635f\u5bb3\u6ce8\u610f\u529b\u5e76\u5ef6\u8fdf\u51b3\u7b56\uff0c\u5728\u822a\u7a7a\u7b49\u9ad8\u5371\u73af\u5883\u4e2d\u6784\u6210\u4e25\u91cd\u5b89\u5168\u98ce\u9669\u3002\u60ca\u5413\u548c\u60ca\u8bb6\u53cd\u5e94\u4ee5\u4e0d\u540c\u65b9\u5f0f\u5f71\u54cd\u98de\u884c\u5458\u8868\u73b0\uff0c\u4f46\u5728\u5b9e\u8df5\u4e2d\u96be\u4ee5\u533a\u5206\u3002\u73b0\u6709\u7814\u7a76\u5927\u591a\u5355\u72ec\u7814\u7a76\u8fd9\u4e9b\u53cd\u5e94\uff0c\u5bf9\u5176\u7ec4\u5408\u6548\u5e94\u6216\u5982\u4f55\u7528\u751f\u7406\u6570\u636e\u533a\u5206\u5b83\u4eec\u5173\u6ce8\u6709\u9650\u3002", "method": "\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u548c\u591a\u6a21\u6001\u878d\u5408\u7b56\u7565\uff0c\u57fa\u4e8e\u751f\u7406\u4fe1\u53f7\u533a\u5206\u60ca\u5413\u548c\u60ca\u8bb6\u4e8b\u4ef6\u3002\u91c7\u7528SVM\u548cXGBoost\u7b49\u7b97\u6cd5\uff0c\u7ed3\u5408Late Fusion\u878d\u5408\u7b56\u7565\u3002", "result": "\u60ca\u5413\u548c\u60ca\u8bb6\u4e8b\u4ef6\u53ef\u4ee5\u53ef\u9760\u9884\u6d4b\uff0cSVM\u548cLate Fusion\u7ec4\u5408\u8fbe\u5230\u6700\u9ad8\u5e73\u5747\u51c6\u786e\u738785.7%\u3002\u6269\u5c55\u8bc4\u4f30\u5305\u62ec\u57fa\u7ebf\u6761\u4ef6\u540e\uff0cXGBoost\u548cLate Fusion\u7ec4\u5408\u80fd\u533a\u5206\u60ca\u5413\u3001\u60ca\u8bb6\u548c\u57fa\u7ebf\u72b6\u6001\uff0c\u6700\u9ad8\u5e73\u5747\u51c6\u786e\u738774.9%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u533a\u5206\u60ca\u5413\u548c\u60ca\u8bb6\u53cd\u5e94\uff0c\u4e3a\u9ad8\u5371\u73af\u5883\u4e2d\u610f\u5916\u4e8b\u4ef6\u7684\u751f\u7406\u76d1\u6d4b\u548c\u5e72\u9884\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6280\u672f\u624b\u6bb5\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b89\u5168\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.10239", "pdf": "https://arxiv.org/pdf/2509.10239", "abs": "https://arxiv.org/abs/2509.10239", "authors": ["Andreas Bluhm", "Matthias C. Caro", "Francisco Escudero Guti\u00e9rrez", "Aadil Oufkir", "Cambyse Rouz\u00e9"], "title": "Certifying and learning quantum Ising Hamiltonians", "categories": ["quant-ph", "cs.CC", "cs.DS"], "comment": "20 pages, no figures", "summary": "In this work, we study the problems of certifying and learning quantum Ising\nHamiltonians. Our main contributions are as follows:\n  Certification of Ising Hamiltonians. We show that certifying an Ising\nHamiltonian in normalized Frobenius norm via access to its time-evolution\noperator requires only $\\widetilde O(1/\\varepsilon)$ time evolution. This\nmatches the Heisenberg-scaling lower bound of $\\Omega(1/\\varepsilon)$ up to\nlogarithmic factors. To our knowledge, this is the first nearly-optimal\nalgorithm for testing a Hamiltonian property. A key ingredient in our analysis\nis the Bonami Lemma from Fourier analysis.\n  Learning Ising Gibbs states. We design an algorithm for learning Ising Gibbs\nstates in trace norm that is sample-efficient in all parameters. In contrast,\nprevious approaches learned the underlying Hamiltonian (which implies learning\nthe Gibbs state) but suffered from exponential sample complexity in the inverse\ntemperature.\n  Certification of Ising Gibbs states. We give an algorithm for certifying\nIsing Gibbs states in trace norm that is both sample and time-efficient,\nthereby solving a question posed by Anshu (Harvard Data Science Review, 2022).\n  Finally, we extend our results on learning and certification of Gibbs states\nto general $k$-local Hamiltonians for any constant $k$.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u91cf\u5b50Ising\u54c8\u5bc6\u987f\u91cf\u7684\u8ba4\u8bc1\u548c\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5728Frobenius\u8303\u6570\u4e0b\u8ba4\u8bc1Ising\u54c8\u5bc6\u987f\u91cf\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u4ee5\u53ca\u5b66\u4e60Ising Gibbs\u6001\u7684\u6837\u672c\u548c\u65f6\u95f4\u9ad8\u6548\u65b9\u6cd5\uff0c\u5e76\u5c06\u7ed3\u679c\u63a8\u5e7f\u5230\u4e00\u822ck-\u5c40\u57df\u54c8\u5bc6\u987f\u91cf\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50Ising\u54c8\u5bc6\u987f\u91cf\u7684\u8ba4\u8bc1\u548c\u5b66\u4e60\u95ee\u9898\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u6837\u672c\u590d\u6742\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u9488\u5bf9Gibbs\u6001\u5b66\u4e60\u4e2d\u7684\u6307\u6570\u6837\u672c\u590d\u6742\u5ea6\u95ee\u9898\u3002", "method": "\u4f7f\u7528Bonami\u5f15\u7406\u8fdb\u884c\u5085\u91cc\u53f6\u5206\u6790\uff0c\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u65f6\u95f4\u6f14\u5316\u7b97\u5b50\u7684\u8ba4\u8bc1\u7b97\u6cd5\uff0c\u4ee5\u53ca\u5b66\u4e60Ising Gibbs\u6001\u7684\u8ff9\u8303\u6570\u65b9\u6cd5\uff0c\u7b97\u6cd5\u5728\u6837\u672c\u548c\u65f6\u95f4\u590d\u6742\u5ea6\u4e0a\u5747\u8fbe\u5230\u9ad8\u6548\u3002", "result": "\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u6700\u4f18\u7684\u54c8\u5bc6\u987f\u91cf\u8ba4\u8bc1\u7b97\u6cd5\uff08O~(1/\u03b5)\u65f6\u95f4\u6f14\u5316\uff09\uff0c\u89e3\u51b3\u4e86Gibbs\u6001\u5b66\u4e60\u7684\u6307\u6570\u6837\u672c\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u6837\u672c\u548c\u65f6\u95f4\u9ad8\u6548\u7684Gibbs\u6001\u8ba4\u8bc1\u7b97\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u91cf\u5b50Ising\u54c8\u5bc6\u987f\u91cf\u8ba4\u8bc1\u548cGibbs\u6001\u5b66\u4e60\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u76f8\u5173\u9886\u57df\u7684\u5173\u952e\u95ee\u9898\uff0c\u5e76\u5c06\u65b9\u6cd5\u6210\u529f\u63a8\u5e7f\u5230\u66f4\u4e00\u822c\u7684k-\u5c40\u57df\u54c8\u5bc6\u987f\u91cf\u60c5\u5f62\u3002"}}
{"id": "2509.10291", "pdf": "https://arxiv.org/pdf/2509.10291", "abs": "https://arxiv.org/abs/2509.10291", "authors": ["Salih Toprak", "Muge Erel-Ozcevik"], "title": "Proof of AutoML: SDN based Secure Energy Trading with Blockchain in Disaster Case", "categories": ["cs.LG", "cs.NI"], "comment": "6 pages, 3 figures, 7th International Conference on Blockchain\n  Computing and Applications (BCCA 2025), \\c{opyright}2025 IEEE", "summary": "In disaster scenarios where conventional energy infrastructure is\ncompromised, secure and traceable energy trading between solar-powered\nhouseholds and mobile charging units becomes a necessity. To ensure the\nintegrity of such transactions over a blockchain network, robust and\nunpredictable nonce generation is vital. This study proposes an SDN-enabled\narchitecture where machine learning regressors are leveraged not for their\naccuracy, but for their potential to generate randomized values suitable as\nnonce candidates. Therefore, it is newly called Proof of AutoML. Here, SDN\nallows flexible control over data flows and energy routing policies even in\nfragmented or degraded networks, ensuring adaptive response during emergencies.\nUsing a 9000-sample dataset, we evaluate five AutoML-selected regression models\n- Gradient Boosting, LightGBM, Random Forest, Extra Trees, and K-Nearest\nNeighbors - not by their prediction accuracy, but by their ability to produce\ndiverse and non-deterministic outputs across shuffled data inputs. Randomness\nanalysis reveals that Random Forest and Extra Trees regressors exhibit complete\ndependency on randomness, whereas Gradient Boosting, K-Nearest Neighbors and\nLightGBM show strong but slightly lower randomness scores (97.6%, 98.8% and\n99.9%, respectively). These findings highlight that certain machine learning\nmodels, particularly tree-based ensembles, may serve as effective and\nlightweight nonce generators within blockchain-secured, SDN-based energy\ntrading infrastructures resilient to disaster conditions.", "AI": {"tldr": "\u63d0\u51faProof of AutoML\u67b6\u6784\uff0c\u5229\u7528\u673a\u5668\u5b66\u4e60\u56de\u5f52\u5668\u751f\u6210\u968f\u673a\u6570\u4f5c\u4e3a\u533a\u5757\u94fenonce\uff0c\u7528\u4e8e\u707e\u96be\u573a\u666f\u4e0b\u592a\u9633\u80fd\u5bb6\u5ead\u4e0e\u79fb\u52a8\u5145\u7535\u5355\u5143\u4e4b\u95f4\u7684\u5b89\u5168\u80fd\u6e90\u4ea4\u6613", "motivation": "\u5728\u707e\u96be\u573a\u666f\u4e2d\u4f20\u7edf\u80fd\u6e90\u57fa\u7840\u8bbe\u65bd\u53d7\u635f\u65f6\uff0c\u9700\u8981\u786e\u4fdd\u592a\u9633\u80fd\u5bb6\u5ead\u4e0e\u79fb\u52a8\u5145\u7535\u5355\u5143\u4e4b\u95f4\u80fd\u6e90\u4ea4\u6613\u7684\u5b89\u5168\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\uff0c\u800c\u533a\u5757\u94fe\u7f51\u7edc\u9700\u8981\u5f3a\u5927\u7684\u968f\u673anonce\u751f\u6210\u673a\u5236", "method": "\u91c7\u7528SDN\u4f7f\u80fd\u67b6\u6784\uff0c\u5229\u7528\u4e94\u79cdAutoML\u9009\u62e9\u7684\u56de\u5f52\u6a21\u578b\uff08\u68af\u5ea6\u63d0\u5347\u3001LightGBM\u3001\u968f\u673a\u68ee\u6797\u3001\u989d\u5916\u6811\u548cK\u8fd1\u90bb\uff09\uff0c\u901a\u8fc79000\u6837\u672c\u6570\u636e\u96c6\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u751f\u6210\u968f\u673a\u8f93\u51fa\u7684\u80fd\u529b\u800c\u975e\u9884\u6d4b\u7cbe\u5ea6", "result": "\u968f\u673a\u6027\u5206\u6790\u663e\u793a\u968f\u673a\u68ee\u6797\u548c\u989d\u5916\u6811\u56de\u5f52\u5668\u8868\u73b0\u51fa\u5b8c\u5168\u7684\u968f\u673a\u6027\u4f9d\u8d56\uff0c\u68af\u5ea6\u63d0\u5347\u3001K\u8fd1\u90bb\u548cLightGBM\u5206\u522b\u8fbe\u523097.6%\u300198.8%\u548c99.9%\u7684\u968f\u673a\u6027\u5206\u6570", "conclusion": "\u67d0\u4e9b\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7279\u522b\u662f\u57fa\u4e8e\u6811\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\u8f7b\u91cf\u7ea7nonce\u751f\u6210\u5668\uff0c\u7528\u4e8e\u6784\u5efa\u6297\u707e\u96be\u7684\u533a\u5757\u94fe\u5b89\u5168SDN\u80fd\u6e90\u4ea4\u6613\u57fa\u7840\u8bbe\u65bd"}}
{"id": "2509.10236", "pdf": "https://arxiv.org/pdf/2509.10236", "abs": "https://arxiv.org/abs/2509.10236", "authors": ["Mingyi Li", "Junmin Xiao", "Siyan Chen", "Hui Ma", "Xi Chen", "Peihua Bao", "Liang Yuan", "Guangming Tan"], "title": "Stencil-Lifting: Hierarchical Recursive Lifting System for Extracting Summary of Stencil Kernel in Legacy Codes", "categories": ["cs.SE", "cs.PF", "cs.PL"], "comment": "33 pages, 12 figures. Submitted to OOPSLA2'25", "summary": "We introduce Stencil-Lifting, a novel system for automatically converting\nstencil kernels written in low-level languages in legacy code into semantically\nequivalent Domain-Specific Language (DSL) implementations. Targeting the\nefficiency bottlenecks of existing verified lifting systems, Stencil-Lifting\nachieves scalable stencil kernel abstraction through two key innovations.\nFirst, we propose a hierarchical recursive lifting theory that represents\nstencil kernels, structured as nested loops, using invariant subgraphs, which\nare customized data dependency graphs that capture loop-carried computation and\nstructural invariants. Each vertex in the invariant subgraph is associated with\na predicate-based summary, encoding its computational semantics. By enforcing\nself-consistency across these summaries, Stencil-Lifting ensures the derivation\nof correct loop invariants and postconditions for nested loops, eliminating the\nneed for external verification. Second, we develop a hierarchical recursive\nlifting algorithm that guarantees termination through a convergent recursive\nprocess, avoiding the inefficiencies of search-based synthesis. The algorithm\nefficiently derives the valid summaries of stencil kernels, and its\ncompleteness is formally proven. We evaluate Stencil-Lifting on diverse stencil\nbenchmarks from two different suites and on four real-world applications.\nExperimental results demonstrate that Stencil-Lifting achieves 31.62$\\times$\nand 5.8$\\times$ speedups compared to the state-of-the-art verified lifting\nsystems STNG and Dexter, respectively, while maintaining full semantic\nequivalence. Our work significantly enhances the translation efficiency of\nlow-level stencil kernels to DSL implementations, effectively bridging the gap\nbetween legacy optimization techniques and modern DSL-based paradigms.", "AI": {"tldr": "Stencil-Lifting\u662f\u4e00\u4e2a\u81ea\u52a8\u5c06\u4f4e\u7ea7\u8bed\u8a00\u7f16\u5199\u7684\u6a21\u677f\u5185\u6838\u8f6c\u6362\u4e3a\u7b49\u6548DSL\u5b9e\u73b0\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u5c42\u9012\u5f52\u63d0\u5347\u7406\u8bba\u548c\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u6548\u8f6c\u6362\uff0c\u6bd4\u73b0\u6709\u7cfb\u7edf\u5feb31.62\u500d\u548c5.8\u500d", "motivation": "\u9488\u5bf9\u73b0\u6709\u9a8c\u8bc1\u63d0\u5347\u7cfb\u7edf\u6548\u7387\u74f6\u9888\uff0c\u89e3\u51b3\u5c06\u9057\u7559\u4ee3\u7801\u4e2d\u7684\u4f4e\u7ea7\u6a21\u677f\u5185\u6838\u8f6c\u6362\u4e3a\u73b0\u4ee3DSL\u5b9e\u73b0\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898", "method": "\u63d0\u51fa\u5206\u5c42\u9012\u5f52\u63d0\u5347\u7406\u8bba\uff0c\u4f7f\u7528\u4e0d\u53d8\u5b50\u56fe\u8868\u793a\u6a21\u677f\u5185\u6838\uff0c\u901a\u8fc7\u8c13\u8bcd\u6458\u8981\u7f16\u7801\u8ba1\u7b97\u8bed\u4e49\uff1b\u5f00\u53d1\u5206\u5c42\u9012\u5f52\u63d0\u5347\u7b97\u6cd5\uff0c\u4fdd\u8bc1\u7ec8\u6b62\u6027\u548c\u5b8c\u6574\u6027", "result": "\u5728\u4e24\u4e2a\u4e0d\u540c\u57fa\u51c6\u5957\u4ef6\u548c\u56db\u4e2a\u5b9e\u9645\u5e94\u7528\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4STNG\u548cDexter\u7cfb\u7edf\u5206\u522b\u5b9e\u73b031.62\u500d\u548c5.8\u500d\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u5b8c\u5168\u8bed\u4e49\u7b49\u4ef7", "conclusion": "\u663e\u8457\u63d0\u9ad8\u4e86\u4f4e\u7ea7\u6a21\u677f\u5185\u6838\u5230DSL\u5b9e\u73b0\u7684\u8f6c\u6362\u6548\u7387\uff0c\u6709\u6548\u5f25\u5408\u4e86\u4f20\u7edf\u4f18\u5316\u6280\u672f\u4e0e\u73b0\u4ee3DSL\u8303\u5f0f\u4e4b\u95f4\u7684\u5dee\u8ddd"}}
{"id": "2509.09838", "pdf": "https://arxiv.org/pdf/2509.09838", "abs": "https://arxiv.org/abs/2509.09838", "authors": ["Reza Asad", "Reza Babanezhad", "Sharan Vaswani"], "title": "Revisiting Actor-Critic Methods in Discrete Action Off-Policy Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Value-based approaches such as DQN are the default methods for off-policy\nreinforcement learning with discrete-action environments such as Atari. Common\npolicy-based methods are either on-policy and do not effectively learn from\noff-policy data (e.g. PPO), or have poor empirical performance in the\ndiscrete-action setting (e.g. SAC). Consequently, starting from discrete SAC\n(DSAC), we revisit the design of actor-critic methods in this setting. First,\nwe determine that the coupling between the actor and critic entropy is the\nprimary reason behind the poor performance of DSAC. We demonstrate that by\nmerely decoupling these components, DSAC can have comparable performance as\nDQN. Motivated by this insight, we introduce a flexible off-policy actor-critic\nframework that subsumes DSAC as a special case. Our framework allows using an\nm-step Bellman operator for the critic update, and enables combining standard\npolicy optimization methods with entropy regularization to instantiate the\nresulting actor objective. Theoretically, we prove that the proposed methods\ncan guarantee convergence to the optimal regularized value function in the\ntabular setting. Empirically, we demonstrate that these methods can approach\nthe performance of DQN on standard Atari games, and do so even without entropy\nregularization or explicit exploration.", "AI": {"tldr": "\u8be5\u8bba\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86\u79bb\u6563\u52a8\u4f5c\u73af\u5883\u4e2d\u7684actor-critic\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026actor\u548ccritic\u7684\u71b5\u9879\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79bb\u6563SAC\u7684\u6027\u80fd\uff0c\u4f7f\u5176\u5728Atari\u6e38\u620f\u4e2d\u8fbe\u5230\u4e0eDQN\u76f8\u5f53\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u503c\u7684\u65b9\u6cd5\uff08\u5982DQN\uff09\u5728\u79bb\u6563\u52a8\u4f5c\u73af\u5883\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u800c\u57fa\u4e8e\u7b56\u7565\u7684\u65b9\u6cd5\u8981\u4e48\u65e0\u6cd5\u6709\u6548\u5229\u7528\u79bb\u7b56\u7565\u6570\u636e\uff08\u5982PPO\uff09\uff0c\u8981\u4e48\u5728\u79bb\u6563\u52a8\u4f5c\u8bbe\u7f6e\u4e2d\u8868\u73b0\u4e0d\u4f73\uff08\u5982SAC\uff09\u3002\u79bb\u6563SAC\uff08DSAC\uff09\u6027\u80fd\u8f83\u5dee\u7684\u4e3b\u8981\u539f\u56e0\u662factor\u548ccritic\u71b5\u9879\u7684\u8026\u5408\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7075\u6d3b\u7684\u79bb\u7b56\u7565actor-critic\u6846\u67b6\uff0c\u89e3\u8026\u4e86actor\u548ccritic\u7684\u71b5\u9879\uff0c\u5141\u8bb8\u4f7f\u7528m\u6b65Bellman\u7b97\u5b50\u8fdb\u884ccritic\u66f4\u65b0\uff0c\u5e76\u5c06\u6807\u51c6\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\u4e0e\u71b5\u6b63\u5219\u5316\u76f8\u7ed3\u5408\u6765\u5b9e\u4f8b\u5316actor\u76ee\u6807\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u5728\u8868\u683c\u8bbe\u7f6e\u4e2d\u8be5\u65b9\u6cd5\u53ef\u4ee5\u4fdd\u8bc1\u6536\u655b\u5230\u6700\u4f18\u6b63\u5219\u5316\u503c\u51fd\u6570\u3002\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u53ef\u4ee5\u5728\u6807\u51c6Atari\u6e38\u620f\u4e2d\u63a5\u8fd1DQN\u7684\u6027\u80fd\uff0c\u751a\u81f3\u5728\u6ca1\u6709\u71b5\u6b63\u5219\u5316\u6216\u663e\u5f0f\u63a2\u7d22\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u3002", "conclusion": "\u901a\u8fc7\u89e3\u8026actor\u548ccritic\u7684\u71b5\u9879\uff0c\u79bb\u6563\u52a8\u4f5c\u73af\u5883\u4e2d\u7684actor-critic\u65b9\u6cd5\u53ef\u4ee5\u8fbe\u5230\u4e0e\u503c\u57fa\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u4e3a\u79bb\u6563\u52a8\u4f5cRL\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10361", "pdf": "https://arxiv.org/pdf/2509.10361", "abs": "https://arxiv.org/abs/2509.10361", "authors": ["Michelle D\u00f6ring", "Jan Fehse", "Tobias Friedrich", "Paula Marten", "Niklas Mohrin", "Kirill Simonov", "Farehe Soheil", "Jakob Timm", "Shaily Verma"], "title": "Parameterized Complexity of Vehicle Routing", "categories": ["cs.CC", "cs.DS"], "comment": "IPEC 2025", "summary": "The Vehicle Routing Problem (VRP) is a popular generalization of the\nTraveling Salesperson Problem. Instead of one salesperson traversing the entire\nweighted, undirected graph $G$, there are $k$ vehicles available to jointly\ncover the set of clients $C \\subseteq V(G)$. Every vehicle must start at one of\nthe depot vertices $D \\subseteq V(G)$ and return to its start. Capacitated\nVehicle Routing (CVRP) additionally restricts the route of each vehicle by\nlimiting the number of clients it can cover, the distance it can travel, or\nboth.\n  In this work, we study the complexity of VRP and the three variants of CVRP\nfor several parameterizations, in particular focusing on the treewidth of $G$.\nWe present an FPT algorithm for VRP parameterized by treewidth. For CVRP, we\nprove paraNP- and $W[\\cdot]$-hardness for various parameterizations, including\ntreewidth, thereby rendering the existence of FPT algorithms unlikely. In turn,\nwe provide an XP algorithm for CVRP when parameterized by both treewidth and\nthe vehicle capacity.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8f66\u8f86\u8def\u5f84\u95ee\u9898(VRP)\u53ca\u5176\u53d8\u79cd\u5728\u6811\u5bbd\u7b49\u53c2\u6570\u5316\u4e0b\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u63d0\u51fa\u4e86VRP\u7684FPT\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86CVRP\u7684paraNP-\u548cW[\u00b7]-\u56f0\u96be\u6027\uff0c\u5e76\u7ed9\u51fa\u4e86\u6811\u5bbd\u548c\u8f66\u8f86\u5bb9\u91cf\u53cc\u53c2\u6570\u5316\u7684XP\u7b97\u6cd5\u3002", "motivation": "\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u662f\u65c5\u884c\u5546\u95ee\u9898\u7684\u63a8\u5e7f\uff0c\u5728\u7269\u6d41\u548c\u8fd0\u8f93\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\u3002\u7814\u7a76\u4e0d\u540c\u53c2\u6570\u5316\u4e0b\u7684\u8ba1\u7b97\u590d\u6742\u6027\u6709\u52a9\u4e8e\u7406\u89e3\u95ee\u9898\u7684\u53ef\u89e3\u6027\u8fb9\u754c\uff0c\u4e3a\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u53c2\u6570\u590d\u6742\u6027\u7406\u8bba\u5206\u6790\uff0c\u7814\u7a76VRP\u548cCVRP\u5728\u6811\u5bbd\u7b49\u53c2\u6570\u4e0b\u7684\u8ba1\u7b97\u590d\u6742\u6027\u3002\u4f7f\u7528FPT\u3001paraNP-hardness\u3001W[\u00b7]-hardness\u7b49\u590d\u6742\u6027\u5206\u7c7b\u5de5\u5177\uff0c\u5e76\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7684\u7b97\u6cd5\u3002", "result": "1. \u5bf9VRP\u53c2\u6570\u5316\u6811\u5bbd\u63d0\u51fa\u4e86FPT\u7b97\u6cd5\uff1b2. \u8bc1\u660e\u4e86CVRP\u5728\u6811\u5bbd\u7b49\u53c2\u6570\u5316\u4e0b\u7684paraNP-\u548cW[\u00b7]-\u56f0\u96be\u6027\uff1b3. \u4e3a\u6811\u5bbd\u548c\u8f66\u8f86\u5bb9\u91cf\u53cc\u53c2\u6570\u5316\u7684CVRP\u63d0\u4f9b\u4e86XP\u7b97\u6cd5\u3002", "conclusion": "VRP\u5728\u6811\u5bbd\u53c2\u6570\u5316\u4e0b\u662f\u53ef\u5904\u7406\u7684(FPT)\uff0c\u800cCVRP\u5728\u76f8\u540c\u53c2\u6570\u5316\u4e0b\u6781\u4e0d\u53ef\u80fd\u5b58\u5728FPT\u7b97\u6cd5\uff0c\u4f46\u5728\u6811\u5bbd\u548c\u5bb9\u91cf\u53cc\u53c2\u6570\u5316\u4e0b\u5b58\u5728XP\u7b97\u6cd5\uff0c\u8fd9\u4e3a\u5b9e\u9645\u95ee\u9898\u6c42\u89e3\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2509.10357", "pdf": "https://arxiv.org/pdf/2509.10357", "abs": "https://arxiv.org/abs/2509.10357", "authors": ["Simon Svendsen", "Dimitri Gold", "Christian Rom", "Volker Pauli", "Vuokko Nurmela"], "title": "Realistic UE Antennas for 6G in the 3GPP Channel Model", "categories": ["eess.SP", "cs.NI", "94A05, 78M31", "C.2.1; I.6.5"], "comment": "This is a tutorial paper with the limit of 4500 words, 6\n  Fgiures/Tables and 15 refernces", "summary": "The transition to 6G has driven significant updates to the 3GPP channel\nmodel, particularly in modeling UE antennas and user-induced blockage for\nhandheld devices. The 3GPP Rel.19 revision of TR 38.901 introduces a more\nrealistic framework that captures directive antenna patterns, practical antenna\nplacements, polarization effects, and element-specific blockage. These updates\nare based on high-fidelity simulations and measurements of a reference\nsmartphone across multiple frequency ranges. By aligning link- and system-level\nsimulations with real-world device behavior, the new model enables more\naccurate evaluation of 6G technologies and supports consistent performance\nassessment across industry and research.", "AI": {"tldr": "3GPP Rel.19\u5bf9TR 38.901\u4fe1\u9053\u6a21\u578b\u8fdb\u884c\u4e86\u91cd\u8981\u66f4\u65b0\uff0c\u5f15\u5165\u4e86\u66f4\u771f\u5b9e\u7684UE\u5929\u7ebf\u5efa\u6a21\u548c\u7528\u6237\u906e\u6321\u6548\u5e94\uff0c\u57fa\u4e8e\u667a\u80fd\u624b\u673a\u7684\u9ad8\u4fdd\u771f\u4eff\u771f\u548c\u6d4b\u91cf\u6570\u636e\uff0c\u4e3a6G\u6280\u672f\u8bc4\u4f30\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u6027\u80fd\u5206\u6790\u6846\u67b6\u3002", "motivation": "6G\u53d1\u5c55\u9700\u8981\u66f4\u7cbe\u786e\u7684\u4fe1\u9053\u6a21\u578b\u6765\u8bc4\u4f30\u65b0\u6280\u672f\u6027\u80fd\uff0c\u7279\u522b\u662f\u624b\u6301\u8bbe\u5907\u7684UE\u5929\u7ebf\u7279\u6027\u548c\u7528\u6237\u906e\u6321\u6548\u5e94\uff0c\u73b0\u6709\u6a21\u578b\u5728\u8fd9\u4e9b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u9ad8\u4fdd\u771f\u4eff\u771f\u548c\u6d4b\u91cf\u53c2\u8003\u667a\u80fd\u624b\u673a\u5728\u591a\u4e2a\u9891\u6bb5\u7684\u6570\u636e\uff0c\u5efa\u7acb\u5305\u542b\u5b9a\u5411\u5929\u7ebf\u6a21\u5f0f\u3001\u5b9e\u9645\u5929\u7ebf\u5e03\u5c40\u3001\u6781\u5316\u6548\u5e94\u548c\u5355\u5143\u7279\u5b9a\u906e\u6321\u7684\u66f4\u771f\u5b9e\u6846\u67b6\u3002", "result": "\u65b0\u6a21\u578b\u4f7f\u94fe\u8def\u7ea7\u548c\u7cfb\u7edf\u7ea7\u4eff\u771f\u66f4\u8d34\u8fd1\u771f\u5b9e\u8bbe\u5907\u884c\u4e3a\uff0c\u652f\u6301\u8de8\u884c\u4e1a\u548c\u7814\u7a76\u7684\u4e00\u81f4\u6027\u80fd\u8bc4\u4f30\u3002", "conclusion": "\u66f4\u65b0\u540e\u76843GPP\u4fe1\u9053\u6a21\u578b\u4e3a6G\u6280\u672f\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u8bc4\u4f30\u57fa\u7840\uff0c\u63a8\u52a8\u4e86\u6807\u51c6\u5316\u548c\u4ea7\u4e1a\u53d1\u5c55\u3002"}}
{"id": "2509.10279", "pdf": "https://arxiv.org/pdf/2509.10279", "abs": "https://arxiv.org/abs/2509.10279", "authors": ["Pavel Plyusnin", "Aleksey Antonov", "Vasilii Ermakov", "Aleksandr Khaybriev", "Margarita Kikot", "Ilseyar Alimova", "Stanislav Moiseev"], "title": "Targeted Test Selection Approach in Continuous Integration", "categories": ["cs.SE", "cs.LG"], "comment": "Accepted at ICSME 2025", "summary": "In modern software development change-based testing plays a crucial role.\nHowever, as codebases expand and test suites grow, efficiently managing the\ntesting process becomes increasingly challenging, especially given the high\nfrequency of daily code commits. We propose Targeted Test Selection (T-TS), a\nmachine learning approach for industrial test selection. Our key innovation is\na data representation that represent commits as Bags-of-Words of changed files,\nincorporates cross-file and additional predictive features, and notably avoids\nthe use of coverage maps. Deployed in production, T-TS was comprehensively\nevaluated against industry standards and recent methods using both internal and\npublic datasets, measuring time efficiency and fault detection. On live\nindustrial data, T-TS selects only 15% of tests, reduces execution time by\n$5.9\\times$, accelerates the pipeline by $5.6\\times$, and detects over 95% of\ntest failures. The implementation is publicly available to support further\nresearch and practical adoption.", "AI": {"tldr": "T-TS\u662f\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u5de5\u4e1a\u6d4b\u8bd5\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u63d0\u4ea4\u8868\u793a\u4e3a\u53d8\u66f4\u6587\u4ef6\u7684\u8bcd\u888b\uff0c\u7ed3\u5408\u8de8\u6587\u4ef6\u548c\u9884\u6d4b\u7279\u5f81\uff0c\u65e0\u9700\u8986\u76d6\u7387\u6620\u5c04\uff0c\u5728\u5de5\u4e1a\u90e8\u7f72\u4e2d\u4ec5\u9009\u62e915%\u7684\u6d4b\u8bd5\uff0c\u6267\u884c\u65f6\u95f4\u51cf\u5c115.9\u500d\uff0c\u7ba1\u9053\u52a0\u901f5.6\u500d\uff0c\u6545\u969c\u68c0\u6d4b\u7387\u8d85\u8fc795%\u3002", "motivation": "\u968f\u7740\u4ee3\u7801\u5e93\u6269\u5c55\u548c\u6d4b\u8bd5\u5957\u4ef6\u589e\u957f\uff0c\u5728\u9ad8\u9891\u7387\u4ee3\u7801\u63d0\u4ea4\u7684\u60c5\u51b5\u4e0b\uff0c\u9ad8\u6548\u7ba1\u7406\u6d4b\u8bd5\u8fc7\u7a0b\u53d8\u5f97\u8d8a\u6765\u8d8a\u5177\u6709\u6311\u6218\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u9009\u62e9\u76f8\u5173\u6d4b\u8bd5\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u6d4b\u8bd5\u6548\u7387\u3002", "method": "\u63d0\u51faTargeted Test Selection (T-TS)\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5173\u952e\u521b\u65b0\u662f\u6570\u636e\u8868\u793a\u65b9\u5f0f\uff1a\u5c06\u63d0\u4ea4\u8868\u793a\u4e3a\u53d8\u66f4\u6587\u4ef6\u7684\u8bcd\u888b\uff0c\u5305\u542b\u8de8\u6587\u4ef6\u548c\u989d\u5916\u9884\u6d4b\u7279\u5f81\uff0c\u907f\u514d\u4f7f\u7528\u8986\u76d6\u7387\u6620\u5c04\u3002", "result": "\u5728\u5de5\u4e1a\u6570\u636e\u4e0a\uff0cT-TS\u4ec5\u9009\u62e915%\u7684\u6d4b\u8bd5\uff0c\u6267\u884c\u65f6\u95f4\u51cf\u5c115.9\u500d\uff0c\u7ba1\u9053\u52a0\u901f5.6\u500d\uff0c\u68c0\u6d4b\u8d85\u8fc795%\u7684\u6d4b\u8bd5\u6545\u969c\u3002\u65b9\u6cd5\u5728\u5185\u90e8\u548c\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u3002", "conclusion": "T-TS\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u6548\u7387\uff0c\u5b9e\u73b0\u516c\u5f00\u53ef\u7528\u4ee5\u652f\u6301\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2509.09843", "pdf": "https://arxiv.org/pdf/2509.09843", "abs": "https://arxiv.org/abs/2509.09843", "authors": ["Jiajun Shen", "Yufei Jin", "Yi He", "Xingquan Zhu"], "title": "HGEN: Heterogeneous Graph Ensemble Networks", "categories": ["cs.LG", "cs.AI"], "comment": "The paper is in proceedings of the 34th IJCAI Conference, 2025", "summary": "This paper presents HGEN that pioneers ensemble learning for heterogeneous\ngraphs. We argue that the heterogeneity in node types, nodal features, and\nlocal neighborhood topology poses significant challenges for ensemble learning,\nparticularly in accommodating diverse graph learners. Our HGEN framework\nensembles multiple learners through a meta-path and transformation-based\noptimization pipeline to uplift classification accuracy. Specifically, HGEN\nuses meta-path combined with random dropping to create Allele Graph Neural\nNetworks (GNNs), whereby the base graph learners are trained and aligned for\nlater ensembling. To ensure effective ensemble learning, HGEN presents two key\ncomponents: 1) a residual-attention mechanism to calibrate allele GNNs of\ndifferent meta-paths, thereby enforcing node embeddings to focus on more\ninformative graphs to improve base learner accuracy, and 2) a\ncorrelation-regularization term to enlarge the disparity among embedding\nmatrices generated from different meta-paths, thereby enriching base learner\ndiversity. We analyze the convergence of HGEN and attest its higher\nregularization magnitude over simple voting. Experiments on five heterogeneous\nnetworks validate that HGEN consistently outperforms its state-of-the-art\ncompetitors by substantial margin.", "AI": {"tldr": "HGEN\u662f\u9996\u4e2a\u9488\u5bf9\u5f02\u8d28\u56fe\u7684\u96c6\u6210\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5143\u8def\u5f84\u548c\u968f\u673a\u4e22\u5f03\u521b\u5efa\u7b49\u4f4dGNN\uff0c\u5229\u7528\u6b8b\u5dee\u6ce8\u610f\u529b\u673a\u5236\u548c\u76f8\u5173\u6027\u6b63\u5219\u5316\u63d0\u5347\u5206\u7c7b\u7cbe\u5ea6", "motivation": "\u5f02\u8d28\u56fe\u4e2d\u8282\u70b9\u7c7b\u578b\u3001\u8282\u70b9\u7279\u5f81\u548c\u5c40\u90e8\u90bb\u57df\u62d3\u6251\u7684\u5f02\u8d28\u6027\u7ed9\u96c6\u6210\u5b66\u4e60\u5e26\u6765\u6311\u6218\uff0c\u9700\u8981\u9002\u5e94\u591a\u6837\u5316\u7684\u56fe\u5b66\u4e60\u5668", "method": "\u4f7f\u7528\u5143\u8def\u5f84\u7ed3\u5408\u968f\u673a\u4e22\u5f03\u521b\u5efa\u7b49\u4f4dGNN\uff0c\u91c7\u7528\u6b8b\u5dee\u6ce8\u610f\u529b\u673a\u5236\u6821\u51c6\u4e0d\u540c\u5143\u8def\u5f84\u7684\u7b49\u4f4dGNN\uff0c\u5e76\u901a\u8fc7\u76f8\u5173\u6027\u6b63\u5219\u5316\u9879\u589e\u5927\u4e0d\u540c\u5143\u8def\u5f84\u751f\u6210\u5d4c\u5165\u77e9\u9635\u7684\u5dee\u5f02\u6027", "result": "\u5728\u4e94\u4e2a\u5f02\u8d28\u7f51\u7edc\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1HGEN\u59cb\u7ec8\u4ee5\u663e\u8457\u4f18\u52bf\u8d85\u8d8a\u6700\u5148\u8fdb\u7684\u7ade\u4e89\u5bf9\u624b", "conclusion": "HGEN\u901a\u8fc7\u6709\u6548\u7684\u96c6\u6210\u5b66\u4e60\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5f02\u8d28\u56fe\u5b66\u4e60\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u5347\u4e86\u5206\u7c7b\u51c6\u786e\u6027"}}
{"id": "2509.10402", "pdf": "https://arxiv.org/pdf/2509.10402", "abs": "https://arxiv.org/abs/2509.10402", "authors": ["Suzhen Zhong", "Ying Zou", "Bram Adams"], "title": "Developer-LLM Conversations: An Empirical Study of Interactions and Generated Code Quality", "categories": ["cs.SE", "D.2.0; D.2.7"], "comment": null, "summary": "Large Language Models (LLMs) are becoming integral to modern software\ndevelopment workflows, assisting developers with code generation, API\nexplanation, and iterative problem-solving through natural language\nconversations. Despite widespread adoption, there is limited understanding of\nhow developers interact with LLMs in practice and how these conversational\ndynamics influence task outcomes, code quality, and software engineering\nworkflows. To address this, we leverage CodeChat, a large dataset comprising\n82,845 real-world developer-LLM conversations, containing 368,506 code snippets\ngenerated across over 20 programming languages, derived from the WildChat\ndataset. We find that LLM responses are substantially longer than developer\nprompts, with a median token-length ratio of 14:1. Multi-turn conversations\naccount for 68% of the dataset and often evolve due to shifting requirements,\nincomplete prompts, or clarification requests. Topic analysis identifies web\ndesign (9.6% of conversations) and neural network training (8.7% of\nconversations) as the most frequent LLM-assisted tasks. Evaluation across five\nlanguages (i.e., Python, JavaScript, C++, Java, and C#) reveals prevalent and\nlanguage-specific issues in LLM-generated code: generated Python and JavaScript\ncode often include undefined variables (83.4% and 75.3% of code snippets,\nrespectively); Java code lacks required comments (75.9%); C++ code frequently\nomits headers (41.1%) and C# code shows unresolved namespaces (49.2%). During a\nconversation, syntax and import errors persist across turns; however,\ndocumentation quality in Java improves by up to 14.7%, and import handling in\nPython improves by 3.7% over 5 turns. Prompts that point out mistakes in code\ngenerated in prior turns and explicitly request a fix are most effective for\nresolving errors.", "AI": {"tldr": "\u57fa\u4e8e82,845\u4e2a\u771f\u5b9e\u5f00\u53d1\u8005\u4e0eLLM\u5bf9\u8bdd\u7684\u5206\u6790\u663e\u793a\uff0cLLM\u54cd\u5e94\u6bd4\u5f00\u53d1\u8005\u63d0\u793a\u957f14\u500d\uff0c68%\u4e3a\u591a\u8f6e\u5bf9\u8bdd\uff0c\u4ee3\u7801\u751f\u6210\u5b58\u5728\u8bed\u8a00\u7279\u5b9a\u7684\u8d28\u91cf\u95ee\u9898\uff0c\u4f46\u901a\u8fc7\u660e\u786e\u6307\u9519\u548c\u8bf7\u6c42\u4fee\u590d\u53ef\u4ee5\u6709\u6548\u6539\u5584\u4ee3\u7801\u8d28\u91cf\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5f00\u53d1\u8005\u5b9e\u9645\u4ea4\u4e92\u65b9\u5f0f\u548c\u5bf9\u8bdd\u52a8\u6001\u5982\u4f55\u5f71\u54cd\u4efb\u52a1\u7ed3\u679c\u3001\u4ee3\u7801\u8d28\u91cf\u548c\u5de5\u4f5c\u6d41\u7684\u6df1\u5165\u7406\u89e3\u3002", "method": "\u5229\u7528CodeChat\u6570\u636e\u96c6\uff08\u5305\u542b82,845\u4e2a\u771f\u5b9e\u5f00\u53d1\u8005-LLM\u5bf9\u8bdd\uff0c368,506\u4e2a\u4ee3\u7801\u7247\u6bb5\uff0c\u8986\u76d620+\u7f16\u7a0b\u8bed\u8a00\uff09\uff0c\u8fdb\u884c\u5bf9\u8bdd\u957f\u5ea6\u5206\u6790\u3001\u8bdd\u9898\u5206\u7c7b\u548c\u4e94\u79cd\u4e3b\u8981\u7f16\u7a0b\u8bed\u8a00\u7684\u4ee3\u7801\u8d28\u91cf\u8bc4\u4f30\u3002", "result": "\u53d1\u73b0LLM\u54cd\u5e94\u663e\u8457\u957f\u4e8e\u5f00\u53d1\u8005\u63d0\u793a\uff0814:1\u6bd4\u4f8b\uff09\uff0c\u591a\u8f6e\u5bf9\u8bdd\u536068%\uff1b\u4e0d\u540c\u8bed\u8a00\u5b58\u5728\u7279\u5b9a\u95ee\u9898\uff1aPython/JavaScript\u672a\u5b9a\u4e49\u53d8\u91cf\uff0883.4%/75.3%\uff09\u3001Java\u7f3a\u5c11\u6ce8\u91ca\uff0875.9%\uff09\u3001C++\u7f3a\u5c11\u5934\u6587\u4ef6\uff0841.1%\uff09\u3001C#\u672a\u89e3\u6790\u547d\u540d\u7a7a\u95f4\uff0849.2%\uff09\uff1b\u4f46\u901a\u8fc7\u591a\u8f6e\u4ea4\u4e92\uff0cJava\u6587\u6863\u8d28\u91cf\u63d0\u534714.7%\uff0cPython\u5bfc\u5165\u5904\u7406\u6539\u55843.7%\u3002", "conclusion": "\u5f00\u53d1\u8005\u4e0eLLM\u7684\u5bf9\u8bdd\u901a\u5e38\u662f\u8fed\u4ee3\u548c\u52a8\u6001\u7684\uff0c\u660e\u786e\u6307\u51fa\u73b0\u6709\u4ee3\u7801\u9519\u8bef\u5e76\u8bf7\u6c42\u4fee\u590d\u7684\u63d0\u793a\u6700\u6709\u6548\uff0c\u591a\u8f6e\u5bf9\u8bdd\u53ef\u4ee5\u9010\u6b65\u6539\u5584\u4ee3\u7801\u8d28\u91cf\uff0c\u4f46\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u9700\u8981\u9488\u5bf9\u6027\u7684\u8d28\u91cf\u5173\u6ce8\u70b9\u3002"}}
{"id": "2509.09864", "pdf": "https://arxiv.org/pdf/2509.09864", "abs": "https://arxiv.org/abs/2509.09864", "authors": ["Jenny Y. Huang", "Mehul Damani", "Yousef El-Kurdi", "Ramon Astudillo", "Wei Sun"], "title": "Latency and Token-Aware Test-Time Compute", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Inference-time scaling has emerged as a powerful way to improve large\nlanguage model (LLM) performance by generating multiple candidate responses and\nselecting among them. However, existing work on dynamic allocation for\ntest-time compute typically considers only parallel generation methods such as\nbest-of-N, overlooking incremental decoding methods like beam search, and has\nlargely ignored latency, focusing only on token usage. We formulate\ninference-time scaling as a problem of dynamic compute allocation and method\nselection, where the system must decide which strategy to apply and how much\ncompute to allocate on a per-query basis. Our framework explicitly incorporates\nboth token cost and wall-clock latency, the latter being critical for user\nexperience and particularly for agentic workflows where models must issue\nmultiple queries efficiently. Experiments on reasoning benchmarks show that our\napproach consistently outperforms static strategies, achieving favorable\naccuracy-cost trade-offs while remaining practical for deployment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u52a8\u6001\u8ba1\u7b97\u5206\u914d\u6846\u67b6\uff0c\u5728\u63a8\u7406\u65f6\u6839\u636e\u67e5\u8be2\u9700\u6c42\u9009\u62e9\u6700\u4f73\u751f\u6210\u7b56\u7565\uff08\u5982beam search\u6216best-of-N\uff09\uff0c\u540c\u65f6\u8003\u8651token\u6210\u672c\u548c\u5ef6\u8fdf\u65f6\u95f4\uff0c\u4ee5\u4f18\u5316LLM\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u65f6\u6269\u5c55\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5e76\u884c\u751f\u6210\u548ctoken\u4f7f\u7528\uff0c\u5ffd\u7565\u4e86\u589e\u91cf\u89e3\u7801\u65b9\u6cd5\u548c\u5ef6\u8fdf\u65f6\u95f4\uff0c\u800c\u5ef6\u8fdf\u5bf9\u7528\u6237\u4f53\u9a8c\u548c\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6784\u5efa\u52a8\u6001\u8ba1\u7b97\u5206\u914d\u548c\u7b56\u7565\u9009\u62e9\u6846\u67b6\uff0c\u5728\u6bcf\u67e5\u8be2\u57fa\u7840\u4e0a\u51b3\u5b9a\u5e94\u7528\u54ea\u79cd\u751f\u6210\u7b56\u7565\u4ee5\u53ca\u5206\u914d\u591a\u5c11\u8ba1\u7b97\u8d44\u6e90\uff0c\u540c\u65f6\u663e\u5f0f\u8003\u8651token\u6210\u672c\u548cwall-clock\u5ef6\u8fdf\u3002", "result": "\u5728\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6301\u7eed\u4f18\u4e8e\u9759\u6001\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u826f\u597d\u7684\u51c6\u786e\u7387-\u6210\u672c\u6743\u8861\uff0c\u4e14\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u53ef\u884c\u6027\u3002", "conclusion": "\u52a8\u6001\u8ba1\u7b97\u5206\u914d\u6846\u67b6\u80fd\u591f\u6709\u6548\u4f18\u5316LLM\u63a8\u7406\u6027\u80fd\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u548c\u5ef6\u8fdf\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u9ad8\u6548\u591a\u67e5\u8be2\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u3002"}}
{"id": "2509.09775", "pdf": "https://arxiv.org/pdf/2509.09775", "abs": "https://arxiv.org/abs/2509.09775", "authors": ["Aleksandr Boldachev"], "title": "Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture", "categories": ["cs.AI", "cs.CL", "cs.FL", "cs.SE"], "comment": "22 pages, 6 figures", "summary": "This paper presents boldsea, Boldachev's semantic-event approach -- an\narchitecture for modeling complex dynamic systems using executable ontologies\n-- semantic models that act as dynamic structures, directly controlling process\nexecution. We demonstrate that integrating event semantics with a dataflow\narchitecture addresses the limitations of traditional Business Process\nManagement (BPM) systems and object-oriented semantic technologies. The paper\npresents the formal BSL (boldsea Semantic Language), including its BNF grammar,\nand outlines the boldsea-engine's architecture, which directly interprets\nsemantic models as executable algorithms without compilation. It enables the\nmodification of event models at runtime, ensures temporal transparency, and\nseamlessly merges data and business logic within a unified semantic framework.", "AI": {"tldr": "Boldsea\u662f\u4e00\u4e2a\u57fa\u4e8e\u8bed\u4e49\u4e8b\u4ef6\u65b9\u6cd5\u7684\u67b6\u6784\uff0c\u4f7f\u7528\u53ef\u6267\u884c\u672c\u4f53\u6765\u5efa\u6a21\u590d\u6742\u52a8\u6001\u7cfb\u7edf\uff0c\u5c06\u4e8b\u4ef6\u8bed\u4e49\u4e0e\u6570\u636e\u6d41\u67b6\u6784\u7ed3\u5408\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfBPM\u7cfb\u7edf\u548c\u9762\u5411\u5bf9\u8c61\u8bed\u4e49\u6280\u672f\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u4e1a\u52a1\u6d41\u7a0b\u7ba1\u7406(BPM)\u7cfb\u7edf\u548c\u9762\u5411\u5bf9\u8c61\u8bed\u4e49\u6280\u672f\u5728\u52a8\u6001\u7cfb\u7edf\u5efa\u6a21\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u80fd\u591f\u5b9e\u65f6\u4fee\u6539\u4e8b\u4ef6\u6a21\u578b\u5e76\u7edf\u4e00\u6570\u636e\u548c\u4e1a\u52a1\u903b\u8f91\u7684\u8bed\u4e49\u6846\u67b6\u3002", "method": "\u63d0\u51faBoldsea\u8bed\u4e49\u8bed\u8a00(BSL)\u53ca\u5176BNF\u8bed\u6cd5\uff0c\u8bbe\u8ba1boldsea-engine\u67b6\u6784\uff0c\u76f4\u63a5\u89e3\u91ca\u8bed\u4e49\u6a21\u578b\u4f5c\u4e3a\u53ef\u6267\u884c\u7b97\u6cd5\uff0c\u65e0\u9700\u7f16\u8bd1\u8fc7\u7a0b\u3002", "result": "\u5b9e\u73b0\u4e86\u8fd0\u884c\u65f6\u4fee\u6539\u4e8b\u4ef6\u6a21\u578b\u7684\u80fd\u529b\uff0c\u786e\u4fdd\u65f6\u95f4\u900f\u660e\u5ea6\uff0c\u5e76\u5728\u7edf\u4e00\u7684\u8bed\u4e49\u6846\u67b6\u5185\u65e0\u7f1d\u878d\u5408\u6570\u636e\u548c\u4e1a\u52a1\u903b\u8f91\u3002", "conclusion": "Boldsea\u67b6\u6784\u901a\u8fc7\u53ef\u6267\u884c\u672c\u4f53\u548c\u8bed\u4e49\u4e8b\u4ef6\u65b9\u6cd5\uff0c\u4e3a\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u6280\u672f\u7684\u9650\u5236\u3002"}}
{"id": "2509.09899", "pdf": "https://arxiv.org/pdf/2509.09899", "abs": "https://arxiv.org/abs/2509.09899", "authors": ["Christopher Eldred", "Fran\u00e7ois Gay-Balmaz", "Vakhtang Putkaradze"], "title": "Variational Neural Networks for Observable Thermodynamics (V-NOTS)", "categories": ["cs.LG"], "comment": "26 pages, 6 figures", "summary": "Much attention has recently been devoted to data-based computing of evolution\nof physical systems. In such approaches, information about data points from\npast trajectories in phase space is used to reconstruct the equations of motion\nand to predict future solutions that have not been observed before. However, in\nmany cases, the available data does not correspond to the variables that define\nthe system's phase space. We focus our attention on the important example of\ndissipative dynamical systems. In that case, the phase space consists of\ncoordinates, momenta and entropies; however, the momenta and entropies cannot,\nin general, be observed directly. To address this difficulty, we develop an\nefficient data-based computing framework based exclusively on observable\nvariables, by constructing a novel approach based on the \\emph{thermodynamic\nLagrangian}, and constructing neural networks that respect the thermodynamics\nand guarantees the non-decreasing entropy evolution. We show that our network\ncan provide an efficient description of phase space evolution based on a\nlimited number of data points and a relatively small number of parameters in\nthe system.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u89c2\u6d4b\u53d8\u91cf\u7684\u6570\u636e\u9a71\u52a8\u8ba1\u7b97\u6846\u67b6\uff0c\u7528\u4e8e\u63cf\u8ff0\u8017\u6563\u52a8\u529b\u7cfb\u7edf\u7684\u76f8\u7a7a\u95f4\u6f14\u5316\uff0c\u901a\u8fc7\u70ed\u529b\u5b66\u62c9\u683c\u6717\u65e5\u65b9\u6cd5\u548c\u795e\u7ecf\u7f51\u7edc\u6765\u4fdd\u8bc1\u70ed\u529b\u5b66\u7ea6\u675f\u548c\u71b5\u589e\u7279\u6027\u3002", "motivation": "\u8bb8\u591a\u7269\u7406\u7cfb\u7edf\u7684\u6f14\u5316\u8ba1\u7b97\u4f9d\u8d56\u4e8e\u76f8\u7a7a\u95f4\u6570\u636e\uff0c\u4f46\u5b9e\u9645\u4e2d\u53ef\u89c2\u6d4b\u7684\u53d8\u91cf\u5f80\u5f80\u4e0d\u5305\u542b\u5b8c\u6574\u7684\u76f8\u7a7a\u95f4\u4fe1\u606f\uff08\u5982\u52a8\u91cf\u548c\u71b5\uff09\uff0c\u7279\u522b\u662f\u5728\u8017\u6563\u52a8\u529b\u7cfb\u7edf\u4e2d\uff0c\u8fd9\u4e9b\u53d8\u91cf\u901a\u5e38\u65e0\u6cd5\u76f4\u63a5\u89c2\u6d4b\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u70ed\u529b\u5b66\u62c9\u683c\u6717\u65e5\u7684\u65b0\u578b\u65b9\u6cd5\uff0c\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u6765\u4fdd\u6301\u70ed\u529b\u5b66\u7ea6\u675f\uff0c\u786e\u4fdd\u71b5\u7684\u975e\u9012\u51cf\u6f14\u5316\uff0c\u4ec5\u4f7f\u7528\u53ef\u89c2\u6d4b\u53d8\u91cf\u8fdb\u884c\u76f8\u7a7a\u95f4\u6f14\u5316\u63cf\u8ff0\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u8be5\u7f51\u7edc\u80fd\u591f\u57fa\u4e8e\u6709\u9650\u7684\u6570\u636e\u70b9\u548c\u76f8\u5bf9\u8f83\u5c11\u7684\u7cfb\u7edf\u53c2\u6570\uff0c\u6709\u6548\u63cf\u8ff0\u76f8\u7a7a\u95f4\u6f14\u5316\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4ec5\u4f7f\u7528\u53ef\u89c2\u6d4b\u53d8\u91cf\u8fdb\u884c\u8017\u6563\u52a8\u529b\u7cfb\u7edf\u6f14\u5316\u8ba1\u7b97\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6846\u67b6\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5b8c\u6574\u76f8\u7a7a\u95f4\u4fe1\u606f\u7684\u9650\u5236\u3002"}}
{"id": "2509.09942", "pdf": "https://arxiv.org/pdf/2509.09942", "abs": "https://arxiv.org/abs/2509.09942", "authors": ["Lei Yu", "Jingyuan Zhang", "Xin Wang", "Jiajia Ma", "Li Yang", "Fengjun Zhang"], "title": "SmartCoder-R1: Towards Secure and Explainable Smart Contract Generation with Security-Aware Group Relative Policy Optimization", "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": null, "summary": "Smart contracts automate the management of high-value assets, where\nvulnerabilities can lead to catastrophic financial losses. This challenge is\namplified in Large Language Models (LLMs) by two interconnected failures: they\noperate as unauditable \"black boxes\" lacking a transparent reasoning process,\nand consequently, generate code riddled with critical security vulnerabilities.\nTo address both issues, we propose SmartCoder-R1 (based on Qwen2.5-Coder-7B), a\nnovel framework for secure and explainable smart contract generation. It begins\nwith Continual Pre-training (CPT) to specialize the model. We then apply Long\nChain-of-Thought Supervised Fine-Tuning (L-CoT SFT) on 7,998 expert-validated\nreasoning-and-code samples to train the model to emulate human security\nanalysis. Finally, to directly mitigate vulnerabilities, we employ\nSecurity-Aware Group Relative Policy Optimization (S-GRPO), a reinforcement\nlearning phase that refines the generation policy by optimizing a weighted\nreward signal for compilation success, security compliance, and format\ncorrectness. Evaluated against 17 baselines on a benchmark of 756 real-world\nfunctions, SmartCoder-R1 establishes a new state of the art, achieving top\nperformance across five key metrics: a ComPass of 87.70%, a VulRate of 8.60%, a\nSafeAval of 80.16%, a FuncRate of 53.84%, and a FullRate of 50.53%. This\nFullRate marks a 45.79% relative improvement over the strongest baseline,\nDeepSeek-R1. Crucially, its generated reasoning also excels in human\nevaluations, achieving high-quality ratings for Functionality (82.7%), Security\n(85.3%), and Clarity (90.7%).", "AI": {"tldr": "SmartCoder-R1\u662f\u4e00\u4e2a\u57fa\u4e8eQwen2.5-Coder-7B\u7684\u65b0\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u957f\u601d\u7ef4\u94fe\u76d1\u7763\u5fae\u8c03\u548c\u5b89\u5168\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u4e14\u53ef\u89e3\u91ca\u7684\u667a\u80fd\u5408\u7ea6\u751f\u6210\uff0c\u5728\u591a\u9879\u6307\u6807\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u667a\u80fd\u5408\u7ea6\u751f\u6210\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u4f5c\u4e3a\u4e0d\u53ef\u5ba1\u8ba1\u7684\"\u9ed1\u76d2\"\u7f3a\u4e4f\u900f\u660e\u63a8\u7406\u8fc7\u7a0b\uff0c\u4ee5\u53ca\u751f\u6210\u7684\u4ee3\u7801\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u53ef\u80fd\u5bfc\u81f4\u707e\u96be\u6027\u8d22\u52a1\u635f\u5931\u3002", "method": "1) \u6301\u7eed\u9884\u8bad\u7ec3(CPT)\u8fdb\u884c\u6a21\u578b\u4e13\u4e1a\u5316\uff1b2) \u57287,998\u4e2a\u4e13\u5bb6\u9a8c\u8bc1\u7684\u63a8\u7406-\u4ee3\u7801\u6837\u672c\u4e0a\u8fdb\u884c\u957f\u601d\u7ef4\u94fe\u76d1\u7763\u5fae\u8c03(L-CoT SFT)\uff1b3) \u4f7f\u7528\u5b89\u5168\u611f\u77e5\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(S-GRPO)\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\uff0c\u4f18\u5316\u7f16\u8bd1\u6210\u529f\u3001\u5b89\u5168\u5408\u89c4\u548c\u683c\u5f0f\u6b63\u786e\u7684\u52a0\u6743\u5956\u52b1\u4fe1\u53f7\u3002", "result": "\u5728756\u4e2a\u771f\u5b9e\u4e16\u754c\u51fd\u6570\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSmartCoder-R1\u572817\u4e2a\u57fa\u7ebf\u6a21\u578b\u4e2d\u8868\u73b0\u6700\u4f73\uff1aComPass 87.70%\u3001VulRate 8.60%\u3001SafeAval 80.16%\u3001FuncRate 53.84%\u3001FullRate 50.53%\uff08\u6bd4\u6700\u5f3a\u57fa\u7ebfDeepSeek-R1\u76f8\u5bf9\u63d0\u534745.79%\uff09\u3002\u4eba\u7c7b\u8bc4\u4f30\u663e\u793a\u5176\u63a8\u7406\u8d28\u91cf\u4f18\u79c0\uff1a\u529f\u80fd\u602782.7%\u3001\u5b89\u5168\u602785.3%\u3001\u6e05\u6670\u5ea690.7%\u3002", "conclusion": "SmartCoder-R1\u901a\u8fc7\u7ed3\u5408\u4e13\u4e1a\u5316\u9884\u8bad\u7ec3\u3001\u601d\u7ef4\u94fe\u5fae\u8c03\u548c\u5b89\u5168\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\uff0c\u6210\u529f\u89e3\u51b3\u4e86LLM\u5728\u667a\u80fd\u5408\u7ea6\u751f\u6210\u4e2d\u7684\u5b89\u5168\u6027\u548c\u53ef\u89e3\u91ca\u6027\u95ee\u9898\uff0c\u5efa\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\u6807\u51c6\u3002"}}
{"id": "2509.09926", "pdf": "https://arxiv.org/pdf/2509.09926", "abs": "https://arxiv.org/abs/2509.09926", "authors": ["Jiahao Chen", "Zhiyuan Huang", "Yurou Liu", "Bing Su"], "title": "LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Long-tailed learning has garnered increasing attention due to its wide\napplicability in real-world scenarios. Among existing approaches, Long-Tailed\nSemi-Supervised Learning (LTSSL) has emerged as an effective solution by\nincorporating a large amount of unlabeled data into the imbalanced labeled\ndataset. However, most prior LTSSL methods are designed to train models from\nscratch, which often leads to issues such as overconfidence and low-quality\npseudo-labels. To address these challenges, we extend LTSSL into the foundation\nmodel fine-tuning paradigm and propose a novel framework: LoFT (Long-tailed\nsemi-supervised learning via parameter-efficient Fine-Tuning). We demonstrate\nthat fine-tuned foundation models can generate more reliable pseudolabels,\nthereby benefiting imbalanced learning. Furthermore, we explore a more\npractical setting by investigating semi-supervised learning under open-world\nconditions, where the unlabeled data may include out-of-distribution (OOD)\nsamples. To handle this problem, we propose LoFT-OW (LoFT under Open-World\nscenarios) to improve the discriminative ability. Experimental results on\nmultiple benchmarks demonstrate that our method achieves superior performance\ncompared to previous approaches, even when utilizing only 1\\% of the unlabeled\ndata compared with previous works.", "AI": {"tldr": "\u63d0\u51fa\u4e86LoFT\u6846\u67b6\uff0c\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u6765\u89e3\u51b3\u957f\u5c3e\u534a\u76d1\u7763\u5b66\u4e60\u95ee\u9898\uff0c\u76f8\u6bd4\u4ece\u96f6\u8bad\u7ec3\u7684\u65b9\u6cd5\u80fd\u751f\u6210\u66f4\u53ef\u9760\u7684\u4f2a\u6807\u7b7e\uff0c\u5e76\u5728\u5f00\u653e\u4e16\u754c\u573a\u666f\u4e0b\u5904\u7406OOD\u6837\u672c\u3002", "motivation": "\u73b0\u6709\u7684\u957f\u5c3e\u534a\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u5927\u591a\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\u6a21\u578b\uff0c\u5bb9\u6613\u5bfc\u81f4\u8fc7\u81ea\u4fe1\u548c\u4f4e\u8d28\u91cf\u4f2a\u6807\u7b7e\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5229\u7528\u57fa\u7840\u6a21\u578b\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faLoFT\u6846\u67b6\uff0c\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u9884\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u6765\u751f\u6210\u66f4\u53ef\u9760\u7684\u4f2a\u6807\u7b7e\uff1b\u8fdb\u4e00\u6b65\u63d0\u51faLoFT-OW\u5904\u7406\u5f00\u653e\u4e16\u754c\u573a\u666f\u4e0b\u7684OOD\u6837\u672c\u95ee\u9898\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5373\u4f7f\u53ea\u4f7f\u75281%\u7684\u65e0\u6807\u7b7e\u6570\u636e\u4e5f\u80fd\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u957f\u5c3e\u534a\u76d1\u7763\u5b66\u4e60\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5f00\u653e\u4e16\u754c\u573a\u666f\u65f6\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2509.10320", "pdf": "https://arxiv.org/pdf/2509.10320", "abs": "https://arxiv.org/abs/2509.10320", "authors": ["Davide Corradini", "Mariano Ceccato", "Mohammad Ghafari"], "title": "Automated Testing of Broken Authentication Vulnerabilities in Web APIs with AuthREST", "categories": ["cs.CR", "cs.SE"], "comment": null, "summary": "We present AuthREST, an open-source security testing tool targeting broken\nauthentication, one of the most prevalent API security risks in the wild.\nAuthREST automatically tests web APIs for credential stuffing, password brute\nforcing, and unchecked token authenticity. Empirical results show that AuthREST\nis effective in improving web API security. Notably, it uncovered previously\nunknown authentication vulnerabilitiesin in four public APIs.", "AI": {"tldr": "AuthREST\u662f\u4e00\u4e2a\u5f00\u6e90\u5b89\u5168\u6d4b\u8bd5\u5de5\u5177\uff0c\u4e13\u6ce8\u4e8e\u68c0\u6d4bAPI\u8eab\u4efd\u9a8c\u8bc1\u6f0f\u6d1e\uff0c\u5305\u62ec\u51ed\u636e\u586b\u5145\u3001\u5bc6\u7801\u66b4\u529b\u7834\u89e3\u548c\u4ee4\u724c\u771f\u5b9e\u6027\u68c0\u67e5\u7b49\u95ee\u9898", "motivation": "\u9488\u5bf9API\u5b89\u5168\u4e2d\u6700\u666e\u904d\u7684\u98ce\u9669\u4e4b\u4e00\u2014\u2014\u8eab\u4efd\u9a8c\u8bc1\u6f0f\u6d1e\uff0c\u5f00\u53d1\u81ea\u52a8\u5316\u6d4b\u8bd5\u5de5\u5177\u4ee5\u63d0\u9ad8Web API\u7684\u5b89\u5168\u6027", "method": "\u5f00\u53d1\u5f00\u6e90\u5b89\u5168\u6d4b\u8bd5\u5de5\u5177AuthREST\uff0c\u81ea\u52a8\u6d4b\u8bd5Web API\u7684\u4e09\u79cd\u4e3b\u8981\u8eab\u4efd\u9a8c\u8bc1\u6f0f\u6d1e\uff1a\u51ed\u636e\u586b\u5145\u3001\u5bc6\u7801\u66b4\u529b\u7834\u89e3\u548c\u672a\u68c0\u67e5\u4ee4\u724c\u771f\u5b9e\u6027", "result": "\u5b9e\u8bc1\u7ed3\u679c\u663e\u793aAuthREST\u80fd\u6709\u6548\u63d0\u5347Web API\u5b89\u5168\u6027\uff0c\u5728\u56db\u4e2a\u516c\u5171API\u4e2d\u53d1\u73b0\u4e86\u4e4b\u524d\u672a\u77e5\u7684\u8eab\u4efd\u9a8c\u8bc1\u6f0f\u6d1e", "conclusion": "AuthREST\u662f\u4e00\u4e2a\u6709\u6548\u7684\u81ea\u52a8\u5316\u5b89\u5168\u6d4b\u8bd5\u5de5\u5177\uff0c\u80fd\u591f\u6210\u529f\u68c0\u6d4b\u548c\u5e2e\u52a9\u4fee\u590dWeb API\u4e2d\u7684\u8eab\u4efd\u9a8c\u8bc1\u5b89\u5168\u6f0f\u6d1e"}}
{"id": "2509.09933", "pdf": "https://arxiv.org/pdf/2509.09933", "abs": "https://arxiv.org/abs/2509.09933", "authors": ["Shintaro Nakamura", "Yuko Kuroki", "Wei Chen"], "title": "Multi-Play Combinatorial Semi-Bandit Problem", "categories": ["cs.LG"], "comment": null, "summary": "In the combinatorial semi-bandit (CSB) problem, a player selects an action\nfrom a combinatorial action set and observes feedback from the base arms\nincluded in the action. While CSB is widely applicable to combinatorial\noptimization problems, its restriction to binary decision spaces excludes\nimportant cases involving non-negative integer flows or allocations, such as\nthe optimal transport and knapsack problems.To overcome this limitation, we\npropose the multi-play combinatorial semi-bandit (MP-CSB), where a player can\nselect a non-negative integer action and observe multiple feedbacks from a\nsingle arm in each round. We propose two algorithms for the MP-CSB. One is a\nThompson-sampling-based algorithm that is computationally feasible even when\nthe action space is exponentially large with respect to the number of arms, and\nattains $O(\\log T)$ distribution-dependent regret in the stochastic regime,\nwhere $T$ is the time horizon. The other is a best-of-both-worlds algorithm,\nwhich achieves $O(\\log T)$ variance-dependent regret in the stochastic regime\nand the worst-case $\\tilde{\\mathcal{O}}\\left( \\sqrt{T} \\right)$ regret in the\nadversarial regime. Moreover, its regret in adversarial one is data-dependent,\nadapting to the cumulative loss of the optimal action, the total quadratic\nvariation, and the path-length of the loss sequence. Finally, we numerically\nshow that the proposed algorithms outperform existing methods in the CSB\nliterature.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u591a\u64ad\u653e\u7ec4\u5408\u534a\u5f3a\u76d7(MP-CSB)\u6a21\u578b\uff0c\u6269\u5c55\u4e86\u4f20\u7edf\u7ec4\u5408\u534a\u5f3a\u76d7\u95ee\u9898\u5230\u975e\u8d1f\u6574\u6570\u52a8\u4f5c\u7a7a\u95f4\uff0c\u89e3\u51b3\u4e86\u6700\u4f18\u8fd0\u8f93\u548c\u80cc\u5305\u7b49\u95ee\u9898\u3002\u63d0\u51fa\u4e86\u4e24\u79cd\u7b97\u6cd5\uff1a\u57fa\u4e8eThompson\u91c7\u6837\u7684\u7b97\u6cd5\u548c\u6700\u4f73\u4e24\u7528\u7b97\u6cd5\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7ec4\u5408\u534a\u5f3a\u76d7(CSB)\u95ee\u9898\u9650\u5236\u5728\u4e8c\u5143\u51b3\u7b56\u7a7a\u95f4\uff0c\u65e0\u6cd5\u5904\u7406\u6d89\u53ca\u975e\u8d1f\u6574\u6570\u6d41\u6216\u5206\u914d\u7684\u91cd\u8981\u95ee\u9898\uff0c\u5982\u6700\u4f18\u8fd0\u8f93\u548c\u80cc\u5305\u95ee\u9898\u3002\u9700\u8981\u6269\u5c55\u6a21\u578b\u6765\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\u3002", "method": "\u63d0\u51fa\u4e86MP-CSB\u6a21\u578b\uff0c\u5141\u8bb8\u9009\u62e9\u975e\u8d1f\u6574\u6570\u52a8\u4f5c\u5e76\u4ece\u5355\u4e2a\u81c2\u83b7\u5f97\u591a\u6b21\u53cd\u9988\u3002\u8bbe\u8ba1\u4e86\u4e24\u79cd\u7b97\u6cd5\uff1a1)\u57fa\u4e8eThompson\u91c7\u6837\u7684\u7b97\u6cd5\uff0c\u8ba1\u7b97\u53ef\u884c\u4e14\u8fbe\u5230O(log T)\u9057\u61be\uff1b2)\u6700\u4f73\u4e24\u7528\u7b97\u6cd5\uff0c\u5728\u968f\u673a\u548c\u5bf9\u6297\u73af\u5883\u4e0b\u90fd\u8868\u73b0\u826f\u597d\u3002", "result": "Thompson\u91c7\u6837\u7b97\u6cd5\u5728\u968f\u673a\u73af\u5883\u4e0b\u8fbe\u5230O(log T)\u5206\u5e03\u4f9d\u8d56\u9057\u61be\uff1b\u6700\u4f73\u4e24\u7528\u7b97\u6cd5\u5728\u968f\u673a\u73af\u5883\u4e0b\u8fbe\u5230O(log T)\u65b9\u5dee\u4f9d\u8d56\u9057\u61be\uff0c\u5728\u5bf9\u6297\u73af\u5883\u4e0b\u8fbe\u5230\u00d5(\u221aT)\u6700\u574f\u60c5\u51b5\u9057\u61be\uff0c\u4e14\u5177\u6709\u6570\u636e\u9002\u5e94\u6027\u3002\u5b9e\u9a8c\u663e\u793a\u63d0\u51fa\u7684\u7b97\u6cd5\u4f18\u4e8e\u73b0\u6709CSB\u65b9\u6cd5\u3002", "conclusion": "MP-CSB\u6a21\u578b\u6210\u529f\u6269\u5c55\u4e86\u7ec4\u5408\u534a\u5f3a\u76d7\u95ee\u9898\u5230\u6574\u6570\u52a8\u4f5c\u7a7a\u95f4\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u6027\u80fd\u4e0a\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u89e3\u51b3\u6700\u4f18\u8fd0\u8f93\u3001\u80cc\u5305\u7b49\u5b9e\u9645\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2509.10413", "pdf": "https://arxiv.org/pdf/2509.10413", "abs": "https://arxiv.org/abs/2509.10413", "authors": ["Guojun Tang", "Carylyne Chan", "Ning Nan", "Spencer Yang", "Jiayu Zhou", "Henry Leung", "Mohammad Mamun", "Steve Drew"], "title": "Bitcoin Cross-Chain Bridge: A Taxonomy and Its Promise in Artificial Intelligence of Things", "categories": ["cs.CR", "cs.SE"], "comment": "Blockchain Cross-Chain Bridge Survey", "summary": "Bitcoin's limited scripting capabilities and lack of native interoperability\nmechanisms have constrained its integration into the broader blockchain\necosystem, especially decentralized finance (DeFi) and multi-chain\napplications. This paper presents a comprehensive taxonomy of Bitcoin\ncross-chain bridge protocols, systematically analyzing their trust assumptions,\nperformance characteristics, and applicability to the Artificial Intelligence\nof Things (AIoT) scenarios. We categorize bridge designs into three main types:\nnaive token swapping, pegged-asset bridges, and arbitrary-message bridges. Each\ncategory is evaluated across key metrics such as trust model, latency, capital\nefficiency, and DeFi composability. Emerging innovations like BitVM and\nrecursive sidechains are highlighted for their potential to enable secure,\nscalable, and programmable Bitcoin interoperability. Furthermore, we explore\npractical use cases of cross-chain bridges in AIoT applications, including\ndecentralized energy trading, healthcare data integration, and supply chain\nautomation. This taxonomy provides a foundational framework for researchers and\npractitioners seeking to design secure and efficient cross-chain\ninfrastructures in AIoT systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6bd4\u7279\u5e01\u8de8\u94fe\u6865\u534f\u8bae\u7684\u5168\u9762\u5206\u7c7b\u6cd5\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u5176\u5728AIoT\u573a\u666f\u4e2d\u7684\u4fe1\u4efb\u5047\u8bbe\u3001\u6027\u80fd\u7279\u5f81\u548c\u9002\u7528\u6027\uff0c\u4e3aAIoT\u7cfb\u7edf\u8bbe\u8ba1\u5b89\u5168\u9ad8\u6548\u7684\u8de8\u94fe\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u6846\u67b6\u3002", "motivation": "\u6bd4\u7279\u5e01\u6709\u9650\u7684\u811a\u672c\u529f\u80fd\u548c\u7f3a\u4e4f\u539f\u751f\u4e92\u64cd\u4f5c\u6027\u673a\u5236\u9650\u5236\u4e86\u5176\u4e0e\u66f4\u5e7f\u6cdb\u533a\u5757\u94fe\u751f\u6001\u7cfb\u7edf\u7684\u96c6\u6210\uff0c\u7279\u522b\u662f\u5728DeFi\u548c\u591a\u94fe\u5e94\u7528\u65b9\u9762\u3002", "method": "\u5c06\u6865\u63a5\u8bbe\u8ba1\u5206\u4e3a\u4e09\u7c7b\uff1a\u7b80\u5355\u4ee3\u5e01\u4ea4\u6362\u3001\u951a\u5b9a\u8d44\u4ea7\u6865\u548c\u4efb\u610f\u6d88\u606f\u6865\uff0c\u5e76\u4ece\u4fe1\u4efb\u6a21\u578b\u3001\u5ef6\u8fdf\u3001\u8d44\u672c\u6548\u7387\u548cDeFi\u53ef\u7ec4\u5408\u6027\u7b49\u5173\u952e\u6307\u6807\u5bf9\u6bcf\u7c7b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u63d0\u51fa\u4e86\u7cfb\u7edf\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u7a81\u51fa\u4e86BitVM\u548c\u9012\u5f52\u4fa7\u94fe\u7b49\u65b0\u5174\u521b\u65b0\u6280\u672f\u5728\u5b9e\u73b0\u5b89\u5168\u3001\u53ef\u6269\u5c55\u548c\u53ef\u7f16\u7a0b\u7684\u6bd4\u7279\u5e01\u4e92\u64cd\u4f5c\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u5206\u7c7b\u6cd5\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u5728AIoT\u7cfb\u7edf\u4e2d\u8bbe\u8ba1\u5b89\u5168\u9ad8\u6548\u7684\u8de8\u94fe\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u57fa\u7840\u6846\u67b6\uff0c\u5e76\u63a2\u7d22\u4e86\u8de8\u94fe\u6865\u5728\u53bb\u4e2d\u5fc3\u5316\u80fd\u6e90\u4ea4\u6613\u3001\u533b\u7597\u6570\u636e\u96c6\u6210\u548c\u4f9b\u5e94\u94fe\u81ea\u52a8\u5316\u7b49AIoT\u5e94\u7528\u4e2d\u7684\u5b9e\u9645\u7528\u4f8b\u3002"}}
{"id": "2509.09936", "pdf": "https://arxiv.org/pdf/2509.09936", "abs": "https://arxiv.org/abs/2509.09936", "authors": ["Saarth Gaonkar", "Xiang Zheng", "Haocheng Xi", "Rishabh Tiwari", "Kurt Keutzer", "Dmitriy Morozov", "Michael W. Mahoney", "Amir Gholami"], "title": "SciML Agents: Write the Solver, Not the Solution", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Recent work in scientific machine learning aims to tackle scientific tasks\ndirectly by predicting target values with neural networks (e.g.,\nphysics-informed neural networks, neural ODEs, neural operators, etc.), but\nattaining high accuracy and robustness has been challenging. We explore an\nalternative view: use LLMs to write code that leverages decades of numerical\nalgorithms. This shifts the burden from learning a solution function to making\ndomain-aware numerical choices. We ask whether LLMs can act as SciML agents\nthat, given a natural-language ODE description, generate runnable code that is\nscientifically appropriate, selecting suitable solvers (stiff vs. non-stiff),\nand enforcing stability checks. There is currently no benchmark to measure this\nkind of capability for scientific computing tasks. As such, we first introduce\ntwo new datasets: a diagnostic dataset of adversarial \"misleading\" problems;\nand a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set\ncontains problems whose superficial appearance suggests stiffness, and that\nrequire algebraic simplification to demonstrate non-stiffness; and the\nlarge-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open-\nand closed-source LLM models along two axes: (i) unguided versus guided\nprompting with domain-specific knowledge; and (ii) off-the-shelf versus\nfine-tuned variants. Our evaluation measures both executability and numerical\nvalidity against reference solutions. We find that with sufficient context and\nguided prompts, newer instruction-following models achieve high accuracy on\nboth criteria. In many cases, recent open-source systems perform strongly\nwithout fine-tuning, while older or smaller models still benefit from\nfine-tuning. Overall, our preliminary results indicate that careful prompting\nand fine-tuning can yield a specialized LLM agent capable of reliably solving\nsimple ODE problems.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4f7f\u7528LLMs\u751f\u6210\u79d1\u5b66\u8ba1\u7b97\u4ee3\u7801\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u8bca\u65ad\u6570\u636e\u96c6\u548c\u5927\u89c4\u6a21ODE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30LLMs\u5728\u6570\u503c\u7b97\u6cd5\u9009\u62e9\u548c\u7a33\u5b9a\u6027\u68c0\u67e5\u65b9\u9762\u7684\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u672c\u6587\u63a2\u7d22\u4f7f\u7528LLMs\u7f16\u5199\u6570\u503c\u7b97\u6cd5\u4ee3\u7801\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5c06\u5b66\u4e60\u8d1f\u62c5\u4ece\u6c42\u89e3\u51fd\u6570\u8f6c\u79fb\u5230\u9886\u57df\u611f\u77e5\u7684\u6570\u503c\u9009\u62e9\u3002", "method": "\u5f15\u5165\u4e24\u4e2a\u65b0\u6570\u636e\u96c6\uff1a\u8bca\u65ad\u6027\u8bef\u5bfc\u95ee\u9898\u548c1000\u4e2a\u591a\u6837\u5316ODE\u4efb\u52a1\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u3002\u8bc4\u4f30\u5f00\u6e90\u548c\u95ed\u6e90LLM\u6a21\u578b\u5728\u65e0\u5f15\u5bfc\u4e0e\u9886\u57df\u77e5\u8bc6\u5f15\u5bfc\u63d0\u793a\u3001\u73b0\u6210\u4e0e\u5fae\u8c03\u53d8\u4f53\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u5145\u5206\u4e0a\u4e0b\u6587\u548c\u5f15\u5bfc\u63d0\u793a\u4e0b\uff0c\u8f83\u65b0\u7684\u6307\u4ee4\u8ddf\u968f\u6a21\u578b\u5728\u4e24\u4e2a\u8bc4\u4f30\u6807\u51c6\u4e0a\u90fd\u8fbe\u5230\u9ad8\u51c6\u786e\u7387\u3002\u5f00\u6e90\u7cfb\u7edf\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u8868\u73b0\u826f\u597d\uff0c\u800c\u8f83\u8001\u6216\u8f83\u5c0f\u6a21\u578b\u4ecd\u80fd\u4ece\u5fae\u8c03\u4e2d\u53d7\u76ca\u3002", "conclusion": "\u521d\u6b65\u7ed3\u679c\u8868\u660e\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u548c\u5fae\u8c03\u53ef\u4ee5\u4ea7\u751f\u80fd\u591f\u53ef\u9760\u89e3\u51b3\u7b80\u5355ODE\u95ee\u9898\u7684\u4e13\u7528LLM\u4ee3\u7406\uff0c\u4e3a\u79d1\u5b66\u8ba1\u7b97\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u8def\u5f84\u3002"}}
{"id": "2509.09940", "pdf": "https://arxiv.org/pdf/2509.09940", "abs": "https://arxiv.org/abs/2509.09940", "authors": ["Yifei Wang", "Wenbin Wang", "Yong Luo"], "title": "DyKen-Hyena: Dynamic Kernel Generation via Cross-Modal Attention for Multimodal Intent Recognition", "categories": ["cs.LG"], "comment": "8 pages, 2 figures", "summary": "Though Multimodal Intent Recognition (MIR) proves effective by utilizing rich\ninformation from multiple sources (e.g., language, video, and audio), the\npotential for intent-irrelevant and conflicting information across modalities\nmay hinder performance from being further improved. Most current models attempt\nto fuse modalities by applying mechanisms like multi-head attention to unimodal\nfeature sequences and then adding the result back to the original\nrepresentation. This process risks corrupting the primary linguistic features\nwith noisy or irrelevant non-verbal signals, as it often fails to capture the\nfine-grained, token-level influence where non-verbal cues should modulate, not\njust augment, textual meaning. To address this, we introduce DyKen-Hyena, which\nreframes the problem from feature fusion to processing modulation. Our model\ntranslates audio-visual cues into dynamic, per-token convolutional kernels that\ndirectly modulate textual feature extraction. This fine-grained approach\nachieves state-of-the-art results on the MIntRec and MIntRec2.0 benchmarks.\nNotably, it yields a +10.46% F1-score improvement in out-of-scope detection,\nvalidating that our method creates a fundamentally more robust intent\nrepresentation.", "AI": {"tldr": "DyKen-Hyena\u6a21\u578b\u901a\u8fc7\u5c06\u97f3\u9891\u89c6\u89c9\u7ebf\u7d22\u8f6c\u6362\u4e3a\u52a8\u6001\u7684\u9010token\u5377\u79ef\u6838\u6765\u76f4\u63a5\u8c03\u5236\u6587\u672c\u7279\u5f81\u63d0\u53d6\uff0c\u800c\u4e0d\u662f\u7b80\u5355\u7684\u7279\u5f81\u878d\u5408\uff0c\u5728\u591a\u6a21\u6001\u610f\u56fe\u8bc6\u522b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u610f\u56fe\u8bc6\u522b\u6a21\u578b\u901a\u8fc7\u591a\u5934\u6ce8\u610f\u529b\u7b49\u673a\u5236\u878d\u5408\u591a\u6a21\u6001\u7279\u5f81\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u53ef\u80fd\u4f1a\u7528\u566a\u58f0\u6216\u65e0\u5173\u7684\u975e\u8bed\u8a00\u4fe1\u53f7\u6c61\u67d3\u4e3b\u8981\u8bed\u8a00\u7279\u5f81\uff0c\u65e0\u6cd5\u6355\u6349\u7ec6\u7c92\u5ea6\u7684token\u7ea7\u5f71\u54cd\u3002", "method": "\u63d0\u51faDyKen-Hyena\u6a21\u578b\uff0c\u5c06\u95ee\u9898\u4ece\u7279\u5f81\u878d\u5408\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5904\u7406\u8c03\u5236\uff0c\u5c06\u97f3\u9891\u89c6\u89c9\u7ebf\u7d22\u8f6c\u6362\u4e3a\u52a8\u6001\u7684\u9010token\u5377\u79ef\u6838\u6765\u76f4\u63a5\u8c03\u5236\u6587\u672c\u7279\u5f81\u63d0\u53d6\u8fc7\u7a0b\u3002", "result": "\u5728MIntRec\u548cMIntRec2.0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u5728out-of-scope\u68c0\u6d4b\u4e2d\u83b7\u5f97+10.46%\u7684F1\u5206\u6570\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u521b\u5efa\u4e86\u66f4\u9c81\u68d2\u7684\u610f\u56fe\u8868\u793a\uff0c\u9a8c\u8bc1\u4e86\u901a\u8fc7\u8c03\u5236\u800c\u975e\u7b80\u5355\u878d\u5408\u7684\u65b9\u5f0f\u5904\u7406\u591a\u6a21\u6001\u4fe1\u606f\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.09955", "pdf": "https://arxiv.org/pdf/2509.09955", "abs": "https://arxiv.org/abs/2509.09955", "authors": ["Omar Erak", "Omar Alhussein", "Hatem Abou-Zeid", "Mehdi Bennis", "Sami Muhaidat"], "title": "Adaptive Token Merging for Efficient Transformer Semantic Communication at the Edge", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.IV"], "comment": "Submitted to IEEE Journals", "summary": "Large-scale transformers are central to modern semantic communication, yet\ntheir high computational and communication costs hinder deployment on\nresource-constrained edge devices. This paper introduces a training-free\nframework for adaptive token merging, a novel mechanism that compresses\ntransformer representations at runtime by selectively merging semantically\nredundant tokens under per-layer similarity thresholds. Unlike prior\nfixed-ratio reduction, our approach couples merging directly to input\nredundancy, enabling data-dependent adaptation that balances efficiency and\ntask relevance without retraining. We cast the discovery of merging strategies\nas a multi-objective optimization problem and leverage Bayesian optimization to\nobtain Pareto-optimal trade-offs between accuracy, inference cost, and\ncommunication cost. On ImageNet classification, we match the accuracy of the\nunmodified transformer with 30\\% fewer floating-point operations per second and\nunder 20\\% of the original communication cost, while for visual question\nanswering our method achieves performance competitive with the full LLaVA model\nat less than one-third of the compute and one-tenth of the bandwidth. Finally,\nwe show that our adaptive merging is robust across varying channel conditions\nand provides inherent privacy benefits, substantially degrading the efficacy of\nmodel inversion attacks. Our framework provides a practical and versatile\nsolution for deploying powerful transformer models in resource-limited edge\nintelligence scenarios.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u9700\u8bad\u7ec3\u7684token\u5408\u5e76\u6846\u67b6\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u4f18\u5316\u5b9e\u73b0\u8ba1\u7b97\u548c\u901a\u4fe1\u6210\u672c\u7684\u52a8\u6001\u538b\u7f29\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8d44\u6e90\u6d88\u8017", "motivation": "\u5927\u89c4\u6a21transformer\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u65f6\u9762\u4e34\u9ad8\u8ba1\u7b97\u548c\u901a\u4fe1\u6210\u672c\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u7684\u81ea\u9002\u5e94\u538b\u7f29\u65b9\u6cd5", "method": "\u57fa\u4e8e\u6bcf\u5c42\u76f8\u4f3c\u5ea6\u9608\u503c\u9009\u62e9\u6027\u5408\u5e76\u8bed\u4e49\u5197\u4f59token\uff0c\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u5bfb\u627e\u5e15\u7d2f\u6258\u6700\u4f18\u7684\u7cbe\u5ea6-\u6548\u7387\u6743\u8861\u7b56\u7565", "result": "\u5728ImageNet\u5206\u7c7b\u4e0a\u51cf\u5c1130%\u8ba1\u7b97\u91cf\u548c80%\u901a\u4fe1\u6210\u672c\uff0c\u5728VQA\u4efb\u52a1\u4e0a\u4ee51/3\u8ba1\u7b97\u91cf\u548c1/10\u5e26\u5bbd\u8fbe\u5230LLaVA\u6a21\u578b\u6027\u80fd", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u667a\u80fd\u573a\u666f\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u901a\u7528\u7684transformer\u90e8\u7f72\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u9c81\u68d2\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u4f18\u52bf"}}
{"id": "2509.09960", "pdf": "https://arxiv.org/pdf/2509.09960", "abs": "https://arxiv.org/abs/2509.09960", "authors": ["Mingxuan Jiang", "Yongxin Wang", "Ziyue Dai", "Yicun Liu", "Hongyi Nie", "Sen Liu", "Hongfeng Chai"], "title": "Limited Reference, Reliable Generation: A Two-Component Framework for Tabular Data Generation in Low-Data Regimes", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Synthetic tabular data generation is increasingly essential in data\nmanagement, supporting downstream applications when real-world and high-quality\ntabular data is insufficient. Existing tabular generation approaches, such as\ngenerative adversarial networks (GANs), diffusion models, and fine-tuned Large\nLanguage Models (LLMs), typically require sufficient reference data, limiting\ntheir effectiveness in domain-specific databases with scarce records. While\nprompt-based LLMs offer flexibility without parameter tuning, they often fail\nto capture dataset-specific feature-label dependencies and generate redundant\ndata, leading to degradation in downstream task performance. To overcome these\nissues, we propose ReFine, a framework that (i) derives symbolic \"if-then\"\nrules from interpretable models and embeds them into prompts to explicitly\nguide generation toward domain-specific feature distribution, and (ii) applies\na dual-granularity filtering strategy that suppresses over-sampling patterns\nand selectively refines rare but informative samples to reduce distributional\nimbalance. Extensive experiments on various regression and classification\nbenchmarks demonstrate that ReFine consistently outperforms state-of-the-art\nmethods, achieving up to 0.44 absolute improvement in R-squared for regression\nand 10.0 percent relative improvement in F1 score for classification tasks.", "AI": {"tldr": "ReFine\u662f\u4e00\u4e2a\u5408\u6210\u8868\u683c\u6570\u636e\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u53ef\u89e3\u91ca\u6a21\u578b\u4e2d\u63d0\u53d6\u7b26\u53f7\u89c4\u5219\u5d4c\u5165\u63d0\u793a\u8bcd\uff0c\u5e76\u91c7\u7528\u53cc\u7c92\u5ea6\u8fc7\u6ee4\u7b56\u7565\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8868\u683c\u751f\u6210\u65b9\u6cd5\uff08GANs\u3001\u6269\u6563\u6a21\u578b\u3001\u5fae\u8c03LLMs\uff09\u9700\u8981\u5145\u8db3\u53c2\u8003\u6570\u636e\uff0c\u5728\u9886\u57df\u7279\u5b9a\u6570\u636e\u5e93\u8bb0\u5f55\u7a00\u7f3a\u65f6\u6548\u679c\u6709\u9650\u3002\u57fa\u4e8e\u63d0\u793a\u7684LLMs\u867d\u7136\u7075\u6d3b\u4f46\u96be\u4ee5\u6355\u6349\u6570\u636e\u96c6\u7279\u5b9a\u7684\u7279\u5f81-\u6807\u7b7e\u4f9d\u8d56\u5173\u7cfb\uff0c\u4e14\u751f\u6210\u5197\u4f59\u6570\u636e\u5bfc\u81f4\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u4e0b\u964d\u3002", "method": "1) \u4ece\u53ef\u89e3\u91ca\u6a21\u578b\u63a8\u5bfc\u7b26\u53f7\"if-then\"\u89c4\u5219\u5e76\u5d4c\u5165\u63d0\u793a\u8bcd\uff0c\u663e\u5f0f\u6307\u5bfc\u751f\u6210\u7b26\u5408\u9886\u57df\u7279\u5b9a\u7279\u5f81\u5206\u5e03\uff1b2) \u5e94\u7528\u53cc\u7c92\u5ea6\u8fc7\u6ee4\u7b56\u7565\uff0c\u6291\u5236\u8fc7\u91c7\u6837\u6a21\u5f0f\u5e76\u9009\u62e9\u6027\u7cbe\u70bc\u7a00\u6709\u4f46\u4fe1\u606f\u4e30\u5bcc\u7684\u6837\u672c\u4ee5\u51cf\u5c11\u5206\u5e03\u4e0d\u5e73\u8861\u3002", "result": "\u5728\u591a\u79cd\u56de\u5f52\u548c\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cReFine consistently outperforms state-of-the-art methods\uff0c\u56de\u5f52\u4efb\u52a1R\u5e73\u65b9\u7edd\u5bf9\u63d0\u53470.44\uff0c\u5206\u7c7b\u4efb\u52a1F1\u5206\u6570\u76f8\u5bf9\u63d0\u534710.0%\u3002", "conclusion": "ReFine\u6846\u67b6\u901a\u8fc7\u89c4\u5219\u5f15\u5bfc\u548c\u667a\u80fd\u8fc7\u6ee4\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u7684\u8868\u683c\u751f\u6210\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u6570\u636e\u7684\u8d28\u91cf\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002"}}
{"id": "2509.09991", "pdf": "https://arxiv.org/pdf/2509.09991", "abs": "https://arxiv.org/abs/2509.09991", "authors": ["Amandip Sangha"], "title": "Data-Driven Energy Estimation for Virtual Servers Using Combined System Metrics and Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "This paper presents a machine learning-based approach to estimate the energy\nconsumption of virtual servers without access to physical power measurement\ninterfaces. Using resource utilization metrics collected from guest virtual\nmachines, we train a Gradient Boosting Regressor to predict energy consumption\nmeasured via RAPL on the host. We demonstrate, for the first time, guest-only\nresource-based energy estimation without privileged host access with\nexperiments across diverse workloads, achieving high predictive accuracy and\nvariance explained ($0.90 \\leq R^2 \\leq 0.97$), indicating the feasibility of\nguest-side energy estimation. This approach can enable energy-aware scheduling,\ncost optimization and physical host independent energy estimates in virtualized\nenvironments. Our approach addresses a critical gap in virtualized environments\n(e.g. cloud) where direct energy measurement is infeasible.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u865a\u62df\u670d\u52a1\u5668\u80fd\u8017\u4f30\u8ba1\u65b9\u6cd5\uff0c\u4ec5\u4f7f\u7528\u865a\u62df\u673a\u8d44\u6e90\u5229\u7528\u7387\u6307\u6807\u5373\u53ef\u9884\u6d4b\u80fd\u8017\uff0c\u65e0\u9700\u7269\u7406\u529f\u8017\u6d4b\u91cf\u63a5\u53e3\u6216\u4e3b\u673a\u7279\u6743\u8bbf\u95ee", "motivation": "\u89e3\u51b3\u865a\u62df\u5316\u73af\u5883\uff08\u5982\u4e91\u5e73\u53f0\uff09\u4e2d\u65e0\u6cd5\u76f4\u63a5\u6d4b\u91cf\u80fd\u8017\u7684\u5173\u952e\u95ee\u9898\uff0c\u5b9e\u73b0\u65e0\u4e3b\u673a\u7279\u6743\u8bbf\u95ee\u7684\u80fd\u8017\u4f30\u8ba1", "method": "\u4f7f\u7528\u68af\u5ea6\u63d0\u5347\u56de\u5f52\u5668\uff08Gradient Boosting Regressor\uff09\uff0c\u57fa\u4e8e\u865a\u62df\u673a\u6536\u96c6\u7684\u8d44\u6e90\u5229\u7528\u7387\u6307\u6807\u6765\u9884\u6d4b\u901a\u8fc7RAPL\u6d4b\u91cf\u7684\u4e3b\u673a\u80fd\u8017", "result": "\u5728\u591a\u6837\u5316\u5de5\u4f5c\u8d1f\u8f7d\u5b9e\u9a8c\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff08R\u00b2\u57280.90\u52300.97\u4e4b\u95f4\uff09\uff0c\u8bc1\u660e\u4e86\u4ec5\u4f7f\u7528\u865a\u62df\u673a\u7aef\u8d44\u6e90\u8fdb\u884c\u80fd\u8017\u4f30\u8ba1\u7684\u53ef\u884c\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4e3a\u865a\u62df\u5316\u73af\u5883\u4e2d\u7684\u80fd\u91cf\u611f\u77e5\u8c03\u5ea6\u3001\u6210\u672c\u4f18\u5316\u548c\u72ec\u7acb\u4e8e\u7269\u7406\u4e3b\u673a\u7684\u80fd\u8017\u4f30\u8ba1\u63d0\u4f9b\u652f\u6301"}}
{"id": "2509.10000", "pdf": "https://arxiv.org/pdf/2509.10000", "abs": "https://arxiv.org/abs/2509.10000", "authors": ["Tilen Cadez", "Kyoung-Min Kim"], "title": "Neural Scaling Laws for Deep Regression", "categories": ["cs.LG", "cond-mat.other"], "comment": "Supplementary Information will be provided with the published\n  manuscript", "summary": "Neural scaling laws--power-law relationships between generalization errors\nand characteristics of deep learning models--are vital tools for developing\nreliable models while managing limited resources. Although the success of large\nlanguage models highlights the importance of these laws, their application to\ndeep regression models remains largely unexplored. Here, we empirically\ninvestigate neural scaling laws in deep regression using a parameter estimation\nmodel for twisted van der Waals magnets. We observe power-law relationships\nbetween the loss and both training dataset size and model capacity across a\nwide range of values, employing various architectures--including fully\nconnected networks, residual networks, and vision transformers. Furthermore,\nthe scaling exponents governing these relationships range from 1 to 2, with\nspecific values depending on the regressed parameters and model details. The\nconsistent scaling behaviors and their large scaling exponents suggest that the\nperformance of deep regression models can improve substantially with increasing\ndata size.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5b9e\u9a8c\u63a2\u7d22\u4e86\u6df1\u5ea6\u56de\u5f52\u6a21\u578b\u4e2d\u7684\u795e\u7ecf\u7f29\u653e\u5b9a\u5f8b\uff0c\u53d1\u73b0\u5728\u626d\u66f2\u8303\u5fb7\u74e6\u5c14\u65af\u78c1\u4f53\u53c2\u6570\u4f30\u8ba1\u4efb\u52a1\u4e2d\uff0c\u635f\u5931\u4e0e\u8bad\u7ec3\u6570\u636e\u96c6\u5927\u5c0f\u548c\u6a21\u578b\u5bb9\u91cf\u4e4b\u95f4\u5b58\u5728\u5e42\u5f8b\u5173\u7cfb\uff0c\u7f29\u653e\u6307\u6570\u57281\u52302\u4e4b\u95f4\u3002", "motivation": "\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6210\u529f\u8bc1\u660e\u4e86\u795e\u7ecf\u7f29\u653e\u5b9a\u5f8b\u7684\u91cd\u8981\u6027\uff0c\u4f46\u8fd9\u4e9b\u5b9a\u5f8b\u5728\u6df1\u5ea6\u56de\u5f52\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u4ecd\u7136\u5f88\u5c11\u88ab\u63a2\u7d22\u3002\u7814\u7a76\u8005\u5e0c\u671b\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u6df1\u5ea6\u56de\u5f52\u6a21\u578b\u7684\u53d1\u5c55\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc\u3002", "method": "\u4f7f\u7528\u626d\u66f2\u8303\u5fb7\u74e6\u5c14\u65af\u78c1\u4f53\u7684\u53c2\u6570\u4f30\u8ba1\u6a21\u578b\uff0c\u5728\u4e0d\u540c\u67b6\u6784\uff08\u5168\u8fde\u63a5\u7f51\u7edc\u3001\u6b8b\u5dee\u7f51\u7edc\u3001\u89c6\u89c9\u53d8\u6362\u5668\uff09\u4e0a\u5b9e\u9a8c\u7814\u7a76\u635f\u5931\u4e0e\u8bad\u7ec3\u6570\u636e\u96c6\u5927\u5c0f\u3001\u6a21\u578b\u5bb9\u91cf\u4e4b\u95f4\u7684\u5e42\u5f8b\u5173\u7cfb\u3002", "result": "\u89c2\u5bdf\u5230\u635f\u5931\u4e0e\u8bad\u7ec3\u6570\u636e\u96c6\u5927\u5c0f\u548c\u6a21\u578b\u5bb9\u91cf\u4e4b\u95f4\u5b58\u5728\u5e42\u5f8b\u5173\u7cfb\uff0c\u7f29\u653e\u6307\u6570\u8303\u56f4\u57281\u52302\u4e4b\u95f4\uff0c\u5177\u4f53\u503c\u53d6\u51b3\u4e8e\u56de\u5f52\u53c2\u6570\u548c\u6a21\u578b\u7ec6\u8282\u3002", "conclusion": "\u4e00\u81f4\u7684\u7f29\u653e\u884c\u4e3a\u548c\u5927\u7f29\u653e\u6307\u6570\u8868\u660e\uff0c\u6df1\u5ea6\u56de\u5f52\u6a21\u578b\u7684\u6027\u80fd\u53ef\u4ee5\u968f\u7740\u6570\u636e\u91cf\u7684\u589e\u52a0\u800c\u663e\u8457\u63d0\u5347\uff0c\u8fd9\u4e3a\u8d44\u6e90\u7ba1\u7406\u548c\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2509.10011", "pdf": "https://arxiv.org/pdf/2509.10011", "abs": "https://arxiv.org/abs/2509.10011", "authors": ["Antoine Orioua", "Philipp Krah", "Julian Koellermeier"], "title": "Intrinsic Dimension Estimating Autoencoder (IDEA) Using CancelOut Layer and a Projected Loss", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "comment": "Preprint with 12 pages and 12 figures", "summary": "This paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA),\nwhich identifies the underlying intrinsic dimension of a wide range of datasets\nwhose samples lie on either linear or nonlinear manifolds. Beyond estimating\nthe intrinsic dimension, IDEA is also able to reconstruct the original dataset\nafter projecting it onto the corresponding latent space, which is structured\nusing re-weighted double CancelOut layers. Our key contribution is the\nintroduction of the projected reconstruction loss term, guiding the training of\nthe model by continuously assessing the reconstruction quality under the\nremoval of an additional latent dimension. We first assess the performance of\nIDEA on a series of theoretical benchmarks to validate its robustness. These\nexperiments allow us to test its reconstruction ability and compare its\nperformance with state-of-the-art intrinsic dimension estimators. The\nbenchmarks show good accuracy and high versatility of our approach.\nSubsequently, we apply our model to data generated from the numerical solution\nof a vertically resolved one-dimensional free-surface flow, following a\npointwise discretization of the vertical velocity profile in the horizontal\ndirection, vertical direction, and time. IDEA succeeds in estimating the\ndataset's intrinsic dimension and then reconstructs the original solution by\nworking directly within the projection space identified by the network.", "AI": {"tldr": "IDEA\u662f\u4e00\u79cd\u80fd\u591f\u4f30\u8ba1\u6570\u636e\u96c6\u5185\u5728\u7ef4\u5ea6\u5e76\u91cd\u5efa\u539f\u59cb\u6570\u636e\u7684\u81ea\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u6295\u5f71\u91cd\u5efa\u635f\u5931\u9879\u548c\u91cd\u52a0\u6743\u53ccCancelOut\u5c42\u7ed3\u6784\uff0c\u5728\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u6d41\u5f62\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u4f30\u8ba1\u6570\u636e\u96c6\u5185\u5728\u7ef4\u5ea6\u65f6\u5f80\u5f80\u65e0\u6cd5\u540c\u65f6\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u91cd\u5efa\u80fd\u529b\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u51c6\u786e\u4f30\u8ba1\u5185\u5728\u7ef4\u5ea6\u53c8\u80fd\u6709\u6548\u91cd\u5efa\u539f\u59cb\u6570\u636e\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u63d0\u51faIDEA\u81ea\u7f16\u7801\u5668\uff0c\u4f7f\u7528\u91cd\u52a0\u6743\u53ccCancelOut\u5c42\u6784\u5efa\u6f5c\u5728\u7a7a\u95f4\uff0c\u5f15\u5165\u6295\u5f71\u91cd\u5efa\u635f\u5931\u9879\u6765\u6307\u5bfc\u8bad\u7ec3\uff0c\u901a\u8fc7\u8fde\u7eed\u8bc4\u4f30\u53bb\u9664\u6f5c\u5728\u7ef4\u5ea6\u540e\u7684\u91cd\u5efa\u8d28\u91cf\u6765\u786e\u5b9a\u5185\u5728\u7ef4\u5ea6\u3002", "result": "\u5728\u7406\u8bba\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u51c6\u786e\u6027\u548c\u9ad8\u901a\u7528\u6027\uff0c\u5728\u5782\u76f4\u89e3\u6790\u4e00\u7ef4\u81ea\u7531\u8868\u9762\u6d41\u6570\u503c\u89e3\u6570\u636e\u4e0a\u6210\u529f\u4f30\u8ba1\u5185\u5728\u7ef4\u5ea6\u5e76\u91cd\u5efa\u539f\u59cb\u89e3\u3002", "conclusion": "IDEA\u662f\u4e00\u4e2a\u5f3a\u5927\u4e14\u901a\u7528\u7684\u5de5\u5177\uff0c\u80fd\u591f\u540c\u65f6\u51c6\u786e\u4f30\u8ba1\u6570\u636e\u96c6\u5185\u5728\u7ef4\u5ea6\u548c\u91cd\u5efa\u539f\u59cb\u6570\u636e\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u90fd\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.10025", "pdf": "https://arxiv.org/pdf/2509.10025", "abs": "https://arxiv.org/abs/2509.10025", "authors": ["Strahinja Nikolic", "Ilker Oguz", "Demetri Psaltis"], "title": "Exploring Expert Specialization through Unsupervised Training in Sparse Mixture of Experts", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 7 figures", "summary": "Understanding the internal organization of neural networks remains a\nfundamental challenge in deep learning interpretability. We address this\nchallenge by exploring a novel Sparse Mixture of Experts Variational\nAutoencoder (SMoE-VAE) architecture. We test our model on the QuickDraw\ndataset, comparing unsupervised expert routing against a supervised baseline\nguided by ground-truth labels. Surprisingly, we find that unsupervised routing\nconsistently achieves superior reconstruction performance. The experts learn to\nidentify meaningful sub-categorical structures that often transcend\nhuman-defined class boundaries. Through t-SNE visualizations and reconstruction\nanalysis, we investigate how MoE models uncover fundamental data structures\nthat are more aligned with the model's objective than predefined labels.\nFurthermore, our study on the impact of dataset size provides insights into the\ntrade-offs between data quantity and expert specialization, offering guidance\nfor designing efficient MoE architectures.", "AI": {"tldr": "SMoE-VAE\u67b6\u6784\u5728\u65e0\u76d1\u7763\u4e13\u5bb6\u8def\u7531\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u6709\u76d1\u7763\u57fa\u7ebf\uff0c\u80fd\u591f\u8bc6\u522b\u51fa\u8d85\u8d8a\u4eba\u5de5\u5b9a\u4e49\u7c7b\u522b\u8fb9\u754c\u7684\u6709\u610f\u4e49\u5b50\u7c7b\u522b\u7ed3\u6784\u3002", "motivation": "\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u5185\u90e8\u7ec4\u7ec7\u662f\u6df1\u5ea6\u5b66\u4e60\u53ef\u89e3\u91ca\u6027\u7684\u57fa\u672c\u6311\u6218\uff0c\u63a2\u7d22\u7a00\u758f\u6df7\u5408\u4e13\u5bb6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u67b6\u6784\u6765\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u5728QuickDraw\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5SMoE-VAE\u6a21\u578b\uff0c\u6bd4\u8f83\u65e0\u76d1\u7763\u4e13\u5bb6\u8def\u7531\u4e0e\u57fa\u4e8e\u771f\u5b9e\u6807\u7b7e\u7684\u6709\u76d1\u7763\u57fa\u7ebf\uff0c\u4f7f\u7528t-SNE\u53ef\u89c6\u5316\u548c\u91cd\u5efa\u5206\u6790\u3002", "result": "\u65e0\u76d1\u7763\u8def\u7531\u59cb\u7ec8\u83b7\u5f97\u66f4\u597d\u7684\u91cd\u5efa\u6027\u80fd\uff0c\u4e13\u5bb6\u5b66\u4f1a\u8bc6\u522b\u6709\u610f\u4e49\u4e14\u5e38\u8d85\u8d8a\u4eba\u5de5\u7c7b\u522b\u8fb9\u754c\u7684\u5b50\u7c7b\u522b\u7ed3\u6784\uff0c\u6570\u636e\u96c6\u5927\u5c0f\u5f71\u54cd\u4e13\u5bb6\u4e13\u4e1a\u5316\u7a0b\u5ea6\u3002", "conclusion": "MoE\u6a21\u578b\u80fd\u591f\u53d1\u73b0\u4e0e\u6a21\u578b\u76ee\u6807\u66f4\u4e00\u81f4\u7684\u57fa\u672c\u6570\u636e\u7ed3\u6784\uff0c\u4e3a\u8bbe\u8ba1\u9ad8\u6548MoE\u67b6\u6784\u63d0\u4f9b\u4e86\u5173\u4e8e\u6570\u636e\u91cf\u4e0e\u4e13\u5bb6\u4e13\u4e1a\u5316\u6743\u8861\u7684\u6307\u5bfc\u3002"}}
{"id": "2509.10033", "pdf": "https://arxiv.org/pdf/2509.10033", "abs": "https://arxiv.org/abs/2509.10033", "authors": ["Boya Ma", "Abram Magner", "Maxwell McNeil", "Petko Bogdanov"], "title": "Sparse Coding Representation of 2-way Data", "categories": ["cs.LG"], "comment": null, "summary": "Sparse dictionary coding represents signals as linear combinations of a few\ndictionary atoms. It has been applied to images, time series, graph signals and\nmulti-way spatio-temporal data by jointly employing temporal and spatial\ndictionaries. Data-agnostic analytical dictionaries, such as the discrete\nFourier transform, wavelets and graph Fourier, have seen wide adoption due to\nefficient implementations and good practical performance. On the other hand,\ndictionaries learned from data offer sparser and more accurate solutions but\nrequire learning of both the dictionaries and the coding coefficients. This\nbecomes especially challenging for multi-dictionary scenarios since encoding\ncoefficients correspond to all atom combinations from the dictionaries. To\naddress this challenge, we propose a low-rank coding model for 2-dictionary\nscenarios and study its data complexity. Namely, we establish a bound on the\nnumber of samples needed to learn dictionaries that generalize to unseen\nsamples from the same distribution. We propose a convex relaxation solution,\ncalled AODL, whose exact solution we show also solves the original problem. We\nthen solve this relaxation via alternating optimization between the sparse\ncoding matrices and the learned dictionaries, which we prove to be convergent.\nWe demonstrate its quality for data reconstruction and missing value imputation\nin both synthetic and real-world datasets. For a fixed reconstruction quality,\nAODL learns up to 90\\% sparser solutions compared to non-low-rank and\nanalytical (fixed) dictionary baselines. In addition, the learned dictionaries\nreveal interpretable insights into patterns present within the samples used for\ntraining.", "AI": {"tldr": "\u63d0\u51fa\u4e86AODL\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f4e\u79e9\u7f16\u7801\u6a21\u578b\u89e3\u51b3\u591a\u5b57\u5178\u573a\u666f\u4e0b\u7684\u5b57\u5178\u5b66\u4e60\u95ee\u9898\uff0c\u5728\u4fdd\u8bc1\u91cd\u5efa\u8d28\u91cf\u7684\u540c\u65f6\u83b7\u5f97\u66f4\u7a00\u758f\u7684\u89e3\uff0c\u5e76\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6536\u655b\u6027\u548c\u6cdb\u5316\u6027\u80fd", "motivation": "\u4f20\u7edf\u7a00\u758f\u5b57\u5178\u7f16\u7801\u5728\u5904\u7406\u591a\u5b57\u5178\u573a\u666f\u65f6\u9762\u4e34\u5b57\u5178\u548c\u7f16\u7801\u7cfb\u6570\u8054\u5408\u5b66\u4e60\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u7f16\u7801\u7cfb\u6570\u9700\u8981\u5904\u7406\u6240\u6709\u5b57\u5178\u539f\u5b50\u7684\u7ec4\u5408\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8", "method": "\u63d0\u51fa\u4f4e\u79e9\u7f16\u7801\u6a21\u578b\uff0c\u4f7f\u7528\u51f8\u677e\u5f1b\u89e3\u51b3\u65b9\u6848AODL\uff0c\u901a\u8fc7\u7a00\u758f\u7f16\u7801\u77e9\u9635\u548c\u5b66\u4e60\u5b57\u5178\u4e4b\u95f4\u7684\u4ea4\u66ff\u4f18\u5316\u8fdb\u884c\u6c42\u89e3", "result": "AODL\u5728\u76f8\u540c\u91cd\u5efa\u8d28\u91cf\u4e0b\u6bd4\u975e\u4f4e\u79e9\u548c\u56fa\u5b9a\u5b57\u5178\u57fa\u7ebf\u83b7\u5f97\u9ad8\u8fbe90%\u66f4\u7a00\u758f\u7684\u89e3\uff0c\u5b66\u4e60\u5230\u7684\u5b57\u5178\u80fd\u591f\u63ed\u793a\u8bad\u7ec3\u6837\u672c\u4e2d\u7684\u53ef\u89e3\u91ca\u6a21\u5f0f", "conclusion": "AODL\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u5b57\u5178\u5b66\u4e60\u7684\u6570\u636e\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u90fd\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u91cd\u5efa\u548c\u7f3a\u5931\u503c\u586b\u8865\u6027\u80fd"}}
{"id": "2509.10034", "pdf": "https://arxiv.org/pdf/2509.10034", "abs": "https://arxiv.org/abs/2509.10034", "authors": ["Sahil Rajesh Dhayalkar"], "title": "Symbolic Feedforward Networks for Probabilistic Finite Automata: Exact Simulation and Learnability", "categories": ["cs.LG"], "comment": "19 pages, 2 figures", "summary": "We present a formal and constructive theory showing that probabilistic finite\nautomata (PFAs) can be exactly simulated using symbolic feedforward neural\nnetworks. Our architecture represents state distributions as vectors and\ntransitions as stochastic matrices, enabling probabilistic state propagation\nvia matrix-vector products. This yields a parallel, interpretable, and\ndifferentiable simulation of PFA dynamics using soft updates-without\nrecurrence. We formally characterize probabilistic subset construction,\n$\\varepsilon$-closure, and exact simulation via layered symbolic computation,\nand prove equivalence between PFAs and specific classes of neural networks. We\nfurther show that these symbolic simulators are not only expressive but\nlearnable: trained with standard gradient descent-based optimization on labeled\nsequence data, they recover the exact behavior of ground-truth PFAs. This\nlearnability, formalized in Proposition 5.1, is the crux of this work. Our\nresults unify probabilistic automata theory with neural architectures under a\nrigorous algebraic framework, bridging the gap between symbolic computation and\ndeep learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u7406\u8bba\uff0c\u8bc1\u660e\u6982\u7387\u6709\u9650\u81ea\u52a8\u673a(PFAs)\u53ef\u4ee5\u901a\u8fc7\u7b26\u53f7\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u7cbe\u786e\u6a21\u62df\u3002\u8be5\u67b6\u6784\u4f7f\u7528\u5411\u91cf\u8868\u793a\u72b6\u6001\u5206\u5e03\uff0c\u968f\u673a\u77e9\u9635\u8868\u793a\u8f6c\u79fb\uff0c\u901a\u8fc7\u77e9\u9635\u5411\u91cf\u4e58\u79ef\u5b9e\u73b0\u6982\u7387\u72b6\u6001\u4f20\u64ad\uff0c\u63d0\u4f9b\u5e76\u884c\u3001\u53ef\u89e3\u91ca\u3001\u53ef\u5fae\u5206\u7684PFA\u52a8\u6001\u6a21\u62df\u3002", "motivation": "\u7edf\u4e00\u6982\u7387\u81ea\u52a8\u673a\u7406\u8bba\u4e0e\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5728\u4e25\u683c\u7684\u4ee3\u6570\u6846\u67b6\u4e0b\u5f25\u5408\u7b26\u53f7\u8ba1\u7b97\u4e0e\u6df1\u5ea6\u5b66\u4e60\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5b9e\u73b0\u6982\u7387\u81ea\u52a8\u673a\u7684\u53ef\u5b66\u4e60\u795e\u7ecf\u7f51\u7edc\u6a21\u62df\u3002", "method": "\u4f7f\u7528\u7b26\u53f7\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5c06\u72b6\u6001\u5206\u5e03\u8868\u793a\u4e3a\u5411\u91cf\uff0c\u8f6c\u79fb\u8868\u793a\u4e3a\u968f\u673a\u77e9\u9635\uff0c\u901a\u8fc7\u77e9\u9635\u5411\u91cf\u4e58\u79ef\u8fdb\u884c\u6982\u7387\u72b6\u6001\u4f20\u64ad\uff0c\u5b9e\u73b0\u975e\u5faa\u73af\u7684\u8f6f\u66f4\u65b0\u6a21\u62df\u3002\u91c7\u7528\u6807\u51c6\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u5728\u6807\u8bb0\u5e8f\u5217\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u8bc1\u660e\u4e86PFAs\u4e0e\u7279\u5b9a\u7c7b\u522b\u795e\u7ecf\u7f51\u7edc\u7684\u7b49\u4ef7\u6027\uff0c\u5c55\u793a\u4e86\u7b26\u53f7\u6a21\u62df\u5668\u4e0d\u4ec5\u5177\u6709\u8868\u8fbe\u6027\u800c\u4e14\u53ef\u5b66\u4e60\uff1a\u901a\u8fc7\u8bad\u7ec3\u80fd\u591f\u7cbe\u786e\u6062\u590d\u771f\u5b9ePFAs\u7684\u884c\u4e3a\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5efa\u7acb\u4e86\u6982\u7387\u81ea\u52a8\u673a\u7406\u8bba\u4e0e\u795e\u7ecf\u67b6\u6784\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u4ece\u7b26\u53f7\u8ba1\u7b97\u5230\u6df1\u5ea6\u5b66\u4e60\u7684\u6865\u6881\uff0c\u4e3a\u6982\u7387\u81ea\u52a8\u673a\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u62df\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2509.10041", "pdf": "https://arxiv.org/pdf/2509.10041", "abs": "https://arxiv.org/abs/2509.10041", "authors": ["Mohammad Hasan Narimani", "Mostafa Tavassolipour"], "title": "FedRP: A Communication-Efficient Approach for Differentially Private Federated Learning Using Random Projection", "categories": ["cs.LG"], "comment": null, "summary": "Federated learning (FL) offers an innovative paradigm for collaborative model\ntraining across decentralized devices, such as smartphones, balancing enhanced\npredictive performance with the protection of user privacy in sensitive areas\nlike Internet of Things (IoT) and medical data analysis. Despite its\nadvantages, FL encounters significant challenges related to user privacy\nprotection against potential attacks and the management of communication costs.\nThis paper introduces a novel federated learning algorithm called FedRP, which\nintegrates random projection techniques with the Alternating Direction Method\nof Multipliers (ADMM) optimization framework. This approach enhances privacy by\nemploying random projection to reduce the dimensionality of model parameters\nprior to their transmission to a central server, reducing the communication\ncost. The proposed algorithm offers a strong $(\\epsilon, \\delta)$-differential\nprivacy guarantee, demonstrating resilience against data reconstruction\nattacks. Experimental results reveal that FedRP not only maintains high model\naccuracy but also outperforms existing methods, including conventional\ndifferential privacy approaches and FedADMM, in terms of both privacy\npreservation and communication efficiency.", "AI": {"tldr": "FedRP\u662f\u4e00\u79cd\u65b0\u9896\u7684\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u968f\u673a\u6295\u5f71\u6280\u672f\u548cADMM\u4f18\u5316\u6846\u67b6\u7ed3\u5408\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u964d\u4f4e\u901a\u4fe1\u6210\u672c\uff0c\u5e76\u63d0\u4f9b\u5f3a\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5bf9\u6297\u6f5c\u5728\u653b\u51fb\u548c\u7ba1\u7406\u901a\u4fe1\u6210\u672c\u65b9\u9762\u9700\u8981\u6539\u8fdb\u3002", "method": "\u91c7\u7528\u968f\u673a\u6295\u5f71\u6280\u672f\u964d\u4f4e\u6a21\u578b\u53c2\u6570\u7ef4\u5ea6\uff0c\u7ed3\u5408ADMM\u4f18\u5316\u6846\u67b6\uff0c\u5728\u53c2\u6570\u4f20\u8f93\u5230\u4e2d\u592e\u670d\u52a1\u5668\u524d\u8fdb\u884c\u964d\u7ef4\u5904\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aFedRP\u4e0d\u4ec5\u4fdd\u6301\u9ad8\u6a21\u578b\u7cbe\u5ea6\uff0c\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u901a\u4fe1\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5305\u62ec\u4f20\u7edf\u5dee\u5206\u9690\u79c1\u65b9\u6cd5\u548cFedADMM\u3002", "conclusion": "FedRP\u7b97\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u548c\u901a\u4fe1\u6210\u672c\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10048", "pdf": "https://arxiv.org/pdf/2509.10048", "abs": "https://arxiv.org/abs/2509.10048", "authors": ["Madhushan Ramalingam"], "title": "Uncertainty-Aware Tabular Prediction: Evaluating VBLL-Enhanced TabPFN in Safety-Critical Medical Data", "categories": ["cs.LG"], "comment": null, "summary": "Predictive models are being increasingly used across a wide range of domains,\nincluding safety-critical applications such as medical diagnosis and criminal\njustice. Reliable uncertainty estimation is a crucial task in such settings.\nTabular Prior-data Fitted Network (TabPFN) is a recently proposed machine\nlearning foundation model for tabular dataset, which uses a generative\ntransformer architecture. Variational Bayesian Last Layers (VBLL) is a\nstate-of-the-art lightweight variational formulation that effectively improves\nuncertainty estimation with minimal computational overhead. In this work we aim\nto evaluate the performance of VBLL integrated with the recently proposed\nTabPFN in uncertainty calibration. Our experiments, conducted on three\nbenchmark medical tabular datasets, compare the performance of the original\nTabPFN and the VBLL-integrated version. Contrary to expectations, we observed\nthat original TabPFN consistently outperforms VBLL integrated TabPFN in\nuncertainty calibration across all datasets.", "AI": {"tldr": "\u8bc4\u4f30VBLL\u4e0eTabPFN\u96c6\u6210\u5728\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u539f\u59cbTabPFN\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\u59cb\u7ec8\u4f18\u4e8eVBLL\u96c6\u6210\u7248\u672c", "motivation": "\u5728\u533b\u7597\u8bca\u65ad\u7b49\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\uff0c\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u8bc4\u4f30\u5148\u8fdb\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5VBLL\u4e0e\u65b0\u5174\u7684\u8868\u683c\u57fa\u7840\u6a21\u578bTabPFN\u7684\u96c6\u6210\u6548\u679c", "method": "\u5728\u4e09\u4e2a\u57fa\u51c6\u533b\u7597\u8868\u683c\u6570\u636e\u96c6\u4e0a\u5bf9\u6bd4\u539f\u59cbTabPFN\u548cVBLL\u96c6\u6210\u7248\u672c\u7684\u6027\u80fd\uff0c\u4f7f\u7528\u53d8\u5206\u8d1d\u53f6\u65af\u6700\u540e\u4e00\u5c42(VBLL)\u65b9\u6cd5\u4e0eTabPFN\u8fdb\u884c\u96c6\u6210", "result": "\u4e0e\u9884\u671f\u76f8\u53cd\uff0c\u539f\u59cbTabPFN\u5728\u6240\u6709\u6570\u636e\u96c6\u7684\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8eVBLL\u96c6\u6210\u7684TabPFN", "conclusion": "VBLL\u96c6\u6210\u5e76\u672a\u6539\u5584TabPFN\u7684\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u6027\u80fd\uff0c\u539f\u59cbTabPFN\u5728\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u9762\u8868\u73b0\u66f4\u4f18"}}
{"id": "2509.10089", "pdf": "https://arxiv.org/pdf/2509.10089", "abs": "https://arxiv.org/abs/2509.10089", "authors": ["Marco Andrea B\u00fchler", "Gonzalo Guill\u00e9n-Gos\u00e1lbez"], "title": "KAN-SR: A Kolmogorov-Arnold Network Guided Symbolic Regression Framework", "categories": ["cs.LG"], "comment": null, "summary": "We introduce a novel symbolic regression framework, namely KAN-SR, built on\nKolmogorov Arnold Networks (KANs) which follows a divide-and-conquer approach.\nSymbolic regression searches for mathematical equations that best fit a given\ndataset and is commonly solved with genetic programming approaches. We show\nthat by using deep learning techniques, more specific KANs, and combining them\nwith simplification strategies such as translational symmetries and\nseparabilities, we are able to recover ground-truth equations of the Feynman\nSymbolic Regression for Scientific Discovery (SRSD) dataset. Additionally, we\nshow that by combining the proposed framework with neural controlled\ndifferential equations, we are able to model the dynamics of an in-silico\nbioprocess system precisely, opening the door for the dynamic modeling of other\nengineering systems.", "AI": {"tldr": "KAN-SR\u662f\u4e00\u4e2a\u57fa\u4e8eKolmogorov Arnold Networks\u7684\u65b0\u578b\u7b26\u53f7\u56de\u5f52\u6846\u67b6\uff0c\u91c7\u7528\u5206\u6cbb\u65b9\u6cd5\uff0c\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u548c\u7b80\u5316\u7b56\u7565\uff0c\u80fd\u591f\u6062\u590dFeynman SRSD\u6570\u636e\u96c6\u7684\u771f\u5b9e\u65b9\u7a0b\uff0c\u5e76\u80fd\u7cbe\u786e\u6a21\u62df\u751f\u7269\u8fc7\u7a0b\u7cfb\u7edf\u52a8\u529b\u5b66\u3002", "motivation": "\u4f20\u7edf\u7b26\u53f7\u56de\u5f52\u901a\u5e38\u4f7f\u7528\u9057\u4f20\u7f16\u7a0b\u65b9\u6cd5\uff0c\u672c\u6587\u65e8\u5728\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u3001\u7279\u5b9aKAN\u7f51\u7edc\u548c\u7b80\u5316\u7b56\u7565\u6765\u6539\u8fdb\u7b26\u53f7\u56de\u5f52\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u79d1\u5b66\u53d1\u73b0\u548c\u5de5\u7a0b\u7cfb\u7edf\u52a8\u6001\u5efa\u6a21\u65b9\u9762\u3002", "method": "\u4f7f\u7528Kolmogorov Arnold Networks (KANs)\u6784\u5efa\u7b26\u53f7\u56de\u5f52\u6846\u67b6\uff0c\u91c7\u7528\u5206\u6cbb\u65b9\u6cd5\uff0c\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u3001\u5e73\u79fb\u5bf9\u79f0\u6027\u548c\u53ef\u5206\u79bb\u6027\u7b49\u7b80\u5316\u7b56\u7565\uff0c\u5e76\u4e0e\u795e\u7ecf\u63a7\u5236\u5fae\u5206\u65b9\u7a0b\u7ed3\u5408\u8fdb\u884c\u52a8\u6001\u5efa\u6a21\u3002", "result": "\u6210\u529f\u6062\u590d\u4e86Feynman SRSD\u6570\u636e\u96c6\u7684\u771f\u5b9e\u65b9\u7a0b\uff0c\u5e76\u7cbe\u786e\u6a21\u62df\u4e86\u7845\u5185\u751f\u7269\u8fc7\u7a0b\u7cfb\u7edf\u7684\u52a8\u529b\u5b66\uff0c\u4e3a\u5176\u4ed6\u5de5\u7a0b\u7cfb\u7edf\u7684\u52a8\u6001\u5efa\u6a21\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002", "conclusion": "KAN-SR\u6846\u67b6\u5728\u7b26\u53f7\u56de\u5f52\u548c\u52a8\u6001\u7cfb\u7edf\u5efa\u6a21\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u548c\u7b80\u5316\u7b56\u7565\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u9762\u4e34\u7684\u6311\u6218\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2509.10132", "pdf": "https://arxiv.org/pdf/2509.10132", "abs": "https://arxiv.org/abs/2509.10132", "authors": ["Nour Jamoussi", "Giuseppe Serra", "Photios A. Stavrou", "Marios Kountouris"], "title": "Cost-Free Personalization via Information-Geometric Projection in Bayesian Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Bayesian Federated Learning (BFL) combines uncertainty modeling with\ndecentralized training, enabling the development of personalized and reliable\nmodels under data heterogeneity and privacy constraints. Existing approaches\ntypically rely on Markov Chain Monte Carlo (MCMC) sampling or variational\ninference, often incorporating personalization mechanisms to better adapt to\nlocal data distributions. In this work, we propose an information-geometric\nprojection framework for personalization in parametric BFL. By projecting the\nglobal model onto a neighborhood of the user's local model, our method enables\na tunable trade-off between global generalization and local specialization.\nUnder mild assumptions, we show that this projection step is equivalent to\ncomputing a barycenter on the statistical manifold, allowing us to derive\nclosed-form solutions and achieve cost-free personalization. We apply the\nproposed approach to a variational learning setup using the Improved\nVariational Online Newton (IVON) optimizer and extend its application to\ngeneral aggregation schemes in BFL. Empirical evaluations under heterogeneous\ndata distributions confirm that our method effectively balances global and\nlocal performance with minimal computational overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u51e0\u4f55\u6295\u5f71\u7684\u8d1d\u53f6\u65af\u8054\u90a6\u5b66\u4e60\u4e2a\u6027\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5168\u5c40\u6a21\u578b\u6295\u5f71\u5230\u7528\u6237\u672c\u5730\u6a21\u578b\u90bb\u57df\uff0c\u5b9e\u73b0\u5168\u5c40\u6cdb\u5316\u4e0e\u672c\u5730\u7279\u5316\u7684\u53ef\u8c03\u6743\u8861\uff0c\u8ba1\u7b97\u6210\u672c\u4f4e\u4e14\u6548\u679c\u663e\u8457", "motivation": "\u73b0\u6709\u8d1d\u53f6\u65af\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56MCMC\u91c7\u6837\u6216\u53d8\u5206\u63a8\u65ad\uff0c\u9700\u8981\u4e2a\u6027\u5316\u673a\u5236\u6765\u9002\u5e94\u5f02\u6784\u6570\u636e\u5206\u5e03\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u8f83\u9ad8\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u4e2a\u4eba\u5316\u65b9\u6cd5", "method": "\u91c7\u7528\u4fe1\u606f\u51e0\u4f55\u6295\u5f71\u6846\u67b6\uff0c\u5c06\u5168\u5c40\u6a21\u578b\u6295\u5f71\u5230\u7528\u6237\u672c\u5730\u6a21\u578b\u90bb\u57df\uff0c\u8bc1\u660e\u8be5\u6295\u5f71\u7b49\u4ef7\u4e8e\u7edf\u8ba1\u6d41\u5f62\u4e0a\u7684\u91cd\u5fc3\u8ba1\u7b97\uff0c\u4ece\u800c\u83b7\u5f97\u95ed\u5f0f\u89e3\u3002\u7ed3\u5408\u6539\u8fdb\u7684\u53d8\u5206\u5728\u7ebf\u725b\u987f\u4f18\u5316\u5668(IVON)\u5e94\u7528\u4e8e\u53d8\u5206\u5b66\u4e60\u8bbe\u7f6e", "result": "\u5728\u5f02\u6784\u6570\u636e\u5206\u5e03\u4e0b\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5e73\u8861\u5168\u5c40\u548c\u672c\u5730\u6027\u80fd\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f", "conclusion": "\u63d0\u51fa\u7684\u4fe1\u606f\u51e0\u4f55\u6295\u5f71\u6846\u67b6\u4e3a\u8d1d\u53f6\u65af\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u7684\u4e2a\u4eba\u5316\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5168\u5c40\u6cdb\u5316\u4e0e\u672c\u5730\u7279\u5316\u7684\u6700\u4f18\u6743\u8861"}}
{"id": "2509.10151", "pdf": "https://arxiv.org/pdf/2509.10151", "abs": "https://arxiv.org/abs/2509.10151", "authors": ["Riccardo Lunelli", "Angus Nicolson", "Samuel Martin Pr\u00f6ll", "Sebastian Johannes Reinstadler", "Axel Bauer", "Clemens Dlaska"], "title": "BenchECG and xECG: a benchmark and baseline for ECG foundation models", "categories": ["cs.LG", "cs.AI", "I.2.1"], "comment": "32 pages, 4 figures, 22 tables", "summary": "Electrocardiograms (ECGs) are inexpensive, widely used, and well-suited to\ndeep learning. Recently, interest has grown in developing foundation models for\nECGs - models that generalise across diverse downstream tasks. However,\nconsistent evaluation has been lacking: prior work often uses narrow task\nselections and inconsistent datasets, hindering fair comparison. Here, we\nintroduce BenchECG, a standardised benchmark comprising a comprehensive suite\nof publicly available ECG datasets and versatile tasks. We also propose xECG,\nan xLSTM-based recurrent model trained with SimDINOv2 self-supervised learning,\nwhich achieves the best BenchECG score compared to publicly available\nstate-of-the-art models. In particular, xECG is the only publicly available\nmodel to perform strongly on all datasets and tasks. By standardising\nevaluation, BenchECG enables rigorous comparison and aims to accelerate\nprogress in ECG representation learning. xECG achieves superior performance\nover earlier approaches, defining a new baseline for future ECG foundation\nmodels.", "AI": {"tldr": "\u63d0\u51fa\u4e86BenchECG\u6807\u51c6\u5316\u57fa\u51c6\u548cxECG\u6a21\u578b\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\u89e3\u51b3ECG\u57fa\u7840\u6a21\u578b\u7f3a\u4e4f\u516c\u5e73\u6bd4\u8f83\u7684\u95ee\u9898\uff0cxECG\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u4efb\u52a1\u4e0a\u8868\u73b0\u6700\u4f73", "motivation": "\u73b0\u6709ECG\u57fa\u7840\u6a21\u578b\u7814\u7a76\u7f3a\u4e4f\u4e00\u81f4\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u4f7f\u7528\u4e0d\u540c\u7684\u4efb\u52a1\u9009\u62e9\u548c\u6570\u636e\u96c6\uff0c\u963b\u788d\u4e86\u516c\u5e73\u6bd4\u8f83\u548c\u8fdb\u5c55", "method": "\u5f00\u53d1BenchECG\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u5305\u542b\u5168\u9762\u7684\u516c\u5f00ECG\u6570\u636e\u96c6\u548c\u591a\u6837\u5316\u4efb\u52a1\uff1b\u63d0\u51fa\u57fa\u4e8exLSTM\u7684xECG\u6a21\u578b\uff0c\u4f7f\u7528SimDINOv2\u81ea\u76d1\u7763\u5b66\u4e60\u8fdb\u884c\u8bad\u7ec3", "result": "xECG\u5728BenchECG\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u83b7\u5f97\u6700\u4f73\u5206\u6570\uff0c\u662f\u552f\u4e00\u5728\u6240\u6709\u6570\u636e\u96c6\u548c\u4efb\u52a1\u4e0a\u90fd\u8868\u73b0\u4f18\u5f02\u7684\u516c\u5f00\u53ef\u7528\u6a21\u578b", "conclusion": "BenchECG\u901a\u8fc7\u6807\u51c6\u5316\u8bc4\u4f30\u5b9e\u73b0\u4e86\u4e25\u683c\u6bd4\u8f83\uff0cxECG\u4e3a\u672a\u6765ECG\u57fa\u7840\u6a21\u578b\u8bbe\u7acb\u4e86\u65b0\u7684\u6027\u80fd\u57fa\u51c6\uff0c\u6709\u671b\u52a0\u901fECG\u8868\u793a\u5b66\u4e60\u9886\u57df\u7684\u8fdb\u5c55"}}
{"id": "2509.10163", "pdf": "https://arxiv.org/pdf/2509.10163", "abs": "https://arxiv.org/abs/2509.10163", "authors": ["Francisco Javier Esono Nkulu Andong", "Qi Min"], "title": "Federated Multi-Agent Reinforcement Learning for Privacy-Preserving and Energy-Aware Resource Management in 6G Edge Networks", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": null, "summary": "As sixth-generation (6G) networks move toward ultra-dense, intelligent edge\nenvironments, efficient resource management under stringent privacy, mobility,\nand energy constraints becomes critical. This paper introduces a novel\nFederated Multi-Agent Reinforcement Learning (Fed-MARL) framework that\nincorporates cross-layer orchestration of both the MAC layer and application\nlayer for energy-efficient, privacy-preserving, and real-time resource\nmanagement across heterogeneous edge devices. Each agent uses a Deep Recurrent\nQ-Network (DRQN) to learn decentralized policies for task offloading, spectrum\naccess, and CPU energy adaptation based on local observations (e.g., queue\nlength, energy, CPU usage, and mobility). To protect privacy, we introduce a\nsecure aggregation protocol based on elliptic curve Diffie Hellman key\nexchange, which ensures accurate model updates without exposing raw data to\nsemi-honest adversaries. We formulate the resource management problem as a\npartially observable multi-agent Markov decision process (POMMDP) with a\nmulti-objective reward function that jointly optimizes latency, energy\nefficiency, spectral efficiency, fairness, and reliability under 6G-specific\nservice requirements such as URLLC, eMBB, and mMTC. Simulation results\ndemonstrate that Fed-MARL outperforms centralized MARL and heuristic baselines\nin task success rate, latency, energy efficiency, and fairness, while ensuring\nrobust privacy protection and scalability in dynamic, resource-constrained 6G\nedge networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8054\u90a6\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6Fed-MARL\uff0c\u7528\u4e8e6G\u8d85\u5bc6\u96c6\u8fb9\u7f18\u7f51\u7edc\u7684\u9690\u79c1\u4fdd\u62a4\u3001\u5b9e\u65f6\u8d44\u6e90\u7ba1\u7406\uff0c\u901a\u8fc7\u8de8\u5c42\u534f\u8c03MAC\u5c42\u548c\u5e94\u7528\u5c42\u5b9e\u73b0\u80fd\u6548\u4f18\u5316\u3002", "motivation": "6G\u7f51\u7edc\u5411\u8d85\u5bc6\u96c6\u667a\u80fd\u8fb9\u7f18\u73af\u5883\u53d1\u5c55\uff0c\u9700\u8981\u5728\u4e25\u683c\u9690\u79c1\u3001\u79fb\u52a8\u6027\u548c\u80fd\u8017\u7ea6\u675f\u4e0b\u5b9e\u73b0\u9ad8\u6548\u8d44\u6e90\u7ba1\u7406\uff0c\u4f20\u7edf\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u9762\u4e34\u9690\u79c1\u6cc4\u9732\u548c\u53ef\u6269\u5c55\u6027\u6311\u6218\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u5faa\u73afQ\u7f51\u7edc(DRQN)\u8ba9\u6bcf\u4e2a\u667a\u80fd\u4f53\u57fa\u4e8e\u672c\u5730\u89c2\u6d4b\u5b66\u4e60\u53bb\u4e2d\u5fc3\u5316\u7b56\u7565\uff0c\u7ed3\u5408\u692d\u5706\u66f2\u7ebfDiffie-Hellman\u5bc6\u94a5\u4ea4\u6362\u7684\u5b89\u5168\u805a\u5408\u534f\u8bae\u4fdd\u62a4\u9690\u79c1\uff0c\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u591a\u667a\u80fd\u4f53\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660eFed-MARL\u5728\u4efb\u52a1\u6210\u529f\u7387\u3001\u5ef6\u8fdf\u3001\u80fd\u6548\u548c\u516c\u5e73\u6027\u65b9\u9762\u4f18\u4e8e\u96c6\u4e2d\u5f0fMARL\u548c\u542f\u53d1\u5f0f\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u786e\u4fdd\u5f3a\u5927\u7684\u9690\u79c1\u4fdd\u62a4\u548c\u52a8\u60016G\u8fb9\u7f18\u7f51\u7edc\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "Fed-MARL\u6846\u67b6\u4e3a6G\u8fb9\u7f18\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u8d44\u6e90\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u540c\u65f6\u4f18\u5316\u591a\u4e2a\u6027\u80fd\u6307\u6807\u5e76\u6ee1\u8db36G\u7279\u5b9a\u670d\u52a1\u8981\u6c42\u3002"}}
{"id": "2509.10164", "pdf": "https://arxiv.org/pdf/2509.10164", "abs": "https://arxiv.org/abs/2509.10164", "authors": ["Hoshitaro Ohnishi", "Hideo Mukai"], "title": "A Symmetry-Integrated Approach to Surface Code Decoding", "categories": ["cs.LG", "quant-ph"], "comment": "12 pages, 6 figures", "summary": "Quantum error correction, which utilizes logical qubits that are encoded as\nredundant multiple physical qubits to find and correct errors in physical\nqubits, is indispensable for practical quantum computing. Surface code is\nconsidered to be a promising encoding method with a high error threshold that\nis defined by stabilizer generators. However, previous methods have suffered\nfrom the problem that the decoder acquires solely the error probability\ndistribution because of the non-uniqueness of correct prediction obtained from\nthe input. To circumvent this problem, we propose a technique to reoptimize the\ndecoder model by approximating syndrome measurements with a continuous function\nthat is mathematically interpolated by neural network. We evaluated the\nimprovement in accuracy of a multilayer perceptron based decoder for code\ndistances of 5 and 7 as well as for decoders based on convolutional and\nrecurrent neural networks and transformers for a code distance of 5. In all\ncases, the reoptimized decoder gave better accuracy than the original models,\ndemonstrating the universal effectiveness of the proposed method that is\nindependent of code distance or network architecture. These results suggest\nthat re-framing the problem of surface code decoding into a regression problem\nthat can be tackled by deep learning is a useful strategy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u8fde\u7eed\u51fd\u6570\u8fd1\u4f3c\u6765\u91cd\u65b0\u4f18\u5316\u8868\u9762\u7801\u89e3\u7801\u5668\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u56e0\u975e\u552f\u4e00\u6027\u9884\u6d4b\u53ea\u80fd\u83b7\u53d6\u8bef\u5dee\u6982\u7387\u5206\u5e03\u7684\u95ee\u9898", "motivation": "\u91cf\u5b50\u7ea0\u9519\u7801\u4e2d\u8868\u9762\u7801\u867d\u7136\u5177\u6709\u9ad8\u9519\u8bef\u9608\u503c\uff0c\u4f46\u4f20\u7edf\u89e3\u7801\u5668\u7531\u4e8e\u8f93\u5165\u9884\u6d4b\u7684\u975e\u552f\u4e00\u6027\u53ea\u80fd\u83b7\u53d6\u8bef\u5dee\u6982\u7387\u5206\u5e03\uff0c\u9700\u8981\u6539\u8fdb\u89e3\u7801\u7cbe\u5ea6", "method": "\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u6570\u5b66\u63d2\u503c\u8fd1\u4f3c\u7efc\u5408\u5f81\u6d4b\u91cf\uff0c\u5c06\u89e3\u7801\u95ee\u9898\u91cd\u6784\u4e3a\u56de\u5f52\u95ee\u9898\uff0c\u901a\u8fc7\u8fde\u7eed\u51fd\u6570\u91cd\u65b0\u4f18\u5316\u89e3\u7801\u5668\u6a21\u578b", "result": "\u5728\u7801\u8ddd5\u548c7\u7684\u591a\u5c42\u611f\u77e5\u673a\u89e3\u7801\u5668\uff0c\u4ee5\u53ca\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u3001\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u548cTransformer\u89e3\u7801\u5668\u4e0a\u5747\u663e\u793a\u51fa\u7cbe\u5ea6\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u666e\u9002\u6709\u6548\u6027", "conclusion": "\u5c06\u8868\u9762\u7801\u89e3\u7801\u95ee\u9898\u91cd\u65b0\u6784\u5efa\u4e3a\u53ef\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u89e3\u51b3\u7684\u56de\u5f52\u95ee\u9898\u662f\u4e00\u4e2a\u6709\u6548\u7684\u7b56\u7565\uff0c\u8be5\u65b9\u6cd5\u72ec\u7acb\u4e8e\u7801\u8ddd\u548c\u7f51\u7edc\u67b6\u6784\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd"}}
{"id": "2509.10167", "pdf": "https://arxiv.org/pdf/2509.10167", "abs": "https://arxiv.org/abs/2509.10167", "authors": ["L\u00e9na\u00efc Chizat"], "title": "The Hidden Width of Deep ResNets: Tight Error Bounds and Phase Diagrams", "categories": ["cs.LG", "68T07, 60H30, 34F05"], "comment": null, "summary": "We study the gradient-based training of large-depth residual networks\n(ResNets) from standard random initializations. We show that with a diverging\ndepth $L$, a fixed embedding dimension $D$, and an arbitrary hidden width $M$,\nthe training dynamics converges to a Neural Mean ODE training dynamics.\nRemarkably, the limit is independent of the scaling of $M$, covering practical\ncases of, say, Transformers, where $M$ (the number of hidden units or attention\nheads per layer) is typically of the order of $D$. For a residual scale\n$\\Theta_D\\big(\\frac{\\alpha}{LM}\\big)$, we obtain the error bound\n$O_D\\big(\\frac{1}{L}+ \\frac{\\alpha}{\\sqrt{LM}}\\big)$ between the model's output\nand its limit after a fixed number gradient of steps, and we verify empirically\nthat this rate is tight. When $\\alpha=\\Theta(1)$, the limit exhibits complete\nfeature learning, i.e. the Mean ODE is genuinely non-linearly parameterized. In\ncontrast, we show that $\\alpha \\to \\infty$ yields a \\lazy ODE regime where the\nMean ODE is linearly parameterized. We then focus on the particular case of\nResNets with two-layer perceptron blocks, for which we study how these scalings\ndepend on the embedding dimension $D$. We show that for this model, the only\nresidual scale that leads to complete feature learning is\n$\\Theta\\big(\\frac{\\sqrt{D}}{LM}\\big)$. In this regime, we prove the error bound\n$O\\big(\\frac{1}{L}+ \\frac{\\sqrt{D}}{\\sqrt{LM}}\\big)$ between the ResNet and its\nlimit after a fixed number of gradient steps, which is also empirically tight.\nOur convergence results rely on a novel mathematical perspective on ResNets :\n(i) due to the randomness of the initialization, the forward and backward pass\nthrough the ResNet behave as the stochastic approximation of certain mean ODEs,\nand (ii) by propagation of chaos (that is, asymptotic independence of the\nunits) this behavior is preserved through the training dynamics.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6df1\u5ea6\u6b8b\u5dee\u7f51\u7edc\u5728\u6807\u51c6\u968f\u673a\u521d\u59cb\u5316\u4e0b\u7684\u68af\u5ea6\u8bad\u7ec3\u52a8\u6001\uff0c\u8bc1\u660e\u4e86\u5f53\u6df1\u5ea6L\u8d8b\u8fd1\u65e0\u7a77\u65f6\uff0c\u8bad\u7ec3\u52a8\u6001\u6536\u655b\u5230\u795e\u7ecf\u5e73\u5747ODE\uff0c\u5e76\u7ed9\u51fa\u4e86\u8f93\u51fa\u4e0e\u6781\u9650\u4e4b\u95f4\u7684\u8bef\u5dee\u754c\u3002", "motivation": "\u7814\u7a76\u6df1\u5ea6\u6b8b\u5dee\u7f51\u7edc\u5728\u6807\u51c6\u968f\u673a\u521d\u59cb\u5316\u4e0b\u7684\u8bad\u7ec3\u52a8\u6001\uff0c\u7279\u522b\u662f\u5f53\u7f51\u7edc\u6df1\u5ea6\u5f88\u5927\u65f6\u7684\u6781\u9650\u884c\u4e3a\uff0c\u8fd9\u5bf9\u4e8e\u7406\u89e3Transformer\u7b49\u5b9e\u9645\u6a21\u578b\u7684\u7406\u8bba\u57fa\u7840\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u91c7\u7528\u6570\u5b66\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u968f\u673a\u521d\u59cb\u5316\u7684\u524d\u5411\u548c\u540e\u5411\u4f20\u64ad\u884c\u4e3a\u4f5c\u4e3a\u968f\u673a\u5e73\u5747ODE\u7684\u8fd1\u4f3c\uff0c\u5229\u7528\u4f20\u64ad\u6df7\u6c8c\u7406\u8bba\u4fdd\u6301\u8bad\u7ec3\u52a8\u6001\u4e2d\u7684\u8fd9\u79cd\u884c\u4e3a\u3002", "result": "\u8bc1\u660e\u4e86\u6df1\u5ea6\u6b8b\u5dee\u7f51\u7edc\u8bad\u7ec3\u52a8\u6001\u6536\u655b\u5230\u795e\u7ecf\u5e73\u5747ODE\uff0c\u7ed9\u51fa\u4e86\u8bef\u5dee\u754cO(1/L + \u03b1/\u221a(LM))\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8be5\u901f\u7387\u7684\u7d27\u6027\u3002\u5bf9\u4e8e\u4e24\u5c42\u611f\u77e5\u5668\u5757\u7684\u7279\u6b8a\u60c5\u51b5\uff0c\u786e\u5b9a\u4e86\u5bfc\u81f4\u5b8c\u5168\u7279\u5f81\u5b66\u4e60\u7684\u552f\u4e00\u6b8b\u5dee\u7f29\u653e\u6bd4\u4f8b\u3002", "conclusion": "\u6df1\u5ea6\u6b8b\u5dee\u7f51\u7edc\u5728\u6807\u51c6\u968f\u673a\u521d\u59cb\u5316\u4e0b\u5177\u6709\u660e\u786e\u7684\u6781\u9650\u8bad\u7ec3\u52a8\u6001\uff0c\u4e0d\u540c\u7684\u6b8b\u5dee\u7f29\u653e\u53c2\u6570\u4f1a\u5bfc\u81f4\u4e0d\u540c\u7684\u7279\u5f81\u5b66\u4e60\u673a\u5236\uff08\u5b8c\u5168\u7279\u5f81\u5b66\u4e60\u6216\u60f0\u6027ODE\u673a\u5236\uff09\uff0c\u8fd9\u4e3a\u7406\u89e3\u6df1\u5ea6\u7f51\u7edc\u7684\u7406\u8bba\u6027\u8d28\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u5b66\u89c6\u89d2\u3002"}}
{"id": "2509.10186", "pdf": "https://arxiv.org/pdf/2509.10186", "abs": "https://arxiv.org/abs/2509.10186", "authors": ["Benjamin Holzschuh", "Georg Kohl", "Florian Redinger", "Nils Thuerey"], "title": "P3D: Scalable Neural Surrogates for High-Resolution 3D Physics Simulations with Global Context", "categories": ["cs.LG"], "comment": null, "summary": "We present a scalable framework for learning deterministic and probabilistic\nneural surrogates for high-resolution 3D physics simulations. We introduce a\nhybrid CNN-Transformer backbone architecture targeted for 3D physics\nsimulations, which significantly outperforms existing architectures in terms of\nspeed and accuracy. Our proposed network can be pretrained on small patches of\nthe simulation domain, which can be fused to obtain a global solution,\noptionally guided via a fast and scalable sequence-to-sequence model to include\nlong-range dependencies. This setup allows for training large-scale models with\nreduced memory and compute requirements for high-resolution datasets. We\nevaluate our backbone architecture against a large set of baseline methods with\nthe objective to simultaneously learn the dynamics of 14 different types of\nPDEs in 3D. We demonstrate how to scale our model to high-resolution isotropic\nturbulence with spatial resolutions of up to $512^3$. Finally, we demonstrate\nthe versatility of our network by training it as a diffusion model to produce\nprobabilistic samples of highly turbulent 3D channel flows across varying\nReynolds numbers, accurately capturing the underlying flow statistics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5b66\u4e60\u9ad8\u5206\u8fa8\u73873D\u7269\u7406\u6a21\u62df\u7684\u786e\u5b9a\u6027\u548c\u6982\u7387\u6027\u795e\u7ecf\u4ee3\u7406\u6a21\u578b\uff0c\u91c7\u7528\u6df7\u5408CNN-Transformer\u67b6\u6784\uff0c\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u9ad8\u5206\u8fa8\u73873D\u7269\u7406\u6a21\u62df\u4e2d\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u5185\u5b58\u9700\u6c42\u5927\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u795e\u7ecf\u4ee3\u7406\u6a21\u578b\u6765\u66ff\u4ee3\u4f20\u7edf\u7684\u6570\u503c\u6a21\u62df\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u6df7\u5408CNN-Transformer\u9aa8\u5e72\u67b6\u6784\uff0c\u652f\u6301\u5728\u5c0f\u5757\u6a21\u62df\u57df\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u878d\u5408\u83b7\u5f97\u5168\u5c40\u89e3\uff0c\u53ef\u9009\u5730\u901a\u8fc7\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b\u5305\u542b\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\uff0c\u51cf\u5c11\u5185\u5b58\u548c\u8ba1\u7b97\u9700\u6c42\u3002", "result": "\u572814\u79cd\u4e0d\u540c\u7c7b\u578b3D PDE\u52a8\u529b\u5b66\u5b66\u4e60\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u53ef\u6269\u5c55\u5230512^3\u7a7a\u95f4\u5206\u8fa8\u7387\u7684\u9ad8\u5206\u8fa8\u7387\u5404\u5411\u540c\u6027\u6e4d\u6d41\uff0c\u5e76\u80fd\u4f5c\u4e3a\u6269\u6563\u6a21\u578b\u751f\u6210\u4e0d\u540c\u96f7\u8bfa\u6570\u4e0b\u9ad8\u5ea6\u6e4d\u6d413D\u901a\u9053\u6d41\u7684\u6982\u7387\u6837\u672c\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u9ad8\u5206\u8fa8\u73873D\u7269\u7406\u6a21\u62df\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u795e\u7ecf\u4ee3\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\uff0c\u5c55\u73b0\u4e86\u5728\u590d\u6742\u7269\u7406\u7cfb\u7edf\u5efa\u6a21\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2509.10189", "pdf": "https://arxiv.org/pdf/2509.10189", "abs": "https://arxiv.org/abs/2509.10189", "authors": ["Zexu Jin"], "title": "Hadamard-Riemannian Optimization for Margin-Variance Ensemble", "categories": ["cs.LG"], "comment": null, "summary": "Ensemble learning has been widely recognized as a pivotal technique for\nboosting predictive performance by combining multiple base models.\nNevertheless, conventional margin-based ensemble methods predominantly focus on\nmaximizing the expected margin while neglecting the critical role of margin\nvariance, which inherently restricts the generalization capability of the model\nand heightens its vulnerability to overfitting, particularly in noisy or\nimbalanced datasets. Additionally, the conventional approach of optimizing\nensemble weights within the probability simplex often introduces computational\ninefficiency and scalability challenges, complicating its application to\nlarge-scale problems. To tackle these limitations, this paper introduces a\nnovel ensemble learning framework that explicitly incorporates margin variance\ninto the loss function. Our method jointly optimizes the negative expected\nmargin and its variance, leading to enhanced robustness and improved\ngeneralization performance. Moreover, by reparameterizing the ensemble weights\nonto the unit sphere, we substantially simplify the optimization process and\nimprove computational efficiency. Extensive experiments conducted on multiple\nbenchmark datasets demonstrate that the proposed approach consistently\noutperforms traditional margin-based ensemble techniques, underscoring its\neffectiveness and practical utility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u96c6\u6210\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5c06margin\u65b9\u5dee\u7eb3\u5165\u635f\u5931\u51fd\u6570\u5e76\u91cd\u65b0\u53c2\u6570\u5316\u96c6\u6210\u6743\u91cd\u5230\u5355\u4f4d\u7403\u9762\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u57fa\u4e8emargin\u7684\u96c6\u6210\u65b9\u6cd5\u5ffd\u7565\u65b9\u5dee\u548c\u8ba1\u7b97\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8emargin\u7684\u96c6\u6210\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6700\u5927\u5316\u671f\u671bmargin\u800c\u5ffd\u7565margin\u65b9\u5dee\u7684\u91cd\u8981\u6027\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u5e76\u589e\u52a0\u4e86\u8fc7\u62df\u5408\u98ce\u9669\uff0c\u7279\u522b\u662f\u5728\u566a\u58f0\u6216\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u4e2d\u3002\u540c\u65f6\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u6982\u7387\u5355\u7eaf\u5f62\u4e2d\u4f18\u5316\u96c6\u6210\u6743\u91cd\u5b58\u5728\u8ba1\u7b97\u6548\u7387\u4f4e\u548c\u53ef\u6269\u5c55\u6027\u6311\u6218\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u96c6\u6210\u5b66\u4e60\u6846\u67b6\uff0c\u5c06margin\u65b9\u5dee\u663e\u5f0f\u7eb3\u5165\u635f\u5931\u51fd\u6570\uff0c\u8054\u5408\u4f18\u5316\u8d1f\u671f\u671bmargin\u53ca\u5176\u65b9\u5dee\u3002\u901a\u8fc7\u5c06\u96c6\u6210\u6743\u91cd\u91cd\u65b0\u53c2\u6570\u5316\u5230\u5355\u4f4d\u7403\u9762\uff0c\u7b80\u5316\u4f18\u5316\u8fc7\u7a0b\u5e76\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u4f20\u7edf\u7684\u57fa\u4e8emargin\u7684\u96c6\u6210\u6280\u672f\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u540c\u65f6\u8003\u8651\u671f\u671bmargin\u548cmargin\u65b9\u5dee\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u96c6\u6210\u5b66\u4e60\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u80fd\uff0c\u540c\u65f6\u901a\u8fc7\u91cd\u65b0\u53c2\u6570\u5316\u6280\u672f\u6539\u5584\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u5927\u89c4\u6a21\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10227", "pdf": "https://arxiv.org/pdf/2509.10227", "abs": "https://arxiv.org/abs/2509.10227", "authors": ["\u00c1ngel Ladr\u00f3n", "Miguel S\u00e1nchez-Dom\u00ednguez", "Javier Rozal\u00e9n", "Fernando R. S\u00e1nchez", "Javier de Vicente", "Lucas Lacasa", "Eusebio Valero", "Gonzalo Rubio"], "title": "A Certifiable Machine Learning-Based Pipeline to Predict Fatigue Life of Aircraft Structures", "categories": ["cs.LG", "physics.app-ph"], "comment": "29 pages, 15 figures", "summary": "Fatigue life prediction is essential in both the design and operational\nphases of any aircraft, and in this sense safety in the aerospace industry\nrequires early detection of fatigue cracks to prevent in-flight failures.\nRobust and precise fatigue life predictors are thus essential to ensure safety.\nTraditional engineering methods, while reliable, are time consuming and involve\ncomplex workflows, including steps such as conducting several Finite Element\nMethod (FEM) simulations, deriving the expected loading spectrum, and applying\ncycle counting techniques like peak-valley or rainflow counting. These steps\noften require collaboration between multiple teams and tools, added to the\ncomputational time and effort required to achieve fatigue life predictions.\nMachine learning (ML) offers a promising complement to traditional fatigue life\nestimation methods, enabling faster iterations and generalization, providing\nquick estimates that guide decisions alongside conventional simulations.\n  In this paper, we present a ML-based pipeline that aims to estimate the\nfatigue life of different aircraft wing locations given the flight parameters\nof the different missions that the aircraft will be operating throughout its\noperational life. We validate the pipeline in a realistic use case of fatigue\nlife estimation, yielding accurate predictions alongside a thorough statistical\nvalidation and uncertainty quantification. Our pipeline constitutes a\ncomplement to traditional methodologies by reducing the amount of costly\nsimulations and, thereby, lowering the required computational and human\nresources.", "AI": {"tldr": "\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u98de\u673a\u673a\u7ffc\u75b2\u52b3\u5bff\u547d\u9884\u6d4b\u7ba1\u9053\uff0c\u901a\u8fc7\u98de\u884c\u53c2\u6570\u5feb\u901f\u4f30\u7b97\u75b2\u52b3\u5bff\u547d\uff0c\u51cf\u5c11\u4f20\u7edf\u6709\u9650\u5143\u6a21\u62df\u7684\u8ba1\u7b97\u6210\u672c", "motivation": "\u4f20\u7edf\u75b2\u52b3\u5bff\u547d\u9884\u6d4b\u65b9\u6cd5\u8017\u65f6\u4e14\u590d\u6742\uff0c\u9700\u8981\u591a\u56e2\u961f\u534f\u4f5c\u548c\u5927\u91cf\u6709\u9650\u5143\u6a21\u62df\u3002\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ee5\u63d0\u4f9b\u5feb\u901f\u4f30\u7b97\uff0c\u4f5c\u4e3a\u4f20\u7edf\u65b9\u6cd5\u7684\u8865\u5145\uff0c\u63d0\u9ad8\u6548\u7387\u5e76\u964d\u4f4e\u8d44\u6e90\u9700\u6c42", "method": "\u63d0\u51fa\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u7ba1\u9053\uff0c\u6839\u636e\u98de\u673a\u6574\u4e2a\u8fd0\u884c\u5bff\u547d\u4e2d\u4e0d\u540c\u4efb\u52a1\u7684\u98de\u884c\u53c2\u6570\uff0c\u4f30\u7b97\u673a\u7ffc\u4e0d\u540c\u4f4d\u7f6e\u7684\u75b2\u52b3\u5bff\u547d\u3002\u5305\u62ec\u7edf\u8ba1\u9a8c\u8bc1\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316", "result": "\u5728\u771f\u5b9e\u75b2\u52b3\u5bff\u547d\u4f30\u7b97\u7528\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u7ba1\u9053\u7684\u51c6\u786e\u6027\uff0c\u80fd\u591f\u63d0\u4f9b\u7cbe\u786e\u9884\u6d4b", "conclusion": "\u8be5\u673a\u5668\u5b66\u4e60\u7ba1\u9053\u662f\u5bf9\u4f20\u7edf\u65b9\u6cd5\u7684\u6709\u6548\u8865\u5145\uff0c\u901a\u8fc7\u51cf\u5c11\u6602\u8d35\u6a21\u62df\u7684\u6570\u91cf\uff0c\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u4eba\u529b\u8d44\u6e90\u9700\u6c42"}}
{"id": "2509.10248", "pdf": "https://arxiv.org/pdf/2509.10248", "abs": "https://arxiv.org/abs/2509.10248", "authors": ["Janis Keuper"], "title": "Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications", "categories": ["cs.LG"], "comment": null, "summary": "The ongoing intense discussion on rising LLM usage in the scientific\npeer-review process has recently been mingled by reports of authors using\nhidden prompt injections to manipulate review scores. Since the existence of\nsuch \"attacks\" - although seen by some commentators as \"self-defense\" - would\nhave a great impact on the further debate, this paper investigates the\npracticability and technical success of the described manipulations. Our\nsystematic evaluation uses 1k reviews of 2024 ICLR papers generated by a wide\nrange of LLMs shows two distinct results: I) very simple prompt injections are\nindeed highly effective, reaching up to 100% acceptance scores. II) LLM reviews\nare generally biased toward acceptance (>95% in many models). Both results have\ngreat impact on the ongoing discussions on LLM usage in peer-review.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u8bc4\u4f30\u53d1\u73b0\uff1a\u7b80\u5355\u7684\u63d0\u793a\u8bcd\u6ce8\u5165\u653b\u51fb\u5bf9LLM\u540c\u884c\u8bc4\u5ba1\u9ad8\u5ea6\u6709\u6548\uff08\u53ef\u8fbe100%\u63a5\u53d7\u7387\uff09\uff0c\u4e14LLM\u8bc4\u5ba1\u666e\u904d\u5b58\u5728\u63a5\u53d7\u504f\u5411\uff08>95%\uff09\uff0c\u8fd9\u5bf9LLM\u5728\u5b66\u672f\u8bc4\u5ba1\u4e2d\u7684\u5e94\u7528\u8ba8\u8bba\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002", "motivation": "\u9488\u5bf9\u8fd1\u671f\u5173\u4e8e\u4f5c\u8005\u4f7f\u7528\u9690\u85cf\u63d0\u793a\u8bcd\u6ce8\u5165\u64cd\u7eb5LLM\u540c\u884c\u8bc4\u5ba1\u5206\u6570\u7684\u62a5\u9053\uff0c\u7814\u7a76\u6b64\u7c7b\u653b\u51fb\u7684\u53ef\u884c\u6027\u548c\u6280\u672f\u6210\u529f\u7387\uff0c\u56e0\u4e3a\u5176\u5b58\u5728\u5c06\u5bf9LLM\u5728\u5b66\u672f\u8bc4\u5ba1\u4e2d\u7684\u4f7f\u7528\u8fa9\u8bba\u4ea7\u751f\u91cd\u5927\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u591a\u79cdLLM\u5bf92024\u5e74ICLR\u4f1a\u8bae\u76841000\u7bc7\u8bba\u6587\u8bc4\u5ba1\u8fdb\u884c\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u5206\u6790\u63d0\u793a\u8bcd\u6ce8\u5165\u653b\u51fb\u7684\u6548\u679c\u548cLLM\u8bc4\u5ba1\u7684\u504f\u5411\u6027\u3002", "result": "1) \u975e\u5e38\u7b80\u5355\u63d0\u793a\u8bcd\u6ce8\u5165\u653b\u51fb\u9ad8\u5ea6\u6709\u6548\uff0c\u6700\u9ad8\u53ef\u8fbe100%\u63a5\u53d7\u7387\uff1b2) LLM\u8bc4\u5ba1\u666e\u904d\u5b58\u5728\u63a5\u53d7\u504f\u5411\uff0c\u8bb8\u591a\u6a21\u578b\u63a5\u53d7\u7387\u8d85\u8fc795%\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9\u5f53\u524d\u5173\u4e8eLLM\u5728\u540c\u884c\u8bc4\u5ba1\u4e2d\u4f7f\u7528\u7684\u8ba8\u8bba\u5177\u6709\u91cd\u5927\u5f71\u54cd\uff0c\u63ed\u793a\u4e86\u7cfb\u7edf\u6f0f\u6d1e\u548c\u56fa\u6709\u504f\u5411\u95ee\u9898\u3002"}}
{"id": "2509.10273", "pdf": "https://arxiv.org/pdf/2509.10273", "abs": "https://arxiv.org/abs/2509.10273", "authors": ["Sahil Sethi", "Kai Sundmacher", "Caroline Ganzer"], "title": "Property prediction for ionic liquids without prior structural knowledge using limited experimental data: A data-driven neural recommender system leveraging transfer learning", "categories": ["cs.LG"], "comment": null, "summary": "Ionic liquids (ILs) have emerged as versatile replacements for traditional\nsolvents because their physicochemical properties can be precisely tailored to\nvarious applications. However, accurately predicting key thermophysical\nproperties remains challenging due to the vast chemical design space and the\nlimited availability of experimental data. In this study, we present a\ndata-driven transfer learning framework that leverages a neural recommender\nsystem (NRS) to enable reliable property prediction for ILs using sparse\nexperimental datasets. The approach involves a two-stage process: first,\npre-training NRS models on COSMO-RS-based simulated data at fixed temperature\nand pressure to learn property-specific structural embeddings for cations and\nanions; and second, fine-tuning simple feedforward neural networks using these\nembeddings with experimental data at varying temperatures and pressures. In\nthis work, five essential IL properties are considered: density, viscosity,\nsurface tension, heat capacity, and melting point. The framework supports both\nwithin-property and cross-property knowledge transfer. Notably, pre-trained\nmodels for density, viscosity, and heat capacity are used to fine-tune models\nfor all five target properties, achieving improved performance by a substantial\nmargin for four of them. The model exhibits robust extrapolation to previously\nunseen ILs. Moreover, the final trained models enable property prediction for\nover 700,000 IL combinations, offering a scalable solution for IL screening in\nprocess design. This work highlights the effectiveness of combining simulated\ndata and transfer learning to overcome sparsity in the experimental data.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u63a8\u8350\u7cfb\u7edf\u7684\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528COSMO-RS\u6a21\u62df\u6570\u636e\u548c\u7a00\u758f\u5b9e\u9a8c\u6570\u636e\uff0c\u51c6\u786e\u9884\u6d4b\u79bb\u5b50\u6db2\u4f53\u7684\u4e94\u79cd\u5173\u952e\u70ed\u7269\u7406\u6027\u8d28", "motivation": "\u79bb\u5b50\u6db2\u4f53\u5177\u6709\u53ef\u5b9a\u5236\u7684\u7269\u7406\u5316\u5b66\u6027\u8d28\uff0c\u4f46\u7531\u4e8e\u5316\u5b66\u8bbe\u8ba1\u7a7a\u95f4\u5de8\u5927\u548c\u5b9e\u9a8c\u6570\u636e\u6709\u9650\uff0c\u51c6\u786e\u9884\u6d4b\u5176\u70ed\u7269\u7406\u6027\u8d28\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u9996\u5148\u5728\u56fa\u5b9a\u6e29\u538b\u4e0b\u7684COSMO-RS\u6a21\u62df\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\u795e\u7ecf\u63a8\u8350\u7cfb\u7edf\u6a21\u578b\uff0c\u5b66\u4e60\u9634\u9633\u79bb\u5b50\u7684\u6027\u8d28\u7279\u5f02\u6027\u7ed3\u6784\u5d4c\u5165\uff1b\u7136\u540e\u4f7f\u7528\u8fd9\u4e9b\u5d4c\u5165\u548c\u53d8\u6e29\u53d8\u538b\u5b9e\u9a8c\u6570\u636e\u5fae\u8c03\u7b80\u5355\u524d\u9988\u795e\u7ecf\u7f51\u7edc", "result": "\u9884\u8bad\u7ec3\u7684\u5bc6\u5ea6\u3001\u7c98\u5ea6\u548c\u70ed\u5bb9\u6a21\u578b\u7528\u4e8e\u5fae\u8c03\u6240\u6709\u4e94\u79cd\u76ee\u6807\u6027\u8d28\u6a21\u578b\uff0c\u5176\u4e2d\u56db\u79cd\u6027\u8d28\u7684\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002\u6a21\u578b\u5bf9\u672a\u89c1\u8fc7\u7684\u79bb\u5b50\u6db2\u4f53\u5177\u6709\u7a33\u5065\u5916\u63a8\u80fd\u529b\uff0c\u53ef\u4e3a\u8d85\u8fc770\u4e07\u79cd\u79bb\u5b50\u6db2\u4f53\u7ec4\u5408\u63d0\u4f9b\u6027\u8d28\u9884\u6d4b", "conclusion": "\u8be5\u5de5\u4f5c\u5c55\u793a\u4e86\u7ed3\u5408\u6a21\u62df\u6570\u636e\u548c\u8fc1\u79fb\u5b66\u4e60\u6765\u514b\u670d\u5b9e\u9a8c\u6570\u636e\u7a00\u758f\u6027\u7684\u6709\u6548\u6027\uff0c\u4e3a\u8fc7\u7a0b\u8bbe\u8ba1\u4e2d\u7684\u79bb\u5b50\u6db2\u4f53\u7b5b\u9009\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.10303", "pdf": "https://arxiv.org/pdf/2509.10303", "abs": "https://arxiv.org/abs/2509.10303", "authors": ["Jesse van Remmerden", "Zaharah Bukhsh", "Yingqian Zhang"], "title": "Generalizing Beyond Suboptimality: Offline Reinforcement Learning Learns Effective Scheduling through Random Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The Job-Shop Scheduling Problem (JSP) and Flexible Job-Shop Scheduling\nProblem (FJSP), are canonical combinatorial optimization problems with\nwide-ranging applications in industrial operations. In recent years, many\nonline reinforcement learning (RL) approaches have been proposed to learn\nconstructive heuristics for JSP and FJSP. Although effective, these online RL\nmethods require millions of interactions with simulated environments that may\nnot capture real-world complexities, and their random policy initialization\nleads to poor sample efficiency. To address these limitations, we introduce\nConservative Discrete Quantile Actor-Critic (CDQAC), a novel offline RL\nalgorithm that learns effective scheduling policies directly from historical\ndata, eliminating the need for costly online interactions, while maintaining\nthe ability to improve upon suboptimal training data. CDQAC couples a\nquantile-based critic with a delayed policy update, estimating the return\ndistribution of each machine-operation pair rather than selecting pairs\noutright. Our extensive experiments demonstrate CDQAC's remarkable ability to\nlearn from diverse data sources. CDQAC consistently outperforms the original\ndata-generating heuristics and surpasses state-of-the-art offline and online RL\nbaselines. In addition, CDQAC is highly sample efficient, requiring only 10-20\ntraining instances to learn high-quality policies. Surprisingly, we find that\nCDQAC performs better when trained on data generated by a random heuristic than\nwhen trained on higher-quality data from genetic algorithms and priority\ndispatching rules.", "AI": {"tldr": "\u63d0\u51faCDQAC\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u76f4\u63a5\u4ece\u5386\u53f2\u6570\u636e\u5b66\u4e60\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u7b56\u7565\uff0c\u65e0\u9700\u5728\u7ebf\u4ea4\u4e92\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u5728\u7ebfRL\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6a21\u62df\u73af\u5883\u4ea4\u4e92\u4e14\u6837\u672c\u6548\u7387\u4f4e\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u4e16\u754c\u590d\u6742\u6027\uff0c\u9700\u8981\u76f4\u63a5\u4ece\u5386\u53f2\u6570\u636e\u5b66\u4e60\u7684\u79bb\u7ebf\u65b9\u6cd5", "method": "CDQAC\u7ed3\u5408\u5206\u4f4d\u6570critic\u548c\u5ef6\u8fdf\u7b56\u7565\u66f4\u65b0\uff0c\u4f30\u8ba1\u6bcf\u4e2a\u673a\u5668-\u64cd\u4f5c\u5bf9\u7684\u56de\u62a5\u5206\u5e03\u800c\u975e\u76f4\u63a5\u9009\u62e9\uff0c\u80fd\u591f\u4ece\u6b21\u4f18\u6570\u636e\u4e2d\u6539\u8fdb", "result": "CDQAC\u5728\u591a\u79cd\u6570\u636e\u6e90\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u59cb\u7ec8\u4f18\u4e8e\u539f\u59cb\u6570\u636e\u751f\u6210\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u8d85\u8d8a\u6700\u5148\u8fdb\u7684\u79bb\u7ebf\u548c\u5728\u7ebfRL\u57fa\u7ebf\uff0c\u4ec5\u970010-20\u4e2a\u8bad\u7ec3\u5b9e\u4f8b", "conclusion": "CDQAC\u662f\u9ad8\u6548\u7684\u79bb\u7ebfRL\u8c03\u5ea6\u65b9\u6cd5\uff0c\u610f\u5916\u53d1\u73b0\u5728\u968f\u673a\u542f\u53d1\u5f0f\u751f\u6210\u6570\u636e\u4e0a\u8bad\u7ec3\u6548\u679c\u4f18\u4e8e\u9ad8\u8d28\u91cf\u9057\u4f20\u7b97\u6cd5\u6570\u636e"}}
{"id": "2509.10308", "pdf": "https://arxiv.org/pdf/2509.10308", "abs": "https://arxiv.org/abs/2509.10308", "authors": ["Joshua Dimasaka", "Christian Gei\u00df", "Robert Muir-Wood", "Emily So"], "title": "GraphCSVAE: Graph Categorical Structured Variational Autoencoder for Spatiotemporal Auditing of Physical Vulnerability Towards Sustainable Post-Disaster Risk Reduction", "categories": ["cs.LG"], "comment": "Accepted full paper at the 8th International Disaster and Risk\n  Conference, IDRC 2025 | Keywords: weakly supervised, graph deep learning,\n  categorical distribution, physical vulnerability, remote sensing,\n  spatiotemporal disaster risk, transition matrix | The data and code are\n  respectively available at https://doi.org/10.5281/zenodo.16656471 and\n  https://github.com/riskaudit/GraphCSVAE", "summary": "In the aftermath of disasters, many institutions worldwide face challenges in\ncontinually monitoring changes in disaster risk, limiting the ability of key\ndecision-makers to assess progress towards the UN Sendai Framework for Disaster\nRisk Reduction 2015-2030. While numerous efforts have substantially advanced\nthe large-scale modeling of hazard and exposure through Earth observation and\ndata-driven methods, progress remains limited in modeling another equally\nimportant yet challenging element of the risk equation: physical vulnerability.\nTo address this gap, we introduce Graph Categorical Structured Variational\nAutoencoder (GraphCSVAE), a novel probabilistic data-driven framework for\nmodeling physical vulnerability by integrating deep learning, graph\nrepresentation, and categorical probabilistic inference, using time-series\nsatellite-derived datasets and prior expert belief systems. We introduce a\nweakly supervised first-order transition matrix that reflects the changes in\nthe spatiotemporal distribution of physical vulnerability in two\ndisaster-stricken and socioeconomically disadvantaged areas: (1) the\ncyclone-impacted coastal Khurushkul community in Bangladesh and (2) the\nmudslide-affected city of Freetown in Sierra Leone. Our work reveals\npost-disaster regional dynamics in physical vulnerability, offering valuable\ninsights into localized spatiotemporal auditing and sustainable strategies for\npost-disaster risk reduction.", "AI": {"tldr": "\u63d0\u51fa\u4e86GraphCSVAE\u6846\u67b6\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u3001\u56fe\u8868\u793a\u548c\u5206\u7c7b\u6982\u7387\u63a8\u7406\u6574\u5408\u536b\u661f\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u548c\u4e13\u5bb6\u77e5\u8bc6\uff0c\u7528\u4e8e\u5efa\u6a21\u707e\u5bb3\u7269\u7406\u8106\u5f31\u6027\uff0c\u5e76\u5728\u5b5f\u52a0\u62c9\u56fd\u548c\u585e\u62c9\u5229\u6602\u7684\u707e\u5bb3\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u707e\u5bb3\u98ce\u9669\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u707e\u5bb3\u548c\u66b4\u9732\u5ea6\u5efa\u6a21\uff0c\u4f46\u5728\u7269\u7406\u8106\u5f31\u6027\u5efa\u6a21\u65b9\u9762\u8fdb\u5c55\u6709\u9650\uff0c\u9650\u5236\u4e86\u51b3\u7b56\u8005\u5bf9\u8054\u5408\u56fd\u4ed9\u53f0\u6846\u67b6\u8fdb\u5c55\u7684\u8bc4\u4f30\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e86Graph Categorical Structured Variational Autoencoder (GraphCSVAE)\u6982\u7387\u6846\u67b6\uff0c\u6574\u5408\u6df1\u5ea6\u5b66\u4e60\u3001\u56fe\u8868\u793a\u548c\u5206\u7c7b\u6982\u7387\u63a8\u7406\uff0c\u4f7f\u7528\u65f6\u95f4\u5e8f\u5217\u536b\u661f\u6570\u636e\u548c\u4e13\u5bb6\u5148\u9a8c\u77e5\u8bc6\uff0c\u5f15\u5165\u5f31\u76d1\u7763\u4e00\u9636\u8f6c\u79fb\u77e9\u9635\u6765\u53cd\u6620\u7269\u7406\u8106\u5f31\u6027\u7684\u65f6\u7a7a\u5206\u5e03\u53d8\u5316\u3002", "result": "\u5728\u4e24\u4e2a\u707e\u5bb3\u9891\u53d1\u4e14\u793e\u4f1a\u7ecf\u6d4e\u5f31\u52bf\u5730\u533a\uff08\u5b5f\u52a0\u62c9\u56fdKhurushkul\u793e\u533a\u548c\u585e\u62c9\u5229\u6602\u5f17\u91cc\u6566\u5e02\uff09\u6210\u529f\u63ed\u793a\u4e86\u707e\u540e\u7269\u7406\u8106\u5f31\u6027\u7684\u533a\u57df\u52a8\u6001\u53d8\u5316\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5c40\u90e8\u65f6\u7a7a\u5ba1\u8ba1\u548c\u707e\u540e\u98ce\u9669\u51cf\u5c11\u7684\u53ef\u6301\u7eed\u7b56\u7565\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u80fd\u591f\u6709\u6548\u5efa\u6a21\u7269\u7406\u8106\u5f31\u6027\u7684\u65f6\u7a7a\u53d8\u5316\u3002"}}
{"id": "2509.10324", "pdf": "https://arxiv.org/pdf/2509.10324", "abs": "https://arxiv.org/abs/2509.10324", "authors": ["Myung Jin Kim", "YeongHyeon Park", "Il Dong Yun"], "title": "ARMA Block: A CNN-Based Autoregressive and Moving Average Module for Long-Term Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "This paper proposes a simple yet effective convolutional module for long-term\ntime series forecasting. The proposed block, inspired by the Auto-Regressive\nIntegrated Moving Average (ARIMA) model, consists of two convolutional\ncomponents: one for capturing the trend (autoregression) and the other for\nrefining local variations (moving average). Unlike conventional ARIMA, which\nrequires iterative multi-step forecasting, the block directly performs\nmulti-step forecasting, making it easily extendable to multivariate settings.\nExperiments on nine widely used benchmark datasets demonstrate that our method\nARMA achieves competitive accuracy, particularly on datasets exhibiting strong\ntrend variations, while maintaining architectural simplicity. Furthermore,\nanalysis shows that the block inherently encodes absolute positional\ninformation, suggesting its potential as a lightweight replacement for\npositional embeddings in sequential models.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eARIMA\u6a21\u578b\u542f\u53d1\u7684\u7b80\u5355\u5377\u79ef\u6a21\u5757ARMA\uff0c\u7528\u4e8e\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u5305\u542b\u8d8b\u52bf\u6355\u6349\u548c\u5c40\u90e8\u53d8\u5316\u4fee\u6b63\u4e24\u4e2a\u7ec4\u4ef6\uff0c\u76f4\u63a5\u8fdb\u884c\u591a\u6b65\u9884\u6d4b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edfARIMA\u6a21\u578b\u9700\u8981\u8fed\u4ee3\u591a\u6b65\u9884\u6d4b\u4e14\u96be\u4ee5\u6269\u5c55\u5230\u591a\u53d8\u91cf\u8bbe\u7f6e\uff0c\u9700\u8981\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u53cc\u7ec4\u4ef6\u5377\u79ef\u6a21\u5757\uff1a\u4e00\u4e2a\u5377\u79ef\u7ec4\u4ef6\u6355\u6349\u8d8b\u52bf\uff08\u81ea\u56de\u5f52\uff09\uff0c\u53e6\u4e00\u4e2a\u5377\u79ef\u7ec4\u4ef6\u4fee\u6b63\u5c40\u90e8\u53d8\u5316\uff08\u79fb\u52a8\u5e73\u5747\uff09\uff0c\u76f4\u63a5\u8fdb\u884c\u591a\u6b65\u9884\u6d4b\uff0c\u6613\u4e8e\u6269\u5c55\u5230\u591a\u53d8\u91cf\u573a\u666f\u3002", "result": "\u57289\u4e2a\u5e38\u7528\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cARMA\u65b9\u6cd5\u5728\u5177\u6709\u5f3a\u8d8b\u52bf\u53d8\u5316\u7684\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u4fdd\u6301\u67b6\u6784\u7b80\u5355\u6027\u3002\u5206\u6790\u663e\u793a\u8be5\u6a21\u5757\u80fd\u81ea\u7136\u7f16\u7801\u7edd\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u3002", "conclusion": "ARMA\u6a21\u5757\u662f\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u7ade\u4e89\u6027\u7684\u51c6\u786e\u6027\u3001\u67b6\u6784\u7b80\u5355\u6027\uff0c\u5e76\u53ef\u4f5c\u4e3a\u5e8f\u5217\u6a21\u578b\u4e2d\u4f4d\u7f6e\u5d4c\u5165\u7684\u8f7b\u91cf\u7ea7\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2509.10363", "pdf": "https://arxiv.org/pdf/2509.10363", "abs": "https://arxiv.org/abs/2509.10363", "authors": ["Benjamin David Shaffer", "Brooks Kinch", "Joseph Klobusicky", "M. Ani Hsieh", "Nathaniel Trask"], "title": "Physics-informed sensor coverage through structure preserving machine learning", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "We present a machine learning framework for adaptive source localization in\nwhich agents use a structure-preserving digital twin of a coupled\nhydrodynamic-transport system for real-time trajectory planning and data\nassimilation. The twin is constructed with conditional neural Whitney forms\n(CNWF), coupling the numerical guarantees of finite element exterior calculus\n(FEEC) with transformer-based operator learning. The resulting model preserves\ndiscrete conservation, and adapts in real time to streaming sensor data. It\nemploys a conditional attention mechanism to identify: a reduced Whitney-form\nbasis; reduced integral balance equations; and a source field, each compatible\nwith given sensor measurements. The induced reduced-order environmental model\nretains the stability and consistency of standard finite-element simulation,\nyielding a physically realizable, regular mapping from sensor data to the\nsource field. We propose a staggered scheme that alternates between evaluating\nthe digital twin and applying Lloyd's algorithm to guide sensor placement, with\nanalysis providing conditions for monotone improvement of a coverage\nfunctional. Using the predicted source field as an importance function within\nan optimal-recovery scheme, we demonstrate recovery of point sources under\ncontinuity assumptions, highlighting the role of regularity as a sufficient\ncondition for localization. Experimental comparisons with physics-agnostic\ntransformer architectures show improved accuracy in complex geometries when\nphysical constraints are enforced, indicating that structure preservation\nprovides an effective inductive bias for source identification.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ed3\u6784\u4fdd\u6301\u6570\u5b57\u5b6a\u751f\u7684\u81ea\u9002\u5e94\u6e90\u5b9a\u4f4d\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u6761\u4ef6\u795e\u7ecfWhitney\u5f62\u5f0f\u548c\u53d8\u538b\u5668\u7b97\u5b50\u5b66\u4e60\uff0c\u5b9e\u73b0\u5b9e\u65f6\u8f68\u8ff9\u89c4\u5212\u548c\u6570\u636e\u540c\u5316", "motivation": "\u89e3\u51b3\u590d\u6742\u6d41\u4f53\u8f93\u8fd0\u7cfb\u7edf\u4e2d\u6e90\u5b9a\u4f4d\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5728\u5b9e\u65f6\u6027\u548c\u7269\u7406\u7ea6\u675f\u4fdd\u6301\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u4fdd\u6301\u7269\u7406\u5b88\u6052\u5f8b\u53c8\u80fd\u9002\u5e94\u5b9e\u65f6\u4f20\u611f\u5668\u6570\u636e\u7684\u667a\u80fd\u65b9\u6cd5", "method": "\u4f7f\u7528\u6761\u4ef6\u795e\u7ecfWhitney\u5f62\u5f0f(CNWF)\u6784\u5efa\u6570\u5b57\u5b6a\u751f\uff0c\u8026\u5408\u6709\u9650\u5143\u5916\u5fae\u79ef\u5206(FEEC)\u7684\u6570\u503c\u4fdd\u8bc1\u4e0e\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u7b97\u5b50\u5b66\u4e60\uff0c\u91c7\u7528\u4ea4\u9519\u65b9\u6848\u4ea4\u66ff\u8bc4\u4f30\u6570\u5b57\u5b6a\u751f\u548c\u5e94\u7528Lloyd\u7b97\u6cd5\u6307\u5bfc\u4f20\u611f\u5668\u5e03\u7f6e", "result": "\u5b9e\u9a8c\u663e\u793a\u5728\u590d\u6742\u51e0\u4f55\u5f62\u72b6\u4e2d\uff0c\u5f53\u5f3a\u5236\u6267\u884c\u7269\u7406\u7ea6\u675f\u65f6\uff0c\u76f8\u6bd4\u7269\u7406\u4e0d\u53ef\u77e5\u53d8\u538b\u5668\u67b6\u6784\u5177\u6709\u66f4\u9ad8\u7684\u7cbe\u5ea6\uff0c\u7ed3\u6784\u4fdd\u6301\u4e3a\u6e90\u8bc6\u522b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5f52\u7eb3\u504f\u7f6e", "conclusion": "\u7ed3\u6784\u4fdd\u6301\u7684\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u81ea\u9002\u5e94\u6e90\u5b9a\u4f4d\uff0c\u4fdd\u6301\u79bb\u6563\u5b88\u6052\u6027\u5e76\u5b9e\u65f6\u9002\u5e94\u4f20\u611f\u5668\u6570\u636e\uff0c\u4e3a\u590d\u6742\u73af\u5883\u7cfb\u7edf\u4e2d\u7684\u6e90\u8bc6\u522b\u95ee\u9898\u63d0\u4f9b\u4e86\u7269\u7406\u53ef\u5b9e\u73b0\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.10367", "pdf": "https://arxiv.org/pdf/2509.10367", "abs": "https://arxiv.org/abs/2509.10367", "authors": ["Tong Chen", "Raghavendra Selvan"], "title": "A Discrepancy-Based Perspective on Dataset Condensation", "categories": ["cs.LG"], "comment": "30 pages, 4 tables, 1 figure", "summary": "Given a dataset of finitely many elements $\\mathcal{T} = \\{\\mathbf{x}_i\\}_{i\n= 1}^N$, the goal of dataset condensation (DC) is to construct a synthetic\ndataset $\\mathcal{S} = \\{\\tilde{\\mathbf{x}}_j\\}_{j = 1}^M$ which is\nsignificantly smaller ($M \\ll N$) such that a model trained from scratch on\n$\\mathcal{S}$ achieves comparable or even superior generalization performance\nto a model trained on $\\mathcal{T}$. Recent advances in DC reveal a close\nconnection to the problem of approximating the data distribution represented by\n$\\mathcal{T}$ with a reduced set of points. In this work, we present a unified\nframework that encompasses existing DC methods and extend the task-specific\nnotion of DC to a more general and formal definition using notions of\ndiscrepancy, which quantify the distance between probability distribution in\ndifferent regimes. Our framework broadens the objective of DC beyond\ngeneralization, accommodating additional objectives such as robustness,\nprivacy, and other desirable properties.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u6765\u5f62\u5f0f\u5316\u6570\u636e\u96c6\u538b\u7f29\u95ee\u9898\uff0c\u5c06\u4f20\u7edf\u57fa\u4e8e\u6cdb\u5316\u6027\u80fd\u7684\u65b9\u6cd5\u6269\u5c55\u5230\u66f4\u5e7f\u6cdb\u7684\u5206\u5e03\u8fd1\u4f3c\u76ee\u6807\uff0c\u5305\u62ec\u9c81\u68d2\u6027\u3001\u9690\u79c1\u4fdd\u62a4\u7b49\u7279\u6027\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u96c6\u538b\u7f29\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6cdb\u5316\u6027\u80fd\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u3002\u4f5c\u8005\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u66f4\u901a\u7528\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u80fd\u591f\u6db5\u76d6\u591a\u79cd\u76ee\u6807\u5e76\u91cf\u5316\u5206\u5e03\u8fd1\u4f3c\u8d28\u91cf\u3002", "method": "\u4f7f\u7528\u5dee\u5f02\u5ea6\u6982\u5ff5\u6765\u91cf\u5316\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u6784\u5efa\u7edf\u4e00\u6846\u67b6\u6765\u5f62\u5f0f\u5316\u6570\u636e\u96c6\u538b\u7f29\u95ee\u9898\uff0c\u5c06\u4efb\u52a1\u6269\u5c55\u5230\u5305\u62ec\u9c81\u68d2\u6027\u3001\u9690\u79c1\u4fdd\u62a4\u7b49\u591a\u91cd\u76ee\u6807\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u7edf\u4e00\u73b0\u6709\u6570\u636e\u96c6\u538b\u7f29\u65b9\u6cd5\u7684\u7406\u8bba\u6846\u67b6\uff0c\u6269\u5c55\u4e86\u538b\u7f29\u76ee\u6807\u7684\u8303\u56f4\uff0c\u4e3a\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e0b\u7684\u6570\u636e\u96c6\u538b\u7f29\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u57fa\u7840\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6570\u636e\u96c6\u538b\u7f29\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u548c\u5f62\u5f0f\u5316\u7684\u7406\u8bba\u57fa\u7840\uff0c\u4f7f\u5f97\u538b\u7f29\u65b9\u6cd5\u80fd\u591f\u9488\u5bf9\u4e0d\u540c\u5e94\u7528\u9700\u6c42\uff08\u5982\u6cdb\u5316\u3001\u9c81\u68d2\u6027\u3001\u9690\u79c1\u7b49\uff09\u8fdb\u884c\u4f18\u5316\u8bbe\u8ba1\u3002"}}
{"id": "2509.10369", "pdf": "https://arxiv.org/pdf/2509.10369", "abs": "https://arxiv.org/abs/2509.10369", "authors": ["Gul Rukh Khattak", "Konstantinos Patlatzoglou", "Joseph Barker", "Libor Pastika", "Boroumand Zeidaabadi", "Ahmed El-Medany", "Hesham Aggour", "Yixiu Liang", "Antonio H. Ribeiro", "Jeffrey Annis", "Antonio Luiz Pinho Ribeiro", "Junbo Ge", "Daniel B. Kramer", "Jonathan W. Waks", "Evan Brittain", "Nicholas Peters", "Fu Siong Ng", "Arunashis Sau"], "title": "Data distribution impacts the performance and generalisability of contrastive learning-based foundation models of electrocardiograms", "categories": ["cs.LG", "cs.AI", "eess.SP", "q-bio.TO"], "comment": "Currently under review at npj Digital Medicine", "summary": "Contrastive learning is a widely adopted self-supervised pretraining\nstrategy, yet its dependence on cohort composition remains underexplored. We\npresent Contrasting by Patient Augmented Electrocardiograms (CAPE) foundation\nmodel and pretrain on four cohorts (n = 5,203,352), from diverse populations\nacross three continents (North America, South America, Asia). We systematically\nassess how cohort demographics, health status, and population diversity\ninfluence the downstream performance for prediction tasks also including two\nadditional cohorts from another continent (Europe). We find that downstream\nperformance depends on the distributional properties of the pretraining cohort,\nincluding demographics and health status. Moreover, while pretraining with a\nmulti-centre, demographically diverse cohort improves in-distribution accuracy,\nit reduces out-of-distribution (OOD) generalisation of our contrastive approach\nby encoding cohort-specific artifacts. To address this, we propose the\nIn-Distribution Batch (IDB) strategy, which preserves intra-cohort consistency\nduring pretraining and enhances OOD robustness. This work provides important\ninsights for developing clinically fair and generalisable foundation models.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5bf9\u6bd4\u5b66\u4e60\u5728ECG\u9884\u8bad\u7ec3\u4e2d\u961f\u5217\u7ec4\u6210\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u591a\u4e2d\u5fc3\u591a\u6837\u5316\u961f\u5217\u867d\u7136\u63d0\u9ad8\u5206\u5e03\u5185\u51c6\u786e\u7387\uff0c\u4f46\u4f1a\u964d\u4f4e\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86IDB\u7b56\u7565\u6765\u589e\u5f3a\u9c81\u68d2\u6027\u3002", "motivation": "\u63a2\u7d22\u5bf9\u6bd4\u5b66\u4e60\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u7b56\u7565\u5bf9\u961f\u5217\u7ec4\u6210\u7684\u4f9d\u8d56\u6027\uff0c\u7279\u522b\u662f\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u5b66\u3001\u5065\u5eb7\u72b6\u51b5\u548c\u4eba\u7fa4\u591a\u6837\u6027\u5bf9\u4e0b\u6e38\u9884\u6d4b\u4efb\u52a1\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86CAPE\u57fa\u7840\u6a21\u578b\uff0c\u5728\u56db\u5927\u6d32\u4e94\u4e2a\u961f\u5217\uff08n=5,203,352\uff09\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7cfb\u7edf\u8bc4\u4f30\u9884\u8bad\u7ec3\u961f\u5217\u7279\u5f81\u5bf9\u4e0b\u6e38\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86In-Distribution Batch (IDB)\u7b56\u7565\u6765\u4fdd\u6301\u961f\u5217\u5185\u4e00\u81f4\u6027\u3002", "result": "\u53d1\u73b0\u4e0b\u6e38\u6027\u80fd\u53d6\u51b3\u4e8e\u9884\u8bad\u7ec3\u961f\u5217\u7684\u5206\u5e03\u7279\u6027\uff0c\u5305\u62ec\u4eba\u53e3\u7edf\u8ba1\u5b66\u548c\u5065\u5eb7\u72b6\u51b5\u3002\u591a\u4e2d\u5fc3\u591a\u6837\u5316\u961f\u5217\u63d0\u9ad8\u4e86\u5206\u5e03\u5185\u51c6\u786e\u7387\uff0c\u4f46\u901a\u8fc7\u7f16\u7801\u961f\u5217\u7279\u5b9a\u4f2a\u5f71\u964d\u4f4e\u4e86\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u7684\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "IDB\u7b56\u7565\u80fd\u591f\u4fdd\u6301\u9884\u8bad\u7ec3\u671f\u95f4\u7684\u961f\u5217\u5185\u4e00\u81f4\u6027\u5e76\u589e\u5f3a\u5206\u5e03\u5916\u9c81\u68d2\u6027\uff0c\u4e3a\u5f00\u53d1\u4e34\u5e8a\u516c\u5e73\u548c\u53ef\u6cdb\u5316\u7684\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2509.10384", "pdf": "https://arxiv.org/pdf/2509.10384", "abs": "https://arxiv.org/abs/2509.10384", "authors": ["Jianxin Zhang", "Clayton Scott"], "title": "Flow Straight and Fast in Hilbert Space: Functional Rectified Flow", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Many generative models originally developed in finite-dimensional Euclidean\nspace have functional generalizations in infinite-dimensional settings.\nHowever, the extension of rectified flow to infinite-dimensional spaces remains\nunexplored. In this work, we establish a rigorous functional formulation of\nrectified flow in an infinite-dimensional Hilbert space. Our approach builds\nupon the superposition principle for continuity equations in an\ninfinite-dimensional space. We further show that this framework extends\nnaturally to functional flow matching and functional probability flow ODEs,\ninterpreting them as nonlinear generalizations of rectified flow. Notably, our\nextension to functional flow matching removes the restrictive measure-theoretic\nassumptions in the existing theory of \\citet{kerrigan2024functional}.\nFurthermore, we demonstrate experimentally that our method achieves superior\nperformance compared to existing functional generative models.", "AI": {"tldr": "\u672c\u6587\u5efa\u7acb\u4e86\u65e0\u9650\u7ef4\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u6574\u6d41\u6d41\u7684\u4e25\u683c\u51fd\u6570\u5316\u8868\u8ff0\uff0c\u6269\u5c55\u4e86\u6574\u6d41\u6d41\u5230\u65e0\u9650\u7ef4\u7a7a\u95f4\u7684\u6846\u67b6\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u51fd\u6570\u6d41\u5339\u914d\u548c\u6982\u7387\u6d41ODE\u4e2d\u7684\u81ea\u7136\u5e94\u7528\u3002", "motivation": "\u8bb8\u591a\u5728\u6709\u9650\u7ef4\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u5f00\u53d1\u7684\u751f\u6210\u6a21\u578b\u5728\u65e0\u9650\u7ef4\u8bbe\u7f6e\u4e2d\u90fd\u6709\u51fd\u6570\u5316\u63a8\u5e7f\uff0c\u4f46\u6574\u6d41\u6d41\u5411\u65e0\u9650\u7ef4\u7a7a\u95f4\u7684\u6269\u5c55\u5c1a\u672a\u88ab\u63a2\u7d22\u3002", "method": "\u57fa\u4e8e\u65e0\u9650\u7ef4\u7a7a\u95f4\u4e2d\u8fde\u7eed\u6027\u65b9\u7a0b\u7684\u53e0\u52a0\u539f\u7406\uff0c\u5efa\u7acb\u4e86\u6574\u6d41\u6d41\u7684\u51fd\u6570\u5316\u8868\u8ff0\u6846\u67b6\uff0c\u5e76\u5c06\u5176\u6269\u5c55\u5230\u51fd\u6570\u6d41\u5339\u914d\u548c\u51fd\u6570\u6982\u7387\u6d41ODE\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u51fd\u6570\u751f\u6210\u6a21\u578b\u5177\u6709\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u540c\u65f6\u79fb\u9664\u4e86\u73b0\u6709\u7406\u8bba\u4e2d\u7684\u9650\u5236\u6027\u6d4b\u5ea6\u7406\u8bba\u5047\u8bbe\u3002", "conclusion": "\u6210\u529f\u5efa\u7acb\u4e86\u65e0\u9650\u7ef4\u7a7a\u95f4\u4e2d\u6574\u6d41\u6d41\u7684\u4e25\u683c\u6570\u5b66\u6846\u67b6\uff0c\u4e3a\u51fd\u6570\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2509.10390", "pdf": "https://arxiv.org/pdf/2509.10390", "abs": "https://arxiv.org/abs/2509.10390", "authors": ["Quan Nguyen", "Adji Bousso Dieng"], "title": "Vendi Information Gain for Active Learning and its Application to Ecology", "categories": ["cs.LG", "cs.IT", "math.IT", "q-bio.PE"], "comment": null, "summary": "While monitoring biodiversity through camera traps has become an important\nendeavor for ecological research, identifying species in the captured image\ndata remains a major bottleneck due to limited labeling resources. Active\nlearning -- a machine learning paradigm that selects the most informative data\nto label and train a predictive model -- offers a promising solution, but\ntypically focuses on uncertainty in the individual predictions without\nconsidering uncertainty across the entire dataset. We introduce a new active\nlearning policy, Vendi information gain (VIG), that selects images based on\ntheir impact on dataset-wide prediction uncertainty, capturing both\ninformativeness and diversity. Applied to the Snapshot Serengeti dataset, VIG\nachieves impressive predictive accuracy close to full supervision using less\nthan 10% of the labels. It consistently outperforms standard baselines across\nmetrics and batch sizes, collecting more diverse data in the feature space. VIG\nhas broad applicability beyond ecology, and our results highlight its value for\nbiodiversity monitoring in data-limited environments.", "AI": {"tldr": "\u63d0\u51faVendi\u4fe1\u606f\u589e\u76ca(VIG)\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\uff0c\u901a\u8fc7\u8003\u8651\u6570\u636e\u96c6\u6574\u4f53\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u6765\u9009\u62e9\u4fe1\u606f\u91cf\u548c\u591a\u6837\u6027\u517c\u5907\u7684\u56fe\u50cf\uff0c\u5728Snapshot Serengeti\u6570\u636e\u96c6\u4e0a\u4ec5\u7528\u4e0d\u523010%\u7684\u6807\u7b7e\u5c31\u8fbe\u5230\u4e86\u63a5\u8fd1\u5168\u76d1\u7763\u7684\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u76f8\u673a\u9677\u9631\u76d1\u6d4b\u751f\u7269\u591a\u6837\u6027\u5df2\u6210\u4e3a\u751f\u6001\u7814\u7a76\u7684\u91cd\u8981\u624b\u6bb5\uff0c\u4f46\u7531\u4e8e\u6807\u6ce8\u8d44\u6e90\u6709\u9650\uff0c\u8bc6\u522b\u6355\u83b7\u56fe\u50cf\u6570\u636e\u4e2d\u7684\u7269\u79cd\u4ecd\u7136\u662f\u4e3b\u8981\u74f6\u9888\u3002\u4f20\u7edf\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u53ea\u5173\u6ce8\u4e2a\u4f53\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u800c\u5ffd\u7565\u4e86\u6574\u4e2a\u6570\u636e\u96c6\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u5f15\u5165\u65b0\u7684\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565Vendi\u4fe1\u606f\u589e\u76ca(VIG)\uff0c\u57fa\u4e8e\u56fe\u50cf\u5bf9\u6574\u4e2a\u6570\u636e\u96c6\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u5f71\u54cd\u6765\u9009\u62e9\u56fe\u50cf\uff0c\u540c\u65f6\u6355\u6349\u4fe1\u606f\u91cf\u548c\u591a\u6837\u6027\u3002", "result": "\u5728Snapshot Serengeti\u6570\u636e\u96c6\u4e0a\uff0cVIG\u4f7f\u7528\u4e0d\u523010%\u7684\u6807\u7b7e\u5c31\u5b9e\u73b0\u4e86\u63a5\u8fd1\u5168\u76d1\u7763\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5728\u5404\u79cd\u6307\u6807\u548c\u6279\u6b21\u5927\u5c0f\u4e0a\u90fd\u6301\u7eed\u4f18\u4e8e\u6807\u51c6\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5728\u7279\u5f81\u7a7a\u95f4\u4e2d\u6536\u96c6\u4e86\u66f4\u591a\u6837\u5316\u7684\u6570\u636e\u3002", "conclusion": "VIG\u5177\u6709\u8d85\u8d8a\u751f\u6001\u5b66\u7684\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u7814\u7a76\u7ed3\u679c\u7a81\u663e\u4e86\u5176\u5728\u6570\u636e\u6709\u9650\u73af\u5883\u4e0b\u8fdb\u884c\u751f\u7269\u591a\u6837\u6027\u76d1\u6d4b\u7684\u4ef7\u503c\u3002"}}
{"id": "2509.10396", "pdf": "https://arxiv.org/pdf/2509.10396", "abs": "https://arxiv.org/abs/2509.10396", "authors": ["Siyan Zhao", "Mengchen Liu", "Jing Huang", "Miao Liu", "Chenyu Wang", "Bo Liu", "Yuandong Tian", "Guan Pang", "Sean Bell", "Aditya Grover", "Feiyu Chen"], "title": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "categories": ["cs.LG"], "comment": "preprint; 21 pages", "summary": "Masked diffusion large language models (dLLMs) are emerging as promising\nalternatives to autoregressive LLMs, offering competitive performance while\nsupporting unique generation capabilities such as inpainting. We explore how\ninpainting can inform RL algorithm design for dLLMs. Aligning LLMs with\nreinforcement learning faces an exploration challenge: sparse reward signals\nand sample waste when models fail to discover correct solutions. While this\ninefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their\ninpainting ability can guide exploration. We introduce IGPO (Inpainting Guided\nPolicy Optimization), an RL framework that strategically inserts partial\nground-truth reasoning traces during online sampling. Unlike providing full\nsolutions, inpainting steers exploration toward promising trajectory spaces\nwhile preserving self-generated reasoning, bridging supervised fine-tuning and\nreinforcement learning. We apply IGPO to group-based optimization methods such\nas GRPO, where exploration failures cause zero advantages and gradients. IGPO\nrestores meaningful gradients while improving sample efficiency. We also\npropose supervised fine-tuning on synthetically rewritten concise traces that\nbetter align with dLLM generation patterns. With additional techniques\nincluding entropy-based filtering, our training recipe yields substantial gains\nacross three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new\nstate-of-the-art results for full-attention masked dLLMs.", "AI": {"tldr": "IGPO\u662f\u4e00\u79cd\u9488\u5bf9\u63a9\u7801\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684RL\u6846\u67b6\uff0c\u901a\u8fc7\u90e8\u5206\u771f\u5b9e\u63a8\u7406\u8f68\u8ff9\u7684\u4fee\u590d\u5f15\u5bfc\u6765\u63d0\u5347\u63a2\u7d22\u6548\u7387\u548c\u6837\u672c\u5229\u7528\u7387\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97SOTA\u7ed3\u679c", "motivation": "\u89e3\u51b3\u4f20\u7edfRL\u65b9\u6cd5\u5728LLM\u5bf9\u9f50\u4e2d\u7684\u63a2\u7d22\u6311\u6218\u2014\u2014\u7a00\u758f\u5956\u52b1\u4fe1\u53f7\u548c\u6837\u672c\u6d6a\u8d39\u95ee\u9898\uff0c\u5229\u7528dLLM\u7684\u4fee\u590d\u80fd\u529b\u6765\u6307\u5bfc\u63a2\u7d22", "method": "\u63d0\u51faIGPO\u6846\u67b6\uff0c\u5728\u5728\u7ebf\u91c7\u6837\u4e2d\u7b56\u7565\u6027\u5730\u63d2\u5165\u90e8\u5206\u771f\u5b9e\u63a8\u7406\u8f68\u8ff9\uff0c\u7ed3\u5408\u76d1\u7763\u5fae\u8c03\u3001\u57fa\u4e8e\u71b5\u7684\u8fc7\u6ee4\u7b49\u6280\u672f", "result": "\u5728GSM8K\u3001Math500\u548cAMC\u4e09\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u5168\u6ce8\u610f\u529b\u63a9\u7801dLLM\u521b\u9020\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u7ed3\u679c", "conclusion": "\u4fee\u590d\u5f15\u5bfc\u7684RL\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347dLLM\u7684\u63a2\u7d22\u6548\u7387\u548c\u6027\u80fd\uff0c\u4e3aLLM\u4e0eRL\u7684\u7ed3\u5408\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2509.10406", "pdf": "https://arxiv.org/pdf/2509.10406", "abs": "https://arxiv.org/abs/2509.10406", "authors": ["Rupert Mitchell", "Kristian Kersting"], "title": "Multipole Semantic Attention: A Fast Approximation of Softmax Attention for Pretraining", "categories": ["cs.LG", "68W25, 68T50 (primary) 68W40, 68T07 (secondary)", "I.2.6; I.2.7"], "comment": null, "summary": "We present Multipole Semantic Attention (MuSe), an efficient approximation of\nsoftmax attention that combines semantic clustering with multipole expansions\nfrom computational physics. Our method addresses the quadratic computational\ncomplexity of transformers in the context length by clustering queries and keys\nseparately in their learned representation spaces, enabling a hierarchical\ntwo-stage attention mechanism. Unlike prior clustering approaches that group\nonly keys or use unified clustering, we maintain separate clusterings that\nrespect attention's asymmetric treatment of these spaces. We augment\ncentroid-based (monopole) approximations with dipole corrections that capture\ndirectional variance within clusters, preserving richer information during\ntraining. The method operates as a drop-in replacement for standard attention,\nrequiring only hyperparameter specification without architectural\nmodifications. Our approach achieves $\\mathcal{O}(NCD)$ complexity for acausal\nattention with $C$ clusters and $\\mathcal{O}(NCD \\log N)$ for causal attention.\nOn isolated attention layers, we demonstrate $3\\times$ speedup over CUDNN Flash\nAttention at 8k context length, with relative squared errors below 20%. For\ncausal attention, we develop a hierarchical block decomposition that combines\nexact local computation with efficient long-range approximation. In end-to-end\npretraining of a 30M parameter model on book-length texts with 16k context, we\nachieve 12.2% runtime reduction with only 0.36% loss degradation, establishing\nthe viability of multipole approximations for efficient transformer\npretraining.", "AI": {"tldr": "MuSe\u662f\u4e00\u79cd\u9ad8\u6548\u7684softmax\u6ce8\u610f\u529b\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bed\u4e49\u805a\u7c7b\u548c\u591a\u6781\u5c55\u5f00\u6280\u672f\u964d\u4f4eTransformer\u7684\u4e8c\u6b21\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u89e3\u51b3Transformer\u5728\u957f\u5e8f\u5217\u5904\u7406\u4e2d\u7684\u4e8c\u6b21\u8ba1\u7b97\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u8981\u4e48\u53ea\u5bf9\u952e\u8fdb\u884c\u805a\u7c7b\uff0c\u8981\u4e48\u4f7f\u7528\u7edf\u4e00\u805a\u7c7b\uff0c\u672a\u80fd\u5145\u5206\u8003\u8651\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u67e5\u8be2\u548c\u952e\u7a7a\u95f4\u7684\u4e0d\u5bf9\u79f0\u6027\u3002", "method": "\u7ed3\u5408\u8bed\u4e49\u805a\u7c7b\u548c\u8ba1\u7b97\u7269\u7406\u4e2d\u7684\u591a\u6781\u5c55\u5f00\u6280\u672f\uff0c\u5206\u522b\u5bf9\u67e5\u8be2\u548c\u952e\u5728\u5b66\u4e60\u7684\u8868\u793a\u7a7a\u95f4\u4e2d\u8fdb\u884c\u805a\u7c7b\uff0c\u91c7\u7528\u5c42\u6b21\u5316\u4e24\u9636\u6bb5\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u8d28\u5fc3\u8fd1\u4f3c\u57fa\u7840\u4e0a\u589e\u52a0\u5076\u6781\u6821\u6b63\u6765\u6355\u6349\u7c07\u5185\u65b9\u5411\u65b9\u5dee\u3002", "result": "\u57288k\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u6bd4CUDNN Flash Attention\u5feb3\u500d\uff0c\u76f8\u5bf9\u5e73\u65b9\u8bef\u5dee\u4f4e\u4e8e20%\uff1b\u572830M\u53c2\u6570\u6a21\u578b\u4e0a\u4f7f\u752816k\u4e0a\u4e0b\u6587\u8fdb\u884c\u7aef\u5230\u7aef\u9884\u8bad\u7ec3\u65f6\uff0c\u8fd0\u884c\u65f6\u95f4\u51cf\u5c1112.2%\uff0c\u6027\u80fd\u635f\u5931\u4ec50.36%\u3002", "conclusion": "\u591a\u6781\u8fd1\u4f3c\u65b9\u6cd5\u4e3a\u9ad8\u6548Transformer\u9884\u8bad\u7ec3\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5904\u7406\u957f\u5e8f\u5217\u6587\u672c\u3002"}}
{"id": "2509.10419", "pdf": "https://arxiv.org/pdf/2509.10419", "abs": "https://arxiv.org/abs/2509.10419", "authors": ["Francesco Vitale", "Tommaso Zoppi", "Francesco Flammini", "Nicola Mazzocca"], "title": "Run-Time Monitoring of ERTMS/ETCS Control Flow by Process Mining", "categories": ["cs.LG"], "comment": "Accepted to the 6th International Conference on Reliability, Safety,\n  and Security of Railway Systems (RSSRail2025)", "summary": "Ensuring the resilience of computer-based railways is increasingly crucial to\naccount for uncertainties and changes due to the growing complexity and\ncriticality of those systems. Although their software relies on strict\nverification and validation processes following well-established best-practices\nand certification standards, anomalies can still occur at run-time due to\nresidual faults, system and environmental modifications that were unknown at\ndesign-time, or other emergent cyber-threat scenarios. This paper explores\nrun-time control-flow anomaly detection using process mining to enhance the\nresilience of ERTMS/ETCS L2 (European Rail Traffic Management System / European\nTrain Control System Level 2). Process mining allows learning the actual\ncontrol flow of the system from its execution traces, thus enabling run-time\nmonitoring through online conformance checking. In addition, anomaly\nlocalization is performed through unsupervised machine learning to link\nrelevant deviations to critical system components. We test our approach on a\nreference ERTMS/ETCS L2 scenario, namely the RBC/RBC Handover, to show its\ncapability to detect and localize anomalies with high accuracy, efficiency, and\nexplainability.", "AI": {"tldr": "\u4f7f\u7528\u8fc7\u7a0b\u6316\u6398\u548c\u673a\u5668\u5b66\u4e60\u6280\u672f\u5bf9ERTMS/ETCS L2\u94c1\u8def\u7cfb\u7edf\u8fdb\u884c\u8fd0\u884c\u65f6\u63a7\u5236\u6d41\u5f02\u5e38\u68c0\u6d4b\u548c\u5b9a\u4f4d\uff0c\u63d0\u9ad8\u7cfb\u7edf\u97e7\u6027", "motivation": "\u968f\u7740\u94c1\u8def\u7cfb\u7edf\u590d\u6742\u6027\u548c\u5173\u952e\u6027\u589e\u52a0\uff0c\u5c3d\u7ba1\u6709\u4e25\u683c\u7684\u9a8c\u8bc1\u548c\u8ba4\u8bc1\u6d41\u7a0b\uff0c\u8fd0\u884c\u65f6\u4ecd\u53ef\u80fd\u51fa\u73b0\u5f02\u5e38\uff0c\u9700\u8981\u589e\u5f3a\u7cfb\u7edf\u97e7\u6027\u6765\u5e94\u5bf9\u8bbe\u8ba1\u65f6\u672a\u77e5\u7684\u6545\u969c\u3001\u4fee\u6539\u548c\u7f51\u7edc\u5a01\u80c1", "method": "\u91c7\u7528\u8fc7\u7a0b\u6316\u6398\u6280\u672f\u4ece\u6267\u884c\u8f68\u8ff9\u4e2d\u5b66\u4e60\u7cfb\u7edf\u5b9e\u9645\u63a7\u5236\u6d41\uff0c\u8fdb\u884c\u5728\u7ebf\u4e00\u81f4\u6027\u68c0\u67e5\uff1b\u4f7f\u7528\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u8fdb\u884c\u5f02\u5e38\u5b9a\u4f4d\uff0c\u5c06\u504f\u5dee\u5173\u8054\u5230\u5173\u952e\u7cfb\u7edf\u7ec4\u4ef6", "result": "\u5728RBC/RBC\u4ea4\u63a5\u53c2\u8003\u573a\u666f\u4e2d\u6d4b\u8bd5\uff0c\u65b9\u6cd5\u80fd\u591f\u4ee5\u9ad8\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u68c0\u6d4b\u548c\u5b9a\u4f4d\u5f02\u5e38", "conclusion": "\u8fc7\u7a0b\u6316\u6398\u548c\u673a\u5668\u5b66\u4e60\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u589e\u5f3a\u94c1\u8def\u63a7\u5236\u7cfb\u7edf\u7684\u8fd0\u884c\u65f6\u97e7\u6027\u548c\u5b89\u5168\u6027"}}
{"id": "2509.10439", "pdf": "https://arxiv.org/pdf/2509.10439", "abs": "https://arxiv.org/abs/2509.10439", "authors": ["Ahmed Khaled", "Satyen Kale", "Arthur Douillard", "Chi Jin", "Rob Fergus", "Manzil Zaheer"], "title": "Understanding Outer Optimizers in Local SGD: Learning Rates, Momentum, and Acceleration", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Modern machine learning often requires training with large batch size,\ndistributed data, and massively parallel compute hardware (like mobile and\nother edge devices or distributed data centers). Communication becomes a major\nbottleneck in such settings but methods like Local Stochastic Gradient Descent\n(Local SGD) show great promise in reducing this additional communication\noverhead. Local SGD consists of three parts: a local optimization process, an\naggregation mechanism, and an outer optimizer that uses the aggregated updates\nfrom the nodes to produce a new model. While there exists an extensive\nliterature on understanding the impact of hyperparameters in the local\noptimization process, the choice of outer optimizer and its hyperparameters is\nless clear. We study the role of the outer optimizer in Local SGD, and prove\nnew convergence guarantees for the algorithm. In particular, we show that\ntuning the outer learning rate allows us to (a) trade off between optimization\nerror and stochastic gradient noise variance, and (b) make up for ill-tuning of\nthe inner learning rate. Our theory suggests that the outer learning rate\nshould sometimes be set to values greater than $1$. We extend our results to\nsettings where we use momentum in the outer optimizer, and we show a similar\nrole for the momentum-adjusted outer learning rate. We also study acceleration\nin the outer optimizer and show that it improves the convergence rate as a\nfunction of the number of communication rounds, improving upon the convergence\nrate of prior algorithms that apply acceleration locally. Finally, we also\nintroduce a novel data-dependent analysis of Local SGD that yields further\ninsights on outer learning rate tuning. We conduct comprehensive experiments\nwith standard language models and various outer optimizers to validate our\ntheory.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Local SGD\u4e2d\u5916\u90e8\u4f18\u5316\u5668\u7684\u4f5c\u7528\uff0c\u8bc1\u660e\u4e86\u65b0\u7684\u6536\u655b\u4fdd\u8bc1\uff0c\u53d1\u73b0\u8c03\u6574\u5916\u90e8\u5b66\u4e60\u7387\u53ef\u4ee5\u5728\u4f18\u5316\u8bef\u5dee\u548c\u968f\u673a\u68af\u5ea6\u566a\u58f0\u65b9\u5dee\u4e4b\u95f4\u6743\u8861\uff0c\u5e76\u5f25\u8865\u5185\u90e8\u5b66\u4e60\u7387\u7684\u4e0d\u826f\u8c03\u6574\u3002\u7406\u8bba\u8868\u660e\u5916\u90e8\u5b66\u4e60\u7387\u6709\u65f6\u5e94\u5927\u4e8e1\uff0c\u52a8\u91cf\u8c03\u6574\u7684\u5916\u90e8\u5b66\u4e60\u7387\u4e5f\u6709\u7c7b\u4f3c\u4f5c\u7528\u3002\u5916\u90e8\u4f18\u5316\u5668\u7684\u52a0\u901f\u6539\u8fdb\u4e86\u6536\u655b\u7387\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u9700\u8981\u5728\u5927\u6279\u91cf\u3001\u5206\u5e03\u5f0f\u6570\u636e\u548c\u5e76\u884c\u8ba1\u7b97\u786c\u4ef6\u4e0a\u8bad\u7ec3\uff0c\u901a\u4fe1\u6210\u4e3a\u4e3b\u8981\u74f6\u9888\u3002Local SGD\u80fd\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u672c\u5730\u4f18\u5316\u8fc7\u7a0b\u7684\u8d85\u53c2\u6570\uff0c\u5bf9\u5916\u90e8\u4f18\u5316\u5668\u53ca\u5176\u8d85\u53c2\u6570\u7684\u9009\u62e9\u4e0d\u591f\u6e05\u6670\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660eLocal SGD\u7684\u6536\u655b\u4fdd\u8bc1\uff0c\u7814\u7a76\u5916\u90e8\u5b66\u4e60\u7387\u7684\u4f5c\u7528\u673a\u5236\uff0c\u6269\u5c55\u5230\u4f7f\u7528\u52a8\u91cf\u7684\u5916\u90e8\u4f18\u5316\u5668\uff0c\u5206\u6790\u5916\u90e8\u4f18\u5316\u5668\u7684\u52a0\u901f\u6548\u679c\uff0c\u5e76\u63d0\u51fa\u65b0\u7684\u6570\u636e\u76f8\u5173\u5206\u6790\u6846\u67b6\u3002", "result": "\u7406\u8bba\u8868\u660e\u8c03\u6574\u5916\u90e8\u5b66\u4e60\u7387\u53ef\u4ee5\u6743\u8861\u4f18\u5316\u8bef\u5dee\u548c\u566a\u58f0\u65b9\u5dee\uff0c\u5f25\u8865\u5185\u90e8\u5b66\u4e60\u7387\u7684\u4e0d\u826f\u8c03\u6574\uff0c\u5916\u90e8\u5b66\u4e60\u7387\u6709\u65f6\u5e94\u5927\u4e8e1\u3002\u5916\u90e8\u52a0\u901f\u6539\u8fdb\u4e86\u6536\u655b\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u672c\u5730\u52a0\u901f\u7b97\u6cd5\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\u3002", "conclusion": "\u5916\u90e8\u4f18\u5316\u5668\u5728Local SGD\u4e2d\u626e\u6f14\u5173\u952e\u89d2\u8272\uff0c\u9002\u5f53\u8c03\u6574\u5916\u90e8\u5b66\u4e60\u7387\u548c\u52a8\u91cf\u53c2\u6570\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5916\u90e8\u52a0\u901f\u6280\u672f\u80fd\u6709\u6548\u6539\u5584\u901a\u4fe1\u8f6e\u6b21\u76f8\u5173\u7684\u6536\u655b\u7387\uff0c\u4e3a\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2509.08919", "pdf": "https://arxiv.org/pdf/2509.08919", "abs": "https://arxiv.org/abs/2509.08919", "authors": ["Mahe Chen", "Xiaoxuan Wang", "Kaiwen Chen", "Nick Koudas"], "title": "Generative Engine Optimization: How to Dominate AI Search", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG", "cs.SI"], "comment": null, "summary": "The rapid adoption of generative AI-powered search engines like ChatGPT,\nPerplexity, and Gemini is fundamentally reshaping information retrieval, moving\nfrom traditional ranked lists to synthesized, citation-backed answers. This\nshift challenges established Search Engine Optimization (SEO) practices and\nnecessitates a new paradigm, which we term Generative Engine Optimization\n(GEO).\n  This paper presents a comprehensive comparative analysis of AI Search and\ntraditional web search (Google). Through a series of large-scale, controlled\nexperiments across multiple verticals, languages, and query paraphrases, we\nquantify critical differences in how these systems source information. Our key\nfindings reveal that AI Search exhibit a systematic and overwhelming bias\ntowards Earned media (third-party, authoritative sources) over Brand-owned and\nSocial content, a stark contrast to Google's more balanced mix. We further\ndemonstrate that AI Search services differ significantly from each other in\ntheir domain diversity, freshness, cross-language stability, and sensitivity to\nphrasing.\n  Based on these empirical results, we formulate a strategic GEO agenda. We\nprovide actionable guidance for practitioners, emphasizing the critical need\nto: (1) engineer content for machine scannability and justification, (2)\ndominate earned media to build AI-perceived authority, (3) adopt\nengine-specific and language-aware strategies, and (4) overcome the inherent\n\"big brand bias\" for niche players. Our work provides the foundational\nempirical analysis and a strategic framework for achieving visibility in the\nnew generative search landscape.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u751f\u6210\u5f0f\u5f15\u64ce\u4f18\u5316(GEO)\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u9a8c\u5bf9\u6bd4AI\u641c\u7d22\u4e0e\u4f20\u7edf\u641c\u7d22\uff0c\u53d1\u73b0AI\u641c\u7d22\u7cfb\u7edf\u6027\u5730\u504f\u5411\u6743\u5a01\u7b2c\u4e09\u65b9\u5185\u5bb9\u800c\u975e\u54c1\u724c\u81ea\u6709\u5185\u5bb9\uff0c\u5e76\u63d0\u4f9b\u4e86\u5177\u4f53\u7684GEO\u7b56\u7565\u6846\u67b6\u3002", "motivation": "\u751f\u6210\u5f0fAI\u641c\u7d22\u5f15\u64ce\u7684\u5174\u8d77\u6b63\u5728\u91cd\u5851\u4fe1\u606f\u68c0\u7d22\u65b9\u5f0f\uff0c\u4ece\u4f20\u7edf\u6392\u540d\u5217\u8868\u8f6c\u5411\u5408\u6210\u5f0f\u3001\u5e26\u5f15\u7528\u7684\u7b54\u6848\uff0c\u8fd9\u6311\u6218\u4e86\u73b0\u6709\u7684SEO\u5b9e\u8df5\uff0c\u9700\u8981\u5efa\u7acb\u65b0\u7684\u4f18\u5316\u8303\u5f0f\u3002", "method": "\u901a\u8fc7\u8de8\u591a\u4e2a\u5782\u76f4\u9886\u57df\u3001\u8bed\u8a00\u548c\u67e5\u8be2\u6539\u5199\u7684\u5927\u89c4\u6a21\u53d7\u63a7\u5b9e\u9a8c\uff0c\u91cf\u5316\u5206\u6790AI\u641c\u7d22\u4e0e\u4f20\u7edf\u641c\u7d22\u5728\u4fe1\u606f\u6765\u6e90\u65b9\u9762\u7684\u5173\u952e\u5dee\u5f02\u3002", "result": "\u7814\u7a76\u53d1\u73b0AI\u641c\u7d22\u7cfb\u7edf\u6027\u5730\u8fc7\u5ea6\u504f\u5411\u6743\u5a01\u7b2c\u4e09\u65b9\u5185\u5bb9(Earned media)\uff0c\u4e0e\u8c37\u6b4c\u66f4\u5e73\u8861\u7684\u5185\u5bb9\u6765\u6e90\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\uff1b\u4e0d\u540cAI\u641c\u7d22\u670d\u52a1\u5728\u57df\u540d\u591a\u6837\u6027\u3001\u65b0\u9c9c\u5ea6\u3001\u8de8\u8bed\u8a00\u7a33\u5b9a\u6027\u548c\u63aa\u8f9e\u654f\u611f\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u57fa\u4e8e\u5b9e\u8bc1\u7ed3\u679c\u63d0\u51fa\u4e86GEO\u6218\u7565\u8bae\u7a0b\uff0c\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u53ef\u64cd\u4f5c\u6307\u5bfc\uff0c\u5305\u62ec\u4f18\u5316\u673a\u5668\u53ef\u626b\u63cf\u6027\u3001\u4e3b\u5bfc\u6743\u5a01\u5a92\u4f53\u5185\u5bb9\u3001\u91c7\u7528\u5f15\u64ce\u7279\u5b9a\u7b56\u7565\u7b49\uff0c\u4e3a\u751f\u6210\u5f0f\u641c\u7d22\u73af\u5883\u4e2d\u7684\u53ef\u89c1\u6027\u63d0\u4f9b\u4e86\u57fa\u7840\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2509.09681", "pdf": "https://arxiv.org/pdf/2509.09681", "abs": "https://arxiv.org/abs/2509.09681", "authors": ["Yikuan Xia", "Jiazun Chen", "Yirui Zhan", "Suifeng Zhao", "Weipeng Jiang", "Chaorui Zhang", "Wei Han", "Bo Bai", "Jun Gao"], "title": "DB3 Team's Solution For Meta KDD Cup' 25", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "This paper presents the db3 team's winning solution for the Meta CRAG-MM\nChallenge 2025 at KDD Cup'25. Addressing the challenge's unique multi-modal,\nmulti-turn question answering benchmark (CRAG-MM), we developed a comprehensive\nframework that integrates tailored retrieval pipelines for different tasks with\na unified LLM-tuning approach for hallucination control. Our solution features\n(1) domain-specific retrieval pipelines handling image-indexed knowledge\ngraphs, web sources, and multi-turn conversations; and (2) advanced refusal\ntraining using SFT, DPO, and RL. The system achieved 2nd place in Task 1, 2nd\nplace in Task 2, and 1st place in Task 3, securing the grand prize for\nexcellence in ego-centric queries through superior handling of first-person\nperspective challenges.", "AI": {"tldr": "db3\u56e2\u961f\u5728KDD Cup'25 Meta CRAG-MM\u6311\u6218\u8d5b\u4e2d\u83b7\u80dc\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u68c0\u7d22\u7ba1\u9053\u548cLLM\u5e7b\u89c9\u63a7\u5236\u6280\u672f\uff0c\u5728\u4e09\u4e2a\u4efb\u52a1\u4e2d\u5206\u522b\u83b7\u5f97\u7b2c2\u3001\u7b2c2\u548c\u7b2c1\u540d\u3002", "motivation": "\u89e3\u51b3CRAG-MM\u6311\u6218\u8d5b\u4e2d\u7684\u591a\u6a21\u6001\u3001\u591a\u8f6e\u95ee\u7b54\u57fa\u51c6\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u7b2c\u4e00\u4eba\u79f0\u89c6\u89d2\u67e5\u8be2\u65b9\u9762\u7684\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b\u56fe\u50cf\u7d22\u5f15\u77e5\u8bc6\u56fe\u8c31\u3001\u7f51\u7edc\u8d44\u6e90\u548c\u591a\u8f6e\u5bf9\u8bdd\u7684\u9886\u57df\u7279\u5b9a\u68c0\u7d22\u7ba1\u9053\uff0c\u4ee5\u53ca\u4f7f\u7528SFT\u3001DPO\u548cRL\u8fdb\u884c\u9ad8\u7ea7\u62d2\u7edd\u8bad\u7ec3\u7684LLM\u8c03\u4f18\u65b9\u6cd5\u3002", "result": "\u5728Task 1\u548cTask 2\u4e2d\u83b7\u5f97\u7b2c2\u540d\uff0c\u5728Task 3\u4e2d\u83b7\u5f97\u7b2c1\u540d\uff0c\u6700\u7ec8\u8d62\u5f97\u603b\u51a0\u519b\uff0c\u7279\u522b\u64c5\u957f\u5904\u7406\u4ee5\u81ea\u6211\u4e3a\u4e2d\u5fc3\u7684\u67e5\u8be2\u3002", "conclusion": "\u8be5\u7efc\u5408\u6846\u67b6\u901a\u8fc7\u4e13\u95e8\u7684\u68c0\u7d22\u7ba1\u9053\u548c\u5148\u8fdb\u7684\u5e7b\u89c9\u63a7\u5236\u6280\u672f\uff0c\u5728\u591a\u6a21\u6001\u591a\u8f6e\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u7b2c\u4e00\u4eba\u79f0\u89c6\u89d2\u5904\u7406\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2509.09689", "pdf": "https://arxiv.org/pdf/2509.09689", "abs": "https://arxiv.org/abs/2509.09689", "authors": ["Himanshu Thakur", "Eshani Agrawal", "Smruthi Mukund"], "title": "Personas within Parameters: Fine-Tuning Small Language Models with Low-Rank Adapters to Mimic User Behaviors", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "A long-standing challenge in developing accurate recommendation models is\nsimulating user behavior, mainly due to the complex and stochastic nature of\nuser interactions. Towards this, one promising line of work has been the use of\nLarge Language Models (LLMs) for simulating user behavior. However, aligning\nthese general-purpose large pre-trained models with user preferences\nnecessitates: (i) effectively and continously parsing large-scale tabular\nuser-item interaction data, (ii) overcoming pre-training-induced inductive\nbiases to accurately learn user specific knowledge, and (iii) achieving the\nformer two at scale for millions of users. While most previous works have\nfocused on complex methods to prompt an LLM or fine-tune it on tabular\ninteraction datasets, our approach shifts the focus to extracting robust\ntextual user representations using a frozen LLM and simulating cost-effective,\nresource-efficient user agents powered by fine-tuned Small Language Models\n(SLMs). Further, we showcase a method for training multiple low-rank adapters\nfor groups of users or \\textit{persona}, striking an optimal balance between\nscalability and performance of user behavior agents. Our experiments provide\ncompelling empirical evidence of the efficacy of our methods, demonstrating\nthat user agents developed using our approach have the potential to bridge the\ngap between offline metrics and real-world performance of recommender systems.", "AI": {"tldr": "\u4f7f\u7528\u51bb\u7ed3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u6587\u672c\u7528\u6237\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u5fae\u8c03\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u6765\u6784\u5efa\u9ad8\u6548\u7684\u7528\u6237\u884c\u4e3a\u6a21\u62df\u4ee3\u7406\uff0c\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u5e73\u8861\u53ef\u6269\u5c55\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u7528\u6237\u884c\u4e3a\u6a21\u62df\u7684\u957f\u671f\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u6709\u6548\u89e3\u6790\u5927\u89c4\u6a21\u8868\u683c\u6570\u636e\u3001\u514b\u670d\u9884\u8bad\u7ec3\u504f\u5dee\u5e76\u5b9e\u73b0\u5927\u89c4\u6a21\u5e94\u7528\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u590d\u6742\u63d0\u793a\u6216\u5fae\u8c03LLM\uff0c\u4f46\u5b58\u5728\u6548\u7387\u548c\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u51bb\u7ed3LLM\u63d0\u53d6\u9c81\u68d2\u7684\u6587\u672c\u7528\u6237\u8868\u793a\uff0c\u4f7f\u7528\u5fae\u8c03\u7684SLMs\u6784\u5efa\u6210\u672c\u6548\u76ca\u9ad8\u7684\u7528\u6237\u4ee3\u7406\uff0c\u5e76\u4e3a\u7528\u6237\u7fa4\u4f53\u8bad\u7ec3\u591a\u4e2a\u4f4e\u79e9\u9002\u914d\u5668\uff08persona\uff09\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u4e0e\u6027\u80fd\u7684\u6700\u4f73\u5e73\u8861\u3002", "result": "\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u6709\u529b\u7684\u5b9e\u8bc1\u8bc1\u636e\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u5f00\u53d1\u51fa\u7684\u7528\u6237\u4ee3\u7406\u80fd\u591f\u5f25\u5408\u63a8\u8350\u7cfb\u7edf\u79bb\u7ebf\u6307\u6807\u4e0e\u5b9e\u9645\u6027\u80fd\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u521b\u65b0\u7684\u7528\u6237\u8868\u793a\u63d0\u53d6\u548c\u9ad8\u6548\u4ee3\u7406\u6784\u5efa\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u7684\u7528\u6237\u884c\u4e3a\u6a21\u62df\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8d44\u6e90\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2509.09690", "pdf": "https://arxiv.org/pdf/2509.09690", "abs": "https://arxiv.org/abs/2509.09690", "authors": ["Ping Liu", "Jianqiang Shen", "Qianqi Shen", "Chunnan Yao", "Kevin Kao", "Dan Xu", "Rajat Arora", "Baofen Zheng", "Caleb Johnson", "Liangjie Hong", "Jingwei Wu", "Wenjing Zhang"], "title": "Powering Job Search at Scale: LLM-Enhanced Query Understanding in Job Matching Systems", "categories": ["cs.IR", "cs.LG"], "comment": "CIKM2025", "summary": "Query understanding is essential in modern relevance systems, where user\nqueries are often short, ambiguous, and highly context-dependent. Traditional\napproaches often rely on multiple task-specific Named Entity Recognition models\nto extract structured facets as seen in job search applications. However, this\nfragmented architecture is brittle, expensive to maintain, and slow to adapt to\nevolving taxonomies and language patterns. In this paper, we introduce a\nunified query understanding framework powered by a Large Language Model (LLM),\ndesigned to address these limitations. Our approach jointly models the user\nquery and contextual signals such as profile attributes to generate structured\ninterpretations that drive more accurate and personalized recommendations. The\nframework improves relevance quality in online A/B testing while significantly\nreducing system complexity and operational overhead. The results demonstrate\nthat our solution provides a scalable and adaptable foundation for query\nunderstanding in dynamic web applications.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7edf\u4e00\u67e5\u8be2\u7406\u89e3\u6846\u67b6\uff0c\u66ff\u4ee3\u4f20\u7edf\u591aNER\u6a21\u578b\u65b9\u6848\uff0c\u901a\u8fc7\u8054\u5408\u5efa\u6a21\u67e5\u8be2\u548c\u4e0a\u4e0b\u6587\u4fe1\u53f7\u6765\u751f\u6210\u7ed3\u6784\u5316\u89e3\u91ca\uff0c\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u548c\u4e2a\u6027\u5316\u7a0b\u5ea6", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u591a\u4e2a\u4efb\u52a1\u7279\u5b9a\u7684\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6a21\u578b\uff0c\u5b58\u5728\u67b6\u6784\u8106\u5f31\u3001\u7ef4\u62a4\u6210\u672c\u9ad8\u3001\u96be\u4ee5\u9002\u5e94\u4e0d\u65ad\u53d8\u5316\u7684\u5206\u7c7b\u4f53\u7cfb\u548c\u8bed\u8a00\u6a21\u5f0f\u7b49\u95ee\u9898", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u7edf\u4e00\u67e5\u8be2\u7406\u89e3\u6846\u67b6\uff0c\u8054\u5408\u5efa\u6a21\u7528\u6237\u67e5\u8be2\u548c\u4e0a\u4e0b\u6587\u4fe1\u53f7\uff08\u5982\u4e2a\u4eba\u8d44\u6599\u5c5e\u6027\uff09\uff0c\u751f\u6210\u7ed3\u6784\u5316\u89e3\u91ca\u6765\u9a71\u52a8\u66f4\u51c6\u786e\u548c\u4e2a\u6027\u5316\u7684\u63a8\u8350", "result": "\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u63d0\u5347\u4e86\u76f8\u5173\u6027\u8d28\u91cf\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u7cfb\u7edf\u590d\u6742\u6027\u548c\u8fd0\u8425\u5f00\u9500", "conclusion": "\u8be5\u89e3\u51b3\u65b9\u6848\u4e3a\u52a8\u6001Web\u5e94\u7528\u4e2d\u7684\u67e5\u8be2\u7406\u89e3\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u548c\u9002\u5e94\u6027\u5f3a\u7684\u6280\u672f\u57fa\u7840"}}
{"id": "2509.09695", "pdf": "https://arxiv.org/pdf/2509.09695", "abs": "https://arxiv.org/abs/2509.09695", "authors": ["Fabio Magarelli", "Geraldine B. Boylan", "Saeed Montazeri", "Feargal O'Sullivan", "Dominic Lightbody", "Minoo Ashoori", "Tamara Skoric Ceranic", "John M. O'Toole"], "title": "Machine-learning competition to grade EEG background patterns in newborns with hypoxic-ischaemic encephalopathy", "categories": ["eess.SP", "cs.LG"], "comment": "29 pages, supplementary materials: \"supplementary materials ML\n  Comp.docx\"", "summary": "Machine learning (ML) has the potential to support and improve expert\nperformance in monitoring the brain function of at-risk newborns. Developing\naccurate and reliable ML models depends on access to high-quality, annotated\ndata, a resource in short supply. ML competitions address this need by\nproviding researchers access to expertly annotated datasets, fostering shared\nlearning through direct model comparisons, and leveraging the benefits of\ncrowdsourcing diverse expertise. We compiled a retrospective dataset containing\n353 hours of EEG from 102 individual newborns from a multi-centre study. The\ndata was fully anonymised and divided into training, testing, and held-out\nvalidation datasets. EEGs were graded for the severity of abnormal background\npatterns. Next, we created a web-based competition platform and hosted a\nmachine learning competition to develop ML models for classifying the severity\nof EEG background patterns in newborns. After the competition closed, the top 4\nperforming models were evaluated offline on a separate held-out validation\ndataset. Although a feature-based model ranked first on the testing dataset,\ndeep learning models generalised better on the validation sets. All methods had\na significant decline in validation performance compared to the testing\nperformance. This highlights the challenges for model generalisation on unseen\ndata, emphasising the need for held-out validation datasets in ML studies with\nneonatal EEG. The study underscores the importance of training ML models on\nlarge and diverse datasets to ensure robust generalisation. The competition's\noutcome demonstrates the potential for open-access data and collaborative ML\ndevelopment to foster a collaborative research environment and expedite the\ndevelopment of clinical decision-support tools for neonatal neuromonitoring.", "AI": {"tldr": "\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u7ade\u8d5b\u5f00\u53d1\u65b0\u751f\u513f\u8111\u7535\u56fe\u80cc\u666f\u6a21\u5f0f\u4e25\u91cd\u7a0b\u5ea6\u5206\u7c7b\u6a21\u578b\uff0c\u53d1\u73b0\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u9a8c\u8bc1\u96c6\u4e0a\u6cdb\u5316\u80fd\u529b\u66f4\u597d\uff0c\u4f46\u6240\u6709\u6a21\u578b\u5728\u672a\u89c1\u6570\u636e\u4e0a\u6027\u80fd\u90fd\u663e\u8457\u4e0b\u964d\uff0c\u5f3a\u8c03\u4e86\u5927\u89c4\u6a21\u591a\u6837\u5316\u6570\u636e\u96c6\u548c\u4fdd\u7559\u9a8c\u8bc1\u96c6\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6709\u6f5c\u529b\u6539\u5584\u9ad8\u5371\u65b0\u751f\u513f\u8111\u529f\u80fd\u76d1\u6d4b\uff0c\u4f46\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u3002\u901a\u8fc7\u7ade\u8d5b\u5f62\u5f0f\u53ef\u4ee5\u4fc3\u8fdb\u6570\u636e\u5171\u4eab\u3001\u6a21\u578b\u6bd4\u8f83\u548c\u591a\u6837\u5316\u4e13\u4e1a\u77e5\u8bc6\u7684\u6c47\u96c6\u3002", "method": "\u6536\u96c6\u4e86102\u540d\u65b0\u751f\u513f353\u5c0f\u65f6\u8111\u7535\u56fe\u6570\u636e\uff0c\u5206\u4e3a\u8bad\u7ec3\u3001\u6d4b\u8bd5\u548c\u4fdd\u7559\u9a8c\u8bc1\u96c6\u3002\u521b\u5efa\u57fa\u4e8eweb\u7684\u7ade\u8d5b\u5e73\u53f0\uff0c\u8ba9\u7814\u7a76\u8005\u5f00\u53d1EEG\u80cc\u666f\u6a21\u5f0f\u4e25\u91cd\u7a0b\u5ea6\u5206\u7c7b\u7684ML\u6a21\u578b\u3002\u8d5b\u540e\u5bf9\u524d4\u540d\u6a21\u578b\u5728\u72ec\u7acb\u9a8c\u8bc1\u96c6\u4e0a\u8fdb\u884c\u79bb\u7ebf\u8bc4\u4f30\u3002", "result": "\u7279\u5f81\u5de5\u7a0b\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u6392\u540d\u7b2c\u4e00\uff0c\u4f46\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u9a8c\u8bc1\u96c6\u4e0a\u6cdb\u5316\u66f4\u597d\u3002\u6240\u6709\u65b9\u6cd5\u5728\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6027\u80fd\u76f8\u6bd4\u6d4b\u8bd5\u96c6\u90fd\u6709\u663e\u8457\u4e0b\u964d\uff0c\u8868\u660e\u6a21\u578b\u6cdb\u5316\u5230\u672a\u89c1\u6570\u636e\u7684\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u5927\u578b\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3ML\u6a21\u578b\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u4fdd\u7559\u9a8c\u8bc1\u96c6\u5728\u65b0\u751f\u513fEEG\u7814\u7a76\u4e2d\u7684\u5fc5\u8981\u6027\u3002\u5f00\u653e\u83b7\u53d6\u6570\u636e\u548c\u534f\u4f5cML\u5f00\u53d1\u6709\u52a9\u4e8e\u8425\u9020\u5408\u4f5c\u7814\u7a76\u73af\u5883\uff0c\u52a0\u901f\u65b0\u751f\u513f\u795e\u7ecf\u76d1\u6d4b\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u5de5\u5177\u7684\u5f00\u53d1\u3002"}}
{"id": "2509.09696", "pdf": "https://arxiv.org/pdf/2509.09696", "abs": "https://arxiv.org/abs/2509.09696", "authors": ["Weibin Li", "Wendu Li", "Quanying Liu"], "title": "DCHO: A Decomposition-Composition Framework for Predicting Higher-Order Brain Connectivity to Enhance Diverse Downstream Applications", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Higher-order brain connectivity (HOBC), which captures interactions among\nthree or more brain regions, provides richer organizational information than\ntraditional pairwise functional connectivity (FC). Recent studies have begun to\ninfer latent HOBC from noninvasive imaging data, but they mainly focus on\nstatic analyses, limiting their applicability in dynamic prediction tasks. To\naddress this gap, we propose DCHO, a unified approach for modeling and\nforecasting the temporal evolution of HOBC based on a Decomposition-Composition\nframework, which is applicable to both non-predictive tasks (state\nclassification) and predictive tasks (brain dynamics forecasting). DCHO adopts\na decomposition-composition strategy that reformulates the prediction task into\ntwo manageable subproblems: HOBC inference and latent trajectory prediction. In\nthe inference stage, we propose a dual-view encoder to extract multiscale\ntopological features and a latent combinatorial learner to capture high-level\nHOBC information. In the forecasting stage, we introduce a latent-space\nprediction loss to enhance the modeling of temporal trajectories. Extensive\nexperiments on multiple neuroimaging datasets demonstrate that DCHO achieves\nsuperior performance in both non-predictive tasks (state classification) and\npredictive tasks (brain dynamics forecasting), significantly outperforming\nexisting methods.", "AI": {"tldr": "DCHO\u662f\u4e00\u4e2a\u7528\u4e8e\u5efa\u6a21\u548c\u9884\u6d4b\u9ad8\u9636\u8111\u8fde\u63a5\u52a8\u6001\u6f14\u5316\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3-\u7ec4\u5408\u7b56\u7565\u5c06\u9884\u6d4b\u4efb\u52a1\u5206\u4e3aHOBC\u63a8\u65ad\u548c\u6f5c\u5728\u8f68\u8ff9\u9884\u6d4b\u4e24\u4e2a\u5b50\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u795e\u7ecf\u5f71\u50cf\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u9ad8\u9636\u8111\u8fde\u63a5\u5206\u6790\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u5206\u6790\uff0c\u9650\u5236\u4e86\u5176\u5728\u52a8\u6001\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5efa\u6a21\u548c\u9884\u6d4bHOBC\u65f6\u95f4\u6f14\u5316\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5206\u89e3-\u7ec4\u5408\u6846\u67b6\uff0c\u5305\u542b\u53cc\u89c6\u56fe\u7f16\u7801\u5668\u63d0\u53d6\u591a\u5c3a\u5ea6\u62d3\u6251\u7279\u5f81\uff0c\u6f5c\u5728\u7ec4\u5408\u5b66\u4e60\u5668\u6355\u83b7\u9ad8\u7ea7HOBC\u4fe1\u606f\uff0c\u4ee5\u53ca\u6f5c\u5728\u7a7a\u95f4\u9884\u6d4b\u635f\u5931\u589e\u5f3a\u65f6\u95f4\u8f68\u8ff9\u5efa\u6a21\u3002", "result": "\u5728\u591a\u4e2a\u795e\u7ecf\u5f71\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDCHO\u5728\u975e\u9884\u6d4b\u6027\u4efb\u52a1\uff08\u72b6\u6001\u5206\u7c7b\uff09\u548c\u9884\u6d4b\u6027\u4efb\u52a1\uff08\u8111\u52a8\u529b\u5b66\u9884\u6d4b\uff09\u4e2d\u90fd\u53d6\u5f97\u4e86\u4f18\u8d8a\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "DCHO\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u7edf\u4e00\u6846\u67b6\u6765\u5efa\u6a21\u548c\u9884\u6d4b\u9ad8\u9636\u8111\u8fde\u63a5\u7684\u52a8\u6001\u6f14\u5316\uff0c\u4e3a\u8111\u8fde\u63a5\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u548c\u65b9\u6cd5\u3002"}}
{"id": "2509.09710", "pdf": "https://arxiv.org/pdf/2509.09710", "abs": "https://arxiv.org/abs/2509.09710", "authors": ["Sepehr Golrokh Amin", "Devin Rhoads", "Fatemeh Fakhrmoosavi", "Nicholas E. Lownes", "John N. Ivan"], "title": "Generating Individual Travel Diaries Using Large Language Models Informed by Census and Land-Use Data", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "This study introduces a Large Language Model (LLM) scheme for generating\nindividual travel diaries in agent-based transportation models. While\ntraditional approaches rely on large quantities of proprietary household travel\nsurveys, the method presented in this study generates personas stochastically\nfrom open-source American Community Survey (ACS) and Smart Location Database\n(SLD) data, then synthesizes diaries through direct prompting. This study\nfeatures a novel one-to-cohort realism score: a composite of four metrics (Trip\nCount Score, Interval Score, Purpose Score, and Mode Score) validated against\nthe Connecticut Statewide Transportation Study (CSTS) diaries, matched across\ndemographic variables. The validation utilizes Jensen-Shannon Divergence to\nmeasure distributional similarities between generated and real diaries. When\ncompared to diaries generated with classical methods (Negative Binomial for\ntrip generation; Multinomial Logit for mode/purpose) calibrated on the\nvalidation set, LLM-generated diaries achieve comparable overall realism (LLM\nmean: 0.485 vs. 0.455). The LLM excels in determining trip purpose and\ndemonstrates greater consistency (narrower realism score distribution), while\nclassical models lead in numerical estimates of trip count and activity\nduration. Aggregate validation confirms the LLM's statistical\nrepresentativeness (LLM mean: 0.612 vs. 0.435), demonstrating LLM's zero-shot\nviability and establishing a quantifiable metric of diary realism for future\nsynthetic diary evaluation systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4e2a\u4f53\u51fa\u884c\u65e5\u8bb0\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f00\u6e90\u6570\u636e\u521b\u5efa\u865a\u62df\u4eba\u7269\u5e76\u5408\u6210\u51fa\u884c\u8bb0\u5f55\uff0c\u5728\u96f6\u6837\u672c\u6761\u4ef6\u4e0b\u8fbe\u5230\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\u7684\u903c\u771f\u5ea6\u3002", "motivation": "\u4f20\u7edf\u51fa\u884c\u6a21\u578b\u4f9d\u8d56\u5927\u91cf\u4e13\u6709\u5bb6\u5ead\u51fa\u884c\u8c03\u67e5\u6570\u636e\uff0c\u6210\u672c\u9ad8\u4e14\u83b7\u53d6\u56f0\u96be\u3002\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u5f00\u6e90\u6570\u636e\u548cLLM\u6280\u672f\uff0c\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u7684\u51fa\u884c\u65e5\u8bb0\u751f\u6210\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u7f8e\u56fd\u793e\u533a\u8c03\u67e5\u548c\u667a\u80fd\u4f4d\u7f6e\u6570\u636e\u5e93\u7684\u5f00\u6e90\u6570\u636e\u968f\u673a\u751f\u6210\u865a\u62df\u4eba\u7269\uff0c\u901a\u8fc7\u76f4\u63a5\u63d0\u793aLLM\u5408\u6210\u51fa\u884c\u65e5\u8bb0\u3002\u91c7\u7528\u5305\u542b\u56db\u4e2a\u6307\u6807\uff08\u51fa\u884c\u6b21\u6570\u3001\u65f6\u95f4\u95f4\u9694\u3001\u76ee\u7684\u3001\u65b9\u5f0f\uff09\u7684\u7efc\u5408\u903c\u771f\u5ea6\u8bc4\u5206\u4f53\u7cfb\uff0c\u5e76\u7528Jensen-Shannon\u6563\u5ea6\u9a8c\u8bc1\u5206\u5e03\u76f8\u4f3c\u6027\u3002", "result": "LLM\u751f\u6210\u7684\u65e5\u8bb0\u6574\u4f53\u903c\u771f\u5ea6\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\uff080.485 vs 0.455\uff09\uff0c\u5728\u51fa\u884c\u76ee\u7684\u786e\u5b9a\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u4e14\u4e00\u81f4\u6027\u66f4\u9ad8\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\u5728\u51fa\u884c\u6b21\u6570\u548c\u6d3b\u52a8\u65f6\u957f\u6570\u503c\u4f30\u8ba1\u65b9\u9762\u7565\u80dc\u3002\u805a\u5408\u9a8c\u8bc1\u663e\u793aLLM\u5177\u6709\u66f4\u597d\u7684\u7edf\u8ba1\u4ee3\u8868\u6027\uff080.612 vs 0.435\uff09\u3002", "conclusion": "LLM\u5728\u96f6\u6837\u672c\u6761\u4ef6\u4e0b\u80fd\u591f\u751f\u6210\u5177\u6709\u7edf\u8ba1\u4ee3\u8868\u6027\u7684\u51fa\u884c\u65e5\u8bb0\uff0c\u8bc1\u660e\u4e86\u5176\u53ef\u884c\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u5408\u6210\u65e5\u8bb0\u8bc4\u4f30\u7cfb\u7edf\u5efa\u7acb\u4e86\u53ef\u91cf\u5316\u7684\u903c\u771f\u5ea6\u5ea6\u91cf\u6807\u51c6\u3002"}}
{"id": "2509.09717", "pdf": "https://arxiv.org/pdf/2509.09717", "abs": "https://arxiv.org/abs/2509.09717", "authors": ["Jorge E. Le\u00f3n", "Miguel Carrasco"], "title": "Testing chatbots on the creation of encoders for audio conditioned image generation", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": null, "summary": "On one hand, recent advances in chatbots has led to a rising popularity in\nusing these models for coding tasks. On the other hand, modern generative image\nmodels primarily rely on text encoders to translate semantic concepts into\nvisual representations, even when there is clear evidence that audio can be\nemployed as input as well. Given the previous, in this work, we explore whether\nstate-of-the-art conversational agents can design effective audio encoders to\nreplace the CLIP text encoder from Stable Diffusion 1.5, enabling image\nsynthesis directly from sound. We prompted five publicly available chatbots to\npropose neural architectures to work as these audio encoders, with a set of\nwell-explained shared conditions. Each valid suggested encoder was trained on\nover two million context related audio-image-text observations, and evaluated\non held-out validation and test sets using various metrics, together with a\nqualitative analysis of their generated images. Although almost all chatbots\ngenerated valid model designs, none achieved satisfactory results, indicating\nthat their audio embeddings failed to align reliably with those of the original\ntext encoder. Among the proposals, the Gemini audio encoder showed the best\nquantitative metrics, while the Grok audio encoder produced more coherent\nimages (particularly, when paired with the text encoder). Our findings reveal a\nshared architectural bias across chatbots and underscore the remaining coding\ngap that needs to be bridged in future versions of these models. We also\ncreated a public demo so everyone could study and try out these audio encoders.\nFinally, we propose research questions that should be tackled in the future,\nand encourage other researchers to perform more focused and highly specialized\ntasks like this one, so the respective chatbots cannot make use of well-known\nsolutions and their creativity/reasoning is fully tested.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u662f\u5426\u80fd\u7528\u804a\u5929\u673a\u5668\u4eba\u8bbe\u8ba1\u7684\u97f3\u9891\u7f16\u7801\u5668\u66ff\u4ee3Stable Diffusion 1.5\u4e2d\u7684CLIP\u6587\u672c\u7f16\u7801\u5668\uff0c\u5b9e\u73b0\u76f4\u63a5\u4ece\u58f0\u97f3\u751f\u6210\u56fe\u50cf\u3002\u867d\u7136\u591a\u4e2a\u804a\u5929\u673a\u5668\u4eba\u80fd\u751f\u6210\u6709\u6548\u7684\u6a21\u578b\u67b6\u6784\uff0c\u4f46\u6240\u6709\u65b9\u6848\u90fd\u672a\u80fd\u8fbe\u5230\u6ee1\u610f\u6548\u679c\uff0c\u8868\u660e\u97f3\u9891\u5d4c\u5165\u4e0e\u539f\u59cb\u6587\u672c\u7f16\u7801\u5668\u65e0\u6cd5\u53ef\u9760\u5bf9\u9f50\u3002", "motivation": "\u57fa\u4e8e\u804a\u5929\u673a\u5668\u4eba\u5728\u7f16\u7801\u4efb\u52a1\u4e2d\u7684\u6d41\u884c\u8868\u73b0\uff0c\u4ee5\u53ca\u5f53\u524d\u751f\u6210\u56fe\u50cf\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u6587\u672c\u7f16\u7801\u5668\u800c\u5ffd\u7565\u97f3\u9891\u8f93\u5165\u7684\u73b0\u72b6\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u662f\u5426\u80fd\u7528\u804a\u5929\u673a\u5668\u4eba\u8bbe\u8ba1\u7684\u97f3\u9891\u7f16\u7801\u5668\u5b9e\u73b0\u58f0\u97f3\u5230\u56fe\u50cf\u7684\u5408\u6210\u3002", "method": "\u4f7f\u7528\u4e94\u4e2a\u516c\u5f00\u53ef\u7528\u7684\u804a\u5929\u673a\u5668\u4eba\u63d0\u51fa\u795e\u7ecf\u67b6\u6784\u4f5c\u4e3a\u97f3\u9891\u7f16\u7801\u5668\uff0c\u6bcf\u4e2a\u6709\u6548\u5efa\u8bae\u7684\u7f16\u7801\u5668\u5728\u8d85\u8fc7200\u4e07\u4e2a\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u97f3\u9891-\u56fe\u50cf-\u6587\u672c\u89c2\u6d4b\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u5e76\u5728\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u4e0a\u4f7f\u7528\u591a\u79cd\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\uff0c\u540c\u65f6\u8fdb\u884c\u751f\u6210\u56fe\u50cf\u7684\u5b9a\u6027\u5206\u6790\u3002", "result": "\u51e0\u4e4e\u6240\u6709\u804a\u5929\u673a\u5668\u4eba\u90fd\u751f\u6210\u4e86\u6709\u6548\u7684\u6a21\u578b\u8bbe\u8ba1\uff0c\u4f46\u6ca1\u6709\u4e00\u4e2a\u8fbe\u5230\u6ee1\u610f\u7ed3\u679c\uff0c\u8868\u660e\u5b83\u4eec\u7684\u97f3\u9891\u5d4c\u5165\u65e0\u6cd5\u4e0e\u539f\u59cb\u6587\u672c\u7f16\u7801\u5668\u53ef\u9760\u5bf9\u9f50\u3002\u5176\u4e2dGemini\u97f3\u9891\u7f16\u7801\u5668\u5728\u5b9a\u91cf\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u800cGrok\u97f3\u9891\u7f16\u7801\u5668\u751f\u6210\u66f4\u8fde\u8d2f\u7684\u56fe\u50cf\uff08\u7279\u522b\u662f\u4e0e\u6587\u672c\u7f16\u7801\u5668\u914d\u5bf9\u65f6\uff09\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u804a\u5929\u673a\u5668\u4eba\u4e4b\u95f4\u5b58\u5728\u5171\u540c\u7684\u67b6\u6784\u504f\u89c1\uff0c\u5e76\u5f3a\u8c03\u4e86\u8fd9\u4e9b\u6a21\u578b\u672a\u6765\u7248\u672c\u9700\u8981\u5f25\u8865\u7684\u7f16\u7801\u5dee\u8ddd\u3002\u7814\u7a76\u8fd8\u63d0\u51fa\u4e86\u672a\u6765\u9700\u8981\u89e3\u51b3\u7684\u7814\u7a76\u95ee\u9898\uff0c\u9f13\u52b1\u5176\u4ed6\u7814\u7a76\u4eba\u5458\u8fdb\u884c\u66f4\u4e13\u6ce8\u548c\u9ad8\u5ea6\u4e13\u4e1a\u5316\u7684\u4efb\u52a1\u6765\u5145\u5206\u6d4b\u8bd5\u804a\u5929\u673a\u5668\u4eba\u7684\u521b\u9020\u529b\u548c\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2509.09721", "pdf": "https://arxiv.org/pdf/2509.09721", "abs": "https://arxiv.org/abs/2509.09721", "authors": ["Jiayi Miao", "Dingxin Lu", "Zhuqi Wang"], "title": "A Multimodal RAG Framework for Housing Damage Assessment: Collaborative Optimization of Image Encoding and Policy Vector Retrieval", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "After natural disasters, accurate evaluations of damage to housing are\nimportant for insurance claims response and planning of resources. In this\nwork, we introduce a novel multimodal retrieval-augmented generation (MM-RAG)\nframework. On top of classical RAG architecture, we further the framework to\ndevise a two-branch multimodal encoder structure that the image branch employs\na visual encoder composed of ResNet and Transformer to extract the\ncharacteristic of building damage after disaster, and the text branch harnesses\na BERT retriever for the text vectorization of posts as well as insurance\npolicies and for the construction of a retrievable restoration index. To impose\ncross-modal semantic alignment, the model integrates a cross-modal interaction\nmodule to bridge the semantic representation between image and text via\nmulti-head attention. Meanwhile, in the generation module, the introduced modal\nattention gating mechanism dynamically controls the role of visual evidence and\ntext prior information during generation. The entire framework takes end-to-end\ntraining, and combines the comparison loss, the retrieval loss and the\ngeneration loss to form multi-task optimization objectives, and achieves image\nunderstanding and policy matching in collaborative learning. The results\ndemonstrate superior performance in retrieval accuracy and classification index\non damage severity, where the Top-1 retrieval accuracy has been improved by\n9.6%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6(MM-RAG)\uff0c\u7528\u4e8e\u81ea\u7136\u707e\u5bb3\u540e\u623f\u5c4b\u635f\u574f\u8bc4\u4f30\uff0c\u901a\u8fc7\u53cc\u5206\u652f\u7f16\u7801\u5668\u548c\u8de8\u6a21\u6001\u4ea4\u4e92\u6a21\u5757\u5b9e\u73b0\u56fe\u50cf\u548c\u6587\u672c\u7684\u8bed\u4e49\u5bf9\u9f50\uff0c\u5728\u68c0\u7d22\u51c6\u786e\u7387\u548c\u635f\u574f\u4e25\u91cd\u7a0b\u5ea6\u5206\u7c7b\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u81ea\u7136\u707e\u5bb3\u540e\u51c6\u786e\u7684\u623f\u5c4b\u635f\u574f\u8bc4\u4f30\u5bf9\u4e8e\u4fdd\u9669\u7406\u8d54\u54cd\u5e94\u548c\u8d44\u6e90\u89c4\u5212\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u7ed3\u5408\u56fe\u50cf\u548c\u6587\u672c\u4fe1\u606f\u8fdb\u884c\u7efc\u5408\u5206\u6790\u3002", "method": "\u91c7\u7528\u53cc\u5206\u652f\u591a\u6a21\u6001\u7f16\u7801\u5668\u7ed3\u6784\uff1a\u56fe\u50cf\u5206\u652f\u4f7f\u7528ResNet\u548cTransformer\u63d0\u53d6\u5efa\u7b51\u635f\u574f\u7279\u5f81\uff0c\u6587\u672c\u5206\u652f\u4f7f\u7528BERT\u68c0\u7d22\u5668\u5904\u7406\u6587\u672c\u5411\u91cf\u5316\uff1b\u96c6\u6210\u8de8\u6a21\u6001\u4ea4\u4e92\u6a21\u5757\u901a\u8fc7\u591a\u5934\u6ce8\u610f\u529b\u5b9e\u73b0\u8bed\u4e49\u5bf9\u9f50\uff1b\u5f15\u5165\u6a21\u6001\u6ce8\u610f\u529b\u95e8\u63a7\u673a\u5236\u52a8\u6001\u63a7\u5236\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u89c6\u89c9\u8bc1\u636e\u548c\u6587\u672c\u5148\u9a8c\u4fe1\u606f\u4f5c\u7528\u3002", "result": "\u5728\u68c0\u7d22\u51c6\u786e\u7387\u548c\u635f\u574f\u4e25\u91cd\u7a0b\u5ea6\u5206\u7c7b\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0cTop-1\u68c0\u7d22\u51c6\u786e\u7387\u63d0\u5347\u4e869.6%\u3002", "conclusion": "\u8be5\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\u80fd\u591f\u6709\u6548\u6574\u5408\u89c6\u89c9\u548c\u6587\u672c\u4fe1\u606f\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u56fe\u50cf\u7406\u89e3\u548c\u653f\u7b56\u5339\u914d\uff0c\u4e3a\u707e\u540e\u623f\u5c4b\u635f\u574f\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.09722", "pdf": "https://arxiv.org/pdf/2509.09722", "abs": "https://arxiv.org/abs/2509.09722", "authors": ["Taylor Archibald", "Tony Martinez"], "title": "Improving MLLM Historical Record Extraction with Test-Time Image", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": null, "summary": "We present a novel ensemble framework that stabilizes LLM based text\nextraction from noisy historical documents. We transcribe multiple augmented\nvariants of each image with Gemini 2.0 Flash and fuse these outputs with a\ncustom Needleman Wunsch style aligner that yields both a consensus\ntranscription and a confidence score. We present a new dataset of 622\nPennsylvania death records, and demonstrate our method improves transcription\naccuracy by 4 percentage points relative to a single shot baseline. We find\nthat padding and blurring are the most useful for improving accuracy, while\ngrid warp perturbations are best for separating high and low confidence cases.\nThe approach is simple, scalable, and immediately deployable to other document\ncollections and transcription models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u566a\u58f0\u5386\u53f2\u6587\u6863\u6587\u672c\u63d0\u53d6\u96c6\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u56fe\u50cf\u589e\u5f3a\u53d8\u4f53\u8f6c\u5f55\u548cNeedleman Wunsch\u5bf9\u9f50\u5668\u878d\u5408\u8f93\u51fa\uff0c\u63d0\u9ad8\u8f6c\u5f55\u51c6\u786e\u60274\u4e2a\u767e\u5206\u70b9", "motivation": "\u89e3\u51b3\u566a\u58f0\u5386\u53f2\u6587\u6863\u4e2d\u6587\u672c\u63d0\u53d6\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u63d0\u9ad8\u8f6c\u5f55\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027", "method": "\u4f7f\u7528Gemini 2.0 Flash\u5bf9\u591a\u4e2a\u589e\u5f3a\u56fe\u50cf\u53d8\u4f53\u8fdb\u884c\u8f6c\u5f55\uff0c\u7136\u540e\u901a\u8fc7\u81ea\u5b9a\u4e49Needleman Wunsch\u98ce\u683c\u5bf9\u9f50\u5668\u878d\u5408\u8f93\u51fa\uff0c\u751f\u6210\u5171\u8bc6\u8f6c\u5f55\u548c\u7f6e\u4fe1\u5ea6\u5206\u6570", "result": "\u5728622\u4efd\u5bbe\u5915\u6cd5\u5c3c\u4e9a\u5dde\u6b7b\u4ea1\u8bb0\u5f55\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u5355\u6b21\u8f6c\u5f55\u57fa\u7ebf\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e864\u4e2a\u767e\u5206\u70b9\uff1b\u586b\u5145\u548c\u6a21\u7cca\u5904\u7406\u5bf9\u63d0\u5347\u51c6\u786e\u6027\u6700\u6709\u6548\uff0c\u7f51\u683c\u626d\u66f2\u6270\u52a8\u6700\u9002\u5408\u533a\u5206\u9ad8\u4f4e\u7f6e\u4fe1\u5ea6\u60c5\u51b5", "conclusion": "\u8be5\u65b9\u6cd5\u7b80\u5355\u3001\u53ef\u6269\u5c55\uff0c\u53ef\u7acb\u5373\u90e8\u7f72\u5230\u5176\u4ed6\u6587\u6863\u96c6\u5408\u548c\u8f6c\u5f55\u6a21\u578b\uff0c\u4e3a\u5386\u53f2\u6587\u6863\u6570\u5b57\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.09723", "pdf": "https://arxiv.org/pdf/2509.09723", "abs": "https://arxiv.org/abs/2509.09723", "authors": ["Kai R. Larsen", "Sen Yan", "Roland M\u00fcller", "Lan Sang", "Mikko R\u00f6nkk\u00f6", "Ravi Starzl", "Donald Edmondson"], "title": "ALIGNS: Unlocking nomological networks in psychological measurement through a large language model", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ME", "I.2.6; J.4; I.5.1; H.3.3; H.2.8"], "comment": null, "summary": "Psychological measurement is critical to many disciplines. Despite advances\nin measurement, building nomological networks, theoretical maps of how concepts\nand measures relate to establish validity, remains a challenge 70 years after\nCronbach and Meehl proposed them as fundamental to validation. This limitation\nhas practical consequences: clinical trials may fail to detect treatment\neffects, and public policy may target the wrong outcomes. We introduce Analysis\nof Latent Indicators to Generate Nomological Structures (ALIGNS), a large\nlanguage model-based system trained with validated questionnaire measures.\nALIGNS provides three comprehensive nomological networks containing over\n550,000 indicators across psychology, medicine, social policy, and other\nfields. This represents the first application of large language models to solve\na foundational problem in measurement validation. We report classification\naccuracy tests used to develop the model, as well as three evaluations. In the\nfirst evaluation, the widely used NIH PROMIS anxiety and depression instruments\nare shown to converge into a single dimension of emotional distress. The second\nevaluation examines child temperament measures and identifies four potential\ndimensions not captured by current frameworks, and questions one existing\ndimension. The third evaluation, an applicability check, engages expert\npsychometricians who assess the system's importance, accessibility, and\nsuitability. ALIGNS is freely available at nomologicalnetwork.org,\ncomplementing traditional validation methods with large-scale nomological\nanalysis.", "AI": {"tldr": "ALIGNS\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u751f\u6210\u5305\u542b55\u4e07+\u6307\u6807\u7684\u7efc\u5408\u7406\u8bba\u7f51\u7edc\uff0c\u89e3\u51b3\u5fc3\u7406\u5b66\u6d4b\u91cf\u4e2d\u7406\u8bba\u7f51\u7edc\u6784\u5efa\u7684\u957f\u671f\u6311\u6218\u3002", "motivation": "\u89e3\u51b3Cronbach\u548cMeehl\u63d0\u51fa\u7684\u7406\u8bba\u7f51\u7edc\u6784\u5efa\u96be\u9898\uff0c\u8be5\u95ee\u989870\u5e74\u6765\u4e00\u76f4\u662f\u6d4b\u91cf\u9a8c\u8bc1\u7684\u57fa\u7840\u6311\u6218\uff0c\u5f71\u54cd\u4e34\u5e8a\u8bd5\u9a8c\u6548\u679c\u68c0\u6d4b\u548c\u516c\u5171\u653f\u7b56\u76ee\u6807\u5236\u5b9a\u3002", "method": "\u4f7f\u7528\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u95ee\u5377\u6d4b\u91cf\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5f00\u53d1ALIGNS\u7cfb\u7edf\uff0c\u5305\u542b\u4e09\u4e2a\u7efc\u5408\u7406\u8bba\u7f51\u7edc\uff0c\u6db5\u76d6\u5fc3\u7406\u5b66\u3001\u533b\u5b66\u3001\u793e\u4f1a\u653f\u7b56\u7b49\u591a\u4e2a\u9886\u57df\u3002", "result": "\u7cfb\u7edf\u5728\u4e09\u4e2a\u8bc4\u4f30\u4e2d\u8868\u73b0\u826f\u597d\uff1a\u53d1\u73b0NIH PROMIS\u7126\u8651\u6291\u90c1\u5de5\u5177\u6536\u655b\u4e3a\u5355\u4e00\u60c5\u7eea\u56f0\u6270\u7ef4\u5ea6\uff1b\u8bc6\u522b\u513f\u7ae5\u6c14\u8d28\u6d4b\u91cf\u7684\u56db\u4e2a\u65b0\u7ef4\u5ea6\u5e76\u8d28\u7591\u73b0\u6709\u7ef4\u5ea6\uff1b\u4e13\u5bb6\u8bc4\u4f30\u663e\u793a\u7cfb\u7edf\u5177\u6709\u91cd\u8981\u6027\u3001\u53ef\u8bbf\u95ee\u6027\u548c\u9002\u7528\u6027\u3002", "conclusion": "ALIGNS\u662f\u9996\u4e2a\u5e94\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u6d4b\u91cf\u9a8c\u8bc1\u57fa\u7840\u95ee\u9898\u7684\u7cfb\u7edf\uff0c\u514d\u8d39\u63d0\u4f9b\u4f7f\u7528\uff0c\u53ef\u8865\u5145\u4f20\u7edf\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21\u7406\u8bba\u5206\u6790\u3002"}}
{"id": "2509.09724", "pdf": "https://arxiv.org/pdf/2509.09724", "abs": "https://arxiv.org/abs/2509.09724", "authors": ["Wonyoung Kim", "Sujeong Seo", "Juhyun Lee"], "title": "DiTTO-LLM: Framework for Discovering Topic-based Technology Opportunities via Large Language Model", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T09"], "comment": "5 figures", "summary": "Technology opportunities are critical information that serve as a foundation\nfor advancements in technology, industry, and innovation. This paper proposes a\nframework based on the temporal relationships between technologies to identify\nemerging technology opportunities. The proposed framework begins by extracting\ntext from a patent dataset, followed by mapping text-based topics to discover\ninter-technology relationships. Technology opportunities are then identified by\ntracking changes in these topics over time. To enhance efficiency, the\nframework leverages a large language model to extract topics and employs a\nprompt for a chat-based language model to support the discovery of technology\nopportunities. The framework was evaluated using an artificial intelligence\npatent dataset provided by the United States Patent and Trademark Office. The\nexperimental results suggest that artificial intelligence technology is\nevolving into forms that facilitate everyday accessibility. This approach\ndemonstrates the potential of the proposed framework to identify future\ntechnology opportunities.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6280\u672f\u95f4\u65f6\u95f4\u5173\u7cfb\u7684\u6846\u67b6\u6765\u8bc6\u522b\u65b0\u5174\u6280\u672f\u673a\u4f1a\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u4e13\u5229\u6570\u636e\u4e2d\u63d0\u53d6\u4e3b\u9898\u5e76\u8ffd\u8e2a\u5176\u968f\u65f6\u95f4\u53d8\u5316", "motivation": "\u6280\u672f\u673a\u4f1a\u662f\u63a8\u52a8\u6280\u672f\u3001\u4ea7\u4e1a\u548c\u521b\u65b0\u8fdb\u6b65\u7684\u5173\u952e\u4fe1\u606f\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u65b9\u6cd5\u6765\u8bc6\u522b\u65b0\u5174\u6280\u672f\u53d1\u5c55\u8d8b\u52bf", "method": "\u4ece\u4e13\u5229\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u6587\u672c\uff0c\u5c06\u57fa\u4e8e\u6587\u672c\u7684\u4e3b\u9898\u6620\u5c04\u4ee5\u53d1\u73b0\u6280\u672f\u95f4\u5173\u7cfb\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u4e3b\u9898\u5e76\u901a\u8fc7\u8ffd\u8e2a\u4e3b\u9898\u968f\u65f6\u95f4\u53d8\u5316\u6765\u8bc6\u522b\u6280\u672f\u673a\u4f1a", "result": "\u4f7f\u7528\u7f8e\u56fd\u4e13\u5229\u5546\u6807\u5c40\u63d0\u4f9b\u7684\u4eba\u5de5\u667a\u80fd\u4e13\u5229\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u4eba\u5de5\u667a\u80fd\u6280\u672f\u6b63\u671d\u7740\u4fbf\u4e8e\u65e5\u5e38\u8bbf\u95ee\u7684\u5f62\u5f0f\u53d1\u5c55", "conclusion": "\u8be5\u6846\u67b6\u5c55\u793a\u4e86\u8bc6\u522b\u672a\u6765\u6280\u672f\u673a\u4f1a\u7684\u6f5c\u529b\uff0c\u4e3a\u6280\u672f\u53d1\u5c55\u548c\u521b\u65b0\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5206\u6790\u5de5\u5177"}}
{"id": "2509.09728", "pdf": "https://arxiv.org/pdf/2509.09728", "abs": "https://arxiv.org/abs/2509.09728", "authors": ["Elena Rohde", "Jonas Klingwort", "Christian Borgs"], "title": "A meta-analysis on the performance of machine-learning based language models for sentiment analysis", "categories": ["cs.CL", "cs.LG", "stat.AP"], "comment": null, "summary": "This paper presents a meta-analysis evaluating ML performance in sentiment\nanalysis for Twitter data. The study aims to estimate the average performance,\nassess heterogeneity between and within studies, and analyze how study\ncharacteristics influence model performance. Using PRISMA guidelines, we\nsearched academic databases and selected 195 trials from 20 studies with 12\nstudy features. Overall accuracy, the most reported performance metric, was\nanalyzed using double arcsine transformation and a three-level random effects\nmodel. The average overall accuracy of the AIC-optimized model was 0.80 [0.76,\n0.84]. This paper provides two key insights: 1) Overall accuracy is widely used\nbut often misleading due to its sensitivity to class imbalance and the number\nof sentiment classes, highlighting the need for normalization. 2) Standardized\nreporting of model performance, including reporting confusion matrices for\nindependent test sets, is essential for reliable comparisons of ML classifiers\nacross studies, which seems far from common practice.", "AI": {"tldr": "\u5bf9Twitter\u60c5\u611f\u5206\u6790\u4e2d\u673a\u5668\u5b66\u4e60\u6027\u80fd\u7684\u5143\u5206\u6790\u663e\u793a\u5e73\u5747\u51c6\u786e\u7387\u4e3a0.80\uff0c\u6307\u51fa\u603b\u4f53\u51c6\u786e\u7387\u6307\u6807\u5b58\u5728\u8bef\u5bfc\u6027\uff0c\u9700\u8981\u6807\u51c6\u5316\u62a5\u544a\u89c4\u8303", "motivation": "\u8bc4\u4f30Twitter\u60c5\u611f\u5206\u6790\u4e2d\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u5e73\u5747\u6027\u80fd\uff0c\u5206\u6790\u7814\u7a76\u95f4\u7684\u5f02\u8d28\u6027\uff0c\u5e76\u63a2\u8ba8\u7814\u7a76\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u6027\u80fd", "method": "\u4f7f\u7528PRISMA\u6307\u5357\u641c\u7d22\u5b66\u672f\u6570\u636e\u5e93\uff0c\u9009\u53d620\u9879\u7814\u7a76\u4e2d\u7684195\u4e2a\u8bd5\u9a8c\uff0c\u91c7\u7528\u53cc\u53cd\u6b63\u5f26\u53d8\u6362\u548c\u4e09\u7ea7\u968f\u673a\u6548\u5e94\u6a21\u578b\u5206\u6790\u603b\u4f53\u51c6\u786e\u7387", "result": "AIC\u4f18\u5316\u6a21\u578b\u7684\u5e73\u5747\u603b\u4f53\u51c6\u786e\u7387\u4e3a0.80 [0.76, 0.84]\uff0c\u53d1\u73b0\u603b\u4f53\u51c6\u786e\u7387\u56e0\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u60c5\u611f\u7c7b\u522b\u6570\u91cf\u800c\u5177\u6709\u8bef\u5bfc\u6027", "conclusion": "\u9700\u8981\u89c4\u8303\u6a21\u578b\u6027\u80fd\u62a5\u544a\u6807\u51c6\uff0c\u5305\u62ec\u62a5\u544a\u72ec\u7acb\u6d4b\u8bd5\u96c6\u7684\u6df7\u6dc6\u77e9\u9635\uff0c\u4ee5\u5b9e\u73b0\u8de8\u7814\u7a76\u7684\u53ef\u9760\u6bd4\u8f83"}}
{"id": "2509.09734", "pdf": "https://arxiv.org/pdf/2509.09734", "abs": "https://arxiv.org/abs/2509.09734", "authors": ["Zikang Guo", "Benfeng Xu", "Chiwei Zhu", "Wentao Hong", "Xiaorui Wang", "Zhendong Mao"], "title": "MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The Model Context Protocol (MCP) is rapidly emerging as a pivotal open\nstandard, designed to enhance agent-tool integration and interoperability, and\nis positioned to unlock a new era of powerful, interconnected, and genuinely\nutilitarian agentic AI. However, despite MCP's growing adoption, existing\nbenchmarks often fail to capture real-world agent performance within this new\nparadigm, leading to a distorted perception of their true operational value and\nan inability to reliably differentiate proficiencies. To bridge this critical\nevaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark\nspecifically engineered to rigorously assess language agent capabilities in\nMCP-mediated tool interactions. Core contributions of MCP-AgentBench include:\nthe establishment of a robust MCP testbed comprising 33 operational servers\nwith 188 distinct tools; the development of a benchmark featuring 600\nsystematically designed queries distributed across 6 distinct categories of\nvarying interaction complexity; and the introduction of MCP-Eval, a novel\noutcome-oriented evaluation methodology prioritizing real-world task success.\nThrough extensive empirical evaluation of leading language agents, we provide\nfoundational insights. MCP-AgentBench aims to equip the research community with\na standardized and reliable framework to build, validate, and advance agents\ncapable of fully leveraging MCP's transformative benefits, thereby accelerating\nprogress toward truly capable and interoperable AI systems.", "AI": {"tldr": "MCP-AgentBench\u662f\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9MCP\u534f\u8bae\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b33\u4e2a\u670d\u52a1\u5668\u3001188\u4e2a\u5de5\u5177\u548c600\u4e2a\u67e5\u8be2\uff0c\u7528\u4e8e\u8bc4\u4f30\u8bed\u8a00\u4ee3\u7406\u5728\u5de5\u5177\u4ea4\u4e92\u4e2d\u7684\u771f\u5b9e\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u5728MCP\u534f\u8bae\u4e0bAI\u4ee3\u7406\u7684\u771f\u5b9e\u64cd\u4f5c\u4ef7\u503c\uff0c\u5bfc\u81f4\u5bf9\u5176\u80fd\u529b\u7684\u8bef\u89e3\u548c\u65e0\u6cd5\u53ef\u9760\u533a\u5206\u4e0d\u540c\u4ee3\u7406\u7684\u719f\u7ec3\u7a0b\u5ea6\u3002", "method": "\u5efa\u7acb\u4e86\u5305\u542b33\u4e2a\u64cd\u4f5c\u670d\u52a1\u5668\u548c188\u4e2a\u4e0d\u540c\u5de5\u5177\u7684MCP\u6d4b\u8bd5\u5e8a\uff0c\u5f00\u53d1\u4e86600\u4e2a\u7cfb\u7edf\u8bbe\u8ba1\u7684\u67e5\u8be2\uff0c\u5206\u5e03\u57286\u4e2a\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u4ea4\u4e92\u7c7b\u522b\u4e2d\uff0c\u5e76\u5f15\u5165\u4e86MCP-Eval\u8fd9\u79cd\u4ee5\u7ed3\u679c\u4e3a\u5bfc\u5411\u7684\u65b0\u578b\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5bf9\u9886\u5148\u8bed\u8a00\u4ee3\u7406\u7684\u5e7f\u6cdb\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u63d0\u4f9b\u4e86\u57fa\u7840\u6027\u89c1\u89e3\uff0c\u5c55\u793a\u4e86\u4e0d\u540c\u4ee3\u7406\u5728MCP\u73af\u5883\u4e0b\u7684\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "MCP-AgentBench\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u548c\u53ef\u9760\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u3001\u9a8c\u8bc1\u548c\u63a8\u8fdb\u80fd\u591f\u5145\u5206\u5229\u7528MCP\u53d8\u9769\u6027\u4f18\u52bf\u7684\u4ee3\u7406\uff0c\u52a0\u901f\u5b9e\u73b0\u771f\u6b63\u6709\u80fd\u529b\u4e14\u53ef\u4e92\u64cd\u4f5c\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2509.09737", "pdf": "https://arxiv.org/pdf/2509.09737", "abs": "https://arxiv.org/abs/2509.09737", "authors": ["Klemen Kotar", "Wanhee Lee", "Rahul Venkatesh", "Honglin Chen", "Daniel Bear", "Jared Watrous", "Simon Kim", "Khai Loong Aw", "Lilian Naing Chen", "Stefan Stojanov", "Kevin Feigelis", "Imran Thobani", "Alex Durango", "Khaled Jedoui", "Atlas Kazemian", "Dan Yamins"], "title": "World Modeling with Probabilistic Structure Integration", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We present Probabilistic Structure Integration (PSI), a system for learning\nrichly controllable and flexibly promptable world models from data. PSI\nconsists of a three-step cycle. The first step, Probabilistic prediction,\ninvolves building a probabilistic graphical model Psi of the data, in the form\nof a random-access autoregressive sequence model. Psi supports a complete set\nof learned conditional distributions describing the dependence of any variables\nin the data on any other set of variables. In step 2, Structure extraction, we\nshow how to extract underlying low-dimensional properties in the data,\ncorresponding to a diverse set of meaningful \"intermediate structures\", in a\nzero-shot fashion via causal inference on Psi. Step 3, Integration, completes\nthe cycle by converting these structures into new token types that are then\ncontinually mixed back into the training diet as conditioning signals and\nprediction targets. Each such cycle augments the capabilities of Psi, both\nallowing it to model the underlying data better, and creating new control\nhandles -- akin to an LLM-like universal prompting language. We train an\ninstance of Psi on 1.4 trillion tokens of internet video data; we use it to\nperform a variety of useful video prediction and understanding inferences; we\nextract state-of-the-art optical flow, self-supervised depth and object\nsegmentation; and we use these structures to support a full cycle of predictive\nimprovements.", "AI": {"tldr": "PSI\u662f\u4e00\u4e2a\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u53ef\u63a7\u5236\u3001\u53ef\u63d0\u793a\u7684\u4e16\u754c\u6a21\u578b\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u6982\u7387\u9884\u6d4b\u3001\u7ed3\u6784\u63d0\u53d6\u548c\u96c6\u6210\u4e09\u4e2a\u6b65\u9aa4\u7684\u5faa\u73af\uff0c\u4e0d\u65ad\u6539\u8fdb\u6a21\u578b\u80fd\u529b\u5e76\u521b\u5efa\u65b0\u7684\u63a7\u5236\u673a\u5236", "motivation": "\u6784\u5efa\u80fd\u591f\u4ece\u89c6\u9891\u6570\u636e\u4e2d\u5b66\u4e60\u4e30\u5bcc\u53ef\u63a7\u4e16\u754c\u6a21\u578b\u7684\u7cfb\u7edf\uff0c\u652f\u6301\u7c7b\u4f3cLLM\u7684\u901a\u7528\u63d0\u793a\u8bed\u8a00\uff0c\u5b9e\u73b0\u66f4\u597d\u7684\u89c6\u9891\u7406\u89e3\u548c\u9884\u6d4b", "method": "\u4e09\u6b65\u5faa\u73af\uff1a1) \u6784\u5efa\u6982\u7387\u56fe\u6a21\u578bPsi\uff1b2) \u901a\u8fc7\u56e0\u679c\u63a8\u65ad\u96f6\u6837\u672c\u63d0\u53d6\u5e95\u5c42\u4f4e\u7ef4\u7ed3\u6784\uff1b3) \u5c06\u7ed3\u6784\u8f6c\u6362\u4e3a\u65b0token\u7c7b\u578b\u5e76\u96c6\u6210\u56de\u8bad\u7ec3\u4e2d", "result": "\u57281.4\u4e07\u4ebftoken\u7684\u89c6\u9891\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u5149\u6d41\u3001\u81ea\u76d1\u7763\u6df1\u5ea6\u548c\u5bf9\u8c61\u5206\u5272\uff0c\u652f\u6301\u5b8c\u6574\u7684\u9884\u6d4b\u6539\u8fdb\u5faa\u73af", "conclusion": "PSI\u7cfb\u7edf\u901a\u8fc7\u5faa\u73af\u96c6\u6210\u7ed3\u6784\u5b66\u4e60\uff0c\u6210\u529f\u6784\u5efa\u4e86\u53ef\u63a7\u3001\u53ef\u63d0\u793a\u7684\u4e16\u754c\u6a21\u578b\uff0c\u5728\u89c6\u9891\u7406\u89e3\u548c\u9884\u6d4b\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272"}}
{"id": "2509.09740", "pdf": "https://arxiv.org/pdf/2509.09740", "abs": "https://arxiv.org/abs/2509.09740", "authors": ["Ying Yuan", "Xing-Yue Monica Ge", "Aaron Archer Waterman", "Tommaso Biancalani", "David Richmond", "Yogesh Pandit", "Avtar Singh", "Russell Littman", "Jin Liu", "Jan-Christian Huetter", "Vladimir Ermakov"], "title": "HypoGeneAgent: A Hypothesis Language Agent for Gene-Set Cluster Resolution Selection Using Perturb-seq Datasets", "categories": ["q-bio.QM", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large-scale single-cell and Perturb-seq investigations routinely involve\nclustering cells and subsequently annotating each cluster with Gene-Ontology\n(GO) terms to elucidate the underlying biological programs. However, both\nstages, resolution selection and functional annotation, are inherently\nsubjective, relying on heuristics and expert curation. We present\nHYPOGENEAGENT, a large language model (LLM)-driven framework, transforming\ncluster annotation into a quantitatively optimizable task. Initially, an LLM\nfunctioning as a gene-set analyst analyzes the content of each gene program or\nperturbation module and generates a ranked list of GO-based hypotheses,\naccompanied by calibrated confidence scores. Subsequently, we embed every\npredicted description with a sentence-embedding model, compute pair-wise cosine\nsimilarities, and let the agent referee panel score (i) the internal\nconsistency of the predictions, high average similarity within the same\ncluster, termed intra-cluster agreement (ii) their external distinctiveness,\nlow similarity between clusters, termed inter-cluster separation. These two\nquantities are combined to produce an agent-derived resolution score, which is\nmaximized when clusters exhibit simultaneous coherence and mutual exclusivity.\nWhen applied to a public K562 CRISPRi Perturb-seq dataset as a preliminary\ntest, our Resolution Score selects clustering granularities that exhibit\nalignment with known pathway compared to classical metrics such silhouette\nscore, modularity score for gene functional enrichment summary. These findings\nestablish LLM agents as objective adjudicators of cluster resolution and\nfunctional annotation, thereby paving the way for fully automated,\ncontext-aware interpretation pipelines in single-cell multi-omics studies.", "AI": {"tldr": "HYPOGENEAGENT\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\uff0c\u5c06\u7ec6\u80de\u805a\u7c7b\u6ce8\u91ca\u8f6c\u5316\u4e3a\u53ef\u91cf\u5316\u4f18\u5316\u7684\u4efb\u52a1\uff0c\u901a\u8fc7LLM\u751f\u6210GO\u5047\u8bbe\u5e76\u8ba1\u7b97\u5185\u90e8\u4e00\u81f4\u6027\u548c\u5916\u90e8\u533a\u5206\u5ea6\u8bc4\u5206\uff0c\u81ea\u52a8\u9009\u62e9\u6700\u4f73\u805a\u7c7b\u5206\u8fa8\u7387\u3002", "motivation": "\u89e3\u51b3\u5355\u7ec6\u80de\u7814\u7a76\u4e2d\u805a\u7c7b\u5206\u8fa8\u7387\u9009\u62e9\u548c\u529f\u80fd\u6ce8\u91ca\u7684\u4e3b\u89c2\u6027\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u89c4\u5219\u548c\u4e13\u5bb6\u7ecf\u9a8c\uff0c\u7f3a\u4e4f\u5ba2\u89c2\u91cf\u5316\u6807\u51c6\u3002", "method": "\u4f7f\u7528LLM\u4f5c\u4e3a\u57fa\u56e0\u96c6\u5206\u6790\u5e08\u751f\u6210GO\u5047\u8bbe\u548c\u7f6e\u4fe1\u5ea6\u8bc4\u5206\uff0c\u7136\u540e\u901a\u8fc7\u53e5\u5b50\u5d4c\u5165\u6a21\u578b\u8ba1\u7b97\u805a\u7c7b\u5185\u4e00\u81f4\u6027\uff08intra-cluster agreement\uff09\u548c\u805a\u7c7b\u95f4\u533a\u5206\u5ea6\uff08inter-cluster separation\uff09\uff0c\u7ec4\u5408\u5f97\u5230\u5206\u8fa8\u7387\u8bc4\u5206\u3002", "result": "\u5728K562 CRISPRi Perturb-seq\u6570\u636e\u96c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u9009\u62e9\u7684\u805a\u7c7b\u7c92\u5ea6\u4e0e\u5df2\u77e5\u901a\u8def\u5bf9\u9f50\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u6307\u6807\u5982\u8f6e\u5ed3\u7cfb\u6570\u548c\u6a21\u5757\u5ea6\u8bc4\u5206\u3002", "conclusion": "LLM\u4ee3\u7406\u53ef\u4ee5\u4f5c\u4e3a\u805a\u7c7b\u5206\u8fa8\u7387\u548c\u529f\u80fd\u6ce8\u91ca\u7684\u5ba2\u89c2\u88c1\u51b3\u8005\uff0c\u4e3a\u5355\u7ec6\u80de\u591a\u7ec4\u5b66\u7814\u7a76\u5b9e\u73b0\u5168\u81ea\u52a8\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u89e3\u91ca\u6d41\u7a0b\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2509.09794", "pdf": "https://arxiv.org/pdf/2509.09794", "abs": "https://arxiv.org/abs/2509.09794", "authors": ["Jackson Eshbaugh", "Chetan Tiwari", "Jorge Silveyra"], "title": "A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes", "categories": ["cs.AI", "cs.LG"], "comment": "44 pages; 2 appendices; 9 figures; 1 table. Code available at\n  https://github.com/Lafayette-EshbaughSilveyra-Group/synthetic-homes", "summary": "Computational models have emerged as powerful tools for energy modeling\nresearch, touting scalability and quantitative results. However, these models\nrequire a plethora of data, some of which is inaccessible, expensive, or raises\nprivacy concerns. We introduce a modular multimodal framework to produce this\ndata from publicly accessible residential information and images using\ngenerative artificial intelligence (AI). Additionally, we provide a pipeline\ndemonstrating this framework, and we evaluate its generative AI components. Our\nexperiments show that our framework's use of AI avoids common issues with\ngenerative models. Our framework produces realistic, labeled data. By reducing\ndependence on costly or restricted data sources, we pave a path towards more\naccessible and reproducible research.", "AI": {"tldr": "\u63d0\u51fa\u6a21\u5757\u5316\u591a\u6a21\u6001\u6846\u67b6\uff0c\u4f7f\u7528\u751f\u6210\u5f0fAI\u4ece\u516c\u5f00\u4f4f\u5b85\u4fe1\u606f\u548c\u56fe\u50cf\u751f\u6210\u80fd\u6e90\u5efa\u6a21\u6240\u9700\u6570\u636e\uff0c\u89e3\u51b3\u6570\u636e\u83b7\u53d6\u96be\u9898", "motivation": "\u80fd\u6e90\u5efa\u6a21\u7814\u7a76\u9700\u8981\u5927\u91cf\u6570\u636e\uff0c\u4f46\u8bb8\u591a\u6570\u636e\u96be\u4ee5\u83b7\u53d6\u3001\u6210\u672c\u9ad8\u6602\u6216\u5b58\u5728\u9690\u79c1\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66ff\u4ee3\u6570\u636e\u751f\u6210\u65b9\u6cd5", "method": "\u5f00\u53d1\u6a21\u5757\u5316\u591a\u6a21\u6001\u6846\u67b6\uff0c\u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u4ece\u516c\u5f00\u53ef\u8bbf\u95ee\u7684\u4f4f\u5b85\u4fe1\u606f\u548c\u56fe\u50cf\u751f\u6210\u6240\u9700\u6570\u636e\uff0c\u5e76\u63d0\u4f9b\u5b8c\u6574\u7684\u5904\u7406\u6d41\u7a0b", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u80fd\u907f\u514d\u751f\u6210\u6a21\u578b\u7684\u5e38\u89c1\u95ee\u9898\uff0c\u4ea7\u751f\u771f\u5b9e\u4e14\u6807\u6ce8\u826f\u597d\u7684\u6570\u636e", "conclusion": "\u901a\u8fc7\u51cf\u5c11\u5bf9\u6602\u8d35\u6216\u53d7\u9650\u6570\u636e\u6e90\u7684\u4f9d\u8d56\uff0c\u4e3a\u66f4\u6613\u83b7\u53d6\u548c\u53ef\u91cd\u590d\u7684\u7814\u7a76\u94fa\u5e73\u9053\u8def"}}
{"id": "2509.09801", "pdf": "https://arxiv.org/pdf/2509.09801", "abs": "https://arxiv.org/abs/2509.09801", "authors": ["Brennen Hill"], "title": "HEFT: A Coarse-to-Fine Hierarchy for Enhancing the Efficiency and Accuracy of Language Model Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T07, 68T50, 68T05", "I.2.7; I.2.6; C.4"], "comment": null, "summary": "The adaptation of large language models (LLMs) to specialized reasoning tasks\nis fundamentally constrained by computational resources. Parameter-Efficient\nFine-Tuning (PEFT) methods have emerged as a powerful solution, yet the\nlandscape of these techniques is diverse, with distinct methods operating in\neither the model's weight space or its representation space. This paper\ninvestigates the hypothesis that a synergistic combination of these paradigms\ncan unlock superior performance and efficiency. We introduce HEFT (Hierarchical\nEfficient Fine-Tuning), a novel hierarchical adaptation strategy that composes\ntwo distinct PEFT methods in a coarse-to-fine manner: first, a broad,\nfoundational adaptation in the weight space using Low-Rank Adaptation (LoRA),\nfollowed by a precise, surgical refinement of internal activations using\nRepresentation Fine-Tuning (ReFT). We evaluate this approach by fine-tuning a\nLlama-2-7B model on the BoolQ benchmark, a challenging dataset for inferential\nreasoning. Our results reveal a profound synergistic effect. A model fine-tuned\nfor only three epochs with our HEFT strategy achieves an accuracy of 85.17\\%,\nexceeding the performance of models trained for 20 epochs with either LoRA-only\n(85.05\\%) or ReFT-only (83.36\\%) methodologies. This work demonstrates that the\nthoughtful composition of PEFT methods is a potent algorithmic innovation,\noffering a more efficient and effective path toward advancing the reasoning\ncapabilities of language models. By achieving superior results with a fraction\nof the computational budget, our findings present a principled approach to\novercoming the obstacles inherent in adapting large-scale models for complex\ncognitive tasks.", "AI": {"tldr": "HEFT\u662f\u4e00\u79cd\u5206\u5c42\u9ad8\u6548\u5fae\u8c03\u7b56\u7565\uff0c\u7ed3\u5408LoRA\u548cReFT\u4e24\u79cdPEFT\u65b9\u6cd5\uff0c\u5728BoolQ\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4ec5\u75283\u4e2aepoch\u5c31\u8fbe\u523085.17%\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u5355\u4e00\u65b9\u6cd5\u8bad\u7ec320\u4e2aepoch\u7684\u6548\u679c\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u95e8\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u9002\u914d\u53d7\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\uff0c\u4e0d\u540cPEFT\u65b9\u6cd5\u5728\u6743\u91cd\u7a7a\u95f4\u548c\u8868\u793a\u7a7a\u95f4\u4e2d\u5404\u6709\u4f18\u52bf\uff0c\u7814\u7a76\u5047\u8bbe\u8fd9\u4e24\u79cd\u8303\u5f0f\u7684\u534f\u540c\u7ec4\u5408\u53ef\u4ee5\u89e3\u9501\u66f4\u597d\u7684\u6027\u80fd\u548c\u6548\u7387\u3002", "method": "\u63d0\u51faHEFT\u5206\u5c42\u9002\u914d\u7b56\u7565\uff1a\u5148\u5728\u6743\u91cd\u7a7a\u95f4\u4f7f\u7528LoRA\u8fdb\u884c\u5e7f\u6cdb\u7684\u57fa\u7840\u9002\u914d\uff0c\u7136\u540e\u5728\u8868\u793a\u7a7a\u95f4\u4f7f\u7528ReFT\u5bf9\u5185\u90e8\u6fc0\u6d3b\u8fdb\u884c\u7cbe\u786e\u7ec6\u5316\uff0c\u5f62\u6210\u4ece\u7c97\u5230\u7ec6\u7684\u5fae\u8c03\u65b9\u5f0f\u3002", "result": "\u5728Llama-2-7B\u6a21\u578b\u548cBoolQ\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cHEFT\u4ec5\u75283\u4e2aepoch\u8bad\u7ec3\u5c31\u8fbe\u523085.17%\u51c6\u786e\u7387\uff0c\u8d85\u8fc7LoRA-only\uff0885.05%\uff09\u548cReFT-only\uff0883.36%\uff09\u65b9\u6cd5\u8bad\u7ec320\u4e2aepoch\u7684\u6027\u80fd\u3002", "conclusion": "PEFT\u65b9\u6cd5\u7684\u7cbe\u5fc3\u7ec4\u5408\u662f\u4e00\u79cd\u5f3a\u5927\u7684\u7b97\u6cd5\u521b\u65b0\uff0c\u4e3a\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u6709\u6548\u7684\u8def\u5f84\uff0c\u4ee5\u66f4\u5c11\u7684\u8ba1\u7b97\u9884\u7b97\u83b7\u5f97\u66f4\u4f18\u7ed3\u679c\u3002"}}
{"id": "2509.09802", "pdf": "https://arxiv.org/pdf/2509.09802", "abs": "https://arxiv.org/abs/2509.09802", "authors": ["Tianqi Qiao", "Marie Maros"], "title": "Sparse Polyak: an adaptive step size rule for high-dimensional M-estimation", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": null, "summary": "We propose and study Sparse Polyak, a variant of Polyak's adaptive step size,\ndesigned to solve high-dimensional statistical estimation problems where the\nproblem dimension is allowed to grow much faster than the sample size. In such\nsettings, the standard Polyak step size performs poorly, requiring an\nincreasing number of iterations to achieve optimal statistical precision-even\nwhen, the problem remains well conditioned and/or the achievable precision\nitself does not degrade with problem size. We trace this limitation to a\nmismatch in how smoothness is measured: in high dimensions, it is no longer\neffective to estimate the Lipschitz smoothness constant. Instead, it is more\nappropriate to estimate the smoothness restricted to specific directions\nrelevant to the problem (restricted Lipschitz smoothness constant). Sparse\nPolyak overcomes this issue by modifying the step size to estimate the\nrestricted Lipschitz smoothness constant. We support our approach with both\ntheoretical analysis and numerical experiments, demonstrating its improved\nperformance.", "AI": {"tldr": "\u63d0\u51fa\u4e86Sparse Polyak\u65b9\u6cd5\uff0c\u6539\u8fdbPolyak\u81ea\u9002\u5e94\u6b65\u957f\u4ee5\u89e3\u51b3\u9ad8\u7ef4\u7edf\u8ba1\u4f30\u8ba1\u95ee\u9898\uff0c\u5728\u7ef4\u5ea6\u8fdc\u5927\u4e8e\u6837\u672c\u91cf\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347\u6027\u80fd", "motivation": "\u6807\u51c6Polyak\u6b65\u957f\u5728\u9ad8\u7ef4\u7edf\u8ba1\u4f30\u8ba1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5373\u4f7f\u95ee\u9898\u6761\u4ef6\u826f\u597d\uff0c\u4e5f\u9700\u8981\u66f4\u591a\u8fed\u4ee3\u624d\u80fd\u8fbe\u5230\u6700\u4f18\u7edf\u8ba1\u7cbe\u5ea6\uff0c\u8fd9\u6e90\u4e8eLipschitz\u5e73\u6ed1\u5ea6\u5e38\u6570\u4f30\u8ba1\u5728\u9ad8\u7ef4\u73af\u5883\u4e2d\u7684\u4e0d\u9002\u7528\u6027", "method": "\u901a\u8fc7\u4fee\u6539\u6b65\u957f\u6765\u4f30\u8ba1\u53d7\u9650Lipschitz\u5e73\u6ed1\u5ea6\u5e38\u6570\uff08\u9488\u5bf9\u95ee\u9898\u76f8\u5173\u65b9\u5411\u7684\u5e73\u6ed1\u5ea6\uff09\uff0c\u800c\u975e\u5168\u5c40Lipschitz\u5e38\u6570\uff0c\u4ece\u800c\u9002\u5e94\u9ad8\u7ef4\u8bbe\u7f6e", "result": "\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u5b9e\u9a8c\u5747\u8868\u660eSparse Polyak\u65b9\u6cd5\u5728\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u6027\u80fd\u663e\u8457\u63d0\u5347", "conclusion": "Sparse Polyak\u901a\u8fc7\u91c7\u7528\u53d7\u9650\u5e73\u6ed1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9ad8\u7ef4\u7edf\u8ba1\u4f30\u8ba1\u4e2d\u7684\u6b65\u957f\u9002\u5e94\u95ee\u9898\uff0c\u4e3a\u9ad8\u7ef4\u4f18\u5316\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u81ea\u9002\u5e94\u6b65\u957f\u7b56\u7565"}}
{"id": "2509.09808", "pdf": "https://arxiv.org/pdf/2509.09808", "abs": "https://arxiv.org/abs/2509.09808", "authors": ["Judith Massmann", "Alexander Lichtenstein", "Francisco M. L\u00f3pez"], "title": "Early Detection of Visual Impairments at Home Using a Smartphone Red-Eye Reflex Test", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at IEEE ICDL 2025. 6 pages, 7 figures, 2 tables", "summary": "Numerous visual impairments can be detected in red-eye reflex images from\nyoung children. The so-called Bruckner test is traditionally performed by\nophthalmologists in clinical settings. Thanks to the recent technological\nadvances in smartphones and artificial intelligence, it is now possible to\nrecreate the Bruckner test using a mobile device. In this paper, we present a\nfirst study conducted during the development of KidsVisionCheck, a free\napplication that can perform vision screening with a mobile device using\nred-eye reflex images. The underlying model relies on deep neural networks\ntrained on children's pupil images collected and labeled by an ophthalmologist.\nWith an accuracy of 90% on unseen test data, our model provides highly reliable\nperformance without the necessity of specialist equipment. Furthermore, we can\nidentify the optimal conditions for data collection, which can in turn be used\nto provide immediate feedback to the users. In summary, this work marks a first\nstep toward accessible pediatric vision screenings and early intervention for\nvision abnormalities worldwide.", "AI": {"tldr": "\u901a\u8fc7\u667a\u80fd\u624b\u673a\u5e94\u7528\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u5206\u6790\u7ea2\u773c\u53cd\u5c04\u56fe\u50cf\uff0c\u5b9e\u73b0\u513f\u7ae5\u89c6\u529b\u7b5b\u67e5\uff0c\u51c6\u786e\u7387\u8fbe90%", "motivation": "\u5229\u7528\u667a\u80fd\u624b\u673a\u548cAI\u6280\u672f\u91cd\u73b0\u4f20\u7edfBruckner\u6d4b\u8bd5\uff0c\u4f7f\u513f\u7ae5\u89c6\u529b\u7b5b\u67e5\u66f4\u52a0\u53ef\u8fbe\u548c\u4fbf\u6377", "method": "\u57fa\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u8bad\u7ec3\u4e8e\u773c\u79d1\u533b\u751f\u6536\u96c6\u548c\u6807\u6ce8\u7684\u513f\u7ae5\u5b54\u5f84\u56fe\u50cf\u6570\u636e", "result": "\u5728\u672a\u89c1\u6d4b\u8bd5\u6570\u636e\u4e0a\u8fbe\u523090%\u7684\u51c6\u786e\u7387\uff0c\u65e0\u9700\u4e13\u4e1a\u8bbe\u5907\u5373\u53ef\u83b7\u5f97\u9ad8\u53ef\u9760\u6027\u80fd", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5168\u7403\u8303\u56f4\u5185\u5b9e\u73b0\u53ef\u8fbe\u7684\u513f\u79d1\u89c6\u529b\u7b5b\u67e5\u548c\u65e9\u671f\u5e72\u9884\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840"}}
{"id": "2509.09828", "pdf": "https://arxiv.org/pdf/2509.09828", "abs": "https://arxiv.org/abs/2509.09828", "authors": ["Tim Broedermannn", "Christos Sakaridis", "Luigi Piccinelli", "Wim Abbeloos", "Luc Van Gool"], "title": "DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "Code and models will be available at\n  https://github.com/timbroed/DGFusion", "summary": "Robust semantic perception for autonomous vehicles relies on effectively\ncombining multiple sensors with complementary strengths and weaknesses.\nState-of-the-art sensor fusion approaches to semantic perception often treat\nsensor data uniformly across the spatial extent of the input, which hinders\nperformance when faced with challenging conditions. By contrast, we propose a\nnovel depth-guided multimodal fusion method that upgrades condition-aware\nfusion by integrating depth information. Our network, DGFusion, poses\nmultimodal segmentation as a multi-task problem, utilizing the lidar\nmeasurements, which are typically available in outdoor sensor suites, both as\none of the model's inputs and as ground truth for learning depth. Our\ncorresponding auxiliary depth head helps to learn depth-aware features, which\nare encoded into spatially varying local depth tokens that condition our\nattentive cross-modal fusion. Together with a global condition token, these\nlocal depth tokens dynamically adapt sensor fusion to the spatially varying\nreliability of each sensor across the scene, which largely depends on depth. In\naddition, we propose a robust loss for our depth, which is essential for\nlearning from lidar inputs that are typically sparse and noisy in adverse\nconditions. Our method achieves state-of-the-art panoptic and semantic\nsegmentation performance on the challenging MUSES and DELIVER datasets. Code\nand models will be available at https://github.com/timbroed/DGFusion", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f15\u5bfc\u7684\u591a\u6a21\u6001\u878d\u5408\u65b9\u6cd5DGFusion\uff0c\u901a\u8fc7\u6df1\u5ea6\u611f\u77e5\u7279\u5f81\u548c\u7a7a\u95f4\u53d8\u5316\u7684\u6761\u4ef6\u878d\u5408\u673a\u5236\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u8bed\u4e49\u611f\u77e5\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u4f20\u611f\u5668\u878d\u5408\u65b9\u6cd5\u5728\u5904\u7406\u5177\u6709\u6311\u6218\u6027\u7684\u73af\u5883\u6761\u4ef6\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u5b83\u4eec\u901a\u5e38\u5728\u6574\u4e2a\u8f93\u5165\u7a7a\u95f4\u8303\u56f4\u5185\u7edf\u4e00\u5904\u7406\u4f20\u611f\u5668\u6570\u636e\uff0c\u800c\u6ca1\u6709\u8003\u8651\u4e0d\u540c\u4f20\u611f\u5668\u5728\u4e0d\u540c\u6df1\u5ea6\u6761\u4ef6\u4e0b\u7684\u53ef\u9760\u6027\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u4e86DGFusion\u7f51\u7edc\uff0c\u5c06\u591a\u6a21\u6001\u5206\u5272\u4f5c\u4e3a\u591a\u4efb\u52a1\u95ee\u9898\u5904\u7406\uff0c\u5229\u7528LiDAR\u6d4b\u91cf\u4f5c\u4e3a\u8f93\u5165\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u771f\u503c\u3002\u901a\u8fc7\u8f85\u52a9\u6df1\u5ea6\u5934\u5b66\u4e60\u6df1\u5ea6\u611f\u77e5\u7279\u5f81\uff0c\u7f16\u7801\u4e3a\u7a7a\u95f4\u53d8\u5316\u7684\u5c40\u90e8\u6df1\u5ea6\u6807\u8bb0\uff0c\u4e0e\u5168\u5c40\u6761\u4ef6\u6807\u8bb0\u4e00\u8d77\u52a8\u6001\u8c03\u6574\u4f20\u611f\u5668\u878d\u5408\u7b56\u7565\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684MUSES\u548cDELIVER\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u5168\u666f\u548c\u8bed\u4e49\u5206\u5272\u6027\u80fd\u3002", "conclusion": "\u6df1\u5ea6\u5f15\u5bfc\u7684\u591a\u6a21\u6001\u878d\u5408\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u9002\u5e94\u4e0d\u540c\u4f20\u611f\u5668\u5728\u4e0d\u540c\u6df1\u5ea6\u6761\u4ef6\u4e0b\u7684\u53ef\u9760\u6027\u53d8\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u9a7e\u9a76\u8bed\u4e49\u611f\u77e5\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2509.09836", "pdf": "https://arxiv.org/pdf/2509.09836", "abs": "https://arxiv.org/abs/2509.09836", "authors": ["Marco Pasini", "Stefan Lattner", "George Fazekas"], "title": "CoDiCodec: Unifying Continuous and Discrete Compressed Representations of Audio", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": "Accepted to ISMIR 2025", "summary": "Efficiently representing audio signals in a compressed latent space is\ncritical for latent generative modelling. However, existing autoencoders often\nforce a choice between continuous embeddings and discrete tokens. Furthermore,\nachieving high compression ratios while maintaining audio fidelity remains a\nchallenge. We introduce CoDiCodec, a novel audio autoencoder that overcomes\nthese limitations by both efficiently encoding global features via summary\nembeddings, and by producing both compressed continuous embeddings at ~ 11 Hz\nand discrete tokens at a rate of 2.38 kbps from the same trained model,\noffering unprecedented flexibility for different downstream generative tasks.\nThis is achieved through Finite Scalar Quantization (FSQ) and a novel\nFSQ-dropout technique, and does not require additional loss terms beyond the\nsingle consistency loss used for end-to-end training. CoDiCodec supports both\nautoregressive decoding and a novel parallel decoding strategy, with the latter\nachieving superior audio quality and faster decoding. CoDiCodec outperforms\nexisting continuous and discrete autoencoders at similar bitrates in terms of\nreconstruction audio quality. Our work enables a unified approach to audio\ncompression, bridging the gap between continuous and discrete generative\nmodelling paradigms.", "AI": {"tldr": "CoDiCodec\u662f\u4e00\u79cd\u65b0\u9896\u7684\u97f3\u9891\u81ea\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u603b\u7ed3\u5d4c\u5165\u548cFSQ\u6280\u672f\uff0c\u5728\u540c\u4e00\u6a21\u578b\u4e2d\u540c\u65f6\u751f\u6210\u8fde\u7eed\u5d4c\u5165\u548c\u79bb\u6563\u6807\u8bb0\uff0c\u63d0\u4f9b11Hz\u7684\u8fde\u7eed\u5d4c\u5165\u548c2.38kbps\u7684\u79bb\u6563\u6807\u8bb0\uff0c\u5728\u76f8\u4f3c\u6bd4\u7279\u7387\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u97f3\u9891\u81ea\u7f16\u7801\u5668\u9700\u8981\u5728\u8fde\u7eed\u5d4c\u5165\u548c\u79bb\u6563\u6807\u8bb0\u4e4b\u95f4\u505a\u51fa\u9009\u62e9\uff0c\u4e14\u5728\u9ad8\u538b\u7f29\u6bd4\u4e0b\u4fdd\u6301\u97f3\u9891\u4fdd\u771f\u5ea6\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u4f7f\u7528\u6709\u9650\u6807\u91cf\u91cf\u5316(FSQ)\u548c\u65b0\u578bFSQ-dropout\u6280\u672f\uff0c\u901a\u8fc7\u5355\u4e00\u4e00\u81f4\u6027\u635f\u5931\u8fdb\u884c\u7aef\u5230\u7aef\u8bad\u7ec3\uff0c\u652f\u6301\u81ea\u56de\u5f52\u89e3\u7801\u548c\u65b0\u578b\u5e76\u884c\u89e3\u7801\u7b56\u7565\u3002", "result": "\u5728\u76f8\u4f3c\u6bd4\u7279\u7387\u4e0b\uff0cCoDiCodec\u5728\u91cd\u5efa\u97f3\u9891\u8d28\u91cf\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7684\u8fde\u7eed\u548c\u79bb\u6563\u81ea\u7f16\u7801\u5668\uff0c\u5e76\u884c\u89e3\u7801\u7b56\u7565\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u97f3\u9891\u8d28\u91cf\u548c\u66f4\u5feb\u7684\u89e3\u7801\u901f\u5ea6\u3002", "conclusion": "CoDiCodec\u4e3a\u97f3\u9891\u538b\u7f29\u63d0\u4f9b\u4e86\u7edf\u4e00\u65b9\u6cd5\uff0c\u5f25\u5408\u4e86\u8fde\u7eed\u548c\u79bb\u6563\u751f\u6210\u5efa\u6a21\u8303\u5f0f\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2509.09855", "pdf": "https://arxiv.org/pdf/2509.09855", "abs": "https://arxiv.org/abs/2509.09855", "authors": ["Agus Sudjianto", "Denis Burakov"], "title": "An Information-Theoretic Framework for Credit Risk Modeling: Unifying Industry Practice with Statistical Theory for Fair and Interpretable Scorecards", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Credit risk modeling relies extensively on Weight of Evidence (WoE) and\nInformation Value (IV) for feature engineering, and Population Stability Index\n(PSI) for drift monitoring, yet their theoretical foundations remain\ndisconnected. We establish a unified information-theoretic framework revealing\nthese industry-standard metrics as instances of classical information\ndivergences. Specifically, we prove that IV exactly equals PSI (Jeffreys\ndivergence) computed between good and bad credit outcomes over identical bins.\nThrough the delta method applied to WoE transformations, we derive standard\nerrors for IV and PSI, enabling formal hypothesis testing and probabilistic\nfairness constraints for the first time. We formalize credit modeling's\ninherent performance-fairness trade-off as maximizing IV for predictive power\nwhile minimizing IV for protected attributes. Using automated binning with\ndepth-1 XGBoost stumps, we compare three encoding strategies: logistic\nregression with one-hot encoding, WoE transformation, and constrained XGBoost.\nAll methods achieve comparable predictive performance (AUC 0.82-0.84),\ndemonstrating that principled, information-theoretic binning outweighs encoding\nchoice. Mixed-integer programming traces Pareto-efficient solutions along the\nperformance-fairness frontier with uncertainty quantification. This framework\nbridges theory and practice, providing the first rigorous statistical\nfoundation for widely-used credit risk metrics while offering principled tools\nfor balancing accuracy and fairness in regulated environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3a\u4fe1\u7528\u98ce\u9669\u5efa\u6a21\u4e2d\u7684WoE\u3001IV\u548cPSI\u6307\u6807\u5efa\u7acb\u4e86\u7edf\u4e00\u7684\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u8fd9\u4e9b\u884c\u4e1a\u6807\u51c6\u6307\u6807\u662f\u7ecf\u5178\u4fe1\u606f\u6563\u5ea6\u7684\u5b9e\u4f8b\uff0c\u5e76\u9996\u6b21\u63d0\u4f9b\u4e86\u7edf\u8ba1\u63a8\u65ad\u548c\u516c\u5e73\u6027\u7ea6\u675f\u7684\u6570\u5b66\u57fa\u7840\u3002", "motivation": "\u4fe1\u7528\u98ce\u9669\u5efa\u6a21\u5e7f\u6cdb\u4f7f\u7528WoE\u3001IV\u548cPSI\u7b49\u6307\u6807\uff0c\u4f46\u8fd9\u4e9b\u6307\u6807\u7684\u7406\u8bba\u57fa\u7840\u5206\u6563\u4e14\u7f3a\u4e4f\u7edf\u4e00\u7684\u7edf\u8ba1\u6846\u67b6\uff0c\u65e0\u6cd5\u8fdb\u884c\u6b63\u5f0f\u7684\u5047\u8bbe\u68c0\u9a8c\u548c\u516c\u5e73\u6027\u7ea6\u675f\u3002", "method": "\u901a\u8fc7\u4fe1\u606f\u8bba\u6846\u67b6\u8bc1\u660eIV\u7b49\u4e8ePSI\uff0c\u5e94\u7528delta\u65b9\u6cd5\u63a8\u5bfcIV\u548cPSI\u7684\u6807\u51c6\u8bef\u5dee\uff0c\u4f7f\u7528\u6df1\u5ea61\u7684XGBoost\u6811\u6869\u8fdb\u884c\u81ea\u52a8\u5206\u7bb1\uff0c\u6bd4\u8f83\u4e09\u79cd\u7f16\u7801\u7b56\u7565\uff0c\u5e76\u5229\u7528\u6df7\u5408\u6574\u6570\u89c4\u5212\u5bfb\u627e\u6027\u80fd-\u516c\u5e73\u6027\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "result": "\u6240\u6709\u65b9\u6cd5\u90fd\u8fbe\u5230\u4e86\u76f8\u5f53\u7684\u9884\u6d4b\u6027\u80fd\uff08AUC 0.82-0.84\uff09\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u5206\u7bb1\u65b9\u6cd5\u6bd4\u7f16\u7801\u9009\u62e9\u66f4\u91cd\u8981\uff0c\u540c\u65f6\u80fd\u591f\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u5e76\u63d0\u4f9b\u6027\u80fd-\u516c\u5e73\u6027\u6743\u8861\u7684\u5e15\u7d2f\u6258\u89e3\u3002", "conclusion": "\u8be5\u6846\u67b6\u9996\u6b21\u4e3a\u5e7f\u6cdb\u4f7f\u7528\u7684\u4fe1\u7528\u98ce\u9669\u6307\u6807\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7edf\u8ba1\u57fa\u7840\uff0c\u4e3a\u53d7\u76d1\u7ba1\u73af\u5883\u4e2d\u5e73\u8861\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u5de5\u5177\uff0c\u8fde\u63a5\u4e86\u7406\u8bba\u4e0e\u5b9e\u8df5\u3002"}}
{"id": "2509.09859", "pdf": "https://arxiv.org/pdf/2509.09859", "abs": "https://arxiv.org/abs/2509.09859", "authors": ["Razvan Stefanescu", "Ethan Oh", "Ruben Vazquez", "Chris Mesterharm", "Constantin Serban", "Ritu Chadha"], "title": "WAVE-DETR Multi-Modal Visible and Acoustic Real-Life Drone Detector", "categories": ["cs.CV", "cs.LG", "68W99"], "comment": "11 pages, 11 figures", "summary": "We introduce a multi-modal WAVE-DETR drone detector combining visible RGB and\nacoustic signals for robust real-life UAV object detection. Our approach fuses\nvisual and acoustic features in a unified object detector model relying on the\nDeformable DETR and Wav2Vec2 architectures, achieving strong performance under\nchallenging environmental conditions. Our work leverage the existing\nDrone-vs-Bird dataset and the newly generated ARDrone dataset containing more\nthan 7,500 synchronized images and audio segments. We show how the acoustic\ninformation is used to improve the performance of the Deformable DETR object\ndetector on the real ARDrone dataset. We developed, trained and tested four\ndifferent fusion configurations based on a gated mechanism, linear layer, MLP\nand cross attention. The Wav2Vec2 acoustic embeddings are fused with the multi\nresolution feature mappings of the Deformable DETR and enhance the object\ndetection performance over all drones dimensions. The best performer is the\ngated fusion approach, which improves the mAP of the Deformable DETR object\ndetector on our in-distribution and out-of-distribution ARDrone datasets by\n11.1% to 15.3% for small drones across all IoU thresholds between 0.5 and 0.9.\nThe mAP scores for medium and large drones are also enhanced, with overall\ngains across all drone sizes ranging from 3.27% to 5.84%.", "AI": {"tldr": "\u63d0\u51faWAVE-DETR\u591a\u6a21\u6001\u65e0\u4eba\u673a\u68c0\u6d4b\u5668\uff0c\u878d\u5408\u53ef\u89c1\u5149RGB\u548c\u58f0\u5b66\u4fe1\u53f7\uff0c\u5728Deformable DETR\u548cWav2Vec2\u67b6\u6784\u57fa\u7840\u4e0a\u5b9e\u73b0\u9c81\u68d2\u7684\u5b9e\u65f6\u65e0\u4eba\u673a\u76ee\u6807\u68c0\u6d4b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u590d\u6742\u73af\u5883\u6761\u4ef6\u4e0b\u65e0\u4eba\u673a\u68c0\u6d4b\u7684\u6311\u6218\uff0c\u5229\u7528\u591a\u6a21\u6001\u4fe1\u606f\uff08\u89c6\u89c9\u548c\u58f0\u5b66\uff09\u6765\u63d0\u9ad8\u68c0\u6d4b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5c0f\u5c3a\u5bf8\u65e0\u4eba\u673a\u68c0\u6d4b\u65b9\u9762\u3002", "method": "\u57fa\u4e8eDeformable DETR\u548cWav2Vec2\u67b6\u6784\uff0c\u5f00\u53d1\u4e86\u56db\u79cd\u878d\u5408\u914d\u7f6e\uff1a\u95e8\u63a7\u673a\u5236\u3001\u7ebf\u6027\u5c42\u3001MLP\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u3002\u5c06\u58f0\u5b66\u5d4c\u5165\u4e0e\u591a\u5206\u8fa8\u7387\u7279\u5f81\u6620\u5c04\u878d\u5408\uff0c\u589e\u5f3a\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\u3002", "result": "\u6700\u4f73\u7684\u95e8\u63a7\u878d\u5408\u65b9\u6cd5\u5728ARDrone\u6570\u636e\u96c6\u4e0a\u5c06Deformable DETR\u68c0\u6d4b\u5668\u7684mAP\u63d0\u9ad8\u4e8611.1%\u523015.3%\uff08\u5c0f\u65e0\u4eba\u673a\uff09\uff0c\u4e2d\u578b\u548c\u5927\u578b\u65e0\u4eba\u673a\u7684mAP\u4e5f\u67093.27%\u52305.84%\u7684\u63d0\u5347\u3002", "conclusion": "\u591a\u6a21\u6001\u878d\u5408\uff08\u89c6\u89c9+\u58f0\u5b66\uff09\u663e\u8457\u63d0\u5347\u4e86\u65e0\u4eba\u673a\u68c0\u6d4b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6311\u6218\u6027\u73af\u5883\u6761\u4ef6\u4e0b\uff0c\u95e8\u63a7\u878d\u5408\u662f\u6700\u6709\u6548\u7684\u878d\u5408\u7b56\u7565\u3002"}}
{"id": "2509.09863", "pdf": "https://arxiv.org/pdf/2509.09863", "abs": "https://arxiv.org/abs/2509.09863", "authors": ["Sarvan Gill", "Daniela Constantinescu"], "title": "Off Policy Lyapunov Stability in Reinforcement Learning", "categories": ["eess.SY", "cs.LG", "cs.RO", "cs.SY"], "comment": "Conference on Robot Learning (CORL) 2025", "summary": "Traditional reinforcement learning lacks the ability to provide stability\nguarantees. More recent algorithms learn Lyapunov functions alongside the\ncontrol policies to ensure stable learning. However, the current self-learned\nLyapunov functions are sample inefficient due to their on-policy nature. This\npaper introduces a method for learning Lyapunov functions off-policy and\nincorporates the proposed off-policy Lyapunov function into the Soft Actor\nCritic and Proximal Policy Optimization algorithms to provide them with a data\nefficient stability certificate. Simulations of an inverted pendulum and a\nquadrotor illustrate the improved performance of the two algorithms when\nendowed with the proposed off-policy Lyapunov function.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u79bb\u7b56\u7565\u5b66\u4e60Lyapunov\u51fd\u6570\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408SAC\u548cPPO\u7b97\u6cd5\u63d0\u4f9b\u6570\u636e\u9ad8\u6548\u7a33\u5b9a\u6027\u4fdd\u8bc1", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u7f3a\u4e4f\u7a33\u5b9a\u6027\u4fdd\u8bc1\uff0c\u73b0\u6709\u57fa\u4e8eLyapunov\u51fd\u6570\u7684\u65b9\u6cd5\u7531\u4e8e\u91c7\u7528\u540c\u7b56\u7565\u5b66\u4e60\u5bfc\u81f4\u6837\u672c\u6548\u7387\u4f4e\u4e0b", "method": "\u5f00\u53d1\u79bb\u7b56\u7565Lyapunov\u51fd\u6570\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230Soft Actor Critic\u548cProximal Policy Optimization\u7b97\u6cd5\u4e2d", "result": "\u5728\u5012\u7acb\u6446\u548c\u56db\u65cb\u7ffc\u98de\u884c\u5668\u4eff\u771f\u4e2d\uff0c\u91c7\u7528\u6240\u63d0\u65b9\u6cd5\u7684\u7b97\u6cd5\u6027\u80fd\u5f97\u5230\u663e\u8457\u63d0\u5347", "conclusion": "\u79bb\u7b56\u7565Lyapunov\u51fd\u6570\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u4e3a\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u63d0\u4f9b\u6570\u636e\u9ad8\u6548\u7684\u7a33\u5b9a\u6027\u8bc1\u4e66\uff0c\u63d0\u9ad8\u6837\u672c\u5229\u7528\u6548\u7387"}}
{"id": "2509.09880", "pdf": "https://arxiv.org/pdf/2509.09880", "abs": "https://arxiv.org/abs/2509.09880", "authors": ["Ya\u015far Utku Al\u00e7alar", "Junno Yun", "Mehmet Ak\u00e7akaya"], "title": "Automated Tuning for Diffusion Inverse Problem Solvers without Generative Prior Retraining", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "physics.med-ph"], "comment": "IEEE International Workshop on Computational Advances in Multi-Sensor\n  Adaptive Processing (CAMSAP), 2025", "summary": "Diffusion/score-based models have recently emerged as powerful generative\npriors for solving inverse problems, including accelerated MRI reconstruction.\nWhile their flexibility allows decoupling the measurement model from the\nlearned prior, their performance heavily depends on carefully tuned data\nfidelity weights, especially under fast sampling schedules with few denoising\nsteps. Existing approaches often rely on heuristics or fixed weights, which\nfail to generalize across varying measurement conditions and irregular timestep\nschedules. In this work, we propose Zero-shot Adaptive Diffusion Sampling\n(ZADS), a test-time optimization method that adaptively tunes fidelity weights\nacross arbitrary noise schedules without requiring retraining of the diffusion\nprior. ZADS treats the denoising process as a fixed unrolled sampler and\noptimizes fidelity weights in a self-supervised manner using only undersampled\nmeasurements. Experiments on the fastMRI knee dataset demonstrate that ZADS\nconsistently outperforms both traditional compressed sensing and recent\ndiffusion-based methods, showcasing its ability to deliver high-fidelity\nreconstructions across varying noise schedules and acquisition settings.", "AI": {"tldr": "\u63d0\u51faZADS\u65b9\u6cd5\uff0c\u901a\u8fc7\u6d4b\u8bd5\u65f6\u4f18\u5316\u81ea\u9002\u5e94\u8c03\u6574\u6269\u6563\u6a21\u578b\u4e2d\u7684\u4fdd\u771f\u5ea6\u6743\u91cd\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u9002\u5e94\u4e0d\u540c\u566a\u58f0\u8c03\u5ea6\uff0c\u5728MRI\u91cd\u5efa\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u5728\u89e3\u51b3\u9006\u95ee\u9898\u65f6\u4e25\u91cd\u4f9d\u8d56\u7cbe\u5fc3\u8c03\u6574\u7684\u4fdd\u771f\u5ea6\u6743\u91cd\uff0c\u7279\u522b\u662f\u5728\u5feb\u901f\u91c7\u6837\u8ba1\u5212\u4e0b\uff0c\u73b0\u6709\u542f\u53d1\u5f0f\u6216\u56fa\u5b9a\u6743\u91cd\u65b9\u6cd5\u65e0\u6cd5\u6cdb\u5316\u5230\u4e0d\u540c\u7684\u6d4b\u91cf\u6761\u4ef6\u548c\u65f6\u95f4\u6b65\u8c03\u5ea6", "method": "ZADS\u5c06\u53bb\u566a\u8fc7\u7a0b\u89c6\u4e3a\u56fa\u5b9a\u7684\u5c55\u5f00\u91c7\u6837\u5668\uff0c\u4ec5\u4f7f\u7528\u6b20\u91c7\u6837\u6d4b\u91cf\u4ee5\u81ea\u76d1\u7763\u65b9\u5f0f\u4f18\u5316\u4fdd\u771f\u5ea6\u6743\u91cd\uff0c\u5b9e\u73b0\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u8c03\u6574", "result": "\u5728fastMRI\u819d\u5173\u8282\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cZADS\u59cb\u7ec8\u4f18\u4e8e\u4f20\u7edf\u538b\u7f29\u611f\u77e5\u548c\u6700\u8fd1\u7684\u57fa\u4e8e\u6269\u6563\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u8de8\u4e0d\u540c\u566a\u58f0\u8c03\u5ea6\u548c\u91c7\u96c6\u8bbe\u7f6e\u63d0\u4f9b\u9ad8\u4fdd\u771f\u91cd\u5efa", "conclusion": "ZADS\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6269\u6563\u5148\u9a8c\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6743\u91cd\u8c03\u6574\u663e\u8457\u63d0\u5347\u4e86\u6269\u6563\u6a21\u578b\u5728\u9006\u95ee\u9898\u6c42\u89e3\u4e2d\u7684\u6027\u80fd"}}
{"id": "2509.09894", "pdf": "https://arxiv.org/pdf/2509.09894", "abs": "https://arxiv.org/abs/2509.09894", "authors": ["Jiayun Wang", "Yousuf Aborahama", "Arya Khokhar", "Yang Zhang", "Chuwei Wang", "Karteekeya Sastry", "Julius Berner", "Yilin Luo", "Boris Bonev", "Zongyi Li", "Kamyar Azizzadenesheli", "Lihong V. Wang", "Anima Anandkumar"], "title": "Accelerating 3D Photoacoustic Computed Tomography with End-to-End Physics-Aware Neural Operators", "categories": ["eess.IV", "cs.LG"], "comment": null, "summary": "Photoacoustic computed tomography (PACT) combines optical contrast with\nultrasonic resolution, achieving deep-tissue imaging beyond the optical\ndiffusion limit. While three-dimensional PACT systems enable high-resolution\nvolumetric imaging for applications spanning transcranial to breast imaging,\ncurrent implementations require dense transducer arrays and prolonged\nacquisition times, limiting clinical translation. We introduce Pano (PACT\nimaging neural operator), an end-to-end physics-aware model that directly\nlearns the inverse acoustic mapping from sensor measurements to volumetric\nreconstructions. Unlike existing approaches (e.g. universal back-projection\nalgorithm), Pano learns both physics and data priors while also being agnostic\nto the input data resolution. Pano employs spherical discrete-continuous\nconvolutions to preserve hemispherical sensor geometry, incorporates Helmholtz\nequation constraints to ensure physical consistency and operates\nresolutionindependently across varying sensor configurations. We demonstrate\nthe robustness and efficiency of Pano in reconstructing high-quality images\nfrom both simulated and real experimental data, achieving consistent\nperformance even with significantly reduced transducer counts and limited-angle\nacquisition configurations. The framework maintains reconstruction fidelity\nacross diverse sparse sampling patterns while enabling real-time volumetric\nimaging capabilities. This advancement establishes a practical pathway for\nmaking 3D PACT more accessible and feasible for both preclinical research and\nclinical applications, substantially reducing hardware requirements without\ncompromising image reconstruction quality.", "AI": {"tldr": "\u63d0\u51faPano\uff08PACT\u6210\u50cf\u795e\u7ecf\u7b97\u5b50\uff09\uff0c\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u7269\u7406\u611f\u77e5\u6a21\u578b\uff0c\u76f4\u63a5\u4ece\u4f20\u611f\u5668\u6d4b\u91cf\u5b66\u4e60\u5230\u4f53\u79ef\u91cd\u5efa\u7684\u9006\u58f0\u5b66\u6620\u5c04\uff0c\u663e\u8457\u51cf\u5c11\u6362\u80fd\u5668\u6570\u91cf\u548c\u91c7\u96c6\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u91cd\u5efa\u8d28\u91cf", "motivation": "\u5f53\u524d\u4e09\u7ef4PACT\u7cfb\u7edf\u9700\u8981\u5bc6\u96c6\u7684\u6362\u80fd\u5668\u9635\u5217\u548c\u957f\u65f6\u95f4\u91c7\u96c6\uff0c\u9650\u5236\u4e86\u4e34\u5e8a\u8f6c\u5316\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u51cf\u5c11\u786c\u4ef6\u9700\u6c42\u540c\u65f6\u4fdd\u6301\u6210\u50cf\u8d28\u91cf\u7684\u65b0\u65b9\u6cd5", "method": "\u4f7f\u7528\u7403\u9762\u79bb\u6563-\u8fde\u7eed\u5377\u79ef\u4fdd\u6301\u534a\u7403\u5f62\u4f20\u611f\u5668\u51e0\u4f55\u7ed3\u6784\uff0c\u7ed3\u5408\u4ea5\u59c6\u970d\u5179\u65b9\u7a0b\u7ea6\u675f\u786e\u4fdd\u7269\u7406\u4e00\u81f4\u6027\uff0c\u91c7\u7528\u5206\u8fa8\u7387\u65e0\u5173\u7684\u7aef\u5230\u7aef\u5b66\u4e60\u6846\u67b6", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u5b9e\u9a8c\u6570\u636e\u4e2d\u90fd\u80fd\u91cd\u5efa\u9ad8\u8d28\u91cf\u56fe\u50cf\uff0c\u5373\u4f7f\u663e\u8457\u51cf\u5c11\u6362\u80fd\u5668\u6570\u91cf\u548c\u6709\u9650\u89d2\u5ea6\u91c7\u96c6\u914d\u7f6e\u4e0b\u4e5f\u80fd\u4fdd\u6301\u4e00\u81f4\u7684\u6027\u80fd", "conclusion": "Pano\u6846\u67b6\u4e3a3D PACT\u7684\u4e34\u5e8a\u8f6c\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\uff0c\u5927\u5e45\u51cf\u5c11\u786c\u4ef6\u9700\u6c42\u800c\u4e0d\u5f71\u54cd\u91cd\u5efa\u8d28\u91cf\uff0c\u4f7f\u5b9e\u65f6\u4f53\u79ef\u6210\u50cf\u6210\u4e3a\u53ef\u80fd"}}
{"id": "2509.09923", "pdf": "https://arxiv.org/pdf/2509.09923", "abs": "https://arxiv.org/abs/2509.09923", "authors": ["Myles Joshua Toledo Tan", "Maria Kapetanaki", "Panayiotis V. Benos"], "title": "Engineering Spatial and Molecular Features from Cellular Niches to Inform Predictions of Inflammatory Bowel Disease", "categories": ["q-bio.GN", "cs.LG"], "comment": "18 pages, 7 figures, 7 tables. Submitted to the 25th BNAIC\n  Conference, Namur, Belgium, November 19 - 21, 2025", "summary": "Differentiating between the two main subtypes of Inflammatory Bowel Disease\n(IBD): Crohns disease (CD) and ulcerative colitis (UC) is a persistent clinical\nchallenge due to overlapping presentations. This study introduces a novel\ncomputational framework that employs spatial transcriptomics (ST) to create an\nexplainable machine learning model for IBD classification. We analyzed ST data\nfrom the colonic mucosa of healthy controls (HC), UC, and CD patients. Using\nNon-negative Matrix Factorization (NMF), we first identified four recurring\ncellular niches, representing distinct functional microenvironments within the\ntissue. From these niches, we systematically engineered 44 features capturing\nthree key aspects of tissue pathology: niche composition, neighborhood\nenrichment, and niche-gene signals. A multilayer perceptron (MLP) classifier\ntrained on these features achieved an accuracy of 0.774 +/- 0.161 for the more\nchallenging three-class problem (HC, UC, and CD) and 0.916 +/- 0.118 in the\ntwo-class problem of distinguishing IBD from healthy tissue. Crucially, model\nexplainability analysis revealed that disruptions in the spatial organization\nof niches were the strongest predictors of general inflammation, while the\nclassification between UC and CD relied on specific niche-gene expression\nsignatures. This work provides a robust, proof-of-concept pipeline that\ntransforms descriptive spatial data into an accurate and explainable predictive\ntool, offering not only a potential new diagnostic paradigm but also deeper\ninsights into the distinct biological mechanisms that drive IBD subtypes.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u7684\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u533a\u5206\u514b\u7f57\u6069\u75c5\u548c\u6e83\u75a1\u6027\u7ed3\u80a0\u708e\uff0c\u901a\u8fc7\u8bc6\u522b\u7ec6\u80de\u751f\u6001\u4f4d\u7279\u5f81\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5206\u7c7b", "motivation": "\u708e\u75c7\u6027\u80a0\u75c5(IBD)\u7684\u4e24\u79cd\u4e3b\u8981\u4e9a\u578b\u514b\u7f57\u6069\u75c5\u548c\u6e83\u75a1\u6027\u7ed3\u80a0\u708e\u4e34\u5e8a\u8868\u73b0\u91cd\u53e0\uff0c\u4f20\u7edf\u8bca\u65ad\u65b9\u6cd5\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u7cbe\u51c6\u8bca\u65ad\u5de5\u5177", "method": "\u4f7f\u7528\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u8bc6\u522b4\u4e2a\u91cd\u590d\u51fa\u73b0\u7684\u7ec6\u80de\u751f\u6001\u4f4d\uff0c\u4ece\u4e2d\u63d0\u53d644\u4e2a\u7279\u5f81\uff08\u751f\u6001\u4f4d\u7ec4\u6210\u3001\u90bb\u57df\u5bcc\u96c6\u548c\u751f\u6001\u4f4d-\u57fa\u56e0\u4fe1\u53f7\uff09\uff0c\u8bad\u7ec3\u591a\u5c42\u611f\u77e5\u673a\u5206\u7c7b\u5668", "result": "\u4e09\u5206\u7c7b\u95ee\u9898\u51c6\u786e\u738777.4%\uff0c\u4e8c\u5206\u7c7b\u95ee\u9898\u51c6\u786e\u738791.6%\uff1b\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5206\u6790\u663e\u793a\u7a7a\u95f4\u7ec4\u7ec7\u7834\u574f\u662f\u708e\u75c7\u7684\u4e3b\u8981\u9884\u6d4b\u56e0\u5b50\uff0c\u800c\u7279\u5b9a\u57fa\u56e0\u8868\u8fbe\u7279\u5f81\u533a\u5206\u4e9a\u578b", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5c06\u63cf\u8ff0\u6027\u7a7a\u95f4\u6570\u636e\u8f6c\u5316\u4e3a\u51c6\u786e\u53ef\u89e3\u91ca\u9884\u6d4b\u5de5\u5177\u7684\u6d41\u7a0b\uff0c\u4e0d\u4ec5\u63d0\u4f9b\u65b0\u7684\u8bca\u65ad\u8303\u5f0f\uff0c\u8fd8\u6df1\u5165\u63ed\u793a\u4e86IBD\u4e9a\u578b\u7684\u751f\u7269\u5b66\u673a\u5236"}}
{"id": "2509.09972", "pdf": "https://arxiv.org/pdf/2509.09972", "abs": "https://arxiv.org/abs/2509.09972", "authors": ["Mohammadreza Narimani", "Alireza Pourreza", "Ali Moghimi", "Mohsen Mesgaran", "Parastoo Farajpoor", "Hamid Jafarbiglu"], "title": "Drone-Based Multispectral Imaging and Deep Learning for Timely Detection of Branched Broomrape in Tomato Farms", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": "Author-accepted version (no publisher header/footer). 10 pages +\n  presentation. Published in Proceedings of SPIE Defense + Commercial Sensing\n  2024, Vol. 13053, Paper 1305304. Event: National Harbor, Maryland, USA.\n  Official version: https://doi.org/10.1117/12.3021219", "summary": "This study addresses the escalating threat of branched broomrape (Phelipanche\nramosa) to California's tomato industry, which supplies over 90 percent of U.S.\nprocessing tomatoes. The parasite's largely underground life cycle makes early\ndetection difficult, while conventional chemical controls are costly,\nenvironmentally harmful, and often ineffective. To address this, we combined\ndrone-based multispectral imagery with Long Short-Term Memory (LSTM) deep\nlearning networks, using the Synthetic Minority Over-sampling Technique (SMOTE)\nto handle class imbalance. Research was conducted on a known broomrape-infested\ntomato farm in Woodland, Yolo County, CA, across five key growth stages\ndetermined by growing degree days (GDD). Multispectral images were processed to\nisolate tomato canopy reflectance. At 897 GDD, broomrape could be detected with\n79.09 percent overall accuracy and 70.36 percent recall without integrating\nlater stages. Incorporating sequential growth stages with LSTM improved\ndetection substantially. The best-performing scenario, which integrated all\ngrowth stages with SMOTE augmentation, achieved 88.37 percent overall accuracy\nand 95.37 percent recall. These results demonstrate the strong potential of\ntemporal multispectral analysis and LSTM networks for early broomrape\ndetection. While further real-world data collection is needed for practical\ndeployment, this study shows that UAV-based multispectral sensing coupled with\ndeep learning could provide a powerful precision agriculture tool to reduce\nlosses and improve sustainability in tomato production.", "AI": {"tldr": "\u672c\u7814\u7a76\u7ed3\u5408\u65e0\u4eba\u673a\u591a\u5149\u8c31\u5f71\u50cf\u548cLSTM\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\uff0c\u4f7f\u7528SMOTE\u6280\u672f\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u756a\u8304\u5bc4\u751f\u690d\u7269\u5206\u679d\u5217\u5f53\u7684\u65e9\u671f\u68c0\u6d4b\uff0c\u6700\u9ad8\u51c6\u786e\u7387\u8fbe\u523088.37%\uff0c\u53ec\u56de\u7387\u8fbe\u523095.37%\u3002", "motivation": "\u5206\u679d\u5217\u5f53\u5bf9\u52a0\u5dde\u756a\u8304\u4ea7\u4e1a\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u5176\u5730\u4e0b\u751f\u547d\u5468\u671f\u4f7f\u5f97\u65e9\u671f\u68c0\u6d4b\u56f0\u96be\uff0c\u4f20\u7edf\u5316\u5b66\u63a7\u5236\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u73af\u5883\u6709\u5bb3\u4e14\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u68c0\u6d4b\u6280\u672f\u3002", "method": "\u5728\u5df2\u77e5\u611f\u67d3\u7684\u756a\u8304\u519c\u573a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4f7f\u7528\u65e0\u4eba\u673a\u91c7\u96c6\u591a\u5149\u8c31\u5f71\u50cf\uff0c\u901a\u8fc7\u751f\u957f\u5ea6\u65e5\u786e\u5b9a\u4e94\u4e2a\u5173\u952e\u751f\u957f\u9636\u6bb5\uff0c\u5229\u7528LSTM\u7f51\u7edc\u5904\u7406\u65f6\u5e8f\u6570\u636e\uff0c\u5e76\u91c7\u7528SMOTE\u6280\u672f\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "\u5728897\u751f\u957f\u5ea6\u65e5\u65f6\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe\u523079.09%\uff0c\u53ec\u56de\u738770.36%\uff1b\u6574\u5408\u6240\u6709\u751f\u957f\u9636\u6bb5\u5e76\u4f7f\u7528SMOTE\u540e\uff0c\u51c6\u786e\u7387\u63d0\u5347\u81f388.37%\uff0c\u53ec\u56de\u7387\u8fbe\u523095.37%\u3002", "conclusion": "\u65f6\u5e8f\u591a\u5149\u8c31\u5206\u6790\u548cLSTM\u7f51\u7edc\u5728\u65e9\u671f\u5217\u5f53\u68c0\u6d4b\u65b9\u9762\u5177\u6709\u5f3a\u5927\u6f5c\u529b\uff0c\u65e0\u4eba\u673a\u591a\u5149\u8c31\u4f20\u611f\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7ed3\u5408\u53ef\u4e3a\u7cbe\u51c6\u519c\u4e1a\u63d0\u4f9b\u6709\u529b\u5de5\u5177\uff0c\u51cf\u5c11\u635f\u5931\u5e76\u63d0\u9ad8\u756a\u8304\u751f\u4ea7\u7684\u53ef\u6301\u7eed\u6027\u3002"}}
{"id": "2509.10031", "pdf": "https://arxiv.org/pdf/2509.10031", "abs": "https://arxiv.org/abs/2509.10031", "authors": ["Peter Vieting", "Benedikt Hilmes", "Ralf Schl\u00fcter", "Hermann Ney"], "title": "Unified Learnable 2D Convolutional Feature Extraction for ASR", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "comment": "Accepted at ITG Conference on Speech Communication 2025", "summary": "Neural front-ends represent a promising approach to feature extraction for\nautomatic speech recognition (ASR) systems as they enable to learn specifically\ntailored features for different tasks. Yet, many of the existing techniques\nremain heavily influenced by classical methods. While this inductive bias may\nease the system design, our work aims to develop a more generic front-end for\nfeature extraction. Furthermore, we seek to unify the front-end architecture\ncontrasting with existing approaches that apply a composition of several layer\ntopologies originating from different sources. The experiments systematically\nshow how to reduce the influence of existing techniques to achieve a generic\nfront-end. The resulting 2D convolutional front-end is parameter-efficient and\nsuitable for a scenario with limited computational resources unlike large\nmodels pre-trained on unlabeled audio. The results demonstrate that this\ngeneric unified approach is not only feasible but also matches the performance\nof existing supervised learnable feature extractors.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u76842D\u5377\u79ef\u524d\u7aef\uff0c\u7528\u4e8e\u8bed\u97f3\u8bc6\u522b\u7279\u5f81\u63d0\u53d6\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u52a0\u901a\u7528\u548c\u7edf\u4e00\uff0c\u5728\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u6027\u80fd\u4e0e\u73b0\u6709\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u76f8\u5f53", "motivation": "\u73b0\u6709\u795e\u7ecf\u524d\u7aef\u65b9\u6cd5\u4ecd\u53d7\u4f20\u7edf\u65b9\u6cd5\u5f71\u54cd\u8f83\u5927\uff0c\u867d\u7136\u8fd9\u79cd\u5f52\u7eb3\u504f\u7f6e\u6709\u52a9\u4e8e\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u4f46\u4f5c\u8005\u5e0c\u671b\u5f00\u53d1\u66f4\u901a\u7528\u7684\u7279\u5f81\u63d0\u53d6\u524d\u7aef\uff0c\u5e76\u7edf\u4e00\u524d\u7aef\u67b6\u6784\uff08\u800c\u4e0d\u662f\u7ec4\u5408\u4e0d\u540c\u6765\u6e90\u7684\u5c42\u62d3\u6251\u7ed3\u6784\uff09", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e2D\u5377\u79ef\u7684\u901a\u7528\u7edf\u4e00\u524d\u7aef\u67b6\u6784\uff0c\u901a\u8fc7\u7cfb\u7edf\u5b9e\u9a8c\u51cf\u5c11\u73b0\u6709\u6280\u672f\u7684\u5f71\u54cd\uff0c\u5b9e\u73b0\u53c2\u6570\u9ad8\u6548\u7684\u8bbe\u8ba1", "result": "\u8be52D\u5377\u79ef\u524d\u7aef\u53c2\u6570\u9ad8\u6548\uff0c\u9002\u5408\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u7684\u573a\u666f\uff0c\u6027\u80fd\u4e0e\u73b0\u6709\u76d1\u7763\u5b66\u4e60\u7279\u5f81\u63d0\u53d6\u5668\u76f8\u5f53", "conclusion": "\u8fd9\u79cd\u901a\u7528\u7684\u7edf\u4e00\u65b9\u6cd5\u4e0d\u4ec5\u53ef\u884c\uff0c\u800c\u4e14\u80fd\u591f\u5339\u914d\u73b0\u6709\u76d1\u7763\u5b66\u4e60\u7279\u5f81\u63d0\u53d6\u5668\u7684\u6027\u80fd\uff0c\u4e3a\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u573a\u666f\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.10057", "pdf": "https://arxiv.org/pdf/2509.10057", "abs": "https://arxiv.org/abs/2509.10057", "authors": ["Jakub Mojsiejuk", "S\u0142awomir Zi\u0119tek", "Witold Skowro\u0144ski"], "title": "Reinforcement learning for spin torque oscillator tasks", "categories": ["physics.app-ph", "cs.AI", "cs.LG"], "comment": "3 figures, 6 pages", "summary": "We address the problem of automatic synchronisation of the spintronic\noscillator (STO) by means of reinforcement learning (RL). A numerical solution\nof the macrospin Landau-Lifschitz-Gilbert-Slonczewski equation is used to\nsimulate the STO and we train the two types of RL agents to synchronise with a\ntarget frequency within a fixed number of steps. We explore modifications to\nthis base task and show an improvement in both convergence and energy\nefficiency of the synchronisation that can be easily achieved in the simulated\nenvironment.", "AI": {"tldr": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u81ea\u52a8\u540c\u6b65\u81ea\u65cb\u7535\u5b50\u632f\u8361\u5668\uff0c\u901a\u8fc7\u8bad\u7ec3\u4e24\u79cdRL\u4ee3\u7406\u5728\u56fa\u5b9a\u6b65\u6570\u5185\u4e0e\u76ee\u6807\u9891\u7387\u540c\u6b65\uff0c\u5e76\u5c55\u793a\u4e86\u6536\u655b\u6027\u548c\u80fd\u91cf\u6548\u7387\u7684\u6539\u8fdb", "motivation": "\u89e3\u51b3\u81ea\u65cb\u7535\u5b50\u632f\u8361\u5668\u7684\u81ea\u52a8\u540c\u6b65\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u53ef\u80fd\u6548\u7387\u4e0d\u9ad8\uff0c\u5e0c\u671b\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u540c\u6b65\u63a7\u5236", "method": "\u4f7f\u7528\u5b8f\u81ea\u65cbLandau-Lifschitz-Gilbert-Slonczewski\u65b9\u7a0b\u6570\u503c\u89e3\u6a21\u62dfSTO\uff0c\u8bad\u7ec3\u4e24\u79cd\u7c7b\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u8fdb\u884c\u9891\u7387\u540c\u6b65", "result": "\u5728\u6a21\u62df\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u540c\u6b65\u6536\u655b\u6027\u548c\u80fd\u91cf\u6548\u7387\u7684\u6539\u8fdb\uff0c\u8bc1\u660e\u4e86\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728STO\u540c\u6b65\u4e2d\u7684\u6709\u6548\u6027", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u4e3a\u81ea\u65cb\u7535\u5b50\u632f\u8361\u5668\u7684\u81ea\u52a8\u540c\u6b65\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u80fd\u91cf\u6548\u7387\u66f4\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u6a21\u62df\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd"}}
{"id": "2509.10074", "pdf": "https://arxiv.org/pdf/2509.10074", "abs": "https://arxiv.org/abs/2509.10074", "authors": ["Christos Sgouropoulos", "Christos Nikou", "Stefanos Vlachos", "Vasileios Theiou", "Christos Foukanelis", "Theodoros Giannakopoulos"], "title": "Prototypical Contrastive Learning For Improved Few-Shot Audio Classification", "categories": ["cs.SD", "cs.LG"], "comment": "Accepted and Presented at IEEE International Workshop on Machine\n  Learning for Signal Processing, Aug.\\ 31-- Sep.\\ 3, 2025, Istanbul, Turkey ,\n  6 pages, 2 figures, 1 table", "summary": "Few-shot learning has emerged as a powerful paradigm for training models with\nlimited labeled data, addressing challenges in scenarios where large-scale\nannotation is impractical. While extensive research has been conducted in the\nimage domain, few-shot learning in audio classification remains relatively\nunderexplored. In this work, we investigate the effect of integrating\nsupervised contrastive loss into prototypical few shot training for audio\nclassification. In detail, we demonstrate that angular loss further improves\nthe performance compared to the standard contrastive loss. Our method leverages\nSpecAugment followed by a self-attention mechanism to encapsulate diverse\ninformation of augmented input versions into one unified embedding. We evaluate\nour approach on MetaAudio, a benchmark including five datasets with predefined\nsplits, standardized preprocessing, and a comprehensive set of few-shot\nlearning models for comparison. The proposed approach achieves state-of-the-art\nperformance in a 5-way, 5-shot setting.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u97f3\u9891\u5206\u7c7b\u7684\u5c11\u6837\u672c\u5b66\u4e60\u4e2d\u96c6\u6210\u76d1\u7763\u5bf9\u6bd4\u635f\u5931\u7684\u6548\u679c\uff0c\u63d0\u51fa\u4f7f\u7528\u89d2\u5ea6\u635f\u5931\u66ff\u4ee3\u6807\u51c6\u5bf9\u6bd4\u635f\u5931\uff0c\u7ed3\u5408SpecAugment\u548c\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728MetaAudio\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u5c11\u6837\u672c\u5b66\u4e60\u5728\u56fe\u50cf\u9886\u57df\u5df2\u6709\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5728\u97f3\u9891\u5206\u7c7b\u4e2d\u76f8\u5bf9\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u97f3\u9891\u5206\u7c7b\u4e2d\u6807\u6ce8\u6570\u636e\u6709\u9650\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u6539\u8fdb\u635f\u5931\u51fd\u6570\u6765\u63d0\u5347\u5c11\u6837\u672c\u5b66\u4e60\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u5c06\u76d1\u7763\u5bf9\u6bd4\u635f\u5931\u96c6\u6210\u5230\u539f\u578b\u5c11\u6837\u672c\u8bad\u7ec3\u4e2d\uff0c\u4f7f\u7528\u89d2\u5ea6\u635f\u5931\u66ff\u4ee3\u6807\u51c6\u5bf9\u6bd4\u635f\u5931\u3002\u65b9\u6cd5\u91c7\u7528SpecAugment\u8fdb\u884c\u6570\u636e\u589e\u5f3a\uff0c\u7136\u540e\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5c06\u589e\u5f3a\u8f93\u5165\u7248\u672c\u7684\u591a\u6837\u5316\u4fe1\u606f\u5c01\u88c5\u5230\u7edf\u4e00\u7684\u5d4c\u5165\u8868\u793a\u4e2d\u3002", "result": "\u5728\u5305\u542b\u4e94\u4e2a\u6570\u636e\u96c6\u7684MetaAudio\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u57285-way 5-shot\u8bbe\u7f6e\u4e0b\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u89d2\u5ea6\u635f\u5931\u76f8\u6bd4\u6807\u51c6\u5bf9\u6bd4\u635f\u5931\u7684\u6539\u8fdb\u6548\u679c\u3002", "conclusion": "\u96c6\u6210\u76d1\u7763\u5bf9\u6bd4\u635f\u5931\u7279\u522b\u662f\u89d2\u5ea6\u635f\u5931\uff0c\u7ed3\u5408SpecAugment\u548c\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u97f3\u9891\u5c11\u6837\u672c\u5206\u7c7b\u7684\u6027\u80fd\uff0c\u4e3a\u97f3\u9891\u9886\u57df\u7684\u5c11\u6837\u672c\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2509.10082", "pdf": "https://arxiv.org/pdf/2509.10082", "abs": "https://arxiv.org/abs/2509.10082", "authors": ["Weitao Tang", "Johann Vargas-Calixto", "Nasim Katebi", "Nhi Tran", "Sharmony B. Kelly", "Gari D. Clifford", "Robert Galinsky", "Faezeh Marzbanrad"], "title": "FetalSleepNet: A Transfer Learning Framework with Spectral Equalisation Domain Adaptation for Fetal Sleep Stage Classification", "categories": ["eess.SP", "cs.LG"], "comment": "13 pages, 4 tables, 5 figures, submitted to IEEE Journal of\n  Biomedical and Health Informatics", "summary": "Introduction: This study presents FetalSleepNet, the first published deep\nlearning approach to classifying sleep states from the ovine\nelectroencephalogram (EEG). Fetal EEG is complex to acquire and difficult and\nlaborious to interpret consistently. However, accurate sleep stage\nclassification may aid in the early detection of abnormal brain maturation\nassociated with pregnancy complications (e.g. hypoxia or intrauterine growth\nrestriction).\n  Methods: EEG electrodes were secured onto the ovine dura over the parietal\ncortices of 24 late gestation fetal sheep. A lightweight deep neural network\noriginally developed for adult EEG sleep staging was trained on the ovine EEG\nusing transfer learning from adult EEG. A spectral equalisation-based domain\nadaptation strategy was used to reduce cross-domain mismatch.\n  Results: We demonstrated that while direct transfer performed poorly, full\nfine tuning combined with spectral equalisation achieved the best overall\nperformance (accuracy: 86.6 percent, macro F1-score: 62.5), outperforming\nbaseline models.\n  Conclusions: To the best of our knowledge, FetalSleepNet is the first deep\nlearning framework specifically developed for automated sleep staging from the\nfetal EEG. Beyond the laboratory, the EEG-based sleep stage classifier\nfunctions as a label engine, enabling large scale weak/semi supervised labeling\nand distillation to facilitate training on less invasive signals that can be\nacquired in the clinic, such as Doppler Ultrasound or electrocardiogram data.\nFetalSleepNet's lightweight design makes it well suited for deployment in low\npower, real time, and wearable fetal monitoring systems.", "AI": {"tldr": "FetalSleepNet\u662f\u9996\u4e2a\u7528\u4e8e\u80ce\u513f\u7f8a\u8111\u7535\u56fe\u7761\u7720\u5206\u671f\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u548c\u9891\u8c31\u5747\u8861\u6280\u672f\uff0c\u5728\u80ce\u513fEEG\u6570\u636e\u4e0a\u5b9e\u73b0\u4e8686.6%\u7684\u51c6\u786e\u7387\uff0c\u4e3a\u80ce\u513f\u8111\u53d1\u80b2\u76d1\u6d4b\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u5de5\u5177\u3002", "motivation": "\u80ce\u513f\u8111\u7535\u56fe\u83b7\u53d6\u590d\u6742\u4e14\u89e3\u8bfb\u56f0\u96be\uff0c\u4f46\u51c6\u786e\u7684\u7761\u7720\u5206\u671f\u6709\u52a9\u4e8e\u65e9\u671f\u53d1\u73b0\u4e0e\u598a\u5a20\u5e76\u53d1\u75c7\u76f8\u5173\u7684\u5f02\u5e38\u8111\u6210\u719f\uff0c\u5982\u7f3a\u6c27\u6216\u5bab\u5185\u751f\u957f\u53d7\u9650\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u4ece\u6210\u4ebaEEG\u7684\u8fc1\u79fb\u5b66\u4e60\u8bad\u7ec3\u80ce\u513f\u7f8aEEG\u6570\u636e\uff0c\u91c7\u7528\u9891\u8c31\u5747\u8861\u57df\u9002\u5e94\u7b56\u7565\u51cf\u5c11\u8de8\u57df\u4e0d\u5339\u914d\u3002", "result": "\u5b8c\u5168\u5fae\u8c03\u7ed3\u5408\u9891\u8c31\u5747\u8861\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\uff08\u51c6\u786e\u738786.6%\uff0c\u5b8f\u89c2F1\u5206\u657062.5\uff09\uff0c\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "FetalSleepNet\u662f\u9996\u4e2a\u4e13\u95e8\u4e3a\u80ce\u513fEEG\u81ea\u52a8\u7761\u7720\u5206\u671f\u5f00\u53d1\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5176\u8f7b\u91cf\u8bbe\u8ba1\u9002\u5408\u4f4e\u529f\u8017\u5b9e\u65f6\u53ef\u7a7f\u6234\u80ce\u513f\u76d1\u6d4b\u7cfb\u7edf\u90e8\u7f72\uff0c\u53ef\u4f5c\u4e3a\u6807\u7b7e\u5f15\u64ce\u652f\u6301\u5927\u89c4\u6a21\u5f31/\u534a\u76d1\u7763\u6807\u6ce8\u3002"}}
{"id": "2509.10127", "pdf": "https://arxiv.org/pdf/2509.10127", "abs": "https://arxiv.org/abs/2509.10127", "authors": ["Zhengyu Hu", "Zheyuan Xiao", "Max Xiong", "Yuxuan Lei", "Tianfu Wang", "Jianxun Lian", "Kaize Ding", "Ziang Xiao", "Nicholas Jing Yuan", "Xing Xie"], "title": "Population-Aligned Persona Generation for LLM-based Social Simulation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled human-like\nsocial simulations at unprecedented scale and fidelity, offering new\nopportunities for computational social science. A key challenge, however, is\nthe construction of persona sets that authentically represent the diversity and\ndistribution of real-world populations. Most existing LLM-based social\nsimulation studies focus primarily on designing agentic frameworks and\nsimulation environments, often overlooking the complexities of persona\ngeneration and the potential biases introduced by unrepresentative persona\nsets. In this paper, we propose a systematic framework for synthesizing\nhigh-quality, population-aligned persona sets for LLM-driven social simulation.\nOur approach begins by leveraging LLMs to generate narrative personas from\nlong-term social media data, followed by rigorous quality assessment to filter\nout low-fidelity profiles. We then apply importance sampling to achieve global\nalignment with reference psychometric distributions, such as the Big Five\npersonality traits. To address the needs of specific simulation contexts, we\nfurther introduce a task-specific module that adapts the globally aligned\npersona set to targeted subpopulations. Extensive experiments demonstrate that\nour method significantly reduces population-level bias and enables accurate,\nflexible social simulation for a wide range of research and policy\napplications.", "AI": {"tldr": "\u63d0\u51fa\u7cfb\u7edf\u6846\u67b6\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u4e0e\u4eba\u53e3\u5206\u5e03\u5bf9\u9f50\u7684LLM\u793e\u4ea4\u6a21\u62df\u89d2\u8272\u96c6\uff0c\u901a\u8fc7\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u751f\u6210\u3001\u8d28\u91cf\u8bc4\u4f30\u3001\u91cd\u8981\u6027\u91c7\u6837\u548c\u5fc3\u7406\u6d4b\u91cf\u5206\u5e03\u5bf9\u9f50\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u53e3\u7ea7\u504f\u5dee", "motivation": "\u73b0\u6709LLM\u793e\u4ea4\u6a21\u62df\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4ee3\u7406\u6846\u67b6\u548c\u6a21\u62df\u73af\u5883\u8bbe\u8ba1\uff0c\u5ffd\u89c6\u4e86\u89d2\u8272\u751f\u6210\u7684\u590d\u6742\u6027\u4ee5\u53ca\u975e\u4ee3\u8868\u6027\u89d2\u8272\u96c6\u5f15\u5165\u7684\u6f5c\u5728\u504f\u5dee\uff0c\u9700\u8981\u6784\u5efa\u80fd\u771f\u5b9e\u53cd\u6620\u73b0\u5b9e\u4e16\u754c\u4eba\u53e3\u591a\u6837\u6027\u548c\u5206\u5e03\u7684\u89d2\u8272\u96c6", "method": "\u5229\u7528LLM\u4ece\u957f\u671f\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u751f\u6210\u53d9\u8ff0\u6027\u89d2\u8272\uff0c\u8fdb\u884c\u4e25\u683c\u8d28\u91cf\u8bc4\u4f30\u7b5b\u9009\u4f4e\u4fdd\u771f\u6863\u6848\uff0c\u5e94\u7528\u91cd\u8981\u6027\u91c7\u6837\u5b9e\u73b0\u4e0e\u53c2\u8003\u5fc3\u7406\u6d4b\u91cf\u5206\u5e03\uff08\u5982\u5927\u4e94\u4eba\u683c\u7279\u8d28\uff09\u7684\u5168\u5c40\u5bf9\u9f50\uff0c\u5e76\u5f15\u5165\u4efb\u52a1\u7279\u5b9a\u6a21\u5757\u9488\u5bf9\u76ee\u6807\u5b50\u7fa4\u4f53\u8fdb\u884c\u9002\u914d", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u53e3\u7ea7\u504f\u5dee\uff0c\u4e3a\u5e7f\u6cdb\u7684\u7814\u7a76\u548c\u653f\u7b56\u5e94\u7528\u5b9e\u73b0\u4e86\u51c6\u786e\u3001\u7075\u6d3b\u7684\u793e\u4ea4\u6a21\u62df", "conclusion": "\u63d0\u51fa\u7684\u7cfb\u7edf\u6846\u67b6\u80fd\u591f\u5408\u6210\u9ad8\u8d28\u91cf\u3001\u4e0e\u4eba\u53e3\u5206\u5e03\u5bf9\u9f50\u7684\u89d2\u8272\u96c6\uff0c\u89e3\u51b3\u4e86LLM\u9a71\u52a8\u793e\u4ea4\u6a21\u62df\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u53ef\u9760\u7684\u57fa\u7840"}}
{"id": "2509.10143", "pdf": "https://arxiv.org/pdf/2509.10143", "abs": "https://arxiv.org/abs/2509.10143", "authors": ["Peter Vieting", "Simon Berger", "Thilo von Neumann", "Christoph Boeddeker", "Ralf Schl\u00fcter", "Reinhold Haeb-Umbach"], "title": "Error Analysis in a Modular Meeting Transcription System", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "comment": "Accepted at ITG Conference on Speech Communication 2025", "summary": "Meeting transcription is a field of high relevance and remarkable progress in\nrecent years. Still, challenges remain that limit its performance. In this\nwork, we extend a previously proposed framework for analyzing leakage in speech\nseparation with proper sensitivity to temporal locality. We show that there is\nsignificant leakage to the cross channel in areas where only the primary\nspeaker is active. At the same time, the results demonstrate that this does not\naffect the final performance much as these leaked parts are largely ignored by\nthe voice activity detection (VAD). Furthermore, different segmentations are\ncompared showing that advanced diarization approaches are able to reduce the\ngap to oracle segmentation by a third compared to a simple energy-based VAD. We\nadditionally reveal what factors contribute to the remaining difference. The\nresults represent state-of-the-art performance on LibriCSS among systems that\ntrain the recognition module on LibriSpeech data only.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u4f1a\u8bae\u8f6c\u5f55\u4e2d\u8bed\u97f3\u5206\u79bb\u7684\u6cc4\u6f0f\u95ee\u9898\uff0c\u53d1\u73b0\u4ea4\u53c9\u901a\u9053\u5b58\u5728\u663e\u8457\u6cc4\u6f0f\u4f46\u88abVAD\u5ffd\u7565\uff0c\u9ad8\u7ea7\u4e8c\u503c\u5316\u65b9\u6cd5\u80fd\u5c06\u4e0eoracle\u5206\u5272\u7684\u5dee\u8ddd\u51cf\u5c11\u4e09\u5206\u4e4b\u4e00", "motivation": "\u4f1a\u8bae\u8f6c\u5f55\u9886\u57df\u8fd1\u5e74\u6765\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\u4f46\u4ecd\u5b58\u5728\u6027\u80fd\u9650\u5236\uff0c\u9700\u8981\u5206\u6790\u8bed\u97f3\u5206\u79bb\u4e2d\u7684\u6cc4\u6f0f\u95ee\u9898\u53ca\u5176\u5bf9\u6700\u7ec8\u6027\u80fd\u7684\u5f71\u54cd", "method": "\u6269\u5c55\u5148\u524d\u63d0\u51fa\u7684\u6cc4\u6f0f\u5206\u6790\u6846\u67b6\uff0c\u589e\u52a0\u5bf9\u65f6\u95f4\u5c40\u90e8\u6027\u7684\u654f\u611f\u6027\uff0c\u6bd4\u8f83\u4e0d\u540c\u5206\u5272\u65b9\u6cd5\uff08\u80fd\u91cf\u57faVAD\u4e0e\u9ad8\u7ea7\u4e8c\u503c\u5316\u65b9\u6cd5\uff09\uff0c\u5206\u6790\u6cc4\u6f0f\u5bf9\u6027\u80fd\u7684\u5f71\u54cd", "result": "\u53d1\u73b0\u5728\u4e3b\u8981\u8bf4\u8bdd\u4eba\u6d3b\u8dc3\u533a\u57df\u5b58\u5728\u663e\u8457\u7684\u4ea4\u53c9\u901a\u9053\u6cc4\u6f0f\uff0c\u4f46\u8fd9\u4e9b\u6cc4\u6f0f\u90e8\u5206\u88abVAD\u5ffd\u7565\u800c\u4e0d\u5f71\u54cd\u6700\u7ec8\u6027\u80fd\uff1b\u9ad8\u7ea7\u4e8c\u503c\u5316\u65b9\u6cd5\u76f8\u6bd4\u7b80\u5355\u80fd\u91cf\u57faVAD\u80fd\u5c06\u4e0eoracle\u5206\u5272\u7684\u5dee\u8ddd\u51cf\u5c11\u4e09\u5206\u4e4b\u4e00", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u8bed\u97f3\u5206\u79bb\u4e2d\u7684\u6cc4\u6f0f\u7279\u6027\u53ca\u5176\u5b9e\u9645\u5f71\u54cd\uff0c\u8bc1\u660e\u4e86\u9ad8\u7ea7\u4e8c\u503c\u5316\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5728\u4ec5\u4f7f\u7528LibriSpeech\u6570\u636e\u8bad\u7ec3\u7684\u7cfb\u7edf\u4e2d\u8fbe\u5230\u4e86LibriCSS\u4e0a\u7684\u6700\u5148\u8fdb\u6027\u80fd"}}
{"id": "2509.10166", "pdf": "https://arxiv.org/pdf/2509.10166", "abs": "https://arxiv.org/abs/2509.10166", "authors": ["Vladimir Petrovic", "R\u00e9mi Bardenet", "Agn\u00e8s Desolneux"], "title": "Repulsive Monte Carlo on the sphere for the sliced Wasserstein distance", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In this paper, we consider the problem of computing the integral of a\nfunction on the unit sphere, in any dimension, using Monte Carlo methods.\nAlthough the methods we present are general, our guiding thread is the sliced\nWasserstein distance between two measures on $\\mathbb{R}^d$, which is precisely\nan integral on the $d$-dimensional sphere. The sliced Wasserstein distance (SW)\nhas gained momentum in machine learning either as a proxy to the less\ncomputationally tractable Wasserstein distance, or as a distance in its own\nright, due in particular to its built-in alleviation of the curse of\ndimensionality. There has been recent numerical benchmarks of quadratures for\nthe sliced Wasserstein, and our viewpoint differs in that we concentrate on\nquadratures where the nodes are repulsive, i.e. negatively dependent. Indeed,\nnegative dependence can bring variance reduction when the quadrature is adapted\nto the integration task. Our first contribution is to extract and motivate\nquadratures from the recent literature on determinantal point processes (DPPs)\nand repelled point processes, as well as repulsive quadratures from the\nliterature specific to the sliced Wasserstein distance. We then numerically\nbenchmark these quadratures. Moreover, we analyze the variance of the UnifOrtho\nestimator, an orthogonal Monte Carlo estimator. Our analysis sheds light on\nUnifOrtho's success for the estimation of the sliced Wasserstein in large\ndimensions, as well as counterexamples from the literature. Our final\nrecommendation for the computation of the sliced Wasserstein distance is to use\nrandomized quasi-Monte Carlo in low dimensions and \\emph{UnifOrtho} in large\ndimensions. DPP-based quadratures only shine when quasi-Monte Carlo also does,\nwhile repelled quadratures show moderate variance reduction in general, but\nmore theoretical effort is needed to make them robust.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u4efb\u610f\u7ef4\u5ea6\u4e0b\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u8ba1\u7b97\u5355\u4f4d\u7403\u9762\u4e0a\u51fd\u6570\u79ef\u5206\u7684\u95ee\u9898\uff0c\u7279\u522b\u5173\u6ce8\u5207\u7247Wasserstein\u8ddd\u79bb\u7684\u8ba1\u7b97\u3002\u901a\u8fc7\u5206\u6790\u5404\u79cd\u6392\u65a5\u6027\u8282\u70b9\u79ef\u5206\u65b9\u6cd5\uff0c\u63a8\u8350\u5728\u4f4e\u7ef4\u4f7f\u7528\u968f\u673a\u62df\u8499\u7279\u5361\u6d1b\uff0c\u9ad8\u7ef4\u4f7f\u7528UnifOrtho\u4f30\u8ba1\u5668\u3002", "motivation": "\u5207\u7247Wasserstein\u8ddd\u79bb\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u4f5c\u4e3aWasserstein\u8ddd\u79bb\u7684\u66ff\u4ee3\u6216\u72ec\u7acb\u8ddd\u79bb\u5ea6\u91cf\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u73b0\u6709\u6570\u503c\u79ef\u5206\u65b9\u6cd5\u5728\u65b9\u5dee\u51cf\u5c11\u65b9\u9762\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u4f7f\u7528\u6392\u65a5\u6027\u8282\u70b9\uff08\u8d1f\u76f8\u5173\uff09\u7684\u79ef\u5206\u65b9\u6cd5\u6765\u5b9e\u73b0\u65b9\u5dee\u51cf\u5c11\u3002", "method": "\u4ece\u786e\u5b9a\u6027\u70b9\u8fc7\u7a0b(DPPs)\u548c\u6392\u65a5\u70b9\u8fc7\u7a0b\u6587\u732e\u4e2d\u63d0\u53d6\u79ef\u5206\u65b9\u6cd5\uff0c\u5206\u6790UnifOrtho\u4f30\u8ba1\u5668\u7684\u65b9\u5dee\u7279\u6027\uff0c\u5e76\u5bf9\u5404\u79cd\u79ef\u5206\u65b9\u6cd5\u8fdb\u884c\u6570\u503c\u57fa\u51c6\u6d4b\u8bd5\u6bd4\u8f83\u3002", "result": "\u7814\u7a76\u53d1\u73b0UnifOrtho\u4f30\u8ba1\u5668\u5728\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u968f\u673a\u62df\u8499\u7279\u5361\u6d1b\u5728\u4f4e\u7ef4\u6548\u679c\u6700\u597d\u3002DPP-based\u79ef\u5206\u65b9\u6cd5\u4ec5\u5728\u62df\u8499\u7279\u5361\u6d1b\u6709\u6548\u65f6\u8868\u73b0\u826f\u597d\uff0c\u800c\u6392\u65a5\u6027\u79ef\u5206\u65b9\u6cd5\u603b\u4f53\u4e0a\u663e\u793a\u51fa\u9002\u5ea6\u7684\u65b9\u5dee\u51cf\u5c11\u3002", "conclusion": "\u63a8\u8350\u8ba1\u7b97\u5207\u7247Wasserstein\u8ddd\u79bb\u65f6\uff0c\u4f4e\u7ef4\u4f7f\u7528\u968f\u673a\u62df\u8499\u7279\u5361\u6d1b\uff0c\u9ad8\u7ef4\u4f7f\u7528UnifOrtho\u65b9\u6cd5\u3002\u6392\u65a5\u6027\u79ef\u5206\u65b9\u6cd5\u9700\u8981\u66f4\u591a\u7406\u8bba\u7814\u7a76\u6765\u63d0\u9ad8\u5176\u9c81\u68d2\u6027\u3002"}}
{"id": "2509.10206", "pdf": "https://arxiv.org/pdf/2509.10206", "abs": "https://arxiv.org/abs/2509.10206", "authors": ["Federica Uccello", "Simin Nadjm-Tehrani"], "title": "Investigating Feature Attribution for 5G Network Intrusion Detection", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "With the rise of fifth-generation (5G) networks in critical applications, it\nis urgent to move from detection of malicious activity to systems capable of\nproviding a reliable verdict suitable for mitigation. In this regard,\nunderstanding and interpreting machine learning (ML) models' security alerts is\ncrucial for enabling actionable incident response orchestration. Explainable\nArtificial Intelligence (XAI) techniques are expected to enhance trust by\nproviding insights into why alerts are raised. A dominant approach\nstatistically associates feature sets that can be correlated to a given alert.\nThis paper starts by questioning whether such attribution is relevant for\nfuture generation communication systems, and investigates its merits in\ncomparison with an approach based on logical explanations. We extensively study\ntwo methods, SHAP and VoTE-XAI, by analyzing their interpretations of alerts\ngenerated by an XGBoost model in three different use cases with several 5G\ncommunication attacks. We identify three metrics for assessing explanations:\nsparsity, how concise they are; stability, how consistent they are across\nsamples from the same attack type; and efficiency, how fast an explanation is\ngenerated. As an example, in a 5G network with 92 features, 6 were deemed\nimportant by VoTE-XAI for a Denial of Service (DoS) variant, ICMPFlood, while\nSHAP identified over 20. More importantly, we found a significant divergence\nbetween features selected by SHAP and VoTE-XAI. However, none of the top-ranked\nfeatures selected by SHAP were missed by VoTE-XAI. When it comes to efficiency\nof providing interpretations, we found that VoTE-XAI is significantly more\nresponsive, e.g. it provides a single explanation in under 0.002 seconds, in a\nhigh-dimensional setting (478 features).", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86SHAP\u548cVoTE-XAI\u4e24\u79cd\u53ef\u89e3\u91caAI\u65b9\u6cd5\u57285G\u7f51\u7edc\u5b89\u5168\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0VoTE-XAI\u5728\u7a00\u758f\u6027\u3001\u7a33\u5b9a\u6027\u548c\u6548\u7387\u65b9\u9762\u4f18\u4e8eSHAP\uff0c\u80fd\u63d0\u4f9b\u66f4\u7b80\u6d01\u4e14\u4e00\u81f4\u7684\u653b\u51fb\u89e3\u91ca\u3002", "motivation": "\u968f\u77405G\u7f51\u7edc\u5728\u5173\u952e\u5e94\u7528\u4e2d\u7684\u666e\u53ca\uff0c\u9700\u8981\u4ece\u6076\u610f\u6d3b\u52a8\u68c0\u6d4b\u8f6c\u5411\u80fd\u591f\u63d0\u4f9b\u53ef\u9760\u5224\u51b3\u7684\u7cfb\u7edf\u3002\u7406\u89e3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u5b89\u5168\u8b66\u62a5\u5bf9\u4e8e\u5b9e\u73b0\u53ef\u64cd\u4f5c\u7684\u4e8b\u4ef6\u54cd\u5e94\u7f16\u6392\u81f3\u5173\u91cd\u8981\uff0c\u53ef\u89e3\u91caAI\u6280\u672f\u901a\u8fc7\u63d0\u4f9b\u8b66\u62a5\u539f\u56e0\u6765\u589e\u5f3a\u4fe1\u4efb\u3002", "method": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4e24\u79cdXAI\u65b9\u6cd5\uff1aSHAP\uff08\u57fa\u4e8e\u7edf\u8ba1\u7279\u5f81\u5173\u8054\uff09\u548cVoTE-XAI\uff08\u57fa\u4e8e\u903b\u8f91\u89e3\u91ca\uff09\u3002\u5728\u4e09\u4e2a\u4e0d\u540c\u7528\u4f8b\u4e2d\u5206\u6790\u5b83\u4eec\u5bf9XGBoost\u6a21\u578b\u751f\u6210\u76845G\u901a\u4fe1\u653b\u51fb\u8b66\u62a5\u7684\u89e3\u91ca\uff0c\u4f7f\u7528\u7a00\u758f\u6027\u3001\u7a33\u5b9a\u6027\u548c\u6548\u7387\u4e09\u4e2a\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u572892\u4e2a\u7279\u5f81\u76845G\u7f51\u7edc\u4e2d\uff0cVoTE-XAI\u5bf9ICMPFlood DoS\u653b\u51fb\u4ec5\u8bc6\u522b6\u4e2a\u91cd\u8981\u7279\u5f81\uff0c\u800cSHAP\u8bc6\u522b\u8d85\u8fc720\u4e2a\u3002\u4e24\u79cd\u65b9\u6cd5\u9009\u62e9\u7684\u7279\u5f81\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u4f46VoTE-XAI\u6ca1\u6709\u9057\u6f0fSHAP\u6392\u540d\u9760\u524d\u7684\u7279\u5f81\u3002VoTE-XAI\u5728\u9ad8\u6548\u6027\u65b9\u9762\u660e\u663e\u66f4\u4f18\uff0c\u5728478\u7ef4\u9ad8\u7ef4\u8bbe\u7f6e\u4e0b\u80fd\u57280.002\u79d2\u5185\u63d0\u4f9b\u5355\u4e2a\u89e3\u91ca\u3002", "conclusion": "\u57fa\u4e8e\u903b\u8f91\u89e3\u91ca\u7684VoTE-XAI\u65b9\u6cd5\u5728\u63d0\u4f9b\u7b80\u6d01\u3001\u7a33\u5b9a\u548c\u9ad8\u6548\u7684\u7f51\u7edc\u5b89\u5168\u8b66\u62a5\u89e3\u91ca\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u7684\u7edf\u8ba1\u5173\u8054\u65b9\u6cd5SHAP\uff0c\u66f4\u9002\u5408\u4e0b\u4e00\u4ee3\u901a\u4fe1\u7cfb\u7edf\u7684\u5b89\u5168\u9700\u6c42\u3002"}}
{"id": "2509.10245", "pdf": "https://arxiv.org/pdf/2509.10245", "abs": "https://arxiv.org/abs/2509.10245", "authors": ["Irina Ar\u00e9valo", "Jose L Salmeron"], "title": "Model-agnostic post-hoc explainability for recommender systems", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Recommender systems often benefit from complex feature embeddings and deep\nlearning algorithms, which deliver sophisticated recommendations that enhance\nuser experience, engagement, and revenue. However, these methods frequently\nreduce the interpretability and transparency of the system. In this research,\nwe develop a systematic application, adaptation, and evaluation of deletion\ndiagnostics in the recommender setting. The method compares the performance of\na model to that of a similar model trained without a specific user or item,\nallowing us to quantify how that observation influences the recommender, either\npositively or negatively. To demonstrate its model-agnostic nature, the\nproposal is applied to both Neural Collaborative Filtering (NCF), a widely used\ndeep learning-based recommender, and Singular Value Decomposition (SVD), a\nclassical collaborative filtering technique. Experiments on the MovieLens and\nAmazon Reviews datasets provide insights into model behavior and highlight the\ngenerality of the approach across different recommendation paradigms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5220\u9664\u8bca\u65ad\u7684\u63a8\u8350\u7cfb\u7edf\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u6bd4\u8f83\u5b8c\u6574\u6a21\u578b\u4e0e\u53bb\u9664\u7279\u5b9a\u7528\u6237/\u7269\u54c1\u540e\u6a21\u578b\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u91cf\u5316\u5355\u4e2a\u89c2\u6d4b\u5bf9\u63a8\u8350\u7cfb\u7edf\u7684\u5f71\u54cd\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u63a8\u8350\u7cfb\u7edf\u867d\u7136\u6027\u80fd\u4f18\u8d8a\u4f46\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u8981\u5f00\u53d1\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u4f7f\u7528\u5220\u9664\u8bca\u65ad\u6280\u672f\uff0c\u8bad\u7ec3\u5b8c\u6574\u6a21\u578b\u548c\u53bb\u9664\u7279\u5b9a\u7528\u6237/\u7269\u54c1\u7684\u5bf9\u6bd4\u6a21\u578b\uff0c\u901a\u8fc7\u6027\u80fd\u5dee\u5f02\u91cf\u5316\u5355\u4e2a\u89c2\u6d4b\u7684\u5f71\u54cd\u3002\u5728NCF\u548cSVD\u4e24\u79cd\u63a8\u8350\u6a21\u578b\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5728MovieLens\u548cAmazon Reviews\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63ed\u793a\u6a21\u578b\u884c\u4e3a\uff0c\u4e14\u9002\u7528\u4e8e\u4e0d\u540c\u63a8\u8350\u8303\u5f0f\uff0c\u5177\u6709\u5f88\u597d\u7684\u901a\u7528\u6027\u3002", "conclusion": "\u5220\u9664\u8bca\u65ad\u662f\u4e00\u79cd\u6709\u6548\u7684\u6a21\u578b\u65e0\u5173\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u80fd\u591f\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u9002\u7528\u4e8e\u6df1\u5ea6\u5b66\u4e60\u548c\u4f20\u7edf\u63a8\u8350\u6a21\u578b\u3002"}}
{"id": "2509.10282", "pdf": "https://arxiv.org/pdf/2509.10282", "abs": "https://arxiv.org/abs/2509.10282", "authors": ["Gang Li", "Tianjiao Chen", "Mingle Zhou", "Min Li", "Delong Han", "Jin Wan"], "title": "MCL-AD: Multimodal Collaboration Learning for Zero-Shot 3D Anomaly Detection", "categories": ["cs.CV", "cs.LG"], "comment": "Page 14, 5 pictures", "summary": "Zero-shot 3D (ZS-3D) anomaly detection aims to identify defects in 3D objects\nwithout relying on labeled training data, making it especially valuable in\nscenarios constrained by data scarcity, privacy, or high annotation cost.\nHowever, most existing methods focus exclusively on point clouds, neglecting\nthe rich semantic cues available from complementary modalities such as RGB\nimages and texts priors. This paper introduces MCL-AD, a novel framework that\nleverages multimodal collaboration learning across point clouds, RGB images,\nand texts semantics to achieve superior zero-shot 3D anomaly detection.\nSpecifically, we propose a Multimodal Prompt Learning Mechanism (MPLM) that\nenhances the intra-modal representation capability and inter-modal\ncollaborative learning by introducing an object-agnostic decoupled text prompt\nand a multimodal contrastive loss. In addition, a collaborative modulation\nmechanism (CMM) is proposed to fully leverage the complementary representations\nof point clouds and RGB images by jointly modulating the RGB image-guided and\npoint cloud-guided branches. Extensive experiments demonstrate that the\nproposed MCL-AD framework achieves state-of-the-art performance in ZS-3D\nanomaly detection.", "AI": {"tldr": "MCL-AD\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u6a21\u6001\u534f\u4f5c\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u70b9\u4e91\u3001RGB\u56fe\u50cf\u548c\u6587\u672c\u8bed\u4e49\uff0c\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u96f6\u6837\u672c3D\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u96f6\u6837\u672c3D\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u70b9\u4e91\u6570\u636e\uff0c\u5ffd\u7565\u4e86RGB\u56fe\u50cf\u548c\u6587\u672c\u5148\u9a8c\u7b49\u4e92\u8865\u6a21\u6001\u63d0\u4f9b\u7684\u4e30\u5bcc\u8bed\u4e49\u7ebf\u7d22\u3002\u4e3a\u4e86\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u3001\u9690\u79c1\u548c\u9ad8\u6807\u6ce8\u6210\u672c\u7b49\u7ea6\u675f\u573a\u666f\u4e0b\u7684\u7f3a\u9677\u68c0\u6d4b\u95ee\u9898\uff0c\u9700\u8981\u5145\u5206\u5229\u7528\u591a\u6a21\u6001\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86\u591a\u6a21\u6001\u63d0\u793a\u5b66\u4e60\u673a\u5236(MPLM)\uff0c\u901a\u8fc7\u5bf9\u8c61\u65e0\u5173\u7684\u89e3\u8026\u6587\u672c\u63d0\u793a\u548c\u591a\u6a21\u6001\u5bf9\u6bd4\u635f\u5931\u589e\u5f3a\u6a21\u6001\u5185\u8868\u793a\u80fd\u529b\u548c\u6a21\u6001\u95f4\u534f\u4f5c\u5b66\u4e60\uff1b\u8bbe\u8ba1\u4e86\u534f\u4f5c\u8c03\u5236\u673a\u5236(CMM)\uff0c\u901a\u8fc7\u8054\u5408\u8c03\u5236RGB\u56fe\u50cf\u5f15\u5bfc\u548c\u70b9\u4e91\u5f15\u5bfc\u5206\u652f\u6765\u5145\u5206\u5229\u7528\u70b9\u4e91\u548cRGB\u56fe\u50cf\u7684\u4e92\u8865\u8868\u793a\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\uff0cMCL-AD\u6846\u67b6\u5728\u96f6\u6837\u672c3D\u5f02\u5e38\u68c0\u6d4b\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u591a\u6a21\u6001\u534f\u4f5c\u5b66\u4e60\uff0cMCL-AD\u6846\u67b6\u80fd\u591f\u6709\u6548\u6574\u5408\u70b9\u4e91\u3001RGB\u56fe\u50cf\u548c\u6587\u672c\u8bed\u4e49\u4fe1\u606f\uff0c\u5728\u96f6\u6837\u672c3D\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u8868\u73b0\uff0c\u4e3a\u89e3\u51b3\u6570\u636e\u7ea6\u675f\u573a\u666f\u4e0b\u7684\u7f3a\u9677\u68c0\u6d4b\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10317", "pdf": "https://arxiv.org/pdf/2509.10317", "abs": "https://arxiv.org/abs/2509.10317", "authors": ["Elizaveta D. Moskovskaya", "Anton D. Moscowsky"], "title": "Robot guide with multi-agent control and automatic scenario generation with LLM", "categories": ["cs.RO", "cs.LG", "93C85", "I.2.9; I.2.7; I.2.11"], "comment": "14 pages, 5 figures, 2 tables, 1 demo-video and repository link", "summary": "The work describes the development of a hybrid control architecture for an\nanthropomorphic tour guide robot, combining a multi-agent resource management\nsystem with automatic behavior scenario generation based on large language\nmodels. The proposed approach aims to overcome the limitations of traditional\nsystems, which rely on manual tuning of behavior scenarios. These limitations\ninclude manual configuration, low flexibility, and lack of naturalness in robot\nbehavior. The process of preparing tour scenarios is implemented through a\ntwo-stage generation: first, a stylized narrative is created, then non-verbal\naction tags are integrated into the text. The multi-agent system ensures\ncoordination and conflict resolution during the execution of parallel actions,\nas well as maintaining default behavior after the completion of main\noperations, contributing to more natural robot behavior. The results obtained\nfrom the trial demonstrate the potential of the proposed approach for\nautomating and scaling social robot control systems.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u8d44\u6e90\u7ba1\u7406\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u884c\u4e3a\u573a\u666f\u7684\u6df7\u5408\u63a7\u5236\u67b6\u6784\uff0c\u7528\u4e8e\u4eba\u5f62\u5bfc\u89c8\u673a\u5668\u4eba\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u7cfb\u7edf\u624b\u52a8\u914d\u7f6e\u3001\u7075\u6d3b\u6027\u5dee\u548c\u884c\u4e3a\u4e0d\u81ea\u7136\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u5bfc\u89c8\u673a\u5668\u4eba\u7cfb\u7edf\u4f9d\u8d56\u624b\u52a8\u8c03\u6574\u884c\u4e3a\u573a\u666f\uff0c\u5b58\u5728\u914d\u7f6e\u7e41\u7410\u3001\u7075\u6d3b\u6027\u4f4e\u548c\u673a\u5668\u4eba\u884c\u4e3a\u4e0d\u591f\u81ea\u7136\u7b49\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u81ea\u52a8\u5316\u548c\u81ea\u7136\u7684\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u751f\u6210\u8fc7\u7a0b\uff1a\u9996\u5148\u751f\u6210\u98ce\u683c\u5316\u53d9\u8ff0\u6587\u672c\uff0c\u7136\u540e\u6574\u5408\u975e\u8bed\u8a00\u52a8\u4f5c\u6807\u7b7e\uff1b\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u534f\u8c03\u5e76\u884c\u52a8\u4f5c\u6267\u884c\u548c\u51b2\u7a81\u89e3\u51b3\uff0c\u5e76\u5728\u4e3b\u8981\u64cd\u4f5c\u5b8c\u6210\u540e\u7ef4\u6301\u9ed8\u8ba4\u884c\u4e3a\u3002", "result": "\u8bd5\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u81ea\u52a8\u5316\u548c\u793e\u4f1a\u673a\u5668\u4eba\u63a7\u5236\u7cfb\u7edf\u6269\u5c55\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u591f\u5b9e\u73b0\u66f4\u81ea\u7136\u7684\u673a\u5668\u4eba\u884c\u4e3a\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u63a7\u5236\u67b6\u6784\u6210\u529f\u514b\u670d\u4e86\u4f20\u7edf\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u793e\u4ea4\u673a\u5668\u4eba\u63a7\u5236\u7684\u81ea\u52a8\u5316\u548c\u89c4\u6a21\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10334", "pdf": "https://arxiv.org/pdf/2509.10334", "abs": "https://arxiv.org/abs/2509.10334", "authors": ["Jordan Sassoon", "Michal Szczepanski", "Martyna Poreba"], "title": "I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Vision Transformers (ViTs) have recently achieved strong results in semantic\nsegmentation, yet their deployment on resource-constrained devices remains\nlimited due to their high memory footprint and computational cost. Quantization\noffers an effective strategy to improve efficiency, but ViT-based segmentation\nmodels are notoriously fragile under low precision, as quantization errors\naccumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the\nfirst fully integer-only ViT segmentation framework. Building on the Segmenter\narchitecture, I-Segmenter systematically replaces floating-point operations\nwith integer-only counterparts. To further stabilize both training and\ninference, we propose $\\lambda$-ShiftGELU, a novel activation function that\nmitigates the limitations of uniform quantization in handling long-tailed\nactivation distributions. In addition, we remove the L2 normalization layer and\nreplace bilinear interpolation in the decoder with nearest neighbor upsampling,\nensuring integer-only execution throughout the computational graph. Extensive\nexperiments show that I-Segmenter achieves accuracy within a reasonable margin\nof its FP32 baseline (5.1 % on average), while reducing model size by up to\n3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably,\neven in one-shot PTQ with a single calibration image, I-Segmenter delivers\ncompetitive accuracy, underscoring its practicality for real-world deployment.", "AI": {"tldr": "I-Segmenter\u662f\u9996\u4e2a\u5b8c\u5168\u6574\u6570\u5316\u7684ViT\u5206\u5272\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u66ff\u6362\u6d6e\u70b9\u8fd0\u7b97\u3001\u63d0\u51fa\u65b0\u6fc0\u6d3b\u51fd\u6570\u03bb-ShiftGELU\u3001\u79fb\u9664L2\u5f52\u4e00\u5316\u5c42\u548c\u4f7f\u7528\u6700\u8fd1\u90bb\u4e0a\u91c7\u6837\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u6a21\u578b\u5927\u5c0f\u548c\u63d0\u5347\u63a8\u7406\u901f\u5ea6\u3002", "motivation": "Vision Transformers\u5728\u8bed\u4e49\u5206\u5272\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u7531\u4e8e\u9ad8\u5185\u5b58\u5360\u7528\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u90e8\u7f72\u53d7\u9650\u3002\u91cf\u5316\u867d\u80fd\u63d0\u5347\u6548\u7387\uff0c\u4f46ViT\u5206\u5272\u6a21\u578b\u5728\u4f4e\u7cbe\u5ea6\u4e0b\u8868\u73b0\u8106\u5f31\uff0c\u91cf\u5316\u8bef\u5dee\u5728\u6df1\u5ea6\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7ba1\u9053\u4e2d\u7d2f\u79ef\u3002", "method": "\u57fa\u4e8eSegmenter\u67b6\u6784\uff0c\u7cfb\u7edf\u66ff\u6362\u6d6e\u70b9\u8fd0\u7b97\u4e3a\u6574\u6570\u8fd0\u7b97\uff1b\u63d0\u51fa\u03bb-ShiftGELU\u6fc0\u6d3b\u51fd\u6570\u5904\u7406\u957f\u5c3e\u6fc0\u6d3b\u5206\u5e03\uff1b\u79fb\u9664L2\u5f52\u4e00\u5316\u5c42\uff1b\u5c06\u89e3\u7801\u5668\u4e2d\u7684\u53cc\u7ebf\u6027\u63d2\u503c\u66ff\u6362\u4e3a\u6700\u8fd1\u90bb\u4e0a\u91c7\u6837\u3002", "result": "I-Segmenter\u5728\u7cbe\u5ea6\u4e0a\u4e0eFP32\u57fa\u7ebf\u76f8\u5dee\u5e73\u57475.1%\uff0c\u6a21\u578b\u5927\u5c0f\u51cf\u5c11\u8fbe3.8\u500d\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u8fbe1.2\u500d\u3002\u5373\u4f7f\u5728\u5355\u5f20\u6821\u51c6\u56fe\u50cf\u7684\u4e00\u6b21\u6027PTQ\u4e0b\u4e5f\u80fd\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "I-Segmenter\u662f\u9996\u4e2a\u5b8c\u5168\u6574\u6570\u5316\u7684ViT\u5206\u5272\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u4f18\u5316\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6574\u6570\u8ba1\u7b97\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10337", "pdf": "https://arxiv.org/pdf/2509.10337", "abs": "https://arxiv.org/abs/2509.10337", "authors": ["Nil Ayday", "Mahalakshmi Sabanayagam", "Debarghya Ghoshdastidar"], "title": "Why does your graph neural network fail on some graphs? Insights from exact generalisation error", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) are widely used in learning on graph-structured\ndata, yet a principled understanding of why they succeed or fail remains\nelusive. While prior works have examined architectural limitations such as\nover-smoothing and over-squashing, these do not explain what enables GNNs to\nextract meaningful representations or why performance varies drastically\nbetween similar architectures. These questions are related to the role of\ngeneralisation: the ability of a model to make accurate predictions on\nunlabelled data. Although several works have derived generalisation error\nbounds for GNNs, these are typically loose, restricted to a single\narchitecture, and offer limited insight into what governs generalisation in\npractice. In this work, we take a different approach by deriving the exact\ngeneralisation error for GNNs in a transductive fixed-design setting through\nthe lens of signal processing. From this viewpoint, GNNs can be interpreted as\ngraph filter operators that act on node features via the graph structure. By\nfocusing on linear GNNs while allowing non-linearity in the graph filters, we\nderive the first exact generalisation error for a broad range of GNNs,\nincluding convolutional, PageRank-based, and attention-based models. The exact\ncharacterisation of the generalisation error reveals that only the aligned\ninformation between node features and graph structure contributes to\ngeneralisation. Furthermore, we quantify the effect of homophily on\ngeneralisation. Our work provides a framework that explains when and why GNNs\ncan effectively leverage structural and feature information, offering practical\nguidance for model selection.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u4fe1\u53f7\u5904\u7406\u89c6\u89d2\u63a8\u5bfc\u51fa\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u8f6c\u5bfc\u56fa\u5b9a\u8bbe\u8ba1\u8bbe\u7f6e\u4e0b\u7684\u7cbe\u786e\u6cdb\u5316\u8bef\u5dee\uff0c\u63ed\u793a\u4e86\u53ea\u6709\u8282\u70b9\u7279\u5f81\u4e0e\u56fe\u7ed3\u6784\u5bf9\u9f50\u7684\u4fe1\u606f\u624d\u6709\u52a9\u4e8e\u6cdb\u5316\uff0c\u5e76\u91cf\u5316\u4e86\u540c\u914d\u6027\u5bf9\u6cdb\u5316\u7684\u5f71\u54cd\u3002", "motivation": "\u867d\u7136GNN\u5728\u56fe\u7ed3\u6784\u6570\u636e\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5bf9\u5176\u6210\u529f\u6216\u5931\u8d25\u7684\u7406\u8bba\u7406\u89e3\u4ecd\u4e0d\u6e05\u6670\u3002\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u67b6\u6784\u9650\u5236\uff08\u5982\u8fc7\u5e73\u6ed1\u548c\u8fc7\u6324\u538b\uff09\uff0c\u4f46\u65e0\u6cd5\u89e3\u91caGNN\u5982\u4f55\u63d0\u53d6\u6709\u610f\u4e49\u7684\u8868\u793a\u6216\u4e3a\u4f55\u76f8\u4f3c\u67b6\u6784\u95f4\u6027\u80fd\u5dee\u5f02\u5de8\u5927\uff0c\u8fd9\u6d89\u53ca\u5230\u6cdb\u5316\u80fd\u529b\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4fe1\u53f7\u5904\u7406\u89c6\u89d2\uff0c\u5c06GNN\u89e3\u91ca\u4e3a\u901a\u8fc7\u56fe\u7ed3\u6784\u5bf9\u8282\u70b9\u7279\u5f81\u8fdb\u884c\u64cd\u4f5c\u7684\u56fe\u6ee4\u6ce2\u5668\u3002\u5728\u7ebf\u6027GNN\u6846\u67b6\u4e0b\u5141\u8bb8\u56fe\u6ee4\u6ce2\u5668\u7684\u975e\u7ebf\u6027\uff0c\u63a8\u5bfc\u51fa\u5305\u62ec\u5377\u79ef\u3001PageRank\u548c\u6ce8\u610f\u529b\u6a21\u578b\u5728\u5185\u7684\u591a\u79cdGNN\u7684\u7cbe\u786e\u6cdb\u5316\u8bef\u5dee\u3002", "result": "\u7cbe\u786e\u6cdb\u5316\u8bef\u5dee\u8868\u5f81\u663e\u793a\uff0c\u53ea\u6709\u8282\u70b9\u7279\u5f81\u4e0e\u56fe\u7ed3\u6784\u5bf9\u9f50\u7684\u4fe1\u606f\u5bf9\u6cdb\u5316\u6709\u8d21\u732e\u3002\u91cf\u5316\u4e86\u540c\u914d\u6027\u5bf9\u6cdb\u5316\u7684\u5f71\u54cd\uff0c\u4e3a\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u6846\u67b6\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u89e3\u91caGNN\u4f55\u65f6\u4ee5\u53ca\u4e3a\u4f55\u80fd\u6709\u6548\u5229\u7528\u7ed3\u6784\u548c\u7279\u5f81\u4fe1\u606f\u7684\u7406\u8bba\u6846\u67b6\uff0c\u586b\u8865\u4e86GNN\u6cdb\u5316\u7406\u8bba\u7406\u89e3\u7684\u7a7a\u767d\uff0c\u5bf9\u5b9e\u9645\u6a21\u578b\u9009\u62e9\u5177\u6709\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2509.10344", "pdf": "https://arxiv.org/pdf/2509.10344", "abs": "https://arxiv.org/abs/2509.10344", "authors": ["Yuexi Du", "Lihui Chen", "Nicha C. Dvornek"], "title": "GLAM: Geometry-Guided Local Alignment for Multi-View VLP in Mammography", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by MICCAI 2025", "summary": "Mammography screening is an essential tool for early detection of breast\ncancer. The speed and accuracy of mammography interpretation have the potential\nto be improved with deep learning methods. However, the development of a\nfoundation visual language model (VLM) is hindered by limited data and domain\ndifferences between natural and medical images. Existing mammography VLMs,\nadapted from natural images, often ignore domain-specific characteristics, such\nas multi-view relationships in mammography. Unlike radiologists who analyze\nboth views together to process ipsilateral correspondence, current methods\ntreat them as independent images or do not properly model the multi-view\ncorrespondence learning, losing critical geometric context and resulting in\nsuboptimal prediction. We propose GLAM: Global and Local Alignment for\nMulti-view mammography for VLM pretraining using geometry guidance. By\nleveraging the prior knowledge about the multi-view imaging process of\nmammograms, our model learns local cross-view alignments and fine-grained local\nfeatures through joint global and local, visual-visual, and visual-language\ncontrastive learning. Pretrained on EMBED [14], one of the largest open\nmammography datasets, our model outperforms baselines across multiple datasets\nunder different settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86GLAM\u6a21\u578b\uff0c\u901a\u8fc7\u51e0\u4f55\u5f15\u5bfc\u7684\u5168\u5c40\u548c\u5c40\u90e8\u5bf9\u9f50\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e73\u817aX\u5149\u591a\u89c6\u56fe\u5bf9\u5e94\u5b66\u4e60\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u73b0\u6709\u4e73\u817aX\u5149\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5ffd\u7565\u591a\u89c6\u56fe\u5173\u7cfb\u7279\u6027\uff0c\u65e0\u6cd5\u50cf\u653e\u5c04\u79d1\u533b\u751f\u90a3\u6837\u540c\u65f6\u5206\u6790\u53cc\u4fa7\u89c6\u56fe\u6765\u5904\u7406\u540c\u4fa7\u5bf9\u5e94\u5173\u7cfb\uff0c\u5bfc\u81f4\u51e0\u4f55\u4e0a\u4e0b\u6587\u4e22\u5931\u548c\u9884\u6d4b\u6548\u679c\u4e0d\u4f73", "method": "\u5229\u7528\u4e73\u817aX\u5149\u591a\u89c6\u56fe\u6210\u50cf\u8fc7\u7a0b\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u901a\u8fc7\u8054\u5408\u5168\u5c40\u548c\u5c40\u90e8\u3001\u89c6\u89c9-\u89c6\u89c9\u3001\u89c6\u89c9-\u8bed\u8a00\u7684\u5bf9\u6bd4\u5b66\u4e60\uff0c\u5b66\u4e60\u5c40\u90e8\u8de8\u89c6\u56fe\u5bf9\u9f50\u548c\u7ec6\u7c92\u5ea6\u5c40\u90e8\u7279\u5f81", "result": "\u5728\u6700\u5927\u7684\u516c\u5f00\u4e73\u817aX\u5149\u6570\u636e\u96c6EMBED\u4e0a\u9884\u8bad\u7ec3\u540e\uff0c\u6a21\u578b\u5728\u591a\u4e2a\u6570\u636e\u96c6\u7684\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "GLAM\u6a21\u578b\u901a\u8fc7\u51e0\u4f55\u5f15\u5bfc\u7684\u591a\u89c6\u56fe\u5bf9\u9f50\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4e73\u817aX\u5149\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4e3a\u65e9\u671f\u4e73\u817a\u764c\u68c0\u6d4b\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u5de5\u5177"}}
{"id": "2509.10348", "pdf": "https://arxiv.org/pdf/2509.10348", "abs": "https://arxiv.org/abs/2509.10348", "authors": ["Yehudit Aperstein", "Amit Tzahar", "Alon Gottlib", "Tal Verber", "Ravit Shagan Damti", "Alexander Apartsin"], "title": "Multi-pathology Chest X-ray Classification with Rejection Mechanisms", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "12 pages, 4 figures", "summary": "Overconfidence in deep learning models poses a significant risk in\nhigh-stakes medical imaging tasks, particularly in multi-label classification\nof chest X-rays, where multiple co-occurring pathologies must be detected\nsimultaneously. This study introduces an uncertainty-aware framework for chest\nX-ray diagnosis based on a DenseNet-121 backbone, enhanced with two selective\nprediction mechanisms: entropy-based rejection and confidence interval-based\nrejection. Both methods enable the model to abstain from uncertain predictions,\nimproving reliability by deferring ambiguous cases to clinical experts. A\nquantile-based calibration procedure is employed to tune rejection thresholds\nusing either global or class-specific strategies. Experiments conducted on\nthree large public datasets (PadChest, NIH ChestX-ray14, and MIMIC-CXR)\ndemonstrate that selective rejection improves the trade-off between diagnostic\naccuracy and coverage, with entropy-based rejection yielding the highest\naverage AUC across all pathologies. These results support the integration of\nselective prediction into AI-assisted diagnostic workflows, providing a\npractical step toward safer, uncertainty-aware deployment of deep learning in\nclinical settings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eDenseNet-121\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u71b5\u62d2\u7edd\u548c\u7f6e\u4fe1\u533a\u95f4\u62d2\u7edd\u4e24\u79cd\u9009\u62e9\u6027\u9884\u6d4b\u673a\u5236\uff0c\u5728\u80f8\u90e8X\u5149\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\u63d0\u9ad8\u6a21\u578b\u53ef\u9760\u6027\uff0c\u907f\u514d\u5bf9\u4e0d\u786e\u5b9a\u9884\u6d4b\u505a\u51fa\u9519\u8bef\u5224\u65ad\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u533b\u5b66\u5f71\u50cf\u4efb\u52a1\u4e2d\u5b58\u5728\u8fc7\u5ea6\u81ea\u4fe1\u98ce\u9669\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u540c\u65f6\u68c0\u6d4b\u591a\u79cd\u5171\u5b58\u75c5\u7406\u7684\u80f8\u90e8X\u5149\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\uff0c\u4e0d\u786e\u5b9a\u7684\u9884\u6d4b\u53ef\u80fd\u5e26\u6765\u9ad8\u98ce\u9669\u3002", "method": "\u4f7f\u7528DenseNet-121\u4f5c\u4e3a\u9aa8\u5e72\u7f51\u7edc\uff0c\u96c6\u6210\u71b5\u57fa\u62d2\u7edd\u548c\u7f6e\u4fe1\u533a\u95f4\u62d2\u7edd\u4e24\u79cd\u9009\u62e9\u6027\u9884\u6d4b\u673a\u5236\uff0c\u91c7\u7528\u5206\u4f4d\u6570\u6821\u51c6\u7a0b\u5e8f\u8c03\u6574\u62d2\u7edd\u9608\u503c\uff0c\u652f\u6301\u5168\u5c40\u548c\u7c7b\u7279\u5b9a\u7b56\u7565\u3002", "result": "\u5728\u4e09\u4e2a\u5927\u578b\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u9009\u62e9\u6027\u62d2\u7edd\u6539\u5584\u4e86\u8bca\u65ad\u51c6\u786e\u6027\u548c\u8986\u76d6\u8303\u56f4\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u71b5\u57fa\u62d2\u7edd\u5728\u6240\u6709\u75c5\u7406\u4e2d\u83b7\u5f97\u4e86\u6700\u9ad8\u7684\u5e73\u5747AUC\u3002", "conclusion": "\u8be5\u7814\u7a76\u652f\u6301\u5c06\u9009\u62e9\u6027\u9884\u6d4b\u6574\u5408\u5230AI\u8f85\u52a9\u8bca\u65ad\u5de5\u4f5c\u6d41\u7a0b\u4e2d\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u66f4\u5b89\u5168\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u6b65\u9aa4\u3002"}}
{"id": "2509.10378", "pdf": "https://arxiv.org/pdf/2509.10378", "abs": "https://arxiv.org/abs/2509.10378", "authors": ["Yixuan Sun", "Srinivas Eswar", "Yin Lin", "William Detmold", "Phiala Shanahan", "Xiaoye Li", "Yang Liu", "Prasanna Balaprakash"], "title": "Matrix-free Neural Preconditioner for the Dirac Operator in Lattice Gauge Theory", "categories": ["hep-lat", "cs.LG"], "comment": null, "summary": "Linear systems arise in generating samples and in calculating observables in\nlattice quantum chromodynamics~(QCD). Solving the Hermitian positive definite\nsystems, which are sparse but ill-conditioned, involves using iterative\nmethods, such as Conjugate Gradient (CG), which are time-consuming and\ncomputationally expensive. Preconditioners can effectively accelerate this\nprocess, with the state-of-the-art being multigrid preconditioners. However,\nconstructing useful preconditioners can be challenging, adding additional\ncomputational overhead, especially in large linear systems. We propose a\nframework, leveraging operator learning techniques, to construct linear maps as\neffective preconditioners. The method in this work does not rely on explicit\nmatrices from either the original linear systems or the produced\npreconditioners, allowing efficient model training and application in the CG\nsolver. In the context of the Schwinger model U(1) gauge theory in 1+1\nspacetime dimensions with two degenerate-mass fermions), this preconditioning\nscheme effectively decreases the condition number of the linear systems and\napproximately halves the number of iterations required for convergence in\nrelevant parameter ranges. We further demonstrate the framework learns a\ngeneral mapping dependent on the lattice structure which leads to zero-shot\nlearning ability for the Dirac operators constructed from gauge field\nconfigurations of different sizes.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7b97\u5b50\u5b66\u4e60\u7684\u6846\u67b6\u6784\u5efa\u7ebf\u6027\u6620\u5c04\u4f5c\u4e3a\u6709\u6548\u9884\u5904\u7406\u5668\uff0c\u7528\u4e8e\u52a0\u901f\u683c\u70b9QCD\u4e2d\u7a00\u758f\u75c5\u6001\u7ebf\u6027\u7cfb\u7edf\u7684\u5171\u8f6d\u68af\u5ea6\u6c42\u89e3\uff0c\u65e0\u9700\u663e\u5f0f\u77e9\u9635\uff0c\u5728Schwinger\u6a21\u578b\u4e2d\u6709\u6548\u964d\u4f4e\u6761\u4ef6\u6570\u5e76\u51cf\u5c11\u7ea6\u4e00\u534a\u8fed\u4ee3\u6b21\u6570\u3002", "motivation": "\u683c\u70b9\u91cf\u5b50\u8272\u52a8\u529b\u5b66\u4e2d\u6c42\u89e3\u7a00\u758f\u4f46\u75c5\u6001\u7684Hermitian\u6b63\u5b9a\u7ebf\u6027\u7cfb\u7edf\u9700\u8981\u8017\u65f6\u7684\u8fed\u4ee3\u65b9\u6cd5\uff0c\u73b0\u6709\u591a\u7f51\u683c\u9884\u5904\u7406\u5668\u6784\u9020\u590d\u6742\u4e14\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u9884\u5904\u7406\u5668\u6784\u5efa\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u7b97\u5b50\u5b66\u4e60\u6280\u672f\u6784\u5efa\u7ebf\u6027\u6620\u5c04\u4f5c\u4e3a\u9884\u5904\u7406\u5668\uff0c\u4e0d\u4f9d\u8d56\u4e8e\u539f\u59cb\u7ebf\u6027\u7cfb\u7edf\u6216\u9884\u5904\u7406\u5668\u7684\u663e\u5f0f\u77e9\u9635\uff0c\u5b9e\u73b0\u9ad8\u6548\u6a21\u578b\u8bad\u7ec3\u548c\u5728CG\u6c42\u89e3\u5668\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u5728Schwinger\u6a21\u578bU(1)\u89c4\u8303\u7406\u8bba\u4e2d\uff0c\u8be5\u9884\u5904\u7406\u5668\u65b9\u6848\u6709\u6548\u964d\u4f4e\u4e86\u7ebf\u6027\u7cfb\u7edf\u7684\u6761\u4ef6\u6570\uff0c\u5728\u76f8\u5173\u53c2\u6570\u8303\u56f4\u5185\u5c06\u6536\u655b\u6240\u9700\u8fed\u4ee3\u6b21\u6570\u51cf\u5c11\u7ea6\u4e00\u534a\uff0c\u5e76\u5c55\u793a\u4e86\u96f6\u6837\u672c\u5b66\u4e60\u80fd\u529b\u3002", "conclusion": "\u57fa\u4e8e\u7b97\u5b50\u5b66\u4e60\u7684\u9884\u5904\u7406\u5668\u6846\u67b6\u4e3a\u683c\u70b9QCD\u4e2d\u7684\u7ebf\u6027\u7cfb\u7edf\u6c42\u89e3\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u52a0\u901f\u65b9\u6848\uff0c\u5177\u6709\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\uff0c\u53ef\u5e94\u7528\u4e8e\u4e0d\u540c\u5c3a\u5bf8\u7684\u89c4\u8303\u573a\u914d\u7f6e\u3002"}}
{"id": "2509.10385", "pdf": "https://arxiv.org/pdf/2509.10385", "abs": "https://arxiv.org/abs/2509.10385", "authors": ["Utsab Saha", "Tanvir Muntakim Tonoy", "Hafiz Imtiaz"], "title": "Differentially Private Decentralized Dataset Synthesis Through Randomized Mixing with Correlated Noise", "categories": ["stat.ML", "cs.LG"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "In this work, we explore differentially private synthetic data generation in\na decentralized-data setting by building on the recently proposed\nDifferentially Private Class-Centric Data Aggregation (DP-CDA). DP-CDA\nsynthesizes data in a centralized setting by mixing multiple randomly-selected\nsamples from the same class and injecting carefully calibrated Gaussian noise,\nensuring ({\\epsilon}, {\\delta})-differential privacy. When deployed in a\ndecentralized or federated setting, where each client holds only a small\npartition of the data, DP-CDA faces new challenges. The limited sample size per\nclient increases the sensitivity of local computations, requiring higher noise\ninjection to maintain the differential privacy guarantee. This, in turn, leads\nto a noticeable degradation in the utility compared to the centralized setting.\nTo mitigate this issue, we integrate the Correlation-Assisted Private\nEstimation (CAPE) protocol into the federated DP-CDA framework and propose CAPE\nAssisted Federated DP-CDA algorithm. CAPE enables limited collaboration among\nthe clients by allowing them to generate jointly distributed (anti-correlated)\nnoise that cancels out in aggregate, while preserving privacy at the individual\nlevel. This technique significantly improves the privacy-utility trade-off in\nthe federated setting. Extensive experiments on MNIST and FashionMNIST datasets\ndemonstrate that the proposed CAPE Assisted Federated DP-CDA approach can\nachieve utility comparable to its centralized counterpart under some parameter\nregime, while maintaining rigorous differential privacy guarantees.", "AI": {"tldr": "\u63d0\u51faCAPE\u8f85\u52a9\u7684\u8054\u90a6DP-CDA\u7b97\u6cd5\uff0c\u901a\u8fc7\u5728\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\u6574\u5408\u76f8\u5173\u6027\u8f85\u52a9\u9690\u79c1\u4f30\u8ba1\u534f\u8bae\uff0c\u6539\u5584\u5dee\u5206\u9690\u79c1\u5408\u6210\u6570\u636e\u751f\u6210\u5728\u5206\u6563\u6570\u636e\u8bbe\u7f6e\u4e2d\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\u3002", "motivation": "\u5728\u5206\u6563\u6570\u636e\u8bbe\u7f6e\u4e2d\uff0cDP-CDA\u9762\u4e34\u6837\u672c\u91cf\u6709\u9650\u5bfc\u81f4\u5c40\u90e8\u8ba1\u7b97\u654f\u611f\u6027\u589e\u52a0\u7684\u95ee\u9898\uff0c\u9700\u8981\u6ce8\u5165\u66f4\u591a\u566a\u58f0\u6765\u4fdd\u6301\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\uff0c\u4ece\u800c\u5bfc\u81f4\u6548\u7528\u663e\u8457\u4e0b\u964d\u3002", "method": "\u5c06CAPE\u534f\u8bae\u96c6\u6210\u5230\u8054\u90a6DP-CDA\u6846\u67b6\u4e2d\uff0c\u5141\u8bb8\u5ba2\u6237\u7aef\u751f\u6210\u8054\u5408\u5206\u5e03\u7684\u53cd\u76f8\u5173\u566a\u58f0\uff0c\u5728\u805a\u5408\u65f6\u76f8\u4e92\u62b5\u6d88\uff0c\u540c\u65f6\u4fdd\u6301\u4e2a\u4f53\u5c42\u9762\u7684\u9690\u79c1\u4fdd\u62a4\u3002", "result": "\u5728MNIST\u548cFashionMNIST\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u67d0\u4e9b\u53c2\u6570\u8303\u56f4\u5185\u53ef\u4ee5\u8fbe\u5230\u4e0e\u96c6\u4e2d\u5f0f\u5bf9\u5e94\u65b9\u6cd5\u76f8\u5f53\u7684\u6548\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u4e25\u683c\u7684\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\u3002", "conclusion": "CAPE\u8f85\u52a9\u8054\u90a6DP-CDA\u7b97\u6cd5\u663e\u8457\u6539\u5584\u4e86\u8054\u90a6\u8bbe\u7f6e\u4e2d\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\uff0c\u4e3a\u5206\u6563\u6570\u636e\u73af\u5883\u4e0b\u7684\u5dee\u5206\u9690\u79c1\u6570\u636e\u5408\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.10414", "pdf": "https://arxiv.org/pdf/2509.10414", "abs": "https://arxiv.org/abs/2509.10414", "authors": ["Adrian de Wynter"], "title": "Is In-Context Learning Learning?", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Director's cut", "summary": "In-context learning (ICL) allows some autoregressive models to solve tasks\nvia next-token prediction and without needing further training. This has led to\nclaims about these model's ability to solve (learn) unseen tasks with only a\nfew shots (exemplars) in the prompt. However, deduction does not always imply\nlearning, as ICL does not explicitly encode a given observation. Instead, the\nmodels rely on their prior knowledge and the exemplars given, if any. We argue\nthat, mathematically, ICL does constitute learning, but its full\ncharacterisation requires empirical work. We then carry out a large-scale\nanalysis of ICL ablating out or accounting for memorisation, pretraining,\ndistributional shifts, and prompting style and phrasing. We find that ICL is an\neffective learning paradigm, but limited in its ability to learn and generalise\nto unseen tasks. We note that, in the limit where exemplars become more\nnumerous, accuracy is insensitive to exemplar distribution, model, prompt\nstyle, and the input's linguistic features. Instead, it deduces patterns from\nregularities in the prompt, which leads to distributional sensitivity,\nespecially in prompting styles such as chain-of-thought. Given the varied\naccuracies on formally similar tasks, we conclude that autoregression's ad-hoc\nencoding is not a robust mechanism, and suggests limited all-purpose\ngeneralisability.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\u53d1\u73b0\uff0c\u4e0a\u4e0b\u6587\u5b66\u4e60(ICL)\u786e\u5b9e\u6784\u6210\u5b66\u4e60\u673a\u5236\uff0c\u4f46\u5176\u5b66\u4e60\u80fd\u529b\u6709\u9650\uff0c\u5bf9\u672a\u89c1\u4efb\u52a1\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u4e14\u5bf9\u63d0\u793a\u4e2d\u7684\u5206\u5e03\u53d8\u5316\u654f\u611f\u3002", "motivation": "\u5c3d\u7ba1ICL\u88ab\u58f0\u79f0\u80fd\u591f\u901a\u8fc7\u5c11\u91cf\u6837\u672c\u5b66\u4e60\u65b0\u4efb\u52a1\uff0c\u4f46\u9700\u8981\u5b9e\u8bc1\u9a8c\u8bc1\u5176\u662f\u5426\u771f\u6b63\u6784\u6210\u5b66\u4e60\u673a\u5236\uff0c\u4ee5\u53ca\u5176\u5b66\u4e60\u80fd\u529b\u7684\u5c40\u9650\u6027\u3002", "method": "\u8fdb\u884c\u5927\u89c4\u6a21ICL\u5206\u6790\uff0c\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u6392\u9664\u8bb0\u5fc6\u6548\u5e94\u3001\u9884\u8bad\u7ec3\u5f71\u54cd\u3001\u5206\u5e03\u504f\u79fb\u7b49\u56e0\u7d20\uff0c\u5206\u6790\u4e0d\u540c\u63d0\u793a\u98ce\u683c\u548c\u63aa\u8f9e\u5bf9ICL\u6548\u679c\u7684\u5f71\u54cd\u3002", "result": "ICL\u662f\u4e00\u79cd\u6709\u6548\u7684\u5b66\u4e60\u8303\u5f0f\uff0c\u4f46\u5728\u5b66\u4e60\u672a\u89c1\u4efb\u52a1\u548c\u6cdb\u5316\u65b9\u9762\u80fd\u529b\u6709\u9650\uff1b\u5f53\u793a\u4f8b\u6570\u91cf\u589e\u591a\u65f6\uff0c\u51c6\u786e\u7387\u5bf9\u793a\u4f8b\u5206\u5e03\u3001\u6a21\u578b\u3001\u63d0\u793a\u98ce\u683c\u7b49\u4e0d\u654f\u611f\uff0c\u4e3b\u8981\u4ece\u63d0\u793a\u4e2d\u7684\u89c4\u5f8b\u6027\u63a8\u65ad\u6a21\u5f0f\u3002", "conclusion": "\u81ea\u56de\u5f52\u6a21\u578b\u7684\u4e34\u65f6\u7f16\u7801\u673a\u5236\u4e0d\u591f\u9c81\u68d2\uff0c\u8868\u660e\u5176\u901a\u7528\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0cICL\u5bf9\u5206\u5e03\u53d8\u5316\u654f\u611f\uff0c\u7279\u522b\u662f\u5728\u601d\u7ef4\u94fe\u7b49\u63d0\u793a\u98ce\u683c\u4e2d\u3002"}}
{"id": "2509.10423", "pdf": "https://arxiv.org/pdf/2509.10423", "abs": "https://arxiv.org/abs/2509.10423", "authors": ["Cameron Reid", "Wael Hafez", "Amirhossein Nazeri"], "title": "Mutual Information Tracks Policy Coherence in Reinforcement Learning", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": "10 pages, 4 figures, 1 table", "summary": "Reinforcement Learning (RL) agents deployed in real-world environments face\ndegradation from sensor faults, actuator wear, and environmental shifts, yet\nlack intrinsic mechanisms to detect and diagnose these failures. We present an\ninformation-theoretic framework that reveals both the fundamental dynamics of\nRL and provides practical methods for diagnosing deployment-time anomalies.\nThrough analysis of state-action mutual information patterns in a robotic\ncontrol task, we first demonstrate that successful learning exhibits\ncharacteristic information signatures: mutual information between states and\nactions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing\nstate entropy, indicating that agents develop increasingly selective attention\nto task-relevant patterns. Intriguingly, states, actions and next states joint\nmutual information, MI(S,A;S'), follows an inverted U-curve, peaking during\nearly learning before declining as the agent specializes suggesting a\ntransition from broad exploration to efficient exploitation. More immediately\nactionable, we show that information metrics can differentially diagnose system\nfailures: observation-space, i.e., states noise (sensor faults) produces broad\ncollapses across all information channels with pronounced drops in state-action\ncoupling, while action-space noise (actuator faults) selectively disrupts\naction-outcome predictability while preserving state-action relationships. This\ndifferential diagnostic capability demonstrated through controlled perturbation\nexperiments enables precise fault localization without architectural\nmodifications or performance degradation. By establishing information patterns\nas both signatures of learning and diagnostic for system health, we provide the\nfoundation for adaptive RL systems capable of autonomous fault detection and\npolicy adjustment based on information-theoretic principles.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u72b6\u6001-\u52a8\u4f5c\u4e92\u4fe1\u606f\u6a21\u5f0f\u6765\u8bca\u65adRL\u7cfb\u7edf\u90e8\u7f72\u65f6\u7684\u5f02\u5e38\u6545\u969c\uff0c\u80fd\u591f\u533a\u5206\u4f20\u611f\u5668\u6545\u969c\u548c\u9a71\u52a8\u5668\u6545\u969c\uff0c\u4e3a\u81ea\u9002\u5e94RL\u7cfb\u7edf\u63d0\u4f9b\u81ea\u4e3b\u6545\u969c\u68c0\u6d4b\u57fa\u7840\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u90e8\u7f72\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u9762\u4e34\u4f20\u611f\u5668\u6545\u969c\u3001\u9a71\u52a8\u5668\u78e8\u635f\u548c\u73af\u5883\u53d8\u5316\u7b49\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u5185\u5728\u673a\u5236\u6765\u68c0\u6d4b\u548c\u8bca\u65ad\u8fd9\u4e9b\u6545\u969c\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u81ea\u4e3b\u68c0\u6d4b\u7cfb\u7edf\u5f02\u5e38\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4fe1\u606f\u8bba\u6846\u67b6\u5206\u6790\u72b6\u6001-\u52a8\u4f5c\u4e92\u4fe1\u606f\u6a21\u5f0f\uff0c\u901a\u8fc7\u63a7\u5236\u6270\u52a8\u5b9e\u9a8c\u7814\u7a76\u4e0d\u540c\u6545\u969c\u7c7b\u578b\u5bf9\u4fe1\u606f\u901a\u9053\u7684\u5f71\u54cd\uff0c\u4f7f\u7528\u4e92\u4fe1\u606f\u6307\u6807\u6765\u8bca\u65ad\u7cfb\u7edf\u6545\u969c\u3002", "result": "\u6210\u529f\u5b66\u4e60\u8868\u73b0\u51fa\u7279\u5f81\u6027\u4fe1\u606f\u7b7e\u540d\uff1a\u72b6\u6001-\u52a8\u4f5c\u4e92\u4fe1\u606f\u4ece0.84\u589e\u957f\u52302.83\u6bd4\u7279\uff08238%\u589e\u957f\uff09\uff1b\u72b6\u6001\u3001\u52a8\u4f5c\u548c\u4e0b\u4e00\u72b6\u6001\u8054\u5408\u4e92\u4fe1\u606f\u5448\u73b0\u5012U\u578b\u66f2\u7ebf\uff1b\u4fe1\u606f\u6307\u6807\u80fd\u591f\u533a\u5206\u4f20\u611f\u5668\u6545\u969c\uff08\u5e7f\u6cdb\u7834\u574f\u6240\u6709\u4fe1\u606f\u901a\u9053\uff09\u548c\u9a71\u52a8\u5668\u6545\u969c\uff08\u9009\u62e9\u6027\u7834\u574f\u52a8\u4f5c-\u7ed3\u679c\u53ef\u9884\u6d4b\u6027\uff09\u3002", "conclusion": "\u4fe1\u606f\u6a21\u5f0f\u65e2\u662f\u5b66\u4e60\u7684\u7b7e\u540d\uff0c\u4e5f\u662f\u7cfb\u7edf\u5065\u5eb7\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u4e3a\u57fa\u4e8e\u4fe1\u606f\u8bba\u539f\u7406\u7684\u81ea\u9002\u5e94RL\u7cfb\u7edf\u63d0\u4f9b\u4e86\u81ea\u4e3b\u6545\u969c\u68c0\u6d4b\u548c\u653f\u7b56\u8c03\u6574\u7684\u57fa\u7840\uff0c\u65e0\u9700\u67b6\u6784\u4fee\u6539\u6216\u6027\u80fd\u4e0b\u964d\u5373\u53ef\u5b9e\u73b0\u7cbe\u786e\u6545\u969c\u5b9a\u4f4d\u3002"}}
{"id": "2509.10452", "pdf": "https://arxiv.org/pdf/2509.10452", "abs": "https://arxiv.org/abs/2509.10452", "authors": ["Akshat Pandey", "Karun Kumar", "Raphael Tang"], "title": "WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers", "categories": ["cs.CL", "cs.LG"], "comment": "5 pages, 2 figures", "summary": "Pretrained automatic speech recognition (ASR) models such as Whisper perform\nwell but still need domain adaptation to handle unseen vocabulary and parlance.\nIn many real-world settings, collecting speech data is impractical,\nnecessitating text-only adaptation. We propose WhisTLE, a deeply supervised,\ntext-only adaptation method for pretrained encoder-decoder ASR models. WhisTLE\ntrains a variational autoencoder (VAE) to model encoder outputs from text and\nfine-tunes the decoder using the learned text-to-latent encoder, optionally\ncombined with text-to-speech (TTS) adaptation. At inference, the original\nencoder is restored, incurring no extra runtime cost. Across four out-of-domain\ndatasets and four ASR models, WhisTLE with TTS reduces word error rate (WER) by\n12.3% relative to TTS-only adaptation and outperforms all non-WhisTLE baselines\nin 27 of 32 scenarios.", "AI": {"tldr": "WhisTLE\u662f\u4e00\u79cd\u4ec5\u4f7f\u7528\u6587\u672c\u6570\u636e\u8fdb\u884c\u9884\u8bad\u7ec3ASR\u6a21\u578b\u9886\u57df\u9002\u5e94\u7684\u6df1\u5ea6\u76d1\u7763\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5efa\u6a21\u7f16\u7801\u5668\u8f93\u51fa\u5e76\u5fae\u8c03\u89e3\u7801\u5668\uff0c\u5728\u63a8\u7406\u65f6\u4e0d\u589e\u52a0\u989d\u5916\u8ba1\u7b97\u6210\u672c", "motivation": "\u9884\u8bad\u7ec3ASR\u6a21\u578b\u5982Whisper\u5728\u5904\u7406\u672a\u89c1\u8bcd\u6c47\u548c\u65b9\u8a00\u65f6\u9700\u8981\u9886\u57df\u9002\u5e94\uff0c\u4f46\u5728\u8bb8\u591a\u5b9e\u9645\u573a\u666f\u4e2d\u6536\u96c6\u8bed\u97f3\u6570\u636e\u4e0d\u73b0\u5b9e\uff0c\u56e0\u6b64\u9700\u8981\u4ec5\u4f7f\u7528\u6587\u672c\u7684\u9002\u5e94\u65b9\u6cd5", "method": "\u8bad\u7ec3\u53d8\u5206\u81ea\u7f16\u7801\u5668(VAE)\u4ece\u6587\u672c\u5efa\u6a21\u7f16\u7801\u5668\u8f93\u51fa\uff0c\u4f7f\u7528\u5b66\u4e60\u7684\u6587\u672c\u5230\u6f5c\u5728\u7f16\u7801\u5668\u5fae\u8c03\u89e3\u7801\u5668\uff0c\u53ef\u9009\u7ed3\u5408\u6587\u672c\u5230\u8bed\u97f3(TTS)\u9002\u5e94\u3002\u63a8\u7406\u65f6\u6062\u590d\u539f\u59cb\u7f16\u7801\u5668", "result": "\u5728\u56db\u4e2a\u57df\u5916\u6570\u636e\u96c6\u548c\u56db\u4e2aASR\u6a21\u578b\u4e0a\uff0cWhisTLE\u7ed3\u5408TTS\u76f8\u6bd4\u4ec5\u4f7f\u7528TTS\u7684\u9002\u5e94\u65b9\u6cd5\u76f8\u5bf9\u964d\u4f4e12.3%\u7684\u8bcd\u9519\u8bef\u7387\uff0c\u572832\u4e2a\u573a\u666f\u4e2d\u768427\u4e2a\u4f18\u4e8e\u6240\u6709\u975eWhisTLE\u57fa\u7ebf", "conclusion": "WhisTLE\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6587\u672c-only\u9002\u5e94\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u9884\u8bad\u7ec3ASR\u6a21\u578b\u5728\u672a\u89c1\u9886\u57df\u7684\u6027\u80fd\uff0c\u4e14\u4e0d\u589e\u52a0\u63a8\u7406\u65f6\u7684\u8ba1\u7b97\u5f00\u9500"}}
{"id": "2509.10453", "pdf": "https://arxiv.org/pdf/2509.10453", "abs": "https://arxiv.org/abs/2509.10453", "authors": ["Emily Kaczmarek", "Justin Szeto", "Brennan Nichyporuk", "Tal Arbel"], "title": "SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and Adaptability Across Alzheimer's Prediction Tasks and Datasets", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Alzheimer's disease is a progressive, neurodegenerative disorder that causes\nmemory loss and cognitive decline. While there has been extensive research in\napplying deep learning models to Alzheimer's prediction tasks, these models\nremain limited by lack of available labeled data, poor generalization across\ndatasets, and inflexibility to varying numbers of input scans and time\nintervals between scans. In this study, we adapt three state-of-the-art\ntemporal self-supervised learning (SSL) approaches for 3D brain MRI analysis,\nand add novel extensions designed to handle variable-length inputs and learn\nrobust spatial features. We aggregate four publicly available datasets\ncomprising 3,161 patients for pre-training, and show the performance of our\nmodel across multiple Alzheimer's prediction tasks including diagnosis\nclassification, conversion detection, and future conversion prediction.\nImportantly, our SSL model implemented with temporal order prediction and\ncontrastive learning outperforms supervised learning on six out of seven\ndownstream tasks. It demonstrates adaptability and generalizability across\ntasks and number of input images with varying time intervals, highlighting its\ncapacity for robust performance across clinical applications. We release our\ncode and model publicly at https://github.com/emilykaczmarek/SSL-AD.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06\u4e09\u79cd\u5148\u8fdb\u7684\u65f6\u5e8f\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u5e94\u7528\u4e8e3D\u8111\u90e8MRI\u5206\u6790\uff0c\u901a\u8fc7\u5904\u7406\u53ef\u53d8\u957f\u5ea6\u8f93\u5165\u548c\u589e\u5f3a\u7a7a\u95f4\u7279\u5f81\u5b66\u4e60\uff0c\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u9884\u6d4b\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u9884\u6d4b\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u9762\u4e34\u6807\u6ce8\u6570\u636e\u4e0d\u8db3\u3001\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\u5dee\u4ee5\u53ca\u5bf9\u4e0d\u540c\u626b\u63cf\u6570\u91cf\u548c\u95f4\u9694\u65f6\u95f4\u7f3a\u4e4f\u7075\u6d3b\u6027\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e09\u79cd\u65f6\u5e8f\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u65b9\u6cd5\uff0c\u5305\u62ec\u65f6\u5e8f\u987a\u5e8f\u9884\u6d4b\u548c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u6dfb\u52a0\u4e86\u5904\u7406\u53ef\u53d8\u957f\u5ea6\u8f93\u5165\u7684\u65b0\u6269\u5c55\uff0c\u5e76\u5728\u5305\u542b3,161\u540d\u60a3\u8005\u7684\u56db\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\u3002", "result": "\u5728\u4e03\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u516d\u4e2a\u4efb\u52a1\u4e0a\uff0c\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u7684\u8868\u73b0\u4f18\u4e8e\u76d1\u7763\u5b66\u4e60\uff0c\u5c55\u793a\u4e86\u8de8\u4efb\u52a1\u548c\u4e0d\u540c\u8f93\u5165\u56fe\u50cf\u6570\u91cf\u53ca\u65f6\u95f4\u95f4\u9694\u7684\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u65f6\u5e8f\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd\uff0c\u5177\u6709\u4e34\u5e8a\u5e94\u7528\u7684\u6f5c\u529b\uff0c\u4ee3\u7801\u548c\u6a21\u578b\u5df2\u516c\u5f00\u3002"}}
