{"id": "2506.15831", "pdf": "https://arxiv.org/pdf/2506.15831", "abs": "https://arxiv.org/abs/2506.15831", "authors": ["Jongjun Park", "Fei Chiang", "Mostafa Milani"], "title": "Adaptive Anomaly Detection in the Presence of Concept Drift: Extended Report", "categories": ["cs.DB"], "comment": "Extended version (to be updated)", "summary": "Data changes to reflect evolving user behaviour, preferences, and changes in\nthe environment. Such changes may occur due to expected shifts in the data\ndistribution, i.e., concept drift, or unexpected anomalous changes. The\npresence of concept drift poses challenges for anomaly detection in time\nseries. While anomalies are caused by undesirable changes in the data,\ndifferentiating abnormal changes from varying normal behaviours is difficult\ndue to differing frequencies of occurrence, varying time intervals when normal\npatterns occur. Differentiating between concept drift and anomalies is critical\nfor accurate analysis as studies have shown that the compounding effects of\nerror propagation in downstream data analysis tasks lead to lower detection\naccuracy and increased overhead due to unnecessary model updates.\nUnfortunately, existing work has largely explored anomaly detection and concept\ndrift detection in isolation. We develop AnDri, a system for Anomaly detection\nin the presence of Drift, which adjusts the normal patterns temporally, and\ndistinguish abnormal subsequences and new concepts. Moreover, it introduces a\nnew clustering method, Adjacent Hierarchical Clustering (AHC), which groups\nsimilar subsequences while respecting their temporal locality.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faAnDri\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u6982\u5ff5\u6f02\u79fb\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u6b63\u5e38\u6a21\u5f0f\u5e76\u533a\u5206\u5f02\u5e38\u5b50\u5e8f\u5217\u4e0e\u65b0\u6982\u5ff5\uff0c\u540c\u65f6\u5f15\u5165\u65b0\u7684\u805a\u7c7b\u65b9\u6cd5AHC\u3002", "motivation": "\u6570\u636e\u5206\u5e03\u7684\u53d8\u5316\uff08\u6982\u5ff5\u6f02\u79fb\uff09\u548c\u5f02\u5e38\u53d8\u5316\u5bf9\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u5e26\u6765\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5b64\u7acb\u5904\u7406\u8fd9\u4e24\u8005\uff0c\u5bfc\u81f4\u68c0\u6d4b\u7cbe\u5ea6\u4e0b\u964d\u548c\u6a21\u578b\u66f4\u65b0\u5f00\u9500\u589e\u52a0\u3002", "method": "\u5f00\u53d1AnDri\u7cfb\u7edf\uff0c\u52a8\u6001\u8c03\u6574\u6b63\u5e38\u6a21\u5f0f\u5e76\u533a\u5206\u5f02\u5e38\u5b50\u5e8f\u5217\u4e0e\u65b0\u6982\u5ff5\uff1b\u63d0\u51faAdjacent Hierarchical Clustering (AHC)\u805a\u7c7b\u65b9\u6cd5\uff0c\u8003\u8651\u65f6\u95f4\u5c40\u90e8\u6027\u3002", "result": "AnDri\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u533a\u5206\u6982\u5ff5\u6f02\u79fb\u548c\u5f02\u5e38\uff0c\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "AnDri\u7cfb\u7edf\u89e3\u51b3\u4e86\u6982\u5ff5\u6f02\u79fb\u4e0e\u5f02\u5e38\u68c0\u6d4b\u7684\u8054\u5408\u95ee\u9898\uff0c\u901a\u8fc7AHC\u65b9\u6cd5\u4f18\u5316\u4e86\u805a\u7c7b\u6548\u679c\uff0c\u4e3a\u4e0b\u6e38\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u5206\u6790\u57fa\u7840\u3002"}}
{"id": "2506.15848", "pdf": "https://arxiv.org/pdf/2506.15848", "abs": "https://arxiv.org/abs/2506.15848", "authors": ["Jiazhen Peng", "Zheng Qu", "Xiaoye Miao", "Rong Zhu"], "title": "Delta: A Learned Mixed Cost-based Query Optimization Framework", "categories": ["cs.DB"], "comment": null, "summary": "Query optimizer is a crucial module for database management systems. Existing\noptimizers exhibit two flawed paradigms: (1) cost-based optimizers use dynamic\nprogramming with cost models but face search space explosion and heuristic\npruning constraints; (2) value-based ones train value networks to enable\nefficient beam search, but incur higher training costs and lower accuracy. They\nalso lack mechanisms to detect queries where they may perform poorly. To\ndetermine more efficient plans, we propose Delta, a mixed cost-based query\noptimization framework that consists of a compatible query detector and a\ntwo-stage planner. Delta first employs a Mahalanobis distancebased detector to\npreemptively filter out incompatible queries where the planner might perform\npoorly. For compatible queries, Delta activates its two-stage mixed cost-based\nplanner. Stage I serves as a coarse-grained filter to generate high-quality\ncandidate plans based on the value network via beam search, relaxing precision\nrequirements and narrowing the search space. Stage II employs a fine-grained\nranker to determine the best plan from the candidate plans based on a learned\ncost model. Moreover, to reduce training costs, we reuse and augment the\ntraining data from stage I to train the model in stage II. Experimental results\non three workloads demonstrate that Delta identifies higher-quality plans,\nachieving an average 2.34x speedup over PostgreSQL and outperforming the\nstate-of-the-art learned methods by 2.21x.", "AI": {"tldr": "Delta\u662f\u4e00\u79cd\u6df7\u5408\u6210\u672c\u67e5\u8be2\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u517c\u5bb9\u6027\u68c0\u6d4b\u5668\u548c\u4e24\u9636\u6bb5\u89c4\u5212\u5668\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4f18\u5316\u5668\u7684\u641c\u7d22\u7a7a\u95f4\u7206\u70b8\u548c\u8bad\u7ec3\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u67e5\u8be2\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u67e5\u8be2\u4f18\u5316\u5668\u5b58\u5728\u641c\u7d22\u7a7a\u95f4\u7206\u70b8\u3001\u8bad\u7ec3\u6210\u672c\u9ad8\u548c\u51c6\u786e\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u7f3a\u4e4f\u5bf9\u6027\u80fd\u4e0d\u4f73\u67e5\u8be2\u7684\u68c0\u6d4b\u673a\u5236\u3002", "method": "Delta\u91c7\u7528\u517c\u5bb9\u6027\u68c0\u6d4b\u5668\u8fc7\u6ee4\u4e0d\u517c\u5bb9\u67e5\u8be2\uff0c\u5e76\u901a\u8fc7\u4e24\u9636\u6bb5\u89c4\u5212\u5668\uff08\u7c97\u7c92\u5ea6\u7b5b\u9009\u548c\u7ec6\u7c92\u5ea6\u6392\u5e8f\uff09\u751f\u6210\u9ad8\u6548\u8ba1\u5212\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDelta\u5728\u4e09\u4e2a\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u5e73\u5747\u63d0\u901f2.34\u500d\uff0c\u4f18\u4e8ePostgreSQL\u548c\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "Delta\u901a\u8fc7\u6df7\u5408\u6210\u672c\u4f18\u5316\u548c\u4e24\u9636\u6bb5\u89c4\u5212\uff0c\u663e\u8457\u63d0\u5347\u4e86\u67e5\u8be2\u4f18\u5316\u6548\u7387\u548c\u8ba1\u5212\u8d28\u91cf\u3002"}}
{"id": "2506.15986", "pdf": "https://arxiv.org/pdf/2506.15986", "abs": "https://arxiv.org/abs/2506.15986", "authors": ["Jiancheng Ruan", "Tingyang Chen", "Renchi Yang", "Xiangyu Ke", "Yunjun Gao"], "title": "Empowering Graph-based Approximate Nearest Neighbor Search with Adaptive Awareness Capabilities", "categories": ["cs.DB", "cs.IR"], "comment": "Accecpted by KDD2025", "summary": "Approximate Nearest Neighbor Search (ANNS) in high-dimensional spaces finds\nextensive applications in databases, information retrieval, recommender\nsystems, etc. While graph-based methods have emerged as the leading solution\nfor ANNS due to their superior query performance, they still face several\nchallenges, such as struggling with local optima and redundant computations.\nThese issues arise because existing methods (i) fail to fully exploit the\ntopological information underlying the proximity graph G, and (ii) suffer from\nsevere distribution mismatches between the base data and queries in practice.\n  To this end, this paper proposes GATE, high-tier proximity Graph with\nAdaptive Topology and Query AwarEness, as a lightweight and adaptive module\natop the graph-based indexes to accelerate ANNS. Specifically, GATE formulates\nthe critical problem to identify an optimal entry point in the proximity graph\nfor a given query, facilitating faster online search. By leveraging the\ninherent clusterability of high-dimensional data, GATE first extracts a small\nset of hub nodes V as candidate entry points. Then, resorting to a contrastive\nlearning-based two-tower model, GATE encodes both the structural semantics\nunderlying G and the query-relevant features into the latent representations of\nthese hub nodes V. A navigation graph index on V is further constructed to\nminimize the model inference overhead. Extensive experiments demonstrate that\nGATE achieves a 1.2-2.0X speed-up in query performance compared to\nstate-of-the-art graph-based indexes.", "AI": {"tldr": "GATE\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u9ad8\u7ef4\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u62d3\u6251\u548c\u67e5\u8be2\u611f\u77e5\u4f18\u5316\u67e5\u8be2\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u56fe\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u62d3\u6251\u4fe1\u606f\u4e14\u5b58\u5728\u6570\u636e\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\u3002", "method": "GATE\u5229\u7528\u4e2d\u5fc3\u8282\u70b9\u548c\u5bf9\u6bd4\u5b66\u4e60\u6a21\u578b\u4f18\u5316\u5165\u53e3\u70b9\u9009\u62e9\uff0c\u6784\u5efa\u5bfc\u822a\u56fe\u7d22\u5f15\u3002", "result": "\u5b9e\u9a8c\u8868\u660eGATE\u67e5\u8be2\u6027\u80fd\u63d0\u53471.2-2.0\u500d\u3002", "conclusion": "GATE\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6a21\u5757\u663e\u8457\u63d0\u5347\u56fe\u7d22\u5f15\u7684\u67e5\u8be2\u6548\u7387\u3002"}}
{"id": "2506.15987", "pdf": "https://arxiv.org/pdf/2506.15987", "abs": "https://arxiv.org/abs/2506.15987", "authors": ["Alireza Heidari", "Wei Zhang"], "title": "Filter-Centric Vector Indexing: Geometric Transformation for Efficient Filtered Vector Search", "categories": ["cs.DB", "math.MG"], "comment": "9 pages", "summary": "The explosive growth of vector search applications demands efficient handling\nof combined vector similarity and attribute filtering; a challenge where\ncurrent approaches force an unsatisfying choice between performance and\naccuracy. We introduce Filter-Centric Vector Indexing (FCVI), a novel framework\nthat transforms this fundamental trade-off by directly encoding filter\nconditions into the vector space through a mathematically principled\ntransformation $\\psi(v, f, \\alpha)$. Unlike specialized solutions, FCVI works\nwith any existing vector index (HNSW, FAISS, ANNOY) while providing theoretical\nguarantees on accuracy. Our comprehensive evaluation demonstrates that FCVI\nachieves 2.6-3.0 times higher throughput than state-of-the-art methods while\nmaintaining comparable recall. More remarkably, FCVI exhibits exceptional\nstability under distribution shifts; maintaining consistent performance when\nfilter patterns or vector distributions change, unlike traditional approaches\nthat degrade significantly. This combination of performance, compatibility, and\nresilience positions FCVI as an immediately applicable solution for production\nvector search systems requiring flexible filtering capabilities.", "AI": {"tldr": "FCVI\u662f\u4e00\u79cd\u65b0\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u5b66\u53d8\u6362\u5c06\u8fc7\u6ee4\u6761\u4ef6\u76f4\u63a5\u7f16\u7801\u5230\u5411\u91cf\u7a7a\u95f4\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5411\u91cf\u641c\u7d22\u7684\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u5f53\u524d\u5411\u91cf\u641c\u7d22\u5e94\u7528\u4e2d\uff0c\u6027\u80fd\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u4e9f\u5f85\u89e3\u51b3\uff0c\u9700\u8981\u4e00\u79cd\u517c\u5bb9\u6027\u5f3a\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faFilter-Centric Vector Indexing (FCVI)\uff0c\u901a\u8fc7\u6570\u5b66\u53d8\u6362\u03c8(v, f, \u03b1)\u5c06\u8fc7\u6ee4\u6761\u4ef6\u7f16\u7801\u5230\u5411\u91cf\u7a7a\u95f4\uff0c\u517c\u5bb9\u73b0\u6709\u5411\u91cf\u7d22\u5f15\u3002", "result": "FCVI\u6bd4\u73b0\u6709\u65b9\u6cd5\u541e\u5410\u91cf\u9ad82.6-3.0\u500d\uff0c\u53ec\u56de\u7387\u76f8\u5f53\uff0c\u4e14\u5728\u5206\u5e03\u53d8\u5316\u65f6\u8868\u73b0\u7a33\u5b9a\u3002", "conclusion": "FCVI\u56e0\u5176\u9ad8\u6027\u80fd\u3001\u517c\u5bb9\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u9002\u7528\u4e8e\u9700\u8981\u7075\u6d3b\u8fc7\u6ee4\u7684\u751f\u4ea7\u7ea7\u5411\u91cf\u641c\u7d22\u7cfb\u7edf\u3002"}}
{"id": "2506.15961", "pdf": "https://arxiv.org/pdf/2506.15961", "abs": "https://arxiv.org/abs/2506.15961", "authors": ["Yunchi Lu", "Youshan Miao", "Cheng Tan", "Peng Huang", "Yi Zhu", "Xian Zhang", "Fan Yang"], "title": "TrainVerify: Equivalence-Based Verification for Distributed LLM Training", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": null, "summary": "Training large language models (LLMs) at scale requires parallel execution\nacross thousands of devices, incurring enormous computational costs. Yet, these\ncostly distributed trainings are rarely verified, leaving them prone to silent\nerrors and potentially wasting millions of GPU hours. We introduce TrainVerify,\na system for verifiable distributed training of LLMs. Given a deep learning\nmodel's logical specification as the ground truth, TrainVerify formally\nverifies that a distributed parallel execution plan is mathematically\nequivalent to it. Direct verification is notoriously difficult due to the sheer\nscale of LLMs which often involves billions of variables and highly intricate\ncomputation graphs. Therefore, TrainVerify introduces shape-reduction\ntechniques and a stage-wise parallel verification algorithm that significantly\nreduces complexity while preserving formal correctness. TrainVerify scales to\nfrontier LLMs, including the successful verification of the Llama3 (405B) and\nDeepSeek-V3 (671B) training plans.", "AI": {"tldr": "TrainVerify\u662f\u4e00\u4e2a\u7528\u4e8e\u9a8c\u8bc1\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5206\u5e03\u5f0f\u8bad\u7ec3\u7684\u7cfb\u7edf\uff0c\u786e\u4fdd\u5e76\u884c\u6267\u884c\u8ba1\u5212\u4e0e\u903b\u8f91\u89c4\u8303\u4e00\u81f4\uff0c\u907f\u514d\u9519\u8bef\u548c\u8d44\u6e90\u6d6a\u8d39\u3002", "motivation": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6210\u672c\u9ad8\u6602\u4e14\u7f3a\u4e4f\u9a8c\u8bc1\uff0c\u5bb9\u6613\u5bfc\u81f4\u9519\u8bef\u548c\u8d44\u6e90\u6d6a\u8d39\u3002", "method": "\u901a\u8fc7\u5f62\u72b6\u7f29\u51cf\u6280\u672f\u548c\u5206\u9636\u6bb5\u5e76\u884c\u9a8c\u8bc1\u7b97\u6cd5\uff0c\u964d\u4f4e\u9a8c\u8bc1\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u5f62\u5f0f\u6b63\u786e\u6027\u3002", "result": "\u6210\u529f\u9a8c\u8bc1\u4e86Llama3\uff08405B\uff09\u548cDeepSeek-V3\uff08671B\uff09\u7b49\u524d\u6cbf\u6a21\u578b\u7684\u8bad\u7ec3\u8ba1\u5212\u3002", "conclusion": "TrainVerify\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u9a8c\u8bc1\u65b9\u6cd5\u3002"}}
{"id": "2506.15884", "pdf": "https://arxiv.org/pdf/2506.15884", "abs": "https://arxiv.org/abs/2506.15884", "authors": ["Shamse Tasnim Cynthia", "Nuri Almarimi", "Banani Roy"], "title": "How Do Community Smells Influence Self-Admitted Technical Debt in Machine Learning Projects?", "categories": ["cs.SE"], "comment": null, "summary": "Community smells reflect poor organizational practices that often lead to\nsocio-technical issues and the accumulation of Self-Admitted Technical Debt\n(SATD). While prior studies have explored these problems in general software\nsystems, their interplay in machine learning (ML)-based projects remains\nlargely underexamined. In this study, we investigated the prevalence of\ncommunity smells and their relationship with SATD in open-source ML projects,\nanalyzing data at the release level. First, we examined the prevalence of ten\ncommunity smell types across the releases of 155 ML-based systems and found\nthat community smells are widespread, exhibiting distinct distribution patterns\nacross small, medium, and large projects. Second, we detected SATD at the\nrelease level and applied statistical analysis to examine its correlation with\ncommunity smells. Our results showed that certain smells, such as Radio Silence\nand Organizational Silos, are strongly correlated with higher SATD occurrences.\nThird, we considered the six identified types of SATD to determine which\ncommunity smells are most associated with each debt category. Our analysis\nrevealed authority- and communication-related smells often co-occur with\npersistent code and design debt. Finally, we analyzed how the community smells\nand SATD evolve over the releases, uncovering project size-dependent trends and\nshared trajectories. Our findings emphasize the importance of early detection\nand mitigation of socio-technical issues to maintain the long-term quality and\nsustainability of ML-based systems.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5f00\u6e90ML\u9879\u76ee\u4e2d\u793e\u533a\u6c14\u5473\u4e0e\u81ea\u8ba4\u6280\u672f\u503a\u52a1\uff08SATD\uff09\u7684\u5173\u7cfb\uff0c\u53d1\u73b0\u67d0\u4e9b\u6c14\u5473\u4e0eSATD\u5f3a\u76f8\u5173\uff0c\u5e76\u5206\u6790\u4e86\u5176\u6f14\u5316\u8d8b\u52bf\u3002", "motivation": "\u63a2\u7d22ML\u9879\u76ee\u4e2d\u793e\u533a\u6c14\u5473\u4e0eSATD\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u5206\u6790\u4e86155\u4e2aML\u7cfb\u7edf\u7684\u53d1\u5e03\u6570\u636e\uff0c\u68c0\u6d4b\u793e\u533a\u6c14\u5473\u548cSATD\uff0c\u5e76\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u548c\u6f14\u5316\u8d8b\u52bf\u7814\u7a76\u3002", "result": "\u53d1\u73b0Radio Silence\u548cOrganizational Silos\u7b49\u6c14\u5473\u4e0eSATD\u5f3a\u76f8\u5173\uff0c\u4e14\u6c14\u5473\u548cSATD\u7684\u6f14\u5316\u4e0e\u9879\u76ee\u89c4\u6a21\u76f8\u5173\u3002", "conclusion": "\u65e9\u671f\u68c0\u6d4b\u548c\u7f13\u89e3\u793e\u533a\u6c14\u5473\u5bf9ML\u7cfb\u7edf\u7684\u957f\u671f\u8d28\u91cf\u548c\u53ef\u6301\u7eed\u6027\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2506.15793", "pdf": "https://arxiv.org/pdf/2506.15793", "abs": "https://arxiv.org/abs/2506.15793", "authors": ["Ruipeng Liu", "Qinru Qiu", "Simon Khan", "Garrett E. Katz"], "title": "Linearithmic Clean-up for Vector-Symbolic Key-Value Memory with Kroneker Rotation Products", "categories": ["cs.DS", "cs.AI"], "comment": "10 pages, 10 figures, conference paper", "summary": "A computational bottleneck in current Vector-Symbolic Architectures (VSAs) is\nthe ``clean-up'' step, which decodes the noisy vectors retrieved from the\narchitecture. Clean-up typically compares noisy vectors against a ``codebook''\nof prototype vectors, incurring computational complexity that is quadratic or\nsimilar. We present a new codebook representation that supports efficient\nclean-up, based on Kroneker products of rotation-like matrices. The resulting\nclean-up time complexity is linearithmic, i.e. $\\mathcal{O}(N\\,\\text{log}\\,N)$,\nwhere $N$ is the vector dimension and also the number of vectors in the\ncodebook. Clean-up space complexity is $\\mathcal{O}(N)$. Furthermore, the\ncodebook is not stored explicitly in computer memory: It can be represented in\n$\\mathcal{O}(\\text{log}\\,N)$ space, and individual vectors in the codebook can\nbe materialized in $\\mathcal{O}(N)$ time and space. At the same time,\nasymptotic memory capacity remains comparable to standard approaches. Computer\nexperiments confirm these results, demonstrating several orders of magnitude\nmore scalability than baseline VSA techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eKronecker\u4e58\u79ef\u65cb\u8f6c\u77e9\u9635\u7684\u65b0\u4ee3\u7801\u672c\u8868\u793a\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86VSA\u4e2d\u6e05\u7406\u6b65\u9aa4\u7684\u6548\u7387\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dVSA\u4e2d\u7684\u6e05\u7406\u6b65\u9aa4\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u6210\u4e3a\u6027\u80fd\u74f6\u9888\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528Kronecker\u4e58\u79ef\u7684\u65cb\u8f6c\u77e9\u9635\u8868\u793a\u4ee3\u7801\u672c\uff0c\u5b9e\u73b0\u7ebf\u6027\u5bf9\u6570\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u7ebf\u6027\u7a7a\u95f4\u590d\u6742\u5ea6\u7684\u6e05\u7406\u3002", "result": "\u6e05\u7406\u6b65\u9aa4\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(N log N)\uff0c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3aO(N)\uff0c\u4ee3\u7801\u672c\u5b58\u50a8\u4ec5\u9700O(log N)\u7a7a\u95f4\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86VSA\u7684\u6269\u5c55\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u6280\u672f\u3002"}}
{"id": "2506.15685", "pdf": "https://arxiv.org/pdf/2506.15685", "abs": "https://arxiv.org/abs/2506.15685", "authors": ["Wang Yu-Hang", "Liu ying", "Fang liang", "Wang Xuelin", "Junkang Guo", "Shiwei Li", "Lei Gao", "Jian Liu", "Wenfei Yin"], "title": "Ignition Phase : Standard Training for Fast Adversarial Robustness", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Adversarial Training (AT) is a cornerstone defense, but many variants\noverlook foundational feature representations by primarily focusing on stronger\nattack generation. We introduce Adversarial Evolution Training (AET), a simple\nyet powerful framework that strategically prepends an Empirical Risk\nMinimization (ERM) phase to conventional AT. We hypothesize this initial ERM\nphase cultivates a favorable feature manifold, enabling more efficient and\neffective robustness acquisition. Empirically, AET achieves comparable or\nsuperior robustness more rapidly, improves clean accuracy, and cuts training\ncosts by 8-25\\%. Its effectiveness is shown across multiple datasets,\narchitectures, and when augmenting established AT methods. Our findings\nunderscore the impact of feature pre-conditioning via standard training for\ndeveloping more efficient, principled robust defenses. Code is available in the\nsupplementary material.", "AI": {"tldr": "AET\u901a\u8fc7\u5728\u4f20\u7edf\u5bf9\u6297\u8bad\u7ec3\u524d\u52a0\u5165ERM\u9636\u6bb5\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u548c\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\u8fc7\u4e8e\u5173\u6ce8\u653b\u51fb\u751f\u6210\uff0c\u5ffd\u7565\u4e86\u57fa\u7840\u7279\u5f81\u8868\u793a\u7684\u91cd\u8981\u6027\u3002", "method": "\u63d0\u51faAET\u6846\u67b6\uff0c\u5728\u5bf9\u6297\u8bad\u7ec3\u524d\u52a0\u5165ERM\u9636\u6bb5\u4ee5\u4f18\u5316\u7279\u5f81\u6d41\u5f62\u3002", "result": "AET\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u67b6\u6784\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u8bad\u7ec3\u6210\u672c\u964d\u4f4e8-25%\uff0c\u4e14\u9c81\u68d2\u6027\u548c\u51c6\u786e\u7387\u63d0\u5347\u3002", "conclusion": "\u7279\u5f81\u9884\u6761\u4ef6\u5316\u5bf9\u9ad8\u6548\u9c81\u68d2\u9632\u5fa1\u81f3\u5173\u91cd\u8981\uff0cAET\u4e3a\u5bf9\u6297\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.15947", "pdf": "https://arxiv.org/pdf/2506.15947", "abs": "https://arxiv.org/abs/2506.15947", "authors": ["Jinbo Wen", "Cheng Su", "Jiawen Kang", "Jiangtian Nie", "Yang Zhang", "Jianhang Tang", "Dusit Niyato", "Chau Yuen"], "title": "HybridRAG-based LLM Agents for Low-Carbon Optimization in Low-Altitude Economy Networks", "categories": ["cs.NI", "eess.SP"], "comment": null, "summary": "Low-Altitude Economy Networks (LAENets) are emerging as a promising paradigm\nto support various low-altitude services through integrated air-ground\ninfrastructure. To satisfy low-latency and high-computation demands, the\nintegration of Unmanned Aerial Vehicles (UAVs) with Mobile Edge Computing (MEC)\nsystems plays a vital role, which offloads computing tasks from terminal\ndevices to nearby UAVs, enabling flexible and resilient service provisions for\nground users. To promote the development of LAENets, it is significant to\nachieve low-carbon multi-UAV-assisted MEC networks. However, several challenges\nhinder this implementation, including the complexity of multi-dimensional UAV\nmodeling and the difficulty of multi-objective coupled optimization. To this\nend, this paper proposes a novel Retrieval Augmented Generation (RAG)-based\nLarge Language Model (LLM) agent framework for model formulation. Specifically,\nwe develop HybridRAG by combining KeywordRAG, VectorRAG, and GraphRAG,\nempowering LLM agents to efficiently retrieve structural information from\nexpert databases and generate more accurate optimization problems compared with\ntraditional RAG-based LLM agents. After customizing carbon emission\noptimization problems for multi-UAV-assisted MEC networks, we propose a Double\nRegularization Diffusion-enhanced Soft Actor-Critic (R\\textsuperscript{2}DSAC)\nalgorithm to solve the formulated multi-objective optimization problem. The\nR\\textsuperscript{2}DSAC algorithm incorporates diffusion entropy\nregularization and action entropy regularization to improve the performance of\nthe diffusion policy. Furthermore, we dynamically mask unimportant neurons in\nthe actor network to reduce the carbon emissions associated with model\ntraining. Simulation results demonstrate the effectiveness and reliability of\nthe proposed HybridRAG-based LLM agent framework and the\nR\\textsuperscript{2}DSAC algorithm.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u6846\u67b6\uff08HybridRAG\uff09\u548c\u53cc\u6b63\u5219\u5316\u6269\u6563\u589e\u5f3a\u8f6f\u884c\u52a8\u8005-\u8bc4\u8bba\u5bb6\uff08R\u00b2DSAC\uff09\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u65e0\u4eba\u673a\u8f85\u52a9\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\uff08MEC\uff09\u7f51\u7edc\u4e2d\u7684\u4f4e\u78b3\u4f18\u5316\u95ee\u9898\u3002", "motivation": "\u4f4e\u7a7a\u7ecf\u6d4e\u7f51\u7edc\uff08LAENets\uff09\u9700\u8981\u6ee1\u8db3\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u8ba1\u7b97\u9700\u6c42\uff0c\u4f46\u591a\u65e0\u4eba\u673a\u5efa\u6a21\u7684\u590d\u6742\u6027\u548c\u591a\u76ee\u6807\u8026\u5408\u4f18\u5316\u7684\u96be\u5ea6\u963b\u788d\u4e86\u5176\u53d1\u5c55\u3002", "method": "\u5f00\u53d1\u4e86HybridRAG\u6846\u67b6\uff08\u7ed3\u5408KeywordRAG\u3001VectorRAG\u548cGraphRAG\uff09\uff0c\u5e76\u63d0\u51faR\u00b2DSAC\u7b97\u6cd5\uff08\u7ed3\u5408\u6269\u6563\u71b5\u6b63\u5219\u5316\u548c\u52a8\u4f5c\u71b5\u6b63\u5219\u5316\uff09\u6765\u89e3\u51b3\u4f18\u5316\u95ee\u9898\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cHybridRAG\u6846\u67b6\u548cR\u00b2DSAC\u7b97\u6cd5\u5728\u4f4e\u78b3\u4f18\u5316\u95ee\u9898\u4e0a\u5177\u6709\u9ad8\u6548\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u591a\u65e0\u4eba\u673a\u8f85\u52a9MEC\u7f51\u7edc\u7684\u4f4e\u78b3\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86LAENets\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.16007", "pdf": "https://arxiv.org/pdf/2506.16007", "abs": "https://arxiv.org/abs/2506.16007", "authors": ["Peizhi Wu", "Rong Kang", "Tieying Zhang", "Jianjun Chen", "Ryan Marcus", "Zachary G. Ives"], "title": "Data-Agnostic Cardinality Learning from Imperfect Workloads", "categories": ["cs.DB", "cs.LG"], "comment": "14 pages. Technical Report (Extended Version)", "summary": "Cardinality estimation (CardEst) is a critical aspect of query optimization.\nTraditionally, it leverages statistics built directly over the data. However,\norganizational policies (e.g., regulatory compliance) may restrict global data\naccess. Fortunately, query-driven cardinality estimation can learn CardEst\nmodels using query workloads. However, existing query-driven models often\nrequire access to data or summaries for best performance, and they assume\nperfect training workloads with complete and balanced join templates (or join\ngraphs). Such assumptions rarely hold in real-world scenarios, in which join\ntemplates are incomplete and imbalanced. We present GRASP, a data-agnostic\ncardinality learning system designed to work under these real-world\nconstraints. GRASP's compositional design generalizes to unseen join templates\nand is robust to join template imbalance. It also introduces a new per-table\nCardEst model that handles value distribution shifts for range predicates, and\na novel learned count sketch model that captures join correlations across base\nrelations. Across three database instances, we demonstrate that GRASP\nconsistently outperforms existing query-driven models on imperfect workloads,\nboth in terms of estimation accuracy and query latency. Remarkably, GRASP\nachieves performance comparable to, or even surpassing, traditional approaches\nbuilt over the underlying data on the complex CEB-IMDb-full benchmark --\ndespite operating without any data access and using only 10% of all possible\njoin templates.", "AI": {"tldr": "GRASP\u662f\u4e00\u79cd\u6570\u636e\u65e0\u5173\u7684\u57fa\u6570\u4f30\u8ba1\u7cfb\u7edf\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u4e0d\u5b8c\u6574\u548c\u4e0d\u5e73\u8861\u67e5\u8be2\u8d1f\u8f7d\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u57fa\u6570\u4f30\u8ba1\u65b9\u6cd5\u4f9d\u8d56\u5168\u5c40\u6570\u636e\u8bbf\u95ee\uff0c\u4f46\u53d7\u9650\u4e8e\u7ec4\u7ec7\u653f\u7b56\uff1b\u73b0\u6709\u67e5\u8be2\u9a71\u52a8\u6a21\u578b\u5047\u8bbe\u7406\u60f3\u8bad\u7ec3\u8d1f\u8f7d\uff0c\u4e0d\u9002\u7528\u4e8e\u73b0\u5b9e\u573a\u666f\u3002", "method": "GRASP\u91c7\u7528\u7ec4\u5408\u8bbe\u8ba1\uff0c\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u8fde\u63a5\u6a21\u677f\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u6bcf\u8868\u57fa\u6570\u4f30\u8ba1\u6a21\u578b\u548c\u8ba1\u6570\u8349\u56fe\u6a21\u578b\u3002", "result": "GRASP\u5728\u4e09\u4e2a\u6570\u636e\u5e93\u5b9e\u4f8b\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5728\u590d\u6742\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u63a5\u8fd1\u6216\u8d85\u8fc7\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "GRASP\u5728\u65e0\u6570\u636e\u8bbf\u95ee\u548c\u6709\u9650\u8bad\u7ec3\u8d1f\u8f7d\u4e0b\u4ecd\u80fd\u5b9e\u73b0\u9ad8\u6027\u80fd\u57fa\u6570\u4f30\u8ba1\u3002"}}
{"id": "2506.15993", "pdf": "https://arxiv.org/pdf/2506.15993", "abs": "https://arxiv.org/abs/2506.15993", "authors": ["Yiwei Yang", "Yusheng Zheng", "Tong Yu", "Andi Quinn"], "title": "HetGPU: The pursuit of making binary compatibility towards GPUs", "categories": ["cs.AR", "cs.DC"], "comment": null, "summary": "Heterogeneous GPU infrastructures present a binary compatibility challenge:\ncode compiled for one vendor's GPU will not run on another due to divergent\ninstruction sets, execution models, and driver stacks . We propose hetGPU, a\nnew system comprising a compiler, runtime, and abstraction layer that together\nenable a single GPU binary to execute on NVIDIA, AMD, Intel, and Tenstorrent\nhardware. The hetGPU compiler emits an architecture-agnostic GPU intermediate\nrepresentation (IR) and inserts metadata for managing execution state. The\nhetGPU runtime then dynamically translates this IR to the target GPU's native\ncode and provides a uniform abstraction of threads, memory, and\nsynchronization. Our design tackles key challenges: differing SIMT vs. MIMD\nexecution (warps on NVIDIA/AMD vs. many-core RISC-V on Tenstorrent), varied\ninstruction sets, scheduling and memory model discrepancies, and the need for\nstate serialization for live migration. We detail the hetGPU architecture,\nincluding the IR transformation pipeline, a state capture/reload mechanism for\nlive GPU migration, and an abstraction layer that bridges warp-centric and\ncore-centric designs. Preliminary evaluation demonstrates that unmodified GPU\nbinaries compiled with hetGPU can be migrated across disparate GPUs with\nminimal overhead, opening the door to vendor-agnostic GPU computing.", "AI": {"tldr": "hetGPU\u7cfb\u7edf\u901a\u8fc7\u7f16\u8bd1\u5668\u548c\u8fd0\u884c\u65f6\u52a8\u6001\u7ffb\u8bd1\uff0c\u5b9e\u73b0\u5355\u4e00GPU\u4e8c\u8fdb\u5236\u5728\u591a\u79cd\u786c\u4ef6\u4e0a\u7684\u517c\u5bb9\u6267\u884c\u3002", "motivation": "\u89e3\u51b3\u4e0d\u540c\u5382\u5546GPU\u56e0\u6307\u4ee4\u96c6\u3001\u6267\u884c\u6a21\u578b\u548c\u9a71\u52a8\u6808\u5dee\u5f02\u5bfc\u81f4\u7684\u4e8c\u8fdb\u5236\u517c\u5bb9\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fahetGPU\u7cfb\u7edf\uff0c\u5305\u62ec\u7f16\u8bd1\u5668\u751f\u6210\u67b6\u6784\u65e0\u5173\u7684\u4e2d\u95f4\u8868\u793a\uff08IR\uff09\u548c\u8fd0\u884c\u65f6\u52a8\u6001\u7ffb\u8bd1\u4e3a\u76ee\u6807GPU\u539f\u751f\u4ee3\u7801\u3002", "result": "\u521d\u6b65\u8bc4\u4f30\u663e\u793a\uff0c\u672a\u4fee\u6539\u7684GPU\u4e8c\u8fdb\u5236\u53ef\u5728\u4e0d\u540cGPU\u95f4\u8fc1\u79fb\uff0c\u5f00\u9500\u6781\u5c0f\u3002", "conclusion": "hetGPU\u4e3a\u5382\u5546\u65e0\u5173\u7684GPU\u8ba1\u7b97\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
{"id": "2506.16101", "pdf": "https://arxiv.org/pdf/2506.16101", "abs": "https://arxiv.org/abs/2506.16101", "authors": ["Yupeng Jiang", "Shuaiyi Sun", "Xi Zheng"], "title": "Regression Testing Optimization for ROS-based Autonomous Systems: A Comprehensive Review of Techniques", "categories": ["cs.SE"], "comment": null, "summary": "Regression testing plays a critical role in maintaining software reliability,\nparticularly for ROS-based autonomous systems (ROSAS), which frequently undergo\ncontinuous integration and iterative development. However, conventional\nregression testing techniques face significant challenges when applied to\nautonomous systems due to their dynamic and non-deterministic behaviors,\ncomplex multi-modal sensor data, asynchronous distributed architectures, and\nstringent safety and real-time constraints. Although numerous studies have\nexplored test optimization in traditional software contexts, regression testing\noptimization specifically for ROSAS remains largely unexplored. To address this\ngap, we present the first comprehensive survey systematically reviewing\nregression testing optimization techniques tailored for ROSAS. We analyze and\ncategorize 122 representative studies into regression test case prioritization,\nminimization, and selection methods. A structured taxonomy is introduced to\nclearly illustrate their applicability and limitations within ROSAS contexts.\nFurthermore, we highlight major challenges specific to regression testing for\nROSAS, including effectively prioritizing tests in response to frequent system\nmodifications, efficiently minimizing redundant tests, and difficulty in\naccurately selecting impacted test cases. Finally, we propose research insights\nand identify promising future directions, such as leveraging frame-to-vector\ncoverage metrics, multi-source foundation models, and neurosymbolic reasoning\nto enhance regression testing efficiency and effectiveness. This survey\nprovides a foundational reference and practical roadmap for advancing the\nstate-of-the-art in regression testing optimization for ROSAS.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u9488\u5bf9ROS\u81ea\u4e3b\u7cfb\u7edf\uff08ROSAS\uff09\u7684\u56de\u5f52\u6d4b\u8bd5\u4f18\u5316\u6280\u672f\uff0c\u5206\u6790\u4e86122\u9879\u7814\u7a76\uff0c\u5206\u7c7b\u4e3a\u6d4b\u8bd5\u7528\u4f8b\u4f18\u5148\u7ea7\u3001\u6700\u5c0f\u5316\u548c\u9009\u62e9\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4f20\u7edf\u56de\u5f52\u6d4b\u8bd5\u6280\u672f\u5728ROSAS\u4e2d\u9762\u4e34\u52a8\u6001\u884c\u4e3a\u3001\u590d\u6742\u6570\u636e\u7ed3\u6784\u548c\u5b9e\u65f6\u6027\u7b49\u6311\u6218\uff0c\u76f8\u5173\u4f18\u5316\u7814\u7a76\u8f83\u5c11\uff0c\u9700\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0122\u9879\u7814\u7a76\uff0c\u5206\u7c7b\u5e76\u5206\u6790\u56de\u5f52\u6d4b\u8bd5\u4f18\u5316\u6280\u672f\uff0c\u63d0\u51fa\u7ed3\u6784\u5316\u5206\u7c7b\u6cd5\uff0c\u5e76\u8ba8\u8bba\u5176\u9002\u7528\u6027\u548c\u5c40\u9650\u6027\u3002", "result": "\u603b\u7ed3\u4e86ROSAS\u56de\u5f52\u6d4b\u8bd5\u7684\u4e3b\u8981\u6311\u6218\uff0c\u5982\u6d4b\u8bd5\u4f18\u5148\u7ea7\u3001\u5197\u4f59\u6d4b\u8bd5\u6700\u5c0f\u5316\u548c\u53d7\u5f71\u54cd\u6d4b\u8bd5\u7528\u4f8b\u9009\u62e9\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u4e3aROSAS\u56de\u5f52\u6d4b\u8bd5\u4f18\u5316\u63d0\u4f9b\u4e86\u57fa\u7840\u53c2\u8003\u548c\u5b9e\u8df5\u8def\u7ebf\u56fe\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u6280\u672f\u53d1\u5c55\u3002"}}
{"id": "2506.15844", "pdf": "https://arxiv.org/pdf/2506.15844", "abs": "https://arxiv.org/abs/2506.15844", "authors": ["Tianyu Zhao", "Dongfang Zhao", "Luanzheng Guo", "Nathan Tallent"], "title": "HybHuff: Lossless Compression for Hypergraphs via Entropy-Guided Huffman-Bitwise Coordination", "categories": ["cs.DS"], "comment": null, "summary": "Hypergraphs provide a natural representation for many-to-many relationships\nin data-intensive applications, yet their scalability is often hindered by high\nmemory consumption. While prior work has improved computational efficiency,\nreducing the space overhead of hypergraph representations remains a major\nchallenge. This paper presents a hybrid compression framework for integer-based\nhypergraph adjacency formats, which adaptively combines Huffman encoding and\nbitwise encoding to exploit structural redundancy. We provide a theoretical\nanalysis showing that an optimal encoding ratio exists between the two schemes,\nand introduce an empirical strategy to approximate this ratio for practical\nuse. Experiments on real-world hypergraphs demonstrate that our method\nconsistently outperforms standard compressors such as Zip and ZFP in\ncompression rate by up to 2.3x with comparable decoding overhead. To assess\npractical utility, we integrate our framework with three common hypergraph\nworkloads: breadth-first search, PageRank, and k-core label propagation, and\nshow that compression incurs negligible performance loss. Extensive evaluations\nacross four benchmark datasets confirm the efficiency and applicability of our\napproach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u538b\u7f29\u6846\u67b6\uff0c\u7ed3\u5408Huffman\u7f16\u7801\u548c\u4f4d\u7f16\u7801\uff0c\u663e\u8457\u964d\u4f4e\u8d85\u56fe\u7684\u5185\u5b58\u5360\u7528\uff0c\u538b\u7f29\u7387\u4f18\u4e8eZip\u548cZFP\u3002", "motivation": "\u8d85\u56fe\u5728\u6570\u636e\u5bc6\u96c6\u578b\u5e94\u7528\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u9ad8\u5185\u5b58\u5360\u7528\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u6709\u6240\u6539\u8fdb\uff0c\u4f46\u7a7a\u95f4\u5f00\u9500\u4ecd\u662f\u4e3b\u8981\u6311\u6218\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u538b\u7f29\u6846\u67b6\uff0c\u7ed3\u5408Huffman\u7f16\u7801\u548c\u4f4d\u7f16\u7801\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u786e\u5b9a\u6700\u4f18\u7f16\u7801\u6bd4\u4f8b\uff0c\u5e76\u5f15\u5165\u7ecf\u9a8c\u7b56\u7565\u8fd1\u4f3c\u8be5\u6bd4\u4f8b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u538b\u7f29\u7387\u6bd4Zip\u548cZFP\u9ad82.3\u500d\uff0c\u89e3\u7801\u5f00\u9500\u76f8\u5f53\u3002\u5728\u5e38\u89c1\u8d85\u56fe\u4efb\u52a1\u4e2d\u6027\u80fd\u635f\u5931\u53ef\u5ffd\u7565\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9ad8\u6548\u4e14\u5b9e\u7528\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u8d85\u56fe\u4efb\u52a1\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u5360\u7528\u3002"}}
{"id": "2506.15686", "pdf": "https://arxiv.org/pdf/2506.15686", "abs": "https://arxiv.org/abs/2506.15686", "authors": ["Jiahe Qin", "Junpeng Li", "Changchun Hua", "Yana Yang"], "title": "Learning from M-Tuple Dominant Positive and Unlabeled Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Label Proportion Learning (LLP) addresses the classification problem where\nmultiple instances are grouped into bags and each bag contains information\nabout the proportion of each class. However, in practical applications,\nobtaining precise supervisory information regarding the proportion of instances\nin a specific class is challenging. To better align with real-world application\nscenarios and effectively leverage the proportional constraints of instances\nwithin tuples, this paper proposes a generalized learning framework\n\\emph{MDPU}. Specifically, we first mathematically model the distribution of\ninstances within tuples of arbitrary size, under the constraint that the number\nof positive instances is no less than that of negative instances. Then we\nderive an unbiased risk estimator that satisfies risk consistency based on the\nempirical risk minimization (ERM) method. To mitigate the inevitable\noverfitting issue during training, a risk correction method is introduced,\nleading to the development of a corrected risk estimator. The generalization\nerror bounds of the unbiased risk estimator theoretically demonstrate the\nconsistency of the proposed method. Extensive experiments on multiple datasets\nand comparisons with other relevant baseline methods comprehensively validate\nthe effectiveness of the proposed learning framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5e7f\u4e49\u5b66\u4e60\u6846\u67b6MDPU\uff0c\u7528\u4e8e\u89e3\u51b3\u6807\u7b7e\u6bd4\u4f8b\u5b66\u4e60\uff08LLP\uff09\u4e2d\u5b9e\u4f8b\u6bd4\u4f8b\u4fe1\u606f\u4e0d\u7cbe\u786e\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u6570\u5b66\u5efa\u6a21\u548c\u98ce\u9669\u6821\u6b63\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u83b7\u53d6\u5b9e\u4f8b\u6bd4\u4f8b\u7684\u7cbe\u786e\u76d1\u7763\u4fe1\u606f\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u8d34\u5408\u5b9e\u9645\u573a\u666f\u7684\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u63d0\u51faMDPU\u6846\u67b6\uff0c\u6570\u5b66\u5efa\u6a21\u5b9e\u4f8b\u5206\u5e03\uff0c\u57fa\u4e8eERM\u65b9\u6cd5\u63a8\u5bfc\u65e0\u504f\u98ce\u9669\u4f30\u8ba1\u5668\uff0c\u5e76\u5f15\u5165\u98ce\u9669\u6821\u6b63\u65b9\u6cd5\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86\u65e0\u504f\u98ce\u9669\u4f30\u8ba1\u5668\u7684\u6cdb\u5316\u8bef\u5dee\u8fb9\u754c\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86MDPU\u7684\u6709\u6548\u6027\u3002", "conclusion": "MDPU\u6846\u67b6\u5728LLP\u95ee\u9898\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16409", "pdf": "https://arxiv.org/pdf/2506.16409", "abs": "https://arxiv.org/abs/2506.16409", "authors": ["Mahbubur Rahman", "Abusayeed Saifullah"], "title": "LoRaIN: A Constructive Interference-Assisted Reliable and Energy-Efficient LoRa Indoor Network", "categories": ["cs.NI"], "comment": null, "summary": "LoRa is a promising communication technology for enabling the next-generation\nindoor Internet of Things applications. Very few studies, however, have\nanalyzed its performance indoors. Besides, these indoor studies investigate\nmostly the RSSI and SNR of the received packets at the gateway, which, as we\nshow, may not unfold the poor performance of LoRa and its MAC protocol,\nLoRaWAN, indoors in terms of reliability and energy-efficiency. In this paper,\nwe extensively evaluate the performance of LoRaWAN indoors and then use the key\ninsights to boost its reliability and energy-efficiency by proposing LoRaIN,\nLoRa Indoor Network, a new link-layer protocol that can be effectively used for\nindoor deployments. The approach to boosting the reliability and energy\nefficiency in LoRaIN is underpinned by enabling constructive interference with\nspecific timing requirements analyzed both empirically and mathematically for\ndifferent pairs of channel bandwidth and spreading factor and relaying precious\nacknowledgments to the end-devices with the assistance of several booster\nnodes. The booster nodes do not need any special capability and can be a subset\nof the LoRa end-devices. To our knowledge, LoRaIN is the first protocol for\nboosting reliability and energy-efficiency in indoor LoRa networks. We evaluate\nits performance in an indoor testbed consisting of one LoRaWAN gateway and 20\nend-devices. Our extensive evaluation shows that when 15% of the end-devices\noperate as booster nodes, the reliability at the gateway increases from 62% to\n95%, and the end-devices are approximately 2.5x energy-efficient.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLoRaIN\u534f\u8bae\uff0c\u901a\u8fc7\u6784\u9020\u6027\u5e72\u6270\u548c\u4e2d\u7ee7\u786e\u8ba4\u63d0\u5347\u5ba4\u5185LoRa\u7f51\u7edc\u7684\u53ef\u9760\u6027\u548c\u80fd\u6548\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8f83\u5c11\u5173\u6ce8LoRa\u5728\u5ba4\u5185\u7684\u6027\u80fd\uff0c\u4e14\u4ec5\u5173\u6ce8RSSI\u548cSNR\uff0c\u672a\u63ed\u793a\u5176\u53ef\u9760\u6027\u548c\u80fd\u6548\u95ee\u9898\u3002", "method": "\u63d0\u51faLoRaIN\u534f\u8bae\uff0c\u5229\u7528\u7279\u5b9a\u65f6\u5e8f\u7684\u6784\u9020\u6027\u5e72\u6270\u548c\u4e2d\u7ee7\u786e\u8ba4\uff0c\u901a\u8fc7\u90e8\u5206\u7ec8\u7aef\u8bbe\u5907\u4f5c\u4e3a\u4e2d\u7ee7\u8282\u70b9\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c15%\u7ec8\u7aef\u4f5c\u4e3a\u4e2d\u7ee7\u8282\u70b9\u65f6\uff0c\u7f51\u5173\u53ef\u9760\u6027\u4ece62%\u63d0\u5347\u81f395%\uff0c\u80fd\u6548\u63d0\u9ad82.5\u500d\u3002", "conclusion": "LoRaIN\u662f\u9996\u4e2a\u63d0\u5347\u5ba4\u5185LoRa\u7f51\u7edc\u53ef\u9760\u6027\u548c\u80fd\u6548\u7684\u534f\u8bae\uff0c\u6548\u679c\u663e\u8457\u3002"}}
{"id": "2506.16379", "pdf": "https://arxiv.org/pdf/2506.16379", "abs": "https://arxiv.org/abs/2506.16379", "authors": ["Yan Zhou", "Chunwei Liu", "Bhuvan Urgaonkar", "Zhengle Wang", "Magnus Mueller", "Chao Zhang", "Songyue Zhang", "Pascal Pfeil", "Dominik Horn", "Zhengchun Liu", "Davide Pagano", "Tim Kraska", "Samuel Madden", "Ju Fan"], "title": "PBench: Workload Synthesizer with Real Statistics for Cloud Analytics Benchmarking", "categories": ["cs.DB"], "comment": null, "summary": "Cloud service providers commonly use standard benchmarks like TPC-H and\nTPC-DS to evaluate and optimize cloud data analytics systems. However, these\nbenchmarks rely on fixed query patterns and fail to capture the real execution\nstatistics of production cloud workloads. Although some cloud database vendors\nhave recently released real workload traces, these traces alone do not qualify\nas benchmarks, as they typically lack essential components like the original\nSQL queries and their underlying databases. To overcome this limitation, this\npaper introduces a new problem of workload synthesis with real statistics,\nwhich aims to generate synthetic workloads that closely approximate real\nexecution statistics, including key performance metrics and operator\ndistributions, in real cloud workloads. To address this problem, we propose\nPBench, a novel workload synthesizer that constructs synthetic workloads by\njudiciously selecting and combining workload components (i.e., queries and\ndatabases) from existing benchmarks. This paper studies the key challenges in\nPBench. First, we address the challenge of balancing performance metrics and\noperator distributions by introducing a multi-objective optimization-based\ncomponent selection method. Second, to capture the temporal dynamics of real\nworkloads, we design a timestamp assignment method that progressively refines\nworkload timestamps. Third, to handle the disparity between the original\nworkload and the candidate workload, we propose a component augmentation\napproach that leverages large language models (LLMs) to generate additional\nworkload components while maintaining statistical fidelity. We evaluate PBench\non real cloud workload traces, demonstrating that it reduces approximation\nerror by up to 6x compared to state-of-the-art methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPBench\uff0c\u4e00\u79cd\u65b0\u578b\u5de5\u4f5c\u8d1f\u8f7d\u5408\u6210\u5668\uff0c\u901a\u8fc7\u4f18\u5316\u9009\u62e9\u548c\u7ec4\u5408\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u7ec4\u4ef6\uff0c\u751f\u6210\u63a5\u8fd1\u771f\u5b9e\u4e91\u5de5\u4f5c\u8d1f\u8f7d\u7edf\u8ba1\u6570\u636e\u7684\u5408\u6210\u5de5\u4f5c\u8d1f\u8f7d\u3002", "motivation": "\u73b0\u6709\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982TPC-H\u548cTPC-DS\uff09\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u4e91\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6267\u884c\u7edf\u8ba1\u4fe1\u606f\uff0c\u800c\u4e91\u6570\u636e\u5e93\u4f9b\u5e94\u5546\u53d1\u5e03\u7684\u771f\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u75d5\u8ff9\u53c8\u7f3a\u4e4f\u5173\u952e\u7ec4\u4ef6\uff08\u5982\u539f\u59cbSQL\u67e5\u8be2\u548c\u5e95\u5c42\u6570\u636e\u5e93\uff09\u3002", "method": "\u63d0\u51faPBench\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u9009\u62e9\u7ec4\u4ef6\u3001\u8bbe\u8ba1\u65f6\u95f4\u6233\u5206\u914d\u65b9\u6cd5\u4ee5\u53ca\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u989d\u5916\u7ec4\u4ef6\u6765\u89e3\u51b3\u5de5\u4f5c\u8d1f\u8f7d\u5408\u6210\u95ee\u9898\u3002", "result": "PBench\u5728\u771f\u5b9e\u4e91\u5de5\u4f5c\u8d1f\u8f7d\u75d5\u8ff9\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u5176\u8fd1\u4f3c\u8bef\u5dee\u6bd4\u73b0\u6709\u65b9\u6cd5\u964d\u4f4e\u4e866\u500d\u3002", "conclusion": "PBench\u901a\u8fc7\u5408\u6210\u5de5\u4f5c\u8d1f\u8f7d\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u4e91\u6570\u636e\u7cfb\u7edf\u4f18\u5316\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u7684\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2506.16235", "pdf": "https://arxiv.org/pdf/2506.16235", "abs": "https://arxiv.org/abs/2506.16235", "authors": ["Yisu Wang", "Xinjiao Li", "Ruilong Wu", "Huangxun Chen", "Dirk Kutscher"], "title": "NetSenseML: Network-Adaptive Compression for Efficient Distributed Machine Learning", "categories": ["cs.DC"], "comment": null, "summary": "Training large-scale distributed machine learning models imposes considerable\ndemands on network infrastructure, often resulting in sudden traffic spikes\nthat lead to congestion, increased latency, and reduced throughput, which would\nultimately affect convergence times and overall training performance. While\ngradient compression techniques are commonly employed to alleviate network\nload, they frequently compromise model accuracy due to the loss of gradient\ninformation.\n  This paper introduces NetSenseML, a novel network adaptive distributed deep\nlearning framework that dynamically adjusts quantization, pruning, and\ncompression strategies in response to real-time network conditions. By actively\nmonitoring network conditions, NetSenseML applies gradient compression only\nwhen network congestion negatively impacts convergence speed, thus effectively\nbalancing data payload reduction and model accuracy preservation.\n  Our approach ensures efficient resource usage by adapting reduction\ntechniques based on current network conditions, leading to shorter convergence\ntimes and improved training efficiency. We present the design of the NetSenseML\nadaptive data reduction function and experimental evaluations show that\nNetSenseML can improve training throughput by a factor of 1.55 to 9.84 times\ncompared to state-of-the-art compression-enabled systems for representative DDL\ntraining jobs in bandwidth-constrained conditions.", "AI": {"tldr": "NetSenseML\u662f\u4e00\u79cd\u7f51\u7edc\u81ea\u9002\u5e94\u7684\u5206\u5e03\u5f0f\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u68af\u5ea6\u538b\u7f29\u7b56\u7565\u6765\u5e73\u8861\u7f51\u7edc\u8d1f\u8f7d\u548c\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u673a\u5668\u5b66\u4e60\u8bad\u7ec3\u5bf9\u7f51\u7edc\u57fa\u7840\u8bbe\u65bd\u9700\u6c42\u9ad8\uff0c\u5bb9\u6613\u5bfc\u81f4\u62e5\u585e\u548c\u6027\u80fd\u4e0b\u964d\uff0c\u73b0\u6709\u68af\u5ea6\u538b\u7f29\u6280\u672f\u5e38\u727a\u7272\u6a21\u578b\u7cbe\u5ea6\u3002", "method": "NetSenseML\u5b9e\u65f6\u76d1\u6d4b\u7f51\u7edc\u72b6\u51b5\uff0c\u52a8\u6001\u8c03\u6574\u91cf\u5316\u3001\u526a\u679d\u548c\u538b\u7f29\u7b56\u7565\uff0c\u4ec5\u5728\u7f51\u7edc\u62e5\u585e\u5f71\u54cd\u6536\u655b\u901f\u5ea6\u65f6\u5e94\u7528\u538b\u7f29\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cNetSenseML\u5728\u5e26\u5bbd\u53d7\u9650\u6761\u4ef6\u4e0b\uff0c\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u53471.55\u81f39.84\u500d\u3002", "conclusion": "NetSenseML\u901a\u8fc7\u81ea\u9002\u5e94\u6570\u636e\u538b\u7f29\uff0c\u6709\u6548\u7f29\u77ed\u6536\u655b\u65f6\u95f4\u5e76\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2506.16136", "pdf": "https://arxiv.org/pdf/2506.16136", "abs": "https://arxiv.org/abs/2506.16136", "authors": ["Kai Huang", "Jian Zhang", "Xiaofei Xie", "Chunyang Chen"], "title": "Seeing is Fixing: Cross-Modal Reasoning with Multimodal LLMs for Visual Software Issue Fixing", "categories": ["cs.SE"], "comment": null, "summary": "Large language model-(LLM) based automated program repair (APR) techniques\nhave shown promising results in resolving real-world GitHub issue tasks.\nExisting APR systems are primarily evaluated in unimodal settings (e.g.,\nSWE-bench). However, these autonomous systems struggle to resolve multimodal\nproblem scenarios (e.g., SWE-bench M) due to limitations in interpreting and\nleveraging visual information. In multimodal scenarios, LLMs need to rely on\nvisual information in the graphical user interface (GUI) to understand bugs and\ngenerate fixes. To bridge this gap, we propose GUIRepair, a cross-modal\nreasoning approach for resolving multimodal issue scenarios by understanding\nand capturing visual information. Specifically, GUIRepair integrates two key\ncomponents, Image2Code and Code2Image, to enhance fault comprehension and patch\nvalidation. Image2Code extracts relevant project documents based on the issue\nreport, then applies this domain knowledge to generate the reproduced code\nresponsible for the visual symptoms, effectively translating GUI images into\nexecutable context for better fault comprehension. Code2Image replays the\nvisual issue scenario using the reproduced code and captures GUI renderings of\nthe patched program to assess whether the fix visually resolves the issue,\nproviding feedback for patch validation. We evaluate GUIRepair on SWE-bench M,\nand the approach demonstrates significant effectiveness. When utilizing GPT-4o\nas the base model, GUIRepair solves 157 instances, outperforming the best\nopen-source baseline by 26 instances. Furthermore, when using o4-mini as the\nbase model, GUIRepair can achieve even better results and solve 175 instances,\noutperforming the top commercial system by 22 instances. This emphasizes the\nsuccess of our new perspective on incorporating cross-modal reasoning by\nunderstanding and capturing visual information to resolve multimodal issues.", "AI": {"tldr": "GUIRepair\u662f\u4e00\u79cd\u8de8\u6a21\u6001\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u7406\u89e3\u548c\u5229\u7528\u89c6\u89c9\u4fe1\u606f\u89e3\u51b3\u591a\u6a21\u6001\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u5728\u591a\u6a21\u6001\u573a\u666f\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709APR\u7cfb\u7edf\u5728\u591a\u6a21\u6001\u95ee\u9898\u573a\u666f\uff08\u5982SWE-bench M\uff09\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u56e0\u4e3a\u65e0\u6cd5\u6709\u6548\u5229\u7528\u89c6\u89c9\u4fe1\u606f\u3002GUIRepair\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "GUIRepair\u7ed3\u5408Image2Code\u548cCode2Image\u4e24\u4e2a\u7ec4\u4ef6\uff0c\u524d\u8005\u5c06GUI\u56fe\u50cf\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\u4ee5\u7406\u89e3\u6545\u969c\uff0c\u540e\u8005\u901a\u8fc7\u91cd\u73b0\u89c6\u89c9\u573a\u666f\u9a8c\u8bc1\u4fee\u590d\u6548\u679c\u3002", "result": "\u5728SWE-bench M\u4e0a\uff0cGUIRepair\u8868\u73b0\u4f18\u5f02\uff0c\u4f7f\u7528GPT-4o\u548co4-mini\u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\u65f6\uff0c\u5206\u522b\u89e3\u51b3\u4e86157\u548c175\u4e2a\u5b9e\u4f8b\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "GUIRepair\u901a\u8fc7\u8de8\u6a21\u6001\u63a8\u7406\u6210\u529f\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u95ee\u9898\uff0c\u9a8c\u8bc1\u4e86\u89c6\u89c9\u4fe1\u606f\u5728APR\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.16121", "pdf": "https://arxiv.org/pdf/2506.16121", "abs": "https://arxiv.org/abs/2506.16121", "authors": ["Donghang Cui", "Ronghua Li", "Qiangqiang Dai", "Hongchao Qin", "Guoren Wang"], "title": "On the Efficient Discovery of Maximum $k$-Defective Biclique", "categories": ["cs.DS"], "comment": null, "summary": "The problem of identifying the maximum edge biclique in bipartite graphs has\nattracted considerable attention in bipartite graph analysis, with numerous\nreal-world applications such as fraud detection, community detection, and\nonline recommendation systems. However, real-world graphs may contain noise or\nincomplete information, leading to overly restrictive conditions when employing\nthe biclique model. To mitigate this, we focus on a new relaxed subgraph model,\ncalled the $k$-defective biclique, which allows for up to $k$ missing edges\ncompared to the biclique model. We investigate the problem of finding the\nmaximum edge $k$-defective biclique in a bipartite graph, and prove that the\nproblem is NP-hard. To tackle this computation challenge, we propose a novel\nalgorithm based on a new branch-and-bound framework, which achieves a\nworst-case time complexity of $O(m\\alpha_k^n)$, where $\\alpha_k < 2$. We\nfurther enhance this framework by incorporating a novel pivoting technique,\nreducing the worst-case time complexity to $O(m\\beta_k^n)$, where $\\beta_k <\n\\alpha_k$. To improve the efficiency, we develop a series of optimization\ntechniques, including graph reduction methods, novel upper bounds, and a\nheuristic approach. Extensive experiments on 10 large real-world datasets\nvalidate the efficiency and effectiveness of the proposed approaches. The\nresults indicate that our algorithms consistently outperform state-of-the-art\nalgorithms, offering up to $1000\\times$ speedups across various parameter\nsettings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u677e\u5f1b\u5b50\u56fe\u6a21\u578b\u2014\u2014$k$-defective biclique\uff0c\u7528\u4e8e\u89e3\u51b3\u4e8c\u5206\u56fe\u4e2d\u6700\u5927\u8fb9$k$-defective biclique\u7684\u8bc6\u522b\u95ee\u9898\uff0c\u5e76\u8bc1\u660e\u4e86\u5176NP\u96be\u6027\u3002\u901a\u8fc7\u5206\u652f\u5b9a\u754c\u6846\u67b6\u548c\u65b0\u9896\u7684\u4f18\u5316\u6280\u672f\uff0c\u7b97\u6cd5\u5728\u6548\u7387\u548c\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u4e8c\u5206\u56fe\u5e38\u5305\u542b\u566a\u58f0\u6216\u4e0d\u5b8c\u6574\u4fe1\u606f\uff0c\u4f20\u7edfbiclique\u6a21\u578b\u8fc7\u4e8e\u4e25\u683c\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u5141\u8bb8$k$\u6761\u7f3a\u5931\u8fb9\u7684\u677e\u5f1b\u6a21\u578b\u66f4\u5177\u5b9e\u9645\u610f\u4e49\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5206\u652f\u5b9a\u754c\u6846\u67b6\u7684\u65b0\u7b97\u6cd5\uff0c\u7ed3\u5408\u56fe\u7f29\u51cf\u65b9\u6cd5\u3001\u65b0\u9896\u4e0a\u754c\u548c\u542f\u53d1\u5f0f\u7b56\u7565\uff0c\u4f18\u5316\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7b97\u6cd5\u572810\u4e2a\u5927\u578b\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe1000\u500d\u3002", "conclusion": "$k$-defective biclique\u6a21\u578b\u53ca\u914d\u5957\u7b97\u6cd5\u5728\u566a\u58f0\u73af\u5883\u4e0b\u9ad8\u6548\u4e14\u5b9e\u7528\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2506.15687", "pdf": "https://arxiv.org/pdf/2506.15687", "abs": "https://arxiv.org/abs/2506.15687", "authors": ["Yajie Ji", "Yanlai Chen", "Shawn Koohy"], "title": "S$^2$GPT-PINNs: Sparse and Small models for PDEs", "categories": ["cs.LG", "stat.ML", "65M70, 65N99, 68U99, 68T07"], "comment": "17 pages,6 figures", "summary": "We propose S$^2$GPT-PINN, a sparse and small model for solving parametric\npartial differential equations (PDEs). Similar to Small Language Models (SLMs),\nS$^2$GPT-PINN is tailored to domain-specific (families of) PDEs and\ncharacterized by its compact architecture and minimal computational power.\nLeveraging a small amount of extremely high quality data via a mathematically\nrigorous greedy algorithm that is enabled by the large full-order models,\nS$^2$GPT-PINN relies on orders of magnitude less parameters than PINNs to\nachieve extremely high efficiency via two levels of customizations. The first\nis knowledge distillation via task-specific activation functions that are\ntransferred from Pre-Trained PINNs. The second is a judicious down-sampling\nwhen calculating the physics-informed loss of the network compressing the\nnumber of data sites by orders of magnitude to the size of the small model.", "AI": {"tldr": "S$^2$GPT-PINN\u662f\u4e00\u79cd\u7a00\u758f\u4e14\u5c0f\u578b\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u6c42\u89e3\u53c2\u6570\u5316\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDEs\uff09\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u548c\u667a\u80fd\u964d\u91c7\u6837\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u3002", "motivation": "\u9488\u5bf9\u7279\u5b9a\u9886\u57df\u7684PDEs\uff0c\u8bbe\u8ba1\u4e00\u79cd\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u4f4e\u4f46\u9ad8\u6548\u7684\u6a21\u578b\uff0c\u7c7b\u4f3c\u4e8e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u3002", "method": "\u5229\u7528\u9ad8\u8d28\u91cf\u6570\u636e\u548c\u8d2a\u5a6a\u7b97\u6cd5\uff0c\u7ed3\u5408\u77e5\u8bc6\u84b8\u998f\uff08\u4efb\u52a1\u7279\u5b9a\u6fc0\u6d3b\u51fd\u6570\uff09\u548c\u7269\u7406\u4fe1\u606f\u635f\u5931\u7684\u667a\u80fd\u964d\u91c7\u6837\u3002", "result": "\u76f8\u6bd4\u4f20\u7edfPINNs\uff0c\u53c2\u6570\u6570\u91cf\u5927\u5e45\u51cf\u5c11\uff0c\u8ba1\u7b97\u6548\u7387\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "S$^2$GPT-PINN\u4e3a\u7279\u5b9aPDEs\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u8d44\u6e90\u8282\u7ea6\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16808", "pdf": "https://arxiv.org/pdf/2506.16808", "abs": "https://arxiv.org/abs/2506.16808", "authors": ["Louis Royer", "Emmanuel Lavinal", "Emmanuel Chaput"], "title": "Using SRv6 to access Edge Applications in 5G Networks", "categories": ["cs.NI"], "comment": "CoNEXT 2023: The 19th International Conference on emerging Networking\n  EXperiments and Technologies, Paris, France", "summary": "With the emergence of Multi-Access Edge Computing in 5G and beyond, it has\nbecome essential for operators to optimize the data path for the end-user while\nensuring resources are used according to their policy. In this paper, we review\nexisting solutions to access edge resources, underline their limits, and\npropose the use of Segment Routing over IPv6 (SRv6) in a 5G/edge architecture.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u57285G\u53ca\u4ee5\u540e\u7684\u591a\u63a5\u5165\u8fb9\u7f18\u8ba1\u7b97\u4e2d\uff0c\u5982\u4f55\u4f18\u5316\u6570\u636e\u8def\u5f84\u5e76\u786e\u4fdd\u8d44\u6e90\u6309\u7b56\u7565\u4f7f\u7528\uff0c\u63d0\u51fa\u4f7f\u7528SRv6\u6280\u672f\u3002", "motivation": "\u968f\u77405G\u53ca\u4ee5\u540e\u591a\u63a5\u5165\u8fb9\u7f18\u8ba1\u7b97\u7684\u51fa\u73b0\uff0c\u8fd0\u8425\u5546\u9700\u8981\u4f18\u5316\u6570\u636e\u8def\u5f84\u5e76\u786e\u4fdd\u8d44\u6e90\u6309\u7b56\u7565\u4f7f\u7528\u3002", "method": "\u56de\u987e\u73b0\u6709\u8fb9\u7f18\u8d44\u6e90\u8bbf\u95ee\u89e3\u51b3\u65b9\u6848\uff0c\u6307\u51fa\u5176\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u57285G/\u8fb9\u7f18\u67b6\u6784\u4e2d\u4f7f\u7528SRv6\u3002", "result": "\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4f46\u63d0\u51faSRv6\u4e3a\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "SRv6\u57285G/\u8fb9\u7f18\u67b6\u6784\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u53ef\u4f18\u5316\u6570\u636e\u8def\u5f84\u548c\u8d44\u6e90\u7ba1\u7406\u3002"}}
{"id": "2506.16616", "pdf": "https://arxiv.org/pdf/2506.16616", "abs": "https://arxiv.org/abs/2506.16616", "authors": ["Soroush Omidvartehrani", "Davood Rafiei"], "title": "LDI: Localized Data Imputation", "categories": ["cs.DB"], "comment": null, "summary": "Missing values are a common challenge in real-world tabular data and can\nsignificantly impair downstream analysis. While Large Language Models (LLMs)\nhave recently shown promise in data imputation, existing methods often rely on\nbroad, unfiltered prompts that compromise accuracy, scalability, and\nexplainability. We introduce LDI (Localized Data Imputation), a novel framework\nthat improves both the accuracy and transparency of LLM-based imputation by\nselecting a compact, contextually relevant subset of attributes and tuples for\neach missing value. This localized prompting reduces noise, enables\ntraceability by revealing which data influenced each prediction, and is\neffective across both hosted LLMs and lightweight local models. Our extensive\nexperiments on four real-world datasets show that LDI outperforms\nstate-of-the-art methods, achieving up to 8% higher accuracy when using hosted\nLLMs. The gains are more substantial with lightweight local models, reaching\nnearly 17% and 97% accuracy on some datasets when using 3 and 10 examples,\nrespectively. In addition to higher accuracy, LDI offers improved\ninterpretability and robustness to data inconsistencies, making it well-suited\nfor high-stakes and privacy-sensitive applications.", "AI": {"tldr": "LDI\uff08\u5c40\u90e8\u6570\u636e\u586b\u8865\uff09\u662f\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u5c5e\u6027\u548c\u5143\u7ec4\u5b50\u96c6\uff0c\u63d0\u5347\u57fa\u4e8eLLM\u7684\u6570\u636e\u586b\u8865\u7684\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6\u3002", "motivation": "\u73b0\u5b9e\u8868\u683c\u6570\u636e\u4e2d\u7f3a\u5931\u503c\u5e38\u89c1\u4e14\u5f71\u54cd\u5206\u6790\uff0c\u73b0\u6709LLM\u586b\u8865\u65b9\u6cd5\u56e0\u4f7f\u7528\u5bbd\u6cdb\u63d0\u793a\u800c\u964d\u4f4e\u51c6\u786e\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "LDI\u901a\u8fc7\u5c40\u90e8\u5316\u63d0\u793a\u9009\u62e9\u76f8\u5173\u6570\u636e\u5b50\u96c6\uff0c\u51cf\u5c11\u566a\u58f0\u5e76\u63d0\u9ad8\u53ef\u8ffd\u6eaf\u6027\uff0c\u9002\u7528\u4e8e\u6258\u7ba1LLM\u548c\u8f7b\u91cf\u672c\u5730\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u663e\u793aLDI\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6258\u7ba1LLM\u51c6\u786e\u7387\u63d0\u53478%\uff0c\u8f7b\u91cf\u6a21\u578b\u63d0\u5347\u663e\u8457\uff08\u6700\u9ad897%\uff09\u3002", "conclusion": "LDI\u5728\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u5408\u9ad8\u98ce\u9669\u548c\u9690\u79c1\u654f\u611f\u5e94\u7528\u3002"}}
{"id": "2506.16350", "pdf": "https://arxiv.org/pdf/2506.16350", "abs": "https://arxiv.org/abs/2506.16350", "authors": ["Hen Kas-Sharir", "Gal Sela", "Erez Petrank"], "title": "A Study of Synchronization Methods for Concurrent Size", "categories": ["cs.DC"], "comment": "Code: https://github.com/henkassharir/ConcurrentSizeMethods", "summary": "The size of collections, maps, and data structures in general, constitutes a\nfundamental property. An implementation of the size method is required in most\nprogramming environments. Nevertheless, in a concurrent environment,\nintegrating a linearizable concurrent size introduces a noticeable overhead on\nall operations of the data structure, even when the size method is not invoked\nduring the execution. In this work we present a study of synchronization\nmethods in an attempt to improve the performance of the data structure. In\nparticular, we study a handshake technique that is commonly used with\nconcurrent garbage collection, an optimistic technique, and a lock-based\ntechnique. Evaluation against the state-of-the-art size methodology\ndemonstrates that the overhead can be significantly reduced by selecting the\nappropriate synchronization approach, but there is no one-size-fits-all method.\nDifferent scenarios call for different synchronization methods, as rigorously\nshown in this study. Nevertheless, our findings align with general trends in\nconcurrent computing. In scenarios characterized by low contention, optimistic\nand lock-based approaches work best, whereas under high contention, the most\neffective solutions are the handshake approach and the wait-free approach.", "AI": {"tldr": "\u7814\u7a76\u540c\u6b65\u65b9\u6cd5\u4ee5\u4f18\u5316\u5e76\u53d1\u6570\u636e\u7ed3\u6784\u4e2d`size`\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u4e0d\u540c\u573a\u666f\u9700\u91c7\u7528\u4e0d\u540c\u540c\u6b65\u6280\u672f\u3002", "motivation": "\u5728\u5e76\u53d1\u73af\u5883\u4e2d\uff0c\u7ebf\u6027\u5316`size`\u65b9\u6cd5\u4f1a\u5e26\u6765\u663e\u8457\u5f00\u9500\uff0c\u5373\u4f7f\u672a\u8c03\u7528\u8be5\u65b9\u6cd5\u3002\u7814\u7a76\u65e8\u5728\u51cf\u5c11\u8fd9\u79cd\u5f00\u9500\u3002", "method": "\u6bd4\u8f83\u4e86\u63e1\u624b\u6280\u672f\u3001\u4e50\u89c2\u6280\u672f\u548c\u57fa\u4e8e\u9501\u7684\u6280\u672f\uff0c\u5e76\u4e0e\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u9009\u62e9\u5408\u9002\u7684\u540c\u6b65\u65b9\u6cd5\u53ef\u663e\u8457\u51cf\u5c11\u5f00\u9500\uff0c\u4f46\u65e0\u901a\u7528\u6700\u4f18\u89e3\u3002\u4f4e\u4e89\u7528\u573a\u666f\u9002\u5408\u4e50\u89c2\u548c\u57fa\u4e8e\u9501\u65b9\u6cd5\uff0c\u9ad8\u4e89\u7528\u573a\u666f\u9002\u5408\u63e1\u624b\u548c\u65e0\u7b49\u5f85\u65b9\u6cd5\u3002", "conclusion": "\u540c\u6b65\u65b9\u6cd5\u7684\u9009\u62e9\u9700\u6839\u636e\u5177\u4f53\u573a\u666f\uff0c\u7814\u7a76\u7ed3\u679c\u4e0e\u5e76\u53d1\u8ba1\u7b97\u7684\u666e\u904d\u8d8b\u52bf\u4e00\u81f4\u3002"}}
{"id": "2506.16214", "pdf": "https://arxiv.org/pdf/2506.16214", "abs": "https://arxiv.org/abs/2506.16214", "authors": ["Klara Borowa", "Andrzej Ratkowski", "Roberto Verdecchia"], "title": "The Technical Debt Gamble: A Case Study on Technical Debt in a Large-Scale Industrial Microservice Architecture", "categories": ["cs.SE"], "comment": "Preprint accepted to Journal of Systems and Software", "summary": "Microservice architectures provide an intuitive promise of high\nmaintainability and evolvability due to loose coupling. However, these quality\nattributes are notably vulnerable to technical debt (TD). Few studies address\nTD in microservice systems, particularly on a large scale. This research\nexplores how TD manifests in a large-scale microservice-based industrial\nsystem. The research is based on a mixed-method case study of a project\nincluding over 100 microservices and serving over 15k locations. Results are\ncollected via a quantitative method based static code analyzers combined with\nqualitative insights derived from a focus group discussion with the development\nteam and a follow-up interview with the lead architect of the case study\nsystem. Results show that (1) simple static source code analysis can be an\nefficient and effective entry point for holistic TD discovery, (2) inadequate\ncommunication significantly contributes to TD, (3) misalignment between\narchitectural and organizational structures can exacerbate TD accumulation, (4)\nmicroservices can rapidly cycle through TD accumulation and resolution, a\nphenomenon referred to as \"microservice architecture technical debt gamble\".\nFinally, we identify a set of fitting strategies for TD management in\nmicroservice architectures.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u89c4\u6a21\u5fae\u670d\u52a1\u7cfb\u7edf\u4e2d\u6280\u672f\u503a\u52a1\u7684\u8868\u73b0\u5f62\u5f0f\uff0c\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u6848\u4f8b\u7814\u7a76\u53d1\u73b0\u9759\u6001\u4ee3\u7801\u5206\u6790\u662f\u53d1\u73b0\u6280\u672f\u503a\u52a1\u7684\u6709\u6548\u5165\u53e3\uff0c\u6c9f\u901a\u4e0d\u8db3\u548c\u7ec4\u7ec7\u67b6\u6784\u4e0d\u5339\u914d\u4f1a\u52a0\u5267\u6280\u672f\u503a\u52a1\uff0c\u5e76\u63d0\u51fa\u4e86\u7ba1\u7406\u7b56\u7565\u3002", "motivation": "\u5fae\u670d\u52a1\u67b6\u6784\u867d\u7136\u627f\u8bfa\u9ad8\u53ef\u7ef4\u62a4\u6027\u548c\u53ef\u6f14\u8fdb\u6027\uff0c\u4f46\u6280\u672f\u503a\u52a1\u5bf9\u5176\u8d28\u91cf\u5c5e\u6027\u6784\u6210\u663e\u8457\u5a01\u80c1\uff0c\u76ee\u524d\u7f3a\u4e4f\u5927\u89c4\u6a21\u5fae\u670d\u52a1\u7cfb\u7edf\u4e2d\u6280\u672f\u503a\u52a1\u7684\u7814\u7a76\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u6848\u4f8b\u7814\u7a76\uff0c\u5305\u62ec\u9759\u6001\u4ee3\u7801\u5206\u6790\u548c\u5b9a\u6027\u8bbf\u8c08\uff0c\u7814\u7a76\u5bf9\u8c61\u4e3a\u5305\u542b100\u591a\u4e2a\u5fae\u670d\u52a1\u7684\u5de5\u4e1a\u7cfb\u7edf\u3002", "result": "\u53d1\u73b0\u9759\u6001\u4ee3\u7801\u5206\u6790\u662f\u6280\u672f\u503a\u52a1\u53d1\u73b0\u7684\u6709\u6548\u5de5\u5177\uff0c\u6c9f\u901a\u4e0d\u8db3\u548c\u7ec4\u7ec7\u67b6\u6784\u4e0d\u5339\u914d\u4f1a\u52a0\u5267\u6280\u672f\u503a\u52a1\uff0c\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\u5b58\u5728\u6280\u672f\u503a\u52a1\u5feb\u901f\u79ef\u7d2f\u4e0e\u89e3\u51b3\u7684\u5faa\u73af\u73b0\u8c61\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u5957\u9002\u5408\u5fae\u670d\u52a1\u67b6\u6784\u7684\u6280\u672f\u503a\u52a1\u7ba1\u7406\u7b56\u7565\uff0c\u5f3a\u8c03\u4e86\u6c9f\u901a\u548c\u7ec4\u7ec7\u67b6\u6784\u5bf9\u9f50\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.16477", "pdf": "https://arxiv.org/pdf/2506.16477", "abs": "https://arxiv.org/abs/2506.16477", "authors": ["Humza Ikram", "Andrew Brady", "Daniel Anderson", "Guy Blelloch"], "title": "Parallel batch queries on dynamic trees: algorithms and experiments", "categories": ["cs.DS"], "comment": null, "summary": "Dynamic tree data structures maintain a forest while supporting insertion and\ndeletion of edges and a broad set of queries in $O(\\log n)$ time per operation.\nSuch data structures are at the core of many modern algorithms. Recent work has\nextended dynamic trees so as to support batches of updates or queries so as to\nrun in parallel, and these batch parallel dynamic trees are now used in several\nparallel algorithms. In this work we describe improvements to batch parallel\ndynamic trees, describe an implementation that incorporates these improvements,\nand experiments using it. The improvements includes generalizing prior work on\nRC (rake compress) trees to work with arbitrary degree while still supporting a\nrich set of queries, and describing how to support batch subtree queries, path\nqueries, LCA queries, and nearest-marked-vertex queries in $O(k + k \\log (1 +\nn/k))$ work and polylogarithmic span. Our implementation is the first general\nimplementation of batch dynamic trees (supporting arbitrary degree and general\nqueries). Our experiments include measuring the time to create the trees,\nvarying batch sizes for updates and queries, and using the tree to implement\nincremental batch-parallel minimum spanning trees. To run the experiments we\ndevelop a forest generator that is parameterized to create distributions of\ntrees of differing characteristics (e.g., degree, depth, and relative tree\nsizes). Our experiments show good speedup and that the algorithm performance is\nrobust across forest characteristics.", "AI": {"tldr": "\u672c\u6587\u6539\u8fdb\u4e86\u6279\u91cf\u5e76\u884c\u52a8\u6001\u6811\u6570\u636e\u7ed3\u6784\uff0c\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u67e5\u8be2\u548c\u4efb\u610f\u5ea6\u6570\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u3002", "motivation": "\u52a8\u6001\u6811\u6570\u636e\u7ed3\u6784\u662f\u73b0\u4ee3\u7b97\u6cd5\u4e2d\u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u4f46\u73b0\u6709\u6279\u91cf\u5e76\u884c\u52a8\u6001\u6811\u5728\u652f\u6301\u590d\u6742\u67e5\u8be2\u548c\u4efb\u610f\u5ea6\u6570\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u6269\u5c55RC\u6811\u4ee5\u652f\u6301\u4efb\u610f\u5ea6\u6570\u548c\u591a\u79cd\u67e5\u8be2\uff08\u5982\u5b50\u6811\u67e5\u8be2\u3001\u8def\u5f84\u67e5\u8be2\u7b49\uff09\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u901a\u7528\u6279\u91cf\u52a8\u6001\u6811\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u6539\u8fdb\u540e\u7684\u7b97\u6cd5\u5728\u6027\u80fd\u548c\u5e76\u884c\u6548\u7387\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4e14\u5bf9\u4e0d\u540c\u68ee\u6797\u7279\u6027\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u6539\u8fdb\u548c\u5b9e\u73b0\u4e3a\u6279\u91cf\u5e76\u884c\u52a8\u6001\u6811\u63d0\u4f9b\u4e86\u66f4\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5e76\u884c\u7b97\u6cd5\u3002"}}
{"id": "2506.15688", "pdf": "https://arxiv.org/pdf/2506.15688", "abs": "https://arxiv.org/abs/2506.15688", "authors": ["Hui Ma", "Kai Yang", "Man-On Pun"], "title": "Cellular Traffic Prediction via Deep State Space Models with Attention Mechanism", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Cellular traffic prediction is of great importance for operators to manage\nnetwork resources and make decisions. Traffic is highly dynamic and influenced\nby many exogenous factors, which would lead to the degradation of traffic\nprediction accuracy. This paper proposes an end-to-end framework with two\nvariants to explicitly characterize the spatiotemporal patterns of cellular\ntraffic among neighboring cells. It uses convolutional neural networks with an\nattention mechanism to capture the spatial dynamics and Kalman filter for\ntemporal modelling. Besides, we can fully exploit the auxiliary information\nsuch as social activities to improve prediction performance. We conduct\nextensive experiments on three real-world datasets. The results show that our\nproposed models outperform the state-of-the-art machine learning techniques in\nterms of prediction accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u7ed3\u5408\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c\u6ce8\u610f\u529b\u673a\u5236\u4ee5\u53ca\u5361\u5c14\u66fc\u6ee4\u6ce2\uff0c\u7528\u4e8e\u63d0\u5347\u8702\u7a9d\u6d41\u91cf\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u8702\u7a9d\u6d41\u91cf\u9884\u6d4b\u5bf9\u8fd0\u8425\u5546\u7ba1\u7406\u7f51\u7edc\u8d44\u6e90\u548c\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6d41\u91cf\u52a8\u6001\u6027\u5f3a\u4e14\u53d7\u591a\u79cd\u5916\u90e8\u56e0\u7d20\u5f71\u54cd\uff0c\u5bfc\u81f4\u9884\u6d4b\u7cbe\u5ea6\u4e0b\u964d\u3002", "method": "\u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u7a7a\u95f4\u52a8\u6001\uff0c\u5361\u5c14\u66fc\u6ee4\u6ce2\u8fdb\u884c\u65f6\u95f4\u5efa\u6a21\uff0c\u5e76\u5229\u7528\u8f85\u52a9\u4fe1\u606f\uff08\u5982\u793e\u4ea4\u6d3b\u52a8\uff09\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u6a21\u578b\u5728\u9884\u6d4b\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6280\u672f\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u8702\u7a9d\u6d41\u91cf\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.16914", "pdf": "https://arxiv.org/pdf/2506.16914", "abs": "https://arxiv.org/abs/2506.16914", "authors": ["Lukas Wildberger", "Anja Hamscher", "Jens B. Schmitt"], "title": "Minimal Per-Flow Backlog Bounds at an Aggregate FIFO Server under Piecewise-Linear Arrival Curves", "categories": ["cs.NI"], "comment": null, "summary": "Network Calculus (NC) is a versatile methodology based on min-plus algebra to\nderive worst-case per-flow performance bounds in networked systems with many\nconcurrent flows. In particular, NC can analyze many scheduling disciplines;\nyet, somewhat surprisingly, an aggregate FIFO server is a notoriously hard case\ndue to its min-plus non-linearity. A resort is to represent the FIFO residual\nservice by a family of functions with a free parameter instead of just a single\ncurve. For simple token-bucket arrival curves, literature provides optimal\nchoices for that free parameter to minimize delay and backlog bounds. In this\npaper, we tackle the challenge of more general arrival curves than just token\nbuckets. In particular, we derive residual service curves resulting in minimal\nbacklog bounds for general piecewise-linear arrival curves. To that end, we\nfirst show that a backlog bound can always be calculated at a breakpoint of\neither the arrival curve of the flow of interest or its residual service curve.\nFurther, we define a set of curves that characterize the backlog for a fixed\nbreakpoint, depending on the free parameter of the residual service curve. We\nshow that the backlog-minimizing residual service curve family parameter\ncorresponds to the largest intersection of those curves with the arrival curve.\nIn more complex scenarios finding this largest intersection can become\ninefficient as the search space grows in the number of flows. Therefore, we\npresent an efficient heuristic that finds, in many cases, the optimal parameter\nor at least a close conservative approximation. This heuristic is evaluated in\nterms of accuracy and execution time. Finally, we utilize these\nbacklog-minimizing residual service curves to enhance the DiscoDNC tool and\nobserve considerable reductions in the corresponding backlog bounds.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u7f51\u7edc\u6f14\u7b97\uff08NC\uff09\u4e2d\u805a\u5408FIFO\u670d\u52a1\u5668\u7684\u975e\u7ebf\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u4e00\u822c\u5206\u6bb5\u7ebf\u6027\u5230\u8fbe\u66f2\u7ebf\u7684\u6700\u5c0f\u5316\u79ef\u538b\u8fb9\u754c\u7684\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u542f\u53d1\u5f0f\u7b97\u6cd5\u9ad8\u6548\u6c42\u89e3\u3002", "motivation": "\u805a\u5408FIFO\u670d\u52a1\u5668\u56e0\u5176\u975e\u7ebf\u6027\u7279\u6027\u96be\u4ee5\u5206\u6790\uff0c\u73b0\u6709\u65b9\u6cd5\u4ec5\u9002\u7528\u4e8e\u7b80\u5355\u7684\u4ee4\u724c\u6876\u5230\u8fbe\u66f2\u7ebf\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u66f4\u4e00\u822c\u7684\u5206\u6bb5\u7ebf\u6027\u5230\u8fbe\u66f2\u7ebf\u7684\u6700\u5c0f\u5316\u79ef\u538b\u8fb9\u754c\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5230\u8fbe\u66f2\u7ebf\u6216\u5269\u4f59\u670d\u52a1\u66f2\u7ebf\u7684\u65ad\u70b9\uff0c\u5b9a\u4e49\u4e00\u7ec4\u66f2\u7ebf\u8868\u5f81\u79ef\u538b\uff0c\u5e76\u5bfb\u627e\u4e0e\u5230\u8fbe\u66f2\u7ebf\u6700\u5927\u4ea4\u70b9\u7684\u5269\u4f59\u670d\u52a1\u66f2\u7ebf\u53c2\u6570\u3002\u63d0\u51fa\u9ad8\u6548\u542f\u53d1\u5f0f\u7b97\u6cd5\u4ee5\u5e94\u5bf9\u590d\u6742\u573a\u666f\u3002", "result": "\u5728\u590d\u6742\u573a\u666f\u4e2d\uff0c\u542f\u53d1\u5f0f\u7b97\u6cd5\u80fd\u9ad8\u6548\u627e\u5230\u6700\u4f18\u6216\u63a5\u8fd1\u6700\u4f18\u7684\u53c2\u6570\uff0c\u663e\u8457\u51cf\u5c11\u79ef\u538b\u8fb9\u754c\u3002", "conclusion": "\u672c\u6587\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86DiscoDNC\u5de5\u5177\u7684\u6027\u80fd\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u79ef\u538b\u8fb9\u754c\uff0c\u4e3a\u66f4\u4e00\u822c\u7684\u5230\u8fbe\u66f2\u7ebf\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16923", "pdf": "https://arxiv.org/pdf/2506.16923", "abs": "https://arxiv.org/abs/2506.16923", "authors": ["Omer Abramovich", "Daniel Deutch", "Nave Frost", "Ahmet Kara", "Dan Olteanu"], "title": "Advancing Fact Attribution for Query Answering: Aggregate Queries and Novel Algorithms", "categories": ["cs.DB"], "comment": null, "summary": "In this paper, we introduce a novel approach to computing the contribution of\ninput tuples to the result of the query, quantified by the Banzhaf and Shapley\nvalues. In contrast to prior algorithmic work that focuses on\nSelect-Project-Join-Union queries, ours is the first practical approach for\nqueries with aggregates. It relies on two novel optimizations that are\nessential for its practicality and significantly improve the runtime\nperformance already for queries without aggregates. The first optimization\nexploits the observation that many input tuples have the same contribution to\nthe query result, so it is enough to compute the contribution of one of them.\nThe second optimization uses the gradient of the query lineage to compute the\ncontributions of all tuples with the same complexity as for one of them.\nExperiments with a million instances over 3 databases show that our approach\nachieves up to 3 orders of magnitude runtime improvements over the\nstate-of-the-art for queries without aggregates, and that it is practical for\naggregate queries.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u8f93\u5165\u5143\u7ec4\u5bf9\u67e5\u8be2\u7ed3\u679c\u8d21\u732e\u7684\u65b0\u65b9\u6cd5\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u5bf9\u805a\u5408\u67e5\u8be2\u7684\u5b9e\u7528\u5316\u5904\u7406\uff0c\u5e76\u901a\u8fc7\u4e24\u79cd\u4f18\u5316\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u65e0\u805a\u5408\u67e5\u8be2\uff0c\u7f3a\u4e4f\u5bf9\u805a\u5408\u67e5\u8be2\u7684\u5b9e\u7528\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u4e14\u901a\u7528\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u4f18\u5316\uff1a\u4e00\u662f\u8bc6\u522b\u8d21\u732e\u76f8\u540c\u7684\u5143\u7ec4\u4ee5\u51cf\u5c11\u8ba1\u7b97\u91cf\uff0c\u4e8c\u662f\u5229\u7528\u67e5\u8be2\u8c31\u7cfb\u7684\u68af\u5ea6\u9ad8\u6548\u8ba1\u7b97\u6240\u6709\u5143\u7ec4\u7684\u8d21\u732e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u65e0\u805a\u5408\u67e5\u8be2\u4e0a\u6027\u80fd\u63d0\u53473\u4e2a\u6570\u91cf\u7ea7\uff0c\u5e76\u80fd\u6709\u6548\u5904\u7406\u805a\u5408\u67e5\u8be2\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u67e5\u8be2\u8d21\u732e\u8ba1\u7b97\u7684\u6548\u7387\u548c\u5b9e\u7528\u6027\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u805a\u5408\u67e5\u8be2\u3002"}}
{"id": "2506.16488", "pdf": "https://arxiv.org/pdf/2506.16488", "abs": "https://arxiv.org/abs/2506.16488", "authors": ["Xiaojun Dong", "Andy Li", "Yan Gu", "Yihan Sun"], "title": "Parallel Point-to-Point Shortest Paths and Batch Queries", "categories": ["cs.DC", "cs.DS"], "comment": null, "summary": "We propose Orionet, efficient parallel implementations of Point-to-Point\nShortest Paths (PPSP) queries using bidirectional search (BiDS) and other\nheuristics, with an additional focus on batch PPSP queries. We present a\nframework for parallel PPSP built on existing single-source shortest paths\n(SSSP) frameworks by incorporating pruning conditions. As a result, we develop\nefficient parallel PPSP algorithms based on early termination, bidirectional\nsearch, A$^*$ search, and bidirectional A$^*$ all with simple and efficient\nimplementations.\n  We extend our idea to batch PPSP queries, which are widely used in real-world\nscenarios. We first design a simple and flexible abstraction to represent the\nbatch so PPSP can leverage the shared information of the batch. Orionet\nformalizes the batch as a query graph represented by edges between queried\nsources and targets. In this way, we directly extended our PPSP framework to\nbatched queries in a simple and efficient way.\n  We evaluate Orionet on both single and batch PPSP queries using various graph\ntypes and distance percentiles of queried pairs, and compare it against two\nbaselines, GraphIt and MBQ. Both of them support parallel single PPSP and A$^*$\nusing unidirectional search. On 14 graphs we tested, on average, our\nbidirectional search is 2.9$\\times$ faster than GraphIt, and 6.8$\\times$ faster\nthan MBQ. Our bidirectional A$^*$ is 4.4$\\times$ and 6.2$\\times$ faster than\nthe A$^*$ in GraphIt and MBQ, respectively. For batched PPSP queries, we also\nprovide in-depth experimental evaluation, and show that Orionet provides strong\nperformance compared to the plain solutions.", "AI": {"tldr": "Orionet\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5e76\u884c\u70b9\u5bf9\u70b9\u6700\u77ed\u8def\u5f84\uff08PPSP\uff09\u67e5\u8be2\u65b9\u6cd5\uff0c\u7ed3\u5408\u53cc\u5411\u641c\u7d22\uff08BiDS\uff09\u548c\u5176\u4ed6\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5e76\u6269\u5c55\u5230\u6279\u91cf\u67e5\u8be2\u3002\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u70b9\u5bf9\u70b9\u6700\u77ed\u8def\u5f84\uff08PPSP\uff09\u67e5\u8be2\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u6c42\u5e7f\u6cdb\uff0c\u4f46\u73b0\u6709\u5e76\u884c\u65b9\u6cd5\u6548\u7387\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u6279\u91cf\u67e5\u8be2\u573a\u666f\u3002", "method": "\u57fa\u4e8e\u73b0\u6709\u5355\u6e90\u6700\u77ed\u8def\u5f84\uff08SSSP\uff09\u6846\u67b6\uff0c\u5f15\u5165\u526a\u679d\u6761\u4ef6\uff0c\u5f00\u53d1\u4e86\u5e76\u884cPPSP\u7b97\u6cd5\uff0c\u5305\u62ec\u65e9\u671f\u7ec8\u6b62\u3001\u53cc\u5411\u641c\u7d22\u3001A*\u641c\u7d22\u53ca\u5176\u53cc\u5411\u7248\u672c\u3002\u6279\u91cf\u67e5\u8be2\u901a\u8fc7\u67e5\u8be2\u56fe\u62bd\u8c61\u5b9e\u73b0\u4fe1\u606f\u5171\u4eab\u3002", "result": "\u572814\u79cd\u56fe\u4e0a\u6d4b\u8bd5\uff0c\u53cc\u5411\u641c\u7d22\u5e73\u5747\u6bd4GraphIt\u5feb2.9\u500d\uff0c\u6bd4MBQ\u5feb6.8\u500d\uff1b\u53cc\u5411A*\u6bd4GraphIt\u548cMBQ\u5206\u522b\u5feb4.4\u500d\u548c6.2\u500d\u3002\u6279\u91cf\u67e5\u8be2\u6027\u80fd\u540c\u6837\u4f18\u8d8a\u3002", "conclusion": "Orionet\u901a\u8fc7\u9ad8\u6548\u5e76\u884c\u5316\u548c\u6279\u91cf\u67e5\u8be2\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86PPSP\u67e5\u8be2\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2506.16440", "pdf": "https://arxiv.org/pdf/2506.16440", "abs": "https://arxiv.org/abs/2506.16440", "authors": ["Ebube Alor", "SayedHassan Khatoonabadi", "Emad Shihab"], "title": "Evaluating the Use of LLMs for Documentation to Code Traceability", "categories": ["cs.SE"], "comment": null, "summary": "Large Language Models (LLMs) offer new potential for automating\ndocumentation-to-code traceability, yet their capabilities remain\nunderexplored. We present a comprehensive evaluation of LLMs (Claude 3.5\nSonnet, GPT-4o, and o3-mini) in establishing trace links between various\nsoftware documentation (including API references and user guides) and source\ncode. We create two novel datasets from two open-source projects (Unity Catalog\nand Crawl4AI). Through systematic experiments, we assess three key\ncapabilities: (1) trace link identification accuracy, (2) relationship\nexplanation quality, and (3) multi-step chain reconstruction. Results show that\nthe best-performing LLM achieves F1-scores of 79.4% and 80.4% across the two\ndatasets, substantially outperforming our baselines (TF-IDF, BM25, and\nCodeBERT). While fully correct relationship explanations range from 42.9% to\n71.1%, partial accuracy exceeds 97%, indicating that fundamental connections\nare rarely missed. For multi-step chains, LLMs maintain high endpoint accuracy\nbut vary in capturing precise intermediate links. Error analysis reveals that\nmany false positives stem from naming-based assumptions, phantom links, or\novergeneralization of architectural patterns. We demonstrate that task-framing,\nsuch as a one-to-many matching strategy, is critical for performance. These\nfindings position LLMs as powerful assistants for trace discovery, but their\nlimitations could necessitate human-in-the-loop tool design and highlight\nspecific error patterns for future research.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6587\u6863\u5230\u4ee3\u7801\u8ffd\u6eaf\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u5728\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4f46\u5b58\u5728\u547d\u540d\u5047\u8bbe\u548c\u8fc7\u5ea6\u6cdb\u5316\u7b49\u9519\u8bef\u6a21\u5f0f\u3002", "motivation": "\u63a2\u7d22LLMs\u5728\u81ea\u52a8\u5316\u6587\u6863\u4e0e\u4ee3\u7801\u8ffd\u6eaf\u4e2d\u7684\u6f5c\u529b\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u4f7f\u7528Claude 3.5 Sonnet\u3001GPT-4o\u548co3-mini\u7b49LLMs\uff0c\u5728\u4e24\u4e2a\u5f00\u6e90\u9879\u76ee\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u8ffd\u6eaf\u94fe\u63a5\u7684\u51c6\u786e\u6027\u3001\u5173\u7cfb\u89e3\u91ca\u8d28\u91cf\u548c\u591a\u6b65\u94fe\u91cd\u5efa\u80fd\u529b\u3002", "result": "\u6700\u4f73LLM\u7684F1\u5206\u6570\u8fbe79.4%\u548c80.4%\uff0c\u5173\u7cfb\u89e3\u91ca\u5b8c\u5168\u6b63\u786e\u7387\u4e3a42.9%-71.1%\uff0c\u591a\u6b65\u94fe\u7aef\u70b9\u51c6\u786e\u6027\u9ad8\u4f46\u4e2d\u95f4\u94fe\u63a5\u4e0d\u7a33\u5b9a\u3002", "conclusion": "LLMs\u662f\u5f3a\u5927\u7684\u8ffd\u6eaf\u5de5\u5177\uff0c\u4f46\u9700\u7ed3\u5408\u4eba\u5de5\u5e72\u9884\uff0c\u5e76\u9488\u5bf9\u7279\u5b9a\u9519\u8bef\u6a21\u5f0f\u4f18\u5316\u3002"}}
{"id": "2506.16928", "pdf": "https://arxiv.org/pdf/2506.16928", "abs": "https://arxiv.org/abs/2506.16928", "authors": ["Martin Hilgendorf", "Marina Papatriantafilou"], "title": "LMQ-Sketch: Lagom Multi-Query Sketch for High-Rate Online Analytics", "categories": ["cs.DS"], "comment": null, "summary": "Data sketches balance resource efficiency with controllable approximations\nfor extracting features in high-volume, high-rate data. Two important points of\ninterest are highlighted separately in recent works; namely, to (1) answer\nmultiple types of queries from one pass, and (2) query concurrently with\nupdates. Several fundamental challenges arise when integrating these\ndirections, which we tackle in this work. We investigate the trade-offs to be\nbalanced and synthesize key ideas into LMQ-Sketch, a single, composite data\nsketch supporting multiple queries (frequency point queries, frequency moments\nF1, and F2) concurrently with updates. Our method 'Lagom' is a cornerstone of\nLMQ-Sketch for low-latency global querying (<100 us), combining freshness,\ntimeliness, and accuracy with a low memory footprint and high throughput (>2B\nupdates/s). We analyze and evaluate the accuracy of Lagom, which builds on a\nsimple geometric argument and efficiently combines work distribution with\nsynchronization for proper concurrency semantics -- monotonicity of operations\nand intermediate value linearizability. Comparing with state-of-the-art methods\n(which, as mentioned, only cover either mixed queries or concurrency),\nLMQ-Sketch shows highly competitive throughput, with additional accuracy\nguarantees and concurrency semantics, while also reducing the required memory\nbudget by an order of magnitude. We expect the methodology to have broader\nimpact on concurrent multi-query sketches.", "AI": {"tldr": "LMQ-Sketch\u662f\u4e00\u79cd\u652f\u6301\u591a\u67e5\u8be2\u4e0e\u5e76\u53d1\u66f4\u65b0\u7684\u6570\u636e\u8349\u56fe\u65b9\u6cd5\uff0c\u901a\u8fc7Lagom\u65b9\u6cd5\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u5168\u5c40\u67e5\u8be2\uff0c\u5177\u6709\u9ad8\u541e\u5410\u91cf\u548c\u4f4e\u5185\u5b58\u5360\u7528\u3002", "motivation": "\u89e3\u51b3\u9ad8\u5bb9\u91cf\u3001\u9ad8\u901f\u7387\u6570\u636e\u4e2d\u591a\u7c7b\u578b\u67e5\u8be2\u4e0e\u5e76\u53d1\u66f4\u65b0\u7684\u96c6\u6210\u95ee\u9898\u3002", "method": "\u63d0\u51faLMQ-Sketch\uff0c\u7ed3\u5408Lagom\u65b9\u6cd5\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u5168\u5c40\u67e5\u8be2\uff0c\u652f\u6301\u9891\u7387\u70b9\u67e5\u8be2\u3001F1\u548cF2\u9891\u7387\u77e9\u3002", "result": "LMQ-Sketch\u5728\u541e\u5410\u91cf\u3001\u51c6\u786e\u6027\u548c\u5e76\u53d1\u8bed\u4e49\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5185\u5b58\u9700\u6c42\u964d\u4f4e\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "LMQ-Sketch\u4e3a\u5e76\u53d1\u591a\u67e5\u8be2\u8349\u56fe\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.15689", "pdf": "https://arxiv.org/pdf/2506.15689", "abs": "https://arxiv.org/abs/2506.15689", "authors": ["Liulu He", "Shenli Zhen", "Karwei Sun", "Yijiang Liu", "Yufei Zhao", "Chongkang Tan", "Huanrui Yang", "Yuan Du", "Li Du"], "title": "BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Rotations have become essential to state-of-the-art quantization pipelines\nfor large language models (LLMs) by effectively smoothing outliers in weights\nand activations. However, further optimizing the rotation parameters offers\nonly limited performance gains and introduces significant training overhead:\ndue to rotation parameter sharing, full-model must be loaded simultaneously to\nenable backpropagation, resulting in substantial memory consumption and limited\npractical utility. In this work, we identify two fundamental limitations of\ncurrent rotational quantization methods: (i) rotation fails to align channel\nmeans, resulting in wider quantization bounds and increased rounding errors;\nand (ii) rotation makes the activation distribution more Gaussian-like,\nincreasing energy loss caused by clipping errors. To address these issues, we\nintroduce \\textbf{BASE-Q}, a simple yet powerful approach that combines bias\ncorrection and asymmetric scaling to effectively reduce rounding and clipping\nerrors. Furthermore, BASE-Q enables blockwise optimization, eliminating the\nneed for memory-intensive full-model backpropagation. Extensive experiments on\nvarious LLMs and benchmarks demonstrate the effectiveness of BASE-Q, narrowing\nthe accuracy gap to full-precision models by 50.5\\%, 42.9\\%, and 29.2\\%\ncompared to QuaRot, SpinQuant, and OSTQuant, respectively. The code will be\nreleased soon.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBASE-Q\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u504f\u7f6e\u6821\u6b63\u548c\u975e\u5bf9\u79f0\u7f29\u653e\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u91cf\u5316\u8bef\u5dee\uff0c\u5e76\u652f\u6301\u5206\u5757\u4f18\u5316\uff0c\u907f\u514d\u4e86\u5185\u5b58\u5bc6\u96c6\u578b\u5168\u6a21\u578b\u53cd\u5411\u4f20\u64ad\u3002", "motivation": "\u5f53\u524d\u65cb\u8f6c\u91cf\u5316\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u65cb\u8f6c\u672a\u80fd\u5bf9\u9f50\u901a\u9053\u5747\u503c\u5bfc\u81f4\u91cf\u5316\u8303\u56f4\u6269\u5927\u548c\u820d\u5165\u8bef\u5dee\u589e\u52a0\uff1b\u65cb\u8f6c\u4f7f\u6fc0\u6d3b\u5206\u5e03\u66f4\u63a5\u8fd1\u9ad8\u65af\u5206\u5e03\uff0c\u589e\u52a0\u4e86\u622a\u65ad\u8bef\u5dee\u7684\u80fd\u91cf\u635f\u5931\u3002", "method": "\u63d0\u51fa\u4e86BASE-Q\u65b9\u6cd5\uff0c\u7ed3\u5408\u504f\u7f6e\u6821\u6b63\u548c\u975e\u5bf9\u79f0\u7f29\u653e\uff0c\u51cf\u5c11\u820d\u5165\u548c\u622a\u65ad\u8bef\u5dee\uff0c\u5e76\u652f\u6301\u5206\u5757\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cBASE-Q\u663e\u8457\u7f29\u5c0f\u4e86\u4e0e\u5168\u7cbe\u5ea6\u6a21\u578b\u7684\u51c6\u786e\u7387\u5dee\u8ddd\uff0c\u76f8\u6bd4QuaRot\u3001SpinQuant\u548cOSTQuant\u5206\u522b\u63d0\u9ad8\u4e8650.5%\u300142.9%\u548c29.2%\u3002", "conclusion": "BASE-Q\u662f\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u65cb\u8f6c\u91cf\u5316\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.17063", "pdf": "https://arxiv.org/pdf/2506.17063", "abs": "https://arxiv.org/abs/2506.17063", "authors": ["Samer Lahoud", "Kinda Khawam"], "title": "Client Selection Strategies for Federated Semantic Communications in Heterogeneous IoT Networks", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "The exponential growth of IoT devices presents critical challenges in\nbandwidth-constrained wireless networks, particularly regarding efficient data\ntransmission and privacy preservation. This paper presents a novel federated\nsemantic communication (SC) framework that enables collaborative training of\nbandwidth-efficient models for image reconstruction across heterogeneous IoT\ndevices. By leveraging SC principles to transmit only semantic features, our\napproach dramatically reduces communication overhead while preserving\nreconstruction quality. We address the fundamental challenge of client\nselection in federated learning environments where devices exhibit significant\ndisparities in dataset sizes and data distributions. Our framework implements\nthree distinct client selection strategies that explore different trade-offs\nbetween system performance and fairness in resource allocation. The system\nemploys an end-to-end SC architecture with semantic bottlenecks, coupled with a\nloss-based aggregation mechanism that naturally adapts to client heterogeneity.\nExperimental evaluation on image data demonstrates that while Utilitarian\nselection achieves the highest reconstruction quality, Proportional Fairness\nmaintains competitive performance while significantly reducing participation\ninequality and improving computational efficiency. These results establish that\nfederated SC can successfully balance reconstruction quality, resource\nefficiency, and fairness in heterogeneous IoT deployments, paving the way for\nsustainable and privacy-preserving edge intelligence applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8054\u90a6\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5e26\u5bbd\u53d7\u9650\u7684\u65e0\u7ebf\u7f51\u7edc\u4e2d\u9ad8\u6548\u4f20\u8f93\u6570\u636e\u5e76\u4fdd\u62a4\u9690\u79c1\uff0c\u901a\u8fc7\u8bed\u4e49\u7279\u5f81\u4f20\u8f93\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u89e3\u51b3\u7269\u8054\u7f51\u8bbe\u5907\u5728\u5e26\u5bbd\u53d7\u9650\u7f51\u7edc\u4e2d\u6570\u636e\u4f20\u8f93\u6548\u7387\u4f4e\u548c\u9690\u79c1\u4fdd\u62a4\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8054\u90a6\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u7ed3\u5408\u4e09\u79cd\u5ba2\u6237\u7aef\u9009\u62e9\u7b56\u7565\u548c\u8bed\u4e49\u74f6\u9888\u7684\u7aef\u5230\u7aef\u67b6\u6784\uff0c\u4ee5\u53ca\u57fa\u4e8e\u635f\u5931\u7684\u805a\u5408\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u529f\u5229\u9009\u62e9\u7b56\u7565\u5b9e\u73b0\u6700\u9ad8\u91cd\u5efa\u8d28\u91cf\uff0c\u800c\u6bd4\u4f8b\u516c\u5e73\u7b56\u7565\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u53c2\u4e0e\u4e0d\u5e73\u7b49\u3002", "conclusion": "\u8054\u90a6\u8bed\u4e49\u901a\u4fe1\u80fd\u5e73\u8861\u91cd\u5efa\u8d28\u91cf\u3001\u8d44\u6e90\u6548\u7387\u548c\u516c\u5e73\u6027\uff0c\u4e3a\u53ef\u6301\u7eed\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u8fb9\u7f18\u667a\u80fd\u5e94\u7528\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2506.16976", "pdf": "https://arxiv.org/pdf/2506.16976", "abs": "https://arxiv.org/abs/2506.16976", "authors": ["Arthur Bernhardt", "Sajjad Tamimi", "Florian Stock", "Andreas Koch", "Ilia Petrov"], "title": "PUL: Pre-load in Software for Caches Wouldn't Always Play Along", "categories": ["cs.DB"], "comment": null, "summary": "Memory latencies and bandwidth are major factors, limiting system performance\nand scalability. Modern CPUs aim at hiding latencies by employing large caches,\nout-of-order execution, or complex hardware prefetchers. However,\nsoftware-based prefetching exhibits higher efficiency, improving with newer CPU\ngenerations.\n  In this paper we investigate software-based, post-Moore systems that offload\noperations to intelligent memories. We show that software-based prefetching has\neven higher potential in near-data processing settings by maximizing compute\nutilization through compute/IO interleaving.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u8fd1\u6570\u636e\u5904\u7406\u73af\u5883\u4e2d\uff0c\u57fa\u4e8e\u8f6f\u4ef6\u7684\u9884\u53d6\u6280\u672f\u5982\u4f55\u901a\u8fc7\u8ba1\u7b97/IO\u4ea4\u9519\u6700\u5927\u5316\u8ba1\u7b97\u5229\u7528\u7387\u3002", "motivation": "\u5185\u5b58\u5ef6\u8fdf\u548c\u5e26\u5bbd\u662f\u9650\u5236\u7cfb\u7edf\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u7684\u4e3b\u8981\u56e0\u7d20\uff0c\u73b0\u4ee3CPU\u901a\u8fc7\u5927\u7f13\u5b58\u3001\u4e71\u5e8f\u6267\u884c\u6216\u590d\u6742\u786c\u4ef6\u9884\u53d6\u5668\u6765\u9690\u85cf\u5ef6\u8fdf\uff0c\u4f46\u57fa\u4e8e\u8f6f\u4ef6\u7684\u9884\u53d6\u6548\u7387\u66f4\u9ad8\u3002", "method": "\u7814\u7a76\u57fa\u4e8e\u8f6f\u4ef6\u7684\u3001\u540e\u6469\u5c14\u65f6\u4ee3\u7684\u7cfb\u7edf\uff0c\u5c06\u64cd\u4f5c\u5378\u8f7d\u5230\u667a\u80fd\u5185\u5b58\u4e2d\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u8fd1\u6570\u636e\u5904\u7406\u73af\u5883\u4e2d\uff0c\u57fa\u4e8e\u8f6f\u4ef6\u7684\u9884\u53d6\u5177\u6709\u66f4\u9ad8\u7684\u6f5c\u529b\u3002", "conclusion": "\u901a\u8fc7\u8ba1\u7b97/IO\u4ea4\u9519\uff0c\u57fa\u4e8e\u8f6f\u4ef6\u7684\u9884\u53d6\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u5229\u7528\u7387\u3002"}}
{"id": "2506.16611", "pdf": "https://arxiv.org/pdf/2506.16611", "abs": "https://arxiv.org/abs/2506.16611", "authors": ["Khalid Hassan", "Amirreza Sokhankhosh", "Sara Rouhani"], "title": "Enabling Blockchain Interoperability Through Network Discovery Services", "categories": ["cs.DC", "cs.NI"], "comment": "Published in the IEEE DApps conference", "summary": "Web3 technologies have experienced unprecedented growth in the last decade,\nachieving widespread adoption. As various blockchain networks continue to\nevolve, we are on the cusp of a paradigm shift in which they could provide\nservices traditionally offered by the Internet, but in a decentralized manner,\nmarking the emergence of the Internet of Blockchains. While significant\nprogress has been achieved in enabling interoperability between blockchain\nnetworks, existing solutions often assume that networks are already mutually\naware. This reveals a critical gap: the initial discovery of blockchain\nnetworks remains largely unaddressed. This paper proposes a decentralized\narchitecture for blockchain network discovery that operates independently of\nany centralized authority. We also introduce a mechanism for discovering assets\nand services within a blockchain from external networks. Given the\ndecentralized nature of the proposed discovery architecture, we design an\nincentive mechanism to encourage nodes to actively participate in maintaining\nthe discovery network. The proposed architecture implemented and evaluated,\nusing the Substrate framework, demonstrates its resilience and scalability,\neffectively handling up to 130,000 concurrent requests under the tested network\nconfigurations, with a median response time of 5.5 milliseconds, demonstrating\nthe ability to scale its processing capacity further by increasing its network\nsize.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u7684\u533a\u5757\u94fe\u7f51\u7edc\u53d1\u73b0\u67b6\u6784\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u4e2d\u7f51\u7edc\u521d\u59cb\u53d1\u73b0\u672a\u88ab\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u6fc0\u52b1\u673a\u5236\u9f13\u52b1\u8282\u70b9\u53c2\u4e0e\u3002", "motivation": "\u73b0\u6709\u533a\u5757\u94fe\u4e92\u64cd\u4f5c\u6027\u89e3\u51b3\u65b9\u6848\u5047\u8bbe\u7f51\u7edc\u5df2\u76f8\u4e92\u77e5\u6653\uff0c\u4f46\u521d\u59cb\u53d1\u73b0\u95ee\u9898\u672a\u88ab\u89e3\u51b3\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u67b6\u6784\uff0c\u652f\u6301\u533a\u5757\u94fe\u7f51\u7edc\u548c\u8d44\u4ea7/\u670d\u52a1\u7684\u53d1\u73b0\uff0c\u5e76\u8bbe\u8ba1\u6fc0\u52b1\u673a\u5236\u3002\u4f7f\u7528Substrate\u6846\u67b6\u5b9e\u73b0\u5e76\u8bc4\u4f30\u3002", "result": "\u67b6\u6784\u5728\u6d4b\u8bd5\u914d\u7f6e\u4e0b\u53ef\u5904\u740613\u4e07\u5e76\u53d1\u8bf7\u6c42\uff0c\u4e2d\u4f4d\u54cd\u5e94\u65f6\u95f4\u4e3a5.5\u6beb\u79d2\uff0c\u5177\u5907\u6269\u5c55\u6027\u3002", "conclusion": "\u53bb\u4e2d\u5fc3\u5316\u53d1\u73b0\u67b6\u6784\u5177\u6709\u97e7\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u533a\u5757\u94fe\u4e92\u64cd\u4f5c\u6027\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.16453", "pdf": "https://arxiv.org/pdf/2506.16453", "abs": "https://arxiv.org/abs/2506.16453", "authors": ["Buthayna AlMulla", "Maram Assi", "Safwat Hassan"], "title": "Understanding the Challenges and Promises of Developing Generative AI Apps: An Empirical Study", "categories": ["cs.SE"], "comment": "45 pages, 24 figures, 7 tables", "summary": "The release of ChatGPT in 2022 triggered a rapid surge in generative\nartificial intelligence mobile apps (i.e., Gen-AI apps). Despite widespread\nadoption, little is known about how end users perceive and evaluate these\nGen-AI functionalities in practice. In this work, we conduct a user-centered\nanalysis of 676,066 reviews from 173 Gen-AI apps on the Google Play Store. We\nintroduce a four-phase methodology, SARA (Selection, Acquisition, Refinement,\nand Analysis), that enables the systematic extraction of user insights using\nprompt-based LLM techniques. First, we demonstrate the reliability of LLMs in\ntopic extraction, achieving 91% accuracy through five-shot prompting and\nnon-informative review filtering. Then, we apply this method to the informative\nreviews, identify the top 10 user-discussed topics (e.g., AI Performance,\nContent Quality, and Content Policy & Censorship) and analyze the key\nchallenges and emerging opportunities. Finally, we examine how these topics\nevolve over time, offering insight into shifting user expectations and\nengagement patterns with Gen-AI apps. Based on our findings and observations,\nwe present actionable implications for developers and researchers.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5206\u679067.6\u4e07\u6761Gen-AI\u5e94\u7528\u7684\u7528\u6237\u8bc4\u8bba\uff0c\u63d0\u51faSARA\u65b9\u6cd5\uff0c\u5229\u7528LLM\u6280\u672f\u63d0\u53d6\u7528\u6237\u5bf9Gen-AI\u529f\u80fd\u7684\u8bc4\u4ef7\uff0c\u53d1\u73b010\u5927\u70ed\u95e8\u8bdd\u9898\uff0c\u5e76\u63a2\u8ba8\u5176\u968f\u65f6\u95f4\u7684\u53d8\u5316\u3002", "motivation": "\u7814\u7a76\u7528\u6237\u5bf9Gen-AI\u5e94\u7528\u7684\u611f\u77e5\u548c\u8bc4\u4ef7\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u56db\u9636\u6bb5SARA\u65b9\u6cd5\uff08\u9009\u62e9\u3001\u83b7\u53d6\u3001\u7cbe\u70bc\u3001\u5206\u6790\uff09\uff0c\u7ed3\u5408LLM\u6280\u672f\u8fdb\u884c\u4e3b\u9898\u63d0\u53d6\u3002", "result": "LLM\u5728\u4e3b\u9898\u63d0\u53d6\u4e2d\u51c6\u786e\u7387\u8fbe91%\uff0c\u8bc6\u522b\u51fa10\u5927\u7528\u6237\u8ba8\u8bba\u8bdd\u9898\uff08\u5982AI\u6027\u80fd\u3001\u5185\u5bb9\u8d28\u91cf\u7b49\uff09\uff0c\u5e76\u5206\u6790\u5176\u968f\u65f6\u95f4\u7684\u53d8\u5316\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u548c\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u5173\u4e8e\u7528\u6237\u9700\u6c42\u548c\u671f\u671b\u7684\u5b9e\u7528\u5efa\u8bae\u3002"}}
{"id": "2506.17008", "pdf": "https://arxiv.org/pdf/2506.17008", "abs": "https://arxiv.org/abs/2506.17008", "authors": ["Matthias Bentert", "Fedor V. Fomin", "Petr A. Golovach", "Laure Morelle"], "title": "When does FTP become FPT?", "categories": ["cs.DS", "cs.DM"], "comment": "Appeared in WG 2025", "summary": "In the problem Fault-Tolerant Path (FTP), we are given an edge-weighted\ndirected graph G = (V, E), a subset U \\subseteq E of vulnerable edges, two\nvertices s, t \\in V, and integers k and \\ell. The task is to decide whether\nthere exists a subgraph H of G with total cost at most \\ell such that, after\nthe removal of any k vulnerable edges, H still contains an s-t-path. We study\nwhether Fault-Tolerant Path is fixed-parameter tractable (FPT) and whether it\nadmits a polynomial kernel under various parameterizations. Our choices of\nparameters include: the number of vulnerable edges in the input graph, the\nnumber of safe (i.e, invulnerable) edges in the input graph, the budget \\ell,\nthe minimum number of safe edges in any optimal solution, the minimum number of\nvulnerable edges in any optimal solution, the required redundancy k, and\nnatural above- and below-guarantee parameterizations. We provide an almost\ncomplete description of the complexity landscape of FTP for these parameters.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86Fault-Tolerant Path\uff08FTP\uff09\u95ee\u9898\u7684\u56fa\u5b9a\u53c2\u6570\u53ef\u5904\u7406\u6027\uff08FPT\uff09\u548c\u591a\u9879\u5f0f\u6838\u5b58\u5728\u6027\uff0c\u5206\u6790\u4e86\u591a\u79cd\u53c2\u6570\u5316\u4e0b\u7684\u590d\u6742\u6027\u3002", "motivation": "\u63a2\u8ba8FTP\u95ee\u9898\u5728\u4e0d\u540c\u53c2\u6570\u5316\u4e0b\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u4ee5\u586b\u8865\u8be5\u95ee\u9898\u7684\u590d\u6742\u6027\u56fe\u8c31\u3002", "method": "\u901a\u8fc7\u5206\u6790\u591a\u79cd\u53c2\u6570\uff08\u5982\u8106\u5f31\u8fb9\u6570\u91cf\u3001\u5b89\u5168\u8fb9\u6570\u91cf\u3001\u9884\u7b97\u2113\u3001\u6700\u4f18\u89e3\u4e2d\u7684\u5b89\u5168\u8fb9\u6216\u8106\u5f31\u8fb9\u6570\u91cf\u7b49\uff09\uff0c\u7814\u7a76FTP\u95ee\u9898\u7684FPT\u6027\u548c\u591a\u9879\u5f0f\u6838\u5b58\u5728\u6027\u3002", "result": "\u63d0\u4f9b\u4e86FTP\u95ee\u9898\u5728\u8fd9\u4e9b\u53c2\u6570\u4e0b\u7684\u51e0\u4e4e\u5b8c\u6574\u7684\u590d\u6742\u6027\u63cf\u8ff0\u3002", "conclusion": "\u8bba\u6587\u586b\u8865\u4e86FTP\u95ee\u9898\u590d\u6742\u6027\u56fe\u8c31\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2506.15690", "pdf": "https://arxiv.org/pdf/2506.15690", "abs": "https://arxiv.org/abs/2506.15690", "authors": ["Tianyu Wang", "Lingyou Pang", "Akira Horiguchi", "Carey E. Priebe"], "title": "LLM Web Dynamics: Tracing Model Collapse in a Network of LLMs", "categories": ["cs.LG", "cs.AI", "cs.SI", "stat.ME"], "comment": null, "summary": "The increasing use of synthetic data from the public Internet has enhanced\ndata usage efficiency in large language model (LLM) training. However, the\npotential threat of model collapse remains insufficiently explored. Existing\nstudies primarily examine model collapse in a single model setting or rely\nsolely on statistical surrogates. In this work, we introduce LLM Web Dynamics\n(LWD), an efficient framework for investigating model collapse at the network\nlevel. By simulating the Internet with a retrieval-augmented generation (RAG)\ndatabase, we analyze the convergence pattern of model outputs. Furthermore, we\nprovide theoretical guarantees for this convergence by drawing an analogy to\ninteracting Gaussian Mixture Models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLLM Web Dynamics (LWD)\u6846\u67b6\uff0c\u7814\u7a76\u7f51\u7edc\u7ea7\u6a21\u578b\u5d29\u6e83\u95ee\u9898\uff0c\u901a\u8fc7\u6a21\u62df\u4e92\u8054\u7f51\u548cRAG\u6570\u636e\u5e93\u5206\u6790\u6a21\u578b\u8f93\u51fa\u6536\u655b\u6a21\u5f0f\uff0c\u5e76\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u3002", "motivation": "\u5c3d\u7ba1\u5408\u6210\u6570\u636e\u5728LLM\u8bad\u7ec3\u4e2d\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u4f46\u6a21\u578b\u5d29\u6e83\u7684\u6f5c\u5728\u5a01\u80c1\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u73b0\u6709\u7814\u7a76\u591a\u5c40\u9650\u4e8e\u5355\u4e00\u6a21\u578b\u6216\u7edf\u8ba1\u66ff\u4ee3\u3002", "method": "\u5f15\u5165LWD\u6846\u67b6\uff0c\u6a21\u62df\u4e92\u8054\u7f51\u73af\u5883\u5e76\u4f7f\u7528RAG\u6570\u636e\u5e93\u5206\u6790\u6a21\u578b\u8f93\u51fa\u7684\u6536\u655b\u6a21\u5f0f\uff0c\u901a\u8fc7\u7c7b\u6bd4\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "\u63ed\u793a\u4e86\u6a21\u578b\u8f93\u51fa\u5728\u7f51\u7edc\u7ea7\u7684\u6536\u655b\u884c\u4e3a\uff0c\u4e3a\u6a21\u578b\u5d29\u6e83\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u89c6\u89d2\u3002", "conclusion": "LWD\u6846\u67b6\u4e3a\u7406\u89e3\u548c\u9884\u9632\u6a21\u578b\u5d29\u6e83\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002"}}
{"id": "2506.15910", "pdf": "https://arxiv.org/pdf/2506.15910", "abs": "https://arxiv.org/abs/2506.15910", "authors": ["Zakria Qadir", "Muhammad Bilal", "Guoqiang Liu", "Xiaolong Xu"], "title": "Autonomous Trajectory Optimization for UAVs in Disaster Zone Using Henry Gas Optimization Scheme", "categories": ["eess.SY", "cs.DC", "cs.NI", "cs.SY", "C.2; I.6"], "comment": "12 pages, 9 figuers", "summary": "The unmanned aerial vehicles (UAVs) in a disaster-prone environment plays\nimportant role in assisting the rescue services and providing the internet\nconnectivity with the outside world. However, in such a complex environment the\nselection of optimum trajectory of UAVs is of utmost importance. UAV trajectory\noptimization deals with finding the shortest path in the minimal possible time.\nIn this paper, a cluster optimization scheme (COS) is proposed using the Henry\ngas optimization (HGO) metaheuristic algorithm to identify the shortest path\nhaving minimal transportation cost and algorithm complexity. The mathematical\nmodel is designed for COS using the HGO algorithm and compared with the\nstate-of-the-art metaheuristic algorithms such as particle swarm optimization\n(PSO), grey wolf optimization (GWO), cuckoo search algorithm (CSA) and\nbarnacles mating optimizer (BMO). In order to prove the robustness of the\nproposed model, four different scenarios are evaluated that includes ambient\nenvironment, constrict environment, tangled environment, and complex\nenvironment. In all the aforementioned scenarios, the HGO algorithm outperforms\nthe existing algorithms. Particularly, in the ambient environment, the HGO\nalgorithm achieves a 39.3% reduction in transportation cost and a 16.8%\nreduction in computational time as compared to the PSO algorithm. Hence, the\nHGO algorithm can be used for autonomous trajectory optimization of UAVs in\nsmart cities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ea8\u5229\u6c14\u4f53\u4f18\u5316\uff08HGO\uff09\u7684\u96c6\u7fa4\u4f18\u5316\u65b9\u6848\uff08COS\uff09\uff0c\u7528\u4e8e\u65e0\u4eba\u673a\uff08UAV\uff09\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u8f68\u8ff9\u4f18\u5316\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8fd0\u8f93\u6210\u672c\u548c\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u5728\u707e\u5bb3\u9891\u53d1\u73af\u5883\u4e2d\uff0c\u65e0\u4eba\u673a\uff08UAV\uff09\u7684\u8f68\u8ff9\u4f18\u5316\u5bf9\u6551\u63f4\u670d\u52a1\u548c\u7f51\u7edc\u8fde\u63a5\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7b97\u6cd5\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u8868\u73b0\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528HGO\u7b97\u6cd5\u8bbe\u8ba1\u6570\u5b66\u6a21\u578b\uff0c\u5e76\u4e0ePSO\u3001GWO\u3001CSA\u548cBMO\u7b49\u73b0\u6709\u7b97\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "HGO\u7b97\u6cd5\u5728\u56db\u79cd\u4e0d\u540c\u73af\u5883\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\uff0c\u5c24\u5176\u5728\u666e\u901a\u73af\u5883\u4e2d\uff0c\u8fd0\u8f93\u6210\u672c\u964d\u4f4e39.3%\uff0c\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c1116.8%\u3002", "conclusion": "HGO\u7b97\u6cd5\u9002\u7528\u4e8e\u667a\u80fd\u57ce\u5e02\u4e2d\u65e0\u4eba\u673a\u7684\u81ea\u4e3b\u8f68\u8ff9\u4f18\u5316\u3002"}}
{"id": "2506.16015", "pdf": "https://arxiv.org/pdf/2506.16015", "abs": "https://arxiv.org/abs/2506.16015", "authors": ["Craig S. Wright"], "title": "Bayesian Epistemology with Weighted Authority: A Formal Architecture for Truth-Promoting Autonomous Scientific Reasoning", "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.LO", "math.LO", "68T27, 03B70, 68P20", "I.2.3; F.4.1; H.2.8"], "comment": "91 pages, 0 figures, includes mathematical appendix and formal\n  proofs. Designed as a foundational submission for a modular autonomous\n  epistemic reasoning system. Suitable for logic in computer science, AI\n  epistemology, and scientific informatics", "summary": "The exponential expansion of scientific literature has surpassed the\nepistemic processing capabilities of both human experts and current artificial\nintelligence systems. This paper introduces Bayesian Epistemology with Weighted\nAuthority (BEWA), a formally structured architecture that operationalises\nbelief as a dynamic, probabilistically coherent function over structured\nscientific claims. Each claim is contextualised, author-attributed, and\nevaluated through a system of replication scores, citation weighting, and\ntemporal decay. Belief updates are performed via evidence-conditioned Bayesian\ninference, contradiction processing, and epistemic decay mechanisms. The\narchitecture supports graph-based claim propagation, authorial credibility\nmodelling, cryptographic anchoring, and zero-knowledge audit verification. By\nformalising scientific reasoning into a computationally verifiable epistemic\nnetwork, BEWA advances the foundation for machine reasoning systems that\npromote truth utility, rational belief convergence, and audit-resilient\nintegrity across dynamic scientific domains.", "AI": {"tldr": "BEWA\u662f\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u63a8\u7406\u7684\u67b6\u6784\uff0c\u7528\u4e8e\u52a8\u6001\u8bc4\u4f30\u79d1\u5b66\u4e3b\u5f20\uff0c\u7ed3\u5408\u4e86\u590d\u5236\u5206\u6570\u3001\u5f15\u7528\u6743\u91cd\u548c\u65f6\u95f4\u8870\u51cf\u673a\u5236\u3002", "motivation": "\u79d1\u5b66\u6587\u732e\u7684\u7206\u70b8\u5f0f\u589e\u957f\u8d85\u51fa\u4e86\u4eba\u7c7b\u548cAI\u7cfb\u7edf\u7684\u5904\u7406\u80fd\u529b\uff0c\u9700\u8981\u4e00\u79cd\u7ed3\u6784\u5316\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u548c\u66f4\u65b0\u79d1\u5b66\u4e3b\u5f20\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "BEWA\u901a\u8fc7\u8d1d\u53f6\u65af\u63a8\u7406\u3001\u77db\u76fe\u5904\u7406\u548c\u77e5\u8bc6\u8870\u51cf\u673a\u5236\u52a8\u6001\u66f4\u65b0\u4fe1\u5ff5\uff0c\u652f\u6301\u57fa\u4e8e\u56fe\u7684\u4f20\u64ad\u3001\u4f5c\u8005\u53ef\u4fe1\u5ea6\u5efa\u6a21\u548c\u52a0\u5bc6\u9a8c\u8bc1\u3002", "result": "BEWA\u4e3a\u673a\u5668\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u9a8c\u8bc1\u7684\u8ba4\u77e5\u7f51\u7edc\uff0c\u4fc3\u8fdb\u4e86\u771f\u7406\u6548\u7528\u3001\u7406\u6027\u4fe1\u5ff5\u6536\u655b\u548c\u5ba1\u8ba1\u5f39\u6027\u3002", "conclusion": "BEWA\u4e3a\u52a8\u6001\u79d1\u5b66\u9886\u57df\u4e2d\u7684\u673a\u5668\u63a8\u7406\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u57fa\u7840\uff0c\u589e\u5f3a\u4e86\u79d1\u5b66\u4e3b\u5f20\u7684\u53ef\u4fe1\u5ea6\u548c\u5b8c\u6574\u6027\u3002"}}
{"id": "2506.17084", "pdf": "https://arxiv.org/pdf/2506.17084", "abs": "https://arxiv.org/abs/2506.17084", "authors": ["Vladislav Esaulov", "Jieyang Chen", "Norbert Podhorszki", "Fred Suter", "Scott Klasky", "Anu G Bourgeois", "Lipeng Wan"], "title": "JANUS: Resilient and Adaptive Data Transmission for Enabling Timely and Efficient Cross-Facility Scientific Workflows", "categories": ["cs.DC", "cs.NI", "cs.PF"], "comment": null, "summary": "In modern science, the growing complexity of large-scale projects has\nincreased reliance on cross-facility workflows, where institutions share\nresources and expertise to accelerate discovery. These workflows often involve\ntransferring massive data over wide-area networks. While high-speed networks\nlike ESnet and data transfer services like Globus have improved data mobility,\nchallenges remain. Large data volumes can strain bandwidth, TCP suffers from\nretransmissions due to packet loss, and traditional fault-tolerance methods\nlike erasure coding introduce significant overhead.\n  This paper presents JANUS, a resilient and adaptive data transmission\napproach for cross-facility scientific workflows. JANUS uses UDP, integrates\nerasure coding for fault tolerance, and applies error-bounded lossy compression\nto reduce overhead. This design enables users to balance transmission time and\naccuracy based on specific needs. JANUS also adapts coding parameters to\nreal-time network conditions and uses optimization models to determine ideal\nconfigurations. Experiments show that JANUS significantly improves data\ntransfer efficiency while preserving fidelity.", "AI": {"tldr": "JANUS\u662f\u4e00\u79cd\u7528\u4e8e\u8de8\u8bbe\u65bd\u79d1\u5b66\u5de5\u4f5c\u6d41\u7684\u81ea\u9002\u5e94\u6570\u636e\u4f20\u8f93\u65b9\u6cd5\uff0c\u901a\u8fc7UDP\u3001\u7ea0\u5220\u7801\u548c\u6709\u635f\u538b\u7f29\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u73b0\u4ee3\u79d1\u5b66\u9879\u76ee\u4e2d\uff0c\u8de8\u8bbe\u65bd\u5de5\u4f5c\u6d41\u7684\u6570\u636e\u4f20\u8f93\u9762\u4e34\u5e26\u5bbd\u538b\u529b\u3001TCP\u91cd\u4f20\u548c\u7ea0\u5220\u7801\u9ad8\u5f00\u9500\u7b49\u95ee\u9898\u3002", "method": "JANUS\u7ed3\u5408UDP\u3001\u7ea0\u5220\u7801\u548c\u8bef\u5dee\u6709\u754c\u538b\u7f29\uff0c\u52a8\u6001\u8c03\u6574\u7f16\u7801\u53c2\u6570\u4ee5\u9002\u5e94\u7f51\u7edc\u6761\u4ef6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cJANUS\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u4f20\u8f93\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6570\u636e\u4fdd\u771f\u5ea6\u3002", "conclusion": "JANUS\u4e3a\u8de8\u8bbe\u65bd\u79d1\u5b66\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u6570\u636e\u4f20\u8f93\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16557", "pdf": "https://arxiv.org/pdf/2506.16557", "abs": "https://arxiv.org/abs/2506.16557", "authors": ["Hern\u00e1n Gagliardi", "Victor Braberman", "Sebastian Uchitel"], "title": "Scaling GR(1) Synthesis via a Compositional Framework for LTL Discrete Event Control", "categories": ["cs.SE"], "comment": "To be published in CAV25", "summary": "We present a compositional approach to controller synthesis of discrete event\nsystem controllers with linear temporal logic (LTL) goals. We exploit the\nmodular structure of the plant to be controlled, given as a set of labelled\ntransition systems (LTS), to mitigate state explosion that monolithic\napproaches to synthesis are prone to. Maximally permissive safe controllers are\niteratively built for subsets of the plant LTSs by solving weaker control\nproblems. Observational synthesis equivalence is used to reduce the size of the\ncontrolled subset of the plant by abstracting away local events. The result of\nsynthesis is also compositional, a set of controllers that when run in parallel\nensure the LTL goal. We implement synthesis in the MTSA tool for an expressive\nsubset of LTL, GR(1), and show it computes solutions to that can be up to 1000\ntimes larger than those that the monolithic approach can solve.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u5757\u5316\u7684\u79bb\u6563\u4e8b\u4ef6\u7cfb\u7edf\u63a7\u5236\u5668\u5408\u6210\u65b9\u6cd5\uff0c\u5229\u7528\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\uff08LTL\uff09\u76ee\u6807\uff0c\u901a\u8fc7\u5206\u89e3\u95ee\u9898\u7f13\u89e3\u72b6\u6001\u7206\u70b8\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u6574\u4f53\u5408\u6210\u65b9\u6cd5\u56e0\u72b6\u6001\u7206\u70b8\u95ee\u9898\u800c\u96be\u4ee5\u5904\u7406\u5927\u89c4\u6a21\u7cfb\u7edf\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u6a21\u5757\u5316\u7ed3\u6784\uff0c\u901a\u8fc7\u9010\u6b65\u89e3\u51b3\u8f83\u5f31\u7684\u63a7\u5236\u95ee\u9898\u6784\u5efa\u6700\u5927\u5141\u8bb8\u5b89\u5168\u63a7\u5236\u5668\uff0c\u5e76\u4f7f\u7528\u89c2\u6d4b\u5408\u6210\u7b49\u4ef7\u6027\u51cf\u5c11\u5c40\u90e8\u4e8b\u4ef6\u3002", "result": "\u5408\u6210\u7ed3\u679c\u5177\u6709\u6a21\u5757\u5316\u7279\u6027\uff0c\u63a7\u5236\u5668\u5e76\u884c\u8fd0\u884c\u65f6\u80fd\u786e\u4fddLTL\u76ee\u6807\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u53ef\u5904\u7406\u6bd4\u6574\u4f53\u65b9\u6cd5\u59271000\u500d\u7684\u95ee\u9898\u3002", "conclusion": "\u6a21\u5757\u5316\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5408\u6210\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u7cfb\u7edf\u3002"}}
{"id": "2506.15758", "pdf": "https://arxiv.org/pdf/2506.15758", "abs": "https://arxiv.org/abs/2506.15758", "authors": ["Marcel Wien\u00f6bst", "Sebastian Weichwald", "Leonard Henckel"], "title": "Linear-Time Primitives for Algorithm Development in Graphical Causal Inference", "categories": ["cs.AI", "cs.DS", "cs.LG", "stat.ME", "stat.ML"], "comment": null, "summary": "We introduce CIfly, a framework for efficient algorithmic primitives in\ngraphical causal inference that isolates reachability as a reusable core\noperation. It builds on the insight that many causal reasoning tasks can be\nreduced to reachability in purpose-built state-space graphs that can be\nconstructed on the fly during traversal. We formalize a rule table schema for\nspecifying such algorithms and prove they run in linear time. We establish\nCIfly as a more efficient alternative to the common primitives moralization and\nlatent projection, which we show are computationally equivalent to Boolean\nmatrix multiplication. Our open-source Rust implementation parses rule table\ntext files and runs the specified CIfly algorithms providing high-performance\nexecution accessible from Python and R. We demonstrate CIfly's utility by\nre-implementing a range of established causal inference tasks within the\nframework and by developing new algorithms for instrumental variables. These\ncontributions position CIfly as a flexible and scalable backbone for graphical\ncausal inference, guiding algorithm development and enabling easy and efficient\ndeployment.", "AI": {"tldr": "CIfly\u662f\u4e00\u4e2a\u9ad8\u6548\u7684\u56fe\u5f62\u56e0\u679c\u63a8\u65ad\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u7b80\u5316\u4e3a\u72b6\u6001\u7a7a\u95f4\u56fe\u4e2d\u7684\u53ef\u8fbe\u6027\u95ee\u9898\uff0c\u63d0\u4f9b\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u63a8\u7406\u539f\u8bed\uff08\u5982\u9053\u5fb7\u5316\u548c\u6f5c\u5728\u6295\u5f71\uff09\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0cCIfly\u65e8\u5728\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u89c4\u5219\u8868\u6a21\u5f0f\u8bbe\u8ba1\u7b97\u6cd5\uff0c\u6784\u5efa\u52a8\u6001\u72b6\u6001\u7a7a\u95f4\u56fe\uff0c\u5e76\u8bc1\u660e\u5176\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "result": "CIfly\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u652f\u6301Python\u548cR\u7684\u9ad8\u6548\u6267\u884c\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e\u5de5\u5177\u53d8\u91cf\u7b49\u65b0\u7b97\u6cd5\u3002", "conclusion": "CIfly\u4e3a\u56fe\u5f62\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u7b80\u5316\u4e86\u7b97\u6cd5\u5f00\u53d1\u548c\u90e8\u7f72\u3002"}}
{"id": "2506.15691", "pdf": "https://arxiv.org/pdf/2506.15691", "abs": "https://arxiv.org/abs/2506.15691", "authors": ["Chuheng Zhang", "Tim Pearce", "Pushi Zhang", "Kaixin Wang", "Xiaoyu Chen", "Wei Shen", "Li Zhao", "Jiang Bian"], "title": "What Do Latent Action Models Actually Learn?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Latent action models (LAMs) aim to learn action-relevant changes from\nunlabeled videos by compressing changes between frames as latents. However,\ndifferences between video frames can be caused by controllable changes as well\nas exogenous noise, leading to an important concern -- do latents capture the\nchanges caused by actions or irrelevant noise? This paper studies this issue\nanalytically, presenting a linear model that encapsulates the essence of LAM\nlearning, while being tractable.This provides several insights, including\nconnections between LAM and principal component analysis (PCA), desiderata of\nthe data-generating policy, and justification of strategies to encourage\nlearning controllable changes using data augmentation, data cleaning, and\nauxiliary action-prediction. We also provide illustrative results based on\nnumerical simulation, shedding light on the specific structure of observations,\nactions, and noise in data that influence LAM learning.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6f5c\u5728\u52a8\u4f5c\u6a21\u578b\uff08LAMs\uff09\u5728\u65e0\u6807\u7b7e\u89c6\u9891\u4e2d\u5b66\u4e60\u52a8\u4f5c\u76f8\u5173\u53d8\u5316\u65f6\uff0c\u662f\u5426\u6355\u6349\u5230\u65e0\u5173\u566a\u58f0\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u7ebf\u6027\u6a21\u578b\u8fdb\u884c\u5206\u6790\u3002", "motivation": "\u63a2\u8ba8LAMs\u662f\u5426\u80fd\u591f\u533a\u5206\u7531\u52a8\u4f5c\u5f15\u8d77\u7684\u53d8\u5316\u4e0e\u65e0\u5173\u566a\u58f0\uff0c\u4ece\u800c\u6539\u8fdb\u6a21\u578b\u5b66\u4e60\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u5206\u6790\u7684\u7ebf\u6027\u6a21\u578b\uff0c\u8fde\u63a5LAM\u4e0ePCA\uff0c\u5e76\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u3001\u6570\u636e\u6e05\u7406\u548c\u8f85\u52a9\u52a8\u4f5c\u9884\u6d4b\u7b56\u7565\u4f18\u5316\u5b66\u4e60\u3002", "result": "\u901a\u8fc7\u6570\u503c\u6a21\u62df\u63ed\u793a\u4e86\u89c2\u6d4b\u6570\u636e\u3001\u52a8\u4f5c\u548c\u566a\u58f0\u7ed3\u6784\u5bf9LAM\u5b66\u4e60\u7684\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u6570\u636e\u751f\u6210\u7b56\u7565\u7684\u8bbe\u8ba1\u548c\u4f18\u5316\u65b9\u6cd5\u5bf9LAM\u5b66\u4e60\u53ef\u63a7\u53d8\u5316\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2506.16545", "pdf": "https://arxiv.org/pdf/2506.16545", "abs": "https://arxiv.org/abs/2506.16545", "authors": ["Marco Stadler", "Michael Vierhauser", "Michael Riegler", "Daniel Waghubinger", "Johannes Sametinger"], "title": "SAFER-D: A Self-Adaptive Security Framework for Distributed Computing Architectures", "categories": ["cs.CR", "cs.NI"], "comment": "Preprint accepted for publication at 19th European Conference on\n  Software Architecture (ECSA)", "summary": "The rise of the Internet of Things and Cyber-Physical Systems has introduced\nnew challenges on ensuring secure and robust communication. The growing number\nof connected devices increases network complexity, leading to higher latency\nand traffic. Distributed computing architectures (DCAs) have gained prominence\nto address these issues. This shift has significantly expanded the attack\nsurface, requiring additional security measures to protect all components --\nfrom sensors and actuators to edge nodes and central servers. Recent incidents\nhighlight the difficulty of this task: Cyberattacks, like distributed denial of\nservice attacks, continue to pose severe threats and cause substantial damage.\nImplementing a holistic defense mechanism remains an open challenge,\nparticularly against attacks that demand both enhanced resilience and rapid\nresponse. Addressing this gap requires innovative solutions to enhance the\nsecurity of DCAs. In this work, we present our holistic self-adaptive security\nframework which combines different adaptation strategies to create\ncomprehensive and efficient defense mechanisms. We describe how to incorporate\nthe framework into a real-world use case scenario and further evaluate its\napplicability and efficiency. Our evaluation yields promising results,\nindicating great potential to further extend the research on our framework.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u7684\u5b89\u5168\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5206\u5e03\u5f0f\u8ba1\u7b97\u67b6\u6784\u4e2d\u7684\u7f51\u7edc\u5b89\u5168\u6311\u6218\u3002", "motivation": "\u968f\u7740\u7269\u8054\u7f51\u548c\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u7684\u666e\u53ca\uff0c\u7f51\u7edc\u590d\u6742\u6027\u548c\u653b\u51fb\u9762\u589e\u52a0\uff0c\u4f20\u7edf\u5b89\u5168\u673a\u5236\u96be\u4ee5\u5e94\u5bf9\u65b0\u578b\u653b\u51fb\uff0c\u5982\u5206\u5e03\u5f0f\u62d2\u7edd\u670d\u52a1\u653b\u51fb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u7684\u5b89\u5168\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u79cd\u9002\u5e94\u7b56\u7565\uff0c\u6784\u5efa\u5168\u9762\u4e14\u9ad8\u6548\u7684\u9632\u5fa1\u673a\u5236\uff0c\u5e76\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u9a8c\u8bc1\u5176\u9002\u7528\u6027\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u8be5\u6846\u67b6\u5177\u6709\u9ad8\u6548\u6027\u548c\u6269\u5c55\u6f5c\u529b\u3002", "conclusion": "\u8be5\u81ea\u9002\u5e94\u5b89\u5168\u6846\u67b6\u4e3a\u89e3\u51b3\u5206\u5e03\u5f0f\u8ba1\u7b97\u67b6\u6784\u7684\u5b89\u5168\u95ee\u9898\u63d0\u4f9b\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5c55\u793a\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.16051", "pdf": "https://arxiv.org/pdf/2506.16051", "abs": "https://arxiv.org/abs/2506.16051", "authors": ["Zhiwei Li", "Carl Kesselman", "Tran Huy Nguyen", "Benjamin Yixing Xu", "Kyle Bolo", "Kimberley Yu"], "title": "From Data to Decision: Data-Centric Infrastructure for Reproducible ML in Collaborative eScience", "categories": ["cs.LG", "cs.DB", "cs.DL", "cs.HC"], "comment": null, "summary": "Reproducibility remains a central challenge in machine learning (ML),\nespecially in collaborative eScience projects where teams iterate over data,\nfeatures, and models. Current ML workflows are often dynamic yet fragmented,\nrelying on informal data sharing, ad hoc scripts, and loosely connected tools.\nThis fragmentation impedes transparency, reproducibility, and the adaptability\nof experiments over time. This paper introduces a data-centric framework for\nlifecycle-aware reproducibility, centered around six structured artifacts:\nDataset, Feature, Workflow, Execution, Asset, and Controlled Vocabulary. These\nartifacts formalize the relationships between data, code, and decisions,\nenabling ML experiments to be versioned, interpretable, and traceable over\ntime. The approach is demonstrated through a clinical ML use case of glaucoma\ndetection, illustrating how the system supports iterative exploration, improves\nreproducibility, and preserves the provenance of collaborative decisions across\nthe ML lifecycle.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u516d\u4e2a\u7ed3\u6784\u5316\u5de5\u4ef6\uff08\u6570\u636e\u96c6\u3001\u7279\u5f81\u3001\u5de5\u4f5c\u6d41\u3001\u6267\u884c\u3001\u8d44\u4ea7\u548c\u63a7\u5236\u8bcd\u6c47\uff09\u63d0\u5347\u673a\u5668\u5b66\u4e60\u5b9e\u9a8c\u7684\u53ef\u91cd\u73b0\u6027\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u53ef\u91cd\u73b0\u6027\u662f\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u534f\u4f5c\u5f0f\u7535\u5b50\u79d1\u5b66\u9879\u76ee\u4e2d\u3002\u5f53\u524d\u7684\u5de5\u4f5c\u6d41\u7a0b\u52a8\u6001\u4f46\u788e\u7247\u5316\uff0c\u963b\u788d\u4e86\u900f\u660e\u5ea6\u548c\u5b9e\u9a8c\u7684\u9002\u5e94\u6027\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u6846\u67b6\uff0c\u56f4\u7ed5\u516d\u4e2a\u7ed3\u6784\u5316\u5de5\u4ef6\uff0c\u5f62\u5f0f\u5316\u6570\u636e\u3001\u4ee3\u7801\u548c\u51b3\u7b56\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u901a\u8fc7\u9752\u5149\u773c\u68c0\u6d4b\u7684\u4e34\u5e8a\u6848\u4f8b\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u5982\u4f55\u652f\u6301\u8fed\u4ee3\u63a2\u7d22\u3001\u63d0\u5347\u53ef\u91cd\u73b0\u6027\u5e76\u4fdd\u7559\u534f\u4f5c\u51b3\u7b56\u7684\u6eaf\u6e90\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u673a\u5668\u5b66\u4e60\u7684\u751f\u547d\u5468\u671f\u63d0\u4f9b\u4e86\u53ef\u7248\u672c\u5316\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u8ffd\u6eaf\u7684\u5b9e\u9a8c\u7ba1\u7406\u65b9\u6cd5\u3002"}}
{"id": "2506.15875", "pdf": "https://arxiv.org/pdf/2506.15875", "abs": "https://arxiv.org/abs/2506.15875", "authors": ["Dirk Van Essendelft", "Patrick Wingo", "Terry Jordan", "Ryan Smith", "Wissam Saidi"], "title": "A System Level Compiler for Massively-Parallel, Spatial, Dataflow Architectures", "categories": ["cs.PL", "cs.AR", "cs.DC", "cs.ET", "D.3; D.1; I.6; J.2"], "comment": "26 pages, 5 figures, 14 listings", "summary": "We have developed a novel compiler called the Multiple-Architecture Compiler\nfor Advanced Computing Hardware (MACH) designed specifically for\nmassively-parallel, spatial, dataflow architectures like the Wafer Scale\nEngine. Additionally, MACH can execute code on traditional unified-memory\ndevices. MACH addresses the complexities in compiling for spatial architectures\nthrough a conceptual Virtual Machine, a flexible domain-specific language, and\na compiler that can lower high-level languages to machine-specific code in\ncompliance with the Virtual Machine concept. While MACH is designed to be\noperable on several architectures and provide the flexibility for several\nstandard and user-defined data mappings, we introduce the concept with dense\ntensor examples from NumPy and show lowering to the Wafer Scale Engine by\ntargeting Cerebras' hardware specific languages.", "AI": {"tldr": "MACH\u662f\u4e00\u79cd\u65b0\u578b\u7f16\u8bd1\u5668\uff0c\u4e13\u4e3a\u5927\u89c4\u6a21\u5e76\u884c\u3001\u7a7a\u95f4\u6570\u636e\u6d41\u67b6\u6784\u8bbe\u8ba1\uff0c\u540c\u65f6\u652f\u6301\u4f20\u7edf\u7edf\u4e00\u5185\u5b58\u8bbe\u5907\u3002\u5b83\u901a\u8fc7\u865a\u62df\u673a\u548c\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u7b80\u5316\u7f16\u8bd1\u8fc7\u7a0b\u3002", "motivation": "\u89e3\u51b3\u7a7a\u95f4\u67b6\u6784\u7f16\u8bd1\u7684\u590d\u6742\u6027\uff0c\u63d0\u4f9b\u8de8\u67b6\u6784\u7075\u6d3b\u6027\u3002", "method": "\u91c7\u7528\u865a\u62df\u673a\u6982\u5ff5\u3001\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff0c\u5c06\u9ad8\u7ea7\u8bed\u8a00\u7f16\u8bd1\u4e3a\u673a\u5668\u7279\u5b9a\u4ee3\u7801\u3002", "result": "\u6210\u529f\u5c55\u793a\u4e86\u5728NumPy\u5bc6\u96c6\u5f20\u91cf\u4e0a\u7684\u5e94\u7528\uff0c\u5e76\u9488\u5bf9Cerebras\u786c\u4ef6\u8bed\u8a00\u8fdb\u884c\u7f16\u8bd1\u3002", "conclusion": "MACH\u4e3a\u7a7a\u95f4\u67b6\u6784\u7f16\u8bd1\u63d0\u4f9b\u4e86\u9ad8\u6548\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16586", "pdf": "https://arxiv.org/pdf/2506.16586", "abs": "https://arxiv.org/abs/2506.16586", "authors": ["Ihor Pysmennyi", "Roman Kyslyi", "Kyrylo Kleshch"], "title": "AI-Driven Tools in Modern Software Quality Assurance: An Assessment of Benefits, Challenges, and Future Directions", "categories": ["cs.SE", "cs.AI"], "comment": "11 pages, 9 figures", "summary": "Traditional quality assurance (QA) methods face significant challenges in\naddressing the complexity, scale, and rapid iteration cycles of modern software\nsystems and are strained by limited resources available, leading to substantial\ncosts associated with poor quality. The object of this research is the Quality\nAssurance processes for modern distributed software applications. The subject\nof the research is the assessment of the benefits, challenges, and prospects of\nintegrating modern AI-oriented tools into quality assurance processes. We\nperformed comprehensive analysis of implications on both verification and\nvalidation processes covering exploratory test analyses, equivalence\npartitioning and boundary analyses, metamorphic testing, finding\ninconsistencies in acceptance criteria (AC), static analyses, test case\ngeneration, unit test generation, test suit optimization and assessment, end to\nend scenario execution. End to end regression of sample enterprise application\nutilizing AI-agents over generated test scenarios was implemented as a proof of\nconcept highlighting practical use of the study. The results, with only 8.3%\nflaky executions of generated test cases, indicate significant potential for\nthe proposed approaches. However, the study also identified substantial\nchallenges for practical adoption concerning generation of semantically\nidentical coverage, \"black box\" nature and lack of explainability from\nstate-of-the-art Large Language Models (LLMs), the tendency to correct mutated\ntest cases to match expected results, underscoring the necessity for thorough\nverification of both generated artifacts and test execution results. The\nresearch demonstrates AI's transformative potential for QA but highlights the\nimportance of a strategic approach to implementing these technologies,\nconsidering the identified limitations and the need for developing appropriate\nverification methodologies.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5c06\u73b0\u4ee3AI\u5de5\u5177\u96c6\u6210\u5230\u8d28\u91cf\u4fdd\u8bc1\uff08QA\uff09\u6d41\u7a0b\u4e2d\u7684\u6f5c\u529b\u4e0e\u6311\u6218\uff0c\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u4f46\u540c\u65f6\u4e5f\u6307\u51fa\u4e86\u8bed\u4e49\u8986\u76d6\u3001\u9ed1\u76d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7b49\u5173\u952e\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfQA\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u73b0\u4ee3\u8f6f\u4ef6\u7cfb\u7edf\u7684\u590d\u6742\u6027\u3001\u89c4\u6a21\u548c\u5feb\u901f\u8fed\u4ee3\uff0c\u8d44\u6e90\u6709\u9650\u5bfc\u81f4\u8d28\u91cf\u6210\u672c\u9ad8\uff0c\u56e0\u6b64\u7814\u7a76AI\u5de5\u5177\u5728QA\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u7efc\u5408\u5206\u6790\u4e86AI\u5de5\u5177\u5bf9\u9a8c\u8bc1\u548c\u9a8c\u8bc1\u8fc7\u7a0b\u7684\u5f71\u54cd\uff0c\u5305\u62ec\u6d4b\u8bd5\u5206\u6790\u3001\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u7b49\uff0c\u5e76\u901a\u8fc7\u4f01\u4e1a\u5e94\u7528\u7684\u7aef\u5230\u7aef\u56de\u5f52\u6d4b\u8bd5\u9a8c\u8bc1\u3002", "result": "\u751f\u6210\u7684\u6d4b\u8bd5\u7528\u4f8b\u4ec5\u67098.3%\u7684\u4e0d\u7a33\u5b9a\u6267\u884c\uff0c\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u4e5f\u53d1\u73b0\u8bed\u4e49\u8986\u76d6\u3001\u9ed1\u76d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7b49\u6311\u6218\u3002", "conclusion": "AI\u5728QA\u4e2d\u5177\u6709\u53d8\u9769\u6f5c\u529b\uff0c\u4f46\u9700\u6218\u7565\u6027\u5730\u5b9e\u65bd\uff0c\u5e76\u89e3\u51b3\u73b0\u6709\u5c40\u9650\u6027\uff0c\u5f00\u53d1\u5408\u9002\u7684\u9a8c\u8bc1\u65b9\u6cd5\u3002"}}
{"id": "2506.15774", "pdf": "https://arxiv.org/pdf/2506.15774", "abs": "https://arxiv.org/abs/2506.15774", "authors": ["J. Schwardt", "J. C. Budich"], "title": "Advancing Stochastic 3-SAT Solvers by Dissipating Oversatisfied Constraints", "categories": ["cs.AI", "cond-mat.stat-mech", "cs.DS", "math.CO", "68Q25, 68W20, 90C27"], "comment": "5+1 pages, 6+2 figures", "summary": "We introduce and benchmark a stochastic local search heuristic for the\nNP-complete satisfiability problem 3-SAT that drastically outperforms existing\nsolvers in the notoriously difficult realm of critically hard instances. Our\nconstruction is based on the crucial observation that well established previous\napproaches such as WalkSAT are prone to get stuck in local minima that are\ndistinguished from true solutions by a larger number of oversatisfied\ncombinatorial constraints. To address this issue, the proposed algorithm,\ncoined DOCSAT, dissipates oversatisfied constraints (DOC), i.e. reduces their\nunfavorable abundance so as to render them critical. We analyze and benchmark\nour algorithm on a randomly generated sample of hard but satisfiable 3-SAT\ninstances with varying problem sizes up to N=15000. Quite remarkably, we find\nthat DOCSAT outperforms both WalkSAT and other well known algorithms including\nthe complete solver Kissat, even when comparing its ability to solve the\nhardest quintile of the sample to the average performance of its competitors.\nThe essence of DOCSAT may be seen as a way of harnessing statistical structure\nbeyond the primary cost function of a combinatorial problem to avoid or escape\nlocal minima traps in stochastic local search, which opens avenues for\ngeneralization to other optimization problems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDOCSAT\u7684\u968f\u673a\u5c40\u90e8\u641c\u7d22\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b33-SAT\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6c42\u89e3\u5668\uff0c\u5c24\u5176\u5728\u5904\u7406\u6781\u7aef\u56f0\u96be\u5b9e\u4f8b\u65f6\u8868\u73b0\u7a81\u51fa\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\uff08\u5982WalkSAT\uff09\u5bb9\u6613\u9677\u5165\u5c40\u90e8\u6781\u5c0f\u503c\uff0c\u8fd9\u4e9b\u6781\u5c0f\u503c\u4e0e\u771f\u5b9e\u89e3\u7684\u533a\u522b\u5728\u4e8e\u8fc7\u6ee1\u8db3\u7684\u7ec4\u5408\u7ea6\u675f\u8f83\u591a\u3002DOCSAT\u901a\u8fc7\u51cf\u5c11\u8fd9\u4e9b\u7ea6\u675f\u7684\u8d1f\u9762\u5f71\u54cd\u6765\u6539\u8fdb\u6027\u80fd\u3002", "method": "DOCSAT\u7b97\u6cd5\u901a\u8fc7\u6d88\u6563\u8fc7\u6ee1\u8db3\u7ea6\u675f\uff08DOC\uff09\uff0c\u4f7f\u5176\u53d8\u5f97\u5173\u952e\uff0c\u4ece\u800c\u907f\u514d\u6216\u9003\u79bb\u5c40\u90e8\u6781\u5c0f\u503c\u9677\u9631\u3002", "result": "\u5728\u968f\u673a\u751f\u6210\u7684\u56f0\u96be3-SAT\u5b9e\u4f8b\uff08\u89c4\u6a21\u8fbeN=15000\uff09\u4e0a\uff0cDOCSAT\u8868\u73b0\u4f18\u4e8eWalkSAT\u548c\u5176\u4ed6\u77e5\u540d\u7b97\u6cd5\uff08\u5982Kissat\uff09\uff0c\u5c24\u5176\u5728\u5904\u7406\u6700\u56f0\u96be\u7684\u5b9e\u4f8b\u65f6\u3002", "conclusion": "DOCSAT\u7684\u6838\u5fc3\u601d\u60f3\u662f\u5229\u7528\u7ec4\u5408\u95ee\u9898\u7684\u4e3b\u8981\u6210\u672c\u51fd\u6570\u4e4b\u5916\u7684\u7edf\u8ba1\u7ed3\u6784\u6765\u907f\u514d\u5c40\u90e8\u6781\u5c0f\u503c\uff0c\u8fd9\u4e00\u65b9\u6cd5\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u4f18\u5316\u95ee\u9898\u3002"}}
{"id": "2506.15692", "pdf": "https://arxiv.org/pdf/2506.15692", "abs": "https://arxiv.org/abs/2506.15692", "authors": ["Jaehyun Nam", "Jinsung Yoon", "Jiefeng Chen", "Jinwoo Shin", "Sercan \u00d6. Ar\u0131k", "Tomas Pfister"], "title": "MLE-STAR: Machine Learning Engineering Agent via Search and Targeted Refinement", "categories": ["cs.LG"], "comment": null, "summary": "Agents based on large language models (LLMs) for machine learning engineering\n(MLE) can automatically implement ML models via code generation. However,\nexisting approaches to build such agents often rely heavily on inherent LLM\nknowledge and employ coarse exploration strategies that modify the entire code\nstructure at once. This limits their ability to select effective task-specific\nmodels and perform deep exploration within specific components, such as\nexperimenting extensively with feature engineering options. To overcome these,\nwe propose MLE-STAR, a novel approach to build MLE agents. MLE-STAR first\nleverages external knowledge by using a search engine to retrieve effective\nmodels from the web, forming an initial solution, then iteratively refines it\nby exploring various strategies targeting specific ML components. This\nexploration is guided by ablation studies analyzing the impact of individual\ncode blocks. Furthermore, we introduce a novel ensembling method using an\neffective strategy suggested by MLE-STAR. Our experimental results show that\nMLE-STAR achieves medals in 44% of the Kaggle competitions on the MLE-bench,\nsignificantly outperforming the best alternative.", "AI": {"tldr": "MLE-STAR\u662f\u4e00\u79cd\u65b0\u578b\u7684MLE\u4ee3\u7406\u6784\u5efa\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u5916\u90e8\u77e5\u8bc6\u548c\u9488\u5bf9\u6027\u63a2\u7d22\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684MLE\u4ee3\u7406\u4f9d\u8d56\u56fa\u6709\u77e5\u8bc6\u4e14\u63a2\u7d22\u7b56\u7565\u7c97\u7cd9\uff0c\u65e0\u6cd5\u6df1\u5165\u4f18\u5316\u7279\u5b9a\u7ec4\u4ef6\u3002", "method": "MLE-STAR\u5229\u7528\u641c\u7d22\u5f15\u64ce\u83b7\u53d6\u521d\u59cb\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u9488\u5bf9\u6027\u63a2\u7d22\u548c\u6d88\u878d\u7814\u7a76\u8fed\u4ee3\u4f18\u5316\u3002", "result": "MLE-STAR\u572844%\u7684Kaggle\u7ade\u8d5b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8fdc\u8d85\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "MLE-STAR\u901a\u8fc7\u7ed3\u5408\u5916\u90e8\u77e5\u8bc6\u548c\u7cbe\u7ec6\u5316\u63a2\u7d22\uff0c\u663e\u8457\u63d0\u5347\u4e86MLE\u4ee3\u7406\u7684\u6027\u80fd\u3002"}}
{"id": "2506.16444", "pdf": "https://arxiv.org/pdf/2506.16444", "abs": "https://arxiv.org/abs/2506.16444", "authors": ["Kangqi Chen", "Andreas Kosmas Kakolyris", "Rakesh Nadig", "Manos Frouzakis", "Nika Mansouri Ghiasi", "Yu Liang", "Haiyu Mao", "Jisung Park", "Mohammad Sadrosadati", "Onur Mutlu"], "title": "REIS: A High-Performance and Energy-Efficient Retrieval System with In-Storage Processing", "categories": ["cs.CL", "cs.AR", "cs.DB", "H.3.3; I.2.7"], "comment": "Extended version of our publication at the 52nd International\n  Symposium on Computer Architecture (ISCA-52), 2025", "summary": "Large Language Models (LLMs) face an inherent challenge: their knowledge is\nconfined to the data that they have been trained on. To overcome this issue,\nRetrieval-Augmented Generation (RAG) complements the static training-derived\nknowledge of LLMs with an external knowledge repository. RAG consists of three\nstages: indexing, retrieval, and generation. The retrieval stage of RAG becomes\na significant bottleneck in inference pipelines. In this stage, a user query is\nmapped to an embedding vector and an Approximate Nearest Neighbor Search (ANNS)\nalgorithm searches for similar vectors in the database to identify relevant\nitems. Due to the large database sizes, ANNS incurs significant data movement\noverheads between the host and the storage system. To alleviate these\noverheads, prior works propose In-Storage Processing (ISP) techniques that\naccelerate ANNS by performing computations inside storage. However, existing\nworks that leverage ISP for ANNS (i) employ algorithms that are not tailored to\nISP systems, (ii) do not accelerate data retrieval operations for data selected\nby ANNS, and (iii) introduce significant hardware modifications, limiting\nperformance and hindering their adoption. We propose REIS, the first ISP system\ntailored for RAG that addresses these limitations with three key mechanisms.\nFirst, REIS employs a database layout that links database embedding vectors to\ntheir associated documents, enabling efficient retrieval. Second, it enables\nefficient ANNS by introducing an ISP-tailored data placement technique that\ndistributes embeddings across the planes of the storage system and employs a\nlightweight Flash Translation Layer. Third, REIS leverages an ANNS engine that\nuses the existing computational resources inside the storage system. Compared\nto a server-grade system, REIS improves the performance (energy efficiency) of\nretrieval by an average of 13x (55x).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faREIS\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f18\u5316\u5b58\u50a8\u5185\u90e8\u5904\u7406\uff08ISP\uff09\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4e2d\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\uff08ANNS\uff09\u7684\u6027\u80fd\u548c\u80fd\u6548\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u77e5\u8bc6\u53d7\u9650\u4e8e\u8bad\u7ec3\u6570\u636e\uff0c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u901a\u8fc7\u5916\u90e8\u77e5\u8bc6\u5e93\u8865\u5145LLMs\u7684\u9759\u6001\u77e5\u8bc6\uff0c\u4f46\u68c0\u7d22\u9636\u6bb5\u6210\u4e3a\u6027\u80fd\u74f6\u9888\u3002\u73b0\u6709ISP\u6280\u672f\u672a\u9488\u5bf9ANNS\u4f18\u5316\uff0c\u4e14\u786c\u4ef6\u4fee\u6539\u590d\u6742\u3002", "method": "REIS\u7cfb\u7edf\u91c7\u7528\u4e09\u79cd\u673a\u5236\uff1a1\uff09\u6570\u636e\u5e93\u5e03\u5c40\u4f18\u5316\uff0c\u94fe\u63a5\u5d4c\u5165\u5411\u91cf\u4e0e\u6587\u6863\uff1b2\uff09ISP\u5b9a\u5236\u6570\u636e\u653e\u7f6e\u6280\u672f\uff1b3\uff09\u5229\u7528\u5b58\u50a8\u7cfb\u7edf\u73b0\u6709\u8ba1\u7b97\u8d44\u6e90\u7684ANNS\u5f15\u64ce\u3002", "result": "\u4e0e\u670d\u52a1\u5668\u7ea7\u7cfb\u7edf\u76f8\u6bd4\uff0cREIS\u5e73\u5747\u63d0\u5347\u68c0\u7d22\u6027\u80fd13\u500d\uff0c\u80fd\u654855\u500d\u3002", "conclusion": "REIS\u662f\u9996\u4e2a\u9488\u5bf9RAG\u4f18\u5316\u7684ISP\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6280\u672f\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u6548\u7387\u548c\u80fd\u6548\u3002"}}
{"id": "2506.16639", "pdf": "https://arxiv.org/pdf/2506.16639", "abs": "https://arxiv.org/abs/2506.16639", "authors": ["Boqi Chen", "Aren A. Babikian", "Shuzhao Feng", "D\u00e1niel Varr\u00f3", "Gunter Mussbacher"], "title": "LLM-based Satisfiability Checking of String Requirements by Consistent Data and Checker Generation", "categories": ["cs.SE"], "comment": "Accepted at the 33rd IEEE International Requirements Engineering 2025\n  conference", "summary": "Requirements over strings, commonly represented using natural language (NL),\nare particularly relevant for software systems due to their heavy reliance on\nstring data manipulation. While individual requirements can usually be analyzed\nmanually, verifying properties (e.g., satisfiability) over sets of NL\nrequirements is particularly challenging. Formal approaches (e.g., SMT solvers)\nmay efficiently verify such properties, but are known to have theoretical\nlimitations. Additionally, the translation of NL requirements into formal\nconstraints typically requires significant manual effort. Recently, large\nlanguage models (LLMs) have emerged as an alternative approach for formal\nreasoning tasks, but their effectiveness in verifying requirements over strings\nis less studied. In this paper, we introduce a hybrid approach that verifies\nthe satisfiability of NL requirements over strings by using LLMs (1) to derive\na satisfiability outcome (and a consistent string, if possible), and (2) to\ngenerate declarative (i.e., SMT) and imperative (i.e., Python) checkers, used\nto validate the correctness of (1). In our experiments, we assess the\nperformance of four LLMs. Results show that LLMs effectively translate natural\nlanguage into checkers, even achieving perfect testing accuracy for\nPython-based checkers. These checkers substantially help LLMs in generating a\nconsistent string and accurately identifying unsatisfiable requirements,\nleading to more than doubled generation success rate and F1-score in certain\ncases compared to baselines without generated checkers.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u9a8c\u8bc1\u5b57\u7b26\u4e32\u81ea\u7136\u8bed\u8a00\uff08NL\uff09\u9700\u6c42\u7684\u53ef\u6ee1\u8db3\u6027\uff0c\u5e76\u901a\u8fc7\u751f\u6210\u68c0\u67e5\u5668\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u9a8c\u8bc1\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u7684\u53ef\u6ee1\u8db3\u6027\u5728\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\uff08\u5982SMT\u6c42\u89e3\u5668\uff09\u5b58\u5728\u7406\u8bba\u9650\u5236\u4e14\u9700\u8981\u5927\u91cf\u4eba\u5de5\u7ffb\u8bd1\u3002LLMs\u4e3a\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u4f46\u5176\u5728\u5b57\u7b26\u4e32\u9700\u6c42\u9a8c\u8bc1\u4e2d\u7684\u6548\u679c\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u5229\u7528LLMs\uff081\uff09\u751f\u6210\u53ef\u6ee1\u8db3\u6027\u7ed3\u679c\u53ca\u4e00\u81f4\u5b57\u7b26\u4e32\uff0c\uff082\uff09\u751f\u6210\u58f0\u660e\u5f0f\uff08SMT\uff09\u548c\u547d\u4ee4\u5f0f\uff08Python\uff09\u68c0\u67e5\u5668\u4ee5\u9a8c\u8bc1\u7ed3\u679c\u3002\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u56db\u79cdLLMs\u7684\u6027\u80fd\u3002", "result": "LLMs\u80fd\u6709\u6548\u5c06\u81ea\u7136\u8bed\u8a00\u7ffb\u8bd1\u4e3a\u68c0\u67e5\u5668\uff0cPython\u68c0\u67e5\u5668\u6d4b\u8bd5\u51c6\u786e\u7387\u5b8c\u7f8e\u3002\u68c0\u67e5\u5668\u663e\u8457\u63d0\u5347\u4e86LLMs\u751f\u6210\u4e00\u81f4\u5b57\u7b26\u4e32\u548c\u8bc6\u522b\u4e0d\u53ef\u6ee1\u8db3\u9700\u6c42\u7684\u80fd\u529b\uff0c\u67d0\u4e9b\u60c5\u51b5\u4e0b\u751f\u6210\u6210\u529f\u7387\u548cF1\u5206\u6570\u7ffb\u500d\u3002", "conclusion": "\u6df7\u5408\u65b9\u6cd5\u901a\u8fc7LLMs\u548c\u68c0\u67e5\u5668\u7684\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u81ea\u7136\u8bed\u8a00\u5b57\u7b26\u4e32\u9700\u6c42\u9a8c\u8bc1\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2506.16021", "pdf": "https://arxiv.org/pdf/2506.16021", "abs": "https://arxiv.org/abs/2506.16021", "authors": ["Andr\u00e9 van Renssen", "Shuei Sakaguchi"], "title": "Local Routing on Ordered $\u0398$-graphs", "categories": ["cs.CG", "cs.DS"], "comment": null, "summary": "The problem of locally routing on geometric networks using limited memory is\nextensively studied in computational geometry. We consider one particular\ngraph, the ordered $\\Theta$-graph, which is significantly harder to route on\nthan the $\\Theta$-graph, for which a number of routing algorithms are known.\nCurrently, no local routing algorithm is known for the ordered $\\Theta$-graph.\n  We prove that, unfortunately, there does not exist a deterministic memoryless\nlocal routing algorithm that works on the ordered $\\Theta$-graph. This\nmotivates us to consider allowing a small amount of memory, and we present a\ndeterministic $O(1)$-memory local routing algorithm that successfully routes\nfrom the source to the destination on the ordered $\\Theta$-graph. We show that\nour local routing algorithm converges to the destination in $O(n)$ hops, where\n$n$ is the number of vertices. To the best of our knowledge, our algorithm is\nthe first deterministic local routing algorithm that is guaranteed to reach the\ndestination on the ordered $\\Theta$-graph.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.15693", "pdf": "https://arxiv.org/pdf/2506.15693", "abs": "https://arxiv.org/abs/2506.15693", "authors": ["Jiaxing Li", "Hanjiang Hu", "Yujie Yang", "Changliu Liu"], "title": "Verifiable Safety Q-Filters via Hamilton-Jacobi Reachability and Multiplicative Q-Networks", "categories": ["cs.LG"], "comment": "6 pages, 3 figures", "summary": "Recent learning-based safety filters have outperformed conventional methods,\nsuch as hand-crafted Control Barrier Functions (CBFs), by effectively adapting\nto complex constraints. However, these learning-based approaches lack formal\nsafety guarantees. In this work, we introduce a verifiable model-free safety\nfilter based on Hamilton-Jacobi reachability analysis. Our primary\ncontributions include: 1) extending verifiable self-consistency properties for\nQ value functions, 2) proposing a multiplicative Q-network structure to\nmitigate zero-sublevel-set shrinkage issues, and 3) developing a verification\npipeline capable of soundly verifying these self-consistency properties. Our\nproposed approach successfully synthesizes formally verified, model-free safety\ncertificates across four standard safe-control benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eHamilton-Jacobi\u53ef\u8fbe\u6027\u5206\u6790\u7684\u53ef\u9a8c\u8bc1\u65e0\u6a21\u578b\u5b89\u5168\u8fc7\u6ee4\u5668\uff0c\u89e3\u51b3\u4e86\u5b66\u4e60\u578b\u5b89\u5168\u8fc7\u6ee4\u5668\u7f3a\u4e4f\u5f62\u5f0f\u5316\u5b89\u5168\u4fdd\u8bc1\u7684\u95ee\u9898\u3002", "motivation": "\u5b66\u4e60\u578b\u5b89\u5168\u8fc7\u6ee4\u5668\u867d\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u624b\u5de5CBFs\uff09\uff0c\u4f46\u7f3a\u4e4f\u5f62\u5f0f\u5316\u5b89\u5168\u4fdd\u8bc1\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u6269\u5c55Q\u503c\u51fd\u6570\u7684\u53ef\u9a8c\u8bc1\u81ea\u4e00\u81f4\u6027\u5c5e\u6027\uff0c\u63d0\u51fa\u4e58\u6cd5Q\u7f51\u7edc\u7ed3\u6784\u4ee5\u51cf\u5c11\u96f6\u5b50\u6c34\u5e73\u96c6\u6536\u7f29\u95ee\u9898\uff0c\u5f00\u53d1\u9a8c\u8bc1\u7ba1\u9053\u3002", "result": "\u5728\u56db\u4e2a\u6807\u51c6\u5b89\u5168\u63a7\u5236\u57fa\u51c6\u4e0a\u6210\u529f\u5408\u6210\u4e86\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u65e0\u6a21\u578b\u5b89\u5168\u8bc1\u4e66\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b66\u4e60\u578b\u5b89\u5168\u8fc7\u6ee4\u5668\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u5b89\u5168\u4fdd\u8bc1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2506.16654", "pdf": "https://arxiv.org/pdf/2506.16654", "abs": "https://arxiv.org/abs/2506.16654", "authors": ["Vijay Prakash Dwivedi", "Charilaos Kanatsoulis", "Shenyang Huang", "Jure Leskovec"], "title": "Relational Deep Learning: Challenges, Foundations and Next-Generation Architectures", "categories": ["cs.LG", "cs.AI", "cs.DB"], "comment": null, "summary": "Graph machine learning has led to a significant increase in the capabilities\nof models that learn on arbitrary graph-structured data and has been applied to\nmolecules, social networks, recommendation systems, and transportation, among\nother domains. Data in multi-tabular relational databases can also be\nconstructed as 'relational entity graphs' for Relational Deep Learning (RDL) -\na new blueprint that enables end-to-end representation learning without\ntraditional feature engineering. Compared to arbitrary graph-structured data,\nrelational entity graphs have key properties: (i) their structure is defined by\nprimary-foreign key relationships between entities in different tables, (ii)\nthe structural connectivity is a function of the relational schema defining a\ndatabase, and (iii) the graph connectivity is temporal and heterogeneous in\nnature. In this paper, we provide a comprehensive review of RDL by first\nintroducing the representation of relational databases as relational entity\ngraphs, and then reviewing public benchmark datasets that have been used to\ndevelop and evaluate recent GNN-based RDL models. We discuss key challenges\nincluding large-scale multi-table integration and the complexities of modeling\ntemporal dynamics and heterogeneous data, while also surveying foundational\nneural network methods and recent architectural advances specialized for\nrelational entity graphs. Finally, we explore opportunities to unify these\ndistinct modeling challenges, highlighting how RDL converges multiple\nsub-fields in graph machine learning towards the design of foundation models\nthat can transform the processing of relational data.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5173\u7cfb\u6df1\u5ea6\u5b66\u4e60\uff08RDL\uff09\uff0c\u5c06\u591a\u8868\u5173\u7cfb\u6570\u636e\u5e93\u8868\u793a\u4e3a\u5173\u7cfb\u5b9e\u4f53\u56fe\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u5173\u952e\u7279\u6027\u3001\u6311\u6218\u53ca\u6700\u65b0\u6a21\u578b\u8fdb\u5c55\u3002", "motivation": "\u5173\u7cfb\u6570\u636e\u5e93\u7684\u4f20\u7edf\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\uff0cRDL\u901a\u8fc7\u56fe\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u7aef\u5230\u7aef\u8868\u793a\u5b66\u4e60\u7684\u65b0\u84dd\u56fe\u3002", "method": "\u5c06\u5173\u7cfb\u6570\u636e\u5e93\u8868\u793a\u4e3a\u5173\u7cfb\u5b9e\u4f53\u56fe\uff0c\u5e76\u7efc\u8ff0\u4e86\u57fa\u4e8eGNN\u7684RDL\u6a21\u578b\u53ca\u5176\u5728\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u3002", "result": "\u8ba8\u8bba\u4e86\u5927\u89c4\u6a21\u591a\u8868\u96c6\u6210\u3001\u65f6\u95f4\u52a8\u6001\u548c\u5f02\u6784\u6570\u636e\u5efa\u6a21\u7684\u6311\u6218\uff0c\u5e76\u603b\u7ed3\u4e86\u9488\u5bf9\u5173\u7cfb\u5b9e\u4f53\u56fe\u7684\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u3002", "conclusion": "RDL\u6709\u671b\u7edf\u4e00\u56fe\u673a\u5668\u5b66\u4e60\u7684\u591a\u4e2a\u5b50\u9886\u57df\uff0c\u63a8\u52a8\u5173\u7cfb\u6570\u636e\u5904\u7406\u7684\u57fa\u7840\u6a21\u578b\u8bbe\u8ba1\u3002"}}
{"id": "2506.15923", "pdf": "https://arxiv.org/pdf/2506.15923", "abs": "https://arxiv.org/abs/2506.15923", "authors": ["Liangyan Li", "Yangyi Liu", "Yimo Ning", "Stefano Rini", "Jun Chen"], "title": "PNCS:Power-Norm Cosine Similarity for Diverse Client Selection in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Federated Learning (FL) has emerged as a powerful paradigm for leveraging\ndiverse datasets from multiple sources while preserving data privacy by\navoiding centralized storage. However, many existing approaches fail to account\nfor the intricate gradient correlations between remote clients, a limitation\nthat becomes especially problematic in data heterogeneity scenarios. In this\nwork, we propose a novel FL framework utilizing Power-Norm Cosine Similarity\n(PNCS) to improve client selection for model aggregation. By capturing\nhigher-order gradient moments, PNCS addresses non-IID data challenges,\nenhancing convergence speed and accuracy. Additionally, we introduce a simple\nalgorithm ensuring diverse client selection through a selection history queue.\nExperiments with a VGG16 model across varied data partitions demonstrate\nconsistent improvements over state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePower-Norm Cosine Similarity\uff08PNCS\uff09\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6355\u6349\u9ad8\u9636\u68af\u5ea6\u77e9\u89e3\u51b3\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u95ee\u9898\uff0c\u63d0\u5347\u6536\u655b\u901f\u5ea6\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u672a\u5145\u5206\u8003\u8651\u5ba2\u6237\u7aef\u95f4\u68af\u5ea6\u76f8\u5173\u6027\uff0c\u5c24\u5176\u5728\u6570\u636e\u5f02\u6784\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u5229\u7528PNCS\u6539\u8fdb\u5ba2\u6237\u7aef\u9009\u62e9\uff0c\u5e76\u901a\u8fc7\u9009\u62e9\u5386\u53f2\u961f\u5217\u786e\u4fdd\u591a\u6837\u6027\u3002", "result": "\u5728VGG16\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u6570\u636e\u5206\u533a\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "PNCS\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u6570\u636e\u5f02\u6784\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u8054\u90a6\u5b66\u4e60\u7684\u6027\u80fd\u3002"}}
{"id": "2506.16650", "pdf": "https://arxiv.org/pdf/2506.16650", "abs": "https://arxiv.org/abs/2506.16650", "authors": ["Anvith Pabba", "Alex Mathai", "Anindya Chakraborty", "Baishakhi Ray"], "title": "SemAgent: A Semantics Aware Program Repair Agent", "categories": ["cs.SE", "cs.AI", "cs.MA"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive capabilities in downstream\nsoftware engineering tasks such as Automated Program Repair (APR). In\nparticular, there has been a lot of research on repository-level\nissue-resolution benchmarks such as SWE-Bench. Although there has been\nsignificant progress on this topic, we notice that in the process of solving\nsuch issues, existing agentic systems tend to hyper-localize on immediately\nsuspicious lines of code and fix them in isolation, without a deeper\nunderstanding of the issue semantics, code semantics, or execution semantics.\nConsequently, many existing systems generate patches that overfit to the user\nissue, even when a more general fix is preferable. To address this limitation,\nwe introduce SemAgent, a novel workflow-based procedure that leverages issue,\ncode, and execution semantics to generate patches that are complete -\nidentifying and fixing all lines relevant to the issue. We achieve this through\na novel pipeline that (a) leverages execution semantics to retrieve relevant\ncontext, (b) comprehends issue-semantics via generalized abstraction, (c)\nisolates code-semantics within the context of this abstraction, and (d)\nleverages this understanding in a two-stage architecture: a repair stage that\nproposes fine-grained fixes, followed by a reviewer stage that filters relevant\nfixes based on the inferred issue-semantics. Our evaluations show that our\nmethodology achieves a solve rate of 44.66% on the SWEBench-Lite benchmark\nbeating all other workflow-based approaches, and an absolute improvement of\n7.66% compared to our baseline, which lacks such deep semantic understanding.\nWe note that our approach performs particularly well on issues requiring\nmulti-line reasoning (and editing) and edge-case handling, suggesting that\nincorporating issue and code semantics into APR pipelines can lead to robust\nand semantically consistent repairs.", "AI": {"tldr": "SemAgent\u901a\u8fc7\u7ed3\u5408\u95ee\u9898\u3001\u4ee3\u7801\u548c\u6267\u884c\u8bed\u4e49\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5de5\u4f5c\u6d41\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7684\u51c6\u786e\u6027\u548c\u5b8c\u6574\u6027\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u5728\u4fee\u590d\u4ee3\u7801\u95ee\u9898\u65f6\u8fc7\u4e8e\u5c40\u90e8\u5316\uff0c\u7f3a\u4e4f\u5bf9\u95ee\u9898\u3001\u4ee3\u7801\u548c\u6267\u884c\u8bed\u4e49\u7684\u6df1\u5165\u7406\u89e3\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u8865\u4e01\u8fc7\u62df\u5408\u3002", "method": "SemAgent\u91c7\u7528\u4e24\u9636\u6bb5\u67b6\u6784\uff1a\u4fee\u590d\u9636\u6bb5\u63d0\u51fa\u7ec6\u7c92\u5ea6\u4fee\u590d\u5efa\u8bae\uff0c\u8bc4\u5ba1\u9636\u6bb5\u6839\u636e\u95ee\u9898\u8bed\u4e49\u7b5b\u9009\u76f8\u5173\u4fee\u590d\u3002", "result": "\u5728SWEBench-Lite\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSemAgent\u7684\u89e3\u51b3\u7387\u8fbe\u523044.66%\uff0c\u4f18\u4e8e\u5176\u4ed6\u5de5\u4f5c\u6d41\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u884c\u63a8\u7406\u548c\u8fb9\u7f18\u60c5\u51b5\u5904\u7406\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u5c06\u95ee\u9898\u548c\u4ee3\u7801\u8bed\u4e49\u878d\u5165APR\u6d41\u7a0b\u53ef\u4ee5\u751f\u6210\u66f4\u9c81\u68d2\u548c\u8bed\u4e49\u4e00\u81f4\u7684\u4fee\u590d\u3002"}}
{"id": "2506.15694", "pdf": "https://arxiv.org/pdf/2506.15694", "abs": "https://arxiv.org/abs/2506.15694", "authors": ["Iliyas Ibrahim Iliyas", "Souley Boukari", "Abdulsalam Yau Gital"], "title": "Development of a Multiprocessing Interface Genetic Algorithm for Optimising a Multilayer Perceptron for Disease Prediction", "categories": ["cs.LG"], "comment": null, "summary": "This study introduces a framework that integrates nonlinear feature\nextraction, classification, and efficient optimization. First, kernel principal\ncomponent analysis with a radial basis function kernel reduces dimensionality\nwhile preserving 95% of the variance. Second, a multilayer perceptron (MLP)\nlearns to predict disease status. Finally, a modified multiprocessing genetic\nalgorithm (MIGA) optimizes MLP hyperparameters in parallel over ten\ngenerations. We evaluated this approach on three datasets: the Wisconsin\nDiagnostic Breast Cancer dataset, the Parkinson's Telemonitoring dataset, and\nthe chronic kidney disease dataset. The MLP tuned by the MIGA achieved the best\naccuracy of 99.12% for breast cancer, 94.87% for Parkinson's disease, and 100%\nfor chronic kidney disease. These results outperform those of other methods,\nsuch as grid search, random search, and Bayesian optimization. Compared with a\nstandard genetic algorithm, kernel PCA revealed nonlinear relationships that\nimproved classification, and the MIGA's parallel fitness evaluations reduced\nthe tuning time by approximately 60%. The genetic algorithm incurs high\ncomputational cost from sequential fitness evaluations, but our multiprocessing\ninterface GA (MIGA) parallelizes this step, slashing the tuning time and\nsteering the MLP toward the best accuracy score of 99.12%, 94.87%, and 100% for\nbreast cancer, Parkinson's disease, and CKD, respectively.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u975e\u7ebf\u6027\u7279\u5f81\u63d0\u53d6\u3001\u5206\u7c7b\u548c\u9ad8\u6548\u4f18\u5316\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6838\u4e3b\u6210\u5206\u5206\u6790\u3001\u591a\u5c42\u611f\u77e5\u673a\u548c\u5e76\u884c\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u75be\u75c5\u9884\u6d4b\uff0c\u540c\u65f6\u89e3\u51b3\u4f20\u7edf\u9057\u4f20\u7b97\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u6838\u4e3b\u6210\u5206\u5206\u6790\u964d\u7ef4\uff0c\u591a\u5c42\u611f\u77e5\u673a\u5206\u7c7b\uff0c\u5e76\u884c\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u8d85\u53c2\u6570\u3002", "result": "\u5728\u4e73\u817a\u764c\u3001\u5e15\u91d1\u68ee\u75c5\u548c\u6162\u6027\u80be\u75c5\u6570\u636e\u96c6\u4e0a\u5206\u522b\u8fbe\u523099.12%\u300194.87%\u548c100%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u5176\u4ed6\u4f18\u5316\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u7c7b\u51c6\u786e\u7387\u5e76\u964d\u4f4e\u4e86\u4f18\u5316\u65f6\u95f4\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u75be\u75c5\u9884\u6d4b\u4efb\u52a1\u3002"}}
{"id": "2506.16731", "pdf": "https://arxiv.org/pdf/2506.16731", "abs": "https://arxiv.org/abs/2506.16731", "authors": ["Jinlong Pang", "Jiaheng Wei", "Yifan Hua", "Chen Qian", "Yang Liu"], "title": "Incentivizing High-quality Participation From Federated Learning Agents", "categories": ["cs.AI", "cs.DC", "cs.LG"], "comment": null, "summary": "Federated learning (FL) provides a promising paradigm for facilitating\ncollaboration between multiple clients that jointly learn a global model\nwithout directly sharing their local data. However, existing research suffers\nfrom two caveats: 1) From the perspective of agents, voluntary and unselfish\nparticipation is often assumed. But self-interested agents may opt out of the\nsystem or provide low-quality contributions without proper incentives; 2) From\nthe mechanism designer's perspective, the aggregated models can be\nunsatisfactory as the existing game-theoretical federated learning approach for\ndata collection ignores the potential heterogeneous effort caused by\ncontributed data. To alleviate above challenges, we propose an incentive-aware\nframework for agent participation that considers data heterogeneity to\naccelerate the convergence process. Specifically, we first introduce the notion\nof Wasserstein distance to explicitly illustrate the heterogeneous effort and\nreformulate the existing upper bound of convergence. To induce truthful\nreporting from agents, we analyze and measure the generalization error gap of\nany two agents by leveraging the peer prediction mechanism to develop score\nfunctions. We further present a two-stage Stackelberg game model that\nformalizes the process and examines the existence of equilibrium. Extensive\nexperiments on real-world datasets demonstrate the effectiveness of our\nproposed mechanism.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6fc0\u52b1\u611f\u77e5\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u51b3\u81ea\u5229\u4ee3\u7406\u53c2\u4e0e\u4e0d\u8db3\u548c\u6570\u636e\u5f02\u6784\u6027\u95ee\u9898\uff0c\u901a\u8fc7Wasserstein\u8ddd\u79bb\u548cStackelberg\u535a\u5f08\u6a21\u578b\u4f18\u5316\u6536\u655b\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u7814\u7a76\u5047\u8bbe\u4ee3\u7406\u81ea\u613f\u65e0\u79c1\u53c2\u4e0e\uff0c\u4f46\u5b9e\u9645\u4e2d\u81ea\u5229\u4ee3\u7406\u53ef\u80fd\u9000\u51fa\u6216\u63d0\u4f9b\u4f4e\u8d28\u91cf\u8d21\u732e\uff0c\u4e14\u6570\u636e\u5f02\u6784\u6027\u5bfc\u81f4\u805a\u5408\u6a21\u578b\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u5f15\u5165Wasserstein\u8ddd\u79bb\u91cf\u5316\u6570\u636e\u5f02\u6784\u6027\uff0c\u5229\u7528\u5bf9\u7b49\u9884\u6d4b\u673a\u5236\u8bbe\u8ba1\u8bc4\u5206\u51fd\u6570\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5Stackelberg\u535a\u5f08\u6a21\u578b\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u673a\u5236\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6fc0\u52b1\u8bbe\u8ba1\u548c\u5f02\u6784\u6027\u5904\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8054\u90a6\u5b66\u4e60\u7684\u6536\u655b\u901f\u5ea6\u548c\u6a21\u578b\u8d28\u91cf\u3002"}}
{"id": "2506.16653", "pdf": "https://arxiv.org/pdf/2506.16653", "abs": "https://arxiv.org/abs/2506.16653", "authors": ["Vladislav Belozerov", "Peter J Barclay", "Askhan Sami"], "title": "LLMs in Coding and their Impact on the Commercial Software Engineering Landscape", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "Large-language-model coding tools are now mainstream in software engineering.\nBut as these same tools move human effort up the development stack, they\npresent fresh dangers: 10% of real prompts leak private data, 42% of generated\nsnippets hide security flaws, and the models can even ``agree'' with wrong\nideas, a trait called sycophancy. We argue that firms must tag and review every\nAI-generated line of code, keep prompts and outputs inside private or\non-premises deployments, obey emerging safety regulations, and add tests that\ncatch sycophantic answers -- so they can gain speed without losing security and\naccuracy.", "AI": {"tldr": "\u8bba\u6587\u8ba8\u8bba\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7f16\u7801\u5de5\u5177\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u4e3b\u6d41\u5e94\u7528\u53ca\u5176\u6f5c\u5728\u98ce\u9669\uff0c\u5305\u62ec\u9690\u79c1\u6570\u636e\u6cc4\u9732\u3001\u5b89\u5168\u6f0f\u6d1e\u548c\u6a21\u578b\u8fce\u5408\u9519\u8bef\u89c2\u70b9\u7684\u503e\u5411\uff08\u79f0\u4e3a\u201c\u5949\u627f\u201d\uff09\u3002\u4f5c\u8005\u5efa\u8bae\u4f01\u4e1a\u5e94\u5ba1\u67e5AI\u751f\u6210\u7684\u4ee3\u7801\u3001\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u3001\u9075\u5b88\u5b89\u5168\u6cd5\u89c4\uff0c\u5e76\u6d4b\u8bd5\u6a21\u578b\u7684\u5949\u627f\u884c\u4e3a\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7f16\u7801\u5de5\u5177\u7684\u666e\u53ca\uff0c\u5176\u5728\u63d0\u5347\u5f00\u53d1\u6548\u7387\u7684\u540c\u65f6\u4e5f\u5e26\u6765\u4e86\u9690\u79c1\u6cc4\u9732\u3001\u5b89\u5168\u6f0f\u6d1e\u548c\u6a21\u578b\u5949\u627f\u7b49\u65b0\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u5206\u6790\u771f\u5b9e\u63d0\u793a\u548c\u751f\u6210\u4ee3\u7801\u7247\u6bb5\uff0c\u63ed\u793a\u4e86\u9690\u79c1\u6cc4\u9732\u548c\u5b89\u5168\u95ee\u9898\u7684\u666e\u904d\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u6a21\u578b\u5949\u627f\u884c\u4e3a\u7684\u73b0\u8c61\u3002", "result": "\u7814\u7a76\u53d1\u73b010%\u7684\u63d0\u793a\u6cc4\u9732\u9690\u79c1\u6570\u636e\uff0c42%\u7684\u751f\u6210\u4ee3\u7801\u7247\u6bb5\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u4e14\u6a21\u578b\u4f1a\u8fce\u5408\u9519\u8bef\u89c2\u70b9\u3002", "conclusion": "\u4f01\u4e1a\u9700\u5ba1\u67e5AI\u751f\u6210\u7684\u4ee3\u7801\u3001\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u3001\u9075\u5b88\u6cd5\u89c4\uff0c\u5e76\u6d4b\u8bd5\u6a21\u578b\u7684\u5949\u627f\u884c\u4e3a\uff0c\u4ee5\u5e73\u8861\u6548\u7387\u4e0e\u5b89\u5168\u3002"}}
{"id": "2506.16651", "pdf": "https://arxiv.org/pdf/2506.16651", "abs": "https://arxiv.org/abs/2506.16651", "authors": ["Guy Blanc", "Jane Lange", "Carmen Strassle", "Li-Yang Tan"], "title": "A Distributional-Lifting Theorem for PAC Learning", "categories": ["cs.LG", "cs.CC", "cs.DS"], "comment": "COLT 2025", "summary": "The apparent difficulty of efficient distribution-free PAC learning has led\nto a large body of work on distribution-specific learning. Distributional\nassumptions facilitate the design of efficient algorithms but also limit their\nreach and relevance. Towards addressing this, we prove a distributional-lifting\ntheorem: This upgrades a learner that succeeds with respect to a limited\ndistribution family $\\mathcal{D}$ to one that succeeds with respect to any\ndistribution $D^\\star$, with an efficiency overhead that scales with the\ncomplexity of expressing $D^\\star$ as a mixture of distributions in\n$\\mathcal{D}$.\n  Recent work of Blanc, Lange, Malik, and Tan considered the special case of\nlifting uniform-distribution learners and designed a lifter that uses a\nconditional sample oracle for $D^\\star$, a strong form of access not afforded\nby the standard PAC model. Their approach, which draws on ideas from\nsemi-supervised learning, first learns $D^\\star$ and then uses this information\nto lift.\n  We show that their approach is information-theoretically intractable with\naccess only to random examples, thereby giving formal justification for their\nuse of the conditional sample oracle. We then take a different approach that\nsidesteps the need to learn $D^\\star$, yielding a lifter that works in the\nstandard PAC model and enjoys additional advantages: it works for all base\ndistribution families, preserves the noise tolerance of learners, has better\nsample complexity, and is simpler.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u63d0\u5347\u5b9a\u7406\uff0c\u5c06\u6709\u9650\u5206\u5e03\u65cf\u7684\u5b66\u4e60\u5668\u63d0\u5347\u4e3a\u9002\u7528\u4e8e\u4efb\u4f55\u5206\u5e03\u7684\u5b66\u4e60\u5668\uff0c\u6548\u7387\u4e0e\u76ee\u6807\u5206\u5e03\u7684\u590d\u6742\u6027\u76f8\u5173\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u7279\u5b9a\u5b66\u4e60\u7b97\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u6269\u5c55\u5176\u9002\u7528\u8303\u56f4\u3002", "method": "\u63d0\u51fa\u5206\u5e03\u63d0\u5347\u5b9a\u7406\uff0c\u907f\u514d\u5b66\u4e60\u76ee\u6807\u5206\u5e03\uff0c\u76f4\u63a5\u5728\u6807\u51c6PAC\u6a21\u578b\u4e2d\u5b9e\u73b0\u63d0\u5347\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u6807\u51c6PAC\u6a21\u578b\u4e2d\u6709\u6548\uff0c\u9002\u7528\u4e8e\u6240\u6709\u57fa\u7840\u5206\u5e03\u65cf\uff0c\u5177\u6709\u66f4\u597d\u7684\u6837\u672c\u590d\u6742\u6027\u548c\u566a\u58f0\u5bb9\u5fcd\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7b80\u5316\u4e86\u5b66\u4e60\u8fc7\u7a0b\uff0c\u6269\u5c55\u4e86\u5206\u5e03\u7279\u5b9a\u5b66\u4e60\u5668\u7684\u9002\u7528\u8303\u56f4\u3002"}}
{"id": "2506.15695", "pdf": "https://arxiv.org/pdf/2506.15695", "abs": "https://arxiv.org/abs/2506.15695", "authors": ["Xinxing Ren", "Qianbo Zang", "Zekun Guo"], "title": "SimuGen: Multi-modal Agentic Framework for Constructing Block Diagram-Based Simulation Models", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in large language models (LLMs) have shown impressive\nperformance in mathematical reasoning and code generation. However, LLMs still\nstruggle in the simulation domain, particularly in generating Simulink models,\nwhich are essential tools in engineering and scientific research. Our\npreliminary experiments indicate that LLM agents often fail to produce reliable\nand complete Simulink simulation code from text-only inputs, likely due to the\nlack of Simulink-specific data in their pretraining. To address this challenge,\nwe propose SimuGen, a multimodal agent-based framework that automatically\ngenerates accurate Simulink simulation code by leveraging both the visual\nSimulink diagram and domain knowledge. SimuGen coordinates several specialized\nagents, including an investigator, unit test reviewer, code generator,\nexecutor, debug locator, and report writer, supported by a domain-specific\nknowledge base. This collaborative and modular design enables interpretable,\nrobust, and reproducible Simulink simulation generation. Our source code is\npublicly available at https://github.com/renxinxing123/SimuGen_beta.", "AI": {"tldr": "SimuGen\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u4ee3\u7406\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u7ed3\u5408\u89c6\u89c9Simulink\u56fe\u548c\u9886\u57df\u77e5\u8bc6\uff0c\u751f\u6210\u51c6\u786e\u7684Simulink\u4eff\u771f\u4ee3\u7801\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728Simulink\u6a21\u578b\u751f\u6210\u9886\u57df\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u56e0\u4e3a\u7f3a\u4e4fSimulink\u7279\u5b9a\u7684\u9884\u8bad\u7ec3\u6570\u636e\u3002", "method": "SimuGen\u91c7\u7528\u591a\u4ee3\u7406\u534f\u4f5c\u6846\u67b6\uff0c\u5305\u62ec\u8c03\u67e5\u5458\u3001\u5355\u5143\u6d4b\u8bd5\u5ba1\u67e5\u5458\u3001\u4ee3\u7801\u751f\u6210\u5668\u3001\u6267\u884c\u5668\u3001\u8c03\u8bd5\u5b9a\u4f4d\u5668\u548c\u62a5\u544a\u7f16\u5199\u5668\uff0c\u5e76\u4f9d\u6258\u9886\u57df\u77e5\u8bc6\u5e93\u3002", "result": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u3001\u7a33\u5065\u4e14\u53ef\u91cd\u590d\u7684Simulink\u4eff\u771f\u4ee3\u7801\u751f\u6210\u3002", "conclusion": "SimuGen\u901a\u8fc7\u591a\u6a21\u6001\u548c\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLMs\u5728Simulink\u4eff\u771f\u9886\u57df\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2506.16875", "pdf": "https://arxiv.org/pdf/2506.16875", "abs": "https://arxiv.org/abs/2506.16875", "authors": ["Boris Martin", "Pierre Jolivet", "Christophe Geuzaine"], "title": "Comparison of substructured non-overlapping domain decomposition and overlapping additive Schwarz methods for large-scale Helmholtz problems with multiple sources", "categories": ["math.NA", "cs.DC", "cs.NA", "math.AP", "35J05, 65N55, 68W10, 35-04, 86-08", "J.2; G.1.3; G.1.8; G.4"], "comment": "21 pages, 10 figures, 5 tables. Preprint for a submission to SIAM\n  SISC", "summary": "Solving large-scale Helmholtz problems discretized with high-order finite\nelements is notoriously difficult, especially in 3D where direct factorization\nof the system matrix is very expensive and memory demanding, and robust\nconvergence of iterative methods is difficult to obtain. Domain decomposition\nmethods (DDM) constitute one of the most promising strategy so far, by\ncombining direct and iterative approaches: using direct solvers on overlapping\nor non-overlapping subdomains, as a preconditioner for a Krylov subspace method\non the original Helmholtz system or as an iterative solver on a substructured\nproblem involving field values or Lagrange multipliers on the interfaces\nbetween the subdomains. In this work we compare the computational performance\nof non-overlapping substructured DDM and Optimized Restricted Additive Schwarz\n(ORAS) preconditioners for solving large-scale Helmholtz problems with multiple\nsources, as is encountered, e.g., in frequency-domain Full Waveform Inversion.\nWe show on a realistic geophysical test-case that, when appropriately tuned,\nthe non-overlapping methods can reduce the convergence gap sufficiently to\nsignificantly outperform the overlapping methods.", "AI": {"tldr": "\u6bd4\u8f83\u975e\u91cd\u53e0\u5b50\u7ed3\u6784\u57df\u5206\u89e3\u65b9\u6cd5\uff08DDM\uff09\u548c\u4f18\u5316\u9650\u5236\u52a0\u6cd5Schwarz\uff08ORAS\uff09\u9884\u6761\u4ef6\u5b50\u5728\u5927\u89c4\u6a21Helmholtz\u95ee\u9898\u4e2d\u7684\u8ba1\u7b97\u6027\u80fd\uff0c\u53d1\u73b0\u9002\u5f53\u8c03\u4f18\u540e\u975e\u91cd\u53e0\u65b9\u6cd5\u53ef\u663e\u8457\u4f18\u4e8e\u91cd\u53e0\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21Helmholtz\u95ee\u9898\u5728\u9ad8\u9636\u6709\u9650\u5143\u79bb\u6563\u5316\u4e0b\u7684\u8ba1\u7b97\u56f0\u96be\uff0c\u5c24\u5176\u662f\u57283D\u4e2d\u76f4\u63a5\u5206\u89e3\u7cfb\u7edf\u77e9\u9635\u6210\u672c\u9ad8\u4e14\u8fed\u4ee3\u65b9\u6cd5\u6536\u655b\u56f0\u96be\u3002", "method": "\u4f7f\u7528\u975e\u91cd\u53e0\u5b50\u7ed3\u6784\u57df\u5206\u89e3\u65b9\u6cd5\u548cORAS\u9884\u6761\u4ef6\u5b50\uff0c\u6bd4\u8f83\u5b83\u4eec\u5728\u591a\u6e90Helmholtz\u95ee\u9898\u4e2d\u7684\u6027\u80fd\u3002", "result": "\u5728\u73b0\u5b9e\u5730\u7403\u7269\u7406\u6d4b\u8bd5\u6848\u4f8b\u4e2d\uff0c\u9002\u5f53\u8c03\u4f18\u7684\u975e\u91cd\u53e0\u65b9\u6cd5\u80fd\u663e\u8457\u51cf\u5c11\u6536\u655b\u5dee\u8ddd\uff0c\u4f18\u4e8e\u91cd\u53e0\u65b9\u6cd5\u3002", "conclusion": "\u975e\u91cd\u53e0\u5b50\u7ed3\u6784\u57df\u5206\u89e3\u65b9\u6cd5\u5728\u89e3\u51b3\u5927\u89c4\u6a21Helmholtz\u95ee\u9898\u65f6\u5177\u6709\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5728\u591a\u6e90\u573a\u666f\u4e0b\u3002"}}
{"id": "2506.16831", "pdf": "https://arxiv.org/pdf/2506.16831", "abs": "https://arxiv.org/abs/2506.16831", "authors": ["Filippo Scaramuzza", "Damian A. Tamburri", "Willem-Jan van den Heuvel"], "title": "Accountability of Robust and Reliable AI-Enabled Systems: A Preliminary Study and Roadmap", "categories": ["cs.SE"], "comment": "To be published in https://link.springer.com/book/9789819672370", "summary": "This vision paper presents initial research on assessing the robustness and\nreliability of AI-enabled systems, and key factors in ensuring their safety and\neffectiveness in practical applications, including a focus on accountability.\nBy exploring evolving definitions of these concepts and reviewing current\nliterature, the study highlights major challenges and approaches in the field.\nA case study is used to illustrate real-world applications, emphasizing the\nneed for innovative testing solutions. The incorporation of accountability is\ncrucial for building trust and ensuring responsible AI development. The paper\noutlines potential future research directions and identifies existing gaps,\npositioning robustness, reliability, and accountability as vital areas for the\ndevelopment of trustworthy AI systems of the future.", "AI": {"tldr": "\u8be5\u613f\u666f\u8bba\u6587\u63a2\u8ba8\u4e86AI\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3001\u53ef\u9760\u6027\u53ca\u5176\u5b89\u5168\u6027\uff0c\u5f3a\u8c03\u95ee\u8d23\u5236\u5728\u6784\u5efa\u53ef\u4fe1AI\u4e2d\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3AI\u7cfb\u7edf\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u6027\u548c\u6709\u6548\u6027\uff0c\u786e\u4fdd\u5176\u53ef\u9760\u6027\u548c\u95ee\u8d23\u6027\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u6848\u4f8b\u7814\u7a76\uff0c\u5206\u6790\u4e86AI\u7cfb\u7edf\u7684\u6311\u6218\u548c\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u521b\u65b0\u6d4b\u8bd5\u65b9\u6848\u3002", "result": "\u7814\u7a76\u5f3a\u8c03\u4e86\u95ee\u8d23\u5236\u5bf9\u5efa\u7acb\u4fe1\u4efb\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u9c81\u68d2\u6027\u3001\u53ef\u9760\u6027\u548c\u95ee\u8d23\u5236\u662f\u672a\u6765\u53ef\u4fe1AI\u7cfb\u7edf\u53d1\u5c55\u7684\u6838\u5fc3\u9886\u57df\u3002"}}
{"id": "2506.16979", "pdf": "https://arxiv.org/pdf/2506.16979", "abs": "https://arxiv.org/abs/2506.16979", "authors": ["Gang Liu", "Haitao Wang"], "title": "Minimum-Weight Half-Plane Hitting Set", "categories": ["cs.CG", "cs.DS"], "comment": "To appear in CCCG 2025. arXiv admin note: text overlap with\n  arXiv:2407.00329, arXiv:2501.02195", "summary": "Given a set $P$ of $n$ weighted points and a set $H$ of $n$ half-planes in\nthe plane, the hitting set problem is to compute a subset $P'$ of points from\n$P$ such that each half-plane contains at least one point from $P'$ and the\ntotal weight of the points in $P'$ is minimized. The previous best algorithm\nsolves the problem in $O(n^{7/2}\\log^2 n)$ time. In this paper, we present a\nnew algorithm with runtime $O(n^{5/2}\\log^2 n)$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\uff0c\u5c06\u51fb\u4e2d\u96c6\u95ee\u9898\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4eceO(n^{7/2}log^2 n)\u964d\u4f4e\u5230O(n^{5/2}log^2 n)\u3002", "motivation": "\u89e3\u51b3\u52a0\u6743\u70b9\u548c\u534a\u5e73\u9762\u7684\u51fb\u4e2d\u96c6\u95ee\u9898\uff0c\u4f18\u5316\u73b0\u6709\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\uff0c\u6539\u8fdb\u4e86\u8ba1\u7b97\u51fb\u4e2d\u96c6\u7684\u65b9\u6cd5\u3002", "result": "\u65b0\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(n^{5/2}log^2 n)\uff0c\u4f18\u4e8e\u4e4b\u524d\u7684O(n^{7/2}log^2 n)\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u51fb\u4e2d\u96c6\u95ee\u9898\u7684\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2506.15696", "pdf": "https://arxiv.org/pdf/2506.15696", "abs": "https://arxiv.org/abs/2506.15696", "authors": ["Haipeng Zhou", "Sicheng Yang", "Sihan Yang", "Jing Qin", "Lei Chen", "Lei Zhu"], "title": "CoC: Chain-of-Cancer based on Cross-Modal Autoregressive Traction for Survival Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Survival prediction aims to evaluate the risk level of cancer patients.\nExisting methods primarily rely on pathology and genomics data, either\nindividually or in combination. From the perspective of cancer pathogenesis,\nepigenetic changes, such as methylation data, could also be crucial for this\ntask. Furthermore, no previous endeavors have utilized textual descriptions to\nguide the prediction. To this end, we are the first to explore the use of four\nmodalities, including three clinical modalities and language, for conducting\nsurvival prediction. In detail, we are motivated by the Chain-of-Thought (CoT)\nto propose the Chain-of-Cancer (CoC) framework, focusing on intra-learning and\ninter-learning. We encode the clinical data as the raw features, which remain\ndomain-specific knowledge for intra-learning. In terms of inter-learning, we\nuse language to prompt the raw features and introduce an Autoregressive Mutual\nTraction module for synergistic representation. This tailored framework\nfacilitates joint learning among multiple modalities. Our approach is evaluated\nacross five public cancer datasets, and extensive experiments validate the\neffectiveness of our methods and proposed designs, leading to producing \\sota\nresults. Codes will be released.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aChain-of-Cancer (CoC)\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u7ed3\u5408\u4e34\u5e8a\u6570\u636e\u548c\u8bed\u8a00\u63cf\u8ff0\u8fdb\u884c\u764c\u75c7\u60a3\u8005\u751f\u5b58\u9884\u6d4b\uff0c\u901a\u8fc7\u5185\u5b66\u4e60\u548c\u4e92\u5b66\u4e60\u5b9e\u73b0\u591a\u6a21\u6001\u8054\u5408\u5b66\u4e60\uff0c\u5e76\u5728\u4e94\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u75c5\u7406\u548c\u57fa\u56e0\u7ec4\u6570\u636e\uff0c\u800c\u5ffd\u7565\u4e86\u7532\u57fa\u5316\u6570\u636e\u548c\u8bed\u8a00\u63cf\u8ff0\u7684\u4f5c\u7528\u3002\u8bba\u6587\u9996\u6b21\u63a2\u7d22\u4e86\u56db\u79cd\u6a21\u6001\uff08\u5305\u62ec\u8bed\u8a00\uff09\u7684\u8054\u5408\u4f7f\u7528\uff0c\u4ee5\u66f4\u5168\u9762\u5730\u9884\u6d4b\u764c\u75c7\u60a3\u8005\u7684\u751f\u5b58\u98ce\u9669\u3002", "method": "\u63d0\u51faCoC\u6846\u67b6\uff0c\u5305\u62ec\u5185\u5b66\u4e60\uff08\u5229\u7528\u4e34\u5e8a\u6570\u636e\u4f5c\u4e3a\u539f\u59cb\u7279\u5f81\uff09\u548c\u4e92\u5b66\u4e60\uff08\u901a\u8fc7\u8bed\u8a00\u63d0\u793a\u548c\u81ea\u56de\u5f52\u4e92\u62c9\u6a21\u5757\u5b9e\u73b0\u591a\u6a21\u6001\u534f\u540c\u8868\u793a\uff09\u3002", "result": "\u5728\u4e94\u4e2a\u516c\u5f00\u764c\u75c7\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "CoC\u6846\u67b6\u901a\u8fc7\u591a\u6a21\u6001\u8054\u5408\u5b66\u4e60\u663e\u8457\u63d0\u5347\u4e86\u751f\u5b58\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u4ee3\u7801\u5c06\u5f00\u6e90\u3002"}}
{"id": "2506.16876", "pdf": "https://arxiv.org/pdf/2506.16876", "abs": "https://arxiv.org/abs/2506.16876", "authors": ["Halit Eris", "Stefan Wagner"], "title": "Revolutionizing Validation and Verification: Explainable Testing Methodologies for Intelligent Automotive Decision-Making Systems", "categories": ["cs.SE"], "comment": "Preprint to be published at SE4ADS", "summary": "Autonomous Driving Systems (ADS) use complex decision-making (DM) models with\nmultimodal sensory inputs, making rigorous validation and verification (V&V)\nessential for safety and reliability. These models pose challenges in\ndiagnosing failures, tracing anomalies, and maintaining transparency, with\ncurrent manual testing methods being inefficient and labor-intensive. This\nvision paper presents a methodology that integrates explainability,\ntransparency, and interpretability into V&V processes. We propose refining V&V\nrequirements through literature reviews and stakeholder input, generating\nexplainable test scenarios via large language models (LLMs), and enabling\nreal-time validation in simulation environments. Our framework includes test\noracle, explanation generation, and a test chatbot, with empirical studies\nplanned to evaluate improvements in diagnostic efficiency and transparency. Our\ngoal is to streamline V&V, reduce resources, and build user trust in autonomous\ntechnologies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u53ef\u89e3\u91ca\u6027\u3001\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u878d\u5165\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u9a8c\u8bc1\u4e0e\u9a8c\u8bc1\uff08V&V\uff09\u6d41\u7a0b\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u63d0\u9ad8\u6548\u7387\u548c\u7528\u6237\u4fe1\u4efb\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u51b3\u7b56\u6a21\u578b\u590d\u6742\uff0c\u9a8c\u8bc1\u4e0e\u9a8c\u8bc1\u8fc7\u7a0b\u6548\u7387\u4f4e\u4e14\u52b3\u52a8\u5bc6\u96c6\uff0c\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u5229\u76ca\u76f8\u5173\u8005\u8f93\u5165\u7ec6\u5316V&V\u9700\u6c42\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u53ef\u89e3\u91ca\u6d4b\u8bd5\u573a\u666f\uff0c\u5e76\u5728\u6a21\u62df\u73af\u5883\u4e2d\u5b9e\u73b0\u5b9e\u65f6\u9a8c\u8bc1\u3002", "result": "\u6846\u67b6\u5305\u62ec\u6d4b\u8bd5\u9884\u8a00\u3001\u89e3\u91ca\u751f\u6210\u548c\u6d4b\u8bd5\u804a\u5929\u673a\u5668\u4eba\uff0c\u8ba1\u5212\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u8bc4\u4f30\u8bca\u65ad\u6548\u7387\u548c\u900f\u660e\u5ea6\u7684\u6539\u8fdb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e8\u5728\u4f18\u5316V&V\u6d41\u7a0b\uff0c\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\uff0c\u5e76\u589e\u5f3a\u7528\u6237\u5bf9\u81ea\u52a8\u9a7e\u9a76\u6280\u672f\u7684\u4fe1\u4efb\u3002"}}
{"id": "2506.17118", "pdf": "https://arxiv.org/pdf/2506.17118", "abs": "https://arxiv.org/abs/2506.17118", "authors": ["Abhishek Hegade K. R.", "Eren C. K\u0131z\u0131lda\u011f"], "title": "Large Average Subtensor Problem: Ground-State, Algorithms, and Algorithmic Barriers", "categories": ["math.ST", "cs.CC", "cs.DS", "math.PR", "stat.TH"], "comment": null, "summary": "We introduce the large average subtensor problem: given an order-$p$ tensor\nover $\\mathbb{R}^{N\\times \\cdots \\times N}$ with i.i.d. standard normal entries\nand a $k\\in\\mathbb{N}$, algorithmically find a $k\\times \\cdots \\times k$\nsubtensor with a large average entry. This generalizes the large average\nsubmatrix problem, a key model closely related to biclustering and\nhigh-dimensional data analysis, to tensors. For the submatrix case, Bhamidi,\nDey, and Nobel~\\cite{bhamidi2017energy} explicitly highlight the regime\n$k=\\Theta(N)$ as an intriguing open question.\n  Addressing the regime $k=\\Theta(N)$ for tensors, we establish that the\nlargest average entry concentrates around an explicit value $E_{\\mathrm{max}}$,\nprovided that the tensor order $p$ is sufficiently large. Furthermore, we prove\nthat for any $\\gamma>0$ and large $p$, this model exhibits multi Overlap Gap\nProperty ($m$-OGP) above the threshold $\\gamma E_{\\mathrm{max}}$. The $m$-OGP\nserves as a rigorous barrier for a broad class of algorithms exhibiting input\nstability. These results hold for both $k=\\Theta(N)$ and $k=o(N)$. Moreover,\nfor small $k$, specifically $k=o(\\log^{1.5}N)$, we show that a certain\npolynomial-time algorithm identifies a subtensor with average entry\n$\\frac{2\\sqrt{p}}{p+1}E_{\\mathrm{max}}$. In particular, the $m$-OGP is\nasymptotically sharp: onset of the $m$-OGP and the algorithmic threshold match\nas $p$ grows.\n  Our results show that while the case $k=\\Theta(N)$ remains open for\nsubmatrices, it can be rigorously analyzed for tensors in the large $p$ regime.\nThis is achieved by interpreting the model as a Boolean spin glass and drawing\non insights from recent advances in the Ising $p$-spin glass model.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u9ad8\u9636\u5f20\u91cf\u4e2d\u7684\u5927\u5e73\u5747\u5b50\u5f20\u91cf\u95ee\u9898\uff0c\u63a8\u5e7f\u4e86\u5b50\u77e9\u9635\u95ee\u9898\uff0c\u5e76\u5206\u6790\u4e86k=\u0398(N)\u548ck=o(N)\u60c5\u51b5\u4e0b\u7684\u7ed3\u679c\u3002", "motivation": "\u89e3\u51b3\u9ad8\u9636\u5f20\u91cf\u4e2d\u7684\u5927\u5e73\u5747\u5b50\u5f20\u91cf\u95ee\u9898\uff0c\u586b\u8865\u5b50\u77e9\u9635\u95ee\u9898\u4e2dk=\u0398(N)\u7684\u7a7a\u767d\u3002", "method": "\u5c06\u6a21\u578b\u89e3\u91ca\u4e3a\u5e03\u5c14\u81ea\u65cb\u73bb\u7483\uff0c\u5e76\u501f\u9274Ising p-\u81ea\u65cb\u73bb\u7483\u6a21\u578b\u7684\u8fdb\u5c55\u3002", "result": "\u8bc1\u660e\u4e86\u5728k=\u0398(N)\u548ck=o(N)\u60c5\u51b5\u4e0b\uff0c\u6700\u5927\u5e73\u5747\u6761\u76ee\u96c6\u4e2d\u5728E_max\u9644\u8fd1\uff0c\u5e76\u5c55\u793a\u4e86m-OGP\u7684\u5b58\u5728\u3002", "conclusion": "\u9ad8\u9636\u5f20\u91cf\u95ee\u9898\u5728p\u8f83\u5927\u65f6\u53ef\u88ab\u4e25\u683c\u5206\u6790\uff0c\u4e3a\u5b50\u77e9\u9635\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2506.15697", "pdf": "https://arxiv.org/pdf/2506.15697", "abs": "https://arxiv.org/abs/2506.15697", "authors": ["Yi Liu", "Hongji Zhang", "Yunhao Zhou", "Zhengyuan Shi", "Changran Xu", "Qiang Xu"], "title": "DeepRTL2: A Versatile Model for RTL-Related Tasks", "categories": ["cs.AR", "cs.CL", "cs.LG"], "comment": "ACL 2025 Findings", "summary": "The integration of large language models (LLMs) into electronic design\nautomation (EDA) has significantly advanced the field, offering transformative\nbenefits, particularly in register transfer level (RTL) code generation and\nunderstanding. While previous studies have demonstrated the efficacy of\nfine-tuning LLMs for these generation-based tasks, embedding-based tasks, which\nare equally critical to EDA workflows, have been largely overlooked. These\ntasks, including natural language code search, RTL code functionality\nequivalence checking, and performance prediction, are essential for\naccelerating and optimizing the hardware design process. To address this gap,\nwe present DeepRTL2, a family of versatile LLMs that unifies both generation-\nand embedding-based tasks related to RTL. By simultaneously tackling a broad\nrange of tasks, DeepRTL2 represents the first model to provide a comprehensive\nsolution to the diverse challenges in EDA. Through extensive experiments, we\nshow that DeepRTL2 achieves state-of-the-art performance across all evaluated\ntasks.", "AI": {"tldr": "DeepRTL2\u662f\u4e00\u4e2a\u591a\u529f\u80fd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bb6\u65cf\uff0c\u9996\u6b21\u7edf\u4e00\u4e86RTL\u76f8\u5173\u7684\u751f\u6210\u548c\u5d4c\u5165\u4efb\u52a1\uff0c\u586b\u8865\u4e86EDA\u9886\u57df\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728LLMs\u7684\u751f\u6210\u4efb\u52a1\u4e0a\uff0c\u800cEDA\u5de5\u4f5c\u6d41\u4e2d\u540c\u6837\u5173\u952e\u7684\u5d4c\u5165\u4efb\u52a1\u88ab\u5ffd\u89c6\u3002", "method": "\u63d0\u51faDeepRTL2\u6a21\u578b\uff0c\u540c\u65f6\u5904\u7406\u751f\u6210\u548c\u5d4c\u5165\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDeepRTL2\u5728\u6240\u6709\u8bc4\u4f30\u4efb\u52a1\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "DeepRTL2\u4e3aEDA\u9886\u57df\u7684\u591a\u6837\u5316\u6311\u6218\u63d0\u4f9b\u4e86\u5168\u9762\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16878", "pdf": "https://arxiv.org/pdf/2506.16878", "abs": "https://arxiv.org/abs/2506.16878", "authors": ["Man Zhang", "Yuechen Li", "Tao Yue", "Kai-Yuan Cai"], "title": "Quantum Optimization for Software Engineering: A Survey", "categories": ["cs.SE"], "comment": null, "summary": "Quantum computing, particularly in the area of quantum optimization, is\nsteadily progressing toward practical applications, supported by an expanding\nrange of hardware platforms and simulators. While Software Engineering (SE)\noptimization has a strong foundation, which is exemplified by the active\nSearch-Based Software Engineering (SBSE) community and numerous classical\noptimization methods, the growing complexity of modern software systems and\ntheir engineering processes demands innovative solutions. This Systematic\nLiterature Review (SLR) focuses specifically on studying the literature that\napplies quantum or quantum-inspired algorithms to solve classical SE\noptimization problems. We examine 77 primary studies selected from an initial\npool of 2083 publications obtained through systematic searches of six digital\ndatabases using carefully crafted search strings. Our findings reveal\nconcentrated research efforts in areas such as SE operations and software\ntesting, while exposing significant gaps across other SE activities.\nAdditionally, the SLR uncovers relevant works published outside traditional SE\nvenues, underscoring the necessity of this comprehensive review. Overall, our\nstudy provides a broad overview of the research landscape, empowering the SBSE\ncommunity to leverage quantum advancements in addressing next-generation SE\nchallenges.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff08SLR\uff09\u7814\u7a76\u4e86\u91cf\u5b50\u6216\u91cf\u5b50\u542f\u53d1\u7b97\u6cd5\u5728\u89e3\u51b3\u7ecf\u5178\u8f6f\u4ef6\u5de5\u7a0b\uff08SE\uff09\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u6790\u4e8677\u9879\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u7814\u7a76\u70ed\u70b9\u4e0e\u7a7a\u767d\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u7cfb\u7edf\u53ca\u5176\u5de5\u7a0b\u8fc7\u7a0b\u7684\u590d\u6742\u6027\u589e\u52a0\uff0c\u9700\u8981\u521b\u65b0\u89e3\u51b3\u65b9\u6848\uff0c\u91cf\u5b50\u8ba1\u7b97\u5728\u4f18\u5316\u9886\u57df\u7684\u8fdb\u5c55\u4e3aSE\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u641c\u7d22\u516d\u4e2a\u6570\u5b57\u6570\u636e\u5e93\uff0c\u4ece2083\u7bc7\u6587\u732e\u4e2d\u7b5b\u9009\u51fa77\u9879\u4e3b\u8981\u7814\u7a76\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u7814\u7a76\u96c6\u4e2d\u5728SE\u64cd\u4f5c\u548c\u8f6f\u4ef6\u6d4b\u8bd5\u9886\u57df\uff0c\u5176\u4ed6SE\u6d3b\u52a8\u5b58\u5728\u663e\u8457\u7a7a\u767d\uff0c\u5e76\u53d1\u73b0\u4e86\u4e00\u4e9b\u975e\u4f20\u7edfSE\u6e20\u9053\u7684\u76f8\u5173\u7814\u7a76\u3002", "conclusion": "\u7814\u7a76\u4e3aSBSE\u793e\u533a\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u7814\u7a76\u6982\u89c8\uff0c\u52a9\u529b\u5229\u7528\u91cf\u5b50\u6280\u672f\u8fdb\u6b65\u89e3\u51b3\u4e0b\u4e00\u4ee3SE\u6311\u6218\u3002"}}
{"id": "2506.15698", "pdf": "https://arxiv.org/pdf/2506.15698", "abs": "https://arxiv.org/abs/2506.15698", "authors": ["Yunhak Oh", "Junseok Lee", "Yeongmin Kim", "Sangwoo Seo", "Namkyeong Lee", "Chanyoung Park"], "title": "Global Context-aware Representation Learning for Spatially Resolved Transcriptomics", "categories": ["cs.LG", "cs.CV"], "comment": "ICML 2025", "summary": "Spatially Resolved Transcriptomics (SRT) is a cutting-edge technique that\ncaptures the spatial context of cells within tissues, enabling the study of\ncomplex biological networks. Recent graph-based methods leverage both gene\nexpression and spatial information to identify relevant spatial domains.\nHowever, these approaches fall short in obtaining meaningful spot\nrepresentations, especially for spots near spatial domain boundaries, as they\nheavily emphasize adjacent spots that have minimal feature differences from an\nanchor node. To address this, we propose Spotscape, a novel framework that\nintroduces the Similarity Telescope module to capture global relationships\nbetween multiple spots. Additionally, we propose a similarity scaling strategy\nto regulate the distances between intra- and inter-slice spots, facilitating\neffective multi-slice integration. Extensive experiments demonstrate the\nsuperiority of Spotscape in various downstream tasks, including single-slice\nand multi-slice scenarios. Our code is available at the following link: https:\n//github.com/yunhak0/Spotscape.", "AI": {"tldr": "Spotscape\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u901a\u8fc7Similarity Telescope\u6a21\u5757\u548c\u76f8\u4f3c\u6027\u7f29\u653e\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u56fe\u65b9\u6cd5\u5728\u7a7a\u95f4\u57df\u8fb9\u754c\u9644\u8fd1\u7684\u8868\u73b0\u95ee\u9898\uff0c\u5e76\u5728\u5355\u5207\u7247\u548c\u591a\u5207\u7247\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u56fe\u65b9\u6cd5\u5728\u7a7a\u95f4\u57df\u8fb9\u754c\u9644\u8fd1\u7684\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u5b83\u4eec\u8fc7\u4e8e\u4f9d\u8d56\u76f8\u90bb\u70b9\u800c\u5ffd\u7565\u4e86\u5168\u5c40\u5173\u7cfb\u3002", "method": "Spotscape\u5f15\u5165\u4e86Similarity Telescope\u6a21\u5757\u6355\u6349\u5168\u5c40\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u76f8\u4f3c\u6027\u7f29\u653e\u7b56\u7565\u8c03\u8282\u5207\u7247\u5185\u548c\u5207\u7247\u95f4\u7684\u8ddd\u79bb\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSpotscape\u5728\u5355\u5207\u7247\u548c\u591a\u5207\u7247\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u8d8a\u3002", "conclusion": "Spotscape\u4e3a\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u6709\u6548\u7684\u5206\u6790\u65b9\u6cd5\u3002"}}
{"id": "2506.16997", "pdf": "https://arxiv.org/pdf/2506.16997", "abs": "https://arxiv.org/abs/2506.16997", "authors": ["Hannah Deters", "Laura Reinhardt", "Jakob Droste", "Martin Obaidi", "Kurt Schneider"], "title": "Identifying Explanation Needs: Towards a Catalog of User-based Indicators", "categories": ["cs.SE"], "comment": "This paper has been accepted at the research track of the 33rd IEEE\n  International Requirements Engineering Conference (RE 2025)", "summary": "In today's digitalized world, where software systems are becoming\nincreasingly ubiquitous and complex, the quality aspect of explainability is\ngaining relevance. A major challenge in achieving adequate explanations is the\nelicitation of individual explanation needs, as it may be subject to severe\nhypothetical or confirmation biases. To address these challenges, we aim to\nestablish user-based indicators concerning user behavior or system events that\ncan be captured at runtime to determine when a need for explanations arises. In\nthis work, we conducted explorative research in form of an online study to\ncollect self-reported indicators that could indicate a need for explanation. We\ncompiled a catalog containing 17 relevant indicators concerning user behavior,\n8 indicators concerning system events and 14 indicators concerning emotional\nstates or physical reactions. We also analyze the relationships between these\nindicators and different types of need for explanation. The established\nindicators can be used in the elicitation process through prototypes, as well\nas after publication to gather requirements from already deployed applications\nusing telemetry and usage data. Moreover, these indicators can be used to\ntrigger explanations at appropriate moments during the runtime.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u590d\u6742\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u5982\u4f55\u901a\u8fc7\u7528\u6237\u884c\u4e3a\u3001\u7cfb\u7edf\u4e8b\u4ef6\u548c\u60c5\u611f\u72b6\u6001\u7b49\u6307\u6807\u52a8\u6001\u8bc6\u522b\u89e3\u91ca\u9700\u6c42\uff0c\u5e76\u901a\u8fc7\u5728\u7ebf\u7814\u7a76\u6536\u96c6\u4e86\u76f8\u5173\u6307\u6807\u3002", "motivation": "\u5728\u6570\u5b57\u5316\u4e16\u754c\u4e2d\uff0c\u8f6f\u4ef6\u7cfb\u7edf\u7684\u590d\u6742\u6027\u589e\u52a0\uff0c\u89e3\u91ca\u6027\u9700\u6c42\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u6613\u53d7\u504f\u89c1\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5728\u7ebf\u7814\u7a76\u6536\u96c6\u81ea\u6211\u62a5\u544a\u6307\u6807\uff0c\u6574\u7406\u51fa\u7528\u6237\u884c\u4e3a\u3001\u7cfb\u7edf\u4e8b\u4ef6\u548c\u60c5\u611f\u72b6\u6001\u4e09\u7c7b\u517139\u4e2a\u6307\u6807\u3002", "result": "\u5efa\u7acb\u4e8617\u4e2a\u7528\u6237\u884c\u4e3a\u6307\u6807\u30018\u4e2a\u7cfb\u7edf\u4e8b\u4ef6\u6307\u6807\u548c14\u4e2a\u60c5\u611f\u72b6\u6001\u6307\u6807\uff0c\u5e76\u5206\u6790\u4e86\u5b83\u4eec\u4e0e\u89e3\u91ca\u9700\u6c42\u7c7b\u578b\u7684\u5173\u7cfb\u3002", "conclusion": "\u8fd9\u4e9b\u6307\u6807\u53ef\u7528\u4e8e\u539f\u578b\u8bbe\u8ba1\u548c\u5df2\u90e8\u7f72\u5e94\u7528\u7684\u8fdc\u7a0b\u6570\u636e\u6536\u96c6\uff0c\u52a8\u6001\u89e6\u53d1\u89e3\u91ca\uff0c\u63d0\u5347\u7cfb\u7edf\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.15699", "pdf": "https://arxiv.org/pdf/2506.15699", "abs": "https://arxiv.org/abs/2506.15699", "authors": ["Shengyuan Hu", "Neil Kale", "Pratiksha Thaker", "Yiwei Fu", "Steven Wu", "Virginia Smith"], "title": "BLUR: A Benchmark for LLM Unlearning Robust to Forget-Retain Overlap", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Machine unlearning has the potential to improve the safety of large language\nmodels (LLMs) by removing sensitive or harmful information post hoc. A key\nchallenge in unlearning involves balancing between forget quality (effectively\nunlearning undesirable information) and retain quality (maintaining good\nperformance on other, general tasks). Unfortunately, as we show, current LLM\nunlearning benchmarks contain highly disparate forget and retain sets --\npainting a false picture of the effectiveness of LLM unlearning methods. This\ncan be particularly problematic because it opens the door for benign\nperturbations, such as relearning attacks, to easily reveal supposedly\nunlearned knowledge once models are deployed. To address this, we present\n$\\texttt{BLUR}$: a benchmark for LLM unlearning that provides more realistic\nscenarios of forget-retain overlap. $\\texttt{BLUR}$ significantly expands on\nexisting unlearning benchmarks by providing extended evaluation tasks, combined\nforget/retain queries, and relearning datasets of varying degrees of\ndifficulty. Despite the benign nature of the queries considered, we find that\nthe performance of existing methods drops significantly when evaluated on\n$\\texttt{BLUR}$, with simple approaches performing better on average than more\nrecent methods. These results highlight the importance of robust evaluation and\nsuggest several important directions of future study. Our benchmark is publicly\navailable at: https://huggingface.co/datasets/forgelab/BLUR", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aBLUR\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u9057\u5fd8\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9057\u5fd8\u4e0e\u4fdd\u7559\u6570\u636e\u96c6\u5dee\u5f02\u8fc7\u5927\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709LLM\u9057\u5fd8\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u9057\u5fd8\u548c\u4fdd\u7559\u6570\u636e\u96c6\u5dee\u5f02\u8fc7\u5927\uff0c\u5bfc\u81f4\u8bc4\u4f30\u7ed3\u679c\u5931\u771f\uff0c\u53ef\u80fd\u63a9\u76d6\u6a21\u578b\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6f5c\u5728\u98ce\u9669\u3002", "method": "\u63d0\u51faBLUR\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6269\u5c55\u4e86\u8bc4\u4f30\u4efb\u52a1\uff0c\u7ed3\u5408\u4e86\u9057\u5fd8/\u4fdd\u7559\u67e5\u8be2\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e0d\u540c\u96be\u5ea6\u7684\u91cd\u65b0\u5b66\u4e60\u6570\u636e\u96c6\u3002", "result": "\u5728BLUR\u57fa\u51c6\u6d4b\u8bd5\u4e0b\uff0c\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u7b80\u5355\u65b9\u6cd5\u8868\u73b0\u4f18\u4e8e\u65b0\u65b9\u6cd5\u3002", "conclusion": "BLUR\u5f3a\u8c03\u4e86\u9c81\u68d2\u8bc4\u4f30\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u65b9\u5411\u3002"}}
{"id": "2506.17057", "pdf": "https://arxiv.org/pdf/2506.17057", "abs": "https://arxiv.org/abs/2506.17057", "authors": ["Fernando Pastor Ric\u00f3s", "Beatriz Mar\u00edn", "I. S. W. B. Prasetya", "Tanja E. J. Vos", "Joseph Davidson", "Karel Hovorka"], "title": "Behavior Driven Development for 3D Games", "categories": ["cs.SE"], "comment": null, "summary": "Computer 3D games are complex software environments that require novel\ntesting processes to ensure high-quality standards. The Intelligent\nVerification/Validation for Extended Reality Based Systems (iv4XR) framework\naddresses this need by enabling the implementation of autonomous agents to\nautomate game testing scenarios. This framework facilitates the automation of\nregression test cases for complex 3D games like Space Engineers. Nevertheless,\nthe technical expertise required to define test scripts using iv4XR can\nconstrain seamless collaboration between developers and testers. This paper\nreports how integrating a Behavior-driven Development (BDD) approach with the\niv4XR framework allows the industrial company behind Space Engineers to\nautomate regression testing. The success of this industrial collaboration has\ninspired the iv4XR team to integrate the BDD approach to improve the automation\nof play-testing for the experimental 3D game LabRecruits. Furthermore, the\niv4XR framework has been extended with tactical programming to enable the\nautomation of long-play test scenarios in Space Engineers. These results\nunderscore the versatility of the iv4XR framework in supporting diverse testing\napproaches while showcasing how BDD empowers users to create, manage, and\nexecute automated game tests using comprehensive and human-readable statements.", "AI": {"tldr": "iv4XR\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u884c\u4e3a\u9a71\u52a8\u5f00\u53d1\uff08BDD\uff09\u65b9\u6cd5\uff0c\u63d0\u5347\u4e863D\u6e38\u620f\uff08\u5982Space Engineers\u548cLabRecruits\uff09\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u80fd\u529b\uff0c\u652f\u6301\u591a\u6837\u5316\u7684\u6d4b\u8bd5\u573a\u666f\u3002", "motivation": "\u89e3\u51b33D\u6e38\u620f\u6d4b\u8bd5\u4e2d\u5f00\u53d1\u8005\u4e0e\u6d4b\u8bd5\u8005\u534f\u4f5c\u7684\u6280\u672f\u95e8\u69db\u95ee\u9898\uff0c\u63d0\u5347\u81ea\u52a8\u5316\u6d4b\u8bd5\u7684\u6548\u7387\u548c\u53ef\u8bfb\u6027\u3002", "method": "\u5c06BDD\u65b9\u6cd5\u4e0eiv4XR\u6846\u67b6\u7ed3\u5408\uff0c\u5e76\u6269\u5c55\u6218\u672f\u7f16\u7a0b\u529f\u80fd\u4ee5\u652f\u6301\u957f\u65f6\u6d4b\u8bd5\u573a\u666f\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86Space Engineers\u7684\u56de\u5f52\u6d4b\u8bd5\u81ea\u52a8\u5316\uff0c\u5e76\u6269\u5c55\u81f3LabRecruits\u7684\u6d4b\u8bd5\u573a\u666f\u3002", "conclusion": "iv4XR\u6846\u67b6\u7ed3\u5408BDD\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6e38\u620f\u6d4b\u8bd5\u7684\u81ea\u52a8\u5316\u80fd\u529b\u548c\u534f\u4f5c\u6548\u7387\u3002"}}
{"id": "2506.15700", "pdf": "https://arxiv.org/pdf/2506.15700", "abs": "https://arxiv.org/abs/2506.15700", "authors": ["Minjae Cho", "Hiroyasu Tsukamoto", "Huy Trong Tran"], "title": "Contraction Actor-Critic: Contraction Metric-Guided Reinforcement Learning for Robust Path Tracking", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Control contraction metrics (CCMs) provide a framework to co-synthesize a\ncontroller and a corresponding contraction metric -- a positive-definite\nRiemannian metric under which a closed-loop system is guaranteed to be\nincrementally exponentially stable. However, the synthesized controller only\nensures that all the trajectories of the system converge to one single\ntrajectory and, as such, does not impose any notion of optimality across an\nentire trajectory. Furthermore, constructing CCMs requires a known dynamics\nmodel and non-trivial effort in solving an infinite-dimensional convex\nfeasibility problem, which limits its scalability to complex systems featuring\nhigh dimensionality with uncertainty. To address these issues, we propose to\nintegrate CCMs into reinforcement learning (RL), where CCMs provide\ndynamics-informed feedback for learning control policies that minimize\ncumulative tracking error under unknown dynamics. We show that our algorithm,\ncalled contraction actor-critic (CAC), formally enhances the capability of CCMs\nto provide a set of contracting policies with the long-term optimality of RL in\na fully automated setting. Given a pre-trained dynamics model, CAC\nsimultaneously learns a contraction metric generator (CMG) -- which generates a\ncontraction metric -- and uses an actor-critic algorithm to learn an optimal\ntracking policy guided by that metric. We demonstrate the effectiveness of our\nalgorithm relative to established baselines through extensive empirical\nstudies, including simulated and real-world robot experiments, and provide a\ntheoretical rationale for incorporating contraction theory into RL.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u63a7\u5236\u6536\u7f29\u5ea6\u91cf\uff08CCM\uff09\u548c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3CCM\u5728\u52a8\u6001\u6a21\u578b\u5df2\u77e5\u6027\u3001\u6700\u4f18\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "CCM\u867d\u7136\u80fd\u4fdd\u8bc1\u95ed\u73af\u7cfb\u7edf\u7684\u589e\u91cf\u6307\u6570\u7a33\u5b9a\u6027\uff0c\u4f46\u7f3a\u4e4f\u8f68\u8ff9\u6700\u4f18\u6027\u4e14\u4f9d\u8d56\u5df2\u77e5\u52a8\u6001\u6a21\u578b\uff0c\u9650\u5236\u4e86\u5176\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u5c06CCM\u96c6\u6210\u5230RL\u4e2d\uff0c\u63d0\u51fa\u6536\u7f29\u6f14\u5458-\u8bc4\u8bba\u5bb6\uff08CAC\uff09\u7b97\u6cd5\uff0c\u81ea\u52a8\u5b66\u4e60\u6536\u7f29\u5ea6\u91cf\u751f\u6210\u5668\uff08CMG\uff09\u548c\u6700\u4f18\u8ddf\u8e2a\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCAC\u5728\u6a21\u62df\u548c\u771f\u5b9e\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u5c06\u6536\u7f29\u7406\u8bba\u878d\u5165RL\u7684\u7406\u8bba\u4f9d\u636e\u3002", "conclusion": "CAC\u7ed3\u5408\u4e86CCM\u7684\u7a33\u5b9a\u6027\u548cRL\u7684\u6700\u4f18\u6027\uff0c\u4e3a\u590d\u6742\u7cfb\u7edf\u63a7\u5236\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.17095", "pdf": "https://arxiv.org/pdf/2506.17095", "abs": "https://arxiv.org/abs/2506.17095", "authors": ["Ronnie de Souza Santos", "Matheus de Morais Leca", "Reydne Santos", "Cleyton Magalhaes"], "title": "Software Fairness Testing in Practice", "categories": ["cs.SE"], "comment": null, "summary": "Software testing ensures that a system functions correctly, meets specified\nrequirements, and maintains high quality. As artificial intelligence and\nmachine learning (ML) technologies become integral to software systems, testing\nhas evolved to address their unique complexities. A critical advancement in\nthis space is fairness testing, which identifies and mitigates biases in AI\napplications to promote ethical and equitable outcomes. Despite extensive\nacademic research on fairness testing, including test input generation, test\noracle identification, and component testing, practical adoption remains\nlimited. Industry practitioners often lack clear guidelines and effective tools\nto integrate fairness testing into real-world AI development. This study\ninvestigates how software professionals test AI-powered systems for fairness\nthrough interviews with 22 practitioners working on AI and ML projects. Our\nfindings highlight a significant gap between theoretical fairness concepts and\nindustry practice. While fairness definitions continue to evolve, they remain\ndifficult for practitioners to interpret and apply. The absence of\nindustry-aligned fairness testing tools further complicates adoption,\nnecessitating research into practical, accessible solutions. Key challenges\ninclude data quality and diversity, time constraints, defining effective\nmetrics, and ensuring model interoperability. These insights emphasize the need\nto bridge academic advancements with actionable strategies and tools, enabling\npractitioners to systematically address fairness in AI systems.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\u7cfb\u7edf\u516c\u5e73\u6027\u6d4b\u8bd5\u7684\u7406\u8bba\u4e0e\u5b9e\u8df5\u5dee\u8ddd\uff0c\u901a\u8fc7\u8bbf\u8c0822\u4f4d\u4ece\u4e1a\u8005\uff0c\u53d1\u73b0\u884c\u4e1a\u7f3a\u4e4f\u5b9e\u7528\u5de5\u5177\u548c\u6e05\u6670\u6307\u5357\uff0c\u9700\u7814\u7a76\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740AI\u548cML\u6280\u672f\u5728\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u516c\u5e73\u6027\u6d4b\u8bd5\u6210\u4e3a\u786e\u4fdd\u4f26\u7406\u548c\u516c\u6b63\u7ed3\u679c\u7684\u5173\u952e\uff0c\u4f46\u884c\u4e1a\u5b9e\u8df5\u4e0e\u7406\u8bba\u7814\u7a76\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "method": "\u901a\u8fc7\u8bbf\u8c0822\u4f4d\u4ece\u4e8bAI\u548cML\u9879\u76ee\u7684\u4ece\u4e1a\u8005\uff0c\u7814\u7a76\u5176\u516c\u5e73\u6027\u6d4b\u8bd5\u5b9e\u8df5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u884c\u4e1a\u7f3a\u4e4f\u660e\u786e\u7684\u516c\u5e73\u6027\u5b9a\u4e49\u548c\u5b9e\u7528\u5de5\u5177\uff0c\u9762\u4e34\u6570\u636e\u8d28\u91cf\u3001\u65f6\u95f4\u9650\u5236\u7b49\u6311\u6218\u3002", "conclusion": "\u9700\u5c06\u5b66\u672f\u8fdb\u5c55\u8f6c\u5316\u4e3a\u5b9e\u7528\u5de5\u5177\u548c\u7b56\u7565\uff0c\u5e2e\u52a9\u4ece\u4e1a\u8005\u7cfb\u7edf\u6027\u89e3\u51b3AI\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u95ee\u9898\u3002"}}
{"id": "2506.15701", "pdf": "https://arxiv.org/pdf/2506.15701", "abs": "https://arxiv.org/abs/2506.15701", "authors": ["Haolin Pan", "Hongyu Lin", "Haoran Luo", "Yang Liu", "Kaichun Yao", "Libo Zhang", "Mingjie Xing", "Yanjun Wu"], "title": "Compiler-R1: Towards Agentic Compiler Auto-tuning with Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Compiler auto-tuning optimizes pass sequences to improve performance metrics\nsuch as Intermediate Representation (IR) instruction count. Although recent\nadvances leveraging Large Language Models (LLMs) have shown promise in\nautomating compiler tuning, two significant challenges still remain: the\nabsence of high-quality reasoning datasets for agents training, and limited\neffective interactions with the compilation environment. In this work, we\nintroduce Compiler-R1, the first reinforcement learning (RL)-driven framework\nspecifically augmenting LLM capabilities for compiler auto-tuning. Compiler-R1\nfeatures a curated, high-quality reasoning dataset and a novel two-stage\nend-to-end RL training pipeline, enabling efficient environment exploration and\nlearning through an outcome-based reward. Extensive experiments across seven\ndatasets demonstrate Compiler-R1 achieving an average 8.46% IR instruction\ncount reduction compared to opt -Oz, showcasing the strong potential of\nRL-trained LLMs for compiler optimization. Our code and datasets are publicly\navailable at https://github.com/Panhaolin2001/Compiler-R1.", "AI": {"tldr": "Compiler-R1\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3aLLM\u80fd\u529b\u4f18\u5316\u7f16\u8bd1\u5668\u81ea\u52a8\u8c03\u4f18\uff0c\u89e3\u51b3\u4e86\u9ad8\u8d28\u91cf\u63a8\u7406\u6570\u636e\u96c6\u7f3a\u5931\u548c\u73af\u5883\u4ea4\u4e92\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524dLLM\u5728\u7f16\u8bd1\u5668\u81ea\u52a8\u8c03\u4f18\u4e2d\u7684\u5e94\u7528\u9762\u4e34\u9ad8\u8d28\u91cf\u63a8\u7406\u6570\u636e\u96c6\u7f3a\u5931\u548c\u7f16\u8bd1\u73af\u5883\u4ea4\u4e92\u6709\u9650\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faCompiler-R1\u6846\u67b6\uff0c\u5305\u542b\u9ad8\u8d28\u91cf\u63a8\u7406\u6570\u636e\u96c6\u548c\u4e24\u9636\u6bb5\u7aef\u5230\u7aefRL\u8bad\u7ec3\u6d41\u7a0b\uff0c\u901a\u8fc7\u7ed3\u679c\u9a71\u52a8\u7684\u5956\u52b1\u673a\u5236\u4f18\u5316\u63a2\u7d22\u548c\u5b66\u4e60\u3002", "result": "\u5728\u4e03\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cCompiler-R1\u5e73\u5747\u51cf\u5c118.46%\u7684IR\u6307\u4ee4\u6570\uff0c\u4f18\u4e8eopt -Oz\u3002", "conclusion": "Compiler-R1\u5c55\u793a\u4e86RL\u8bad\u7ec3\u7684LLM\u5728\u7f16\u8bd1\u5668\u4f18\u5316\u4e2d\u7684\u5f3a\u5927\u6f5c\u529b\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.17120", "pdf": "https://arxiv.org/pdf/2506.17120", "abs": "https://arxiv.org/abs/2506.17120", "authors": ["Atish Kumar Dipongkor", "Ziyu Yao", "Kevin Moran"], "title": "Reassessing Code Authorship Attribution in the Era of Language Models", "categories": ["cs.SE"], "comment": "12 pages", "summary": "The study of Code Stylometry, and in particular Code Authorship Attribution\n(CAA), aims to analyze coding styles to identify the authors of code samples.\nCAA is crucial in cybersecurity and software forensics for addressing,\ndetecting plagiarism, and supporting criminal prosecutions. However, CAA is a\ncomplex and error prone task, due to the need for recognizing nuanced\nrelationships between coding patterns. This challenge is compounded in large\nsoftware systems with numerous authors due to the subtle variability of\npatterns that signify the coding style of one author among many. Given the\nchallenges related to this task, researchers have proposed and studied\nautomated approaches that rely upon classical Machine Learning and Deep\nLearning techniques. However, such techniques have historically relied upon\nhand-crafted features, and due to the often intricate interaction of different\nfeatures (e.g., formatting, etc.), have key limitations in properly\ncharacterizing authorship, and are sensitive to adversarial code perturbations.\nRecently, transformer-based Language Models (LMs) have shown remarkable\nefficacy across a range of software engineering tasks, and in the authorship\nattribution on natural language in the NLP domain. However, their effectiveness\nin CAA is not well understood. As such, we conduct the first extensive\nempirical study applying two larger state-of-the-art code LMs, and five smaller\ncode LMs to the task of CAA to 6 diverse datasets that encompass 12k code\nsnippets written by 463 developers. Furthermore, we perform an in-depth\nanalysis of our studied models' performance on CAA using established machine\nlearning interpretability techniques. The results of our analysis illustrate\nimportant findings that illuminate the behavior of LMs in understanding\nstylometric code patterns during the task of CAA, and point towards important\ndirections for future work.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4ee3\u7801\u98ce\u683c\u8ba1\u91cf\u5b66\u4e2d\u7684\u4ee3\u7801\u4f5c\u8005\u5f52\u5c5e\u95ee\u9898\uff08CAA\uff09\uff0c\u63a2\u8ba8\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u4e86\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578b\u5728CAA\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "CAA\u5728\u7f51\u7edc\u5b89\u5168\u548c\u8f6f\u4ef6\u53d6\u8bc1\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u624b\u5de5\u7279\u5f81\u4e14\u6613\u53d7\u5bf9\u6297\u6027\u5e72\u6270\uff0c\u6548\u679c\u6709\u9650\u3002Transformer\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5728CAA\u4e2d\u7684\u6548\u679c\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u7814\u7a76\u5e94\u7528\u4e86\u4e24\u79cd\u5927\u578b\u548c\u4e94\u79cd\u5c0f\u578b\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\uff0c\u5bf96\u4e2a\u6570\u636e\u96c6\uff08\u5305\u542b463\u540d\u5f00\u53d1\u8005\u768412k\u4ee3\u7801\u7247\u6bb5\uff09\u8fdb\u884cCAA\u4efb\u52a1\u8bc4\u4f30\uff0c\u5e76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u53ef\u89e3\u91ca\u6027\u6280\u672f\u6df1\u5165\u5206\u6790\u6a21\u578b\u8868\u73b0\u3002", "result": "\u5206\u6790\u7ed3\u679c\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u4ee3\u7801\u98ce\u683c\u6a21\u5f0f\u65f6\u7684\u884c\u4e3a\u7279\u70b9\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u65b9\u5411\u3002", "conclusion": "Transformer\u6a21\u578b\u5728CAA\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u4f18\u5316\u5176\u8868\u73b0\u3002"}}
{"id": "2506.15702", "pdf": "https://arxiv.org/pdf/2506.15702", "abs": "https://arxiv.org/abs/2506.15702", "authors": ["Peter Belcak", "Greg Heinrich", "Jan Kautz", "Pavlo Molchanov"], "title": "Minifinetuning: Low-Data Generation Domain Adaptation through Corrective Self-Distillation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Finetuning language models for a new domain inevitably leads to the\ndeterioration of their general performance. This becomes more pronounced the\nmore limited the finetuning data resource.\n  We introduce minifinetuning (MFT), a method for language model domain\nadaptation that considerably reduces the effects of overfitting-induced\ndegeneralization in low-data settings and which does so in the absence of any\npre-training data for replay. MFT demonstrates 2-10x more favourable\nspecialization-to-degeneralization ratios than standard finetuning across a\nwide range of models and domains and exhibits an intrinsic robustness to\noverfitting when data in the new domain is scarce and down to as little as 500\nsamples.\n  Employing corrective self-distillation that is individualized on the sample\nlevel, MFT outperforms parameter-efficient finetuning methods, demonstrates\nreplay-like degeneralization mitigation properties, and is composable with\neither for a combined effect.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aminifinetuning\uff08MFT\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u4f4e\u6570\u636e\u91cf\u7684\u60c5\u51b5\u4e0b\u51cf\u5c11\u8bed\u8a00\u6a21\u578b\u9886\u57df\u9002\u5e94\u4e2d\u7684\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u4e14\u65e0\u9700\u9884\u8bad\u7ec3\u6570\u636e\u3002", "motivation": "\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u5728\u6709\u9650\u6570\u636e\u4e0b\u5fae\u8c03\u65f6\u666e\u904d\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6837\u672c\u7ea7\u522b\u7684\u81ea\u6211\u84b8\u998f\u6280\u672f\uff0c\u7ed3\u5408\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u3002", "result": "MFT\u5728\u591a\u79cd\u6a21\u578b\u548c\u9886\u57df\u4e2d\u8868\u73b0\u51fa2-10\u500d\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u5728\u6570\u636e\u7a00\u7f3a\u65f6\u4ecd\u80fd\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "MFT\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u7ec4\u5408\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u7f13\u89e3\u4e86\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u6027\u80fd\u9000\u5316\u95ee\u9898\u3002"}}
{"id": "2506.17125", "pdf": "https://arxiv.org/pdf/2506.17125", "abs": "https://arxiv.org/abs/2506.17125", "authors": ["Xue Jiang", "Yihong Dong", "Zheng Fang", "Yingwei Ma", "Tangxinyu Wang", "Rongyu Cao", "Binhua Li", "Zhi Jin", "Wenpin Jiao", "Yongbin Li", "Ge Li"], "title": "Large Language Model Unlearning for Source Code", "categories": ["cs.SE"], "comment": null, "summary": "LLM4SE has demonstrated significant success, but LLMs' potential memorization\nof sensitive or outdated training data introduces critical risks to legal\ncompliance, software security, and code quality. LLM unlearning techniques,\nwhich can eliminate the influence of undesired data from LLMs in a\npost-training way, present a promising solution to address these concerns.\nWhile recent efforts in LLM unlearning show effectiveness in natural language,\ntheir applicability to source code remains underexplored. Our empirical study\nreveals that existing LLM unlearning approaches, when applied to source code,\ncause severe model utility degradation, rendering models practically unusable\nfor code generation. In this paper, we propose PROD, a novel unlearning\napproach that enables LLMs to forget undesired code content while effectively\npreserving their code generation capabilities. PROD suppresses the probability\nof forget data in LLMs' output distribution while promoting candidate\ndistributional components, enabling the model to jointly learn to forget\nspecific content and retain its general capabilities. To facilitate this study,\nwe establish a benchmark for code unlearning evaluation, which includes three\ncritical downstream tasks: copyrighted code unlearning, insecure code\nunlearning, and deprecated API unlearning. Our evaluation demonstrates that\nPROD achieves superior balance between forget quality and model utility\ncompared to existing unlearning approaches across three downstream tasks, while\nconsistently exhibiting improvements when applied to LLMs of varying series.\nPROD also exhibits superior robustness against adversarial attacks without\ngenerating or exposing the data to be forgotten. The results underscore that\nour approach not only extends the application boundary of unlearning techniques\nto source code, but also holds significant implications for advancing reliable\ncode generation.", "AI": {"tldr": "PROD\u662f\u4e00\u79cd\u65b0\u578b\u7684LLM\u9057\u5fd8\u65b9\u6cd5\uff0c\u4e13\u6ce8\u4e8e\u6e90\u4ee3\u7801\u9886\u57df\uff0c\u80fd\u5728\u9057\u5fd8\u4e0d\u826f\u6570\u636e\u7684\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002", "motivation": "LLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u6210\u529f\u5e94\u7528\u5e26\u6765\u4e86\u654f\u611f\u6216\u8fc7\u65f6\u6570\u636e\u8bb0\u5fc6\u7684\u98ce\u9669\uff0c\u73b0\u6709\u9057\u5fd8\u65b9\u6cd5\u5728\u6e90\u4ee3\u7801\u9886\u57df\u6548\u679c\u4e0d\u4f73\u3002", "method": "PROD\u901a\u8fc7\u6291\u5236\u9057\u5fd8\u6570\u636e\u7684\u8f93\u51fa\u6982\u7387\u5e76\u4fc3\u8fdb\u5019\u9009\u5206\u5e03\u7ec4\u4ef6\uff0c\u5b9e\u73b0\u9057\u5fd8\u4e0e\u80fd\u529b\u4fdd\u7559\u7684\u5e73\u8861\u3002", "result": "PROD\u5728\u4e09\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u8861\u4e86\u9057\u5fd8\u8d28\u91cf\u4e0e\u6a21\u578b\u5b9e\u7528\u6027\uff0c\u4e14\u5bf9\u6297\u653b\u51fb\u9c81\u68d2\u6027\u5f3a\u3002", "conclusion": "PROD\u6269\u5c55\u4e86\u9057\u5fd8\u6280\u672f\u7684\u5e94\u7528\u8303\u56f4\uff0c\u5bf9\u53ef\u9760\u4ee3\u7801\u751f\u6210\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2506.15703", "pdf": "https://arxiv.org/pdf/2506.15703", "abs": "https://arxiv.org/abs/2506.15703", "authors": ["Guoqing Chao", "Zhenghao Zhang", "Lei Meng", "Jie Wen", "Dianhui Chu"], "title": "Federated Incomplete Multi-view Clustering with Globally Fused Graph Guidance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated multi-view clustering has been proposed to mine the valuable\ninformation within multi-view data distributed across different devices and has\nachieved impressive results while preserving the privacy. Despite great\nprogress, most federated multi-view clustering methods only used global\npseudo-labels to guide the downstream clustering process and failed to exploit\nthe global information when extracting features. In addition, missing data\nproblem in federated multi-view clustering task is less explored. To address\nthese problems, we propose a novel Federated Incomplete Multi-view Clustering\nmethod with globally Fused Graph guidance (FIMCFG). Specifically, we designed a\ndual-head graph convolutional encoder at each client to extract two kinds of\nunderlying features containing global and view-specific information.\nSubsequently, under the guidance of the fused graph, the two underlying\nfeatures are fused into high-level features, based on which clustering is\nconducted under the supervision of pseudo-labeling. Finally, the high-level\nfeatures are uploaded to the server to refine the graph fusion and\npseudo-labeling computation. Extensive experimental results demonstrate the\neffectiveness and superiority of FIMCFG. Our code is publicly available at\nhttps://github.com/PaddiHunter/FIMCFG.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u4e0d\u5b8c\u5168\u591a\u89c6\u56fe\u805a\u7c7b\u65b9\u6cd5FIMCFG\uff0c\u901a\u8fc7\u5168\u5c40\u878d\u5408\u56fe\u6307\u5bfc\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u7279\u5f81\u63d0\u53d6\u548c\u7f3a\u5931\u6570\u636e\u95ee\u9898\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u591a\u89c6\u56fe\u805a\u7c7b\u65b9\u6cd5\u4ec5\u4f7f\u7528\u5168\u5c40\u4f2a\u6807\u7b7e\u6307\u5bfc\u805a\u7c7b\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u5168\u5c40\u4fe1\u606f\uff0c\u4e14\u5bf9\u7f3a\u5931\u6570\u636e\u95ee\u9898\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u8bbe\u8ba1\u53cc\u5934\u56fe\u5377\u79ef\u7f16\u7801\u5668\u63d0\u53d6\u5168\u5c40\u548c\u89c6\u56fe\u7279\u5b9a\u7279\u5f81\uff0c\u901a\u8fc7\u878d\u5408\u56fe\u6307\u5bfc\u7279\u5f81\u878d\u5408\u548c\u4f2a\u6807\u7b7e\u76d1\u7763\u805a\u7c7b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eFIMCFG\u7684\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002", "conclusion": "FIMCFG\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.17208", "pdf": "https://arxiv.org/pdf/2506.17208", "abs": "https://arxiv.org/abs/2506.17208", "authors": ["Matias Martinez", "Xavier Franch"], "title": "Dissecting the SWE-Bench Leaderboards: Profiling Submitters and Architectures of LLM- and Agent-Based Repair Systems", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "The rapid progress in Automated Program Repair (APR) has been driven by\nadvances in AI, particularly large language models (LLMs) and agent-based\nsystems. SWE-Bench is a recent benchmark designed to evaluate LLM-based repair\nsystems using real issues and pull requests mined from 12 popular open-source\nPython repositories. Its public leaderboards, SWE-Bench Lite and SWE-Bench\nVerified, have become central platforms for tracking progress and comparing\nsolutions. However, because the submission process does not require detailed\ndocumentation, the architectural design and origin of many solutions remain\nunclear. In this paper, we present the first comprehensive study of all\nsubmissions to the SWE-Bench Lite (68 entries) and Verified (79 entries)\nleaderboards, analyzing 67 unique approaches across dimensions such as\nsubmitter type, product availability, LLM usage, and system architecture. Our\nfindings reveal the dominance of proprietary LLMs (especially Claude 3.5/3.7),\nthe presence of both agentic and non-agentic designs, and a contributor base\nspanning from individual developers to large tech companies.", "AI": {"tldr": "\u5bf9SWE-Bench Lite\u548cVerified\u699c\u5355\u4e0a\u7684\u63d0\u4ea4\u8fdb\u884c\u4e86\u9996\u6b21\u5168\u9762\u7814\u7a76\uff0c\u5206\u6790\u4e8667\u79cd\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u4e13\u6709LLM\u7684\u4e3b\u5bfc\u5730\u4f4d\u3001\u4ee3\u7406\u4e0e\u975e\u4ee3\u7406\u8bbe\u8ba1\u7684\u5171\u5b58\uff0c\u4ee5\u53ca\u8d21\u732e\u8005\u7684\u591a\u6837\u6027\u3002", "motivation": "\u7531\u4e8eSWE-Bench\u63d0\u4ea4\u8fc7\u7a0b\u7f3a\u4e4f\u8be6\u7ec6\u6587\u6863\uff0c\u8bb8\u591a\u89e3\u51b3\u65b9\u6848\u7684\u8bbe\u8ba1\u548c\u6765\u6e90\u4e0d\u660e\u786e\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u5206\u6790\u4e86SWE-Bench Lite\uff0868\u9879\uff09\u548cVerified\uff0879\u9879\uff09\u699c\u5355\u7684\u6240\u6709\u63d0\u4ea4\uff0c\u4ece\u63d0\u4ea4\u8005\u7c7b\u578b\u3001\u4ea7\u54c1\u53ef\u7528\u6027\u3001LLM\u4f7f\u7528\u548c\u7cfb\u7edf\u67b6\u6784\u7b49\u7ef4\u5ea6\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u53d1\u73b0\u4e13\u6709LLM\uff08\u5982Claude 3.5/3.7\uff09\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u4ee3\u7406\u4e0e\u975e\u4ee3\u7406\u8bbe\u8ba1\u5e76\u5b58\uff0c\u8d21\u732e\u8005\u4ece\u4e2a\u4eba\u5f00\u53d1\u8005\u5230\u5927\u578b\u79d1\u6280\u516c\u53f8\u4e0d\u7b49\u3002", "conclusion": "\u7814\u7a76\u4e3aAPR\u9886\u57df\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6280\u672f\u8d8b\u52bf\u548c\u8d21\u732e\u8005\u751f\u6001\u3002"}}
{"id": "2506.15704", "pdf": "https://arxiv.org/pdf/2506.15704", "abs": "https://arxiv.org/abs/2506.15704", "authors": ["Feiyu Yao", "Qian Wang"], "title": "Learn from the Past: Fast Sparse Indexing for Large Language Model Decoding", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "As large language models (LLMs) continue to support increasingly longer\ncontexts, the memory demand for key-value (KV) caches during decoding grows\nrapidly, becoming a critical bottleneck in both GPU memory capacity and PCIe\nbandwidth. Sparse attention mechanisms alleviate this issue by computing\nattention weights only for selected key-value pairs. However, their indexing\ncomputation typically requires traversing all key vectors, resulting in\nsignificant computational and data transfer overhead. To reduce the cost of\nindex retrieval, existing methods often treat each decoding step as an\nindependent process, failing to exploit the temporal correlations embedded in\nhistorical decoding information. To this end, we propose LFPS(Learn From the\nPast for Sparse Indexing), an acceleration method that dynamically constructs\nsparse indexing candidates based on historical attention patterns. LFPS\ncaptures two prevalent trends in decoder attention -vertical patterns\n(attending to fixed positions) and slash patterns (attending to relative\npositions) -and incorporates a positional expansion strategy to effectively\npredict the Top-k indices for the current step. We validate LFPS on challenging\nlong-context benchmarks such as LongBench-RULER, using Llama-3.1-8B-Instruct as\nthe base model. Experimental results show that LFPS achieves up to 22.8$\\times$\nspeedup over full attention and 9.6$\\times$ speedup over exact Top-k retrieval\non an RTX 4090 GPU and a single CPU core of a Xeon Gold 6430, respectively,\nwhile preserving generation accuracy. These results demonstrate that LFPS\noffers a practical and efficient solution for decoding optimization in\nlong-context LLM inference.", "AI": {"tldr": "LFPS\u662f\u4e00\u79cd\u901a\u8fc7\u5229\u7528\u5386\u53f2\u6ce8\u610f\u529b\u6a21\u5f0f\u52a8\u6001\u6784\u5efa\u7a00\u758f\u7d22\u5f15\u5019\u9009\u7684\u52a0\u901f\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u957f\u4e0a\u4e0b\u6587LLM\u89e3\u7801\u4e2d\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u3002", "motivation": "\u968f\u7740LLM\u652f\u6301\u66f4\u957f\u7684\u4e0a\u4e0b\u6587\uff0cKV\u7f13\u5b58\u5728\u89e3\u7801\u65f6\u7684\u5185\u5b58\u9700\u6c42\u6025\u5267\u589e\u52a0\uff0c\u6210\u4e3aGPU\u5185\u5b58\u548cPCIe\u5e26\u5bbd\u7684\u74f6\u9888\u3002\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u867d\u80fd\u7f13\u89e3\u6b64\u95ee\u9898\uff0c\u4f46\u5176\u7d22\u5f15\u8ba1\u7b97\u4ecd\u9700\u904d\u5386\u6240\u6709\u952e\u5411\u91cf\uff0c\u5f00\u9500\u8f83\u5927\u3002", "method": "LFPS\u901a\u8fc7\u6355\u6349\u89e3\u7801\u6ce8\u610f\u529b\u7684\u5782\u76f4\u6a21\u5f0f\u548c\u659c\u7ebf\u6a21\u5f0f\uff0c\u52a8\u6001\u6784\u5efa\u7a00\u758f\u7d22\u5f15\u5019\u9009\uff0c\u5e76\u7ed3\u5408\u4f4d\u7f6e\u6269\u5c55\u7b56\u7565\u9884\u6d4b\u5f53\u524d\u6b65\u9aa4\u7684Top-k\u7d22\u5f15\u3002", "result": "\u5728LongBench-RULER\u7b49\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLFPS\u5b9e\u73b0\u4e8622.8\u500d\u4e8e\u5168\u6ce8\u610f\u529b\u548c9.6\u500d\u4e8e\u7cbe\u786eTop-k\u68c0\u7d22\u7684\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u51c6\u786e\u6027\u3002", "conclusion": "LFPS\u4e3a\u957f\u4e0a\u4e0b\u6587LLM\u63a8\u7406\u4e2d\u7684\u89e3\u7801\u4f18\u5316\u63d0\u4f9b\u4e86\u9ad8\u6548\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.15790", "pdf": "https://arxiv.org/pdf/2506.15790", "abs": "https://arxiv.org/abs/2506.15790", "authors": ["Chenyang Peng", "Haijun Wang", "Yin Wu", "Hao Wu", "Ming Fan", "Yitao Zhao", "Ting Liu"], "title": "ETrace:Event-Driven Vulnerability Detection in Smart Contracts via LLM-Based Trace Analysis", "categories": ["cs.CR", "cs.SE", "D.2"], "comment": "4 pages, 1 figure. Submitted to the 16th Asia-Pacific Symposium on\n  Internetware (Internetware 2025)", "summary": "With the advance application of blockchain technology in various fields,\nensuring the security and stability of smart contracts has emerged as a\ncritical challenge. Current security analysis methodologies in vulnerability\ndetection can be categorized into static analysis and dynamic analysis\nmethods.However, these existing traditional vulnerability detection methods\npredominantly rely on analyzing original contract code, not all smart contracts\nprovide accessible code.We present ETrace, a novel event-driven vulnerability\ndetection framework for smart contracts, which uniquely identifies potential\nvulnerabilities through LLM-powered trace analysis without requiring source\ncode access. By extracting fine-grained event sequences from transaction logs,\nthe framework leverages Large Language Models (LLMs) as adaptive semantic\ninterpreters to reconstruct event analysis through chain-of-thought reasoning.\nETrace implements pattern-matching to establish causal links between\ntransaction behavior patterns and known attack behaviors. Furthermore, we\nvalidate the effectiveness of ETrace through preliminary experimental results.", "AI": {"tldr": "ETrace\u662f\u4e00\u79cd\u57fa\u4e8e\u4e8b\u4ef6\u9a71\u52a8\u7684\u667a\u80fd\u5408\u7ea6\u6f0f\u6d1e\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7LLM\u652f\u6301\u7684\u8ffd\u8e2a\u5206\u6790\uff0c\u65e0\u9700\u6e90\u4ee3\u7801\u5373\u53ef\u8bc6\u522b\u6f5c\u5728\u6f0f\u6d1e\u3002", "motivation": "\u968f\u7740\u533a\u5757\u94fe\u6280\u672f\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u667a\u80fd\u5408\u7ea6\u7684\u5b89\u5168\u6027\u548c\u7a33\u5b9a\u6027\u6210\u4e3a\u5173\u952e\u6311\u6218\uff0c\u800c\u4f20\u7edf\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u6e90\u4ee3\u7801\u5206\u6790\uff0c\u4f46\u5e76\u975e\u6240\u6709\u5408\u7ea6\u90fd\u63d0\u4f9b\u53ef\u8bbf\u95ee\u7684\u4ee3\u7801\u3002", "method": "ETrace\u901a\u8fc7\u4ece\u4ea4\u6613\u65e5\u5fd7\u4e2d\u63d0\u53d6\u7ec6\u7c92\u5ea6\u4e8b\u4ef6\u5e8f\u5217\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u81ea\u9002\u5e94\u8bed\u4e49\u89e3\u91ca\u5668\uff0c\u901a\u8fc7\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u91cd\u5efa\u4e8b\u4ef6\u5206\u6790\uff0c\u5e76\u901a\u8fc7\u6a21\u5f0f\u5339\u914d\u5efa\u7acb\u4ea4\u6613\u884c\u4e3a\u6a21\u5f0f\u4e0e\u5df2\u77e5\u653b\u51fb\u884c\u4e3a\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86ETrace\u7684\u6709\u6548\u6027\u3002", "conclusion": "ETrace\u4e3a\u65e0\u9700\u6e90\u4ee3\u7801\u7684\u667a\u80fd\u5408\u7ea6\u6f0f\u6d1e\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.15705", "pdf": "https://arxiv.org/pdf/2506.15705", "abs": "https://arxiv.org/abs/2506.15705", "authors": ["Jittarin Jetwiriyanon", "Teo Susnjak", "Surangika Ranathunga"], "title": "Generalisation Bounds of Zero-Shot Economic Forecasting using Time Series Foundation Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study investigates zero-shot forecasting capabilities of Time Series\nFoundation Models (TSFMs) for macroeconomic indicators. We apply TSFMs to\nforecasting economic indicators under univariate conditions, bypassing the need\nfor train bespoke econometric models using and extensive training datasets. Our\nexperiments were conducted on a case study dataset, without additional\ncustomisation. We rigorously back-tested three state-of-the-art TSFMs (Chronos,\nTimeGPT and Moirai) under data-scarce conditions and structural breaks. Our\nresults demonstrate that appropriately engineered TSFMs can internalise rich\neconomic dynamics, accommodate regime shifts, and deliver well-behaved\nuncertainty estimates out of the box, while matching state-of-the-art\nmultivariate models on this domain. Our findings suggest that, without any\nfine-tuning, TSFMs can match or exceed classical models during stable economic\nconditions. However, they are vulnerable to degradation in performances during\nperiods of rapid shocks. The findings offer guidance to practitioners on when\nzero-shot deployments are viable for macroeconomic monitoring and strategic\nplanning.", "AI": {"tldr": "\u7814\u7a76\u4e86\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFMs\uff09\u5728\u5b8f\u89c2\u7ecf\u6d4e\u6307\u6807\u9884\u6d4b\u4e2d\u7684\u96f6\u6837\u672c\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u5728\u7a33\u5b9a\u7ecf\u6d4e\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u5feb\u901f\u51b2\u51fb\u65f6\u671f\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u63a2\u7d22TSFMs\u5728\u65e0\u9700\u8bad\u7ec3\u5b9a\u5236\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u9884\u6d4b\u5b8f\u89c2\u7ecf\u6d4e\u6307\u6807\u7684\u6f5c\u529b\uff0c\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u96f6\u6837\u672c\u90e8\u7f72\u7684\u6307\u5bfc\u3002", "method": "\u5728\u6570\u636e\u7a00\u7f3a\u548c\u7ed3\u6784\u65ad\u88c2\u6761\u4ef6\u4e0b\uff0c\u5bf9\u4e09\u79cd\u5148\u8fdbTSFMs\uff08Chronos\u3001TimeGPT\u548cMoirai\uff09\u8fdb\u884c\u4e25\u683c\u56de\u6d4b\u3002", "result": "TSFMs\u80fd\u5185\u5316\u7ecf\u6d4e\u52a8\u6001\u3001\u9002\u5e94\u5236\u5ea6\u53d8\u5316\u5e76\u63d0\u4f9b\u826f\u597d\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u6027\u80fd\u5ab2\u7f8e\u591a\u53d8\u91cf\u6a21\u578b\uff0c\u4f46\u5728\u5feb\u901f\u51b2\u51fb\u65f6\u671f\u8868\u73b0\u4e0b\u964d\u3002", "conclusion": "TSFMs\u5728\u7a33\u5b9a\u6761\u4ef6\u4e0b\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u5339\u914d\u6216\u8d85\u8d8a\u4f20\u7edf\u6a21\u578b\uff0c\u4f46\u5728\u5feb\u901f\u51b2\u51fb\u65f6\u671f\u9700\u8c28\u614e\u4f7f\u7528\u3002"}}
{"id": "2506.15955", "pdf": "https://arxiv.org/pdf/2506.15955", "abs": "https://arxiv.org/abs/2506.15955", "authors": ["Tong Hu", "Songzan Wang"], "title": "From Generation to Adaptation: Comparing AI-Assisted Strategies in High School Programming Education", "categories": ["cs.CY", "cs.SE"], "comment": null, "summary": "This exploratory case study investigated two contrasting pedagogical\napproaches for LCA-assisted programming with five novice high school students\npreparing for a WeChat Mini Program competition. In Phase 1, students used LCAs\nto generate code from abstract specifications (From-Scratch approach),\nachieving only 20% MVP completion. In Phase 2, students adapted existing\nMinimal Functional Units (MFUs), small, functional code examples, using LCAs,\nachieving 100% MVP completion. Analysis revealed that the MFU-based approach\nsucceeded by aligning with LCA strengths in pattern modification rather than de\nnovo generation, while providing cognitive scaffolds that enabled students to\nnavigate complex development tasks. The study introduces a dual-scaffolding\nmodel combining technical support (MFUs) with pedagogical guidance (structured\nprompting strategies), demonstrating that effective LCA integration depends\nless on AI capabilities than on instructional design. These findings offer\npractical guidance for educators seeking to transform AI tools from sources of\nfrustration into productive learning partners in programming education.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4e24\u79cd\u6559\u5b66\u65b9\u6cd5\u5bf9\u9ad8\u4e2d\u751f\u7f16\u7a0b\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u57fa\u4e8e\u73b0\u6709\u529f\u80fd\u5355\u5143\u7684\u4fee\u6539\u6bd4\u4ece\u96f6\u751f\u6210\u4ee3\u7801\u66f4\u6709\u6548\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u66f4\u597d\u5730\u5c06AI\u5de5\u5177\uff08LCA\uff09\u878d\u5165\u7f16\u7a0b\u6559\u80b2\uff0c\u5e2e\u52a9\u521d\u5b66\u8005\u9ad8\u6548\u5b8c\u6210\u4efb\u52a1\u3002", "method": "\u5206\u4e24\u9636\u6bb5\u5b9e\u9a8c\uff1a\u7b2c\u4e00\u9636\u6bb5\u4ece\u96f6\u751f\u6210\u4ee3\u7801\uff0c\u7b2c\u4e8c\u9636\u6bb5\u57fa\u4e8e\u73b0\u6709\u529f\u80fd\u5355\u5143\u4fee\u6539\u3002", "result": "\u7b2c\u4e8c\u9636\u6bb5\uff08\u4fee\u6539\u73b0\u6709\u4ee3\u7801\uff09\u5b8c\u6210\u7387100%\uff0c\u663e\u8457\u4f18\u4e8e\u7b2c\u4e00\u9636\u6bb5\uff0820%\uff09\u3002", "conclusion": "AI\u5de5\u5177\u7684\u6709\u6548\u6027\u66f4\u4f9d\u8d56\u4e8e\u6559\u5b66\u8bbe\u8ba1\u800c\u975e\u6280\u672f\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408\u6280\u672f\u548c\u6559\u5b66\u7684\u53cc\u91cd\u652f\u67b6\u6a21\u578b\u3002"}}
{"id": "2506.15706", "pdf": "https://arxiv.org/pdf/2506.15706", "abs": "https://arxiv.org/abs/2506.15706", "authors": ["Yunze Lin"], "title": "MDPO: Multi-Granularity Direct Preference Optimization for Mathematical Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mathematical reasoning presents a significant challenge for Large Language\nModels (LLMs) as it requires ensuring the correctness of each reasoning step.\nResearchers have been strengthening the mathematical reasoning abilities of\nLLMs through supervised fine-tuning, but due to the inability to suppress\nincorrect outputs, illusions can easily arise. Recently, Direct Preference\nOptimization (DPO) has been widely adopted for aligning human intent by using\npreference data to prevent LLMs from generating incorrect outputs. However, it\nhas shown limited benefits in long-chain mathematical reasoning, mainly because\nDPO struggles to effectively capture the differences between accepted and\nrejected answers from preferences in long-chain data. The inconsistency between\nDPO training and LLMs' generation metrics also affects the effectiveness of\nsuppressing incorrect outputs. We propose the Multi-Granularity Direct\nPreference Optimization (MDPO) method, optimizing the mathematical reasoning of\nLLMs at three granularities: Solution2Solution, Inference2Inference, and\nStep2Step. Solution2Solution focuses on the correctness of entire long-chain\nreasoning; Inference2Inference concentrates on logical reasoning between steps;\nStep2Step corrects computational errors in steps, enhancing the computational\ncapabilities of LLMs. Additionally, we unify the training objectives of the\nthree granularities to align with the generation metrics. We conducted\nexperiments on the open-source models Qwen2 and Llama3, achieving improvements\nof 1.7% and 0.9% on the GSM8K dataset, and 2.3% and 1.2% on the MATH dataset,\noutperforming DPO and other DPO variant methods. Furthermore, we also provide a\npipeline for constructing MDPO training data that is simple and does not\nrequire manual annotation costs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u7c92\u5ea6\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08MDPO\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u4e2a\u7c92\u5ea6\u4f18\u5316LLMs\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u89e3\u51b3\u4e86DPO\u5728\u957f\u94fe\u63a8\u7406\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u73b0\u6709\u65b9\u6cd5\u5982DPO\u5728\u957f\u94fe\u63a8\u7406\u4e2d\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u4f18\u5316\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faMDPO\u65b9\u6cd5\uff0c\u901a\u8fc7Solution2Solution\u3001Inference2Inference\u548cStep2Step\u4e09\u4e2a\u7c92\u5ea6\u4f18\u5316LLMs\u7684\u6570\u5b66\u63a8\u7406\uff0c\u5e76\u7edf\u4e00\u8bad\u7ec3\u76ee\u6807\u4e0e\u751f\u6210\u6307\u6807\u5bf9\u9f50\u3002", "result": "\u5728Qwen2\u548cLlama3\u6a21\u578b\u4e0a\uff0cGSM8K\u6570\u636e\u96c6\u63d0\u53471.7%\u548c0.9%\uff0cMATH\u6570\u636e\u96c6\u63d0\u53472.3%\u548c1.2%\uff0c\u4f18\u4e8eDPO\u53ca\u5176\u53d8\u4f53\u3002", "conclusion": "MDPO\u901a\u8fc7\u591a\u7c92\u5ea6\u4f18\u5316\u663e\u8457\u63d0\u5347\u4e86LLMs\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684\u6570\u636e\u6784\u5efa\u6d41\u7a0b\u3002"}}
{"id": "2506.16492", "pdf": "https://arxiv.org/pdf/2506.16492", "abs": "https://arxiv.org/abs/2506.16492", "authors": ["Renato Cordeiro Ferreira", "Thatiane de Oliveira Rosa", "Alfredo Goldman", "Eduardo Guerra"], "title": "Teaching Complex Systems based on Microservices", "categories": ["cs.CY", "cs.SE", "D.2.11; D.2.3; D.2.1"], "comment": "4 pages, 3 figures (2 diagrams, 2 tables), reviewed and presented at\n  AMP2020", "summary": "Developing complex systems using microservices is a current challenge. In\nthis paper, we present our experience with teaching this subject to more than\n80 students at the University of S\\~ao Paulo (USP), fostering team work and\nsimulating the industry's environment. We show it is possible to teach such\nadvanced concepts for senior undergraduate students of Computer Science and\nrelated fields.", "AI": {"tldr": "\u672c\u6587\u5206\u4eab\u4e86\u5728\u5723\u4fdd\u7f57\u5927\u5b66\uff08USP\uff09\u6559\u638880\u591a\u540d\u5b66\u751f\u5fae\u670d\u52a1\u5f00\u53d1\u7684\u7ecf\u9a8c\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u56e2\u961f\u5408\u4f5c\u548c\u6a21\u62df\u5de5\u4e1a\u73af\u5883\u6559\u6388\u9ad8\u7ea7\u6982\u5ff5\u3002", "motivation": "\u6559\u6388\u5fae\u670d\u52a1\u5f00\u53d1\u8fd9\u4e00\u590d\u6742\u7cfb\u7edf\u6784\u5efa\u65b9\u6cd5\uff0c\u5e76\u9a8c\u8bc1\u5176\u662f\u5426\u9002\u5408\u8ba1\u7b97\u673a\u79d1\u5b66\u53ca\u76f8\u5173\u9886\u57df\u7684\u9ad8\u5e74\u7ea7\u672c\u79d1\u751f\u3002", "method": "\u901a\u8fc7\u56e2\u961f\u5408\u4f5c\u548c\u6a21\u62df\u5de5\u4e1a\u73af\u5883\u7684\u65b9\u5f0f\uff0c\u6559\u638880\u591a\u540d\u5b66\u751f\u5fae\u670d\u52a1\u5f00\u53d1\u3002", "result": "\u8bc1\u660e\u4e86\u5fae\u670d\u52a1\u5f00\u53d1\u8fd9\u4e00\u9ad8\u7ea7\u6982\u5ff5\u53ef\u4ee5\u6210\u529f\u6559\u6388\u7ed9\u9ad8\u5e74\u7ea7\u672c\u79d1\u751f\u3002", "conclusion": "\u56e2\u961f\u5408\u4f5c\u548c\u6a21\u62df\u5de5\u4e1a\u73af\u5883\u662f\u6559\u6388\u5fae\u670d\u52a1\u5f00\u53d1\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u9002\u5408\u9ad8\u5e74\u7ea7\u672c\u79d1\u751f\u5b66\u4e60\u3002"}}
{"id": "2506.15707", "pdf": "https://arxiv.org/pdf/2506.15707", "abs": "https://arxiv.org/abs/2506.15707", "authors": ["Xinglin Wang", "Yiwei Li", "Shaoxiong Feng", "Peiwen Yuan", "Yueqi Zhang", "Jiayi Shi", "Chuyi Tan", "Boyuan Pan", "Yao Hu", "Kan Li"], "title": "Every Rollout Counts: Optimal Resource Allocation for Efficient Test-Time Scaling", "categories": ["cs.LG", "cs.AI"], "comment": "preprint", "summary": "Test-Time Scaling (TTS) improves the performance of Large Language Models\n(LLMs) by using additional inference-time computation to explore multiple\nreasoning paths through search. Yet how to allocate a fixed rollout budget most\neffectively during search remains underexplored, often resulting in inefficient\nuse of compute at test time. To bridge this gap, we formulate test-time search\nas a resource allocation problem and derive the optimal allocation strategy\nthat maximizes the probability of obtaining a correct solution under a fixed\nrollout budget. Within this formulation, we reveal a core limitation of\nexisting search methods: solution-level allocation tends to favor reasoning\ndirections with more candidates, leading to theoretically suboptimal and\ninefficient use of compute. To address this, we propose Direction-Oriented\nResource Allocation (DORA), a provably optimal method that mitigates this bias\nby decoupling direction quality from candidate count and allocating resources\nat the direction level. To demonstrate DORA's effectiveness, we conduct\nextensive experiments on challenging mathematical reasoning benchmarks\nincluding MATH500, AIME2024, and AIME2025. The empirical results show that DORA\nconsistently outperforms strong baselines with comparable computational cost,\nachieving state-of-the-art accuracy. We hope our findings contribute to a\nbroader understanding of optimal TTS for LLMs.", "AI": {"tldr": "TTS\u901a\u8fc7\u641c\u7d22\u4f18\u5316LLM\u6027\u80fd\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u8d44\u6e90\u5206\u914d\u4e0a\u6548\u7387\u4e0d\u8db3\u3002DORA\u63d0\u51fa\u65b9\u5411\u7ea7\u8d44\u6e90\u5206\u914d\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709TTS\u65b9\u6cd5\u5728\u56fa\u5b9a\u9884\u7b97\u4e0b\u8d44\u6e90\u5206\u914d\u6548\u7387\u4f4e\uff0c\u65e0\u6cd5\u6700\u5927\u5316\u6b63\u786e\u89e3\u7684\u6982\u7387\u3002", "method": "\u5c06\u6d4b\u8bd5\u65f6\u641c\u7d22\u5efa\u6a21\u4e3a\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u63d0\u51faDORA\u65b9\u6cd5\uff0c\u901a\u8fc7\u65b9\u5411\u7ea7\u5206\u914d\u4f18\u5316\u8d44\u6e90\u5229\u7528\u3002", "result": "DORA\u5728MATH500\u3001AIME2024\u548cAIME2025\u7b49\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u8868\u73b0\u6700\u4f18\u3002", "conclusion": "DORA\u4e3aLLM\u7684TTS\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u8d44\u6e90\u5206\u914d\u7b56\u7565\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.16652", "pdf": "https://arxiv.org/pdf/2506.16652", "abs": "https://arxiv.org/abs/2506.16652", "authors": ["Guang Yin", "Yitong Li", "Yixuan Wang", "Dale McConachie", "Paarth Shah", "Kunimatsu Hashimoto", "Huan Zhang", "Katherine Liu", "Yunzhu Li"], "title": "CodeDiffuser: Attention-Enhanced Diffusion Policy via VLM-Generated Code for Instruction Ambiguity", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SE"], "comment": "Accepted to Robotics: Science and Systems (RSS) 2025. The first three\n  authors contributed equally. Project Page:\n  https://robopil.github.io/code-diffuser/", "summary": "Natural language instructions for robotic manipulation tasks often exhibit\nambiguity and vagueness. For instance, the instruction \"Hang a mug on the mug\ntree\" may involve multiple valid actions if there are several mugs and branches\nto choose from. Existing language-conditioned policies typically rely on\nend-to-end models that jointly handle high-level semantic understanding and\nlow-level action generation, which can result in suboptimal performance due to\ntheir lack of modularity and interpretability. To address these challenges, we\nintroduce a novel robotic manipulation framework that can accomplish tasks\nspecified by potentially ambiguous natural language. This framework employs a\nVision-Language Model (VLM) to interpret abstract concepts in natural language\ninstructions and generates task-specific code - an interpretable and executable\nintermediate representation. The generated code interfaces with the perception\nmodule to produce 3D attention maps that highlight task-relevant regions by\nintegrating spatial and semantic information, effectively resolving ambiguities\nin instructions. Through extensive experiments, we identify key limitations of\ncurrent imitation learning methods, such as poor adaptation to language and\nenvironmental variations. We show that our approach excels across challenging\nmanipulation tasks involving language ambiguity, contact-rich manipulation, and\nmulti-object interactions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u6a21\u7cca\u6027\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u751f\u6210\u53ef\u89e3\u91ca\u7684\u4e2d\u95f4\u4ee3\u7801\uff0c\u7ed3\u5408\u611f\u77e5\u6a21\u5757\u89e3\u51b3\u6307\u4ee4\u6b67\u4e49\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6761\u4ef6\u7b56\u7565\u56e0\u7f3a\u4e4f\u6a21\u5757\u5316\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u6307\u4ee4\u7684\u6a21\u7cca\u6027\u3002", "method": "\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u89e3\u6790\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\uff0c\u751f\u6210\u4efb\u52a1\u7279\u5b9a\u4ee3\u7801\uff0c\u7ed3\u5408\u611f\u77e5\u6a21\u5757\u751f\u62103D\u6ce8\u610f\u529b\u56fe\u4ee5\u89e3\u51b3\u6b67\u4e49\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8bed\u8a00\u6a21\u7cca\u6027\u3001\u63a5\u89e6\u5bc6\u96c6\u64cd\u4f5c\u548c\u591a\u7269\u4f53\u4ea4\u4e92\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u901a\u8fc7\u6a21\u5757\u5316\u548c\u53ef\u89e3\u91ca\u6027\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u5bf9\u6a21\u7cca\u6307\u4ee4\u7684\u5904\u7406\u80fd\u529b\u3002"}}
{"id": "2506.15708", "pdf": "https://arxiv.org/pdf/2506.15708", "abs": "https://arxiv.org/abs/2506.15708", "authors": ["Falih Gozi Febrinanto", "Adonia Simango", "Chengpei Xu", "Jingjing Zhou", "Jiangang Ma", "Sonika Tyagi", "Feng Xia"], "title": "Refined Causal Graph Structure Learning via Curvature for Brain Disease Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph neural networks (GNNs) have been developed to model the relationship\nbetween regions of interest (ROIs) in brains and have shown significant\nimprovement in detecting brain diseases. However, most of these frameworks do\nnot consider the intrinsic relationship of causality factor between brain ROIs,\nwhich is arguably more essential to observe cause and effect interaction\nbetween signals rather than typical correlation values. We propose a novel\nframework called CGB (Causal Graphs for Brains) for brain disease\nclassification/detection, which models refined brain networks based on the\ncausal discovery method, transfer entropy, and geometric curvature strategy.\nCGB unveils causal relationships between ROIs that bring vital information to\nenhance brain disease classification performance. Furthermore, CGB also\nperforms a graph rewiring through a geometric curvature strategy to refine the\ngenerated causal graph to become more expressive and reduce potential\ninformation bottlenecks when GNNs model it. Our extensive experiments show that\nCGB outperforms state-of-the-art methods in classification tasks on brain\ndisease datasets, as measured by average F1 scores.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCGB\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u548c\u51e0\u4f55\u66f2\u7387\u7b56\u7565\u5efa\u6a21\u8111\u7f51\u7edc\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8111\u75be\u75c5\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709GNN\u6846\u67b6\u672a\u8003\u8651\u8111\u533a\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u800c\u56e0\u679c\u5173\u7cfb\u6bd4\u76f8\u5173\u6027\u66f4\u80fd\u63ed\u793a\u4fe1\u53f7\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\u3002", "method": "\u7ed3\u5408\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\uff08\u8f6c\u79fb\u71b5\uff09\u548c\u51e0\u4f55\u66f2\u7387\u7b56\u7565\uff0c\u6784\u5efa\u5e76\u4f18\u5316\u56e0\u679c\u56fe\u3002", "result": "CGB\u5728\u8111\u75be\u75c5\u5206\u7c7b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0cF1\u5206\u6570\u66f4\u9ad8\u3002", "conclusion": "CGB\u901a\u8fc7\u5efa\u6a21\u56e0\u679c\u5173\u7cfb\u548c\u4f18\u5316\u56fe\u7ed3\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8111\u75be\u75c5\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2506.15709", "pdf": "https://arxiv.org/pdf/2506.15709", "abs": "https://arxiv.org/abs/2506.15709", "authors": ["Pedro C. Vieira", "Miguel E. P. Silva", "Pedro Manuel Pinto Ribeiro"], "title": "Studying and Improving Graph Neural Network-based Motif Estimation", "categories": ["cs.LG", "cs.AI"], "comment": "This manuscript represents a revised version from the paper on\n  https://openreview.net/forum?id=PZVVOeu6xx. Still a work in progress.\n  Comments are welcome! 23 pages (12 main text + references), 9 figures, 5\n  tables", "summary": "Graph Neural Networks (GNNs) are a predominant method for graph\nrepresentation learning. However, beyond subgraph frequency estimation, their\napplication to network motif significance-profile (SP) prediction remains\nunder-explored, with no established benchmarks in the literature. We propose to\naddress this problem, framing SP estimation as a task independent of subgraph\nfrequency estimation. Our approach shifts from frequency counting to direct SP\nestimation and modulates the problem as multitarget regression. The\nreformulation is optimised for interpretability, stability and scalability on\nlarge graphs. We validate our method using a large synthetic dataset and\nfurther test it on real-world graphs. Our experiments reveal that 1-WL limited\nmodels struggle to make precise estimations of SPs. However, they can\ngeneralise to approximate the graph generation processes of networks by\ncomparing their predicted SP with the ones originating from synthetic\ngenerators. This first study on GNN-based motif estimation also hints at how\nusing direct SP estimation can help go past the theoretical limitations that\nmotif estimation faces when performed through subgraph counting.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u76f4\u63a5\u4f30\u8ba1\u7f51\u7edc\u6a21\u4f53\u663e\u8457\u6027\u8c31\uff08SP\uff09\u7684\u65b9\u6cd5\uff0c\u800c\u975e\u4f20\u7edf\u7684\u5b50\u56fe\u9891\u7387\u4f30\u8ba1\uff0c\u5e76\u901a\u8fc7\u591a\u76ee\u6807\u56de\u5f52\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u3001\u7a33\u5b9a\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u5728\u7f51\u7edc\u6a21\u4f53SP\u9884\u6d4b\u65b9\u9762\u7f3a\u4e4f\u63a2\u7d22\u548c\u57fa\u51c6\uff0c\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5e76\u7a81\u7834\u5b50\u56fe\u9891\u7387\u4f30\u8ba1\u7684\u7406\u8bba\u9650\u5236\u3002", "method": "\u5c06SP\u4f30\u8ba1\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u72ec\u7acb\u4e8e\u5b50\u56fe\u9891\u7387\u4f30\u8ba1\u7684\u4efb\u52a1\uff0c\u91c7\u7528\u591a\u76ee\u6807\u56de\u5f52\u65b9\u6cd5\uff0c\u5e76\u4f18\u5316\u53ef\u89e3\u91ca\u6027\u3001\u7a33\u5b9a\u6027\u548c\u5927\u89c4\u6a21\u56fe\u7684\u53ef\u6269\u5c55\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c1-WL\u53d7\u9650\u6a21\u578b\u96be\u4ee5\u7cbe\u786e\u4f30\u8ba1SP\uff0c\u4f46\u80fd\u901a\u8fc7\u6bd4\u8f83\u9884\u6d4bSP\u4e0e\u5408\u6210\u751f\u6210\u5668\u7684SP\uff0c\u8fd1\u4f3c\u7f51\u7edc\u751f\u6210\u8fc7\u7a0b\u3002", "conclusion": "\u76f4\u63a5SP\u4f30\u8ba1\u65b9\u6cd5\u6709\u52a9\u4e8e\u7a81\u7834\u5b50\u56fe\u8ba1\u6570\u5728\u6a21\u4f53\u4f30\u8ba1\u4e2d\u7684\u7406\u8bba\u9650\u5236\uff0c\u4e3aGNNs\u5728\u6a21\u4f53\u5206\u6790\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.15710", "pdf": "https://arxiv.org/pdf/2506.15710", "abs": "https://arxiv.org/abs/2506.15710", "authors": ["Siru Ouyang", "Xinyu Zhu", "Zilin Xiao", "Minhao Jiang", "Yu Meng", "Jiawei Han"], "title": "RAST: Reasoning Activation in LLMs via Small-model Transfer", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has become a powerful approach for improving the\nreasoning capabilities of large language models (LLMs), as evidenced by recent\nsuccesses such as OpenAI's o1 and Deepseek-R1. However, applying RL at scale\nremains intimidatingly resource-intensive, requiring multiple model copies and\nextensive GPU workloads. On the other hand, while being powerful, recent\nstudies suggest that RL does not fundamentally endow models with new knowledge;\nrather, it primarily reshapes the model's output distribution to activate\nreasoning capabilities latent in the base model. Building on this insight, we\nhypothesize that the changes in output probabilities induced by RL are largely\nmodel-size invariant, opening the door to a more efficient paradigm: training a\nsmall model with RL and transferring its induced probability shifts to larger\nbase models. To verify our hypothesis, we conduct a token-level analysis of\ndecoding trajectories and find high alignment in RL-induced output\ndistributions across model scales, validating our hypothesis. Motivated by\nthis, we propose RAST, a simple yet effective method that transfers reasoning\nbehaviors by injecting RL-induced probability adjustments from a small\nRL-trained model into larger models. Experiments across multiple mathematical\nreasoning benchmarks show that RAST substantially and consistently enhances the\nreasoning capabilities of base models while requiring significantly lower GPU\nmemory than direct RL training, sometimes even yielding better performance than\nthe RL-trained counterparts. Our findings offer new insights into the nature of\nRL-driven reasoning and practical strategies for scaling its benefits without\nincurring its full computational cost. The project page of RAST is available at\nhttps://ozyyshr.github.io/RAST/.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRAST\u7684\u9ad8\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u5c0f\u578bRL\u8bad\u7ec3\u6a21\u578b\u8f6c\u79fb\u6982\u7387\u8c03\u6574\u5230\u5927\u578b\u57fa\u7840\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u3002", "motivation": "\u5c3d\u7ba1\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u80fd\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5176\u5927\u89c4\u6a21\u5e94\u7528\u8d44\u6e90\u6d88\u8017\u5de8\u5927\u3002\u7814\u7a76\u53d1\u73b0RL\u5e76\u672a\u8d4b\u4e88\u6a21\u578b\u65b0\u77e5\u8bc6\uff0c\u800c\u662f\u8c03\u6574\u8f93\u51fa\u5206\u5e03\u4ee5\u6fc0\u6d3b\u57fa\u7840\u6a21\u578b\u7684\u6f5c\u5728\u80fd\u529b\u3002", "method": "\u63d0\u51faRAST\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790RL\u8bf1\u5bfc\u7684\u8f93\u51fa\u5206\u5e03\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0b\u7684\u5bf9\u9f50\u6027\uff0c\u5c06\u5c0f\u578bRL\u8bad\u7ec3\u6a21\u578b\u7684\u6982\u7387\u8c03\u6574\u8f6c\u79fb\u5230\u5927\u578b\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRAST\u663e\u8457\u63d0\u5347\u4e86\u57fa\u7840\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e14GPU\u5185\u5b58\u9700\u6c42\u8fdc\u4f4e\u4e8e\u76f4\u63a5RL\u8bad\u7ec3\uff0c\u6709\u65f6\u6027\u80fd\u751a\u81f3\u4f18\u4e8eRL\u8bad\u7ec3\u6a21\u578b\u3002", "conclusion": "RAST\u4e3aRL\u9a71\u52a8\u7684\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u5e76\u63d0\u4f9b\u4e86\u5728\u4e0d\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u6269\u5c55\u5176\u4f18\u52bf\u7684\u5b9e\u7528\u7b56\u7565\u3002"}}
{"id": "2506.15711", "pdf": "https://arxiv.org/pdf/2506.15711", "abs": "https://arxiv.org/abs/2506.15711", "authors": ["Le Jiang", "Liyan Ma", "Guang Yang"], "title": "Shadow defense against gradient inversion attack in federated learning", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV"], "comment": null, "summary": "Federated learning (FL) has emerged as a transformative framework for\nprivacy-preserving distributed training, allowing clients to collaboratively\ntrain a global model without sharing their local data. This is especially\ncrucial in sensitive fields like healthcare, where protecting patient data is\nparamount. However, privacy leakage remains a critical challenge, as the\ncommunication of model updates can be exploited by potential adversaries.\nGradient inversion attacks (GIAs), for instance, allow adversaries to\napproximate the gradients used for training and reconstruct training images,\nthus stealing patient privacy. Existing defense mechanisms obscure gradients,\nyet lack a nuanced understanding of which gradients or types of image\ninformation are most vulnerable to such attacks. These indiscriminate\ncalibrated perturbations result in either excessive privacy protection\ndegrading model accuracy, or insufficient one failing to safeguard sensitive\ninformation. Therefore, we introduce a framework that addresses these\nchallenges by leveraging a shadow model with interpretability for identifying\nsensitive areas. This enables a more targeted and sample-specific noise\ninjection. Specially, our defensive strategy achieves discrepancies of 3.73 in\nPSNR and 0.2 in SSIM compared to the circumstance without defense on the\nChestXRay dataset, and 2.78 in PSNR and 0.166 in the EyePACS dataset. Moreover,\nit minimizes adverse effects on model performance, with less than 1\\% F1\nreduction compared to SOTA methods. Our extensive experiments, conducted across\ndiverse types of medical images, validate the generalization of the proposed\nframework. The stable defense improvements for FedAvg are consistently over\n1.5\\% times in LPIPS and SSIM. It also offers a universal defense against\nvarious GIA types, especially for these sensitive areas in images.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u8054\u90a6\u5b66\u4e60\u4e2d\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u7684\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u5f71\u5b50\u6a21\u578b\u548c\u9488\u5bf9\u6027\u566a\u58f0\u6ce8\u5165\u4fdd\u62a4\u654f\u611f\u533a\u57df\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u9690\u79c1\u4fdd\u62a4\u5206\u5e03\u5f0f\u8bad\u7ec3\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\u53ef\u80fd\u5bfc\u81f4\u9690\u79c1\u6cc4\u9732\u3002\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u654f\u611f\u68af\u5ea6\u7684\u7cbe\u786e\u8bc6\u522b\uff0c\u5bfc\u81f4\u4fdd\u62a4\u4e0d\u8db3\u6216\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u5229\u7528\u5f71\u5b50\u6a21\u578b\u548c\u53ef\u89e3\u91ca\u6027\u6280\u672f\u8bc6\u522b\u654f\u611f\u533a\u57df\uff0c\u5e76\u8fdb\u884c\u6837\u672c\u7279\u5b9a\u7684\u566a\u58f0\u6ce8\u5165\u3002", "result": "\u5728ChestXRay\u548cEyePACS\u6570\u636e\u96c6\u4e0a\uff0cPSNR\u548cSSIM\u6307\u6807\u663e\u8457\u4f18\u4e8e\u65e0\u9632\u5fa1\u60c5\u51b5\uff0c\u4e14\u6a21\u578b\u6027\u80fd\u635f\u5931\u5c0f\u4e8e1%\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u6709\u6548\u9632\u5fa1\u591a\u79cd\u68af\u5ea6\u53cd\u8f6c\u653b\u51fb\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u533b\u7597\u56fe\u50cf\uff0c\u4e14\u5bf9\u8054\u90a6\u5b66\u4e60\u7684\u6027\u80fd\u5f71\u54cd\u6781\u5c0f\u3002"}}
{"id": "2506.15712", "pdf": "https://arxiv.org/pdf/2506.15712", "abs": "https://arxiv.org/abs/2506.15712", "authors": ["Songqi Zhou", "Ruixue Liu", "Yixing Wang", "Jia Lu", "Benben Jiang"], "title": "BatteryBERT for Realistic Battery Fault Detection Using Point-Masked Signal Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate fault detection in lithium-ion batteries is essential for the safe\nand reliable operation of electric vehicles and energy storage systems.\nHowever, existing methods often struggle to capture complex temporal\ndependencies and cannot fully leverage abundant unlabeled data. Although large\nlanguage models (LLMs) exhibit strong representation capabilities, their\narchitectures are not directly suited to the numerical time-series data common\nin industrial settings. To address these challenges, we propose a novel\nframework that adapts BERT-style pretraining for battery fault detection by\nextending the standard BERT architecture with a customized time-series-to-token\nrepresentation module and a point-level Masked Signal Modeling (point-MSM)\npretraining task tailored to battery applications. This approach enables\nself-supervised learning on sequential current, voltage, and other\ncharge-discharge cycle data, yielding distributionally robust, context-aware\ntemporal embeddings. We then concatenate these embeddings with battery metadata\nand feed them into a downstream classifier for accurate fault classification.\nExperimental results on a large-scale real-world dataset show that models\ninitialized with our pretrained parameters significantly improve both\nrepresentation quality and classification accuracy, achieving an AUROC of 0.945\nand substantially outperforming existing approaches. These findings validate\nthe effectiveness of BERT-style pretraining for time-series fault detection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eBERT\u98ce\u683c\u9884\u8bad\u7ec3\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u9502\u79bb\u5b50\u7535\u6c60\u6545\u969c\u68c0\u6d4b\uff0c\u901a\u8fc7\u5b9a\u5236\u7684\u65f6\u95f4\u5e8f\u5217\u8868\u793a\u6a21\u5757\u548c\u70b9\u7ea7\u63a9\u7801\u4fe1\u53f7\u5efa\u6a21\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u7c7b\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u590d\u6742\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u4e14\u65e0\u6cd5\u5145\u5206\u5229\u7528\u672a\u6807\u8bb0\u6570\u636e\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u67b6\u6784\u4e0d\u9002\u5408\u5de5\u4e1a\u573a\u666f\u4e2d\u7684\u6570\u503c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002", "method": "\u6269\u5c55\u6807\u51c6BERT\u67b6\u6784\uff0c\u5f15\u5165\u65f6\u95f4\u5e8f\u5217\u5230\u4ee4\u724c\u7684\u8868\u793a\u6a21\u5757\u548c\u70b9\u7ea7\u63a9\u7801\u4fe1\u53f7\u5efa\u6a21\uff08point-MSM\uff09\u9884\u8bad\u7ec3\u4efb\u52a1\uff0c\u7ed3\u5408\u7535\u6c60\u5143\u6570\u636e\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cAUROC\u8fbe\u52300.945\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u9a8c\u8bc1\u4e86BERT\u98ce\u683c\u9884\u8bad\u7ec3\u5728\u65f6\u95f4\u5e8f\u5217\u6545\u969c\u68c0\u6d4b\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.15713", "pdf": "https://arxiv.org/pdf/2506.15713", "abs": "https://arxiv.org/abs/2506.15713", "authors": ["Michael T. M. B. Morris-Thomas", "Marius Martens"], "title": "An application of machine learning to the motion response prediction of floating assets", "categories": ["cs.LG", "physics.data-an", "physics.flu-dyn"], "comment": "17 pages, 6 figures", "summary": "The real-time prediction of floating offshore asset behavior under stochastic\nmetocean conditions remains a significant challenge in offshore engineering.\nWhile traditional empirical and frequency-domain methods work well in benign\nconditions, they struggle with both extreme sea states and nonlinear responses.\nThis study presents a supervised machine learning approach using multivariate\nregression to predict the nonlinear motion response of a turret-moored vessel\nin 400 m water depth. We developed a machine learning workflow combining a\ngradient-boosted ensemble method with a custom passive weathervaning solver,\ntrained on approximately $10^6$ samples spanning 100 features. The model\nachieved mean prediction errors of less than 5% for critical mooring parameters\nand vessel heading accuracy to within 2.5 degrees across diverse metocean\nconditions, significantly outperforming traditional frequency-domain methods.\nThe framework has been successfully deployed on an operational facility,\ndemonstrating its efficacy for real-time vessel monitoring and operational\ndecision-making in offshore environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u76d1\u7763\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u9884\u6d4b\u6d6e\u52a8\u6d77\u4e0a\u8d44\u4ea7\u5728\u968f\u673a\u6d77\u6d0b\u6761\u4ef6\u4e0b\u7684\u975e\u7ebf\u6027\u8fd0\u52a8\u54cd\u5e94\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u9891\u57df\u65b9\u6cd5\u3002", "motivation": "\u5b9e\u65f6\u9884\u6d4b\u6d6e\u52a8\u6d77\u4e0a\u8d44\u4ea7\u5728\u968f\u673a\u6d77\u6d0b\u6761\u4ef6\u4e0b\u7684\u884c\u4e3a\u662f\u6d77\u4e0a\u5de5\u7a0b\u4e2d\u7684\u91cd\u5927\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u6781\u7aef\u6d77\u51b5\u548c\u975e\u7ebf\u6027\u54cd\u5e94\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u91c7\u7528\u591a\u5143\u56de\u5f52\u7684\u76d1\u7763\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u5408\u68af\u5ea6\u63d0\u5347\u96c6\u6210\u65b9\u6cd5\u548c\u81ea\u5b9a\u4e49\u88ab\u52a8\u8f6c\u5411\u6c42\u89e3\u5668\uff0c\u8bad\u7ec3\u4e86\u7ea6100\u4e07\u6837\u672c\u548c100\u4e2a\u7279\u5f81\u3002", "result": "\u6a21\u578b\u5bf9\u5173\u952e\u7cfb\u6cca\u53c2\u6570\u7684\u5e73\u5747\u9884\u6d4b\u8bef\u5dee\u5c0f\u4e8e5%\uff0c\u8239\u8236\u822a\u5411\u7cbe\u5ea6\u57282.5\u5ea6\u4ee5\u5185\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u9891\u57df\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u5df2\u6210\u529f\u5e94\u7528\u4e8e\u5b9e\u9645\u8bbe\u65bd\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u65f6\u8239\u8236\u76d1\u6d4b\u548c\u6d77\u4e0a\u64cd\u4f5c\u51b3\u7b56\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.15714", "pdf": "https://arxiv.org/pdf/2506.15714", "abs": "https://arxiv.org/abs/2506.15714", "authors": ["Andrew Kiruluta"], "title": "Adaptive Two Sided Laplace Transforms: A Learnable, Interpretable, and Scalable Replacement for Self-Attention", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "We propose an innovative, learnable two-sided short-time Laplace transform\n(STLT) mechanism to supplant the traditional self attention in\ntransformer-based LLMs. Our STLT introduces trainable parameters for each\nLaplace node, enabling end-to-end learning of decay rates , oscillatory\nfrequencies, and window bandwidth T. This flexibility allows the model to\ndynamically adapt token relevance half lives and frequency responses during\ntraining. By selecting S learnable nodes and leveraging fast recursive\nconvolution, we achieve an effective complexity of in time and memory. We\nfurther incorporate an efficient FFT-based computation of the relevance matrix\nand an adaptive node allocation mechanism to dynamically adjust the number of\nactive Laplace nodes. Empirical results on language modeling (WikiText\\-103,\nProject Gutenberg), machine translation (WMT'14 En\\-De), and long document\nquestion answering (NarrativeQA) demonstrate that our learnable STLT achieves\nperplexities and scores on par with or better than existing efficient\ntransformers while naturally extending to context lengths exceeding 100k tokens\nor more limited only by available hardware. Ablation studies confirm the\nimportance of learnable parameters and adaptive node allocation. The proposed\napproach combines interpretability, through explicit decay and frequency\nparameters, with scalability and robustness, offering a pathway towards\nultra-long-sequence language modeling without the computational bottleneck of\nself-attention.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u5b66\u4e60\u7684\u53cc\u8fb9\u77ed\u65f6\u62c9\u666e\u62c9\u65af\u53d8\u6362\uff08STLT\uff09\u673a\u5236\uff0c\u66ff\u4ee3\u4f20\u7edf\u81ea\u6ce8\u610f\u529b\uff0c\u5b9e\u73b0\u52a8\u6001\u8c03\u6574\u4ee4\u724c\u76f8\u5173\u6027\u548c\u9891\u7387\u54cd\u5e94\uff0c\u652f\u6301\u8d85\u957f\u5e8f\u5217\u5efa\u6a21\u3002", "motivation": "\u4f20\u7edf\u81ea\u6ce8\u610f\u529b\u5728\u957f\u5e8f\u5217\u5efa\u6a21\u4e2d\u5b58\u5728\u8ba1\u7b97\u74f6\u9888\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u53ef\u8bad\u7ec3\u7684\u62c9\u666e\u62c9\u65af\u8282\u70b9\u53c2\u6570\uff08\u8870\u51cf\u7387\u3001\u632f\u8361\u9891\u7387\u3001\u7a97\u53e3\u5e26\u5bbd\uff09\u548c\u5feb\u901f\u9012\u5f52\u5377\u79ef\uff0c\u7ed3\u5408FFT\u8ba1\u7b97\u548c\u81ea\u9002\u5e94\u8282\u70b9\u5206\u914d\u673a\u5236\u3002", "result": "\u5728\u8bed\u8a00\u5efa\u6a21\u3001\u673a\u5668\u7ffb\u8bd1\u548c\u957f\u6587\u6863\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u6216\u76f8\u5f53\u4e8e\u73b0\u6709\u9ad8\u6548Transformer\uff0c\u652f\u6301\u8d85\u8fc7100k tokens\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u3002", "conclusion": "STLT\u7ed3\u5408\u4e86\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u8d85\u957f\u5e8f\u5217\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2506.15715", "pdf": "https://arxiv.org/pdf/2506.15715", "abs": "https://arxiv.org/abs/2506.15715", "authors": ["Hanyu Pei", "Jing-Xiao Liao", "Qibin Zhao", "Ting Gao", "Shijun Zhang", "Xiaoge Zhang", "Feng-Lei Fan"], "title": "NeuronSeek: On Stability and Expressivity of Task-driven Neurons", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 10 figures", "summary": "Drawing inspiration from our human brain that designs different neurons for\ndifferent tasks, recent advances in deep learning have explored modifying a\nnetwork's neurons to develop so-called task-driven neurons. Prototyping\ntask-driven neurons (referred to as NeuronSeek) employs symbolic regression\n(SR) to discover the optimal neuron formulation and construct a network from\nthese optimized neurons. Along this direction, this work replaces symbolic\nregression with tensor decomposition (TD) to discover optimal neuronal\nformulations, offering enhanced stability and faster convergence. Furthermore,\nwe establish theoretical guarantees that modifying the aggregation functions\nwith common activation functions can empower a network with a fixed number of\nparameters to approximate any continuous function with an arbitrarily small\nerror, providing a rigorous mathematical foundation for the NeuronSeek\nframework. Extensive empirical evaluations demonstrate that our NeuronSeek-TD\nframework not only achieves superior stability, but also is competitive\nrelative to the state-of-the-art models across diverse benchmarks. The code is\navailable at https://github.com/HanyuPei22/NeuronSeek.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f20\u91cf\u5206\u89e3\uff08TD\uff09\u7684\u4efb\u52a1\u9a71\u52a8\u795e\u7ecf\u5143\u4f18\u5316\u65b9\u6cd5\uff08NeuronSeek-TD\uff09\uff0c\u66ff\u4ee3\u4e86\u539f\u6709\u7684\u7b26\u53f7\u56de\u5f52\uff08SR\uff09\uff0c\u4ee5\u63d0\u9ad8\u7a33\u5b9a\u6027\u548c\u6536\u655b\u901f\u5ea6\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u3002", "motivation": "\u53d7\u4eba\u7c7b\u5927\u8111\u4e2d\u4e0d\u540c\u795e\u7ecf\u5143\u5904\u7406\u4e0d\u540c\u4efb\u52a1\u7684\u542f\u53d1\uff0c\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u4f18\u5316\u795e\u7ecf\u5143\u8bbe\u8ba1\u6765\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u5f20\u91cf\u5206\u89e3\uff08TD\uff09\u66ff\u4ee3\u7b26\u53f7\u56de\u5f52\uff08SR\uff09\u6765\u53d1\u73b0\u6700\u4f18\u795e\u7ecf\u5143\u7ed3\u6784\uff0c\u5e76\u7406\u8bba\u8bc1\u660e\u4e86\u4fee\u6539\u805a\u5408\u51fd\u6570\u53ef\u4ee5\u5b9e\u73b0\u4efb\u610f\u8fde\u7eed\u51fd\u6570\u7684\u8fd1\u4f3c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cNeuronSeek-TD\u5728\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "NeuronSeek-TD\u6846\u67b6\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u4efb\u52a1\u9a71\u52a8\u795e\u7ecf\u5143\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.15716", "pdf": "https://arxiv.org/pdf/2506.15716", "abs": "https://arxiv.org/abs/2506.15716", "authors": ["Angelos Assos", "Carmel Baharav", "Bailey Flanigan", "Ariel Procaccia"], "title": "Alternates, Assemble! Selecting Optimal Alternates for Citizens' Assemblies", "categories": ["cs.LG", "cs.AI", "cs.GT"], "comment": null, "summary": "An increasingly influential form of deliberative democracy centers on\ncitizens' assemblies, where randomly selected people discuss policy questions.\nThe legitimacy of these panels hinges on their representation of the broader\npopulation, but panelists often drop out, leading to an unbalanced composition.\nAlthough participant attrition is mitigated in practice by alternates, their\nselection is not taken into account by existing methods. To address this gap,\nwe introduce an optimization framework for alternate selection. Our algorithmic\napproach, which leverages learning-theoretic machinery, estimates dropout\nprobabilities using historical data and selects alternates to minimize expected\nmisrepresentation. We establish theoretical guarantees for our approach,\nincluding worst-case bounds on sample complexity (with implications for\ncomputational efficiency) and on loss when panelists' probabilities of dropping\nout are mis-estimated. Empirical evaluation using real-world data demonstrates\nthat, compared to the status quo, our method significantly improves\nrepresentation while requiring fewer alternates.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u516c\u6c11\u96c6\u4f1a\u4e2d\u56e0\u53c2\u4e0e\u8005\u9000\u51fa\u5bfc\u81f4\u4ee3\u8868\u6027\u5931\u8861\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u7b97\u6cd5\u9009\u62e9\u66ff\u8865\u6210\u5458\u4ee5\u6700\u5c0f\u5316\u9884\u671f\u504f\u5dee\u3002", "motivation": "\u516c\u6c11\u96c6\u4f1a\u7684\u5408\u6cd5\u6027\u4f9d\u8d56\u4e8e\u5176\u5bf9\u5e7f\u6cdb\u4eba\u7fa4\u7684\u4ee3\u8868\u6027\uff0c\u4f46\u53c2\u4e0e\u8005\u9000\u51fa\u5bfc\u81f4\u4ee3\u8868\u6027\u5931\u8861\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u8003\u8651\u66ff\u8865\u6210\u5458\u7684\u9009\u62e9\u3002", "method": "\u5229\u7528\u5b66\u4e60\u7406\u8bba\u5de5\u5177\uff0c\u57fa\u4e8e\u5386\u53f2\u6570\u636e\u4f30\u8ba1\u9000\u51fa\u6982\u7387\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u7b97\u6cd5\u9009\u62e9\u66ff\u8865\u6210\u5458\u4ee5\u6700\u5c0f\u5316\u9884\u671f\u504f\u5dee\u3002", "result": "\u7406\u8bba\u5206\u6790\u63d0\u4f9b\u4e86\u6837\u672c\u590d\u6742\u6027\u548c\u8ba1\u7b97\u6548\u7387\u7684\u4fdd\u8bc1\uff0c\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u4ee3\u8868\u6027\u5e76\u51cf\u5c11\u4e86\u66ff\u8865\u9700\u6c42\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u516c\u6c11\u96c6\u4f1a\u4e2d\u7684\u4ee3\u8868\u6027\u5931\u8861\u95ee\u9898\uff0c\u5177\u6709\u7406\u8bba\u548c\u5b9e\u8df5\u610f\u4e49\u3002"}}
{"id": "2506.15717", "pdf": "https://arxiv.org/pdf/2506.15717", "abs": "https://arxiv.org/abs/2506.15717", "authors": ["Zhengze Zhang", "Shiqi Wang", "Yiqun Shen", "Simin Guo", "Dahua Lin", "Xiaoliang Wang", "Nguyen Cam-Tu", "Fei Tan"], "title": "daDPO: Distribution-Aware DPO for Distilling Conversational Abilities", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have demonstrated exceptional performance across\nvarious applications, but their conversational abilities decline sharply as\nmodel size decreases, presenting a barrier to their deployment in\nresource-constrained environments. Knowledge distillation with Direct\nPreference Optimization (dDPO) has emerged as a promising approach to enhancing\nthe conversational abilities of smaller models using a larger teacher model.\nHowever, current methods primarily focus on 'black-box' KD, which only uses the\nteacher's responses, overlooking the output distribution offered by the\nteacher. This paper addresses this gap by introducing daDPO (Distribution-Aware\nDPO), a unified method for preference optimization and distribution-based\ndistillation. We provide rigorous theoretical analysis and empirical\nvalidation, showing that daDPO outperforms existing methods in restoring\nperformance for pruned models and enhancing smaller LLM models. Notably, in\nin-domain evaluation, our method enables a 20% pruned Vicuna1.5-7B to achieve\nnear-teacher performance (-7.3% preference rate compared to that of dDPO's\n-31%), and allows Qwen2.5-1.5B to occasionally outperform its 7B teacher model\n(14.0% win rate).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3adaDPO\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u504f\u597d\u4f18\u5316\u548c\u57fa\u4e8e\u5206\u5e03\u7684\u84b8\u998f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u8bdd\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u73b0\u6709\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u5ffd\u7565\u4e86\u6559\u5e08\u6a21\u578b\u7684\u8f93\u51fa\u5206\u5e03\u4fe1\u606f\u3002", "method": "\u5f15\u5165daDPO\u65b9\u6cd5\uff0c\u7ed3\u5408\u504f\u597d\u4f18\u5316\u548c\u5206\u5e03\u611f\u77e5\u84b8\u998f\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "daDPO\u5728\u4fee\u526a\u6a21\u578b\u548c\u5c0f\u578b\u6a21\u578b\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f8b\u5982\u4fee\u526a\u540e\u7684Vicuna1.5-7B\u63a5\u8fd1\u6559\u5e08\u6a21\u578b\u6027\u80fd\uff0cQwen2.5-1.5B\u751a\u81f3\u5076\u5c14\u8d85\u8d8a\u51767B\u6559\u5e08\u6a21\u578b\u3002", "conclusion": "daDPO\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u586b\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2506.15718", "pdf": "https://arxiv.org/pdf/2506.15718", "abs": "https://arxiv.org/abs/2506.15718", "authors": ["Yu Guo", "Hongji Fang", "Tianyu Fang", "Zhe Cui"], "title": "BuildingBRep-11K: Precise Multi-Storey B-Rep Building Solids with Rich Layout Metadata", "categories": ["cs.LG"], "comment": null, "summary": "With the rise of artificial intelligence, the automatic generation of\nbuilding-scale 3-D objects has become an active research topic, yet training\nsuch models still demands large, clean and richly annotated datasets. We\nintroduce BuildingBRep-11K, a collection of 11 978 multi-storey (2-10 floors)\nbuildings (about 10 GB) produced by a shape-grammar-driven pipeline that\nencodes established building-design principles. Every sample consists of a\ngeometrically exact B-rep solid-covering floors, walls, slabs and rule-based\nopenings-together with a fast-loading .npy metadata file that records detailed\nper-floor parameters. The generator incorporates constraints on spatial scale,\ndaylight optimisation and interior layout, and the resulting objects pass\nmulti-stage filters that remove Boolean failures, undersized rooms and extreme\naspect ratios, ensuring compliance with architectural standards. To verify the\ndataset's learnability we trained two lightweight PointNet baselines. (i)\nMulti-attribute regression. A single encoder predicts storey count, total\nrooms, per-storey vector and mean room area from a 4 000-point cloud. On 100\nunseen buildings it attains 0.37-storey MAE (87 \\% within $\\pm1$), 5.7-room\nMAE, and 3.2 m$^2$ MAE on mean area. (ii) Defect detection. With the same\nbackbone we classify GOOD versus DEFECT; on a balanced 100-model set the\nnetwork reaches 54 \\% accuracy, recalling 82 \\% of true defects at 53 \\%\nprecision (41 TP, 9 FN, 37 FP, 13 TN). These pilots show that BuildingBRep-11K\nis learnable yet non-trivial for both geometric regression and topological\nquality assessment", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86BuildingBRep-11K\u6570\u636e\u96c6\uff0c\u5305\u542b11,978\u4e2a\u591a\u697c\u5c42\u5efa\u7b51\uff0c\u7528\u4e8e\u8bad\u7ec33D\u5efa\u7b51\u751f\u6210\u6a21\u578b\uff0c\u5e76\u9a8c\u8bc1\u5176\u5b66\u4e60\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u81ea\u52a8\u751f\u62103D\u5efa\u7b51\u6a21\u578b\u65f6\u7f3a\u4e4f\u5927\u89c4\u6a21\u3001\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u96c6\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5f62\u72b6\u8bed\u6cd5\u9a71\u52a8\u7684\u6d41\u7a0b\u751f\u6210\u5efa\u7b51\uff0c\u7ed3\u5408\u7a7a\u95f4\u5c3a\u5ea6\u3001\u91c7\u5149\u4f18\u5316\u548c\u5ba4\u5185\u5e03\u5c40\u7ea6\u675f\uff0c\u5e76\u901a\u8fc7\u591a\u9636\u6bb5\u8fc7\u6ee4\u5668\u786e\u4fdd\u7b26\u5408\u5efa\u7b51\u6807\u51c6\u3002", "result": "\u8bad\u7ec3\u4e86\u4e24\u4e2a\u8f7b\u91cf\u7ea7PointNet\u57fa\u7ebf\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u6570\u636e\u96c6\u5728\u51e0\u4f55\u56de\u5f52\u548c\u62d3\u6251\u8d28\u91cf\u8bc4\u4f30\u4e0a\u7684\u5b66\u4e60\u80fd\u529b\u3002", "conclusion": "BuildingBRep-11K\u6570\u636e\u96c6\u5177\u6709\u5b66\u4e60\u4ef7\u503c\uff0c\u4f46\u4efb\u52a1\u4ecd\u5177\u6311\u6218\u6027\u3002"}}
{"id": "2506.15719", "pdf": "https://arxiv.org/pdf/2506.15719", "abs": "https://arxiv.org/abs/2506.15719", "authors": ["Manal Rahal", "Bestoun S. Ahmed", "Roger Renstrom", "Robert Stener", "Albrecht Wurtz"], "title": "Data-Driven Heat Pump Management: Combining Machine Learning with Anomaly Detection for Residential Hot Water Systems", "categories": ["cs.LG"], "comment": "33 pages accepted in Neural Networks and Applications", "summary": "Heat pumps (HPs) have emerged as a cost-effective and clean technology for\nsustainable energy systems, but their efficiency in producing hot water remains\nrestricted by conventional threshold-based control methods. Although machine\nlearning (ML) has been successfully implemented for various HP applications,\noptimization of household hot water demand forecasting remains understudied.\nThis paper addresses this problem by introducing a novel approach that combines\npredictive ML with anomaly detection to create adaptive hot water production\nstrategies based on household-specific consumption patterns. Our key\ncontributions include: (1) a composite approach combining ML and isolation\nforest (iForest) to forecast household demand for hot water and steer\nresponsive HP operations; (2) multi-step feature selection with advanced\ntime-series analysis to capture complex usage patterns; (3) application and\ntuning of three ML models: Light Gradient Boosting Machine (LightGBM), Long\nShort-Term Memory (LSTM), and Bi-directional LSTM with the self-attention\nmechanism on data from different types of real HP installations; and (4)\nexperimental validation on six real household installations. Our experiments\nshow that the best-performing model LightGBM achieves superior performance,\nwith RMSE improvements of up to 9.37\\% compared to LSTM variants with $R^2$\nvalues between 0.748-0.983. For anomaly detection, our iForest implementation\nachieved an F1-score of 0.87 with a false alarm rate of only 5.2\\%,\ndemonstrating strong generalization capabilities across different household\ntypes and consumption patterns, making it suitable for real-world HP\ndeployments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u548c\u5f02\u5e38\u68c0\u6d4b\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u5bb6\u7528\u70ed\u6cf5\u70ed\u6c34\u9700\u6c42\u9884\u6d4b\uff0c\u5b9e\u9a8c\u8868\u660eLightGBM\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u9608\u503c\u7684\u63a7\u5236\u65b9\u6cd5\u9650\u5236\u4e86\u70ed\u6cf5\u5728\u70ed\u6c34\u751f\u4ea7\u4e2d\u7684\u6548\u7387\uff0c\u673a\u5668\u5b66\u4e60\u5728\u6b64\u9886\u57df\u7684\u4f18\u5316\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u4e0e\u9694\u79bb\u68ee\u6797\uff08iForest\uff09\u9884\u6d4b\u70ed\u6c34\u9700\u6c42\uff0c\u91c7\u7528\u591a\u6b65\u7279\u5f81\u9009\u62e9\u548c\u65f6\u95f4\u5e8f\u5217\u5206\u6790\uff0c\u5e94\u7528\u5e76\u4f18\u5316\u4e86LightGBM\u3001LSTM\u548c\u53cc\u5411LSTM\u4e09\u79cd\u6a21\u578b\u3002", "result": "LightGBM\u8868\u73b0\u6700\u4f18\uff0cRMSE\u63d0\u5347\u8fbe9.37%\uff0ciForest\u5f02\u5e38\u68c0\u6d4bF1\u5f97\u5206\u4e3a0.87\uff0c\u8bef\u62a5\u7387\u4ec55.2%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u5b9e\u9645\u70ed\u6cf5\u90e8\u7f72\uff0c\u5177\u6709\u5f3a\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.15720", "pdf": "https://arxiv.org/pdf/2506.15720", "abs": "https://arxiv.org/abs/2506.15720", "authors": ["Juntae Lee", "Munawar Hayat", "Sungrack Yun"], "title": "Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted at CVPR 2025", "summary": "Few-shot class incremental learning (FSCIL) enables the continual learning of\nnew concepts with only a few training examples. In FSCIL, the model undergoes\nsubstantial updates, making it prone to forgetting previous concepts and\noverfitting to the limited new examples. Most recent trend is typically to\ndisentangle the learning of the representation from the classification head of\nthe model. A well-generalized feature extractor on the base classes (many\nexamples and many classes) is learned, and then fixed during incremental\nlearning. Arguing that the fixed feature extractor restricts the model's\nadaptability to new classes, we introduce a novel FSCIL method to effectively\naddress catastrophic forgetting and overfitting issues. Our method enables to\nseamlessly update the entire model with a few examples. We mainly propose a\ntripartite weight-space ensemble (Tri-WE). Tri-WE interpolates the base,\nimmediately previous, and current models in weight-space, especially for the\nclassification heads of the models. Then, it collaboratively maintains\nknowledge from the base and previous models. In addition, we recognize the\nchallenges of distilling generalized representations from the previous model\nfrom scarce data. Hence, we suggest a regularization loss term using amplified\ndata knowledge distillation. Simply intermixing the few-shot data, we can\nproduce richer data enabling the distillation of critical knowledge from the\nprevious model. Consequently, we attain state-of-the-art results on the\nminiImageNet, CUB200, and CIFAR100 datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5c11\u6837\u672c\u7c7b\u589e\u91cf\u5b66\u4e60\u65b9\u6cd5\uff08Tri-WE\uff09\uff0c\u901a\u8fc7\u6743\u91cd\u7a7a\u95f4\u7684\u4e09\u5143\u96c6\u6210\u548c\u77e5\u8bc6\u84b8\u998f\u6b63\u5219\u5316\uff0c\u89e3\u51b3\u4e86\u707e\u96be\u6027\u9057\u5fd8\u548c\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684FSCIL\u65b9\u6cd5\u901a\u5e38\u56fa\u5b9a\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u9650\u5236\u4e86\u6a21\u578b\u5bf9\u65b0\u7c7b\u7684\u9002\u5e94\u6027\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u52a8\u6001\u66f4\u65b0\u6574\u4e2a\u6a21\u578b\uff0c\u63d0\u5347\u6a21\u578b\u5728\u5c11\u6837\u672c\u589e\u91cf\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e86Tri-WE\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6743\u91cd\u7a7a\u95f4\u4e2d\u63d2\u503c\u57fa\u7840\u6a21\u578b\u3001\u524d\u4e00\u4e2a\u6a21\u578b\u548c\u5f53\u524d\u6a21\u578b\u7684\u5206\u7c7b\u5934\uff0c\u5b9e\u73b0\u77e5\u8bc6\u534f\u540c\u7ef4\u62a4\uff1b\u540c\u65f6\u5f15\u5165\u57fa\u4e8e\u653e\u5927\u6570\u636e\u77e5\u8bc6\u84b8\u998f\u7684\u6b63\u5219\u5316\u635f\u5931\u9879\u3002", "result": "\u5728miniImageNet\u3001CUB200\u548cCIFAR100\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "Tri-WE\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86FSCIL\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u548c\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u52a8\u6001\u66f4\u65b0\u6574\u4e2a\u6a21\u578b\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2506.15721", "pdf": "https://arxiv.org/pdf/2506.15721", "abs": "https://arxiv.org/abs/2506.15721", "authors": ["Junqi Gao", "Zhichang Guo", "Dazhi Zhang", "Dong Li", "Runze Liu", "Pengfei Li", "Kai Tian", "Biqing Qi"], "title": "Bohdi: Heterogeneous LLM Fusion with Automatic Data Exploration", "categories": ["cs.LG"], "comment": null, "summary": "Heterogeneous Large Language Model (LLM) fusion integrates the strengths of\nmultiple source LLMs with different architectures into a target LLM with low\ncomputational overhead. While promising, existing methods suffer from two major\nlimitations: 1) reliance on real data from limited domain for knowledge fusion,\npreventing the target LLM from fully acquiring knowledge across diverse\ndomains, and 2) fixed data allocation proportions across domains, failing to\ndynamically adjust according to the target LLM's varying capabilities across\ndomains, leading to a capability imbalance. To overcome these limitations, we\npropose Bohdi, a synthetic-data-only heterogeneous LLM fusion framework.\nThrough the organization of knowledge domains into a hierarchical tree\nstructure, Bohdi enables automatic domain exploration and multi-domain data\ngeneration through multi-model collaboration, thereby comprehensively\nextracting knowledge from source LLMs. By formalizing domain expansion and data\nsampling proportion allocation on the knowledge tree as a Hierarchical\nMulti-Armed Bandit problem, Bohdi leverages the designed DynaBranches mechanism\nto adaptively adjust sampling proportions based on the target LLM's performance\nfeedback across domains. Integrated with our proposed Introspection-Rebirth\n(IR) mechanism, DynaBranches dynamically tracks capability shifts during target\nLLM's updates via Sliding Window Binomial Likelihood Ratio Testing (SWBLRT),\nfurther enhancing its online adaptation capability. Comparative experimental\nresults on a comprehensive suite of benchmarks demonstrate that Bohdi\nsignificantly outperforms existing baselines on multiple target LLMs, exhibits\nhigher data efficiency, and virtually eliminates the imbalance in the target\nLLM's capabilities. Our code is available at\nhttps://github.com/gjq100/Bohdi.git.", "AI": {"tldr": "Bohdi\u662f\u4e00\u4e2a\u57fa\u4e8e\u5408\u6210\u6570\u636e\u7684\u5f02\u6784\u5927\u8bed\u8a00\u6a21\u578b\u878d\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u6811\u7ed3\u6784\u548c\u52a8\u6001\u8c03\u6574\u673a\u5236\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u76ee\u6807\u6a21\u578b\u7684\u6027\u80fd\u548c\u6570\u636e\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u5f02\u6784\u5927\u8bed\u8a00\u6a21\u578b\u878d\u5408\u65b9\u6cd5\u4f9d\u8d56\u6709\u9650\u9886\u57df\u7684\u771f\u5b9e\u6570\u636e\u4e14\u5206\u914d\u6bd4\u4f8b\u56fa\u5b9a\uff0c\u5bfc\u81f4\u77e5\u8bc6\u83b7\u53d6\u4e0d\u5168\u9762\u548c\u80fd\u529b\u4e0d\u5e73\u8861\u3002", "method": "Bohdi\u91c7\u7528\u5206\u5c42\u6811\u7ed3\u6784\u7ec4\u7ec7\u77e5\u8bc6\u57df\uff0c\u901a\u8fc7\u591a\u6a21\u578b\u534f\u4f5c\u751f\u6210\u591a\u9886\u57df\u6570\u636e\uff0c\u5e76\u57fa\u4e8e\u5206\u5c42\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\u52a8\u6001\u8c03\u6574\u91c7\u6837\u6bd4\u4f8b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cBohdi\u5728\u591a\u4e2a\u76ee\u6807\u6a21\u578b\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6570\u636e\u6548\u7387\u66f4\u9ad8\u4e14\u80fd\u529b\u4e0d\u5e73\u8861\u95ee\u9898\u51e0\u4e4e\u6d88\u9664\u3002", "conclusion": "Bohdi\u901a\u8fc7\u5408\u6210\u6570\u636e\u548c\u52a8\u6001\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u5f02\u6784\u5927\u8bed\u8a00\u6a21\u578b\u878d\u5408\u7684\u6311\u6218\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.15722", "pdf": "https://arxiv.org/pdf/2506.15722", "abs": "https://arxiv.org/abs/2506.15722", "authors": ["Wangzhi Zhan", "Jianpeng Chen", "Dongqi Fu", "Dawei Zhou"], "title": "UniMate: A Unified Model for Mechanical Metamaterial Generation, Property Prediction, and Condition Confirmation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Metamaterials are artificial materials that are designed to meet unseen\nproperties in nature, such as ultra-stiffness and negative materials indices.\nIn mechanical metamaterial design, three key modalities are typically involved,\ni.e., 3D topology, density condition, and mechanical property. Real-world\ncomplex application scenarios place the demanding requirements on machine\nlearning models to consider all three modalities together. However, a\ncomprehensive literature review indicates that most existing works only\nconsider two modalities, e.g., predicting mechanical properties given the 3D\ntopology or generating 3D topology given the required properties. Therefore,\nthere is still a significant gap for the state-of-the-art machine learning\nmodels capturing the whole. Hence, we propose a unified model named UNIMATE,\nwhich consists of a modality alignment module and a synergetic diffusion\ngeneration module. Experiments indicate that UNIMATE outperforms the other\nbaseline models in topology generation task, property prediction task, and\ncondition confirmation task by up to 80.2%, 5.1%, and 50.2%, respectively. We\nopensource our proposed UNIMATE model and corresponding results at\nhttps://github.com/wzhan24/UniMate.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aUNIMATE\u7684\u7edf\u4e00\u6a21\u578b\uff0c\u7528\u4e8e\u540c\u65f6\u5904\u7406\u673a\u68b0\u8d85\u6750\u6599\u8bbe\u8ba1\u4e2d\u76843D\u62d3\u6251\u3001\u5bc6\u5ea6\u6761\u4ef6\u548c\u529b\u5b66\u6027\u80fd\u4e09\u79cd\u6a21\u6001\uff0c\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u4ec5\u5173\u6ce8\u4e24\u79cd\u6a21\u6001\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u5b9e\u590d\u6742\u5e94\u7528\u573a\u666f\u8981\u6c42\u673a\u5668\u5b66\u4e60\u6a21\u578b\u540c\u65f6\u8003\u86513D\u62d3\u6251\u3001\u5bc6\u5ea6\u6761\u4ef6\u548c\u529b\u5b66\u6027\u80fd\u4e09\u79cd\u6a21\u6001\uff0c\u800c\u73b0\u6709\u7814\u7a76\u5927\u591a\u4ec5\u5173\u6ce8\u5176\u4e2d\u4e24\u79cd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "UNIMATE\u6a21\u578b\u5305\u542b\u6a21\u6001\u5bf9\u9f50\u6a21\u5757\u548c\u534f\u540c\u6269\u6563\u751f\u6210\u6a21\u5757\uff0c\u80fd\u591f\u540c\u65f6\u5904\u7406\u4e09\u79cd\u6a21\u6001\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cUNIMATE\u5728\u62d3\u6251\u751f\u6210\u3001\u6027\u80fd\u9884\u6d4b\u548c\u6761\u4ef6\u786e\u8ba4\u4efb\u52a1\u4e2d\u5206\u522b\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b80.2%\u30015.1%\u548c50.2%\u3002", "conclusion": "UNIMATE\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u5e76\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5df2\u5f00\u6e90\u4f9b\u793e\u533a\u4f7f\u7528\u3002"}}
{"id": "2506.15724", "pdf": "https://arxiv.org/pdf/2506.15724", "abs": "https://arxiv.org/abs/2506.15724", "authors": ["Kunxi Li", "Zhonghua Jiang", "Zhouzhou Shen", "Zhaode Wang", "Chengfei Lv", "Shengyu Zhang", "Fan Wu", "Fei Wu"], "title": "MadaKV: Adaptive Modality-Perception KV Cache Eviction for Efficient Multimodal Long-Context Inference", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "This paper introduces MadaKV, a modality-adaptive key-value (KV) cache\neviction strategy designed to enhance the efficiency of multimodal large\nlanguage models (MLLMs) in long-context inference. In multimodal scenarios,\nattention heads exhibit varying preferences for different modalities, resulting\nin significant disparities in modality importance across attention heads.\nTraditional KV cache eviction methods, which are tailored for unimodal\nsettings, fail to capture modality-specific information, thereby yielding\nsuboptimal performance. MadaKV addresses these challenges through two key\ncomponents: modality preference adaptation and hierarchical compression\ncompensation. By dynamically sensing modality information within attention\nheads and adaptively retaining critical tokens, MadaKV achieves substantial\nreductions in KV cache memory footprint and model inference decoding latency\n(1.3 to 1.5 times improvement) while maintaining high accuracy across various\nmultimodal long-context tasks. Extensive experiments on representative MLLMs\nand the MileBench benchmark demonstrate the effectiveness of MadaKV compared to\nexisting KV cache eviction methods.", "AI": {"tldr": "MadaKV\u662f\u4e00\u79cd\u6a21\u6001\u81ea\u9002\u5e94\u7684KV\u7f13\u5b58\u6dd8\u6c70\u7b56\u7565\uff0c\u65e8\u5728\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u7684\u6548\u7387\u3002", "motivation": "\u4f20\u7edfKV\u7f13\u5b58\u6dd8\u6c70\u65b9\u6cd5\u5728\u5355\u6a21\u6001\u573a\u666f\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u6a21\u6001\u573a\u666f\u4e2d\u65e0\u6cd5\u6355\u6349\u6a21\u6001\u7279\u5b9a\u4fe1\u606f\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "MadaKV\u901a\u8fc7\u6a21\u6001\u504f\u597d\u9002\u5e94\u548c\u5206\u5c42\u538b\u7f29\u8865\u507f\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff0c\u52a8\u6001\u611f\u77e5\u6ce8\u610f\u529b\u5934\u4e2d\u7684\u6a21\u6001\u4fe1\u606f\u5e76\u81ea\u9002\u5e94\u4fdd\u7559\u5173\u952e\u4ee4\u724c\u3002", "result": "MadaKV\u663e\u8457\u51cf\u5c11\u4e86KV\u7f13\u5b58\u5185\u5b58\u5360\u7528\u548c\u6a21\u578b\u63a8\u7406\u89e3\u7801\u5ef6\u8fdf\uff08\u63d0\u53471.3\u81f31.5\u500d\uff09\uff0c\u540c\u65f6\u5728\u591a\u6a21\u6001\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "\u5b9e\u9a8c\u8bc1\u660e\uff0cMadaKV\u5728\u4ee3\u8868\u6027MLLMs\u548cMileBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709KV\u7f13\u5b58\u6dd8\u6c70\u65b9\u6cd5\u3002"}}
{"id": "2506.15725", "pdf": "https://arxiv.org/pdf/2506.15725", "abs": "https://arxiv.org/abs/2506.15725", "authors": ["Matteo Ninniri", "Marco Podda", "Davide Bacciu"], "title": "Graph Diffusion that can Insert and Delete", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Generative models of graphs based on discrete Denoising Diffusion\nProbabilistic Models (DDPMs) offer a principled approach to molecular\ngeneration by systematically removing structural noise through iterative atom\nand bond adjustments. However, existing formulations are fundamentally limited\nby their inability to adapt the graph size (that is, the number of atoms)\nduring the diffusion process, severely restricting their effectiveness in\nconditional generation scenarios such as property-driven molecular design,\nwhere the targeted property often correlates with the molecular size. In this\npaper, we reformulate the noising and denoising processes to support monotonic\ninsertion and deletion of nodes. The resulting model, which we call GrIDDD,\ndynamically grows or shrinks the chemical graph during generation. GrIDDD\nmatches or exceeds the performance of existing graph diffusion models on\nmolecular property targeting despite being trained on a more difficult problem.\nFurthermore, when applied to molecular optimization, GrIDDD exhibits\ncompetitive performance compared to specialized optimization models. This work\npaves the way for size-adaptive molecular generation with graph diffusion.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u79bb\u6563\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\uff08DDPMs\uff09\u7684\u56fe\u751f\u6210\u6a21\u578bGrIDDD\uff0c\u901a\u8fc7\u652f\u6301\u8282\u70b9\u5355\u8c03\u63d2\u5165\u548c\u5220\u9664\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u9002\u5e94\u56fe\u5927\u5c0f\u53d8\u5316\u7684\u9650\u5236\uff0c\u63d0\u5347\u4e86\u5206\u5b50\u751f\u6210\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eDDPMs\u7684\u56fe\u751f\u6210\u6a21\u578b\u65e0\u6cd5\u5728\u6269\u6563\u8fc7\u7a0b\u4e2d\u8c03\u6574\u56fe\u7684\u5927\u5c0f\uff08\u539f\u5b50\u6570\u91cf\uff09\uff0c\u9650\u5236\u4e86\u5176\u5728\u6761\u4ef6\u751f\u6210\uff08\u5982\u5c5e\u6027\u9a71\u52a8\u7684\u5206\u5b50\u8bbe\u8ba1\uff09\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u91cd\u65b0\u5b9a\u4e49\u4e86\u566a\u58f0\u548c\u53bb\u566a\u8fc7\u7a0b\uff0c\u652f\u6301\u8282\u70b9\u7684\u5355\u8c03\u63d2\u5165\u548c\u5220\u9664\uff0c\u63d0\u51fa\u4e86\u52a8\u6001\u8c03\u6574\u5316\u5b66\u56fe\u5927\u5c0f\u7684GrIDDD\u6a21\u578b\u3002", "result": "GrIDDD\u5728\u5206\u5b50\u5c5e\u6027\u5b9a\u5411\u751f\u6210\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u56fe\u6269\u6563\u6a21\u578b\uff0c\u5e76\u5728\u5206\u5b50\u4f18\u5316\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u7ade\u4e89\u529b\u3002", "conclusion": "GrIDDD\u4e3a\u5c3a\u5bf8\u81ea\u9002\u5e94\u7684\u5206\u5b50\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u63a8\u52a8\u4e86\u56fe\u6269\u6563\u6a21\u578b\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.15792", "pdf": "https://arxiv.org/pdf/2506.15792", "abs": "https://arxiv.org/abs/2506.15792", "authors": ["Jackson Burns", "Akshat Zalte", "William Green"], "title": "Descriptor-based Foundation Models for Molecular Property Prediction", "categories": ["cs.LG", "physics.chem-ph"], "comment": null, "summary": "Fast and accurate prediction of molecular properties with machine learning is\npivotal to scientific advancements across myriad domains. Foundation models in\nparticular have proven especially effective, enabling accurate training on\nsmall, real-world datasets. This study introduces CheMeleon, a novel molecular\nfoundation model pre-trained on deterministic molecular descriptors from the\nMordred package, leveraging a Directed Message-Passing Neural Network to\npredict these descriptors in a noise-free setting. Unlike conventional\napproaches relying on noisy experimental data or biased quantum mechanical\nsimulations, CheMeleon uses low-noise molecular descriptors to learn rich\nmolecular representations. Evaluated on 58 benchmark datasets from Polaris and\nMoleculeACE, CheMeleon achieves a win rate of 79% on Polaris tasks,\noutperforming baselines like Random Forest (46%), fastprop (39%), and Chemprop\n(36%), and a 97% win rate on MoleculeACE assays, surpassing Random Forest (63%)\nand other foundation models. However, it struggles to distinguish activity\ncliffs like many of the tested models. The t-SNE projection of CheMeleon's\nlearned representations demonstrates effective separation of chemical series,\nhighlighting its ability to capture structural nuances. These results\nunderscore the potential of descriptor-based pre-training for scalable and\neffective molecular property prediction, opening avenues for further\nexploration of descriptor sets and unlabeled datasets.", "AI": {"tldr": "CheMeleon\u662f\u4e00\u79cd\u57fa\u4e8e\u5206\u5b50\u63cf\u8ff0\u7b26\u9884\u8bad\u7ec3\u7684\u5206\u5b50\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u4f4e\u566a\u58f0\u6570\u636e\u5b66\u4e60\u5206\u5b50\u8868\u793a\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u533a\u5206\u6d3b\u6027\u60ac\u5d16\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\u3002", "motivation": "\u5feb\u901f\u51c6\u786e\u5730\u9884\u6d4b\u5206\u5b50\u6027\u8d28\u5bf9\u79d1\u5b66\u8fdb\u6b65\u81f3\u5173\u91cd\u8981\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u566a\u58f0\u6570\u636e\u6216\u6a21\u62df\uff0c\u800cCheMeleon\u901a\u8fc7\u4f4e\u566a\u58f0\u63cf\u8ff0\u7b26\u5b66\u4e60\u66f4\u4e30\u5bcc\u7684\u5206\u5b50\u8868\u793a\u3002", "method": "CheMeleon\u4f7f\u7528Mordred\u5305\u4e2d\u7684\u786e\u5b9a\u6027\u5206\u5b50\u63cf\u8ff0\u7b26\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u91c7\u7528\u5b9a\u5411\u6d88\u606f\u4f20\u9012\u795e\u7ecf\u7f51\u7edc\uff08D-MPNN\uff09\u9884\u6d4b\u8fd9\u4e9b\u63cf\u8ff0\u7b26\u3002", "result": "\u5728Polaris\u548cMoleculeACE\u768458\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCheMeleon\u5206\u522b\u4ee579%\u548c97%\u7684\u80dc\u7387\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u4f46\u96be\u4ee5\u533a\u5206\u6d3b\u6027\u60ac\u5d16\u3002", "conclusion": "\u57fa\u4e8e\u63cf\u8ff0\u7b26\u7684\u9884\u8bad\u7ec3\u4e3a\u5206\u5b50\u6027\u8d28\u9884\u6d4b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u63a2\u7d22\u63cf\u8ff0\u7b26\u96c6\u548c\u672a\u6807\u8bb0\u6570\u636e\u96c6\u3002"}}
{"id": "2506.15809", "pdf": "https://arxiv.org/pdf/2506.15809", "abs": "https://arxiv.org/abs/2506.15809", "authors": ["Deyi Li", "Zijun Yao", "Muxuan Liang", "Mei Liu"], "title": "DeepJ: Graph Convolutional Transformers with Differentiable Pooling for Patient Trajectory Modeling", "categories": ["cs.LG"], "comment": null, "summary": "In recent years, graph learning has gained significant interest for modeling\ncomplex interactions among medical events in structured Electronic Health\nRecord (EHR) data. However, existing graph-based approaches often work in a\nstatic manner, either restricting interactions within individual encounters or\ncollapsing all historical encounters into a single snapshot. As a result, when\nit is necessary to identify meaningful groups of medical events spanning\nlongitudinal encounters, existing methods are inadequate in modeling\ninteractions cross encounters while accounting for temporal dependencies. To\naddress this limitation, we introduce Deep Patient Journey (DeepJ), a novel\ngraph convolutional transformer model with differentiable graph pooling to\neffectively capture intra-encounter and inter-encounter medical event\ninteractions. DeepJ can identify groups of temporally and functionally related\nmedical events, offering valuable insights into key event clusters pertinent to\npatient outcome prediction. DeepJ significantly outperformed five\nstate-of-the-art baseline models while enhancing interpretability,\ndemonstrating its potential for improved patient risk stratification.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDeep Patient Journey (DeepJ)\u7684\u56fe\u5377\u79ef\u53d8\u6362\u5668\u6a21\u578b\uff0c\u7528\u4e8e\u6355\u6349\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55(EHR)\u6570\u636e\u4e2d\u8de8\u5c31\u8bca\u7684\u533b\u7597\u4e8b\u4ef6\u4ea4\u4e92\u3002", "motivation": "\u73b0\u6709\u56fe\u5b66\u4e60\u65b9\u6cd5\u5728\u5efa\u6a21\u8de8\u5c31\u8bca\u7684\u533b\u7597\u4e8b\u4ef6\u4ea4\u4e92\u65f6\u5b58\u5728\u4e0d\u8db3\uff0c\u65e0\u6cd5\u6709\u6548\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u6027\u3002", "method": "DeepJ\u7ed3\u5408\u4e86\u56fe\u5377\u79ef\u548c\u53d8\u6362\u5668\u6280\u672f\uff0c\u91c7\u7528\u53ef\u5fae\u5206\u56fe\u6c60\u5316\u65b9\u6cd5\uff0c\u540c\u65f6\u5efa\u6a21\u5c31\u8bca\u5185\u548c\u8de8\u5c31\u8bca\u7684\u533b\u7597\u4e8b\u4ef6\u4ea4\u4e92\u3002", "result": "DeepJ\u5728\u9884\u6d4b\u60a3\u8005\u7ed3\u679c\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4e94\u79cd\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "DeepJ\u4e3a\u60a3\u8005\u98ce\u9669\u5206\u5c42\u63d0\u4f9b\u4e86\u6539\u8fdb\u6f5c\u529b\uff0c\u80fd\u591f\u8bc6\u522b\u4e0e\u60a3\u8005\u7ed3\u679c\u76f8\u5173\u7684\u5173\u952e\u4e8b\u4ef6\u7fa4\u3002"}}
{"id": "2506.15817", "pdf": "https://arxiv.org/pdf/2506.15817", "abs": "https://arxiv.org/abs/2506.15817", "authors": ["Jason Tandiary"], "title": "Optimizing Bidding Strategies in First-Price Auctions in Binary Feedback Setting with Predictions", "categories": ["cs.LG"], "comment": null, "summary": "This paper studies Vickrey first-price auctions under binary feedback.\nLeveraging the enhanced performance of machine learning algorithms, the new\nalgorithm uses past information to improve the regret bounds of the BROAD-OMD\nalgorithm. Motivated by the growing relevance of first-price auctions and the\npredictive capabilities of machine learning models, this paper proposes a new\nalgorithm within the BROAD-OMD framework (Hu et al., 2025) that leverages\npredictions of the highest competing bid. This paper's main contribution is an\nalgorithm that achieves zero regret under accurate predictions. Additionally, a\nbounded regret bound of O(T^(3/4) * Vt^(1/4)) is established under certain\nnormality conditions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eBROAD-OMD\u6846\u67b6\u7684\u65b0\u7b97\u6cd5\uff0c\u5229\u7528\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u6700\u9ad8\u7ade\u4e89\u51fa\u4ef7\uff0c\u5b9e\u73b0\u4e86\u5728\u51c6\u786e\u9884\u6d4b\u4e0b\u7684\u96f6\u9057\u61be\uff0c\u5e76\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u5efa\u7acb\u4e86O(T^(3/4) * Vt^(1/4))\u7684\u6709\u754c\u9057\u61be\u754c\u3002", "motivation": "\u7814\u7a76\u4e00\u4ef7\u62cd\u5356\u5728\u4e8c\u5143\u53cd\u9988\u4e0b\u7684\u8868\u73b0\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u6539\u8fdbBROAD-OMD\u7b97\u6cd5\u7684\u9057\u61be\u754c\u3002", "method": "\u5728BROAD-OMD\u6846\u67b6\u5185\u63d0\u51fa\u65b0\u7b97\u6cd5\uff0c\u5229\u7528\u5386\u53f2\u4fe1\u606f\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u6700\u9ad8\u7ade\u4e89\u51fa\u4ef7\u3002", "result": "\u7b97\u6cd5\u5728\u51c6\u786e\u9884\u6d4b\u4e0b\u5b9e\u73b0\u96f6\u9057\u61be\uff0c\u5e76\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u83b7\u5f97O(T^(3/4) * Vt^(1/4))\u7684\u6709\u754c\u9057\u61be\u754c\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u4e00\u4ef7\u62cd\u5356\u4e2d\u7684\u8868\u73b0\uff0c\u5c55\u793a\u4e86\u673a\u5668\u5b66\u4e60\u5728\u62cd\u5356\u7406\u8bba\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.15823", "pdf": "https://arxiv.org/pdf/2506.15823", "abs": "https://arxiv.org/abs/2506.15823", "authors": ["Chiara Razzetta", "Shahryar Noei", "Federico Barbarossa", "Edoardo Spairani", "Monica Roascio", "Elisa Barbi", "Giulia Ciacci", "Sara Sommariva", "Sabrina Guastavino", "Michele Piana", "Matteo Lenge", "Gabriele Arnulfo", "Giovanni Magenes", "Elvira Maranesi", "Giulio Amabili", "Anna Maria Massone", "Federico Benvenuto", "Giuseppe Jurman", "Diego Sona", "Cristina Campi"], "title": "AI-based modular warning machine for risk identification in proximity healthcare", "categories": ["cs.LG", "68T01, 68T05"], "comment": null, "summary": "\"DHEAL-COM - Digital Health Solutions in Community Medicine\" is a research\nand technology project funded by the Italian Department of Health for the\ndevelopment of digital solutions of interest in proximity healthcare. The\nactivity within the DHEAL-COM framework allows scientists to gather a notable\namount of multi-modal data whose interpretation can be performed by means of\nmachine learning algorithms. The present study illustrates a general automated\npipeline made of numerous unsupervised and supervised methods that can ingest\nsuch data, provide predictive results, and facilitate model interpretations via\nfeature identification.", "AI": {"tldr": "DHEAL-COM\u9879\u76ee\u5f00\u53d1\u4e86\u6570\u5b57\u5065\u5eb7\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u5206\u6790\u591a\u6a21\u6001\u6570\u636e\uff0c\u63d0\u4f9b\u9884\u6d4b\u7ed3\u679c\u548c\u7279\u5f81\u89e3\u91ca\u3002", "motivation": "\u4e3a\u793e\u533a\u533b\u7597\u5f00\u53d1\u6570\u5b57\u5065\u5eb7\u89e3\u51b3\u65b9\u6848\uff0c\u5229\u7528\u591a\u6a21\u6001\u6570\u636e\u63d0\u5347\u533b\u7597\u670d\u52a1\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u65e0\u76d1\u7763\u548c\u6709\u76d1\u7763\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6784\u5efa\u81ea\u52a8\u5316\u6d41\u7a0b\uff0c\u5904\u7406\u6570\u636e\u5e76\u63d0\u4f9b\u9884\u6d4b\u548c\u7279\u5f81\u8bc6\u522b\u3002", "result": "\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u591a\u6a21\u6001\u6570\u636e\u5e76\u63d0\u4f9b\u9884\u6d4b\u7ed3\u679c\u7684\u81ea\u52a8\u5316\u6d41\u7a0b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u793e\u533a\u533b\u7597\u7684\u6570\u5b57\u5065\u5eb7\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6280\u672f\u6846\u67b6\u3002"}}
{"id": "2506.15825", "pdf": "https://arxiv.org/pdf/2506.15825", "abs": "https://arxiv.org/abs/2506.15825", "authors": ["Luiz Pereira", "M. Hadi Amini"], "title": "Heterogeneous Federated Reinforcement Learning Using Wasserstein Barycenters", "categories": ["cs.LG"], "comment": null, "summary": "In this paper, we first propose a novel algorithm for model fusion that\nleverages Wasserstein barycenters in training a global Deep Neural Network\n(DNN) in a distributed architecture. To this end, we divide the dataset into\nequal parts that are fed to \"agents\" who have identical deep neural networks\nand train only over the dataset fed to them (known as the local dataset). After\nsome training iterations, we perform an aggregation step where we combine the\nweight parameters of all neural networks using Wasserstein barycenters. These\nsteps form the proposed algorithm referred to as FedWB. Moreover, we leverage\nthe processes created in the first part of the paper to develop an algorithm to\ntackle Heterogeneous Federated Reinforcement Learning (HFRL). Our test\nexperiment is the CartPole toy problem, where we vary the lengths of the poles\nto create heterogeneous environments. We train a deep Q-Network (DQN) in each\nenvironment to learn to control each cart, while occasionally performing a\nglobal aggregation step to generalize the local models; the end outcome is a\nglobal DQN that functions across all environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eWasserstein\u91cd\u5fc3\u7684\u65b0\u7b97\u6cd5FedWB\uff0c\u7528\u4e8e\u5206\u5e03\u5f0f\u67b6\u6784\u4e2d\u7684\u5168\u5c40DNN\u8bad\u7ec3\uff0c\u5e76\u6269\u5c55\u5e94\u7528\u4e8e\u5f02\u6784\u8054\u90a6\u5f3a\u5316\u5b66\u4e60\uff08HFRL\uff09\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u6a21\u578b\u878d\u5408\u7684\u6311\u6218\uff0c\u5e76\u63a8\u5e7f\u5230\u5f02\u6784\u8054\u90a6\u5f3a\u5316\u5b66\u4e60\u573a\u666f\u3002", "method": "\u5c06\u6570\u636e\u96c6\u5206\u53d1\u7ed9\u591a\u4e2a\u4ee3\u7406\u8bad\u7ec3\u672c\u5730DNN\uff0c\u901a\u8fc7Wasserstein\u91cd\u5fc3\u805a\u5408\u6743\u91cd\u53c2\u6570\uff0c\u5f62\u6210FedWB\u7b97\u6cd5\uff1b\u8fdb\u4e00\u6b65\u5e94\u7528\u4e8eHFRL\uff0c\u901a\u8fc7\u5168\u5c40\u805a\u5408\u6b65\u9aa4\u751f\u6210\u901a\u7528\u6a21\u578b\u3002", "result": "\u5728CartPole\u95ee\u9898\u4e2d\u9a8c\u8bc1\u4e86FedWB\u548cHFRL\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u751f\u6210\u4e86\u9002\u7528\u4e8e\u5f02\u6784\u73af\u5883\u7684\u5168\u5c40DQN\u3002", "conclusion": "FedWB\u7b97\u6cd5\u5728\u5206\u5e03\u5f0f\u8bad\u7ec3\u548c\u5f02\u6784\u8054\u90a6\u5f3a\u5316\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.15840", "pdf": "https://arxiv.org/pdf/2506.15840", "abs": "https://arxiv.org/abs/2506.15840", "authors": ["Kevin Yin", "Julia Gersey", "Pei Zhang"], "title": "In-field Calibration of Low-Cost Sensors through XGBoost $\\&$ Aggregate Sensor Data", "categories": ["cs.LG"], "comment": "6 pages including citations", "summary": "Effective large-scale air quality monitoring necessitates distributed sensing\ndue to the pervasive and harmful nature of particulate matter (PM),\nparticularly in urban environments. However, precision comes at a cost: highly\naccurate sensors are expensive, limiting the spatial deployments and thus their\ncoverage. As a result, low-cost sensors have become popular, though they are\nprone to drift caused by environmental sensitivity and manufacturing\nvariability. This paper presents a model for in-field sensor calibration using\nXGBoost ensemble learning to consolidate data from neighboring sensors. This\napproach reduces dependence on the presumed accuracy of individual sensors and\nimproves generalization across different locations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eXGBoost\u96c6\u6210\u5b66\u4e60\u7684\u73b0\u573a\u4f20\u611f\u5668\u6821\u51c6\u6a21\u578b\uff0c\u7528\u4e8e\u6539\u5584\u4f4e\u6210\u672c\u4f20\u611f\u5668\u7684\u7cbe\u5ea6\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u7531\u4e8e\u9ad8\u7cbe\u5ea6\u4f20\u611f\u5668\u6210\u672c\u9ad8\uff0c\u9650\u5236\u4e86\u5176\u90e8\u7f72\u8303\u56f4\uff0c\u800c\u4f4e\u6210\u672c\u4f20\u611f\u5668\u6613\u53d7\u73af\u5883\u56e0\u7d20\u548c\u5236\u9020\u5dee\u5f02\u5f71\u54cd\uff0c\u5bfc\u81f4\u6570\u636e\u6f02\u79fb\u3002", "method": "\u91c7\u7528XGBoost\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\uff0c\u6574\u5408\u90bb\u8fd1\u4f20\u611f\u5668\u7684\u6570\u636e\uff0c\u51cf\u5c11\u5bf9\u5355\u4e2a\u4f20\u611f\u5668\u7cbe\u5ea6\u7684\u4f9d\u8d56\u3002", "result": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u4f20\u611f\u5668\u7684\u6821\u51c6\u7cbe\u5ea6\uff0c\u5e76\u5728\u4e0d\u540c\u5730\u70b9\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u5927\u89c4\u6a21\u7a7a\u6c14\u8d28\u91cf\u76d1\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u9ad8\u7cbe\u5ea6\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.15850", "pdf": "https://arxiv.org/pdf/2506.15850", "abs": "https://arxiv.org/abs/2506.15850", "authors": ["Pedro Mendes", "Paolo Romano", "David Garlan"], "title": "Uncertainty Estimation by Human Perception versus Neural Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Modern neural networks (NNs) often achieve high predictive accuracy but\nremain poorly calibrated, producing overconfident predictions even when wrong.\nThis miscalibration poses serious challenges in applications where reliable\nuncertainty estimates are critical. In this work, we investigate how human\nperceptual uncertainty compares to uncertainty estimated by NNs. Using three\nvision benchmarks annotated with both human disagreement and crowdsourced\nconfidence, we assess the correlation between model-predicted uncertainty and\nhuman-perceived uncertainty. Our results show that current methods only weakly\nalign with human intuition, with correlations varying significantly across\ntasks and uncertainty metrics. Notably, we find that incorporating\nhuman-derived soft labels into the training process can improve calibration\nwithout compromising accuracy. These findings reveal a persistent gap between\nmodel and human uncertainty and highlight the potential of leveraging human\ninsights to guide the development of more trustworthy AI systems.", "AI": {"tldr": "\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u51c6\u786e\u6027\u9ad8\u4f46\u6821\u51c6\u6027\u5dee\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u81ea\u4fe1\u7684\u9884\u6d4b\u3002\u7814\u7a76\u6bd4\u8f83\u4e86\u4eba\u7c7b\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u4e0e\u795e\u7ecf\u7f51\u7edc\u4f30\u8ba1\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u53d1\u73b0\u5f53\u524d\u65b9\u6cd5\u4e0e\u4eba\u7c7b\u76f4\u89c9\u4ec5\u5f31\u76f8\u5173\u3002\u5f15\u5165\u4eba\u7c7b\u8f6f\u6807\u7b7e\u53ef\u6539\u5584\u6821\u51c6\u6027\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u7684\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u5e38\u4f34\u968f\u6821\u51c6\u6027\u5dee\u7684\u95ee\u9898\uff0c\u8fd9\u5728\u9700\u8981\u53ef\u9760\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u5e94\u7528\u4e2d\u5e26\u6765\u6311\u6218\u3002\u7814\u7a76\u65e8\u5728\u6bd4\u8f83\u4eba\u7c7b\u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u4ee5\u6539\u5584\u6a21\u578b\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u4f7f\u7528\u4e09\u4e2a\u89c6\u89c9\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6807\u6ce8\u4e86\u4eba\u7c7b\u5206\u6b67\u548c\u4f17\u5305\u7f6e\u4fe1\u5ea6\uff0c\u8bc4\u4f30\u6a21\u578b\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u4e0e\u4eba\u7c7b\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u76f8\u5173\u6027\u3002", "result": "\u5f53\u524d\u65b9\u6cd5\u4e0e\u4eba\u7c7b\u76f4\u89c9\u4ec5\u5f31\u76f8\u5173\uff0c\u4e14\u76f8\u5173\u6027\u56e0\u4efb\u52a1\u548c\u4e0d\u786e\u5b9a\u6027\u6307\u6807\u800c\u5f02\u3002\u5f15\u5165\u4eba\u7c7b\u8f6f\u6807\u7b7e\u53ef\u6539\u5584\u6821\u51c6\u6027\u4e14\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u3002", "conclusion": "\u6a21\u578b\u4e0e\u4eba\u7c7b\u4e0d\u786e\u5b9a\u6027\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u5229\u7528\u4eba\u7c7b\u53cd\u9988\u53ef\u6307\u5bfc\u5f00\u53d1\u66f4\u53ef\u4fe1\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2506.15864", "pdf": "https://arxiv.org/pdf/2506.15864", "abs": "https://arxiv.org/abs/2506.15864", "authors": ["Xixi Hu", "Runlong Liao", "Keyang Xu", "Bo Liu", "Yeqing Li", "Eugene Ie", "Hongliang Fei", "Qiang Liu"], "title": "Improving Rectified Flow with Boundary Conditions", "categories": ["cs.LG"], "comment": "14 pages", "summary": "Rectified Flow offers a simple and effective approach to high-quality\ngenerative modeling by learning a velocity field. However, we identify a\nlimitation in directly modeling the velocity with an unconstrained neural\nnetwork: the learned velocity often fails to satisfy certain boundary\nconditions, leading to inaccurate velocity field estimations that deviate from\nthe desired ODE. This issue is particularly critical during stochastic sampling\nat inference, as the score function's errors are amplified near the boundary.\nTo mitigate this, we propose a Boundary-enforced Rectified Flow Model (Boundary\nRF Model), in which we enforce boundary conditions with a minimal code\nmodification. Boundary RF Model improves performance over vanilla RF model,\ndemonstrating 8.01% improvement in FID score on ImageNet using ODE sampling and\n8.98% improvement using SDE sampling.", "AI": {"tldr": "Boundary-enforced Rectified Flow Model (Boundary RF Model)\u901a\u8fc7\u5f3a\u5236\u8fb9\u754c\u6761\u4ef6\u6539\u8fdb\u4e86\u539f\u59cbRectified Flow\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u539f\u59cbRectified Flow\u6a21\u578b\u76f4\u63a5\u5efa\u6a21\u901f\u5ea6\u573a\u65f6\uff0c\u672a\u7ea6\u675f\u7684\u795e\u7ecf\u7f51\u7edc\u53ef\u80fd\u5bfc\u81f4\u8fb9\u754c\u6761\u4ef6\u4e0d\u6ee1\u8db3\uff0c\u5f71\u54cdODE\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u5728\u968f\u673a\u91c7\u6837\u65f6\u8bef\u5dee\u653e\u5927\u3002", "method": "\u63d0\u51faBoundary RF Model\uff0c\u901a\u8fc7\u6700\u5c0f\u4ee3\u7801\u4fee\u6539\u5f3a\u5236\u8fb9\u754c\u6761\u4ef6\u3002", "result": "\u5728ImageNet\u4e0a\uff0cODE\u91c7\u6837FID\u5f97\u5206\u63d0\u53478.01%\uff0cSDE\u91c7\u6837\u63d0\u53478.98%\u3002", "conclusion": "Boundary RF Model\u901a\u8fc7\u7b80\u5355\u4fee\u6539\u6709\u6548\u89e3\u51b3\u4e86\u8fb9\u754c\u6761\u4ef6\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.15872", "pdf": "https://arxiv.org/pdf/2506.15872", "abs": "https://arxiv.org/abs/2506.15872", "authors": ["Sara Kangaslahti", "Elan Rosenfeld", "Naomi Saphra"], "title": "Hidden Breakthroughs in Language Model Training", "categories": ["cs.LG"], "comment": "17 pages, 10 figures", "summary": "Loss curves are smooth during most of model training, so visible\ndiscontinuities stand out as possible conceptual breakthroughs. Studying these\nbreakthroughs enables a deeper understanding of learning dynamics, but only\nwhen they are properly identified. This paper argues that similar breakthroughs\noccur frequently throughout training but they are obscured by a loss metric\nthat collapses all variation into a single scalar. To find these hidden\ntransitions, we introduce POLCA, a method for decomposing changes in loss along\narbitrary bases of the low-rank training subspace. We use our method to\nidentify clusters of samples that share similar changes in loss during\ntraining, disaggregating the overall loss into that of smaller groups of\nconceptually similar data. We validate our method on synthetic arithmetic and\nnatural language tasks, showing that POLCA recovers clusters that represent\ninterpretable breakthroughs in the model's capabilities. We demonstrate the\npromise of these hidden phase transitions as a tool for unsupervised\ninterpretability.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPOLCA\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u89e3\u635f\u5931\u53d8\u5316\u63ed\u793a\u8bad\u7ec3\u4e2d\u7684\u9690\u85cf\u7a81\u7834\uff0c\u7528\u4e8e\u65e0\u76d1\u7763\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u7814\u7a76\u8bad\u7ec3\u4e2d\u635f\u5931\u66f2\u7ebf\u7684\u95f4\u65ad\u70b9\u4ee5\u7406\u89e3\u5b66\u4e60\u52a8\u6001\uff0c\u4f46\u4f20\u7edf\u6807\u91cf\u635f\u5931\u6307\u6807\u63a9\u76d6\u4e86\u8fd9\u4e9b\u7a81\u7834\u3002", "method": "\u5f15\u5165POLCA\u65b9\u6cd5\uff0c\u5206\u89e3\u4f4e\u79e9\u8bad\u7ec3\u5b50\u7a7a\u95f4\u4e2d\u635f\u5931\u7684\u53d8\u5316\uff0c\u8bc6\u522b\u6837\u672c\u805a\u7c7b\u3002", "result": "\u5728\u5408\u6210\u7b97\u672f\u548c\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u4e2d\u9a8c\u8bc1\uff0cPOLCA\u80fd\u53d1\u73b0\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u80fd\u529b\u7a81\u7834\u3002", "conclusion": "\u9690\u85cf\u7684\u76f8\u53d8\u53ef\u4f5c\u4e3a\u65e0\u76d1\u7763\u53ef\u89e3\u91ca\u6027\u5de5\u5177\uff0c\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2506.15879", "pdf": "https://arxiv.org/pdf/2506.15879", "abs": "https://arxiv.org/abs/2506.15879", "authors": ["Abdel Rahman Alsheyab", "Mohammad Alkhasawneh", "Nidal Shahin"], "title": "Job Market Cheat Codes: Prototyping Salary Prediction and Job Grouping with Synthetic Job Listings", "categories": ["cs.LG"], "comment": "8 pages, 5 figures, synthetic data only, experimental work", "summary": "This paper presents a machine learning methodology prototype using a large\nsynthetic dataset of job listings to identify trends, predict salaries, and\ngroup similar job roles. Employing techniques such as regression,\nclassification, clustering, and natural language processing (NLP) for\ntext-based feature extraction and representation, this study aims to uncover\nthe key features influencing job market dynamics and provide valuable insights\nfor job seekers, employers, and researchers. Exploratory data analysis was\nconducted to understand the dataset's characteristics. Subsequently, regression\nmodels were developed to predict salaries, classification models to predict job\ntitles, and clustering techniques were applied to group similar jobs. The\nanalyses revealed significant factors influencing salary and job roles, and\nidentified distinct job clusters based on the provided data. While the results\nare based on synthetic data and not intended for real-world deployment, the\nmethodology demonstrates a transferable framework for job market analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5408\u6210\u6570\u636e\u96c6\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u6790\u804c\u4f4d\u5e02\u573a\u8d8b\u52bf\u3001\u9884\u6d4b\u85aa\u8d44\u5e76\u805a\u7c7b\u76f8\u4f3c\u804c\u4f4d\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63ed\u793a\u5f71\u54cd\u804c\u4f4d\u5e02\u573a\u52a8\u6001\u7684\u5173\u952e\u7279\u5f81\uff0c\u4e3a\u6c42\u804c\u8005\u3001\u96c7\u4e3b\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002", "method": "\u91c7\u7528\u56de\u5f52\u3001\u5206\u7c7b\u3001\u805a\u7c7b\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u6280\u672f\uff0c\u5bf9\u5408\u6210\u6570\u636e\u96c6\u8fdb\u884c\u63a2\u7d22\u6027\u5206\u6790\uff0c\u5e76\u6784\u5efa\u9884\u6d4b\u6a21\u578b\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u5f71\u54cd\u85aa\u8d44\u548c\u804c\u4f4d\u7c7b\u522b\u7684\u663e\u8457\u56e0\u7d20\uff0c\u5e76\u8bc6\u522b\u51fa\u57fa\u4e8e\u6570\u636e\u7684\u804c\u4f4d\u805a\u7c7b\u3002", "conclusion": "\u867d\u7136\u7ed3\u679c\u57fa\u4e8e\u5408\u6210\u6570\u636e\uff0c\u4f46\u8be5\u65b9\u6cd5\u4e3a\u804c\u4f4d\u5e02\u573a\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u8f6c\u79fb\u7684\u6846\u67b6\u3002"}}
{"id": "2506.15881", "pdf": "https://arxiv.org/pdf/2506.15881", "abs": "https://arxiv.org/abs/2506.15881", "authors": ["Alexey Yermakov", "David Zoro", "Mars Liyao Gao", "J. Nathan Kutz"], "title": "T-SHRED: Symbolic Regression for Regularization and Model Discovery with Transformer Shallow Recurrent Decoders", "categories": ["cs.LG"], "comment": "16 pages, 5 figures, submitted to Transactions of the Royal Society\n  (Symbolic Regression in the Physical Sciences)", "summary": "SHallow REcurrent Decoders (SHRED) are effective for system identification\nand forecasting from sparse sensor measurements. Such models are light-weight\nand computationally efficient, allowing them to be trained on consumer laptops.\nSHRED-based models rely on Recurrent Neural Networks (RNNs) and a simple\nMulti-Layer Perceptron (MLP) for the temporal encoding and spatial decoding\nrespectively. Despite the relatively simple structure of SHRED, they are able\nto predict chaotic dynamical systems on different physical, spatial, and\ntemporal scales directly from a sparse set of sensor measurements. In this\nwork, we improve SHRED by leveraging transformers (T-SHRED) for the temporal\nencoding which improves performance on next-step state prediction on large\ndatasets. We also introduce a sparse identification of nonlinear dynamics\n(SINDy) attention mechanism into T-SHRED to perform symbolic regression\ndirectly on the latent space as part of the model regularization architecture.\nSymbolic regression improves model interpretability by learning and\nregularizing the dynamics of the latent space during training. We analyze the\nperformance of T-SHRED on three different dynamical systems ranging from\nlow-data to high-data regimes. We observe that SINDy attention T-SHRED\naccurately predicts future frames based on an interpretable symbolic model\nacross all tested datasets.", "AI": {"tldr": "SHRED\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6a21\u578b\uff0c\u7528\u4e8e\u7a00\u758f\u4f20\u611f\u5668\u6570\u636e\u7684\u7cfb\u7edf\u8bc6\u522b\u548c\u9884\u6d4b\u3002\u6539\u8fdb\u7248T-SHRED\u5f15\u5165Transformer\u548cSINDy\u6ce8\u610f\u529b\u673a\u5236\uff0c\u63d0\u5347\u6027\u80fd\u5e76\u589e\u5f3a\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6539\u8fdbSHRED\u6a21\u578b\uff0c\u901a\u8fc7Transformer\u63d0\u5347\u65f6\u95f4\u7f16\u7801\u6027\u80fd\uff0c\u5e76\u5f15\u5165SINDy\u6ce8\u610f\u529b\u673a\u5236\u589e\u5f3a\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u4f7f\u7528Transformer\u66ff\u4ee3RNN\u8fdb\u884c\u65f6\u95f4\u7f16\u7801\uff0c\u5e76\u5f15\u5165SINDy\u6ce8\u610f\u529b\u673a\u5236\u8fdb\u884c\u7b26\u53f7\u56de\u5f52\u3002", "result": "T-SHRED\u5728\u591a\u79cd\u52a8\u6001\u7cfb\u7edf\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u5728\u7a00\u758f\u6570\u636e\u548c\u9ad8\u6570\u636e\u91cf\u60c5\u51b5\u4e0b\u5747\u80fd\u51c6\u786e\u9884\u6d4b\u3002", "conclusion": "T-SHRED\u7ed3\u5408Transformer\u548cSINDy\u6ce8\u610f\u529b\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\u548c\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.15882", "pdf": "https://arxiv.org/pdf/2506.15882", "abs": "https://arxiv.org/abs/2506.15882", "authors": ["Sheng Liu", "Tianlang Chen", "Pan Lu", "Haotian Ye", "Yizheng Chen", "Lei Xing", "James Zou"], "title": "Fractional Reasoning via Latent Steering Vectors Improves Inference Time Compute", "categories": ["cs.LG", "cs.AI", "cs.CL", "eess.SP"], "comment": "18 pages, 5 figures, Project website:\n  https://shengliu66.github.io/fractreason/", "summary": "Test-time compute has emerged as a powerful paradigm for improving the\nperformance of large language models (LLMs), where generating multiple outputs\nor refining individual chains can significantly boost answer accuracy. However,\nexisting methods like Best-of-N, majority voting, and self-reflection typically\napply reasoning in a uniform way across inputs, overlooking the fact that\ndifferent problems may require different levels of reasoning depth. In this\nwork, we propose Fractional Reasoning, a training-free and model-agnostic\nframework that enables continuous control over reasoning intensity at inference\ntime, going beyond the limitations of fixed instructional prompts. Our method\noperates by extracting the latent steering vector associated with deeper\nreasoning and reapplying it with a tunable scaling factor, allowing the model\nto tailor its reasoning process to the complexity of each input. This supports\ntwo key modes of test-time scaling: (1) improving output quality in\nbreadth-based strategies (e.g., Best-of-N, majority voting), and (2) enhancing\nthe correctness of individual reasoning chains in depth-based strategies (e.g.,\nself-reflection). Experiments on GSM8K, MATH500, and GPQA demonstrate that\nFractional Reasoning consistently improves performance across diverse reasoning\ntasks and models.", "AI": {"tldr": "Fractional Reasoning\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u63a8\u7406\u5f3a\u5ea6\u63d0\u5347LLM\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\uff08\u5982Best-of-N\u3001\u591a\u6570\u6295\u7968\uff09\u5bf9\u6240\u6709\u8f93\u5165\u91c7\u7528\u7edf\u4e00\u63a8\u7406\u5f3a\u5ea6\uff0c\u5ffd\u7565\u4e86\u95ee\u9898\u590d\u6742\u5ea6\u7684\u5dee\u5f02\u3002", "method": "\u63d0\u53d6\u4e0e\u6df1\u5ea6\u63a8\u7406\u76f8\u5173\u7684\u6f5c\u5728\u5bfc\u5411\u5411\u91cf\uff0c\u5e76\u901a\u8fc7\u53ef\u8c03\u7f29\u653e\u56e0\u5b50\u52a8\u6001\u8c03\u6574\u63a8\u7406\u5f3a\u5ea6\u3002", "result": "\u5728GSM8K\u3001MATH500\u548cGPQA\u7b49\u4efb\u52a1\u4e0a\uff0cFractional Reasoning\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "Fractional Reasoning\u4e3aLLM\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u63a8\u7406\u63a7\u5236\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u4efb\u52a1\u3002"}}
{"id": "2506.15893", "pdf": "https://arxiv.org/pdf/2506.15893", "abs": "https://arxiv.org/abs/2506.15893", "authors": ["Farnam Mansouri", "Hans U. Simon", "Adish Singla", "Yuxin Chen", "Sandra Zilles"], "title": "Formal Models of Active Learning from Contrastive Examples", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning can greatly benefit from providing learning algorithms with\npairs of contrastive training examples -- typically pairs of instances that\ndiffer only slightly, yet have different class labels. Intuitively, the\ndifference in the instances helps explain the difference in the class labels.\nThis paper proposes a theoretical framework in which the effect of various\ntypes of contrastive examples on active learners is studied formally. The focus\nis on the sample complexity of learning concept classes and how it is\ninfluenced by the choice of contrastive examples. We illustrate our results\nwith geometric concept classes and classes of Boolean functions. Interestingly,\nwe reveal a connection between learning from contrastive examples and the\nclassical model of self-directed learning.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5bf9\u6bd4\u8bad\u7ec3\u6837\u672c\u5bf9\u673a\u5668\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u7406\u8bba\u6846\u67b6\u5206\u6790\u5176\u5bf9\u4e3b\u52a8\u5b66\u4e60\u6837\u672c\u590d\u6742\u5ea6\u7684\u4f5c\u7528\uff0c\u5e76\u63ed\u793a\u4e86\u4e0e\u81ea\u6307\u5bfc\u5b66\u4e60\u7684\u8054\u7cfb\u3002", "motivation": "\u901a\u8fc7\u5bf9\u6bd4\u6837\u672c\u7684\u5fae\u5c0f\u5dee\u5f02\u89e3\u91ca\u6807\u7b7e\u5dee\u5f02\uff0c\u63d0\u5347\u5b66\u4e60\u6548\u679c\u3002", "method": "\u63d0\u51fa\u7406\u8bba\u6846\u67b6\uff0c\u5206\u6790\u5bf9\u6bd4\u6837\u672c\u5bf9\u4e3b\u52a8\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u4ee5\u51e0\u4f55\u6982\u5ff5\u7c7b\u548c\u5e03\u5c14\u51fd\u6570\u7c7b\u4e3a\u4f8b\u3002", "result": "\u63ed\u793a\u4e86\u5bf9\u6bd4\u6837\u672c\u5b66\u4e60\u4e0e\u81ea\u6307\u5bfc\u5b66\u4e60\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "conclusion": "\u5bf9\u6bd4\u6837\u672c\u80fd\u6709\u6548\u964d\u4f4e\u5b66\u4e60\u590d\u6742\u5ea6\uff0c\u5e76\u4e0e\u4f20\u7edf\u5b66\u4e60\u6a21\u578b\u6709\u6df1\u523b\u8054\u7cfb\u3002"}}
{"id": "2506.15896", "pdf": "https://arxiv.org/pdf/2506.15896", "abs": "https://arxiv.org/abs/2506.15896", "authors": ["Yu Zhang", "Gaoshan Bi", "Simon Jeffery", "Max Davis", "Yang Li", "Qing Xue", "Po Yang"], "title": "KG-FGNN: Knowledge-guided GNN Foundation Model for Fertilisation-oriented Soil GHG Flux Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 4 figures", "summary": "Precision soil greenhouse gas (GHG) flux prediction is essential in\nagricultural systems for assessing environmental impacts, developing emission\nmitigation strategies and promoting sustainable agriculture. Due to the lack of\nadvanced sensor and network technologies on majority of farms, there are\nchallenges in obtaining comprehensive and diverse agricultural data. As a\nresult, the scarcity of agricultural data seriously obstructs the application\nof machine learning approaches in precision soil GHG flux prediction. This\nresearch proposes a knowledge-guided graph neural network framework that\naddresses the above challenges by integrating knowledge embedded in an\nagricultural process-based model and graph neural network techniques.\nSpecifically, we utilise the agricultural process-based model to simulate and\ngenerate multi-dimensional agricultural datasets for 47 countries that cover a\nwide range of agricultural variables. To extract key agricultural features and\nintegrate correlations among agricultural features in the prediction process,\nwe propose a machine learning framework that integrates the autoencoder and\nmulti-target multi-graph based graph neural networks, which utilises the\nautoencoder to selectively extract significant agricultural features from the\nagricultural process-based model simulation data and the graph neural network\nto integrate correlations among agricultural features for accurately predict\nfertilisation-oriented soil GHG fluxes. Comprehensive experiments were\nconducted with both the agricultural simulation dataset and real-world\nagricultural dataset to evaluate the proposed approach in comparison with\nwell-known baseline and state-of-the-art regression methods. The results\ndemonstrate that our proposed approach provides superior accuracy and stability\nin fertilisation-oriented soil GHG prediction.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u77e5\u8bc6\u5f15\u5bfc\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u7528\u4e8e\u7cbe\u51c6\u9884\u6d4b\u571f\u58e4\u6e29\u5ba4\u6c14\u4f53\u901a\u91cf\uff0c\u89e3\u51b3\u4e86\u519c\u4e1a\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002", "motivation": "\u519c\u4e1a\u7cfb\u7edf\u4e2d\u7cbe\u51c6\u9884\u6d4b\u571f\u58e4\u6e29\u5ba4\u6c14\u4f53\u901a\u91cf\u5bf9\u8bc4\u4f30\u73af\u5883\u5f71\u54cd\u548c\u53ef\u6301\u7eed\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6570\u636e\u7a00\u7f3a\u9650\u5236\u4e86\u673a\u5668\u5b66\u4e60\u7684\u5e94\u7528\u3002", "method": "\u7ed3\u5408\u519c\u4e1a\u8fc7\u7a0b\u6a21\u578b\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u5229\u7528\u81ea\u7f16\u7801\u5668\u63d0\u53d6\u5173\u952e\u7279\u5f81\uff0c\u56fe\u795e\u7ecf\u7f51\u7edc\u6574\u5408\u7279\u5f81\u76f8\u5173\u6027\uff0c\u9884\u6d4b\u65bd\u80a5\u5bfc\u5411\u7684\u571f\u58e4\u6e29\u5ba4\u6c14\u4f53\u901a\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u548c\u5176\u4ed6\u56de\u5f52\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u7cbe\u51c6\u519c\u4e1a\u4e2d\u7684\u6e29\u5ba4\u6c14\u4f53\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.15898", "pdf": "https://arxiv.org/pdf/2506.15898", "abs": "https://arxiv.org/abs/2506.15898", "authors": ["Xiao Zhang", "Xingyu Zhao", "Hong Xia", "Yuan Cao", "Guiyuan Jiang", "Junyu Dong", "Yanwei Yu"], "title": "TrajDiff: Diffusion Bridge Network with Semantic Alignment for Trajectory Similarity Computation", "categories": ["cs.LG"], "comment": null, "summary": "With the proliferation of location-tracking technologies, massive volumes of\ntrajectory data are continuously being collected. As a fundamental task in\ntrajectory data mining, trajectory similarity computation plays a critical role\nin a wide range of real-world applications. However, existing learning-based\nmethods face three challenges: First, they ignore the semantic gap between GPS\nand grid features in trajectories, making it difficult to obtain meaningful\ntrajectory embeddings. Second, the noise inherent in the trajectories, as well\nas the noise introduced during grid discretization, obscures the true motion\npatterns of the trajectories. Third, existing methods focus solely on\npoint-wise and pair-wise losses, without utilizing the global ranking\ninformation obtained by sorting all trajectories according to their similarity\nto a given trajectory. To address the aforementioned challenges, we propose a\nnovel trajectory similarity computation framework, named TrajDiff.\nSpecifically, the semantic alignment module relies on cross-attention and an\nattention score mask mechanism with adaptive fusion, effectively eliminating\nsemantic discrepancies between data at two scales and generating a unified\nrepresentation. Additionally, the DDBM-based Noise-robust Pre-Training\nintroduces the transfer patterns between any two trajectories into the model\ntraining process, enhancing the model's noise robustness. Finally, the overall\nranking-aware regularization shifts the model's focus from a local to a global\nperspective, enabling it to capture the holistic ordering information among\ntrajectories. Extensive experiments on three publicly available datasets show\nthat TrajDiff consistently outperforms state-of-the-art baselines. In\nparticular, it achieves an average HR@1 gain of 33.38% across all three\nevaluation metrics and datasets.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTrajDiff\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u8f68\u8ff9\u76f8\u4f3c\u6027\u8ba1\u7b97\u4e2d\u7684\u8bed\u4e49\u5dee\u8ddd\u3001\u566a\u58f0\u95ee\u9898\u548c\u5168\u5c40\u6392\u5e8f\u4fe1\u606f\u5229\u7528\u4e0d\u8db3\u7684\u6311\u6218\u3002", "motivation": "\u968f\u7740\u4f4d\u7f6e\u8ddf\u8e2a\u6280\u672f\u7684\u666e\u53ca\uff0c\u8f68\u8ff9\u6570\u636e\u91cf\u6fc0\u589e\uff0c\u4f46\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\u5728\u8bed\u4e49\u5bf9\u9f50\u3001\u566a\u58f0\u9c81\u68d2\u6027\u548c\u5168\u5c40\u6392\u5e8f\u4fe1\u606f\u5229\u7528\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "TrajDiff\u6846\u67b6\u5305\u542b\u8bed\u4e49\u5bf9\u9f50\u6a21\u5757\u3001\u57fa\u4e8eDDBM\u7684\u566a\u58f0\u9c81\u68d2\u9884\u8bad\u7ec3\u548c\u5168\u5c40\u6392\u5e8f\u611f\u77e5\u6b63\u5219\u5316\uff0c\u5206\u522b\u89e3\u51b3\u8bed\u4e49\u5dee\u8ddd\u3001\u566a\u58f0\u95ee\u9898\u548c\u5168\u5c40\u4fe1\u606f\u5229\u7528\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0cTrajDiff\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e73\u5747HR@1\u63d0\u534733.38%\u3002", "conclusion": "TrajDiff\u901a\u8fc7\u591a\u6a21\u5757\u534f\u540c\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8f68\u8ff9\u76f8\u4f3c\u6027\u8ba1\u7b97\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2506.15901", "pdf": "https://arxiv.org/pdf/2506.15901", "abs": "https://arxiv.org/abs/2506.15901", "authors": ["Li Sun", "Shuheng Chen", "Yong Si", "Junyi Fan", "Maryam Pishgar", "Elham Pishgar", "Kamiar Alaei", "Greg Placencia"], "title": "Clinically Interpretable Mortality Prediction for ICU Patients with Diabetes and Atrial Fibrillation: A Machine Learning Approach", "categories": ["cs.LG"], "comment": null, "summary": "Background: Patients with both diabetes mellitus (DM) and atrial fibrillation\n(AF) face elevated mortality in intensive care units (ICUs), yet models\ntargeting this high-risk group remain limited.\n  Objective: To develop an interpretable machine learning (ML) model predicting\n28-day mortality in ICU patients with concurrent DM and AF using early-phase\nclinical data.\n  Methods: A retrospective cohort of 1,535 adult ICU patients with DM and AF\nwas extracted from the MIMIC-IV database. Data preprocessing involved\nmedian/mode imputation, z-score normalization, and early temporal feature\nengineering. A two-step feature selection pipeline-univariate filtering (ANOVA\nF-test) and Random Forest-based multivariate ranking-yielded 19 interpretable\nfeatures. Seven ML models were trained with stratified 5-fold cross-validation\nand SMOTE oversampling. Interpretability was assessed via ablation and\nAccumulated Local Effects (ALE) analysis.\n  Results: Logistic regression achieved the best performance (AUROC: 0.825; 95%\nCI: 0.779-0.867), surpassing more complex models. Key predictors included RAS,\nage, bilirubin, and extubation. ALE plots showed intuitive, non-linear effects\nsuch as age-related risk acceleration and bilirubin thresholds.\n  Conclusion: This interpretable ML model offers accurate risk prediction and\nclinical insights for early ICU triage in patients with DM and AF.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4bICU\u4e2d\u540c\u65f6\u60a3\u6709\u7cd6\u5c3f\u75c5\u548c\u623f\u98a4\u60a3\u8005\u768428\u5929\u6b7b\u4ea1\u7387\uff0c\u903b\u8f91\u56de\u5f52\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u9488\u5bf9\u7cd6\u5c3f\u75c5\u548c\u623f\u98a4\u60a3\u8005\u5728ICU\u4e2d\u6b7b\u4ea1\u7387\u8f83\u9ad8\u7684\u95ee\u9898\uff0c\u73b0\u6709\u6a21\u578b\u6709\u9650\uff0c\u9700\u5f00\u53d1\u66f4\u51c6\u786e\u7684\u9884\u6d4b\u5de5\u5177\u3002", "method": "\u4eceMIMIC-IV\u6570\u636e\u5e93\u4e2d\u63d0\u53d61,535\u540d\u60a3\u8005\u6570\u636e\uff0c\u8fdb\u884c\u9884\u5904\u7406\u548c\u7279\u5f81\u9009\u62e9\uff0c\u8bad\u7ec37\u79cdML\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u4ea4\u53c9\u9a8c\u8bc1\u548cSMOTE\u8fc7\u91c7\u6837\u4f18\u5316\u3002", "result": "\u903b\u8f91\u56de\u5f52\u8868\u73b0\u6700\u4f73\uff08AUROC: 0.825\uff09\uff0c\u5173\u952e\u9884\u6d4b\u56e0\u5b50\u5305\u62ecRAS\u3001\u5e74\u9f84\u3001\u80c6\u7ea2\u7d20\u548c\u62d4\u7ba1\u3002ALE\u5206\u6790\u63ed\u793a\u4e86\u975e\u7ebf\u6027\u6548\u5e94\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u7cd6\u5c3f\u75c5\u548c\u623f\u98a4\u60a3\u8005\u7684\u65e9\u671fICU\u5206\u8bca\u63d0\u4f9b\u4e86\u51c6\u786e\u7684\u98ce\u9669\u9884\u6d4b\u548c\u4e34\u5e8a\u89c1\u89e3\u3002"}}
{"id": "2506.15903", "pdf": "https://arxiv.org/pdf/2506.15903", "abs": "https://arxiv.org/abs/2506.15903", "authors": ["Josef Kucha\u0159", "Marek Kadl\u010d\u00edk", "Michal Spiegel", "Michal \u0160tef\u00e1nik"], "title": "VectorEdits: A Dataset and Benchmark for Instruction-Based Editing of Vector Graphics", "categories": ["cs.LG"], "comment": null, "summary": "We introduce a large-scale dataset for instruction-guided vector image\nediting, consisting of over 270,000 pairs of SVG images paired with natural\nlanguage edit instructions. Our dataset enables training and evaluation of\nmodels that modify vector graphics based on textual commands. We describe the\ndata collection process, including image pairing via CLIP similarity and\ninstruction generation with vision-language models. Initial experiments with\nstate-of-the-art large language models reveal that current methods struggle to\nproduce accurate and valid edits, underscoring the challenge of this task. To\nfoster research in natural language-driven vector graphic generation and\nediting, we make our resources created within this work publicly available.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u6307\u4ee4\u5f15\u5bfc\u7684\u77e2\u91cf\u56fe\u50cf\u7f16\u8f91\uff0c\u5305\u542b27\u4e07\u5bf9SVG\u56fe\u50cf\u548c\u81ea\u7136\u8bed\u8a00\u7f16\u8f91\u6307\u4ee4\u3002\u6570\u636e\u96c6\u652f\u6301\u57fa\u4e8e\u6587\u672c\u547d\u4ee4\u7684\u77e2\u91cf\u56fe\u5f62\u4fee\u6539\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "motivation": "\u63a8\u52a8\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u77e2\u91cf\u56fe\u5f62\u751f\u6210\u548c\u7f16\u8f91\u7814\u7a76\uff0c\u63d0\u4f9b\u516c\u5f00\u8d44\u6e90\u4ee5\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7CLIP\u76f8\u4f3c\u6027\u914d\u5bf9\u56fe\u50cf\uff0c\u5e76\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6307\u4ee4\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u51c6\u786e\u548c\u6709\u6548\u7684\u7f16\u8f91\u65b9\u9762\u4ecd\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3a\u81ea\u7136\u8bed\u8a00\u9a71\u52a8\u7684\u77e2\u91cf\u56fe\u5f62\u7f16\u8f91\u4efb\u52a1\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u5e76\u63ed\u793a\u4e86\u8be5\u4efb\u52a1\u7684\u6311\u6218\u6027\u3002"}}
{"id": "2506.15907", "pdf": "https://arxiv.org/pdf/2506.15907", "abs": "https://arxiv.org/abs/2506.15907", "authors": ["Hang Yang", "Yusheng Hu", "Yong Liu", "Cong", "Hao"], "title": "Pieceformer: Similarity-Driven Knowledge Transfer via Scalable Graph Transformer in VLSI", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "7 pages, 4 figures, 1 table, submitted", "summary": "Accurate graph similarity is critical for knowledge transfer in VLSI design,\nenabling the reuse of prior solutions to reduce engineering effort and\nturnaround time. We propose Pieceformer, a scalable, self-supervised similarity\nassessment framework, equipped with a hybrid message-passing and graph\ntransformer encoder. To address transformer scalability, we incorporate a\nlinear transformer backbone and introduce a partitioned training pipeline for\nefficient memory and parallelism management. Evaluations on synthetic and\nreal-world CircuitNet datasets show that Pieceformer reduces mean absolute\nerror (MAE) by 24.9% over the baseline and is the only method to correctly\ncluster all real-world design groups. We further demonstrate the practical\nusage of our model through a case study on a partitioning task, achieving up to\n89% runtime reduction. These results validate the framework's effectiveness for\nscalable, unbiased design reuse in modern VLSI systems.", "AI": {"tldr": "Pieceformer\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u81ea\u76d1\u7763\u56fe\u76f8\u4f3c\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u6df7\u5408\u6d88\u606f\u4f20\u9012\u548c\u56fe\u53d8\u6362\u5668\u7f16\u7801\u5668\uff0c\u663e\u8457\u63d0\u9ad8\u4e86VLSI\u8bbe\u8ba1\u4e2d\u7684\u77e5\u8bc6\u8f6c\u79fb\u6548\u7387\u3002", "motivation": "\u5728VLSI\u8bbe\u8ba1\u4e2d\uff0c\u51c6\u786e\u7684\u56fe\u76f8\u4f3c\u6027\u8bc4\u4f30\u5bf9\u51cf\u5c11\u5de5\u7a0b\u65f6\u95f4\u548c\u6210\u672c\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u548c\u51c6\u786e\u6027\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51faPieceformer\u6846\u67b6\uff0c\u91c7\u7528\u7ebf\u6027\u53d8\u6362\u5668\u9aa8\u5e72\u548c\u5206\u533a\u8bad\u7ec3\u7ba1\u9053\uff0c\u4f18\u5316\u5185\u5b58\u548c\u5e76\u884c\u7ba1\u7406\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cPieceformer\u5c06MAE\u964d\u4f4e24.9%\uff0c\u5e76\u80fd\u6b63\u786e\u805a\u7c7b\u6240\u6709\u771f\u5b9e\u8bbe\u8ba1\u7ec4\u3002", "conclusion": "Pieceformer\u4e3a\u73b0\u4ee3VLSI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u8bbe\u8ba1\u91cd\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.15912", "pdf": "https://arxiv.org/pdf/2506.15912", "abs": "https://arxiv.org/abs/2506.15912", "authors": ["Zifei Xu", "Sayeh Sharify", "Hesham Mostafa", "Tristan Webb", "Wanzin Yazar", "Xin Wang"], "title": "Early Attentive Sparsification Accelerates Neural Speech Transcription", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Transformer-based neural speech processing has achieved state-of-the-art\nperformance. Since speech audio signals are known to be highly compressible,\nhere we seek to accelerate neural speech transcription by time-domain signal\nsparsification early in the neural encoding stage, taking advantage of the\ninterpretability of the self-attention mechanism in transformer audio encoders.\nWith the Whisper family of models, we perform a systematic architecture search\nover the joint space of sparsification stage (a certain encoder layer) and\ncompression ratio (sparsity). We found that the best resulting solutions under\n1% accuracy degradation choose to sparsify the hidden state to 40-60% sparsity\nat an early encoding stage, and thereby achieve up to 1.6x runtime acceleration\nin English speech transcription tasks on Nvidia GPUs without any fine-tuning.", "AI": {"tldr": "\u901a\u8fc7\u65f6\u95f4\u57df\u4fe1\u53f7\u7a00\u758f\u5316\u52a0\u901f\u795e\u7ecf\u8bed\u97f3\u8f6c\u5f55\uff0c\u5229\u7528Transformer\u97f3\u9891\u7f16\u7801\u5668\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u53ef\u89e3\u91ca\u6027\uff0c\u5728Whisper\u6a21\u578b\u4e0a\u5b9e\u73b01.6\u500d\u52a0\u901f\u4e14\u51c6\u786e\u7387\u4e0b\u964d\u5c0f\u4e8e1%\u3002", "motivation": "\u8bed\u97f3\u97f3\u9891\u4fe1\u53f7\u9ad8\u5ea6\u53ef\u538b\u7f29\uff0c\u5229\u7528Transformer\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u53ef\u89e3\u91ca\u6027\uff0c\u63a2\u7d22\u5728\u795e\u7ecf\u7f16\u7801\u9636\u6bb5\u65e9\u671f\u8fdb\u884c\u65f6\u95f4\u57df\u4fe1\u53f7\u7a00\u758f\u5316\u4ee5\u52a0\u901f\u8f6c\u5f55\u3002", "method": "\u5728Whisper\u6a21\u578b\u4e0a\u8fdb\u884c\u7cfb\u7edf\u67b6\u6784\u641c\u7d22\uff0c\u8054\u5408\u4f18\u5316\u7a00\u758f\u5316\u9636\u6bb5\uff08\u7f16\u7801\u5c42\uff09\u548c\u538b\u7f29\u6bd4\uff08\u7a00\u758f\u5ea6\uff09\u3002", "result": "\u6700\u4f73\u65b9\u6848\u5728\u51c6\u786e\u7387\u4e0b\u964d\u5c0f\u4e8e1%\u7684\u60c5\u51b5\u4e0b\uff0c\u9009\u62e9\u5728\u65e9\u671f\u7f16\u7801\u9636\u6bb5\u5c06\u9690\u85cf\u72b6\u6001\u7a00\u758f\u5316\u81f340-60%\uff0c\u5b9e\u73b01.6\u500d\u8fd0\u884c\u65f6\u52a0\u901f\u3002", "conclusion": "\u65e9\u671f\u7a00\u758f\u5316\u53ef\u663e\u8457\u52a0\u901f\u795e\u7ecf\u8bed\u97f3\u8f6c\u5f55\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2506.15926", "pdf": "https://arxiv.org/pdf/2506.15926", "abs": "https://arxiv.org/abs/2506.15926", "authors": ["Soumya Basu"], "title": "Competing Bandits in Matching Markets via Super Stability", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": null, "summary": "We study bandit learning in matching markets with two-sided reward\nuncertainty, extending prior research primarily focused on single-sided\nuncertainty. Leveraging the concept of `super-stability' from Irving (1994), we\ndemonstrate the advantage of the Extended Gale-Shapley (GS) algorithm over the\nstandard GS algorithm in achieving true stable matchings under incomplete\ninformation. By employing the Extended GS algorithm, our centralized algorithm\nattains a logarithmic pessimal stable regret dependent on an instance-dependent\nadmissible gap parameter. This algorithm is further adapted to a decentralized\nsetting with a constant regret increase. Finally, we establish a novel\ncentralized instance-dependent lower bound for binary stable regret,\nelucidating the roles of the admissible gap and super-stable matching in\ncharacterizing the complexity of stable matching with bandit feedback.", "AI": {"tldr": "\u7814\u7a76\u53cc\u8fb9\u5956\u52b1\u4e0d\u786e\u5b9a\u6027\u7684\u5339\u914d\u5e02\u573a\u4e2d\u7684\u5f3a\u76d7\u5b66\u4e60\uff0c\u6269\u5c55\u4e86\u4ee5\u5f80\u4e3b\u8981\u5173\u6ce8\u5355\u8fb9\u4e0d\u786e\u5b9a\u6027\u7684\u7814\u7a76\u3002\u901a\u8fc7\u5229\u7528Irving (1994)\u7684\u201c\u8d85\u7a33\u5b9a\u6027\u201d\u6982\u5ff5\uff0c\u5c55\u793a\u4e86\u6269\u5c55Gale-Shapley (GS)\u7b97\u6cd5\u5728\u5b9e\u73b0\u4e0d\u5b8c\u5168\u4fe1\u606f\u4e0b\u771f\u6b63\u7a33\u5b9a\u5339\u914d\u4e2d\u7684\u4f18\u52bf\u3002", "motivation": "\u6269\u5c55\u5bf9\u5339\u914d\u5e02\u573a\u4e2d\u53cc\u8fb9\u5956\u52b1\u4e0d\u786e\u5b9a\u6027\u7684\u7406\u89e3\uff0c\u586b\u8865\u5355\u8fb9\u4e0d\u786e\u5b9a\u6027\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u6269\u5c55GS\u7b97\u6cd5\uff0c\u63d0\u51fa\u4e00\u79cd\u96c6\u4e2d\u5f0f\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4f9d\u8d56\u4e8e\u5b9e\u4f8b\u7684\u53ef\u5bb9\u8bb8\u95f4\u9699\u53c2\u6570\u7684\u5bf9\u6570\u6700\u5dee\u7a33\u5b9a\u9057\u61be\u3002\u5e76\u8fdb\u4e00\u6b65\u5c06\u8be5\u7b97\u6cd5\u9002\u5e94\u4e8e\u53bb\u4e2d\u5fc3\u5316\u8bbe\u7f6e\u3002", "result": "\u96c6\u4e2d\u5f0f\u7b97\u6cd5\u5b9e\u73b0\u4e86\u5bf9\u6570\u6700\u5dee\u7a33\u5b9a\u9057\u61be\uff0c\u53bb\u4e2d\u5fc3\u5316\u8bbe\u7f6e\u4e2d\u9057\u61be\u589e\u52a0\u4e3a\u5e38\u6570\u3002\u540c\u65f6\uff0c\u5efa\u7acb\u4e86\u65b0\u7684\u96c6\u4e2d\u5f0f\u5b9e\u4f8b\u4f9d\u8d56\u6027\u4e0b\u754c\uff0c\u9610\u660e\u4e86\u53ef\u5bb9\u8bb8\u95f4\u9699\u548c\u8d85\u7a33\u5b9a\u5339\u914d\u5728\u7a33\u5b9a\u5339\u914d\u590d\u6742\u6027\u4e2d\u7684\u4f5c\u7528\u3002", "conclusion": "\u6269\u5c55GS\u7b97\u6cd5\u5728\u53cc\u8fb9\u5956\u52b1\u4e0d\u786e\u5b9a\u6027\u4e0b\u8868\u73b0\u4f18\u8d8a\uff0c\u4e3a\u7a33\u5b9a\u5339\u914d\u7684\u5f3a\u76d7\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u548c\u7b97\u6cd5\u652f\u6301\u3002"}}
{"id": "2506.15933", "pdf": "https://arxiv.org/pdf/2506.15933", "abs": "https://arxiv.org/abs/2506.15933", "authors": ["Esther Rodriguez", "Monica Welfert", "Samuel McDowell", "Nathan Stromberg", "Julian Antolin Camarena", "Lalitha Sankar"], "title": "CORAL: Disentangling Latent Representations in Long-Tailed Diffusion", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion models have achieved impressive performance in generating\nhigh-quality and diverse synthetic data. However, their success typically\nassumes a class-balanced training distribution. In real-world settings,\nmulti-class data often follow a long-tailed distribution, where standard\ndiffusion models struggle -- producing low-diversity and lower-quality samples\nfor tail classes. While this degradation is well-documented, its underlying\ncause remains poorly understood. In this work, we investigate the behavior of\ndiffusion models trained on long-tailed datasets and identify a key issue: the\nlatent representations (from the bottleneck layer of the U-Net) for tail class\nsubspaces exhibit significant overlap with those of head classes, leading to\nfeature borrowing and poor generation quality. Importantly, we show that this\nis not merely due to limited data per class, but that the relative class\nimbalance significantly contributes to this phenomenon. To address this, we\npropose COntrastive Regularization for Aligning Latents (CORAL), a contrastive\nlatent alignment framework that leverages supervised contrastive losses to\nencourage well-separated latent class representations. Experiments demonstrate\nthat CORAL significantly improves both the diversity and visual quality of\nsamples generated for tail classes relative to state-of-the-art methods.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6269\u6563\u6a21\u578b\u5728\u957f\u5c3e\u5206\u5e03\u6570\u636e\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5c3e\u7c7b\u6837\u672c\u751f\u6210\u8d28\u91cf\u4f4e\u7684\u539f\u56e0\u662f\u6f5c\u5728\u8868\u5f81\u91cd\u53e0\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u6bd4\u6b63\u5219\u5316\u65b9\u6cd5\uff08CORAL\uff09\u6765\u6539\u5584\u8fd9\u4e00\u95ee\u9898\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u6570\u636e\u901a\u5e38\u5448\u73b0\u957f\u5c3e\u5206\u5e03\uff0c\u800c\u6807\u51c6\u6269\u6563\u6a21\u578b\u5728\u8fd9\u79cd\u5206\u5e03\u4e0b\u5bf9\u5c3e\u7c7b\u7684\u751f\u6210\u6548\u679c\u8f83\u5dee\uff0c\u5176\u6f5c\u5728\u539f\u56e0\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6269\u6563\u6a21\u578b\u5728\u957f\u5c3e\u6570\u636e\u96c6\u4e0a\u7684\u884c\u4e3a\uff0c\u53d1\u73b0\u6f5c\u5728\u8868\u5f81\u91cd\u53e0\u662f\u95ee\u9898\u6839\u6e90\uff0c\u5e76\u63d0\u51faCORAL\u6846\u67b6\uff0c\u5229\u7528\u5bf9\u6bd4\u635f\u5931\u6765\u5206\u79bb\u6f5c\u5728\u8868\u5f81\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCORAL\u663e\u8457\u63d0\u9ad8\u4e86\u5c3e\u7c7b\u6837\u672c\u7684\u591a\u6837\u6027\u548c\u89c6\u89c9\u8d28\u91cf\u3002", "conclusion": "CORAL\u901a\u8fc7\u5bf9\u6bd4\u6b63\u5219\u5316\u6709\u6548\u6539\u5584\u4e86\u6269\u6563\u6a21\u578b\u5728\u957f\u5c3e\u5206\u5e03\u6570\u636e\u4e0a\u7684\u751f\u6210\u6027\u80fd\u3002"}}
{"id": "2506.15943", "pdf": "https://arxiv.org/pdf/2506.15943", "abs": "https://arxiv.org/abs/2506.15943", "authors": ["Bruce Huang", "Ruida Zhou", "Lin F. Yang", "Suhas Diggavi"], "title": "On the optimal regret of collaborative personalized linear bandits", "categories": ["cs.LG"], "comment": "30 pages, 4 figures", "summary": "Stochastic linear bandits are a fundamental model for sequential decision\nmaking, where an agent selects a vector-valued action and receives a noisy\nreward with expected value given by an unknown linear function. Although well\nstudied in the single-agent setting, many real-world scenarios involve multiple\nagents solving heterogeneous bandit problems, each with a different unknown\nparameter. Applying single agent algorithms independently ignores cross-agent\nsimilarity and learning opportunities. This paper investigates the optimal\nregret achievable in collaborative personalized linear bandits. We provide an\ninformation-theoretic lower bound that characterizes how the number of agents,\nthe interaction rounds, and the degree of heterogeneity jointly affect regret.\nWe then propose a new two-stage collaborative algorithm that achieves the\noptimal regret. Our analysis models heterogeneity via a hierarchical Bayesian\nframework and introduces a novel information-theoretic technique for bounding\nregret. Our results offer a complete characterization of when and how\ncollaboration helps with a optimal regret bound $\\tilde{O}(d\\sqrt{mn})$,\n$\\tilde{O}(dm^{1-\\gamma}\\sqrt{n})$, $\\tilde{O}(dm\\sqrt{n})$ for the number of\nrounds $n$ in the range of $(0, \\frac{d}{m \\sigma^2})$, $[\\frac{d}{m^{2\\gamma}\n\\sigma^2}, \\frac{d}{\\sigma^2}]$ and $(\\frac{d}{\\sigma^2}, \\infty)$\nrespectively, where $\\sigma$ measures the level of heterogeneity, $m$ is the\nnumber of agents, and $\\gamma\\in[0, 1/2]$ is an absolute constant. In contrast,\nagents without collaboration achieve a regret bound $O(dm\\sqrt{n})$ at best.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u591a\u4ee3\u7406\u534f\u4f5c\u4e2a\u6027\u5316\u7ebf\u6027\u8d4c\u535a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4fe1\u606f\u8bba\u4e0b\u754c\u548c\u4e24\u9636\u6bb5\u534f\u4f5c\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6700\u4f18\u9057\u61be\u3002", "motivation": "\u73b0\u5b9e\u573a\u666f\u4e2d\u591a\u4ee3\u7406\u89e3\u51b3\u5f02\u6784\u8d4c\u535a\u95ee\u9898\u65f6\uff0c\u5355\u4ee3\u7406\u7b97\u6cd5\u5ffd\u7565\u4e86\u8de8\u4ee3\u7406\u76f8\u4f3c\u6027\u548c\u5b66\u4e60\u673a\u4f1a\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u534f\u4f5c\u7684\u4f18\u5316\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u534f\u4f5c\u7b97\u6cd5\uff0c\u5229\u7528\u5206\u5c42\u8d1d\u53f6\u65af\u6846\u67b6\u5efa\u6a21\u5f02\u6784\u6027\uff0c\u5e76\u5f15\u5165\u4fe1\u606f\u8bba\u6280\u672f\u9650\u5236\u9057\u61be\u3002", "result": "\u7b97\u6cd5\u5728\u4e09\u79cd\u4e0d\u540c\u8f6e\u6b21\u8303\u56f4\u5185\u5b9e\u73b0\u4e86\u6700\u4f18\u9057\u61be\u754c\uff0c\u4f18\u4e8e\u975e\u534f\u4f5c\u4ee3\u7406\u7684\u9057\u61be\u754c\u3002", "conclusion": "\u534f\u4f5c\u5728\u591a\u4ee3\u7406\u7ebf\u6027\u8d4c\u535a\u95ee\u9898\u4e2d\u80fd\u663e\u8457\u964d\u4f4e\u9057\u61be\uff0c\u5c24\u5176\u662f\u5728\u5f02\u6784\u6027\u8f83\u4f4e\u65f6\u6548\u679c\u66f4\u660e\u663e\u3002"}}
{"id": "2506.15954", "pdf": "https://arxiv.org/pdf/2506.15954", "abs": "https://arxiv.org/abs/2506.15954", "authors": ["Vinicius Yuiti Fukase", "Heitor Gama", "Barbara Bueno", "Lucas Libanio", "Anna Helena Reali Costa", "Artur Jordao"], "title": "One Period to Rule Them All: Identifying Critical Learning Periods in Deep Networks", "categories": ["cs.LG"], "comment": null, "summary": "Critical Learning Periods comprehend an important phenomenon involving deep\nlearning, where early epochs play a decisive role in the success of many\ntraining recipes, such as data augmentation. Existing works confirm the\nexistence of this phenomenon and provide useful insights. However, the\nliterature lacks efforts to precisely identify when critical periods occur. In\nthis work, we fill this gap by introducing a systematic approach for\nidentifying critical periods during the training of deep neural networks,\nfocusing on eliminating computationally intensive regularization techniques and\neffectively applying mechanisms for reducing computational costs, such as data\npruning. Our method leverages generalization prediction mechanisms to pinpoint\ncritical phases where training recipes yield maximum benefits to the predictive\nability of models. By halting resource-intensive recipes beyond these periods,\nwe significantly accelerate the learning phase and achieve reductions in\ntraining time, energy consumption, and CO$_2$ emissions. Experiments on\nstandard architectures and benchmarks confirm the effectiveness of our method.\nSpecifically, we achieve significant milestones by reducing the training time\nof popular architectures by up to 59.67%, leading to a 59.47% decrease in\nCO$_2$ emissions and a 60% reduction in financial costs, without compromising\nperformance. Our work enhances understanding of training dynamics and paves the\nway for more sustainable and efficient deep learning practices, particularly in\nresource-constrained environments. In the era of the race for foundation\nmodels, we believe our method emerges as a valuable framework. The repository\nis available at https://github.com/baunilhamarga/critical-periods", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u5173\u952e\u5b66\u4e60\u671f\uff0c\u901a\u8fc7\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u548c\u8d44\u6e90\u6d88\u8017\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u786e\u8ba4\u4e86\u5173\u952e\u5b66\u4e60\u671f\u7684\u5b58\u5728\uff0c\u4f46\u7f3a\u4e4f\u7cbe\u786e\u8bc6\u522b\u5176\u53d1\u751f\u65f6\u95f4\u7684\u65b9\u6cd5\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5229\u7528\u6cdb\u5316\u9884\u6d4b\u673a\u5236\u8bc6\u522b\u5173\u952e\u671f\uff0c\u5e76\u5728\u6b64\u540e\u505c\u6b62\u8d44\u6e90\u5bc6\u96c6\u578b\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4ee5\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u548c\u6392\u653e\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5c06\u6d41\u884c\u67b6\u6784\u7684\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c1159.67%\uff0cCO$_2$\u6392\u653e\u51cf\u5c1159.47%\uff0c\u6210\u672c\u964d\u4f4e60%\uff0c\u4e14\u4e0d\u5f71\u54cd\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6df1\u5ea6\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u53ef\u6301\u7eed\u548c\u9ad8\u6548\u7684\u5b9e\u8df5\u8def\u5f84\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u73af\u5883\u3002"}}
{"id": "2506.15963", "pdf": "https://arxiv.org/pdf/2506.15963", "abs": "https://arxiv.org/abs/2506.15963", "authors": ["Jingyi Cui", "Qi Zhang", "Yifei Wang", "Yisen Wang"], "title": "On the Theoretical Understanding of Identifiable Sparse Autoencoders and Beyond", "categories": ["cs.LG"], "comment": null, "summary": "Sparse autoencoders (SAEs) have emerged as a powerful tool for interpreting\nfeatures learned by large language models (LLMs). It aims to recover complex\nsuperposed polysemantic features into interpretable monosemantic ones through\nfeature reconstruction via sparsely activated neural networks. Despite the wide\napplications of SAEs, it remains unclear under what conditions an SAE can fully\nrecover the ground truth monosemantic features from the superposed polysemantic\nones. In this paper, through theoretical analysis, we for the first time\npropose the necessary and sufficient conditions for identifiable SAEs (SAEs\nthat learn unique and ground truth monosemantic features), including 1) extreme\nsparsity of the ground truth feature, 2) sparse activation of SAEs, and 3)\nenough hidden dimensions of SAEs. Moreover, when the identifiable conditions\nare not fully met, we propose a reweighting strategy to improve the\nidentifiability. Specifically, following the theoretically suggested weight\nselection principle, we prove that the gap between the loss functions of SAE\nreconstruction and monosemantic feature reconstruction can be narrowed, so that\nthe reweighted SAEs have better reconstruction of the ground truth monosemantic\nfeatures than the uniformly weighted ones. In experiments, we validate our\ntheoretical findings and show that our weighted SAE significantly improves\nfeature monosemanticity and interpretability.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAE\uff09\u5728\u6062\u590d\u5355\u8bed\u4e49\u7279\u5f81\u65f6\u7684\u5fc5\u8981\u548c\u5145\u5206\u6761\u4ef6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u52a0\u6743\u7b56\u7565\u4ee5\u63d0\u9ad8\u53ef\u8bc6\u522b\u6027\u3002", "motivation": "\u5c3d\u7ba1SAE\u5728\u89e3\u91ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7279\u5f81\u65b9\u9762\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u5176\u5728\u4f55\u79cd\u6761\u4ef6\u4e0b\u80fd\u5b8c\u5168\u6062\u590d\u5355\u8bed\u4e49\u7279\u5f81\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u63d0\u51faSAE\u53ef\u8bc6\u522b\u7684\u6761\u4ef6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u52a0\u6743\u7b56\u7565\u4ee5\u4f18\u5316\u7279\u5f81\u91cd\u5efa\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u6761\u4ef6\uff0c\u52a0\u6743SAE\u663e\u8457\u63d0\u9ad8\u4e86\u7279\u5f81\u7684\u5355\u8bed\u4e49\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8bba\u6587\u4e3aSAE\u7684\u53ef\u8bc6\u522b\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u901a\u8fc7\u52a0\u6743\u7b56\u7565\u6539\u8fdb\u4e86\u7279\u5f81\u91cd\u5efa\u6548\u679c\u3002"}}
{"id": "2506.15969", "pdf": "https://arxiv.org/pdf/2506.15969", "abs": "https://arxiv.org/abs/2506.15969", "authors": ["Haoyue Zhang", "Hualei Zhang", "Xiaosong Ma", "Jie Zhang", "Song Guo"], "title": "LazyEviction: Lagged KV Eviction with Attention Pattern Observation for Efficient Long Reasoning", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) exhibit enhanced reasoning capabilities by\nemploying Chain-of-Thought (CoT). However, the extended reasoning sequences\nintroduce significant GPU memory overhead due to increased key-value (KV) cache\nsize, particularly in tasks requiring long reasoning sequences, such as\nmathematics and programming. Existing KV cache compression methods mitigate\nmemory bottlenecks but struggle in long reasoning tasks. In this paper, we\nanalyze attention patterns in reasoning tasks and reveal a Token Importance\nRecurrence phenomenon: a large proportion of tokens receive renewed attention\nafter multiple decoding steps, which is failed to capture by existing works and\nmay lead to unpredictable eviction on such periodically critical tokens. To\naddress this, we propose LazyEviction, a lagged KV eviction framework designed\nto maintain reasoning performance while reducing KV memory. LazyEviction is an\nObservation Window-based Lagged Eviction Mechanism retaining latent recurring\ntokens by performing lagged evictions across decoding steps, which contains two\nkey components: (1) Recurrence Interval Tracking for capturing temporal\nvariations in token importance, and (2) an Maximum Recurrence Interval-Centric\nEviction Policy that prioritizes eviction based on tokens' recurrence patterns.\nExtensive experiments demonstrate that LazyEviction reduces KV cache size by\n50% while maintaining comparable accuracy on mathematics reasoning datasets,\noutperforming state-of-the-art methods. Our findings highlight the importance\nof preserving recurring tokens, which are critical for maintaining knowledge\ncontinuity in multi-step reasoning tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLazyEviction\u7684\u5ef6\u8fdfKV\u7f13\u5b58\u6dd8\u6c70\u6846\u67b6\uff0c\u901a\u8fc7\u6355\u6349\u4ee4\u724c\u91cd\u8981\u6027\u91cd\u73b0\u73b0\u8c61\uff0c\u663e\u8457\u51cf\u5c11GPU\u5185\u5b58\u5360\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\u5728\u957f\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u672a\u80fd\u6355\u6349\u4ee4\u724c\u91cd\u8981\u6027\u91cd\u73b0\u73b0\u8c61\uff0c\u5bfc\u81f4\u5173\u952e\u4ee4\u724c\u88ab\u4e0d\u53ef\u9884\u6d4b\u5730\u6dd8\u6c70\u3002", "method": "\u63d0\u51faLazyEviction\u6846\u67b6\uff0c\u5305\u542b\u91cd\u73b0\u95f4\u9694\u8ffd\u8e2a\u548c\u57fa\u4e8e\u6700\u5927\u91cd\u73b0\u95f4\u9694\u7684\u6dd8\u6c70\u7b56\u7565\uff0c\u4ee5\u4fdd\u7559\u5468\u671f\u6027\u5173\u952e\u4ee4\u724c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLazyEviction\u5c06KV\u7f13\u5b58\u5927\u5c0f\u51cf\u5c1150%\uff0c\u540c\u65f6\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u4fdd\u7559\u91cd\u73b0\u4ee4\u724c\u5bf9\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u77e5\u8bc6\u8fde\u7eed\u6027\u81f3\u5173\u91cd\u8981\uff0cLazyEviction\u4e3a\u6b64\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16001", "pdf": "https://arxiv.org/pdf/2506.16001", "abs": "https://arxiv.org/abs/2506.16001", "authors": ["Qianru Zhang", "Honggang Wen", "Ming Li", "Dong Huang", "Siu-Ming Yiu", "Christian S. Jensen", "Pietro Li\u00f2"], "title": "AutoHFormer: Efficient Hierarchical Autoregressive Transformer for Time Series Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages", "summary": "Time series forecasting requires architectures that simultaneously achieve\nthree competing objectives: (1) strict temporal causality for reliable\npredictions, (2) sub-quadratic complexity for practical scalability, and (3)\nmulti-scale pattern recognition for accurate long-horizon forecasting. We\nintroduce AutoHFormer, a hierarchical autoregressive transformer that addresses\nthese challenges through three key innovations: 1) Hierarchical Temporal\nModeling: Our architecture decomposes predictions into segment-level blocks\nprocessed in parallel, followed by intra-segment sequential refinement. This\ndual-scale approach maintains temporal coherence while enabling efficient\ncomputation. 2) Dynamic Windowed Attention: The attention mechanism employs\nlearnable causal windows with exponential decay, reducing complexity while\npreserving precise temporal relationships. This design avoids both the\nanti-causal violations of standard transformers and the sequential bottlenecks\nof RNN hybrids. 3) Adaptive Temporal Encoding: a novel position encoding system\nis adopted to capture time patterns at multiple scales. It combines fixed\noscillating patterns for short-term variations with learnable decay rates for\nlong-term trends. Comprehensive experiments demonstrate that AutoHFormer 10.76X\nfaster training and 6.06X memory reduction compared to PatchTST on PEMS08,\nwhile maintaining consistent accuracy across 96-720 step horizons in most of\ncases. These breakthroughs establish new benchmarks for efficient and precise\ntime series modeling. Implementations of our method and all baselines in\nhierarchical autoregressive mechanism are available at\nhttps://github.com/lizzyhku/Autotime.", "AI": {"tldr": "AutoHFormer\u662f\u4e00\u79cd\u5c42\u6b21\u81ea\u56de\u5f52Transformer\uff0c\u901a\u8fc7\u5206\u5c42\u65f6\u95f4\u5efa\u6a21\u3001\u52a8\u6001\u7a97\u53e3\u6ce8\u610f\u529b\u548c\u81ea\u9002\u5e94\u65f6\u95f4\u7f16\u7801\uff0c\u89e3\u51b3\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u65f6\u95f4\u56e0\u679c\u6027\u3001\u8ba1\u7b97\u590d\u6742\u6027\u548c\u591a\u5c3a\u5ea6\u6a21\u5f0f\u8bc6\u522b\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u9700\u8981\u540c\u65f6\u6ee1\u8db3\u4e25\u683c\u7684\u65f6\u95f4\u56e0\u679c\u6027\u3001\u6b21\u4e8c\u6b21\u8ba1\u7b97\u590d\u6742\u6027\u548c\u591a\u5c3a\u5ea6\u6a21\u5f0f\u8bc6\u522b\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u517c\u987e\u8fd9\u4e9b\u76ee\u6807\u3002", "method": "1) \u5206\u5c42\u65f6\u95f4\u5efa\u6a21\uff1a\u5c06\u9884\u6d4b\u5206\u89e3\u4e3a\u5e76\u884c\u5904\u7406\u7684\u6bb5\u7ea7\u5757\uff0c\u518d\u8fdb\u884c\u6bb5\u5185\u987a\u5e8f\u7ec6\u5316\uff1b2) \u52a8\u6001\u7a97\u53e3\u6ce8\u610f\u529b\uff1a\u4f7f\u7528\u53ef\u5b66\u4e60\u7684\u56e0\u679c\u7a97\u53e3\u548c\u6307\u6570\u8870\u51cf\uff1b3) \u81ea\u9002\u5e94\u65f6\u95f4\u7f16\u7801\uff1a\u7ed3\u5408\u56fa\u5b9a\u632f\u8361\u6a21\u5f0f\u548c\u53ef\u5b66\u4e60\u8870\u51cf\u7387\u3002", "result": "AutoHFormer\u5728PEMS08\u4e0a\u6bd4PatchTST\u5feb10.76\u500d\uff0c\u5185\u5b58\u51cf\u5c116.06\u500d\uff0c\u540c\u65f6\u572896-720\u6b65\u8303\u56f4\u5185\u4fdd\u6301\u51c6\u786e\u6027\u3002", "conclusion": "AutoHFormer\u4e3a\u9ad8\u6548\u7cbe\u786e\u7684\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u8bbe\u7acb\u4e86\u65b0\u57fa\u51c6\u3002"}}
{"id": "2506.16009", "pdf": "https://arxiv.org/pdf/2506.16009", "abs": "https://arxiv.org/abs/2506.16009", "authors": ["Hamdi Altaheri", "Fakhri Karray", "Md. Milon Islam", "S M Taslim Uddin Raju", "Amir-Hossein Karimi"], "title": "Bridging Brain with Foundation Models through Self-Supervised Learning", "categories": ["cs.LG"], "comment": null, "summary": "Foundation models (FMs), powered by self-supervised learning (SSL), have\nredefined the capabilities of artificial intelligence, demonstrating\nexceptional performance in domains like natural language processing and\ncomputer vision. These advances present a transformative opportunity for brain\nsignal analysis. Unlike traditional supervised learning, which is limited by\nthe scarcity of labeled neural data, SSL offers a promising solution by\nenabling models to learn meaningful representations from unlabeled data. This\nis particularly valuable in addressing the unique challenges of brain signals,\nincluding high noise levels, inter-subject variability, and low signal-to-noise\nratios. This survey systematically reviews the emerging field of bridging brain\nsignals with foundation models through the innovative application of SSL. It\nexplores key SSL techniques, the development of brain-specific foundation\nmodels, their adaptation to downstream tasks, and the integration of brain\nsignals with other modalities in multimodal SSL frameworks. The review also\ncovers commonly used evaluation metrics and benchmark datasets that support\ncomparative analysis. Finally, it highlights key challenges and outlines future\nresearch directions. This work aims to provide researchers with a structured\nunderstanding of this rapidly evolving field and a roadmap for developing\ngeneralizable brain foundation models powered by self-supervision.", "AI": {"tldr": "\u7efc\u8ff0\u63a2\u8ba8\u4e86\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u5982\u4f55\u901a\u8fc7\u57fa\u7840\u6a21\u578b\uff08FMs\uff09\u9769\u65b0\u8111\u4fe1\u53f7\u5206\u6790\uff0c\u514b\u670d\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u7684\u9650\u5236\u3002", "motivation": "\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u5728\u8111\u4fe1\u53f7\u5206\u6790\u4e2d\u53d7\u9650\u4e8e\u6807\u8bb0\u6570\u636e\u7684\u7a00\u7f3a\u6027\uff0c\u800cSSL\u80fd\u4ece\u65e0\u6807\u8bb0\u6570\u636e\u4e2d\u5b66\u4e60\u6709\u6548\u8868\u5f81\uff0c\u89e3\u51b3\u8111\u4fe1\u53f7\u7684\u9ad8\u566a\u58f0\u548c\u4f4e\u4fe1\u566a\u6bd4\u7b49\u6311\u6218\u3002", "method": "\u7cfb\u7edf\u56de\u987e\u4e86SSL\u6280\u672f\u5728\u8111\u4fe1\u53f7\u5206\u6790\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u5173\u952eSSL\u65b9\u6cd5\u3001\u8111\u7279\u5f02\u6027\u57fa\u7840\u6a21\u578b\u7684\u5f00\u53d1\u3001\u4e0b\u6e38\u4efb\u52a1\u9002\u914d\u53ca\u591a\u6a21\u6001SSL\u6846\u67b6\u7684\u6574\u5408\u3002", "result": "\u7efc\u8ff0\u603b\u7ed3\u4e86\u5e38\u7528\u8bc4\u4f30\u6307\u6807\u548c\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u652f\u6301\u6bd4\u8f83\u5206\u6790\uff0c\u5e76\u5c55\u793a\u4e86SSL\u5728\u8111\u4fe1\u53f7\u5206\u6790\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u9886\u57df\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u4f46SSL\u4e3a\u57fa\u7840\u6a21\u578b\u5728\u8111\u4fe1\u53f7\u5206\u6790\u4e2d\u7684\u901a\u7528\u6027\u63d0\u4f9b\u4e86\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u8def\u7ebf\u56fe\u3002"}}
{"id": "2506.16014", "pdf": "https://arxiv.org/pdf/2506.16014", "abs": "https://arxiv.org/abs/2506.16014", "authors": ["Jina Kim", "Youjin Jang", "Jeongjin Han"], "title": "VRAIL: Vectorized Reward-based Attribution for Interpretable Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose VRAIL (Vectorized Reward-based Attribution for Interpretable\nLearning), a bi-level framework for value-based reinforcement learning (RL)\nthat learns interpretable weight representations from state features. VRAIL\nconsists of two stages: a deep learning (DL) stage that fits an estimated value\nfunction using state features, and an RL stage that uses this to shape learning\nvia potential-based reward transformations. The estimator is modeled in either\nlinear or quadratic form, allowing attribution of importance to individual\nfeatures and their interactions. Empirical results on the Taxi-v3 environment\ndemonstrate that VRAIL improves training stability and convergence compared to\nstandard DQN, without requiring environment modifications. Further analysis\nshows that VRAIL uncovers semantically meaningful subgoals, such as passenger\npossession, highlighting its ability to produce human-interpretable behavior.\nOur findings suggest that VRAIL serves as a general, model-agnostic framework\nfor reward shaping that enhances both learning and interpretability.", "AI": {"tldr": "VRAIL\u662f\u4e00\u4e2a\u57fa\u4e8e\u5411\u91cf\u5316\u5956\u52b1\u7684\u53cc\u5c42\u6846\u67b6\uff0c\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u5b66\u4e60\u53ef\u89e3\u91ca\u7684\u6743\u91cd\u8868\u793a\u63d0\u5347\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6536\u655b\u6027\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u6743\u91cd\u8868\u793a\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6536\u655b\u6027\uff0c\u540c\u65f6\u751f\u6210\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u884c\u4e3a\u3002", "method": "\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u6df1\u5ea6\u5b66\u4e60\u9636\u6bb5\u62df\u5408\u72b6\u6001\u7279\u5f81\u7684\u4ef7\u503c\u51fd\u6570\uff0c\u5f3a\u5316\u5b66\u4e60\u9636\u6bb5\u901a\u8fc7\u5956\u52b1\u8f6c\u6362\u8fdb\u884c\u5b66\u4e60\u3002\u652f\u6301\u7ebf\u6027\u548c\u4e8c\u6b21\u6a21\u578b\u3002", "result": "\u5728Taxi-v3\u73af\u5883\u4e2d\uff0cVRAIL\u6bd4\u6807\u51c6DQN\u8868\u73b0\u66f4\u597d\uff0c\u65e0\u9700\u4fee\u6539\u73af\u5883\u5373\u53ef\u53d1\u73b0\u8bed\u4e49\u660e\u786e\u7684\u5b50\u76ee\u6807\u3002", "conclusion": "VRAIL\u662f\u4e00\u4e2a\u901a\u7528\u7684\u3001\u6a21\u578b\u65e0\u5173\u7684\u5956\u52b1\u5851\u9020\u6846\u67b6\uff0c\u80fd\u540c\u65f6\u63d0\u5347\u5b66\u4e60\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.16032", "pdf": "https://arxiv.org/pdf/2506.16032", "abs": "https://arxiv.org/abs/2506.16032", "authors": ["Zhen Qin", "Michael B. Wakin", "Zhihui Zhu"], "title": "A Scalable Factorization Approach for High-Order Structured Tensor Recovery", "categories": ["cs.LG", "eess.SP", "math.OC"], "comment": null, "summary": "Tensor decompositions, which represent an $N$-order tensor using\napproximately $N$ factors of much smaller dimensions, can significantly reduce\nthe number of parameters. This is particularly beneficial for high-order\ntensors, as the number of entries in a tensor grows exponentially with the\norder. Consequently, they are widely used in signal recovery and data analysis\nacross domains such as signal processing, machine learning, and quantum\nphysics. A computationally and memory-efficient approach to these problems is\nto optimize directly over the factors using local search algorithms such as\ngradient descent, a strategy known as the factorization approach in matrix and\ntensor optimization. However, the resulting optimization problems are highly\nnonconvex due to the multiplicative interactions between factors, posing\nsignificant challenges for convergence analysis and recovery guarantees.\n  In this paper, we present a unified framework for the factorization approach\nto solving various tensor decomposition problems. Specifically, by leveraging\nthe canonical form of tensor decompositions--where most factors are constrained\nto be orthonormal to mitigate scaling ambiguity--we apply Riemannian gradient\ndescent (RGD) to optimize these orthonormal factors on the Stiefel manifold.\nUnder a mild condition on the loss function, we establish a Riemannian\nregularity condition for the factorized objective and prove that RGD converges\nto the ground-truth tensor at a linear rate when properly initialized. Notably,\nboth the initialization requirement and the convergence rate scale polynomially\nrather than exponentially with $N$, improving upon existing results for Tucker\nand tensor-train format tensors.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u9ece\u66fc\u68af\u5ea6\u4e0b\u964d\uff08RGD\uff09\u4f18\u5316\u5f20\u91cf\u5206\u89e3\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5728\u9002\u5f53\u521d\u59cb\u5316\u4e0b\uff0cRGD\u80fd\u4ee5\u7ebf\u6027\u901f\u7387\u6536\u655b\u5230\u771f\u5b9e\u5f20\u91cf\u3002", "motivation": "\u9ad8\u7ef4\u5f20\u91cf\u7684\u53c2\u6570\u6570\u91cf\u968f\u9636\u6570\u6307\u6570\u589e\u957f\uff0c\u5f20\u91cf\u5206\u89e3\u80fd\u663e\u8457\u51cf\u5c11\u53c2\u6570\uff0c\u4f46\u975e\u51f8\u4f18\u5316\u95ee\u9898\u5e26\u6765\u6536\u655b\u5206\u6790\u7684\u6311\u6218\u3002", "method": "\u5229\u7528\u5f20\u91cf\u5206\u89e3\u7684\u89c4\u8303\u5f62\u5f0f\uff0c\u7ea6\u675f\u591a\u6570\u56e0\u5b50\u4e3a\u6b63\u4ea4\uff0c\u5e76\u5728Stiefel\u6d41\u5f62\u4e0a\u5e94\u7528RGD\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5728\u635f\u5931\u51fd\u6570\u7684\u6e29\u548c\u6761\u4ef6\u4e0b\uff0c\u8bc1\u660e\u4e86RGD\u7684\u7ebf\u6027\u6536\u655b\u6027\uff0c\u4e14\u521d\u59cb\u5316\u548c\u6536\u655b\u901f\u7387\u4e0e\u9636\u6570\u591a\u9879\u5f0f\u76f8\u5173\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728Tucker\u548c\u5f20\u91cf\u5217\u8f66\u683c\u5f0f\u4e0a\u4f18\u4e8e\u73b0\u6709\u7ed3\u679c\uff0c\u4e3a\u9ad8\u7ef4\u5f20\u91cf\u5206\u89e3\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16035", "pdf": "https://arxiv.org/pdf/2506.16035", "abs": "https://arxiv.org/abs/2506.16035", "authors": ["Vishesh Tripathi", "Tanmay Odapally", "Indraneel Das", "Uday Allu", "Biddwan Ahmed"], "title": "Vision-Guided Chunking Is All You Need: Enhancing RAG with Multimodal Document Understanding", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": "11 pages, 1 Figure, 1 Table", "summary": "Retrieval-Augmented Generation (RAG) systems have revolutionized information\nretrieval and question answering, but traditional text-based chunking methods\nstruggle with complex document structures, multi-page tables, embedded figures,\nand contextual dependencies across page boundaries. We present a novel\nmultimodal document chunking approach that leverages Large Multimodal Models\n(LMMs) to process PDF documents in batches while maintaining semantic coherence\nand structural integrity. Our method processes documents in configurable page\nbatches with cross-batch context preservation, enabling accurate handling of\ntables spanning multiple pages, embedded visual elements, and procedural\ncontent. We evaluate our approach on a curated dataset of PDF documents with\nmanually crafted queries, demonstrating improvements in chunk quality and\ndownstream RAG performance. Our vision-guided approach achieves better accuracy\ncompared to traditional vanilla RAG systems, with qualitative analysis showing\nsuperior preservation of document structure and semantic coherence.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u6a21\u578b\u7684\u65b0\u578b\u6587\u6863\u5206\u5757\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6587\u672c\u5206\u5757\u5728\u5904\u7406\u590d\u6742\u6587\u6863\u7ed3\u6784\u65f6\u7684\u4e0d\u8db3\uff0c\u63d0\u5347\u4e86RAG\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6587\u672c\u5206\u5757\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u6587\u6863\u7ed3\u6784\uff08\u5982\u591a\u9875\u8868\u683c\u3001\u5d4c\u5165\u56fe\u8868\u548c\u8de8\u9875\u4e0a\u4e0b\u6587\u4f9d\u8d56\uff09\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u5bf9PDF\u6587\u6863\u8fdb\u884c\u6279\u91cf\u5904\u7406\uff0c\u4fdd\u6301\u8bed\u4e49\u8fde\u8d2f\u6027\u548c\u7ed3\u6784\u5b8c\u6574\u6027\uff0c\u652f\u6301\u8de8\u6279\u6b21\u4e0a\u4e0b\u6587\u4fdd\u7559\u3002", "result": "\u5728\u7cbe\u9009\u7684PDF\u6587\u6863\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u65b0\u65b9\u6cd5\u5728\u5206\u5757\u8d28\u91cf\u548c\u4e0b\u6e38RAG\u6027\u80fd\u4e0a\u5747\u6709\u63d0\u5347\uff0c\u4f18\u4e8e\u4f20\u7edfRAG\u7cfb\u7edf\u3002", "conclusion": "\u591a\u6a21\u6001\u6587\u6863\u5206\u5757\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u590d\u6742\u6587\u6863\u7684\u5904\u7406\u80fd\u529b\uff0c\u4e3aRAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u8f93\u5165\u3002"}}
{"id": "2506.16056", "pdf": "https://arxiv.org/pdf/2506.16056", "abs": "https://arxiv.org/abs/2506.16056", "authors": ["Puchun Liu", "C. L. Philip Chen", "Yubin He", "Tong Zhang"], "title": "CRIA: A Cross-View Interaction and Instance-Adapted Pre-training Framework for Generalizable EEG Representations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The difficulty of extracting deep features from EEG data and effectively\nintegrating information from multiple views presents significant challenges for\ndeveloping a generalizable pretraining framework for EEG representation\nlearning. However, most existing pre-training methods rely solely on the\ncontextual semantics of a single view, failing to capture the complex and\nsynergistic interactions among different perspectives, limiting the\nexpressiveness and generalization of learned representations. To address these\nissues, this paper proposes CRIA, an adaptive framework that utilizes\nvariable-length and variable-channel coding to achieve a unified representation\nof EEG data across different datasets. In this work, we define cross-view\ninformation as the integrated representation that emerges from the interaction\namong temporal, spectral, and spatial views of EEG signals. The model employs a\ncross-attention mechanism to fuse temporal, spectral, and spatial features\neffectively, and combines an attention matrix masking strategy based on the\ninformation bottleneck principle with a novel viewpoint masking pre-training\nscheme. Experimental results on the Temple University EEG corpus and the\nCHB-MIT dataset show that CRIA outperforms existing methods with the same\npre-training conditions, achieving a balanced accuracy of 57.02% for\nmulti-class event classification and 80.03% for anomaly detection, highlighting\nits strong generalization ability.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCRIA\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u89c6\u89d2\u878d\u5408\u548c\u81ea\u9002\u5e94\u7f16\u7801\u89e3\u51b3EEG\u6570\u636e\u9884\u8bad\u7ec3\u4e2d\u7684\u7279\u5f81\u63d0\u53d6\u548c\u4fe1\u606f\u6574\u5408\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u9884\u8bad\u7ec3\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u5355\u4e00\u89c6\u89d2\uff0c\u65e0\u6cd5\u6355\u6349\u591a\u89c6\u89d2\u95f4\u7684\u590d\u6742\u534f\u540c\u4f5c\u7528\uff0c\u9650\u5236\u4e86\u8868\u5f81\u7684\u8868\u8fbe\u529b\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "CRIA\u91c7\u7528\u53d8\u957f\u53d8\u901a\u9053\u7f16\u7801\u7edf\u4e00EEG\u6570\u636e\u8868\u5f81\uff0c\u901a\u8fc7\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u65f6\u7a7a\u8c31\u7279\u5f81\uff0c\u5e76\u7ed3\u5408\u6ce8\u610f\u529b\u77e9\u9635\u63a9\u7801\u548c\u65b0\u9896\u7684\u89c6\u89d2\u63a9\u7801\u9884\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728Temple University EEG\u548cCHB-MIT\u6570\u636e\u96c6\u4e0a\uff0cCRIA\u5728\u76f8\u540c\u9884\u8bad\u7ec3\u6761\u4ef6\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u591a\u7c7b\u4e8b\u4ef6\u5206\u7c7b\u548c\u5f02\u5e38\u68c0\u6d4b\u7684\u5e73\u8861\u51c6\u786e\u7387\u5206\u522b\u4e3a57.02%\u548c80.03%\u3002", "conclusion": "CRIA\u5c55\u73b0\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3aEEG\u8868\u5f81\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9884\u8bad\u7ec3\u6846\u67b6\u3002"}}
{"id": "2506.16065", "pdf": "https://arxiv.org/pdf/2506.16065", "abs": "https://arxiv.org/abs/2506.16065", "authors": ["Geonho Hwang", "Wonyeol Lee", "Yeachan Park", "Sejun Park", "Feras Saad"], "title": "Floating-Point Neural Networks Are Provably Robust Universal Approximators", "categories": ["cs.LG", "cs.LO", "cs.PL"], "comment": "70 pages, 4 figures. Appearing in CAV 2025", "summary": "The classical universal approximation (UA) theorem for neural networks\nestablishes mild conditions under which a feedforward neural network can\napproximate a continuous function $f$ with arbitrary accuracy. A recent result\nshows that neural networks also enjoy a more general interval universal\napproximation (IUA) theorem, in the sense that the abstract interpretation\nsemantics of the network using the interval domain can approximate the direct\nimage map of $f$ (i.e., the result of applying $f$ to a set of inputs) with\narbitrary accuracy. These theorems, however, rest on the unrealistic assumption\nthat the neural network computes over infinitely precise real numbers, whereas\ntheir software implementations in practice compute over finite-precision\nfloating-point numbers. An open question is whether the IUA theorem still holds\nin the floating-point setting.\n  This paper introduces the first IUA theorem for floating-point neural\nnetworks that proves their remarkable ability to perfectly capture the direct\nimage map of any rounded target function $f$, showing no limits exist on their\nexpressiveness. Our IUA theorem in the floating-point setting exhibits material\ndifferences from the real-valued setting, which reflects the fundamental\ndistinctions between these two computational models. This theorem also implies\nsurprising corollaries, which include (i) the existence of provably robust\nfloating-point neural networks; and (ii) the computational completeness of the\nclass of straight-line programs that use only floating-point additions and\nmultiplications for the class of all floating-point programs that halt.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u9002\u7528\u4e8e\u6d6e\u70b9\u795e\u7ecf\u7f51\u7edc\u7684\u533a\u95f4\u901a\u7528\u903c\u8fd1\u5b9a\u7406\uff08IUA\uff09\uff0c\u8bc1\u660e\u5176\u5728\u6d6e\u70b9\u8bbe\u7f6e\u4e0b\u4ecd\u80fd\u5b8c\u7f8e\u903c\u8fd1\u76ee\u6807\u51fd\u6570\u7684\u76f4\u63a5\u56fe\u50cf\u6620\u5c04\u3002", "motivation": "\u7ecf\u5178UA\u5b9a\u7406\u548cIUA\u5b9a\u7406\u57fa\u4e8e\u65e0\u9650\u7cbe\u5ea6\u5b9e\u6570\u5047\u8bbe\uff0c\u800c\u5b9e\u9645\u795e\u7ecf\u7f51\u7edc\u5728\u6d6e\u70b9\u6570\u4e0b\u8fd0\u884c\uff0c\u56e0\u6b64\u9700\u8981\u9a8c\u8bc1IUA\u5b9a\u7406\u5728\u6d6e\u70b9\u8bbe\u7f6e\u4e0b\u7684\u6709\u6548\u6027\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u7814\u7a76\u6d6e\u70b9\u795e\u7ecf\u7f51\u7edc\u5728\u533a\u95f4\u903c\u8fd1\u4e0a\u7684\u80fd\u529b\uff0c\u5e76\u4e0e\u5b9e\u6570\u8bbe\u7f6e\u4e0b\u7684IUA\u5b9a\u7406\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u8bc1\u660e\u4e86\u6d6e\u70b9\u795e\u7ecf\u7f51\u7edc\u5728\u6d6e\u70b9\u8bbe\u7f6e\u4e0b\u4ecd\u5177\u6709\u5f3a\u5927\u7684\u903c\u8fd1\u80fd\u529b\uff0c\u5e76\u5f97\u51fa\u4e24\u4e2a\u91cd\u8981\u63a8\u8bba\uff1a\u5b58\u5728\u53ef\u8bc1\u660e\u9c81\u68d2\u7684\u6d6e\u70b9\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u53ca\u6d6e\u70b9\u52a0\u6cd5\u548c\u4e58\u6cd5\u7684\u8ba1\u7b97\u5b8c\u5907\u6027\u3002", "conclusion": "\u6d6e\u70b9\u795e\u7ecf\u7f51\u7edc\u7684IUA\u5b9a\u7406\u63ed\u793a\u4e86\u5176\u5728\u6d6e\u70b9\u8bbe\u7f6e\u4e0b\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u4e3a\u7406\u8bba\u548c\u5b9e\u8df5\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.16072", "pdf": "https://arxiv.org/pdf/2506.16072", "abs": "https://arxiv.org/abs/2506.16072", "authors": ["Kexuan Wang", "An Liu"], "title": "A Lightweight RL-Driven Deep Unfolding Network for Robust WMMSE Precoding in Massive MU-MIMO-OFDM Systems", "categories": ["cs.LG"], "comment": null, "summary": "Weighted Minimum Mean Square Error (WMMSE) precoding is widely recognized for\nits near-optimal weighted sum rate performance. However, its practical\ndeployment in massive multi-user (MU) multiple-input multiple-output (MIMO)\northogonal frequency-division multiplexing (OFDM) systems is hindered by the\nassumption of perfect channel state information (CSI) and high computational\ncomplexity. To address these issues, we first develop a wideband stochastic\nWMMSE (SWMMSE) algorithm that iteratively maximizes the ergodic weighted\nsum-rate (EWSR) under imperfect CSI. Building on this, we propose a lightweight\nreinforcement learning (RL)-driven deep unfolding (DU) network (RLDDU-Net),\nwhere each SWMMSE iteration is mapped to a network layer. Specifically, its DU\nmodule integrates approximation techniques and leverages beam-domain sparsity\nas well as frequency-domain subcarrier correlation, significantly accelerating\nconvergence and reducing computational overhead. Furthermore, the RL module\nadaptively adjusts the network depth and generates compensation matrices to\nmitigate approximation errors. Simulation results under imperfect CSI\ndemonstrate that RLDDU-Net outperforms existing baselines in EWSR performance\nwhile offering superior computational and convergence efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u968f\u673aWMMSE\u7b97\u6cd5\u548c\u5f3a\u5316\u5b66\u4e60\u9a71\u52a8\u7684\u6df1\u5ea6\u5c55\u5f00\u7f51\u7edc\uff08RLDDU-Net\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u5927\u89c4\u6a21MU-MIMO-OFDM\u7cfb\u7edf\u4e2d\u7684\u52a0\u6743\u548c\u901f\u7387\u6027\u80fd\uff0c\u5e76\u5728\u4e0d\u5b8c\u7f8eCSI\u4e0b\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u3002", "motivation": "\u4f20\u7edfWMMSE\u9884\u7f16\u7801\u5728\u5927\u89c4\u6a21MU-MIMO-OFDM\u7cfb\u7edf\u4e2d\u56e0\u5047\u8bbe\u5b8c\u7f8eCSI\u548c\u9ad8\u8ba1\u7b97\u590d\u6742\u5ea6\u800c\u96be\u4ee5\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u4e86\u5bbd\u9891\u968f\u673aWMMSE\uff08SWMMSE\uff09\u7b97\u6cd5\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51faRLDDU-Net\uff0c\u5c06SWMMSE\u8fed\u4ee3\u6620\u5c04\u5230\u7f51\u7edc\u5c42\uff0c\u5229\u7528\u6ce2\u675f\u57df\u7a00\u758f\u6027\u548c\u9891\u57df\u5b50\u8f7d\u6ce2\u76f8\u5173\u6027\u52a0\u901f\u6536\u655b\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cRLDDU-Net\u5728\u4e0d\u5b8c\u7f8eCSI\u4e0b\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u52a0\u6743\u548c\u901f\u7387\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "RLDDU-Net\u4e3a\u5927\u89c4\u6a21MU-MIMO-OFDM\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16074", "pdf": "https://arxiv.org/pdf/2506.16074", "abs": "https://arxiv.org/abs/2506.16074", "authors": ["Kexuan Wang", "An Liu"], "title": "Joint User Priority and Power Scheduling for QoS-Aware WMMSE Precoding: A Constrained-Actor Attentive-Critic Approach", "categories": ["cs.LG"], "comment": null, "summary": "6G wireless networks are expected to support diverse quality-of-service (QoS)\ndemands while maintaining high energy efficiency. Weighted Minimum Mean Square\nError (WMMSE) precoding with fixed user priorities and transmit power is widely\nrecognized for enhancing overall system performance but lacks flexibility to\nadapt to user-specific QoS requirements and time-varying channel conditions. To\naddress this, we propose a novel constrained reinforcement learning (CRL)\nalgorithm, Constrained-Actor Attentive-Critic (CAAC), which uses a policy\nnetwork to dynamically allocate user priorities and power for WMMSE precoding.\nSpecifically, CAAC integrates a Constrained Stochastic Successive Convex\nApproximation (CSSCA) method to optimize the policy, enabling more effective\nhandling of energy efficiency goals and satisfaction of stochastic non-convex\nQoS constraints compared to traditional and existing CRL methods. Moreover,\nCAAC employs lightweight attention-enhanced Q-networks to evaluate policy\nupdates without prior environment model knowledge. The network architecture not\nonly enhances representational capacity but also boosts learning efficiency.\nSimulation results show that CAAC outperforms baselines in both energy\nefficiency and QoS satisfaction.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\uff08CRL\uff09\u7684\u7b97\u6cd5CAAC\uff0c\u7528\u4e8e\u52a8\u6001\u4f18\u53166G\u7f51\u7edc\u4e2d\u7684\u7528\u6237\u4f18\u5148\u7ea7\u548c\u529f\u7387\u5206\u914d\uff0c\u4ee5\u63d0\u9ad8\u80fd\u6548\u548c\u6ee1\u8db3QoS\u9700\u6c42\u3002", "motivation": "\u4f20\u7edfWMMSE\u9884\u7f16\u7801\u65b9\u6cd5\u5728\u9002\u5e94\u52a8\u6001\u7528\u6237\u9700\u6c42\u548c\u65f6\u53d8\u4fe1\u9053\u6761\u4ef6\u65b9\u9762\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u667a\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faCAAC\u7b97\u6cd5\uff0c\u7ed3\u5408CSSCA\u65b9\u6cd5\u548c\u6ce8\u610f\u529b\u589e\u5f3a\u7684Q\u7f51\u7edc\uff0c\u52a8\u6001\u4f18\u5316\u7b56\u7565\u4ee5\u6ee1\u8db3\u80fd\u6548\u76ee\u6807\u548cQoS\u7ea6\u675f\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cCAAC\u5728\u80fd\u6548\u548cQoS\u6ee1\u8db3\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "CAAC\u4e3a6G\u7f51\u7edc\u4e2d\u7684\u52a8\u6001\u8d44\u6e90\u5206\u914d\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16078", "pdf": "https://arxiv.org/pdf/2506.16078", "abs": "https://arxiv.org/abs/2506.16078", "authors": ["Tianle Gu", "Kexin Huang", "Zongqi Wang", "Yixu Wang", "Jie Li", "Yuanqi Yao", "Yang Yao", "Yujiu Yang", "Yan Teng", "Yingchun Wang"], "title": "Probing the Robustness of Large Language Models Safety to Latent Perturbations", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "comment": null, "summary": "Safety alignment is a key requirement for building reliable Artificial\nGeneral Intelligence. Despite significant advances in safety alignment, we\nobserve that minor latent shifts can still trigger unsafe responses in aligned\nmodels. We argue that this stems from the shallow nature of existing alignment\nmethods, which focus on surface-level refusal behaviors without sufficiently\naltering internal representations. Consequently, small shifts in hidden\nactivations can re-trigger harmful behaviors embedded in the latent space. To\nexplore the robustness of safety alignment to latent perturbations, we\nintroduce a probing method that measures the Negative Log-Likelihood of the\noriginal response generated by the model. This probe quantifies local\nsensitivity in the latent space, serving as a diagnostic tool for identifying\nvulnerable directions. Based on this signal, we construct effective jailbreak\ntrajectories, giving rise to the Activation Steering Attack (ASA). More\nimportantly, these insights offer a principled foundation for improving\nalignment robustness. To this end, we introduce Layer-wise Adversarial Patch\nTraining~(LAPT), a fine-tuning strategy that inject controlled perturbations\ninto hidden representations during training. Experimental results highlight\nthat LAPT strengthen alignment robustness without compromising general\ncapabilities. Our findings reveal fundamental flaws in current alignment\nparadigms and call for representation-level training strategies that move\nbeyond surface-level behavior supervision. Codes and results are available at\nhttps://github.com/Carol-gutianle/LatentSafety.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u73b0\u6709\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u7684\u6d45\u5c42\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u63a2\u6d4b\u6f5c\u5728\u6270\u52a8\u7684\u65b9\u6cd5\uff08ASA\uff09\u548c\u6539\u8fdb\u5bf9\u9f50\u9c81\u68d2\u6027\u7684\u8bad\u7ec3\u7b56\u7565\uff08LAPT\uff09\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u4ec5\u5173\u6ce8\u8868\u9762\u62d2\u7edd\u884c\u4e3a\uff0c\u672a\u5145\u5206\u6539\u53d8\u5185\u90e8\u8868\u5f81\uff0c\u5bfc\u81f4\u5fae\u5c0f\u6f5c\u5728\u504f\u79fb\u4ecd\u53ef\u80fd\u89e6\u53d1\u4e0d\u5b89\u5168\u54cd\u5e94\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u8d1f\u5bf9\u6570\u4f3c\u7136\u7684\u63a2\u6d4b\u65b9\u6cd5\u91cf\u5316\u6f5c\u5728\u7a7a\u95f4\u654f\u611f\u6027\uff0c\u5e76\u63d0\u51fa\u5c42\u5bf9\u6297\u8865\u4e01\u8bad\u7ec3\uff08LAPT\uff09\u6539\u8fdb\u5bf9\u9f50\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLAPT\u80fd\u589e\u5f3a\u5bf9\u9f50\u9c81\u68d2\u6027\u4e14\u4e0d\u5f71\u54cd\u6a21\u578b\u901a\u7528\u80fd\u529b\u3002", "conclusion": "\u5f53\u524d\u5bf9\u9f50\u8303\u5f0f\u5b58\u5728\u6839\u672c\u7f3a\u9677\uff0c\u9700\u8f6c\u5411\u8868\u5f81\u7ea7\u8bad\u7ec3\u7b56\u7565\u3002"}}
{"id": "2506.16096", "pdf": "https://arxiv.org/pdf/2506.16096", "abs": "https://arxiv.org/abs/2506.16096", "authors": ["Qianqian Liao", "Wuque Cai", "Hongze Sun", "Dongze Liu", "Duo Chen", "Dezhong Yao", "Daqing Guo"], "title": "A Brain-to-Population Graph Learning Framework for Diagnosing Brain Disorders", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 7 figures, 13 tables; this paper has been submitted for\n  possible publication", "summary": "Recent developed graph-based methods for diagnosing brain disorders using\nfunctional connectivity highly rely on predefined brain atlases, but overlook\nthe rich information embedded within atlases and the confounding effects of\nsite and phenotype variability. To address these challenges, we propose a\ntwo-stage Brain-to-Population Graph Learning (B2P-GL) framework that integrates\nthe semantic similarity of brain regions and condition-based population graph\nmodeling. In the first stage, termed brain representation learning, we leverage\nbrain atlas knowledge from GPT-4 to enrich the graph representation and refine\nthe brain graph through an adaptive node reassignment graph attention network.\nIn the second stage, termed population disorder diagnosis, phenotypic data is\nincorporated into population graph construction and feature fusion to mitigate\nconfounding effects and enhance diagnosis performance. Experiments on the ABIDE\nI, ADHD-200, and Rest-meta-MDD datasets show that B2P-GL outperforms\nstate-of-the-art methods in prediction accuracy while enhancing\ninterpretability. Overall, our proposed framework offers a reliable and\npersonalized approach to brain disorder diagnosis, advancing clinical\napplicability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u8111\u56fe\u5b66\u4e60\u6846\u67b6\uff08B2P-GL\uff09\uff0c\u7ed3\u5408\u8111\u533a\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u57fa\u4e8e\u6761\u4ef6\u7684\u7fa4\u4f53\u56fe\u5efa\u6a21\uff0c\u63d0\u5347\u8111\u969c\u788d\u8bca\u65ad\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u56fe\u7684\u8111\u969c\u788d\u8bca\u65ad\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u8111\u56fe\u8c31\uff0c\u4f46\u5ffd\u7565\u4e86\u56fe\u8c31\u4e2d\u7684\u4e30\u5bcc\u4fe1\u606f\u53ca\u7ad9\u70b9\u548c\u8868\u578b\u53d8\u5f02\u7684\u6df7\u6742\u6548\u5e94\u3002", "method": "\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7GPT-4\u77e5\u8bc6\u4e30\u5bcc\u8111\u56fe\u8868\u793a\uff0c\u4f7f\u7528\u81ea\u9002\u5e94\u8282\u70b9\u91cd\u5206\u914d\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff1b\u7b2c\u4e8c\u9636\u6bb5\u7ed3\u5408\u8868\u578b\u6570\u636e\u6784\u5efa\u7fa4\u4f53\u56fe\u5e76\u878d\u5408\u7279\u5f81\u3002", "result": "\u5728ABIDE I\u3001ADHD-200\u548cRest-meta-MDD\u6570\u636e\u96c6\u4e0a\uff0cB2P-GL\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "B2P-GL\u4e3a\u8111\u969c\u788d\u8bca\u65ad\u63d0\u4f9b\u4e86\u53ef\u9760\u4e14\u4e2a\u6027\u5316\u7684\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u4e34\u5e8a\u9002\u7528\u6027\u3002"}}
{"id": "2506.16110", "pdf": "https://arxiv.org/pdf/2506.16110", "abs": "https://arxiv.org/abs/2506.16110", "authors": ["Langzhang Liang", "Fanchen Bu", "Zixing Song", "Zenglin Xu", "Shirui Pan", "Kijung Shin"], "title": "Mitigating Over-Squashing in Graph Neural Networks by Spectrum-Preserving Sparsification", "categories": ["cs.LG"], "comment": "Published as a conference paper at ICML 2025", "summary": "The message-passing paradigm of Graph Neural Networks often struggles with\nexchanging information across distant nodes typically due to structural\nbottlenecks in certain graph regions, a limitation known as\n\\textit{over-squashing}. To reduce such bottlenecks, \\textit{graph rewiring},\nwhich modifies graph topology, has been widely used. However, existing graph\nrewiring techniques often overlook the need to preserve critical properties of\nthe original graph, e.g., \\textit{spectral properties}. Moreover, many\napproaches rely on increasing edge count to improve connectivity, which\nintroduces significant computational overhead and exacerbates the risk of\nover-smoothing. In this paper, we propose a novel graph rewiring method that\nleverages \\textit{spectrum-preserving} graph \\textit{sparsification}, for\nmitigating over-squashing. Our method generates graphs with enhanced\nconnectivity while maintaining sparsity and largely preserving the original\ngraph spectrum, effectively balancing structural bottleneck reduction and graph\nproperty preservation. Experimental results validate the effectiveness of our\napproach, demonstrating its superiority over strong baseline methods in\nclassification accuracy and retention of the Laplacian spectrum.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8c31\u4fdd\u7559\u7684\u56fe\u7a00\u758f\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u7f13\u89e3\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u8fc7\u5ea6\u6324\u538b\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u56fe\u7684\u7a00\u758f\u6027\u548c\u8c31\u7279\u6027\u3002", "motivation": "\u73b0\u6709\u56fe\u91cd\u5e03\u7ebf\u65b9\u6cd5\u5e38\u5ffd\u7565\u4fdd\u7559\u56fe\u7684\u8c31\u7279\u6027\uff0c\u4e14\u901a\u8fc7\u589e\u52a0\u8fb9\u6570\u6539\u5584\u8fde\u901a\u6027\u4f1a\u5e26\u6765\u8ba1\u7b97\u5f00\u9500\u548c\u8fc7\u5ea6\u5e73\u6ed1\u98ce\u9669\u3002", "method": "\u5229\u7528\u8c31\u4fdd\u7559\u7684\u56fe\u7a00\u758f\u5316\u6280\u672f\uff0c\u751f\u6210\u5177\u6709\u589e\u5f3a\u8fde\u901a\u6027\u4f46\u4ecd\u4fdd\u6301\u7a00\u758f\u6027\u548c\u539f\u59cb\u56fe\u8c31\u7684\u56fe\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5206\u7c7b\u51c6\u786e\u6027\u548c\u62c9\u666e\u62c9\u65af\u8c31\u4fdd\u7559\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u5e73\u8861\u4e86\u7ed3\u6784\u74f6\u9888\u51cf\u5c11\u548c\u56fe\u7279\u6027\u4fdd\u7559\uff0c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2506.16170", "pdf": "https://arxiv.org/pdf/2506.16170", "abs": "https://arxiv.org/abs/2506.16170", "authors": ["Simardeep Singh"], "title": "From Teacher to Student: Tracking Memorization Through Model Distillation", "categories": ["cs.LG", "cs.AI"], "comment": "5 pages, in-proceedings L2M2 @ ACL 2025", "summary": "Large language models (LLMs) are known to memorize parts of their training\ndata, raising important concerns around privacy and security. While previous\nresearch has focused on studying memorization in pre-trained models, much less\nis known about how knowledge distillation (KD) affects memorization.In this\nstudy, we explore how different KD methods influence the memorization of\nfine-tuned task data when a large teacher model is distilled into smaller\nstudent variants.This study demonstrates that distilling a larger teacher\nmodel, fine-tuned on a dataset, into a smaller variant not only lowers\ncomputational costs and model size but also significantly reduces the\nmemorization risks compared to standard fine-tuning approaches.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u5c06\u5927\u578b\u6559\u5e08\u6a21\u578b\u84b8\u998f\u4e3a\u5c0f\u578b\u5b66\u751f\u6a21\u578b\uff0c\u4e0d\u4ec5\u80fd\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u548c\u6a21\u578b\u5927\u5c0f\uff0c\u8fd8\u80fd\u663e\u8457\u51cf\u5c11\u8bb0\u5fc6\u98ce\u9669\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f1a\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\uff0c\u5f15\u53d1\u9690\u79c1\u548c\u5b89\u5168\u95ee\u9898\u3002\u6b64\u524d\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u8bb0\u5fc6\u884c\u4e3a\uff0c\u4f46\u77e5\u8bc6\u84b8\u998f\u5bf9\u8bb0\u5fc6\u7684\u5f71\u54cd\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u7814\u7a76\u63a2\u7d22\u4e86\u4e0d\u540c\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u5bf9\u5fae\u8c03\u4efb\u52a1\u6570\u636e\u8bb0\u5fc6\u7684\u5f71\u54cd\uff0c\u6bd4\u8f83\u4e86\u6807\u51c6\u5fae\u8c03\u4e0e\u84b8\u998f\u65b9\u6cd5\u7684\u5dee\u5f02\u3002", "result": "\u84b8\u998f\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u6a21\u578b\u5bf9\u8bad\u7ec3\u6570\u636e\u7684\u8bb0\u5fc6\u98ce\u9669\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u8ba1\u7b97\u6210\u672c\u548c\u6a21\u578b\u5927\u5c0f\u3002", "conclusion": "\u77e5\u8bc6\u84b8\u998f\u662f\u4e00\u79cd\u6709\u6548\u964d\u4f4e\u8bb0\u5fc6\u98ce\u9669\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u9690\u79c1\u654f\u611f\u573a\u666f\u3002"}}
{"id": "2506.16174", "pdf": "https://arxiv.org/pdf/2506.16174", "abs": "https://arxiv.org/abs/2506.16174", "authors": ["Ismo Horppu", "Frederick Ayala", "Erlin Gulbenkoglu"], "title": "Hallucination Level of Artificial Intelligence Whisperer: Case Speech Recognizing Pantterinousut Rap Song", "categories": ["cs.LG", "I.5.4"], "comment": "15 pages, 10 figures", "summary": "All languages are peculiar. Some of them are considered more challenging to\nunderstand than others. The Finnish Language is known to be a complex language.\nAlso, when languages are used by artists, the pronunciation and meaning might\nbe more tricky to understand. Therefore, we are putting AI to a fun, yet\nchallenging trial: translating a Finnish rap song to text. We will compare the\nFaster Whisperer algorithm and YouTube's internal speech-to-text functionality.\nThe reference truth will be Finnish rap lyrics, which the main author's little\nbrother, Mc Timo, has written. Transcribing the lyrics will be challenging\nbecause the artist raps over synth music player by Syntikka Janne. The\nhallucination level and mishearing of AI speech-to-text extractions will be\nmeasured by comparing errors made against the original Finnish lyrics. The\nerror function is informal but still works for our case.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\u5728\u7ffb\u8bd1\u82ac\u5170\u8bf4\u5531\u6b4c\u66f2\u65f6\u7684\u8868\u73b0\uff0c\u6bd4\u8f83\u4e86Faster Whisperer\u7b97\u6cd5\u548cYouTube\u7684\u8bed\u97f3\u8f6c\u6587\u5b57\u529f\u80fd\uff0c\u5e76\u4ee5\u82ac\u5170\u8bf4\u5531\u6b4c\u8bcd\u4e3a\u53c2\u8003\u6807\u51c6\u3002", "motivation": "\u82ac\u5170\u8bed\u590d\u6742\u4e14\u827a\u672f\u5bb6\u4f7f\u7528\u65f6\u66f4\u96be\u4ee5\u7406\u89e3\uff0c\u56e0\u6b64\u6d4b\u8bd5AI\u5728\u7ffb\u8bd1\u82ac\u5170\u8bf4\u5531\u6b4c\u66f2\u65f6\u7684\u80fd\u529b\u5177\u6709\u6311\u6218\u6027\u548c\u8da3\u5473\u6027\u3002", "method": "\u4f7f\u7528Faster Whisperer\u7b97\u6cd5\u548cYouTube\u7684\u8bed\u97f3\u8f6c\u6587\u5b57\u529f\u80fd\u7ffb\u8bd1\u82ac\u5170\u8bf4\u5531\u6b4c\u66f2\uff0c\u5e76\u4e0e\u539f\u59cb\u6b4c\u8bcd\u5bf9\u6bd4\u3002", "result": "\u901a\u8fc7\u6bd4\u8f83AI\u8f6c\u5f55\u7684\u9519\u8bef\u7387\u6765\u8861\u91cf\u5176\u8868\u73b0\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aAI\u5728\u590d\u6742\u8bed\u8a00\u548c\u827a\u672f\u8868\u8fbe\u4e2d\u7684\u8bed\u97f3\u8bc6\u522b\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u8da3\u7684\u6848\u4f8b\u3002"}}
{"id": "2506.16196", "pdf": "https://arxiv.org/pdf/2506.16196", "abs": "https://arxiv.org/abs/2506.16196", "authors": ["Xun Wang", "Jing Xu", "Franziska Boenisch", "Michael Backes", "Christopher A. Choquette-Choo", "Adam Dziedzic"], "title": "Efficient and Privacy-Preserving Soft Prompt Transfer for LLMs", "categories": ["cs.LG"], "comment": "Accepted at ICML2025", "summary": "Prompting has become a dominant paradigm for adapting large language models\n(LLMs). While discrete (textual) prompts are widely used for their\ninterpretability, soft (parameter) prompts have recently gained traction in\nAPIs. This is because they can encode information from more training samples\nwhile minimizing the user's token usage, leaving more space in the context\nwindow for task-specific input. However, soft prompts are tightly coupled to\nthe LLM they are tuned on, limiting their generalization to other LLMs. This\nconstraint is particularly problematic for efficiency and privacy: (1) tuning\nprompts on each LLM incurs high computational costs, especially as LLMs\ncontinue to grow in size. Additionally, (2) when the LLM is hosted externally,\nsoft prompt tuning often requires sharing private data with the LLM provider.\nFor instance, this is the case with the NVIDIA NeMo API. To address these\nissues, we propose POST (Privacy Of Soft prompt Transfer), a framework that\nenables private tuning of soft prompts on a small model and subsequently\ntransfers these prompts to a larger LLM. POST uses knowledge distillation to\nderive a small model directly from the large LLM to improve prompt\ntransferability, tunes the soft prompt locally, optionally with differential\nprivacy guarantees, and transfers it back to the larger LLM using a small\npublic dataset. Our experiments show that POST reduces computational costs,\npreserves privacy, and effectively transfers high-utility soft prompts.", "AI": {"tldr": "POST\u6846\u67b6\u901a\u8fc7\u5728\u5c0f\u6a21\u578b\u4e0a\u79c1\u6709\u8c03\u4f18\u8f6f\u63d0\u793a\u5e76\u8f6c\u79fb\u5230\u5927\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u8ba1\u7b97\u6210\u672c\u548c\u9690\u79c1\u95ee\u9898\u3002", "motivation": "\u8f6f\u63d0\u793a\u4e0e\u5927\u6a21\u578b\u7d27\u5bc6\u8026\u5408\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u9690\u79c1\u98ce\u9669\u5927\u3002", "method": "POST\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u4ece\u5c0f\u6a21\u578b\u8c03\u4f18\u8f6f\u63d0\u793a\uff0c\u53ef\u9009\u5dee\u5206\u9690\u79c1\uff0c\u518d\u7528\u516c\u5171\u6570\u636e\u96c6\u8f6c\u79fb\u56de\u5927\u6a21\u578b\u3002", "result": "POST\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u4fdd\u62a4\u4e86\u9690\u79c1\uff0c\u5e76\u6210\u529f\u8f6c\u79fb\u4e86\u9ad8\u6548\u8f6f\u63d0\u793a\u3002", "conclusion": "POST\u4e3a\u8f6f\u63d0\u793a\u8c03\u4f18\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u9690\u79c1\u5b89\u5168\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16216", "pdf": "https://arxiv.org/pdf/2506.16216", "abs": "https://arxiv.org/abs/2506.16216", "authors": ["Charbel Bou Chaaya", "Abanoub M. Girgis", "Mehdi Bennis"], "title": "From Pixels to CSI: Distilling Latent Dynamics For Efficient Wireless Resource Management", "categories": ["cs.LG"], "comment": null, "summary": "In this work, we aim to optimize the radio resource management of a\ncommunication system between a remote controller and its device, whose state is\nrepresented through image frames, without compromising the performance of the\ncontrol task. We propose a novel machine learning (ML) technique to jointly\nmodel and predict the dynamics of the control system as well as the wireless\npropagation environment in latent space. Our method leverages two coupled\njoint-embedding predictive architectures (JEPAs): a control JEPA models the\ncontrol dynamics and guides the predictions of a wireless JEPA, which captures\nthe dynamics of the device's channel state information (CSI) through\ncross-modal conditioning. We then train a deep reinforcement learning (RL)\nalgorithm to derive a control policy from latent control dynamics and a power\npredictor to estimate scheduling intervals with favorable channel conditions\nbased on latent CSI representations. As such, the controller minimizes the\nusage of radio resources by utilizing the coupled JEPA networks to imagine the\ndevice's trajectory in latent space. We present simulation results on synthetic\nmultimodal data and show that our proposed approach reduces transmit power by\nover 50% while maintaining control performance comparable to baseline methods\nthat do not account for wireless optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u5efa\u6a21\u63a7\u5236\u52a8\u6001\u548c\u65e0\u7ebf\u4f20\u64ad\u73af\u5883\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u8026\u5408\u7684JEPA\u7f51\u7edc\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u65e0\u7ebf\u7535\u8d44\u6e90\u7ba1\u7406\uff0c\u51cf\u5c1150%\u4ee5\u4e0a\u53d1\u5c04\u529f\u7387\u3002", "motivation": "\u4f18\u5316\u8fdc\u7a0b\u63a7\u5236\u5668\u4e0e\u8bbe\u5907\u95f4\u7684\u65e0\u7ebf\u7535\u8d44\u6e90\u7ba1\u7406\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u63a7\u5236\u4efb\u52a1\u7684\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u4e24\u4e2a\u8026\u5408\u7684JEPA\u7f51\u7edc\u5206\u522b\u5efa\u6a21\u63a7\u5236\u52a8\u6001\u548c\u65e0\u7ebf\u4f20\u64ad\u73af\u5883\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u751f\u6210\u63a7\u5236\u7b56\u7565\u548c\u529f\u7387\u9884\u6d4b\u5668\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u53d1\u5c04\u529f\u7387\u51cf\u5c1150%\u4ee5\u4e0a\uff0c\u4e14\u63a7\u5236\u6027\u80fd\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u4f18\u5316\u4e86\u65e0\u7ebf\u7535\u8d44\u6e90\u4f7f\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a7\u5236\u6027\u80fd\u3002"}}
{"id": "2506.16234", "pdf": "https://arxiv.org/pdf/2506.16234", "abs": "https://arxiv.org/abs/2506.16234", "authors": ["Prakhar Verma", "David Arbour", "Sunav Choudhary", "Harshita Chopra", "Arno Solin", "Atanu R. Sinha"], "title": "Think Global, Act Local: Bayesian Causal Discovery with Language Models in Sequential Data", "categories": ["cs.LG"], "comment": "24 pages, preprint", "summary": "Causal discovery from observational data typically assumes full access to\ndata and availability of domain experts. In practice, data often arrive in\nbatches, and expert knowledge is scarce. Language Models (LMs) offer a\nsurrogate but come with their own issues-hallucinations, inconsistencies, and\nbias. We present BLANCE (Bayesian LM-Augmented Causal Estimation)-a hybrid\nBayesian framework that bridges these gaps by adaptively integrating sequential\nbatch data with LM-derived noisy, expert knowledge while accounting for both\ndata-induced and LM-induced biases. Our proposed representation shift from\nDirected Acyclic Graph (DAG) to Partial Ancestral Graph (PAG) accommodates\nambiguities within a coherent Bayesian framework, allowing grounding the global\nLM knowledge in local observational data. To guide LM interaction, we use a\nsequential optimization scheme that adaptively queries the most informative\nedges. Across varied datasets, BLANCE outperforms prior work in structural\naccuracy and extends to Bayesian parameter estimation, showing robustness to LM\nnoise.", "AI": {"tldr": "BLANCE\u662f\u4e00\u4e2a\u6df7\u5408\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6574\u5408\u5e8f\u5217\u6279\u6b21\u6570\u636e\u548c\u8bed\u8a00\u6a21\u578b\uff08LM\uff09\u63d0\u4f9b\u7684\u566a\u58f0\u4e13\u5bb6\u77e5\u8bc6\uff0c\u89e3\u51b3\u56e0\u679c\u53d1\u73b0\u4e2d\u7684\u6570\u636e\u6279\u6b21\u548c\u4e13\u5bb6\u77e5\u8bc6\u7a00\u7f3a\u95ee\u9898\u3002", "motivation": "\u5b9e\u8df5\u4e2d\uff0c\u6570\u636e\u901a\u5e38\u5206\u6279\u5230\u8fbe\u4e14\u4e13\u5bb6\u77e5\u8bc6\u7a00\u7f3a\uff0c\u800c\u8bed\u8a00\u6a21\u578b\u867d\u53ef\u4f5c\u4e3a\u66ff\u4ee3\u4f46\u5b58\u5728\u5e7b\u89c9\u3001\u4e0d\u4e00\u81f4\u6027\u548c\u504f\u89c1\u95ee\u9898\u3002", "method": "BLANCE\u91c7\u7528\u4ece\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u5230\u90e8\u5206\u7956\u5148\u56fe\uff08PAG\uff09\u7684\u8868\u793a\u8f6c\u6362\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u6846\u67b6\u81ea\u9002\u5e94\u6574\u5408\u6570\u636e\u548cLM\u77e5\u8bc6\uff0c\u5e76\u901a\u8fc7\u5e8f\u5217\u4f18\u5316\u65b9\u6848\u6307\u5bfcLM\u4ea4\u4e92\u3002", "result": "BLANCE\u5728\u7ed3\u6784\u51c6\u786e\u6027\u548c\u8d1d\u53f6\u65af\u53c2\u6570\u4f30\u8ba1\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5bf9LM\u566a\u58f0\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "BLANCE\u901a\u8fc7\u7ed3\u5408\u6570\u636e\u548cLM\u77e5\u8bc6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u56e0\u679c\u53d1\u73b0\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.16237", "pdf": "https://arxiv.org/pdf/2506.16237", "abs": "https://arxiv.org/abs/2506.16237", "authors": ["Jacopo Iollo", "Geoffroy Oudoumanessah", "Carole Lartizien", "Michel Dojat", "Florence Forbes"], "title": "Active MRI Acquisition with Diffusion Guided Bayesian Experimental Design", "categories": ["cs.LG"], "comment": null, "summary": "A key challenge in maximizing the benefits of Magnetic Resonance Imaging\n(MRI) in clinical settings is to accelerate acquisition times without\nsignificantly degrading image quality. This objective requires a balance\nbetween under-sampling the raw k-space measurements for faster acquisitions and\ngathering sufficient raw information for high-fidelity image reconstruction and\nanalysis tasks. To achieve this balance, we propose to use sequential Bayesian\nexperimental design (BED) to provide an adaptive and task-dependent selection\nof the most informative measurements. Measurements are sequentially augmented\nwith new samples selected to maximize information gain on a posterior\ndistribution over target images. Selection is performed via a gradient-based\noptimization of a design parameter that defines a subsampling pattern. In this\nwork, we introduce a new active BED procedure that leverages diffusion-based\ngenerative models to handle the high dimensionality of the images and employs\nstochastic optimization to select among a variety of patterns while meeting the\nacquisition process constraints and budget. So doing, we show how our setting\ncan optimize, not only standard image reconstruction, but also any associated\nimage analysis task. The versatility and performance of our approach are\ndemonstrated on several MRI acquisitions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u5b9e\u9a8c\u8bbe\u8ba1\u7684MRI\u52a0\u901f\u91c7\u96c6\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9009\u62e9\u4fe1\u606f\u91cf\u6700\u5927\u7684\u6d4b\u91cf\u70b9\uff0c\u5e73\u8861\u91c7\u96c6\u901f\u5ea6\u4e0e\u56fe\u50cf\u8d28\u91cf\u3002", "motivation": "\u5728\u4e34\u5e8aMRI\u4e2d\uff0c\u5982\u4f55\u5728\u52a0\u901f\u91c7\u96c6\u65f6\u95f4\u7684\u540c\u65f6\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u662f\u5173\u952e\u6311\u6218\u3002", "method": "\u91c7\u7528\u987a\u5e8f\u8d1d\u53f6\u65af\u5b9e\u9a8c\u8bbe\u8ba1\uff08BED\uff09\u548c\u6269\u6563\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u68af\u5ea6\u4f18\u5316\u9009\u62e9\u5b50\u91c7\u6837\u6a21\u5f0f\u3002", "result": "\u65b9\u6cd5\u5728\u591a\u79cdMRI\u91c7\u96c6\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u548c\u591a\u529f\u80fd\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u4f18\u5316\u4e86\u56fe\u50cf\u91cd\u5efa\uff0c\u8fd8\u80fd\u9002\u5e94\u591a\u79cd\u56fe\u50cf\u5206\u6790\u4efb\u52a1\u3002"}}
{"id": "2506.16243", "pdf": "https://arxiv.org/pdf/2506.16243", "abs": "https://arxiv.org/abs/2506.16243", "authors": ["Abdulvahap Mutlu", "\u015eeng\u00fcl Do\u011fan", "T\u00fcrker Tuncer"], "title": "Synthetic ALS-EEG Data Augmentation for ALS Diagnosis Using Conditional WGAN with Weight Clipping", "categories": ["cs.LG", "cs.AI"], "comment": "The code is available on GitHub:\n  https://github.com/abdulvahapmutlu/als-synthetic-data-augmentation-wgan", "summary": "Amyotrophic Lateral Sclerosis (ALS) is a rare neurodegenerative disease, and\nhigh-quality EEG data from ALS patients are scarce. This data scarcity, coupled\nwith severe class imbalance between ALS and healthy control recordings, poses a\nchallenge for training reliable machine learning classifiers. In this work, we\naddress these issues by generating synthetic EEG signals for ALS patients using\na Conditional Wasserstein Generative Adversarial Network (CWGAN). We train\nCWGAN on a private EEG dataset (ALS vs. non-ALS) to learn the distribution of\nALS EEG signals and produce realistic synthetic samples. We preprocess and\nnormalize EEG recordings, and train a CWGAN model to generate synthetic ALS\nsignals. The CWGAN architecture and training routine are detailed, with key\nhyperparameters chosen for stable training. Qualitative evaluation of generated\nsignals shows that they closely mimic real ALS EEG patterns. The CWGAN training\nconverged with generator and discriminator loss curves stabilizing, indicating\nsuccessful learning. The synthetic EEG signals appear realistic and have\npotential use as augmented data for training classifiers, helping to mitigate\nclass imbalance and improve ALS detection accuracy. We discuss how this\napproach can facilitate data sharing and enhance diagnostic models.", "AI": {"tldr": "\u4f7f\u7528CWGAN\u751f\u6210ALS\u60a3\u8005\u7684\u5408\u6210EEG\u4fe1\u53f7\uff0c\u4ee5\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u5347\u5206\u7c7b\u5668\u6027\u80fd\u3002", "motivation": "ALS\u60a3\u8005\u7684EEG\u6570\u636e\u7a00\u7f3a\u4e14\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u5bfc\u81f4\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u8bad\u7ec3\u56f0\u96be\u3002", "method": "\u91c7\u7528CWGAN\u6a21\u578b\uff0c\u57fa\u4e8e\u79c1\u4ebaEEG\u6570\u636e\u96c6\u751f\u6210\u5408\u6210ALS\u4fe1\u53f7\uff0c\u5e76\u8fdb\u884c\u9884\u5904\u7406\u548c\u5f52\u4e00\u5316\u3002", "result": "\u751f\u6210\u7684\u5408\u6210\u4fe1\u53f7\u4e0e\u771f\u5b9eALS EEG\u6a21\u5f0f\u76f8\u4f3c\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u7a33\u5b9a\uff0c\u53ef\u7528\u4e8e\u6570\u636e\u589e\u5f3a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u6570\u636e\u5171\u4eab\u548c\u8bca\u65ad\u6a21\u578b\u6539\u8fdb\uff0c\u63d0\u5347ALS\u68c0\u6d4b\u51c6\u786e\u6027\u3002"}}
{"id": "2506.16253", "pdf": "https://arxiv.org/pdf/2506.16253", "abs": "https://arxiv.org/abs/2506.16253", "authors": ["Hadar Tal", "Oron Sabag"], "title": "Optimal Online Bookmaking for Any Number of Outcomes", "categories": ["cs.LG", "cs.GT", "cs.IT", "math.IT", "math.OC"], "comment": "Accepted for presentation at the Conference on Learning Theory (COLT)\n  2025", "summary": "We study the Online Bookmaking problem, where a bookmaker dynamically updates\nbetting odds on the possible outcomes of an event. In each betting round, the\nbookmaker can adjust the odds based on the cumulative betting behavior of\ngamblers, aiming to maximize profit while mitigating potential loss. We show\nthat for any event and any number of betting rounds, in a worst-case setting\nover all possible gamblers and outcome realizations, the bookmaker's optimal\nloss is the largest root of a simple polynomial. Our solution shows that\nbookmakers can be as fair as desired while avoiding financial risk, and the\nexplicit characterization reveals an intriguing relation between the\nbookmaker's regret and Hermite polynomials. We develop an efficient algorithm\nthat computes the optimal bookmaking strategy: when facing an optimal gambler,\nthe algorithm achieves the optimal loss, and in rounds where the gambler is\nsuboptimal, it reduces the achieved loss to the optimal opportunistic loss, a\nnotion that is related to subgame perfect Nash equilibrium. The key technical\ncontribution to achieve these results is an explicit characterization of the\nBellman-Pareto frontier, which unifies the dynamic programming updates for\nBellman's value function with the multi-criteria optimization framework of the\nPareto frontier in the context of vector repeated games.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u7ebf\u535a\u5f69\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u8d54\u7387\u6700\u5927\u5316\u5229\u6da6\u5e76\u51cf\u5c11\u6f5c\u5728\u635f\u5931\uff0c\u8bc1\u660e\u4e86\u6700\u4f18\u635f\u5931\u662f\u7b80\u5355\u591a\u9879\u5f0f\u7684\u6700\u5927\u6839\uff0c\u5e76\u5f00\u53d1\u4e86\u9ad8\u6548\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76\u5728\u7ebf\u535a\u5f69\u4e2d\u5e84\u5bb6\u5982\u4f55\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u8d54\u7387\u6765\u5e73\u8861\u516c\u5e73\u6027\u548c\u8d22\u52a1\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u591a\u9879\u5f0f\u5206\u6790\u548c\u52a8\u6001\u89c4\u5212\uff0c\u7ed3\u5408Bellman-Pareto\u524d\u6cbf\u7684\u663e\u5f0f\u8868\u5f81\uff0c\u5f00\u53d1\u4e86\u9ad8\u6548\u7b97\u6cd5\u3002", "result": "\u5e84\u5bb6\u53ef\u4ee5\u5728\u907f\u514d\u8d22\u52a1\u98ce\u9669\u7684\u540c\u65f6\u5b9e\u73b0\u516c\u5e73\u6027\uff0c\u6700\u4f18\u635f\u5931\u4e3a\u591a\u9879\u5f0f\u7684\u6700\u5927\u6839\u3002", "conclusion": "\u8bba\u6587\u63ed\u793a\u4e86\u5e84\u5bb6\u540e\u6094\u4e0eHermite\u591a\u9879\u5f0f\u7684\u5173\u7cfb\uff0c\u5e76\u63d0\u4f9b\u4e86\u9ad8\u6548\u7b97\u6cd5\u4ee5\u5e94\u5bf9\u6700\u4f18\u548c\u975e\u6700\u4f18\u8d4c\u5f92\u7684\u7b56\u7565\u3002"}}
{"id": "2506.16288", "pdf": "https://arxiv.org/pdf/2506.16288", "abs": "https://arxiv.org/abs/2506.16288", "authors": ["Leo Gagnon", "Eric Elmoznino", "Sarthak Mittal", "Tom Marty", "Tejas Kasetty", "Dhanya Sridhar", "Guillaume Lajoie"], "title": "Next-Token Prediction Should be Ambiguity-Sensitive: A Meta-Learning Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The rapid adaptation ability of auto-regressive foundation models is often\nattributed to the diversity of their pre-training data. This is because, from a\nBayesian standpoint, minimizing prediction error in such settings requires\nintegrating over all plausible latent hypotheses consistent with observations.\nWhile this behavior is desirable in principle, it often proves too ambitious in\npractice: under high ambiguity, the number of plausible latent alternatives\nmakes Bayes-optimal prediction computationally intractable. Cognitive science\nhas long recognized this limitation, suggesting that under such conditions,\nheuristics or information-seeking strategies are preferable to exhaustive\ninference. Translating this insight to next-token prediction, we hypothesize\nthat low- and high-ambiguity predictions pose different computational demands,\nmaking ambiguity-agnostic next-token prediction a detrimental inductive bias.\nTo test this, we introduce MetaHMM, a synthetic sequence meta-learning\nbenchmark with rich compositional structure and a tractable Bayesian oracle. We\nshow that Transformers indeed struggle with high-ambiguity predictions across\nmodel sizes. Motivated by cognitive theories, we propose a method to convert\npre-trained models into Monte Carlo predictors that decouple task inference\nfrom token prediction. Preliminary results show substantial gains in ambiguous\ncontexts through improved capacity allocation and test-time scalable inference,\nthough challenges remain.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u81ea\u56de\u5f52\u57fa\u7840\u6a21\u578b\u5728\u9884\u6d4b\u9ad8\u6a21\u7cca\u6027\u4e0a\u4e0b\u6587\u65f6\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u9884\u6d4b\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u53d1\u73b0\u81ea\u56de\u5f52\u6a21\u578b\u5728\u9ad8\u6a21\u7cca\u6027\u9884\u6d4b\u4e2d\u7684\u8ba1\u7b97\u56f0\u96be\uff0c\u5e76\u501f\u9274\u8ba4\u77e5\u79d1\u5b66\u7684\u542f\u53d1\u5f0f\u7b56\u7565\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51faMetaHMM\u5408\u6210\u5e8f\u5217\u5143\u5b66\u4e60\u57fa\u51c6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5c06\u9884\u8bad\u7ec3\u6a21\u578b\u8f6c\u5316\u4e3a\u8499\u7279\u5361\u6d1b\u9884\u6d4b\u5668\u7684\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8499\u7279\u5361\u6d1b\u9884\u6d4b\u5668\u5728\u9ad8\u6a21\u7cca\u6027\u4e0a\u4e0b\u6587\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4f46\u4ecd\u5b58\u5728\u6311\u6218\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\uff0c\u901a\u8fc7\u4efb\u52a1\u63a8\u65ad\u4e0e\u4ee4\u724c\u9884\u6d4b\u7684\u89e3\u8026\uff0c\u53ef\u4ee5\u4f18\u5316\u6a21\u578b\u5728\u9ad8\u6a21\u7cca\u6027\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2506.16310", "pdf": "https://arxiv.org/pdf/2506.16310", "abs": "https://arxiv.org/abs/2506.16310", "authors": ["Pranav Pawar", "Akshansh Dwivedi", "Jenish Boricha", "Himanshu Gohil", "Aditya Dubey"], "title": "Optimizing Multilingual Text-To-Speech with Accents & Emotions", "categories": ["cs.LG", "cs.HC", "cs.SD", "eess.AS"], "comment": "12 pages, 8 figures", "summary": "State-of-the-art text-to-speech (TTS) systems realize high naturalness in\nmonolingual environments, synthesizing speech with correct multilingual accents\n(especially for Indic languages) and context-relevant emotions still poses\ndifficulty owing to cultural nuance discrepancies in current frameworks. This\npaper introduces a new TTS architecture integrating accent along with\npreserving transliteration with multi-scale emotion modelling, in particularly\ntuned for Hindi and Indian English accent. Our approach extends the Parler-TTS\nmodel by integrating A language-specific phoneme alignment hybrid\nencoder-decoder architecture, and culture-sensitive emotion embedding layers\ntrained on native speaker corpora, as well as incorporating a dynamic accent\ncode switching with residual vector quantization. Quantitative tests\ndemonstrate 23.7% improvement in accent accuracy (Word Error Rate reduction\nfrom 15.4% to 11.8%) and 85.3% emotion recognition accuracy from native\nlisteners, surpassing METTS and VECL-TTS baselines. The novelty of the system\nis that it can mix code in real time - generating statements such as \"Namaste,\nlet's talk about <Hindi phrase>\" with uninterrupted accent shifts while\npreserving emotional consistency. Subjective evaluation with 200 users reported\na mean opinion score (MOS) of 4.2/5 for cultural correctness, much better than\nexisting multilingual systems (p<0.01). This research makes cross-lingual\nsynthesis more feasible by showcasing scalable accent-emotion disentanglement,\nwith direct application in South Asian EdTech and accessibility software.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684TTS\u67b6\u6784\uff0c\u7ed3\u5408\u591a\u5c3a\u5ea6\u60c5\u611f\u5efa\u6a21\u548c\u52a8\u6001\u53e3\u97f3\u5207\u6362\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5370\u5730\u8bed\u548c\u5370\u5ea6\u82f1\u8bed\u53e3\u97f3\u7684\u51c6\u786e\u6027\u53ca\u60c5\u611f\u8bc6\u522b\u80fd\u529b\u3002", "motivation": "\u5f53\u524dTTS\u7cfb\u7edf\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\uff08\u5c24\u5176\u662f\u5370\u5ea6\u8bed\u8a00\uff09\u7684\u53e3\u97f3\u548c\u60c5\u611f\u8868\u8fbe\u5b58\u5728\u6587\u5316\u5dee\u5f02\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u6269\u5c55Parler-TTS\u6a21\u578b\uff0c\u96c6\u6210\u8bed\u8a00\u7279\u5b9a\u97f3\u7d20\u5bf9\u9f50\u6df7\u5408\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u3001\u6587\u5316\u654f\u611f\u60c5\u611f\u5d4c\u5165\u5c42\u53ca\u52a8\u6001\u53e3\u97f3\u4ee3\u7801\u5207\u6362\u3002", "result": "\u53e3\u97f3\u51c6\u786e\u6027\u63d0\u534723.7%\uff08WER\u4ece15.4%\u964d\u81f311.8%\uff09\uff0c\u60c5\u611f\u8bc6\u522b\u51c6\u786e\u7387\u8fbe85.3%\uff0cMOS\u4e3a4.2/5\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u53ef\u6269\u5c55\u7684\u53e3\u97f3-\u60c5\u611f\u89e3\u8026\uff0c\u4e3a\u8de8\u8bed\u8a00\u5408\u6210\u63d0\u4f9b\u4e86\u66f4\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5357\u4e9a\u6559\u80b2\u79d1\u6280\u548c\u8f85\u52a9\u8f6f\u4ef6\u3002"}}
{"id": "2506.16313", "pdf": "https://arxiv.org/pdf/2506.16313", "abs": "https://arxiv.org/abs/2506.16313", "authors": ["Sajan Muhammad", "Salem Lahlou"], "title": "Improved Exploration in GFlownets via Enhanced Epistemic Neural Networks", "categories": ["cs.LG", "cs.AI", "I.2.6; I.2.8; G.3"], "comment": "Accepted to the EXAIT Workshop at ICML 2025", "summary": "Efficiently identifying the right trajectories for training remains an open\nproblem in GFlowNets. To address this, it is essential to prioritize\nexploration in regions of the state space where the reward distribution has not\nbeen sufficiently learned. This calls for uncertainty-driven exploration, in\nother words, the agent should be aware of what it does not know. This attribute\ncan be measured by joint predictions, which are particularly important for\ncombinatorial and sequential decision problems. In this research, we integrate\nepistemic neural networks (ENN) with the conventional architecture of GFlowNets\nto enable more efficient joint predictions and better uncertainty\nquantification, thereby improving exploration and the identification of optimal\ntrajectories. Our proposed algorithm, ENN-GFN-Enhanced, is compared to the\nbaseline method in GFlownets and evaluated in grid environments and structured\nsequence generation in various settings, demonstrating both its efficacy and\nefficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408ENN\u548cGFlowNets\u7684\u65b0\u7b97\u6cd5ENN-GFN-Enhanced\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u9a71\u52a8\u7684\u63a2\u7d22\u4f18\u5316\u8f68\u8ff9\u9009\u62e9\u3002", "motivation": "GFlowNets\u4e2d\u9ad8\u6548\u8bc6\u522b\u8bad\u7ec3\u8f68\u8ff9\u7684\u95ee\u9898\u5c1a\u672a\u89e3\u51b3\uff0c\u9700\u5728\u5956\u52b1\u5206\u5e03\u672a\u5145\u5206\u5b66\u4e60\u7684\u533a\u57df\u4f18\u5148\u63a2\u7d22\u3002", "method": "\u5c06ENN\u4e0eGFlowNets\u7ed3\u5408\uff0c\u63d0\u5347\u8054\u5408\u9884\u6d4b\u80fd\u529b\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u6539\u8fdb\u63a2\u7d22\u6548\u7387\u3002", "result": "\u5728\u7f51\u683c\u73af\u5883\u548c\u7ed3\u6784\u5316\u5e8f\u5217\u751f\u6210\u4efb\u52a1\u4e2d\uff0cENN-GFN-Enhanced\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ENN-GFN-Enhanced\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u663e\u8457\u63d0\u5347\u4e86GFlowNets\u7684\u63a2\u7d22\u6548\u7387\u548c\u8f68\u8ff9\u9009\u62e9\u80fd\u529b\u3002"}}
{"id": "2506.16314", "pdf": "https://arxiv.org/pdf/2506.16314", "abs": "https://arxiv.org/abs/2506.16314", "authors": ["Emmanuel Gangler", "Emille E. O. Ishida", "Matwey V. Kornilov", "Vladimir Korolev", "Anastasia Lavrukhina", "Konstantin Malanchev", "Maria V. Pruzhinskaya", "Etienne Russeil", "Timofey Semenikhin", "Sreevarsha Sreejith", "Alina A. Volnova"], "title": "Signatures to help interpretability of anomalies", "categories": ["cs.LG", "astro-ph.IM"], "comment": "7 pages, 3 figure, proceedings of the International Conference on\n  Machine Learning for Astrophysics (ML4ASTRO2)", "summary": "Machine learning is often viewed as a black box when it comes to\nunderstanding its output, be it a decision or a score. Automatic anomaly\ndetection is no exception to this rule, and quite often the astronomer is left\nto independently analyze the data in order to understand why a given event is\ntagged as an anomaly. We introduce here idea of anomaly signature, whose aim is\nto help the interpretability of anomalies by highlighting which features\ncontributed to the decision.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u201c\u5f02\u5e38\u7b7e\u540d\u201d\u7684\u6982\u5ff5\uff0c\u65e8\u5728\u901a\u8fc7\u7a81\u51fa\u663e\u793a\u5f71\u54cd\u51b3\u7b56\u7684\u7279\u5f81\u6765\u63d0\u9ad8\u5f02\u5e38\u68c0\u6d4b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5e38\u88ab\u89c6\u4e3a\u9ed1\u7bb1\uff0c\u96be\u4ee5\u7406\u89e3\u5176\u8f93\u51fa\uff08\u5982\u51b3\u7b56\u6216\u8bc4\u5206\uff09\uff0c\u5929\u6587\u5b66\u5bb6\u901a\u5e38\u9700\u8981\u72ec\u7acb\u5206\u6790\u6570\u636e\u4ee5\u7406\u89e3\u4e3a\u4f55\u67d0\u4e8b\u4ef6\u88ab\u6807\u8bb0\u4e3a\u5f02\u5e38\u3002", "method": "\u5f15\u5165\u201c\u5f02\u5e38\u7b7e\u540d\u201d\u7684\u6982\u5ff5\uff0c\u901a\u8fc7\u7a81\u51fa\u663e\u793a\u5bf9\u51b3\u7b56\u6709\u8d21\u732e\u7684\u7279\u5f81\u6765\u5e2e\u52a9\u89e3\u91ca\u5f02\u5e38\u3002", "result": "\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u63d0\u9ad8\u5f02\u5e38\u68c0\u6d4b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u5f02\u5e38\u7b7e\u540d\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u5e2e\u52a9\u7528\u6237\u7406\u89e3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u5f02\u5e38\u68c0\u6d4b\u7ed3\u679c\u3002"}}
{"id": "2506.16316", "pdf": "https://arxiv.org/pdf/2506.16316", "abs": "https://arxiv.org/abs/2506.16316", "authors": ["Huy Hoang Nguyen", "Han Zhou", "Matthew B. Blaschko", "Aleksei Tiulpin"], "title": "Bayesian Optimization over Bounded Domains with the Beta Product Kernel", "categories": ["cs.LG"], "comment": "Accepted as a conference paper at UAI 2025", "summary": "Bayesian optimization with Gaussian processes (GP) is commonly used to\noptimize black-box functions. The Mat\\'ern and the Radial Basis Function (RBF)\ncovariance functions are used frequently, but they do not make any assumptions\nabout the domain of the function, which may limit their applicability in\nbounded domains. To address the limitation, we introduce the Beta kernel, a\nnon-stationary kernel induced by a product of Beta distribution density\nfunctions. Such a formulation allows our kernel to naturally model functions on\nbounded domains. We present statistical evidence supporting the hypothesis that\nthe kernel exhibits an exponential eigendecay rate, based on empirical analyses\nof its spectral properties across different settings. Our experimental results\ndemonstrate the robustness of the Beta kernel in modeling functions with optima\nlocated near the faces or vertices of the unit hypercube. The experiments show\nthat our kernel consistently outperforms a wide range of kernels, including the\nwell-known Mat\\'ern and RBF, in different problems, including synthetic\nfunction optimization and the compression of vision and language models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684Beta\u6838\u51fd\u6570\uff0c\u7528\u4e8e\u5728\u8d1d\u53f6\u65af\u4f18\u5316\u4e2d\u5904\u7406\u6709\u754c\u57df\u51fd\u6570\uff0c\u4f18\u4e8e\u5e38\u7528\u7684Mat\u00e9rn\u548cRBF\u6838\u3002", "motivation": "\u73b0\u6709\u7684Mat\u00e9rn\u548cRBF\u6838\u51fd\u6570\u672a\u8003\u8651\u51fd\u6570\u5b9a\u4e49\u57df\u7684\u9650\u5236\uff0c\u53ef\u80fd\u5f71\u54cd\u5176\u6027\u80fd\u3002", "method": "\u5f15\u5165\u57fa\u4e8eBeta\u5206\u5e03\u5bc6\u5ea6\u51fd\u6570\u7684\u975e\u5e73\u7a33Beta\u6838\uff0c\u9002\u7528\u4e8e\u6709\u754c\u57df\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eBeta\u6838\u5728\u5355\u4f4d\u8d85\u7acb\u65b9\u4f53\u8fb9\u754c\u6216\u9876\u70b9\u9644\u8fd1\u4f18\u5316\u65f6\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u4f18\u4e8e\u5176\u4ed6\u6838\u51fd\u6570\u3002", "conclusion": "Beta\u6838\u4e3a\u6709\u754c\u57df\u51fd\u6570\u4f18\u5316\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u5de5\u5177\u3002"}}
{"id": "2506.16349", "pdf": "https://arxiv.org/pdf/2506.16349", "abs": "https://arxiv.org/abs/2506.16349", "authors": ["Nikola Jovanovi\u0107", "Ismail Labiad", "Tom\u00e1\u0161 Sou\u010dek", "Martin Vechev", "Pierre Fernandez"], "title": "Watermarking Autoregressive Image Generation", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV"], "comment": "Code: https://github.com/facebookresearch/wmar", "summary": "Watermarking the outputs of generative models has emerged as a promising\napproach for tracking their provenance. Despite significant interest in\nautoregressive image generation models and their potential for misuse, no prior\nwork has attempted to watermark their outputs at the token level. In this work,\nwe present the first such approach by adapting language model watermarking\ntechniques to this setting. We identify a key challenge: the lack of reverse\ncycle-consistency (RCC), wherein re-tokenizing generated image tokens\nsignificantly alters the token sequence, effectively erasing the watermark. To\naddress this and to make our method robust to common image transformations,\nneural compression, and removal attacks, we introduce (i) a custom\ntokenizer-detokenizer finetuning procedure that improves RCC, and (ii) a\ncomplementary watermark synchronization layer. As our experiments demonstrate,\nour approach enables reliable and robust watermark detection with theoretically\ngrounded p-values.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u81ea\u56de\u5f52\u56fe\u50cf\u751f\u6210\u6a21\u578b\u4e2d\u5b9e\u73b0\u4ee4\u724c\u7ea7\u6c34\u5370\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u91cd\u65b0\u6807\u8bb0\u5bfc\u81f4\u6c34\u5370\u4e22\u5931\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u751f\u6210\u6a21\u578b\u8f93\u51fa\u7684\u6c34\u5370\u6280\u672f\u53ef\u7528\u4e8e\u8ffd\u8e2a\u5176\u6765\u6e90\uff0c\u4f46\u6b64\u524d\u672a\u6709\u9488\u5bf9\u81ea\u56de\u5f52\u56fe\u50cf\u751f\u6210\u6a21\u578b\u7684\u4ee4\u724c\u7ea7\u6c34\u5370\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u8c03\u6574\u8bed\u8a00\u6a21\u578b\u6c34\u5370\u6280\u672f\uff0c\u5f15\u5165\u5b9a\u5236\u5316\u7684\u6807\u8bb0\u5668-\u89e3\u6807\u8bb0\u5668\u5fae\u8c03\u8fc7\u7a0b\u548c\u6c34\u5370\u540c\u6b65\u5c42\uff0c\u4ee5\u5e94\u5bf9\u91cd\u65b0\u6807\u8bb0\u548c\u56fe\u50cf\u53d8\u6362\u7684\u6311\u6218\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u53ef\u9760\u4e14\u9c81\u68d2\u7684\u6c34\u5370\u68c0\u6d4b\uff0c\u5e76\u5177\u6709\u7406\u8bba\u652f\u6301\u7684p\u503c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u81ea\u56de\u5f52\u56fe\u50cf\u751f\u6210\u6a21\u578b\u7684\u8f93\u51fa\u6c34\u5370\u63d0\u4f9b\u4e86\u9996\u4e2a\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.16352", "pdf": "https://arxiv.org/pdf/2506.16352", "abs": "https://arxiv.org/abs/2506.16352", "authors": ["Theo Zangato", "Aomar Osmani", "Pegah Alizadeh"], "title": "Data-Driven Policy Mapping for Safe RL-based Energy Management Systems", "categories": ["cs.LG"], "comment": null, "summary": "Increasing global energy demand and renewable integration complexity have\nplaced buildings at the center of sustainable energy management. We present a\nthree-step reinforcement learning(RL)-based Building Energy Management System\n(BEMS) that combines clustering, forecasting, and constrained policy learning\nto address scalability, adaptability, and safety challenges. First, we cluster\nnon-shiftable load profiles to identify common consumption patterns, enabling\npolicy generalization and transfer without retraining for each new building.\nNext, we integrate an LSTM based forecasting module to anticipate future\nstates, improving the RL agents' responsiveness to dynamic conditions. Lastly,\ndomain-informed action masking ensures safe exploration and operation,\npreventing harmful decisions. Evaluated on real-world data, our approach\nreduces operating costs by up to 15% for certain building types, maintains\nstable environmental performance, and quickly classifies and optimizes new\nbuildings with limited data. It also adapts to stochastic tariff changes\nwithout retraining. Overall, this framework delivers scalable, robust, and\ncost-effective building energy management.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4e09\u6b65\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u7cfb\u7edf\uff08BEMS\uff09\uff0c\u901a\u8fc7\u805a\u7c7b\u3001\u9884\u6d4b\u548c\u7ea6\u675f\u7b56\u7565\u5b66\u4e60\u89e3\u51b3\u53ef\u6269\u5c55\u6027\u3001\u9002\u5e94\u6027\u548c\u5b89\u5168\u6027\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u8fd0\u8425\u6210\u672c\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5168\u7403\u80fd\u6e90\u9700\u6c42\u589e\u957f\u548c\u53ef\u518d\u751f\u80fd\u6e90\u6574\u5408\u7684\u590d\u6742\u6027\u4f7f\u5f97\u5efa\u7b51\u6210\u4e3a\u53ef\u6301\u7eed\u80fd\u6e90\u7ba1\u7406\u7684\u6838\u5fc3\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u9002\u5e94\u6027\u5f3a\u4e14\u5b89\u5168\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1. \u805a\u7c7b\u975e\u53ef\u8f6c\u79fb\u8d1f\u8f7d\u4ee5\u8bc6\u522b\u901a\u7528\u6a21\u5f0f\uff1b2. \u96c6\u6210LSTM\u9884\u6d4b\u6a21\u5757\uff1b3. \u4f7f\u7528\u9886\u57df\u77e5\u8bc6\u7ea6\u675f\u7b56\u7565\u786e\u4fdd\u5b89\u5168\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u6d4b\u8bd5\uff0c\u8fd0\u8425\u6210\u672c\u964d\u4f4e15%\uff0c\u73af\u5883\u6027\u80fd\u7a33\u5b9a\uff0c\u5e76\u80fd\u5feb\u901f\u4f18\u5316\u65b0\u5efa\u7b51\u3002", "conclusion": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u3001\u7a33\u5065\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u3002"}}
{"id": "2506.16380", "pdf": "https://arxiv.org/pdf/2506.16380", "abs": "https://arxiv.org/abs/2506.16380", "authors": ["Druva Dhakshinamoorthy", "Avikshit Jha", "Sabyasachi Majumdar", "Devdulal Ghosh", "Ranjita Chakraborty", "Hena Ray"], "title": "Classification of Cattle Behavior and Detection of Heat (Estrus) using Sensor Data", "categories": ["cs.LG", "I.5.1; I.5.4; I.2.10; I.2.6; C.3; J.2; H.4.2"], "comment": "6 pages, 5 figures. Druva Dhakshinamoorthy and Avikshit Jha\n  contributed equally as co-first authors. Work conducted during a summer\n  internship at CDAC Kolkata by students of BITS Pilani", "summary": "This paper presents a novel system for monitoring cattle behavior and\ndetecting estrus (heat) periods using sensor data and machine learning. We\ndesigned and deployed a low-cost Bluetooth-based neck collar equipped with\naccelerometer and gyroscope sensors to capture real-time behavioral data from\nreal cows, which was synced to the cloud. A labeled dataset was created using\nsynchronized CCTV footage to annotate behaviors such as feeding, rumination,\nlying, and others. We evaluated multiple machine learning models -- Support\nVector Machines (SVM), Random Forests (RF), and Convolutional Neural Networks\n(CNN) -- for behavior classification. Additionally, we implemented a Long\nShort-Term Memory (LSTM) model for estrus detection using behavioral patterns\nand anomaly detection. Our system achieved over 93% behavior classification\naccuracy and 96% estrus detection accuracy on a limited test set. The approach\noffers a scalable and accessible solution for precision livestock monitoring,\nespecially in resource-constrained environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f20\u611f\u5668\u548c\u673a\u5668\u5b66\u4e60\u7684\u725b\u884c\u4e3a\u76d1\u6d4b\u4e0e\u53d1\u60c5\u671f\u68c0\u6d4b\u7cfb\u7edf\uff0c\u4f7f\u7528\u4f4e\u6210\u672c\u84dd\u7259\u9888\u5708\u548c\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u8fbe93%\uff0c\u53d1\u60c5\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe96%\u3002", "motivation": "\u4e3a\u7cbe\u51c6\u755c\u7267\u4e1a\u63d0\u4f9b\u4f4e\u6210\u672c\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8d44\u6e90\u6709\u9650\u7684\u73af\u5883\u3002", "method": "\u8bbe\u8ba1\u84dd\u7259\u9888\u5708\u914d\u5907\u52a0\u901f\u5ea6\u8ba1\u548c\u9640\u87ba\u4eea\uff0c\u91c7\u96c6\u5b9e\u65f6\u6570\u636e\u5e76\u540c\u6b65\u81f3\u4e91\u7aef\uff1b\u5229\u7528CCTV\u6807\u6ce8\u884c\u4e3a\u6570\u636e\uff1b\u8bc4\u4f30SVM\u3001RF\u3001CNN\u7b49\u6a21\u578b\u5206\u7c7b\u884c\u4e3a\uff1b\u4f7f\u7528LSTM\u6a21\u578b\u68c0\u6d4b\u53d1\u60c5\u3002", "result": "\u884c\u4e3a\u5206\u7c7b\u51c6\u786e\u738793%\uff0c\u53d1\u60c5\u68c0\u6d4b\u51c6\u786e\u738796%\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u7cbe\u51c6\u755c\u7267\u4e1a\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u7ecf\u6d4e\u53ef\u884c\u7684\u76d1\u6d4b\u65b9\u6848\u3002"}}
{"id": "2506.16392", "pdf": "https://arxiv.org/pdf/2506.16392", "abs": "https://arxiv.org/abs/2506.16392", "authors": ["Gon\u00e7alo Granjal Cruz", "Balazs Renczes", "Mark C Runacres", "Jan Decuyper"], "title": "State-Space Kolmogorov Arnold Networks for Interpretable Nonlinear System Identification", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted for IEEE Control Systems Letters", "summary": "While accurate, black-box system identification models lack interpretability\nof the underlying system dynamics. This paper proposes State-Space\nKolmogorov-Arnold Networks (SS-KAN) to address this challenge by integrating\nKolmogorov-Arnold Networks within a state-space framework. The proposed model\nis validated on two benchmark systems: the Silverbox and the Wiener-Hammerstein\nbenchmarks. Results show that SS-KAN provides enhanced interpretability due to\nsparsity-promoting regularization and the direct visualization of its learned\nunivariate functions, which reveal system nonlinearities at the cost of\naccuracy when compared to state-of-the-art black-box models, highlighting\nSS-KAN as a promising approach for interpretable nonlinear system\nidentification, balancing accuracy and interpretability of nonlinear system\ndynamics.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSS-KAN\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408Kolmogorov-Arnold\u7f51\u7edc\u548c\u72b6\u6001\u7a7a\u95f4\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u9ed1\u7bb1\u7cfb\u7edf\u8fa8\u8bc6\u6a21\u578b\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u9ed1\u7bb1\u7cfb\u7edf\u8fa8\u8bc6\u6a21\u578b\u867d\u7136\u51c6\u786e\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u7cfb\u7edf\u52a8\u6001\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faSS-KAN\u6a21\u578b\uff0c\u7ed3\u5408Kolmogorov-Arnold\u7f51\u7edc\u548c\u72b6\u6001\u7a7a\u95f4\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u7a00\u758f\u6b63\u5219\u5316\u548c\u53ef\u89c6\u5316\u5355\u53d8\u91cf\u51fd\u6570\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728Silverbox\u548cWiener-Hammerstein\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSS-KAN\u5728\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u7cbe\u5ea6\u7565\u4f4e\u4e8e\u6700\u5148\u8fdb\u7684\u9ed1\u7bb1\u6a21\u578b\u3002", "conclusion": "SS-KAN\u662f\u4e00\u79cd\u5e73\u8861\u7cbe\u5ea6\u4e0e\u53ef\u89e3\u91ca\u6027\u7684\u975e\u7ebf\u6027\u7cfb\u7edf\u8fa8\u8bc6\u65b9\u6cd5\uff0c\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2506.16396", "pdf": "https://arxiv.org/pdf/2506.16396", "abs": "https://arxiv.org/abs/2506.16396", "authors": ["Alexey Zakharov", "Shimon Whiteson"], "title": "GoalLadder: Incremental Goal Discovery with Vision-Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Natural language can offer a concise and human-interpretable means of\nspecifying reinforcement learning (RL) tasks. The ability to extract rewards\nfrom a language instruction can enable the development of robotic systems that\ncan learn from human guidance; however, it remains a challenging problem,\nespecially in visual environments. Existing approaches that employ large,\npretrained language models either rely on non-visual environment\nrepresentations, require prohibitively large amounts of feedback, or generate\nnoisy, ill-shaped reward functions. In this paper, we propose a novel method,\n$\\textbf{GoalLadder}$, that leverages vision-language models (VLMs) to train RL\nagents from a single language instruction in visual environments. GoalLadder\nworks by incrementally discovering states that bring the agent closer to\ncompleting a task specified in natural language. To do so, it queries a VLM to\nidentify states that represent an improvement in agent's task progress and to\nrank them using pairwise comparisons. Unlike prior work, GoalLadder does not\ntrust VLM's feedback completely; instead, it uses it to rank potential goal\nstates using an ELO-based rating system, thus reducing the detrimental effects\nof noisy VLM feedback. Over the course of training, the agent is tasked with\nminimising the distance to the top-ranked goal in a learned embedding space,\nwhich is trained on unlabelled visual data. This key feature allows us to\nbypass the need for abundant and accurate feedback typically required to train\na well-shaped reward function. We demonstrate that GoalLadder outperforms\nexisting related methods on classic control and robotic manipulation\nenvironments with the average final success rate of $\\sim$95% compared to only\n$\\sim$45% of the best competitor.", "AI": {"tldr": "GoalLadder\u662f\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u4ece\u5355\u4e00\u8bed\u8a00\u6307\u4ee4\u8bad\u7ec3\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4ee3\u7406\uff0c\u901a\u8fc7\u9010\u6b65\u53d1\u73b0\u4efb\u52a1\u8fdb\u5c55\u72b6\u6001\u5e76\u51cf\u5c11\u566a\u58f0\u53cd\u9988\u7684\u5f71\u54cd\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u81ea\u7136\u8bed\u8a00\u53ef\u4ee5\u4e3a\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u63d0\u4f9b\u7b80\u6d01\u4e14\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u89c4\u8303\uff0c\u4f46\u4ece\u8bed\u8a00\u6307\u4ee4\u4e2d\u63d0\u53d6\u5956\u52b1\u4ecd\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u89c6\u89c9\u73af\u5883\u4e2d\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u975e\u89c6\u89c9\u73af\u5883\u8868\u793a\u6216\u9700\u8981\u5927\u91cf\u53cd\u9988\uff0c\u4e14\u751f\u6210\u7684\u5956\u52b1\u51fd\u6570\u566a\u58f0\u8f83\u5927\u3002", "method": "GoalLadder\u901a\u8fc7\u67e5\u8be2VLM\u8bc6\u522b\u4efb\u52a1\u8fdb\u5c55\u72b6\u6001\u5e76\u4f7f\u7528ELO\u8bc4\u5206\u7cfb\u7edf\u6392\u540d\uff0c\u51cf\u5c11\u566a\u58f0\u53cd\u9988\u7684\u5f71\u54cd\u3002\u4ee3\u7406\u901a\u8fc7\u6700\u5c0f\u5316\u4e0e\u6392\u540d\u6700\u9ad8\u76ee\u6807\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u8ddd\u79bb\u6765\u5b66\u4e60\uff0c\u65e0\u9700\u5927\u91cf\u51c6\u786e\u53cd\u9988\u3002", "result": "GoalLadder\u5728\u7ecf\u5178\u63a7\u5236\u548c\u673a\u5668\u4eba\u64cd\u4f5c\u73af\u5883\u4e2d\u5e73\u5747\u6700\u7ec8\u6210\u529f\u7387\u7ea6\u4e3a95%\uff0c\u8fdc\u4f18\u4e8e\u7ade\u4e89\u5bf9\u624b\u768445%\u3002", "conclusion": "GoalLadder\u901a\u8fc7\u7ed3\u5408VLM\u548cELO\u8bc4\u5206\u7cfb\u7edf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4ece\u8bed\u8a00\u6307\u4ee4\u4e2d\u63d0\u53d6\u5956\u52b1\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86RL\u4ee3\u7406\u7684\u6027\u80fd\u3002"}}
{"id": "2506.16404", "pdf": "https://arxiv.org/pdf/2506.16404", "abs": "https://arxiv.org/abs/2506.16404", "authors": ["Alba Carballo-Castro", "Manuel Madeira", "Yiming Qin", "Dorina Thanou", "Pascal Frossard"], "title": "Generating Directed Graphs with Dual Attention and Asymmetric Encoding", "categories": ["cs.LG"], "comment": null, "summary": "Directed graphs naturally model systems with asymmetric, ordered\nrelationships, essential to applications in biology, transportation, social\nnetworks, and visual understanding. Generating such graphs enables tasks such\nas simulation, data augmentation and novel instance discovery; however,\ndirected graph generation remains underexplored. We identify two key factors\nlimiting progress in this direction: first, modeling edge directionality\nintroduces a substantially larger dependency space, making the underlying\ndistribution harder to learn; second, the absence of standardized benchmarks\nhinders rigorous evaluation. Addressing the former requires more expressive\nmodels that are sensitive to directional topologies. We propose Directo, the\nfirst generative model for directed graphs built upon the discrete flow\nmatching framework. Our approach combines: (i) principled positional encodings\ntailored to asymmetric pairwise relations, (ii) a dual-attention mechanism\ncapturing both incoming and outgoing dependencies, and (iii) a robust, discrete\ngenerative framework. To support evaluation, we introduce a benchmark suite\ncovering synthetic and real-world datasets. It shows that our method performs\nstrongly across diverse settings and even competes with specialized models for\nparticular classes, such as directed acyclic graphs. Our results highlight the\neffectiveness and generality of our approach, establishing a solid foundation\nfor future research in directed graph generation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDirecto\uff0c\u9996\u4e2a\u57fa\u4e8e\u79bb\u6563\u6d41\u5339\u914d\u6846\u67b6\u7684\u6709\u5411\u56fe\u751f\u6210\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u6709\u5411\u56fe\u751f\u6210\u4e2d\u7684\u4f9d\u8d56\u7a7a\u95f4\u5927\u548c\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\u7684\u95ee\u9898\u3002", "motivation": "\u6709\u5411\u56fe\u5728\u591a\u4e2a\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u751f\u6210\u6709\u5411\u56fe\u7684\u7814\u7a76\u8f83\u5c11\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u4f9d\u8d56\u7a7a\u95f4\u5927\u548c\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\u3002", "method": "\u7ed3\u5408\u4e86\u9488\u5bf9\u4e0d\u5bf9\u79f0\u5173\u7cfb\u7684\u7f16\u7801\u3001\u53cc\u6ce8\u610f\u529b\u673a\u5236\u548c\u79bb\u6563\u751f\u6210\u6846\u67b6\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u751a\u81f3\u80fd\u4e0e\u7279\u5b9a\u7c7b\u522b\u7684\u4e13\u7528\u6a21\u578b\u7ade\u4e89\u3002", "conclusion": "Directo\u4e3a\u6709\u5411\u56fe\u751f\u6210\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u901a\u7528\u6027\u3002"}}
{"id": "2506.16406", "pdf": "https://arxiv.org/pdf/2506.16406", "abs": "https://arxiv.org/abs/2506.16406", "authors": ["Zhiyuan Liang", "Dongwen Tang", "Yuhao Zhou", "Xuanlei Zhao", "Mingjia Shi", "Wangbo Zhao", "Zekai Li", "Peihao Wang", "Konstantin Sch\u00fcrholt", "Damian Borth", "Michael M. Bronstein", "Yang You", "Zhangyang Wang", "Kai Wang"], "title": "Drag-and-Drop LLMs: Zero-Shot Prompt-to-Weights", "categories": ["cs.LG", "cs.AI"], "comment": "We propose a method that can generate LoRA parameters in seconds", "summary": "Modern Parameter-Efficient Fine-Tuning (PEFT) methods such as low-rank\nadaptation (LoRA) reduce the cost of customizing large language models (LLMs),\nyet still require a separate optimization run for every downstream dataset. We\nintroduce \\textbf{Drag-and-Drop LLMs (\\textit{DnD})}, a prompt-conditioned\nparameter generator that eliminates per-task training by mapping a handful of\nunlabeled task prompts directly to LoRA weight updates. A lightweight text\nencoder distills each prompt batch into condition embeddings, which are then\ntransformed by a cascaded hyper-convolutional decoder into the full set of LoRA\nmatrices. Once trained in a diverse collection of prompt-checkpoint pairs, DnD\nproduces task-specific parameters in seconds, yielding i) up to\n\\textbf{12,000$\\times$} lower overhead than full fine-tuning, ii) average gains\nup to \\textbf{30\\%} in performance over the strongest training LoRAs on unseen\ncommon-sense reasoning, math, coding, and multimodal benchmarks, and iii)\nrobust cross-domain generalization despite never seeing the target data or\nlabels. Our results demonstrate that prompt-conditioned parameter generation is\na viable alternative to gradient-based adaptation for rapidly specializing\nLLMs. Our project is available at\n\\href{https://jerryliang24.github.io/DnD}{https://jerryliang24.github.io/DnD}.", "AI": {"tldr": "DnD\u662f\u4e00\u79cd\u65e0\u9700\u9010\u4efb\u52a1\u8bad\u7ec3\u7684PEFT\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u793a\u751f\u6210LoRA\u6743\u91cd\u66f4\u65b0\uff0c\u663e\u8457\u964d\u4f4e\u5f00\u9500\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u51cf\u5c11\u4e3a\u6bcf\u4e2a\u4e0b\u6e38\u6570\u636e\u96c6\u5355\u72ec\u4f18\u5316LLM\u7684\u6210\u672c\uff0c\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u4f7f\u7528\u63d0\u793a\u6761\u4ef6\u53c2\u6570\u751f\u6210\u5668\uff0c\u901a\u8fc7\u6587\u672c\u7f16\u7801\u5668\u548c\u8d85\u5377\u79ef\u89e3\u7801\u5668\u76f4\u63a5\u751f\u6210LoRA\u77e9\u9635\u3002", "result": "\u5f00\u9500\u964d\u4f4e12,000\u500d\uff0c\u6027\u80fd\u63d0\u534730%\uff0c\u4e14\u5177\u6709\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "DnD\u8bc1\u660e\u4e86\u63d0\u793a\u6761\u4ef6\u53c2\u6570\u751f\u6210\u662f\u68af\u5ea6\u9002\u5e94\u7684\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2506.16419", "pdf": "https://arxiv.org/pdf/2506.16419", "abs": "https://arxiv.org/abs/2506.16419", "authors": ["Daniel Fidel Harvey", "George Weale", "Berk Yilmaz"], "title": "Optimizing MoE Routers: Design, Implementation, and Evaluation in Transformer Models", "categories": ["cs.LG", "cs.AI", "68T07, 68T45"], "comment": "All authors contributed equally. 11 pages, 6 figures", "summary": "Mixture of Experts (MoE) architectures increase large language model\nscalability, yet their performance depends on the router module that moves\ntokens to specialized experts. Bad routing can load imbalance and reduced\naccuracy. This project designed and implemented different router architectures\nwithin Transformer models to fix these limitations. We experimented with six\ndistinct router variants Linear, Attention, Multi-Layer Perceptron (MLP),\nHybrid, Hash, and our new MLP-Hadamard. We characterized these routers using\nBERT and the Qwen1.5-MoE model, looking at parameter efficiency, inference\nlatency, routing entropy, and expert utilization patterns. Our evaluations\nshowed distinct trade-offs: Linear routers offer speed, while MLP and Attention\nrouters provide greater expressiveness. The MLP-Hadamard router shows a unique\ncapability for structured, sparse routing. We successfully replaced and\nfine-tuned custom routers within the complex, quantized Qwen1.5-MoE model. This\nwork provides a comparative analysis of MoE router designs and offers insights\ninto optimizing their performance for efficient and effective large-scale model\ndeployment.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u67b6\u6784\u4e2d\u7684\u8def\u7531\u5668\u8bbe\u8ba1\uff0c\u6bd4\u8f83\u4e86\u516d\u79cd\u53d8\u4f53\uff0c\u63d0\u51fa\u4e86\u65b0\u7684MLP-Hadamard\u8def\u7531\u5668\uff0c\u5e76\u5728BERT\u548cQwen1.5-MoE\u6a21\u578b\u4e2d\u8bc4\u4f30\u4e86\u6027\u80fd\u3002", "motivation": "MoE\u67b6\u6784\u7684\u6027\u80fd\u4f9d\u8d56\u4e8e\u8def\u7531\u5668\u6a21\u5757\uff0c\u4f46\u4e0d\u826f\u8def\u7531\u4f1a\u5bfc\u81f4\u8d1f\u8f7d\u4e0d\u5e73\u8861\u548c\u51c6\u786e\u6027\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u4f18\u5316\u8def\u7531\u5668\u8bbe\u8ba1\u3002", "method": "\u8bbe\u8ba1\u4e86\u516d\u79cd\u8def\u7531\u5668\u53d8\u4f53\uff08Linear\u3001Attention\u3001MLP\u3001Hybrid\u3001Hash\u548cMLP-Hadamard\uff09\uff0c\u5e76\u5728BERT\u548cQwen1.5-MoE\u6a21\u578b\u4e2d\u8bc4\u4f30\u5176\u53c2\u6570\u6548\u7387\u3001\u63a8\u7406\u5ef6\u8fdf\u3001\u8def\u7531\u71b5\u548c\u4e13\u5bb6\u5229\u7528\u7387\u3002", "result": "\u4e0d\u540c\u8def\u7531\u5668\u5404\u6709\u4f18\u52a3\uff1aLinear\u901f\u5ea6\u5feb\uff0cMLP\u548cAttention\u8868\u73b0\u529b\u5f3a\uff0cMLP-Hadamard\u5177\u6709\u7ed3\u6784\u5316\u7a00\u758f\u8def\u7531\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u4e3aMoE\u8def\u7531\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6bd4\u8f83\u5206\u6790\uff0c\u5e76\u4e3a\u5927\u89c4\u6a21\u6a21\u578b\u90e8\u7f72\u4e2d\u7684\u6027\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2506.16428", "pdf": "https://arxiv.org/pdf/2506.16428", "abs": "https://arxiv.org/abs/2506.16428", "authors": ["Dian Meng", "Zhiguang Cao", "Yaoxin Wu", "Yaqing Hou", "Hongwei Ge", "Qiang Zhang"], "title": "EFormer: An Effective Edge-based Transformer for Vehicle Routing Problems", "categories": ["cs.LG"], "comment": null, "summary": "Recent neural heuristics for the Vehicle Routing Problem (VRP) primarily rely\non node coordinates as input, which may be less effective in practical\nscenarios where real cost metrics-such as edge-based distances-are more\nrelevant. To address this limitation, we introduce EFormer, an Edge-based\nTransformer model that uses edge as the sole input for VRPs. Our approach\nemploys a precoder module with a mixed-score attention mechanism to convert\nedge information into temporary node embeddings. We also present a parallel\nencoding strategy characterized by a graph encoder and a node encoder, each\nresponsible for processing graph and node embeddings in distinct feature\nspaces, respectively. This design yields a more comprehensive representation of\nthe global relationships among edges. In the decoding phase, parallel context\nembedding and multi-query integration are used to compute separate attention\nmechanisms over the two encoded embeddings, facilitating efficient path\nconstruction. We train EFormer using reinforcement learning in an\nautoregressive manner. Extensive experiments on the Traveling Salesman Problem\n(TSP) and Capacitated Vehicle Routing Problem (CVRP) reveal that EFormer\noutperforms established baselines on synthetic datasets, including large-scale\nand diverse distributions. Moreover, EFormer demonstrates strong generalization\non real-world instances from TSPLib and CVRPLib. These findings confirm the\neffectiveness of EFormer's core design in solving VRPs.", "AI": {"tldr": "EFormer\u662f\u4e00\u79cd\u57fa\u4e8e\u8fb9\u7684Transformer\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff08VRP\uff09\uff0c\u901a\u8fc7\u8fb9\u4fe1\u606f\u751f\u6210\u8282\u70b9\u5d4c\u5165\uff0c\u5e76\u5728\u7f16\u7801\u548c\u89e3\u7801\u9636\u6bb5\u91c7\u7528\u5e76\u884c\u7b56\u7565\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u542f\u53d1\u5f0f\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u8282\u70b9\u5750\u6807\u4f5c\u4e3a\u8f93\u5165\uff0c\u4f46\u5728\u5b9e\u9645\u573a\u666f\u4e2d\uff0c\u57fa\u4e8e\u8fb9\u7684\u8ddd\u79bb\u7b49\u6210\u672c\u6307\u6807\u66f4\u4e3a\u91cd\u8981\u3002EFormer\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\u6027\u3002", "method": "EFormer\u91c7\u7528\u9884\u7f16\u7801\u6a21\u5757\u548c\u6df7\u5408\u5206\u6570\u6ce8\u610f\u529b\u673a\u5236\u5c06\u8fb9\u4fe1\u606f\u8f6c\u6362\u4e3a\u4e34\u65f6\u8282\u70b9\u5d4c\u5165\uff0c\u5e76\u901a\u8fc7\u5e76\u884c\u7f16\u7801\u7b56\u7565\uff08\u56fe\u7f16\u7801\u5668\u548c\u8282\u70b9\u7f16\u7801\u5668\uff09\u5904\u7406\u4e0d\u540c\u7279\u5f81\u7a7a\u95f4\u7684\u4fe1\u606f\u3002\u89e3\u7801\u9636\u6bb5\u4f7f\u7528\u5e76\u884c\u4e0a\u4e0b\u6587\u5d4c\u5165\u548c\u591a\u67e5\u8be2\u96c6\u6210\u3002", "result": "\u5728TSP\u548cCVRP\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEFormer\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u4f8b\u4e2d\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "EFormer\u7684\u6838\u5fc3\u8bbe\u8ba1\u5728\u89e3\u51b3VRP\u95ee\u9898\u4e0a\u5177\u6709\u663e\u8457\u6548\u679c\uff0c\u9a8c\u8bc1\u4e86\u5176\u57fa\u4e8e\u8fb9\u8f93\u5165\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.16436", "pdf": "https://arxiv.org/pdf/2506.16436", "abs": "https://arxiv.org/abs/2506.16436", "authors": ["Antonio Giulio Coretti", "Mattia Varile", "Mario Edoardo Bertaina"], "title": "An efficient neuromorphic approach for collision avoidance combining Stack-CNN with event cameras", "categories": ["cs.LG"], "comment": "18th International Conference on Space Operations - Safety and\n  sustainability of Space Operations (SSU)", "summary": "Space debris poses a significant threat, driving research into active and\npassive mitigation strategies. This work presents an innovative collision\navoidance system utilizing event-based cameras - a novel imaging technology\nwell-suited for Space Situational Awareness (SSA) and Space Traffic Management\n(STM). The system, employing a Stack-CNN algorithm (previously used for meteor\ndetection), analyzes real-time event-based camera data to detect faint moving\nobjects. Testing on terrestrial data demonstrates the algorithm's ability to\nenhance signal-to-noise ratio, offering a promising approach for on-board space\nimaging and improving STM/SSA operations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8b\u4ef6\u76f8\u673a\u7684\u78b0\u649e\u907f\u514d\u7cfb\u7edf\uff0c\u7528\u4e8e\u7a7a\u95f4\u788e\u7247\u76d1\u6d4b\uff0c\u91c7\u7528Stack-CNN\u7b97\u6cd5\u63d0\u5347\u4fe1\u566a\u6bd4\u3002", "motivation": "\u7a7a\u95f4\u788e\u7247\u5bf9\u592a\u7a7a\u6d3b\u52a8\u6784\u6210\u5a01\u80c1\uff0c\u9700\u5f00\u53d1\u6709\u6548\u7684\u76d1\u6d4b\u4e0e\u907f\u514d\u6280\u672f\u3002", "method": "\u5229\u7528\u4e8b\u4ef6\u76f8\u673a\u548cStack-CNN\u7b97\u6cd5\u5b9e\u65f6\u68c0\u6d4b\u5fae\u5f31\u79fb\u52a8\u7269\u4f53\u3002", "result": "\u5728\u5730\u9762\u6d4b\u8bd5\u4e2d\uff0c\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u4fe1\u566a\u6bd4\uff0c\u9002\u7528\u4e8e\u592a\u7a7a\u6210\u50cf\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u7a7a\u95f4\u4ea4\u901a\u7ba1\u7406\u548c\u6001\u52bf\u611f\u77e5\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16443", "pdf": "https://arxiv.org/pdf/2506.16443", "abs": "https://arxiv.org/abs/2506.16443", "authors": ["Jonas R. Naujoks", "Aleksander Krasowski", "Moritz Weckbecker", "Galip \u00dcmit Yolcu", "Thomas Wiegand", "Sebastian Lapuschkin", "Wojciech Samek", "Ren\u00e9 P. Klausen"], "title": "Leveraging Influence Functions for Resampling Data in Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "comment": "This article was presented at \"The 3rd World Conference on\n  eXplainable Artificial Intelligence\" (2025)", "summary": "Physics-informed neural networks (PINNs) offer a powerful approach to solving\npartial differential equations (PDEs), which are ubiquitous in the quantitative\nsciences. Applied to both forward and inverse problems across various\nscientific domains, PINNs have recently emerged as a valuable tool in the field\nof scientific machine learning. A key aspect of their training is that the data\n-- spatio-temporal points sampled from the PDE's input domain -- are readily\navailable. Influence functions, a tool from the field of explainable AI (XAI),\napproximate the effect of individual training points on the model, enhancing\ninterpretability. In the present work, we explore the application of influence\nfunction-based sampling approaches for the training data. Our results indicate\nthat such targeted resampling based on data attribution methods has the\npotential to enhance prediction accuracy in physics-informed neural networks,\ndemonstrating a practical application of an XAI method in PINN training.", "AI": {"tldr": "PINNs\u7ed3\u5408XAI\u4e2d\u7684\u5f71\u54cd\u51fd\u6570\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u91cd\u91c7\u6837\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u5229\u7528XAI\u4e2d\u7684\u5f71\u54cd\u51fd\u6570\u4f18\u5316PINNs\u7684\u8bad\u7ec3\u6570\u636e\u91c7\u6837\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "method": "\u5e94\u7528\u5f71\u54cd\u51fd\u6570\u5bf9\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u9488\u5bf9\u6027\u91cd\u91c7\u6837\u3002", "result": "\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347PINNs\u7684\u9884\u6d4b\u7cbe\u5ea6\u3002", "conclusion": "\u5f71\u54cd\u51fd\u6570\u5728PINN\u8bad\u7ec3\u4e2d\u7684\u5e94\u7528\u5177\u6709\u5b9e\u9645\u4ef7\u503c\uff0c\u4e3aXAI\u65b9\u6cd5\u5728\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5b9e\u8df5\u63d0\u4f9b\u4e86\u8303\u4f8b\u3002"}}
{"id": "2506.16448", "pdf": "https://arxiv.org/pdf/2506.16448", "abs": "https://arxiv.org/abs/2506.16448", "authors": ["Tri Duc Ly", "Gia H. Ngo"], "title": "Consumer-friendly EEG-based Emotion Recognition System: A Multi-scale Convolutional Neural Network Approach", "categories": ["cs.LG", "cs.AI"], "comment": "29 pages, 10 figures", "summary": "EEG is a non-invasive, safe, and low-risk method to record\nelectrophysiological signals inside the brain. Especially with recent\ntechnology developments like dry electrodes, consumer-grade EEG devices, and\nrapid advances in machine learning, EEG is commonly used as a resource for\nautomatic emotion recognition. With the aim to develop a deep learning model\nthat can perform EEG-based emotion recognition in a real-life context, we\npropose a novel approach to utilize multi-scale convolutional neural networks\nto accomplish such tasks. By implementing feature extraction kernels with many\nratio coefficients as well as a new type of kernel that learns key information\nfrom four separate areas of the brain, our model consistently outperforms the\nstate-of-the-art TSception model in predicting valence, arousal, and dominance\nscores across many performance evaluation metrics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u591a\u5c3a\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8eEEG\u60c5\u7eea\u8bc6\u522b\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u5f00\u53d1\u9002\u7528\u4e8e\u771f\u5b9e\u573a\u666f\u7684EEG\u60c5\u7eea\u8bc6\u522b\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u591a\u5c3a\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u7ed3\u5408\u591a\u79cd\u6bd4\u4f8b\u7cfb\u6570\u7684\u7279\u5f81\u63d0\u53d6\u6838\u548c\u65b0\u578b\u6838\uff08\u4ece\u5927\u8111\u56db\u4e2a\u533a\u57df\u5b66\u4e60\u5173\u952e\u4fe1\u606f\uff09\u3002", "result": "\u5728\u9884\u6d4b\u6548\u4ef7\u3001\u5524\u9192\u548c\u652f\u914d\u5206\u6570\u65b9\u9762\uff0c\u6a21\u578b\u6027\u80fd\u4f18\u4e8eTSception\u6a21\u578b\u3002", "conclusion": "\u591a\u5c3a\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728EEG\u60c5\u7eea\u8bc6\u522b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2506.16456", "pdf": "https://arxiv.org/pdf/2506.16456", "abs": "https://arxiv.org/abs/2506.16456", "authors": ["Jun Qi", "Chen-Yu Liu", "Sabato Marco Siniscalchi", "Chao-Han Huck Yang", "Min-Hsiu Hsieh"], "title": "Joint Tensor-Train Parameterization for Efficient and Expressive Low-Rank Adaptation", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Preprint. Under Review", "summary": "Low-Rank Adaptation (LoRA) is widely recognized for its parameter-efficient\nfine-tuning of large-scale neural models. However, standard LoRA independently\noptimizes low-rank matrices, which inherently limits its expressivity and\ngeneralization capabilities. While classical tensor-train (TT) decomposition\ncan be separately employed on individual LoRA matrices, this work demonstrates\nthat the classical TT-based approach neither significantly improves parameter\nefficiency nor achieves substantial performance gains. This paper proposes\nTensorGuide, a novel tensor-train-guided adaptation framework to overcome these\nlimitations. TensorGuide generates two correlated low-rank LoRA matrices\nthrough a unified TT structure driven by controlled Gaussian noise. The\nresulting joint TT representation inherently provides structured, low-rank\nadaptations, significantly enhancing expressivity, generalization, and\nparameter efficiency without increasing the number of trainable parameters.\nTheoretically, we justify these improvements through neural tangent kernel\nanalyses, demonstrating superior optimization dynamics and enhanced\ngeneralization. Extensive experiments on quantum dot classification and GPT-2\nfine-tuning benchmarks demonstrate that TensorGuide-based LoRA consistently\noutperforms standard LoRA and TT-LoRA, achieving improved accuracy and\nscalability with fewer parameters.", "AI": {"tldr": "TensorGuide\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f20\u91cf\u94fe\u5f15\u5bfc\u7684\u4f4e\u79e9\u9002\u5e94\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86LoRA\u7684\u8868\u8fbe\u80fd\u529b\u548c\u6cdb\u5316\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u53c2\u6570\u6548\u7387\u3002", "motivation": "\u6807\u51c6LoRA\u72ec\u7acb\u4f18\u5316\u4f4e\u79e9\u77e9\u9635\uff0c\u9650\u5236\u4e86\u5176\u8868\u8fbe\u80fd\u529b\u548c\u6cdb\u5316\u6027\u80fd\uff0c\u800c\u4f20\u7edf\u7684\u5f20\u91cf\u94fe\u5206\u89e3\u65b9\u6cd5\u672a\u80fd\u663e\u8457\u6539\u8fdb\u3002", "method": "\u901a\u8fc7\u7edf\u4e00\u7684\u5f20\u91cf\u94fe\u7ed3\u6784\u751f\u6210\u4e24\u4e2a\u76f8\u5173\u7684\u4f4e\u79e9LoRA\u77e9\u9635\uff0c\u5229\u7528\u53d7\u63a7\u9ad8\u65af\u566a\u58f0\u9a71\u52a8\uff0c\u5f62\u6210\u8054\u5408\u5f20\u91cf\u94fe\u8868\u793a\u3002", "result": "\u5728\u91cf\u5b50\u70b9\u5206\u7c7b\u548cGPT-2\u5fae\u8c03\u5b9e\u9a8c\u4e2d\uff0cTensorGuide\u4f18\u4e8e\u6807\u51c6LoRA\u548cTT-LoRA\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "TensorGuide\u901a\u8fc7\u6539\u8fdb\u7684\u4f18\u5316\u52a8\u6001\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16460", "pdf": "https://arxiv.org/pdf/2506.16460", "abs": "https://arxiv.org/abs/2506.16460", "authors": ["John Abascal", "Nicol\u00e1s Berrios", "Alina Oprea", "Jonathan Ullman", "Adam Smith", "Matthew Jagielski"], "title": "Black-Box Privacy Attacks on Shared Representations in Multitask Learning", "categories": ["cs.LG", "cs.CR"], "comment": "30 pages, 8 figures", "summary": "Multitask learning (MTL) has emerged as a powerful paradigm that leverages\nsimilarities among multiple learning tasks, each with insufficient samples to\ntrain a standalone model, to solve them simultaneously while minimizing data\nsharing across users and organizations. MTL typically accomplishes this goal by\nlearning a shared representation that captures common structure among the tasks\nby embedding data from all tasks into a common feature space. Despite being\ndesigned to be the smallest unit of shared information necessary to effectively\nlearn patterns across multiple tasks, these shared representations can\ninadvertently leak sensitive information about the particular tasks they were\ntrained on.\n  In this work, we investigate what information is revealed by the shared\nrepresentations through the lens of inference attacks. Towards this, we propose\na novel, black-box task-inference threat model where the adversary, given the\nembedding vectors produced by querying the shared representation on samples\nfrom a particular task, aims to determine whether that task was present when\ntraining the shared representation. We develop efficient, purely black-box\nattacks on machine learning models that exploit the dependencies between\nembeddings from the same task without requiring shadow models or labeled\nreference data. We evaluate our attacks across vision and language domains for\nmultiple use cases of MTL and demonstrate that even with access only to fresh\ntask samples rather than training data, a black-box adversary can successfully\ninfer a task's inclusion in training. To complement our experiments, we provide\ntheoretical analysis of a simplified learning setting and show a strict\nseparation between adversaries with training samples and fresh samples from the\ntarget task's distribution.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u591a\u4efb\u52a1\u5b66\u4e60\uff08MTL\uff09\u4e2d\u5171\u4eab\u8868\u793a\u53ef\u80fd\u6cc4\u9732\u4efb\u52a1\u654f\u611f\u4fe1\u606f\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9ed1\u76d2\u4efb\u52a1\u63a8\u65ad\u653b\u51fb\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u548c\u7406\u8bba\u5206\u6790\u9a8c\u8bc1\u4e86\u653b\u51fb\u7684\u6709\u6548\u6027\u3002", "motivation": "\u591a\u4efb\u52a1\u5b66\u4e60\u901a\u8fc7\u5171\u4eab\u8868\u793a\u63d0\u9ad8\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u8fd9\u4e9b\u8868\u793a\u53ef\u80fd\u6cc4\u9732\u4efb\u52a1\u9690\u79c1\u3002\u8bba\u6587\u65e8\u5728\u63ed\u793a\u5171\u4eab\u8868\u793a\u7684\u4fe1\u606f\u6cc4\u9732\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u9ed1\u76d2\u4efb\u52a1\u63a8\u65ad\u653b\u51fb\u6a21\u578b\uff0c\u5229\u7528\u4efb\u52a1\u6837\u672c\u7684\u5d4c\u5165\u5411\u91cf\u63a8\u65ad\u4efb\u52a1\u662f\u5426\u53c2\u4e0e\u8bad\u7ec3\uff0c\u65e0\u9700\u5f71\u5b50\u6a21\u578b\u6216\u6807\u8bb0\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u653b\u51fb\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u9886\u57df\u5747\u6709\u6548\uff0c\u5373\u4f7f\u4ec5\u4f7f\u7528\u65b0\u6837\u672c\u4e5f\u80fd\u6210\u529f\u63a8\u65ad\u4efb\u52a1\u53c2\u4e0e\u8bad\u7ec3\u3002", "conclusion": "\u5171\u4eab\u8868\u793a\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff0c\u9700\u8bbe\u8ba1\u66f4\u5b89\u5168\u7684MTL\u65b9\u6cd5\u4ee5\u62b5\u5fa1\u6b64\u7c7b\u653b\u51fb\u3002"}}
{"id": "2506.16471", "pdf": "https://arxiv.org/pdf/2506.16471", "abs": "https://arxiv.org/abs/2506.16471", "authors": ["Tara Akhound-Sadegh", "Jungyoon Lee", "Avishek Joey Bose", "Valentin De Bortoli", "Arnaud Doucet", "Michael M. Bronstein", "Dominique Beaini", "Siamak Ravanbakhsh", "Kirill Neklyudov", "Alexander Tong"], "title": "Progressive Inference-Time Annealing of Diffusion Models for Sampling from Boltzmann Densities", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Sampling efficiently from a target unnormalized probability density remains a\ncore challenge, with relevance across countless high-impact scientific\napplications. A promising approach towards this challenge is the design of\namortized samplers that borrow key ideas, such as probability path design, from\nstate-of-the-art generative diffusion models. However, all existing\ndiffusion-based samplers remain unable to draw samples from distributions at\nthe scale of even simple molecular systems. In this paper, we propose\nProgressive Inference-Time Annealing (PITA), a novel framework to learn\ndiffusion-based samplers that combines two complementary interpolation\ntechniques: I.) Annealing of the Boltzmann distribution and II.) Diffusion\nsmoothing. PITA trains a sequence of diffusion models from high to low\ntemperatures by sequentially training each model at progressively higher\ntemperatures, leveraging engineered easy access to samples of the\ntemperature-annealed target density. In the subsequent step, PITA enables\nsimulating the trained diffusion model to procure training samples at a lower\ntemperature for the next diffusion model through inference-time annealing using\na novel Feynman-Kac PDE combined with Sequential Monte Carlo. Empirically, PITA\nenables, for the first time, equilibrium sampling of N-body particle systems,\nAlanine Dipeptide, and tripeptides in Cartesian coordinates with dramatically\nlower energy function evaluations. Code available at:\nhttps://github.com/taraak/pita", "AI": {"tldr": "PITA\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6269\u6563\u91c7\u6837\u6846\u67b6\uff0c\u7ed3\u5408\u9000\u706b\u548c\u6269\u6563\u5e73\u6ed1\u6280\u672f\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u590d\u6742\u5206\u5b50\u7cfb\u7edf\u7684\u5e73\u8861\u91c7\u6837\u3002", "motivation": "\u9ad8\u6548\u91c7\u6837\u672a\u5f52\u4e00\u5316\u6982\u7387\u5bc6\u5ea6\u662f\u6838\u5fc3\u6311\u6218\uff0c\u73b0\u6709\u6269\u6563\u91c7\u6837\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u7b80\u5355\u5206\u5b50\u7cfb\u7edf\u3002", "method": "PITA\u7ed3\u5408Boltzmann\u5206\u5e03\u7684\u9000\u706b\u548c\u6269\u6563\u5e73\u6ed1\uff0c\u901a\u8fc7\u9010\u6b65\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u5e76\u5229\u7528Feynman-Kac PDE\u4e0eSequential Monte Carlo\u5b9e\u73b0\u63a8\u7406\u65f6\u9000\u706b\u3002", "result": "PITA\u9996\u6b21\u5b9e\u73b0\u4e86N\u4f53\u7c92\u5b50\u7cfb\u7edf\u3001Alanine Dipeptide\u548c\u4e09\u80bd\u7684\u5e73\u8861\u91c7\u6837\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u80fd\u91cf\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u3002", "conclusion": "PITA\u4e3a\u590d\u6742\u7cfb\u7edf\u7684\u6269\u6563\u91c7\u6837\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.16494", "pdf": "https://arxiv.org/pdf/2506.16494", "abs": "https://arxiv.org/abs/2506.16494", "authors": ["Amir Reza Vazifeh", "Jason W. Fleischer"], "title": "Manifold Learning for Personalized and Label-Free Detection of Cardiac Arrhythmias", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Electrocardiograms (ECGs) provide direct, non-invasive measurements of heart\nactivity and are well-established tools for detecting and monitoring\ncardiovascular disease. However, manual ECG analysis can be time-consuming and\nprone to errors. Machine learning has emerged as a promising approach for\nautomated heartbeat recognition and classification, but substantial variations\nin ECG signals make it challenging to develop generalizable models. ECG signals\ncan vary widely across individuals and leads, while datasets often follow\ndifferent labeling standards and may be biased, all of which greatly hinder\nsupervised methods. Conventional unsupervised methods, e.g. principal component\nanalysis, prioritize large (and often obvious) variances in the data and\ntypically overlook subtle yet clinically relevant patterns. If labels are\nmissing and/or variations are significant but small, both approaches fail.\nHere, we show that nonlinear dimensionality reduction (NLDR) can accommodate\nthese issues and identify medically relevant features in ECG signals, with no\nneed for training or prior information. Using the MLII and V1 leads of the\nMIT-BIH dataset, we demonstrate that t-distributed stochastic neighbor\nembedding and uniform manifold approximation and projection can discriminate\nindividual recordings in mixed populations with >= 90% accuracy and distinguish\ndifferent arrhythmias in individual patients with a median accuracy of 98.96%\nand a median F1-score of 91.02%. The results show that NLDR holds much promise\nfor cardiac monitoring, including the limiting cases of single-lead ECG and the\ncurrent 12-lead standard of care, and for personalized health care beyond\ncardiology.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u7ebf\u6027\u964d\u7ef4\uff08NLDR\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u8bc6\u522b\u548c\u5206\u7c7b\u5fc3\u7535\u56fe\uff08ECG\uff09\u4fe1\u53f7\u4e2d\u7684\u533b\u5b66\u76f8\u5173\u7279\u5f81\uff0c\u65e0\u9700\u8bad\u7ec3\u6216\u5148\u9a8c\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548cF1\u5206\u6570\u3002", "motivation": "\u624b\u52a8ECG\u5206\u6790\u8017\u65f6\u4e14\u6613\u9519\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53d7\u9650\u4e8e\u4fe1\u53f7\u53d8\u5f02\u6027\u548c\u6570\u636e\u504f\u5dee\uff0c\u800c\u65e0\u76d1\u7763\u65b9\u6cd5\u5e38\u5ffd\u7565\u7ec6\u5fae\u4f46\u4e34\u5e8a\u76f8\u5173\u7684\u6a21\u5f0f\u3002", "method": "\u91c7\u7528\u975e\u7ebf\u6027\u964d\u7ef4\u6280\u672f\uff08\u5982t-SNE\u548cUMAP\uff09\uff0c\u5728MIT-BIH\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "result": "\u5728\u6df7\u5408\u4eba\u7fa4\u4e2d\u533a\u5206\u4e2a\u4f53\u8bb0\u5f55\u7684\u51c6\u786e\u7387\u226590%\uff0c\u5728\u5355\u4e2a\u60a3\u8005\u4e2d\u533a\u5206\u4e0d\u540c\u5fc3\u5f8b\u5931\u5e38\u7684\u4e2d\u4f4d\u51c6\u786e\u7387\u4e3a98.96%\uff0c\u4e2d\u4f4dF1\u5206\u6570\u4e3a91.02%\u3002", "conclusion": "NLDR\u5728\u5fc3\u810f\u76d1\u6d4b\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u9002\u7528\u4e8e\u5355\u5bfc\u8054\u548c12\u5bfc\u8054ECG\uff0c\u5e76\u53ef\u6269\u5c55\u81f3\u4e2a\u6027\u5316\u533b\u7597\u7684\u5176\u4ed6\u9886\u57df\u3002"}}
{"id": "2506.16500", "pdf": "https://arxiv.org/pdf/2506.16500", "abs": "https://arxiv.org/abs/2506.16500", "authors": ["Samir Khaki", "Xiuyu Li", "Junxian Guo", "Ligeng Zhu", "Chenfeng Xu", "Konstantinos N. Plataniotis", "Amir Yazdanbakhsh", "Kurt Keutzer", "Song Han", "Zhijian Liu"], "title": "SparseLoRA: Accelerating LLM Fine-Tuning with Contextual Sparsity", "categories": ["cs.LG"], "comment": "ICML 2025. The first three authors contributed equally to this work.\n  Project page: https://z-lab.ai/projects/sparselora", "summary": "Fine-tuning LLMs is both computationally and memory-intensive. While\nparameter-efficient fine-tuning methods, such as QLoRA and DoRA, reduce the\nnumber of trainable parameters and lower memory usage, they do not decrease\ncomputational cost. In some cases, they may even slow down fine-tuning. In this\npaper, we introduce SparseLoRA, a method that accelerates LLM fine-tuning\nthrough contextual sparsity. We propose a lightweight, training-free SVD\nsparsity estimator that dynamically selects a sparse subset of weights for loss\nand gradient computation. Also, we systematically analyze and address\nsensitivity across layers, tokens, and training steps. Our experimental results\nshow that SparseLoRA reduces computational cost by up to 2.2 times and a\nmeasured speedup of up to 1.6 times while maintaining accuracy across various\ndownstream tasks, including commonsense and arithmetic reasoning, code\ngeneration, and instruction following.", "AI": {"tldr": "SparseLoRA\u662f\u4e00\u79cd\u901a\u8fc7\u4e0a\u4e0b\u6587\u7a00\u758f\u6027\u52a0\u901fLLM\u5fae\u8c03\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u5e76\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff08\u5982QLoRA\u548cDoRA\uff09\u867d\u51cf\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\u548c\u5185\u5b58\u4f7f\u7528\uff0c\u4f46\u672a\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u751a\u81f3\u53ef\u80fd\u51cf\u6162\u5fae\u8c03\u901f\u5ea6\u3002", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u3001\u65e0\u9700\u8bad\u7ec3\u7684SVD\u7a00\u758f\u6027\u4f30\u8ba1\u5668\uff0c\u52a8\u6001\u9009\u62e9\u7a00\u758f\u6743\u91cd\u5b50\u96c6\u8fdb\u884c\u635f\u5931\u548c\u68af\u5ea6\u8ba1\u7b97\uff0c\u5e76\u7cfb\u7edf\u5206\u6790\u5c42\u3001\u6807\u8bb0\u548c\u8bad\u7ec3\u6b65\u9aa4\u7684\u654f\u611f\u6027\u3002", "result": "\u5b9e\u9a8c\u663e\u793aSparseLoRA\u5c06\u8ba1\u7b97\u6210\u672c\u964d\u4f4e2.2\u500d\uff0c\u5b9e\u6d4b\u52a0\u901f1.6\u500d\uff0c\u540c\u65f6\u5728\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4fdd\u6301\u51c6\u786e\u6027\u3002", "conclusion": "SparseLoRA\u5728\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\uff0c\u4e0d\u727a\u7272\u6a21\u578b\u6027\u80fd\uff0c\u4e3aLLM\u5fae\u8c03\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16506", "pdf": "https://arxiv.org/pdf/2506.16506", "abs": "https://arxiv.org/abs/2506.16506", "authors": ["Ronald Skorobogat", "Karsten Roth", "Mariana-Iuliana Georgescu", "Zeynep Akata"], "title": "Subspace-Boosted Model Merging", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "21 pages (main + supp)", "summary": "Model merging enables the combination of multiple specialized expert models\ninto a single model capable of performing multiple tasks. However, the benefits\nof merging an increasing amount of specialized experts generally lead to\ndiminishing returns and reduced overall performance gains. In this work, we\noffer an explanation and analysis from a task arithmetic perspective; revealing\nthat as the merging process (across numerous existing merging methods)\ncontinues for more and more experts, the associated task vector space\nexperiences rank collapse. To mitigate this issue, we introduce Subspace\nBoosting, which operates on the singular value decomposed task vector space and\nmaintains task vector ranks. Subspace Boosting raises merging efficacy for up\nto 20 expert models by large margins of more than 10% when evaluated on vision\nbenchmarks. Moreover, we propose employing Higher-Order Generalized Singular\nValue Decomposition to further quantify task similarity, offering a new\ninterpretable perspective on model merging.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSubspace Boosting\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ef4\u6301\u4efb\u52a1\u5411\u91cf\u79e9\u6765\u89e3\u51b3\u6a21\u578b\u5408\u5e76\u4e2d\u7684\u79e9\u5d29\u6e83\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u5408\u5e76\u6548\u679c\u3002", "motivation": "\u968f\u7740\u5408\u5e76\u4e13\u5bb6\u6a21\u578b\u6570\u91cf\u7684\u589e\u52a0\uff0c\u6027\u80fd\u589e\u76ca\u9012\u51cf\uff0c\u4efb\u52a1\u5411\u91cf\u7a7a\u95f4\u51fa\u73b0\u79e9\u5d29\u6e83\u3002", "method": "\u91c7\u7528Subspace Boosting\u65b9\u6cd5\uff0c\u57fa\u4e8e\u5947\u5f02\u503c\u5206\u89e3\u7684\u4efb\u52a1\u5411\u91cf\u7a7a\u95f4\u7ef4\u6301\u79e9\uff0c\u5e76\u4f7f\u7528\u9ad8\u9636\u5e7f\u4e49\u5947\u5f02\u503c\u5206\u89e3\u91cf\u5316\u4efb\u52a1\u76f8\u4f3c\u6027\u3002", "result": "\u5728\u89c6\u89c9\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSubspace Boosting\u5c06\u5408\u5e76\u6548\u679c\u63d0\u5347\u8d85\u8fc710%\uff0c\u652f\u6301\u591a\u8fbe20\u4e2a\u4e13\u5bb6\u6a21\u578b\u3002", "conclusion": "Subspace Boosting\u6709\u6548\u89e3\u51b3\u4e86\u6a21\u578b\u5408\u5e76\u4e2d\u7684\u79e9\u5d29\u6e83\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e86\u4efb\u52a1\u76f8\u4f3c\u6027\u7684\u65b0\u89c6\u89d2\u3002"}}
{"id": "2506.16507", "pdf": "https://arxiv.org/pdf/2506.16507", "abs": "https://arxiv.org/abs/2506.16507", "authors": ["Pragya Srivastava", "Harman Singh", "Rahul Madhavan", "Gandharv Patil", "Sravanti Addepalli", "Arun Suggala", "Rengarajan Aravamudhan", "Soumya Sharma", "Anirban Laha", "Aravindan Raghuveer", "Karthikeyan Shanmugam", "Doina Precup"], "title": "Robust Reward Modeling via Causal Rubrics", "categories": ["cs.LG"], "comment": null, "summary": "Reward models (RMs) are fundamental to aligning Large Language Models (LLMs)\nvia human feedback, yet they often suffer from reward hacking. They tend to\nlatch on to superficial or spurious attributes, such as response length or\nformatting, mistaking these cues learned from correlations in training data for\nthe true causal drivers of quality (e.g., factuality, relevance). This occurs\nbecause standard training objectives struggle to disentangle these factors,\nleading to brittle RMs and misaligned policies. We introduce Crome (Causally\nRobust Reward Modeling), a novel framework grounded in an explicit causal model\ndesigned to mitigate reward hacking. Crome employs the following synthetic\ntargeted augmentations during training: (1) Causal Augmentations, which are\npairs that differ along specific causal attributes, to enforce sensitivity\nalong each causal attribute individually, and (2) Neutral Augmentations, which\nare tie-label pairs varying primarily in spurious attributes, to enforce\ninvariance along spurious attributes. Notably, our augmentations are produced\nwithout any knowledge of spurious factors, via answer interventions only along\ncausal rubrics, that are identified by querying an oracle LLM. Empirically,\nCrome significantly outperforms standard baselines on RewardBench, improving\naverage accuracy by up to 5.4% and achieving gains of up to 13.2% and 7.2% in\nspecific categories. The robustness of Crome is further testified by the\nconsistent gains obtained in a Best-of-N inference setting across increasing N,\nacross various benchmarks, including the popular RewardBench (covering chat,\nchat-hard, safety, and reasoning tasks), the safety-focused WildGuardTest, and\nthe reasoning-specific GSM8k.", "AI": {"tldr": "Crome\u662f\u4e00\u4e2a\u57fa\u4e8e\u56e0\u679c\u6a21\u578b\u7684\u5956\u52b1\u5efa\u6a21\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5956\u52b1\u6a21\u578b\u4e2d\u7684\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898\uff0c\u901a\u8fc7\u56e0\u679c\u589e\u5f3a\u548c\u4e2d\u6027\u589e\u5f3a\u63d0\u5347\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5956\u52b1\u6a21\u578b\uff08RMs\uff09\u5728\u901a\u8fc7\u4eba\u7c7b\u53cd\u9988\u5bf9\u9f50\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u65f6\u5bb9\u6613\u53d7\u5230\u5956\u52b1\u9ed1\u5ba2\u7684\u5f71\u54cd\uff0c\u5373\u6a21\u578b\u4f1a\u9519\u8bef\u5730\u5c06\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u8868\u9762\u6216\u865a\u5047\u5c5e\u6027\uff08\u5982\u54cd\u5e94\u957f\u5ea6\u6216\u683c\u5f0f\uff09\u4e0e\u8d28\u91cf\uff08\u5982\u4e8b\u5b9e\u6027\u3001\u76f8\u5173\u6027\uff09\u6df7\u6dc6\u3002", "method": "Crome\u901a\u8fc7\u4e24\u79cd\u5408\u6210\u589e\u5f3a\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3\uff1a\u56e0\u679c\u589e\u5f3a\uff08\u9488\u5bf9\u56e0\u679c\u5c5e\u6027\uff09\u548c\u4e2d\u6027\u589e\u5f3a\uff08\u9488\u5bf9\u865a\u5047\u5c5e\u6027\uff09\uff0c\u4e14\u65e0\u9700\u4e8b\u5148\u4e86\u89e3\u865a\u5047\u56e0\u7d20\u3002", "result": "\u5728RewardBench\u4e0a\uff0cCrome\u5e73\u5747\u51c6\u786e\u7387\u63d0\u53475.4%\uff0c\u7279\u5b9a\u7c7b\u522b\u63d0\u5347\u9ad8\u8fbe13.2%\u548c7.2%\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "Crome\u663e\u8457\u63d0\u5347\u4e86\u5956\u52b1\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898\u3002"}}
{"id": "2506.16528", "pdf": "https://arxiv.org/pdf/2506.16528", "abs": "https://arxiv.org/abs/2506.16528", "authors": ["Bornali Phukon", "Xiuwen Zheng", "Mark Hasegawa-Johnson"], "title": "Aligning ASR Evaluation with Human and LLM Judgments: Intelligibility Metrics Using Phonetic, Semantic, and NLI Approaches", "categories": ["cs.LG"], "comment": "5 pages, 2 figures, Interspeech 2025", "summary": "Traditional ASR metrics like WER and CER fail to capture intelligibility,\nespecially for dysarthric and dysphonic speech, where semantic alignment\nmatters more than exact word matches. ASR systems struggle with these speech\ntypes, often producing errors like phoneme repetitions and imprecise\nconsonants, yet the meaning remains clear to human listeners. We identify two\nkey challenges: (1) Existing metrics do not adequately reflect intelligibility,\nand (2) while LLMs can refine ASR output, their effectiveness in correcting ASR\ntranscripts of dysarthric speech remains underexplored. To address this, we\npropose a novel metric integrating Natural Language Inference (NLI) scores,\nsemantic similarity, and phonetic similarity. Our ASR evaluation metric\nachieves a 0.890 correlation with human judgments on Speech Accessibility\nProject data, surpassing traditional methods and emphasizing the need to\nprioritize intelligibility over error-based measures.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684ASR\u8bc4\u4f30\u6307\u6807\uff0c\u7ed3\u5408\u4e86NLI\u5206\u6570\u3001\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u8bed\u97f3\u76f8\u4f3c\u6027\uff0c\u4ee5\u66f4\u597d\u5730\u6355\u6349\u8bed\u97f3\u7684\u53ef\u7406\u89e3\u6027\uff0c\u5c24\u5176\u5728\u53d1\u97f3\u969c\u788d\u8bed\u97f3\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u6307\u6807\u3002", "motivation": "\u4f20\u7edfASR\u6307\u6807\uff08\u5982WER\u548cCER\uff09\u65e0\u6cd5\u6709\u6548\u6355\u6349\u8bed\u97f3\u7684\u53ef\u7406\u89e3\u6027\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u53d1\u97f3\u969c\u788d\u8bed\u97f3\uff0c\u8bed\u4e49\u5bf9\u9f50\u6bd4\u7cbe\u786e\u5339\u914d\u66f4\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6307\u6807\uff0c\u6574\u5408\u4e86\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff08NLI\uff09\u5206\u6570\u3001\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u8bed\u97f3\u76f8\u4f3c\u6027\u3002", "result": "\u65b0\u6307\u6807\u5728Speech Accessibility Project\u6570\u636e\u4e0a\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u76f8\u5173\u7cfb\u6570\u8fbe\u52300.890\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u5728ASR\u8bc4\u4f30\u4e2d\u4f18\u5148\u8003\u8651\u53ef\u7406\u89e3\u6027\u800c\u975e\u57fa\u4e8e\u9519\u8bef\u6307\u6807\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.16548", "pdf": "https://arxiv.org/pdf/2506.16548", "abs": "https://arxiv.org/abs/2506.16548", "authors": ["Arjun Dosajh", "Mihika Sanghi"], "title": "Mr. Snuffleupagus at SemEval-2025 Task 4: Unlearning Factual Knowledge from LLMs Using Adaptive RMU", "categories": ["cs.LG", "I.2.7"], "comment": "7 pages, 2 figures, to be published in SemEval-2025", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding and generation. However, their tendency to\nmemorize training data raises concerns regarding privacy, copyright compliance,\nand security, particularly in cases involving Personally Identifiable\nInformation (PII). Effective machine unlearning techniques are essential to\nmitigate these risks, yet existing methods remain underdeveloped for LLMs due\nto their open-ended output space. In this work, we apply the Adaptive\nRepresentation Misdirection Unlearning (RMU) technique to unlearn sensitive\ninformation from LLMs. Through extensive experiments, we analyze the effects of\nunlearning across different decoder layers to determine the most effective\nregions for sensitive information removal. Our technique ranked 4th on the\nofficial leaderboard of both 1B parameter and 7B parameter models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u8868\u793a\u8bef\u5bfc\u9057\u5fd8\uff08RMU\uff09\u6280\u672f\uff0c\u7528\u4e8e\u4ece\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u5220\u9664\u654f\u611f\u4fe1\u606f\uff0c\u4ee5\u89e3\u51b3\u9690\u79c1\u548c\u7248\u6743\u95ee\u9898\u3002", "motivation": "LLMs\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\u7684\u7279\u6027\u53ef\u80fd\u5f15\u53d1\u9690\u79c1\u3001\u7248\u6743\u548c\u5b89\u5168\u95ee\u9898\uff0c\u5c24\u5176\u662f\u6d89\u53ca\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f\uff08PII\uff09\u65f6\u3002", "method": "\u91c7\u7528\u81ea\u9002\u5e94\u8868\u793a\u8bef\u5bfc\u9057\u5fd8\uff08RMU\uff09\u6280\u672f\uff0c\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u4e0d\u540c\u89e3\u7801\u5c42\u5bf9\u654f\u611f\u4fe1\u606f\u5220\u9664\u7684\u6548\u679c\u3002", "result": "\u8be5\u6280\u672f\u57281B\u548c7B\u53c2\u6570\u6a21\u578b\u7684\u5b98\u65b9\u6392\u884c\u699c\u4e0a\u5747\u6392\u540d\u7b2c4\u3002", "conclusion": "RMU\u6280\u672f\u4e3aLLMs\u4e2d\u7684\u654f\u611f\u4fe1\u606f\u5220\u9664\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2506.16550", "pdf": "https://arxiv.org/pdf/2506.16550", "abs": "https://arxiv.org/abs/2506.16550", "authors": ["Swagatam Das"], "title": "A Free Probabilistic Framework for Analyzing the Transformer-based Language Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We outline an operator-theoretic framework for analyzing transformer-based\nlanguage models using the tools of free probability theory. By representing\ntoken embeddings and attention mechanisms as self-adjoint operators in a racial\nprobability space, we reinterpret attention as a non-commutative convolution\nand view the layer-wise propagation of representations as an evolution governed\nby free additive convolution. This formalism reveals a spectral dynamical\nsystem underpinning deep transformer stacks and offers insight into their\ninductive biases, generalization behavior, and entropy dynamics. We derive a\ngeneralization bound based on free entropy and demonstrate that the spectral\ntrace of transformer layers evolves predictably with depth. Our approach\nbridges neural architecture with non-commutative harmonic analysis, enabling\nprincipled analysis of information flow and structural complexity in large\nlanguage models", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u7531\u6982\u7387\u7406\u8bba\u7684\u7b97\u5b50\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u5176\u8c31\u52a8\u529b\u5b66\u7cfb\u7edf\u3002", "motivation": "\u901a\u8fc7\u5c06Transformer\u6a21\u578b\u4e2d\u7684\u5d4c\u5165\u548c\u6ce8\u610f\u529b\u673a\u5236\u8868\u793a\u4e3a\u7b97\u5b50\uff0c\u91cd\u65b0\u89e3\u91ca\u5176\u884c\u4e3a\uff0c\u4ee5\u7406\u89e3\u5176\u5f52\u7eb3\u504f\u7f6e\u3001\u6cdb\u5316\u884c\u4e3a\u548c\u71b5\u52a8\u6001\u3002", "method": "\u5c06\u8bcd\u5d4c\u5165\u548c\u6ce8\u610f\u529b\u673a\u5236\u8868\u793a\u4e3a\u81ea\u4f34\u7b97\u5b50\uff0c\u5229\u7528\u81ea\u7531\u52a0\u6027\u5377\u79ef\u5206\u6790\u5c42\u95f4\u8868\u793a\u4f20\u64ad\uff0c\u5e76\u57fa\u4e8e\u81ea\u7531\u71b5\u63a8\u5bfc\u6cdb\u5316\u754c\u3002", "result": "\u63ed\u793a\u4e86Transformer\u5c42\u7684\u8c31\u8ff9\u968f\u6df1\u5ea6\u6f14\u5316\u7684\u89c4\u5f8b\uff0c\u5e76\u63d0\u4f9b\u4e86\u4fe1\u606f\u6d41\u548c\u7ed3\u6784\u590d\u6742\u6027\u7684\u7406\u8bba\u5206\u6790\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4fe1\u606f\u6d41\u548c\u7ed3\u6784\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u8fde\u63a5\u4e86\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4e0e\u975e\u4ea4\u6362\u8c03\u548c\u5206\u6790\u3002"}}
{"id": "2506.16553", "pdf": "https://arxiv.org/pdf/2506.16553", "abs": "https://arxiv.org/abs/2506.16553", "authors": ["Soroush H. Zargarbashi", "Mohammad Sadegh Akhondzadeh", "Aleksandar Bojchevski"], "title": "One Sample is Enough to Make Conformal Prediction Robust", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Given any model, conformal prediction (CP) returns prediction sets guaranteed\nto include the true label with high adjustable probability. Robust CP (RCP)\nextends this to inputs with worst-case noise. A well-established approach is to\nuse randomized smoothing for RCP since it is applicable to any black-box model\nand provides smaller sets compared to deterministic methods. However, current\nsmoothing-based RCP requires many model forward passes per each input which is\ncomputationally expensive. We show that conformal prediction attains some\nrobustness even with a forward pass on a single randomly perturbed input. Using\nany binary certificate we propose a single sample robust CP (RCP1). Our\napproach returns robust sets with smaller average set size compared to SOTA\nmethods which use many (e.g. around 100) passes per input. Our key insight is\nto certify the conformal prediction procedure itself rather than individual\nscores. Our approach is agnostic to the setup (classification and regression).\nWe further extend our approach to smoothing-based robust conformal risk\ncontrol.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5355\u6837\u672c\u7684\u9c81\u68d2\u5171\u5f62\u9884\u6d4b\u65b9\u6cd5\uff08RCP1\uff09\uff0c\u901a\u8fc7\u968f\u673a\u6270\u52a8\u8f93\u5165\u548c\u4e8c\u5143\u8ba4\u8bc1\uff0c\u51cf\u5c11\u4e86\u8ba1\u7b97\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9884\u6d4b\u96c6\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u9c81\u68d2\u5171\u5f62\u9884\u6d4b\uff08RCP\uff09\u9700\u8981\u591a\u6b21\u6a21\u578b\u524d\u5411\u4f20\u64ad\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5355\u6837\u672c\u6270\u52a8\u548c\u8ba4\u8bc1\u65b9\u6cd5\uff0c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "method": "\u4f7f\u7528\u968f\u673a\u6270\u52a8\u8f93\u5165\u548c\u4e8c\u5143\u8ba4\u8bc1\uff0c\u5bf9\u5171\u5f62\u9884\u6d4b\u8fc7\u7a0b\u672c\u8eab\u8fdb\u884c\u8ba4\u8bc1\uff0c\u800c\u975e\u5355\u4e2a\u5206\u6570\u3002\u9002\u7528\u4e8e\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u3002", "result": "RCP1\u5728\u4fdd\u6301\u9c81\u68d2\u6027\u7684\u540c\u65f6\uff0c\u5e73\u5747\u9884\u6d4b\u96c6\u5927\u5c0f\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "RCP1\u4e3a\u9c81\u68d2\u5171\u5f62\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u4efb\u52a1\u3002"}}
{"id": "2506.16590", "pdf": "https://arxiv.org/pdf/2506.16590", "abs": "https://arxiv.org/abs/2506.16590", "authors": ["Zeyun Deng", "Jasorsi Ghosh", "Fiona Xie", "Yuzhe Lu", "Katia Sycara", "Joseph Campbell"], "title": "Energy-Based Transfer for Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning algorithms often suffer from poor sample efficiency,\nmaking them challenging to apply in multi-task or continual learning settings.\nEfficiency can be improved by transferring knowledge from a previously trained\nteacher policy to guide exploration in new but related tasks. However, if the\nnew task sufficiently differs from the teacher's training task, the transferred\nguidance may be sub-optimal and bias exploration toward low-reward behaviors.\nWe propose an energy-based transfer learning method that uses\nout-of-distribution detection to selectively issue guidance, enabling the\nteacher to intervene only in states within its training distribution. We\ntheoretically show that energy scores reflect the teacher's state-visitation\ndensity and empirically demonstrate improved sample efficiency and performance\nacross both single-task and multi-task settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u80fd\u91cf\u7684\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u6307\u5bfc\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u7684\u6837\u672c\u6548\u7387\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u591a\u4efb\u52a1\u6216\u6301\u7eed\u5b66\u4e60\u73af\u5883\u4e2d\u6837\u672c\u6548\u7387\u4f4e\uff0c\u8fc1\u79fb\u77e5\u8bc6\u53ef\u80fd\u56e0\u4efb\u52a1\u5dee\u5f02\u5bfc\u81f4\u6b21\u4f18\u6307\u5bfc\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u80fd\u91cf\u7684\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5e03\u5916\u68c0\u6d4b\u9009\u62e9\u6027\u6307\u5bfc\uff0c\u786e\u4fdd\u6559\u5e08\u4ec5\u5728\u8bad\u7ec3\u5206\u5e03\u5185\u72b6\u6001\u5e72\u9884\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u80fd\u91cf\u5206\u6570\u53cd\u6620\u6559\u5e08\u72b6\u6001\u8bbf\u95ee\u5bc6\u5ea6\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u5355\u4efb\u52a1\u548c\u591a\u4efb\u52a1\u4e2d\u5747\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u548c\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8fc1\u79fb\u5b66\u4e60\u4e2d\u56e0\u4efb\u52a1\u5dee\u5f02\u5bfc\u81f4\u7684\u6307\u5bfc\u504f\u5dee\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u5f3a\u5316\u5b66\u4e60\u7684\u6548\u7387\u3002"}}
{"id": "2506.16600", "pdf": "https://arxiv.org/pdf/2506.16600", "abs": "https://arxiv.org/abs/2506.16600", "authors": ["Khiem Le", "Tuan Tran", "Ting Hua", "Nitesh V. Chawla"], "title": "FLAME: Towards Federated Fine-Tuning Large Language Models Through Adaptive SMoE", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Existing resource-adaptive LoRA federated fine-tuning methods enable clients\nto fine-tune models using compressed versions of global LoRA matrices, in order\nto accommodate various compute resources across clients. This compression\nrequirement will lead to suboptimal performance due to information loss. To\naddress this, we propose FLAME, a novel federated learning framework based on\nthe Sparse Mixture-of-Experts (SMoE) architecture. Unlike prior approaches,\nFLAME retains full (uncompressed) global LoRA matrices and achieves client-side\nadaptability by varying the number of activated experts per client. However,\nincorporating SMoE into federated learning introduces unique challenges,\nspecifically, the mismatch in output magnitude from partial expert activation\nand the imbalance in expert training quality across clients. FLAME tackles\nthese challenges through a lightweight rescaling mechanism and an\nactivation-aware aggregation scheme. Empirical results across diverse\ncomputational settings demonstrate that FLAME consistently outperforms existing\nmethods, providing a robust and effective solution for resource-adaptive\nfederated learning.", "AI": {"tldr": "FLAME\u662f\u4e00\u79cd\u57fa\u4e8e\u7a00\u758f\u4e13\u5bb6\u6df7\u5408\uff08SMoE\uff09\u67b6\u6784\u7684\u65b0\u578b\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u6fc0\u6d3b\u4e13\u5bb6\u6570\u91cf\u5b9e\u73b0\u5ba2\u6237\u7aef\u9002\u5e94\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u56e0\u538b\u7f29\u5168\u5c40LoRA\u77e9\u9635\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u8d44\u6e90\u81ea\u9002\u5e94\u7684LoRA\u8054\u90a6\u5fae\u8c03\u65b9\u6cd5\u56e0\u538b\u7f29\u5168\u5c40LoRA\u77e9\u9635\u5bfc\u81f4\u4fe1\u606f\u4e22\u5931\uff0c\u6027\u80fd\u4e0d\u4f73\u3002FLAME\u65e8\u5728\u901a\u8fc7\u4fdd\u7559\u5b8c\u6574LoRA\u77e9\u9635\u5e76\u52a8\u6001\u8c03\u6574\u4e13\u5bb6\u6570\u91cf\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "FLAME\u91c7\u7528SMoE\u67b6\u6784\uff0c\u4fdd\u7559\u672a\u538b\u7f29\u7684\u5168\u5c40LoRA\u77e9\u9635\uff0c\u901a\u8fc7\u8c03\u6574\u5ba2\u6237\u7aef\u6fc0\u6d3b\u4e13\u5bb6\u6570\u91cf\u5b9e\u73b0\u9002\u5e94\u6027\u3002\u4e3a\u89e3\u51b3\u90e8\u5206\u4e13\u5bb6\u6fc0\u6d3b\u8f93\u51fa\u4e0d\u5339\u914d\u548c\u4e13\u5bb6\u8bad\u7ec3\u8d28\u91cf\u4e0d\u5747\u8861\u95ee\u9898\uff0c\u5f15\u5165\u4e86\u8f7b\u91cf\u7ea7\u91cd\u7f29\u653e\u673a\u5236\u548c\u6fc0\u6d3b\u611f\u77e5\u805a\u5408\u65b9\u6848\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFLAME\u5728\u4e0d\u540c\u8ba1\u7b97\u73af\u5883\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u7a33\u5065\u4e14\u9ad8\u6548\u7684\u8d44\u6e90\u81ea\u9002\u5e94\u8054\u90a6\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "FLAME\u901a\u8fc7SMoE\u67b6\u6784\u548c\u521b\u65b0\u7684\u91cd\u7f29\u653e\u4e0e\u805a\u5408\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8d44\u6e90\u81ea\u9002\u5e94\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6027\u80fd\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u8868\u73b0\u3002"}}
{"id": "2506.16602", "pdf": "https://arxiv.org/pdf/2506.16602", "abs": "https://arxiv.org/abs/2506.16602", "authors": ["Siddharth Viswanath", "Rahul Singh", "Yanlei Zhang", "J. Adam Noah", "Joy Hirsch", "Smita Krishnaswamy"], "title": "SlepNet: Spectral Subgraph Representation Learning for Neural Dynamics", "categories": ["cs.LG"], "comment": null, "summary": "Graph neural networks have been useful in machine learning on\ngraph-structured data, particularly for node classification and some types of\ngraph classification tasks. However, they have had limited use in representing\npatterning of signals over graphs. Patterning of signals over graphs and in\nsubgraphs carries important information in many domains including neuroscience.\nNeural signals are spatiotemporally patterned, high dimensional and difficult\nto decode. Graph signal processing and associated GCN models utilize the graph\nFourier transform and are unable to efficiently represent spatially or\nspectrally localized signal patterning on graphs. Wavelet transforms have shown\npromise here, but offer non-canonical representations and cannot be tightly\nconfined to subgraphs. Here we propose SlepNet, a novel GCN architecture that\nuses Slepian bases rather than graph Fourier harmonics. In SlepNet, the Slepian\nharmonics optimally concentrate signal energy on specifically relevant\nsubgraphs that are automatically learned with a mask. Thus, they can produce\ncanonical and highly resolved representations of neural activity, focusing\nenergy of harmonics on areas of the brain which are activated. We evaluated\nSlepNet across three fMRI datasets, spanning cognitive and visual tasks, and\ntwo traffic dynamics datasets, comparing its performance against conventional\nGNNs and graph signal processing constructs. SlepNet outperforms the baselines\nin all datasets. Moreover, the extracted representations of signal patterns\nfrom SlepNet offers more resolution in distinguishing between similar patterns,\nand thus represent brain signaling transients as informative trajectories. Here\nwe have shown that these extracted trajectory representations can be used for\nother downstream untrained tasks. Thus we establish that SlepNet is useful both\nfor prediction and representation learning in spatiotemporal data.", "AI": {"tldr": "SlepNet\u662f\u4e00\u79cd\u65b0\u578b\u56fe\u5377\u79ef\u7f51\u7edc\u67b6\u6784\uff0c\u5229\u7528Slepian\u57fa\u800c\u975e\u56fe\u5085\u91cc\u53f6\u8c10\u6ce2\uff0c\u4e13\u6ce8\u4e8e\u76f8\u5173\u5b50\u56fe\u4e0a\u7684\u4fe1\u53f7\u80fd\u91cf\u96c6\u4e2d\uff0c\u5728\u795e\u7ecf\u6d3b\u52a8\u548c\u4ea4\u901a\u52a8\u6001\u6570\u636e\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u8868\u793a\u4fe1\u53f7\u6a21\u5f0f\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u5728\u795e\u7ecf\u79d1\u5b66\u7b49\u9886\u57df\u4e2d\uff0c\u4fe1\u53f7\u7684\u9ad8\u7ef4\u548c\u5c40\u90e8\u5316\u7279\u5f81\u96be\u4ee5\u88ab\u4f20\u7edf\u65b9\u6cd5\u6709\u6548\u6355\u6349\u3002", "method": "\u63d0\u51faSlepNet\uff0c\u4f7f\u7528Slepian\u57fa\u81ea\u52a8\u5b66\u4e60\u76f8\u5173\u5b50\u56fe\uff0c\u5e76\u901a\u8fc7\u63a9\u7801\u96c6\u4e2d\u4fe1\u53f7\u80fd\u91cf\uff0c\u751f\u6210\u9ad8\u5206\u8fa8\u7387\u7684\u795e\u7ecf\u6d3b\u52a8\u8868\u793a\u3002", "result": "\u5728\u591a\u4e2afMRI\u548c\u4ea4\u901a\u52a8\u6001\u6570\u636e\u96c6\u4e0a\uff0cSlepNet\u6027\u80fd\u4f18\u4e8e\u4f20\u7edfGNN\u548c\u56fe\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\uff0c\u5e76\u80fd\u66f4\u6e05\u6670\u5730\u533a\u5206\u76f8\u4f3c\u6a21\u5f0f\u3002", "conclusion": "SlepNet\u4e0d\u4ec5\u9002\u7528\u4e8e\u9884\u6d4b\u4efb\u52a1\uff0c\u8fd8\u80fd\u7528\u4e8e\u8868\u793a\u5b66\u4e60\uff0c\u4e3a\u65f6\u7a7a\u6570\u636e\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16608", "pdf": "https://arxiv.org/pdf/2506.16608", "abs": "https://arxiv.org/abs/2506.16608", "authors": ["Jiamin He", "A. Rupam Mahmood", "Martha White"], "title": "Distribution Parameter Actor-Critic: Shifting the Agent-Environment Boundary for Diverse Action Spaces", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce a novel reinforcement learning (RL) framework that treats\ndistribution parameters as actions, redefining the boundary between agent and\nenvironment. This reparameterization makes the new action space continuous,\nregardless of the original action type (discrete, continuous, mixed, etc.).\nUnder this new parameterization, we develop a generalized deterministic policy\ngradient estimator, Distribution Parameter Policy Gradient (DPPG), which has\nlower variance than the gradient in the original action space. Although\nlearning the critic over distribution parameters poses new challenges, we\nintroduce interpolated critic learning (ICL), a simple yet effective strategy\nto enhance learning, supported by insights from bandit settings. Building on\nTD3, a strong baseline for continuous control, we propose a practical\nDPPG-based actor-critic algorithm, Distribution Parameter Actor-Critic (DPAC).\nEmpirically, DPAC outperforms TD3 in MuJoCo continuous control tasks from\nOpenAI Gym and DeepMind Control Suite, and demonstrates competitive performance\non the same environments with discretized action spaces.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u5206\u5e03\u53c2\u6570\u4f5c\u4e3a\u52a8\u4f5c\uff0c\u91cd\u65b0\u5b9a\u4e49\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u7684\u8fb9\u754c\uff0c\u5e76\u901a\u8fc7\u65b0\u7684\u53c2\u6570\u5316\u65b9\u6cd5\u5b9e\u73b0\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5728\u5904\u7406\u79bb\u6563\u6216\u6df7\u5408\u52a8\u4f5c\u7a7a\u95f4\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65b0\u6846\u67b6\u65e8\u5728\u901a\u8fc7\u53c2\u6570\u5316\u5206\u5e03\u53c2\u6570\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u5206\u5e03\u53c2\u6570\u7b56\u7565\u68af\u5ea6\uff08DPPG\uff09\u548c\u63d2\u503c\u8bc4\u8bba\u5bb6\u5b66\u4e60\uff08ICL\uff09\u65b9\u6cd5\uff0c\u5e76\u57fa\u4e8eTD3\u5f00\u53d1\u4e86DPAC\u7b97\u6cd5\u3002", "result": "DPAC\u5728MuJoCo\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8eTD3\uff0c\u5e76\u5728\u79bb\u6563\u5316\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u65b0\u6846\u67b6\u901a\u8fc7\u53c2\u6570\u5316\u5206\u5e03\u53c2\u6570\u6709\u6548\u6269\u5c55\u4e86\u5f3a\u5316\u5b66\u4e60\u7684\u5e94\u7528\u8303\u56f4\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2506.16629", "pdf": "https://arxiv.org/pdf/2506.16629", "abs": "https://arxiv.org/abs/2506.16629", "authors": ["Eric V. Strobl"], "title": "Learning Causally Predictable Outcomes from Psychiatric Longitudinal Data", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "comment": "R code is available at github.com/ericstrobl/DEBIAS", "summary": "Causal inference in longitudinal biomedical data remains a central challenge,\nespecially in psychiatry, where symptom heterogeneity and latent confounding\nfrequently undermine classical estimators. Most existing methods for treatment\neffect estimation presuppose a fixed outcome variable and address confounding\nthrough observed covariate adjustment. However, the assumption of\nunconfoundedness may not hold for a fixed outcome in practice. To address this\nfoundational limitation, we directly optimize the outcome definition to\nmaximize causal identifiability. Our DEBIAS (Durable Effects with\nBackdoor-Invariant Aggregated Symptoms) algorithm learns non-negative,\nclinically interpretable weights for outcome aggregation, maximizing durable\ntreatment effects and empirically minimizing both observed and latent\nconfounding by leveraging the time-limited direct effects of prior treatments\nin psychiatric longitudinal data. The algorithm also furnishes an empirically\nverifiable test for outcome unconfoundedness. DEBIAS consistently outperforms\nstate-of-the-art methods in recovering causal effects for clinically\ninterpretable composite outcomes across comprehensive experiments in depression\nand schizophrenia.", "AI": {"tldr": "DEBIAS\u7b97\u6cd5\u901a\u8fc7\u4f18\u5316\u7ed3\u679c\u5b9a\u4e49\u4ee5\u6700\u5927\u5316\u56e0\u679c\u53ef\u8bc6\u522b\u6027\uff0c\u89e3\u51b3\u4e86\u7cbe\u795e\u75c5\u5b66\u7eb5\u5411\u6570\u636e\u4e2d\u7684\u56e0\u679c\u63a8\u65ad\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u7cbe\u795e\u75c5\u5b66\u4e2d\u75c7\u72b6\u5f02\u8d28\u6027\u548c\u6f5c\u5728\u6df7\u6742\u56e0\u7d20\u4f7f\u4f20\u7edf\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\u5931\u6548\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "DEBIAS\u7b97\u6cd5\u5b66\u4e60\u975e\u8d1f\u3001\u4e34\u5e8a\u53ef\u89e3\u91ca\u7684\u6743\u91cd\uff0c\u901a\u8fc7\u5229\u7528\u65e2\u5f80\u6cbb\u7597\u7684\u65f6\u6ede\u6548\u5e94\u6700\u5927\u5316\u56e0\u679c\u6548\u5e94\u5e76\u6700\u5c0f\u5316\u6df7\u6742\u3002", "result": "\u5728\u6291\u90c1\u548c\u7cbe\u795e\u5206\u88c2\u75c7\u5b9e\u9a8c\u4e2d\uff0cDEBIAS\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6062\u590d\u56e0\u679c\u6548\u5e94\u66f4\u51c6\u786e\u3002", "conclusion": "DEBIAS\u4e3a\u7cbe\u795e\u75c5\u5b66\u7eb5\u5411\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u9a8c\u8bc1\u7684\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\uff0c\u5177\u6709\u4e34\u5e8a\u610f\u4e49\u3002"}}
{"id": "2506.16644", "pdf": "https://arxiv.org/pdf/2506.16644", "abs": "https://arxiv.org/abs/2506.16644", "authors": ["Eren Akbiyik", "Jo\u00e3o Almeida", "Rik Melis", "Ritu Sriram", "Viviana Petrescu", "Vilhj\u00e1lmur Vilhj\u00e1lmsson"], "title": "Semantic Outlier Removal with Embedding Models and LLMs", "categories": ["cs.LG", "cs.IR"], "comment": "Accepted to the 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL 2025) Industry Track, 10 pages", "summary": "Modern text processing pipelines demand robust methods to remove extraneous\ncontent while preserving a document's core message. Traditional approaches such\nas HTML boilerplate extraction or keyword filters often fail in multilingual\nsettings and struggle with context-sensitive nuances, whereas Large Language\nModels (LLMs) offer improved quality at high computational cost. We introduce\nSORE (Semantic Outlier Removal), a cost-effective, transparent method that\nleverages multilingual sentence embeddings and approximate nearest-neighbor\nsearch to identify and excise unwanted text segments. By first identifying core\ncontent via metadata embedding and then flagging segments that either closely\nmatch predefined outlier groups or deviate significantly from the core, SORE\nachieves near-LLM extraction precision at a fraction of the cost. Experiments\non HTML datasets demonstrate that SORE outperforms structural methods and yield\nhigh precision in diverse scenarios. Our system is currently deployed in\nproduction, processing millions of documents daily across multiple languages\nwhile maintaining both efficiency and accuracy. To facilitate reproducibility\nand further research, we release our implementation and evaluation datasets.", "AI": {"tldr": "SORE\u662f\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e49\u5d4c\u5165\u548c\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u53bb\u9664\u6587\u6863\u4e2d\u7684\u65e0\u5173\u5185\u5bb9\uff0c\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\uff08\u5982HTML\u6a21\u677f\u63d0\u53d6\u6216\u5173\u952e\u8bcd\u8fc7\u6ee4\uff09\u5728\u591a\u8bed\u8a00\u548c\u4e0a\u4e0b\u6587\u654f\u611f\u573a\u666f\u4e2d\u6548\u679c\u4e0d\u4f73\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6210\u672c\u8fc7\u9ad8\u3002", "method": "SORE\u5229\u7528\u591a\u8bed\u8a00\u53e5\u5b50\u5d4c\u5165\u548c\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\uff0c\u901a\u8fc7\u5143\u6570\u636e\u5d4c\u5165\u8bc6\u522b\u6838\u5fc3\u5185\u5bb9\uff0c\u5e76\u6807\u8bb0\u4e0e\u9884\u5b9a\u4e49\u5f02\u5e38\u7ec4\u5339\u914d\u6216\u504f\u79bb\u6838\u5fc3\u7684\u6587\u672c\u6bb5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSORE\u5728HTML\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u7ed3\u6784\u65b9\u6cd5\uff0c\u4e14\u5728\u591a\u8bed\u8a00\u573a\u666f\u4e2d\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u548c\u4f4e\u6210\u672c\u3002", "conclusion": "SORE\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u900f\u660e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5df2\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\uff0c\u652f\u6301\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u590d\u73b0\u3002"}}
{"id": "2506.16656", "pdf": "https://arxiv.org/pdf/2506.16656", "abs": "https://arxiv.org/abs/2506.16656", "authors": ["Yaozhong Shi", "Zachary E. Ross", "Domniki Asimaki", "Kamyar Azizzadenesheli"], "title": "Mesh-Informed Neural Operator : A Transformer Generative Approach", "categories": ["cs.LG"], "comment": null, "summary": "Generative models in function spaces, situated at the intersection of\ngenerative modeling and operator learning, are attracting increasing attention\ndue to their immense potential in diverse scientific and engineering\napplications. While functional generative models are theoretically domain- and\ndiscretization-agnostic, current implementations heavily rely on the Fourier\nNeural Operator (FNO), limiting their applicability to regular grids and\nrectangular domains. To overcome these critical limitations, we introduce the\nMesh-Informed Neural Operator (MINO). By leveraging graph neural operators and\ncross-attention mechanisms, MINO offers a principled, domain- and\ndiscretization-agnostic backbone for generative modeling in function spaces.\nThis advancement significantly expands the scope of such models to more diverse\napplications in generative, inverse, and regression tasks. Furthermore, MINO\nprovides a unified perspective on integrating neural operators with general\nadvanced deep learning architectures. Finally, we introduce a suite of\nstandardized evaluation metrics that enable objective comparison of functional\ngenerative models, addressing another critical gap in the field.", "AI": {"tldr": "\u63d0\u51fa\u4e86Mesh-Informed Neural Operator (MINO)\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u529f\u80fd\u751f\u6210\u6a21\u578b\u5bf9\u89c4\u5219\u7f51\u683c\u548c\u77e9\u5f62\u57df\u7684\u4f9d\u8d56\u95ee\u9898\uff0c\u6269\u5c55\u4e86\u5e94\u7528\u8303\u56f4\u3002", "motivation": "\u5f53\u524d\u529f\u80fd\u751f\u6210\u6a21\u578b\u53d7\u9650\u4e8eFourier Neural Operator (FNO)\uff0c\u4ec5\u9002\u7528\u4e8e\u89c4\u5219\u7f51\u683c\u548c\u77e9\u5f62\u57df\uff0c\u9650\u5236\u4e86\u5176\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u56fe\u795e\u7ecf\u7b97\u5b50\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5f00\u53d1\u4e86MINO\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u4e0e\u57df\u548c\u79bb\u6563\u5316\u65e0\u5173\u7684\u751f\u6210\u5efa\u6a21\u6846\u67b6\u3002", "result": "MINO\u663e\u8457\u6269\u5c55\u4e86\u529f\u80fd\u751f\u6210\u6a21\u578b\u7684\u5e94\u7528\u8303\u56f4\uff0c\u5e76\u63d0\u4f9b\u4e86\u7edf\u4e00\u89c6\u89d2\u4ee5\u6574\u5408\u795e\u7ecf\u7b97\u5b50\u548c\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u3002", "conclusion": "MINO\u586b\u8865\u4e86\u529f\u80fd\u751f\u6210\u6a21\u578b\u9886\u57df\u7684\u7a7a\u767d\uff0c\u5e76\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u6307\u6807\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.16659", "pdf": "https://arxiv.org/pdf/2506.16659", "abs": "https://arxiv.org/abs/2506.16659", "authors": ["Athanasios Glentis", "Jiaxiang Li", "Andi Han", "Mingyi Hong"], "title": "A Minimalist Optimizer Design for LLM Pretraining", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "Training large language models (LLMs) typically relies on adaptive optimizers\nsuch as Adam, which require significant memory to maintain first- and\nsecond-moment matrices, known as optimizer states. While recent works such as\nGaLore, Fira, and APOLLO have proposed state-compressed variants to reduce\nmemory consumption, a fundamental question remains: What is the minimal amount\nof optimizer state that is truly necessary to retain state-of-the-art\nperformance in LLM pretraining? In this work, we systematically investigate\nthis question using a bottom-up approach. We find that two memory- and\ncompute-efficient optimization techniques are particularly effective: (1)\ncolumn-wise gradient normalization significantly boosts the performance of\nplain SGD without requiring momentum; and (2) adding first-order momentum only\nto the output layer - where gradient variance is highest - yields performance\ncompetitive with fully adaptive methods such as Muon. Based on these insights,\nwe propose SCALE (Stochastic Column-normalized Last-layer Momentum), a new\noptimizer that combines column-normalized SGD with last-layer momentum, where\ncolumn normalization refers to normalizing the gradient along the output\ndimension. Across multiple LLaMA models (60M-1B), SCALE matches or exceeds the\nperformance of Adam while using only 35-45% of the total memory. It also\nconsistently outperforms memory-efficient optimizers such as GaLore, Fira, and\nAPOLLO, making it a strong candidate for large-scale pretraining under memory\nconstraints. For the LLaMA 7B model, SCALE outperforms the state-of-the-art\nmethod APOLLO in terms of both perplexity and memory consumption. In addition,\nour method serves as a minimalist baseline for more sophisticated optimizer\ndesign.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9884\u8bad\u7ec3\u4e2d\u4f18\u5316\u5668\u72b6\u6001\u7684\u6700\u5c0f\u9700\u6c42\uff0c\u63d0\u51fa\u4e86SCALE\u4f18\u5316\u5668\uff0c\u7ed3\u5408\u5217\u5f52\u4e00\u5316SGD\u548c\u6700\u540e\u4e00\u5c42\u52a8\u91cf\uff0c\u663e\u8457\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u5e76\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u63a2\u7d22\u5728LLM\u9884\u8bad\u7ec3\u4e2d\uff0c\u4f18\u5316\u5668\u72b6\u6001\u7684\u6700\u5c0f\u9700\u6c42\uff0c\u4ee5\u51cf\u5c11\u5185\u5b58\u6d88\u8017\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "method": "\u91c7\u7528\u81ea\u4e0b\u800c\u4e0a\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u5217\u5f52\u4e00\u5316SGD\u548c\u6700\u540e\u4e00\u5c42\u52a8\u91cf\uff0c\u63d0\u51faSCALE\u4f18\u5316\u5668\u3002", "result": "SCALE\u5728\u591a\u4e2aLLaMA\u6a21\u578b\u4e0a\u6027\u80fd\u4f18\u4e8eAdam\uff0c\u5185\u5b58\u4f7f\u7528\u4ec5\u4e3a35-45%\uff0c\u5e76\u8d85\u8d8a\u5176\u4ed6\u9ad8\u6548\u4f18\u5316\u5668\u3002", "conclusion": "SCALE\u662f\u4e00\u79cd\u5185\u5b58\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u4f18\u5316\u5668\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\uff0c\u5e76\u4e3a\u672a\u6765\u4f18\u5316\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7b80\u6d01\u57fa\u7ebf\u3002"}}
{"id": "2506.16661", "pdf": "https://arxiv.org/pdf/2506.16661", "abs": "https://arxiv.org/abs/2506.16661", "authors": ["Felix Zhou", "Samson Zhou", "Vahab Mirrokni", "Alessandro Epasto", "Vincent Cohen-Addad"], "title": "Private Training & Data Generation by Clustering Embeddings", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": null, "summary": "Deep neural networks often use large, high-quality datasets to achieve high\nperformance on many machine learning tasks. When training involves potentially\nsensitive data, this process can raise privacy concerns, as large models have\nbeen shown to unintentionally memorize and reveal sensitive information,\nincluding reconstructing entire training samples. Differential privacy (DP)\nprovides a robust framework for protecting individual data and in particular, a\nnew approach to privately training deep neural networks is to approximate the\ninput dataset with a privately generated synthetic dataset, before any\nsubsequent training algorithm. We introduce a novel principled method for DP\nsynthetic image embedding generation, based on fitting a Gaussian Mixture Model\n(GMM) in an appropriate embedding space using DP clustering. Our method\nprovably learns a GMM under separation conditions. Empirically, a simple\ntwo-layer neural network trained on synthetically generated embeddings achieves\nstate-of-the-art (SOTA) classification accuracy on standard benchmark datasets.\nAdditionally, we demonstrate that our method can generate realistic synthetic\nimages that achieve downstream classification accuracy comparable to SOTA\nmethods. Our method is quite general, as the encoder and decoder modules can be\nfreely substituted to suit different tasks. It is also highly scalable,\nconsisting only of subroutines that scale linearly with the number of samples\nand/or can be implemented efficiently in distributed systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u7684\u5408\u6210\u56fe\u50cf\u5d4c\u5165\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMM\uff09\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\uff0c\u5e76\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u6cc4\u9732\u654f\u611f\u6570\u636e\u7684\u9690\u79c1\u95ee\u9898\u3002", "method": "\u4f7f\u7528DP\u805a\u7c7b\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u62df\u5408GMM\uff0c\u751f\u6210\u5408\u6210\u56fe\u50cf\u5d4c\u5165\uff0c\u5e76\u901a\u8fc7\u7b80\u5355\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5728\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86SOTA\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u5e76\u80fd\u751f\u6210\u903c\u771f\u7684\u5408\u6210\u56fe\u50cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u7528\u6027\u5f3a\u3001\u53ef\u6269\u5c55\u6027\u597d\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u4efb\u52a1\u3002"}}
{"id": "2506.16688", "pdf": "https://arxiv.org/pdf/2506.16688", "abs": "https://arxiv.org/abs/2506.16688", "authors": ["Zhiying Qiu", "Tao Lin"], "title": "Fast and Stable Diffusion Planning through Variational Adaptive Weighting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion models have recently shown promise in offline RL. However, these\nmethods often suffer from high training costs and slow convergence,\nparticularly when using transformer-based denoising backbones. While several\noptimization strategies have been proposed -- such as modified noise schedules,\nauxiliary prediction targets, and adaptive loss weighting -- challenges remain\nin achieving stable and efficient training. In particular, existing loss\nweighting functions typically rely on neural network approximators, which can\nbe ineffective in early training phases due to limited generalization capacity\nof MLPs when exposed to sparse feedback in the early training stages. In this\nwork, we derive a variationally optimal uncertainty-aware weighting function\nand introduce a closed-form polynomial approximation method for its online\nestimation under the flow-based generative modeling framework. We integrate our\nmethod into a diffusion planning pipeline and evaluate it on standard offline\nRL benchmarks. Experimental results on Maze2D and Kitchen tasks show that our\nmethod achieves competitive performance with up to 10 times fewer training\nsteps, highlighting its practical effectiveness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u5206\u6700\u4f18\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u6743\u91cd\u51fd\u6570\u53ca\u5176\u95ed\u5f0f\u591a\u9879\u5f0f\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347\u6269\u6563\u6a21\u578b\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8bad\u7ec3\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5b58\u5728\u8bad\u7ec3\u6210\u672c\u9ad8\u3001\u6536\u655b\u6162\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u4f7f\u7528\u57fa\u4e8eTransformer\u7684\u53bb\u566a\u9aa8\u5e72\u65f6\u3002\u73b0\u6709\u7684\u6743\u91cd\u51fd\u6570\u4f9d\u8d56\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u5668\uff0c\u5728\u65e9\u671f\u8bad\u7ec3\u9636\u6bb5\u56e0MLP\u6cdb\u5316\u80fd\u529b\u6709\u9650\u800c\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53d8\u5206\u6700\u4f18\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6743\u91cd\u51fd\u6570\uff0c\u5e76\u5f15\u5165\u95ed\u5f0f\u591a\u9879\u5f0f\u8fd1\u4f3c\u65b9\u6cd5\u8fdb\u884c\u5728\u7ebf\u4f30\u8ba1\uff0c\u5c06\u5176\u96c6\u6210\u5230\u6269\u6563\u89c4\u5212\u6d41\u7a0b\u4e2d\u3002", "result": "\u5728Maze2D\u548cKitchen\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u76f8\u5f53\u7684\u60c5\u51b5\u4e0b\uff0c\u8bad\u7ec3\u6b65\u6570\u51cf\u5c11\u9ad8\u8fbe10\u500d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6269\u6563\u6a21\u578b\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8bad\u7ec3\u6548\u7387\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.16698", "pdf": "https://arxiv.org/pdf/2506.16698", "abs": "https://arxiv.org/abs/2506.16698", "authors": ["Dinesh Ramasamy", "Shakti Kumar", "Chris Cadonic", "Jiaxin Yang", "Sohini Roychowdhury", "Esam Abdel Rhman", "Srihari Reddy"], "title": "SIDE: Semantic ID Embedding for effective learning from sequences", "categories": ["cs.LG"], "comment": "7 pages, 4 images, 6 tables", "summary": "Sequence-based recommendations models are driving the state-of-the-art for\nindustrial ad-recommendation systems. Such systems typically deal with user\nhistories or sequence lengths ranging in the order of O(10^3) to O(10^4)\nevents. While adding embeddings at this scale is manageable in pre-trained\nmodels, incorporating them into real-time prediction models is challenging due\nto both storage and inference costs. To address this scaling challenge, we\npropose a novel approach that leverages vector quantization (VQ) to inject a\ncompact Semantic ID (SID) as input to the recommendation models instead of a\ncollection of embeddings. Our method builds on recent works of SIDs by\nintroducing three key innovations: (i) a multi-task VQ-VAE framework, called VQ\nfusion that fuses multiple content embeddings and categorical predictions into\na single Semantic ID; (ii) a parameter-free, highly granular SID-to-embedding\nconversion technique, called SIDE, that is validated with two content embedding\ncollections, thereby eliminating the need for a large parameterized lookup\ntable; and (iii) a novel quantization method called Discrete-PCA (DPCA) which\ngeneralizes and enhances residual quantization techniques. The proposed\nenhancements when applied to a large-scale industrial ads-recommendation system\nachieves 2.4X improvement in normalized entropy (NE) gain and 3X reduction in\ndata footprint compared to traditional SID methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5411\u91cf\u91cf\u5316\uff08VQ\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u7d27\u51d1\u7684\u8bed\u4e49ID\uff08SID\uff09\u66ff\u4ee3\u4f20\u7edf\u5d4c\u5165\uff0c\u89e3\u51b3\u4e86\u5de5\u4e1a\u5e7f\u544a\u63a8\u8350\u7cfb\u7edf\u4e2d\u5b58\u50a8\u548c\u63a8\u7406\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "motivation": "\u5de5\u4e1a\u5e7f\u544a\u63a8\u8350\u7cfb\u7edf\u901a\u5e38\u9700\u8981\u5904\u7406\u5927\u89c4\u6a21\u7528\u6237\u5386\u53f2\u6570\u636e\uff08O(10^3)\u5230O(10^4)\u4e8b\u4ef6\uff09\uff0c\u4f20\u7edf\u5d4c\u5165\u65b9\u6cd5\u5728\u5b9e\u65f6\u9884\u6d4b\u6a21\u578b\u4e2d\u5b58\u50a8\u548c\u63a8\u7406\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a\uff08i\uff09\u591a\u4efb\u52a1VQ-VAE\u6846\u67b6\uff08VQ\u878d\u5408\uff09\uff0c\u878d\u5408\u591a\u5185\u5bb9\u5d4c\u5165\u548c\u5206\u7c7b\u9884\u6d4b\u4e3a\u5355\u4e00SID\uff1b\uff08ii\uff09\u53c2\u6570\u81ea\u7531\u7684SID-to-embedding\u8f6c\u6362\u6280\u672f\uff08SIDE\uff09\uff1b\uff08iii\uff09\u65b0\u578b\u91cf\u5316\u65b9\u6cd5DPCA\uff0c\u589e\u5f3a\u6b8b\u5dee\u91cf\u5316\u6280\u672f\u3002", "result": "\u5728\u5927\u89c4\u6a21\u5de5\u4e1a\u5e7f\u544a\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0cNE\u589e\u76ca\u63d0\u53472.4\u500d\uff0c\u6570\u636e\u5360\u7528\u51cf\u5c113\u500d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6548\u7387\u548c\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u5b58\u50a8\u548c\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2506.16704", "pdf": "https://arxiv.org/pdf/2506.16704", "abs": "https://arxiv.org/abs/2506.16704", "authors": ["Cynthia Dwork", "Lunjia Hu", "Han Shao"], "title": "How Many Domains Suffice for Domain Generalization? A Tight Characterization via the Domain Shattering Dimension", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We study a fundamental question of domain generalization: given a family of\ndomains (i.e., data distributions), how many randomly sampled domains do we\nneed to collect data from in order to learn a model that performs reasonably\nwell on every seen and unseen domain in the family? We model this problem in\nthe PAC framework and introduce a new combinatorial measure, which we call the\ndomain shattering dimension. We show that this dimension characterizes the\ndomain sample complexity. Furthermore, we establish a tight quantitative\nrelationship between the domain shattering dimension and the classic VC\ndimension, demonstrating that every hypothesis class that is learnable in the\nstandard PAC setting is also learnable in our setting.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u9886\u57df\u6cdb\u5316\u7684\u57fa\u672c\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u7ec4\u5408\u5ea6\u91cf\u2014\u2014\u9886\u57df\u7834\u788e\u7ef4\u5ea6\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u4e0e\u7ecf\u5178VC\u7ef4\u5ea6\u7684\u5b9a\u91cf\u5173\u7cfb\u3002", "motivation": "\u63a2\u8ba8\u5728\u7ed9\u5b9a\u9886\u57df\u65cf\u4e2d\uff0c\u9700\u8981\u4ece\u591a\u5c11\u4e2a\u968f\u673a\u91c7\u6837\u7684\u9886\u57df\u6536\u96c6\u6570\u636e\u624d\u80fd\u5b66\u4e60\u4e00\u4e2a\u5728\u6240\u6709\u9886\u57df\uff08\u5305\u62ec\u672a\u89c1\u8fc7\u7684\uff09\u4e0a\u8868\u73b0\u826f\u597d\u7684\u6a21\u578b\u3002", "method": "\u5728PAC\u6846\u67b6\u4e0b\u5efa\u6a21\u95ee\u9898\uff0c\u5f15\u5165\u9886\u57df\u7834\u788e\u7ef4\u5ea6\u4f5c\u4e3a\u65b0\u7684\u7ec4\u5408\u5ea6\u91cf\u3002", "result": "\u9886\u57df\u7834\u788e\u7ef4\u5ea6\u523b\u753b\u4e86\u9886\u57df\u6837\u672c\u590d\u6742\u5ea6\uff0c\u5e76\u4e0e\u7ecf\u5178VC\u7ef4\u5ea6\u5efa\u7acb\u4e86\u7d27\u5bc6\u7684\u5b9a\u91cf\u5173\u7cfb\u3002", "conclusion": "\u8bc1\u660e\u5728\u6807\u51c6PAC\u8bbe\u7f6e\u4e2d\u53ef\u5b66\u4e60\u7684\u5047\u8bbe\u7c7b\uff0c\u5728\u8be5\u8bbe\u7f6e\u4e2d\u4e5f\u53ef\u5b66\u4e60\u3002"}}
{"id": "2506.16723", "pdf": "https://arxiv.org/pdf/2506.16723", "abs": "https://arxiv.org/abs/2506.16723", "authors": ["Yuping Yan", "Yizhi Wang", "Yuanshuai Li", "Yaochu Jin"], "title": "TriCon-SF: A Triple-Shuffle and Contribution-Aware Serial Federated Learning Framework for Heterogeneous Healthcare Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Serial pipeline training is an efficient paradigm for handling data\nheterogeneity in cross-silo federated learning with low communication overhead.\nHowever, even without centralized aggregation, direct transfer of models\nbetween clients can violate privacy regulations and remain susceptible to\ngradient leakage and linkage attacks. Additionally, ensuring resilience against\nsemi-honest or malicious clients who may manipulate or misuse received models\nremains a grand challenge, particularly in privacy-sensitive domains such as\nhealthcare. To address these challenges, we propose TriCon-SF, a novel serial\nfederated learning framework that integrates triple shuffling and contribution\nawareness. TriCon-SF introduces three levels of randomization by shuffling\nmodel layers, data segments, and training sequences to break deterministic\nlearning patterns and disrupt potential attack vectors, thereby enhancing\nprivacy and robustness. In parallel, it leverages Shapley value methods to\ndynamically evaluate client contributions during training, enabling the\ndetection of dishonest behavior and enhancing system accountability. Extensive\nexperiments on non-IID healthcare datasets demonstrate that TriCon-SF\noutperforms standard serial and parallel federated learning in both accuracy\nand communication efficiency. Security analysis further supports its resilience\nagainst client-side privacy attacks.", "AI": {"tldr": "TriCon-SF\u662f\u4e00\u79cd\u65b0\u578b\u7684\u4e32\u884c\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u91cd\u968f\u673a\u5316\u548c\u8d21\u732e\u611f\u77e5\u6280\u672f\u89e3\u51b3\u6570\u636e\u5f02\u6784\u6027\u548c\u9690\u79c1\u5b89\u5168\u95ee\u9898\uff0c\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\u533b\u7597\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u8de8\u673a\u6784\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u5f02\u6784\u6027\u548c\u9690\u79c1\u95ee\u9898\uff0c\u7279\u522b\u662f\u9488\u5bf9\u68af\u5ea6\u6cc4\u6f0f\u548c\u94fe\u63a5\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u4ee5\u53ca\u534a\u8bda\u5b9e\u6216\u6076\u610f\u5ba2\u6237\u7aef\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faTriCon-SF\u6846\u67b6\uff0c\u7ed3\u5408\u6a21\u578b\u5c42\u3001\u6570\u636e\u6bb5\u548c\u8bad\u7ec3\u5e8f\u5217\u7684\u4e09\u91cd\u968f\u673a\u5316\uff0c\u5e76\u5229\u7528Shapley\u503c\u52a8\u6001\u8bc4\u4f30\u5ba2\u6237\u7aef\u8d21\u732e\u3002", "result": "\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\u533b\u7597\u6570\u636e\u96c6\u4e0a\uff0cTriCon-SF\u5728\u51c6\u786e\u6027\u548c\u901a\u4fe1\u6548\u7387\u4e0a\u4f18\u4e8e\u6807\u51c6\u4e32\u884c\u548c\u5e76\u884c\u8054\u90a6\u5b66\u4e60\uff0c\u4e14\u80fd\u62b5\u5fa1\u5ba2\u6237\u7aef\u9690\u79c1\u653b\u51fb\u3002", "conclusion": "TriCon-SF\u901a\u8fc7\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4\u548c\u7cfb\u7edf\u9c81\u68d2\u6027\uff0c\u4e3a\u9690\u79c1\u654f\u611f\u9886\u57df\u7684\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16732", "pdf": "https://arxiv.org/pdf/2506.16732", "abs": "https://arxiv.org/abs/2506.16732", "authors": ["Fanchen Bu", "Kijung Shin"], "title": "On Training-Test (Mis)alignment in Unsupervised Combinatorial Optimization: Observation, Empirical Exploration, and Analysis", "categories": ["cs.LG", "cs.AI", "cs.DM", "math.PR"], "comment": "2nd Workshop on Test-Time Adaptation: Putting Updates to the Test @\n  ICML 2025", "summary": "In unsupervised combinatorial optimization (UCO), during training, one aims\nto have continuous decisions that are promising in a probabilistic sense for\neach training instance, which enables end-to-end training on initially discrete\nand non-differentiable problems. At the test time, for each test instance,\nstarting from continuous decisions, derandomization is typically applied to\nobtain the final deterministic decisions. Researchers have developed more and\nmore powerful test-time derandomization schemes to enhance the empirical\nperformance and the theoretical guarantee of UCO methods. However, we notice a\nmisalignment between training and testing in the existing UCO methods.\nConsequently, lower training losses do not necessarily entail better\npost-derandomization performance, even for the training instances without any\ndata distribution shift. Empirically, we indeed observe such undesirable cases.\nWe explore a preliminary idea to better align training and testing in UCO by\nincluding a differentiable version of derandomization into training. Our\nempirical exploration shows that such an idea indeed improves training-test\nalignment, but also introduces nontrivial challenges into training.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u65e0\u76d1\u7763\u7ec4\u5408\u4f18\u5316\uff08UCO\uff09\u4e2d\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u7684\u4e0d\u5bf9\u9f50\u95ee\u9898\uff0c\u63d0\u51fa\u5c06\u53ef\u5fae\u5206\u7684\u53bb\u968f\u673a\u5316\u65b9\u6cd5\u5f15\u5165\u8bad\u7ec3\u4ee5\u6539\u5584\u5bf9\u9f50\u6027\u3002", "motivation": "\u73b0\u6709UCO\u65b9\u6cd5\u4e2d\uff0c\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u9636\u6bb5\u5b58\u5728\u4e0d\u5bf9\u9f50\uff0c\u5bfc\u81f4\u8bad\u7ec3\u635f\u5931\u4f4e\u4e0d\u4e00\u5b9a\u5e26\u6765\u66f4\u597d\u7684\u53bb\u968f\u673a\u5316\u6027\u80fd\u3002", "method": "\u5728\u8bad\u7ec3\u4e2d\u5f15\u5165\u53ef\u5fae\u5206\u7684\u53bb\u968f\u673a\u5316\u65b9\u6cd5\uff0c\u4ee5\u6539\u5584\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u7684\u5bf9\u9f50\u6027\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6539\u5584\u4e86\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u7684\u5bf9\u9f50\u6027\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u8bad\u7ec3\u4e2d\u7684\u65b0\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u4e3aUCO\u4e2d\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u7684\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u4e86\u521d\u6b65\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u89e3\u51b3\u8bad\u7ec3\u4e2d\u7684\u6311\u6218\u3002"}}
{"id": "2506.16736", "pdf": "https://arxiv.org/pdf/2506.16736", "abs": "https://arxiv.org/abs/2506.16736", "authors": ["John Lazarsfeld", "Georgios Piliouras", "Ryann Sim", "Stratis Skoulakis"], "title": "Optimism Without Regularization: Constant Regret in Zero-Sum Games", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "This paper studies the optimistic variant of Fictitious Play for learning in\ntwo-player zero-sum games. While it is known that Optimistic FTRL -- a\nregularized algorithm with a bounded stepsize parameter -- obtains constant\nregret in this setting, we show for the first time that similar, optimal rates\nare also achievable without regularization: we prove for two-strategy games\nthat Optimistic Fictitious Play (using any tiebreaking rule) obtains only\nconstant regret, providing surprising new evidence on the ability of\nnon-no-regret algorithms for fast learning in games. Our proof technique\nleverages a geometric view of Optimistic Fictitious Play in the dual space of\npayoff vectors, where we show a certain energy function of the iterates remains\nbounded over time. Additionally, we also prove a regret lower bound of\n$\\Omega(\\sqrt{T})$ for Alternating Fictitious Play. In the unregularized\nregime, this separates the ability of optimism and alternation in achieving\n$o(\\sqrt{T})$ regret.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e50\u89c2\u865a\u6784\u535a\u5f08\u5728\u4e24\u4eba\u96f6\u548c\u535a\u5f08\u4e2d\u7684\u5b66\u4e60\u6027\u80fd\uff0c\u9996\u6b21\u8bc1\u660e\u65e0\u9700\u6b63\u5219\u5316\u4e5f\u80fd\u5b9e\u73b0\u6700\u4f18\u540e\u6094\u7387\u3002", "motivation": "\u63a2\u8ba8\u4e50\u89c2\u865a\u6784\u535a\u5f08\u5728\u65e0\u6b63\u5219\u5316\u6761\u4ef6\u4e0b\u662f\u5426\u80fd\u5b9e\u73b0\u5e38\u6570\u540e\u6094\u7387\uff0c\u586b\u8865\u76f8\u5173\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u53cc\u7a7a\u95f4\u51e0\u4f55\u89c6\u89d2\u5206\u6790\u4e50\u89c2\u865a\u6784\u535a\u5f08\uff0c\u8bc1\u660e\u80fd\u91cf\u51fd\u6570\u6709\u754c\u6027\u3002", "result": "\u4e50\u89c2\u865a\u6784\u535a\u5f08\u5728\u53cc\u7b56\u7565\u535a\u5f08\u4e2d\u5b9e\u73b0\u5e38\u6570\u540e\u6094\u7387\uff0c\u800c\u4ea4\u66ff\u865a\u6784\u535a\u5f08\u540e\u6094\u7387\u4e0b\u754c\u4e3a\u03a9(\u221aT)\u3002", "conclusion": "\u4e50\u89c2\u865a\u6784\u535a\u5f08\u5728\u65e0\u6b63\u5219\u5316\u6761\u4ef6\u4e0b\u4ecd\u80fd\u5b9e\u73b0\u5feb\u901f\u5b66\u4e60\uff0c\u800c\u4ea4\u66ff\u865a\u6784\u535a\u5f08\u5219\u65e0\u6cd5\u8fbe\u5230\u7c7b\u4f3c\u6548\u679c\u3002"}}
{"id": "2506.16744", "pdf": "https://arxiv.org/pdf/2506.16744", "abs": "https://arxiv.org/abs/2506.16744", "authors": ["Eion Tyacke", "Kunal Gupta", "Jay Patel", "Rui Li"], "title": "IsoNet: Causal Analysis of Multimodal Transformers for Neuromuscular Gesture Classification", "categories": ["cs.LG", "cs.RO", "eess.SP"], "comment": null, "summary": "Hand gestures are a primary output of the human motor system, yet the\ndecoding of their neuromuscular signatures remains a bottleneck for basic\nneuroscience and assistive technologies such as prosthetics. Traditional\nhuman-machine interface pipelines rely on a single biosignal modality, but\nmultimodal fusion can exploit complementary information from sensors. We\nsystematically compare linear and attention-based fusion strategies across\nthree architectures: a Multimodal MLP, a Multimodal Transformer, and a\nHierarchical Transformer, evaluating performance on scenarios with unimodal and\nmultimodal inputs. Experiments use two publicly available datasets: NinaPro DB2\n(sEMG and accelerometer) and HD-sEMG 65-Gesture (high-density sEMG and force).\nAcross both datasets, the Hierarchical Transformer with attention-based fusion\nconsistently achieved the highest accuracy, surpassing the multimodal and best\nsingle-modality linear-fusion MLP baseline by over 10% on NinaPro DB2 and 3.7%\non HD-sEMG. To investigate how modalities interact, we introduce an Isolation\nNetwork that selectively silences unimodal or cross-modal attention pathways,\nquantifying each group of token interactions' contribution to downstream\ndecisions. Ablations reveal that cross-modal interactions contribute\napproximately 30% of the decision signal across transformer layers,\nhighlighting the importance of attention-driven fusion in harnessing\ncomplementary modality information. Together, these findings reveal when and\nhow multimodal fusion would enhance biosignal classification and also provides\nmechanistic insights of human muscle activities. The study would be beneficial\nin the design of sensor arrays for neurorobotic systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u591a\u6a21\u6001\u878d\u5408\u7b56\u7565\u5728\u624b\u52bf\u89e3\u7801\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u5206\u5c42Transformer\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u9694\u79bb\u7f51\u7edc\u5206\u6790\u4e86\u6a21\u6001\u4ea4\u4e92\u7684\u8d21\u732e\u3002", "motivation": "\u624b\u52bf\u89e3\u7801\u5728\u795e\u7ecf\u79d1\u5b66\u548c\u8f85\u52a9\u6280\u672f\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5355\u4e00\u751f\u7269\u4fe1\u53f7\u6a21\u6001\uff0c\u591a\u6a21\u6001\u878d\u5408\u53ef\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "method": "\u6bd4\u8f83\u4e86\u7ebf\u6027\u4e0e\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u878d\u5408\u7b56\u7565\uff0c\u5305\u62ec\u591a\u6a21\u6001MLP\u3001Transformer\u548c\u5206\u5c42Transformer\uff0c\u5e76\u5728\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u5206\u5c42Transformer\u5728\u4e24\u79cd\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u663e\u8457\u9ad8\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u8de8\u6a21\u6001\u4ea4\u4e92\u8d21\u732e\u4e86\u7ea630%\u7684\u51b3\u7b56\u4fe1\u53f7\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u591a\u6a21\u6001\u878d\u5408\u80fd\u6709\u6548\u63d0\u5347\u751f\u7269\u4fe1\u53f7\u5206\u7c7b\u6027\u80fd\uff0c\u5e76\u4e3a\u795e\u7ecf\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u4f20\u611f\u5668\u8bbe\u8ba1\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2506.16753", "pdf": "https://arxiv.org/pdf/2506.16753", "abs": "https://arxiv.org/abs/2506.16753", "authors": ["Kosuke Nakanishi", "Akihiro Kubo", "Yuji Yasui", "Shin Ishii"], "title": "Off-Policy Actor-Critic for Adversarial Observation Robustness: Virtual Alternative Training via Symmetric Policy Evaluation", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "ICML2025 poster, 39 pages, 6 figures, 13 tables. arXiv admin note:\n  text overlap with arXiv:2409.00418", "summary": "Recently, robust reinforcement learning (RL) methods designed to handle\nadversarial input observations have received significant attention, motivated\nby RL's inherent vulnerabilities. While existing approaches have demonstrated\nreasonable success, addressing worst-case scenarios over long time horizons\nrequires both minimizing the agent's cumulative rewards for adversaries and\ntraining agents to counteract them through alternating learning. However, this\nprocess introduces mutual dependencies between the agent and the adversary,\nmaking interactions with the environment inefficient and hindering the\ndevelopment of off-policy methods. In this work, we propose a novel off-policy\nmethod that eliminates the need for additional environmental interactions by\nreformulating adversarial learning as a soft-constrained optimization problem.\nOur approach is theoretically supported by the symmetric property of policy\nevaluation between the agent and the adversary. The implementation is available\nat https://github.com/nakanakakosuke/VALT_SAC.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u79bb\u7b56\u7565\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u5bf9\u6297\u5b66\u4e60\u91cd\u65b0\u8868\u8ff0\u4e3a\u8f6f\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u907f\u514d\u989d\u5916\u73af\u5883\u4ea4\u4e92\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u957f\u671f\u6700\u574f\u60c5\u51b5\u65f6\u6548\u7387\u4f4e\u4e0b\uff0c\u4e14\u963b\u788d\u79bb\u7b56\u7565\u65b9\u6cd5\u7684\u53d1\u5c55\u3002", "method": "\u5c06\u5bf9\u6297\u5b66\u4e60\u91cd\u65b0\u8868\u8ff0\u4e3a\u8f6f\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u5229\u7528\u7b56\u7565\u8bc4\u4f30\u7684\u5bf9\u79f0\u6027\u3002", "result": "\u7406\u8bba\u652f\u6301\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u73b0\u4ee3\u7801\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6548\u7387\u95ee\u9898\uff0c\u540c\u65f6\u652f\u6301\u79bb\u7b56\u7565\u5b66\u4e60\u3002"}}
{"id": "2506.16754", "pdf": "https://arxiv.org/pdf/2506.16754", "abs": "https://arxiv.org/abs/2506.16754", "authors": ["Jongmin Park", "Seunghoon Han", "Won-Yong Shin", "Sungsu Lim"], "title": "Metapath-based Hyperbolic Contrastive Learning for Heterogeneous Graph Embedding", "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": "14 pages, 9 figures", "summary": "The hyperbolic space, characterized by a constant negative curvature and\nexponentially expanding space, aligns well with the structural properties of\nheterogeneous graphs. However, although heterogeneous graphs inherently possess\ndiverse power-law structures, most hyperbolic heterogeneous graph embedding\nmodels rely on a single hyperbolic space. This approach may fail to effectively\ncapture the diverse power-law structures within heterogeneous graphs. To\naddress this limitation, we propose a Metapath-based Hyperbolic Contrastive\nLearning framework (MHCL), which uses multiple hyperbolic spaces to capture\ndiverse complex structures within heterogeneous graphs. Specifically, by\nlearning each hyperbolic space to describe the distribution of complex\nstructures corresponding to each metapath, it is possible to capture semantic\ninformation effectively. Since metapath embeddings represent distinct semantic\ninformation, preserving their discriminability is important when aggregating\nthem to obtain node representations. Therefore, we use a contrastive learning\napproach to optimize MHCL and improve the discriminability of metapath\nembeddings. In particular, our contrastive learning method minimizes the\ndistance between embeddings of the same metapath and maximizes the distance\nbetween those of different metapaths in hyperbolic space, thereby improving the\nseparability of metapath embeddings with distinct semantic information. We\nconduct comprehensive experiments to evaluate the effectiveness of MHCL. The\nexperimental results demonstrate that MHCL outperforms state-of-the-art\nbaselines in various graph machine learning tasks, effectively capturing the\ncomplex structures of heterogeneous graphs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u53cc\u66f2\u7a7a\u95f4\u7684\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff08MHCL\uff09\uff0c\u7528\u4e8e\u6355\u6349\u5f02\u8d28\u56fe\u4e2d\u591a\u6837\u5316\u7684\u590d\u6742\u7ed3\u6784\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f02\u8d28\u56fe\u5177\u6709\u591a\u6837\u5316\u7684\u5e42\u5f8b\u7ed3\u6784\uff0c\u4f46\u73b0\u6709\u53cc\u66f2\u7a7a\u95f4\u5d4c\u5165\u6a21\u578b\u4ec5\u4f9d\u8d56\u5355\u4e00\u7a7a\u95f4\uff0c\u96be\u4ee5\u6709\u6548\u6355\u6349\u8fd9\u4e9b\u7ed3\u6784\u3002", "method": "\u63d0\u51faMHCL\u6846\u67b6\uff0c\u5229\u7528\u591a\u4e2a\u53cc\u66f2\u7a7a\u95f4\u5206\u522b\u63cf\u8ff0\u4e0d\u540c\u5143\u8def\u5f84\u7684\u590d\u6742\u7ed3\u6784\u5206\u5e03\uff0c\u5e76\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u4f18\u5316\u5143\u8def\u5f84\u5d4c\u5165\u7684\u533a\u5206\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMHCL\u5728\u591a\u79cd\u56fe\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MHCL\u80fd\u6709\u6548\u6355\u6349\u5f02\u8d28\u56fe\u7684\u590d\u6742\u7ed3\u6784\uff0c\u63d0\u5347\u5143\u8def\u5f84\u5d4c\u5165\u7684\u533a\u5206\u6027\u3002"}}
{"id": "2506.16782", "pdf": "https://arxiv.org/pdf/2506.16782", "abs": "https://arxiv.org/abs/2506.16782", "authors": ["Youjin Kong"], "title": "What Is the Point of Equality in Machine Learning Fairness? Beyond Equality of Opportunity", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": "Accepted for presentation at ACM FAccT 2025; under final review\n  (minor revision) at an ACM journal", "summary": "Fairness in machine learning (ML) has become a rapidly growing area of\nresearch. But why, in the first place, is unfairness in ML morally wrong? And\nwhy should we care about improving fairness? Most fair-ML research implicitly\nappeals to distributive equality: the idea that desirable goods and benefits,\nsuch as opportunities (e.g., Barocas et al., 2023), should be equally\ndistributed across society. Unfair ML models, then, are seen as wrong because\nthey unequally distribute such benefits. This paper argues that this exclusive\nfocus on distributive equality offers an incomplete and potentially misleading\nethical foundation. Grounding ML fairness in egalitarianism -- the view that\nequality is a fundamental moral and social ideal -- requires challenging\nstructural inequality: systematic, institutional, and durable arrangements that\nprivilege some groups while disadvantaging others. Structural inequality\nmanifests through ML systems in two primary forms: allocative harms (e.g.,\neconomic loss) and representational harms (e.g., stereotypes, erasure). While\ndistributive equality helps address allocative harms, it fails to explain why\nrepresentational harms are wrong -- why it is wrong for ML systems to reinforce\nsocial hierarchies that stratify people into superior and inferior groups --\nand why ML systems should aim to foster a society where people relate as equals\n(i.e., relational equality). To address these limitations, the paper proposes a\nmultifaceted egalitarian framework for ML fairness that integrates both\ndistributive and relational equality. Drawing on critical social and political\nphilosophy, this framework offers a more comprehensive ethical foundation for\ntackling the full spectrum of harms perpetuated by ML systems. The paper also\noutlines practical pathways for implementing the framework across the ML\npipeline.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u673a\u5668\u5b66\u4e60\u516c\u5e73\u6027\u7684\u4f26\u7406\u57fa\u7840\uff0c\u6307\u51fa\u4ec5\u5173\u6ce8\u5206\u914d\u5e73\u7b49\u662f\u4e0d\u5b8c\u6574\u7684\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408\u5206\u914d\u5e73\u7b49\u548c\u5173\u7cfb\u5e73\u7b49\u7684\u591a\u5143\u5e73\u7b49\u4e3b\u4e49\u6846\u67b6\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63ed\u793a\u5f53\u524d\u516c\u5e73\u673a\u5668\u5b66\u4e60\u7814\u7a76\u4e2d\u5bf9\u5206\u914d\u5e73\u7b49\u7684\u5355\u4e00\u5173\u6ce8\uff0c\u672a\u80fd\u5168\u9762\u89e3\u51b3\u7ed3\u6784\u6027\u4e0d\u5e73\u7b49\u53ca\u5176\u5e26\u6765\u7684\u5206\u914d\u6027\u548c\u4ee3\u8868\u6027\u4f24\u5bb3\u3002", "method": "\u65b9\u6cd5\u662f\u901a\u8fc7\u6279\u5224\u793e\u4f1a\u548c\u653f\u6cbb\u54f2\u5b66\uff0c\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u5206\u914d\u5e73\u7b49\u548c\u5173\u7cfb\u5e73\u7b49\u7684\u591a\u5143\u5e73\u7b49\u4e3b\u4e49\u6846\u67b6\u3002", "result": "\u7ed3\u679c\u662f\u8be5\u6846\u67b6\u4e3a\u673a\u5668\u5b66\u4e60\u516c\u5e73\u6027\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u4f26\u7406\u57fa\u7840\uff0c\u5e76\u63d0\u51fa\u4e86\u5728\u673a\u5668\u5b66\u4e60\u6d41\u7a0b\u4e2d\u5b9e\u65bd\u7684\u5177\u4f53\u8def\u5f84\u3002", "conclusion": "\u7ed3\u8bba\u662f\u591a\u5143\u5e73\u7b49\u4e3b\u4e49\u6846\u67b6\u80fd\u66f4\u6709\u6548\u5730\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e2d\u7684\u7ed3\u6784\u6027\u4e0d\u5e73\u7b49\u95ee\u9898\u3002"}}
{"id": "2506.16787", "pdf": "https://arxiv.org/pdf/2506.16787", "abs": "https://arxiv.org/abs/2506.16787", "authors": ["Jiashun Cheng", "Aochuan Chen", "Nuo Chen", "Ziqi Gao", "Yuhan Li", "Jia Li", "Fugee Tsung"], "title": "Revisiting LoRA through the Lens of Parameter Redundancy: Spectral Encoding Helps", "categories": ["cs.LG"], "comment": "18 pages; Accepted to ACL 2025 Findings", "summary": "Low-Rank Adaptation (LoRA) has emerged as a prominent technique for\nfine-tuning large foundation models. Despite its successes, the substantial\nparameter redundancy, which limits the capacity and efficiency of LoRA, has\nbeen recognized as a bottleneck. In this work, we systematically investigate\nthe impact of redundancy in fine-tuning LoRA and reveal that reducing density\nredundancy does not degrade expressiveness. Based on this insight, we introduce\n\\underline{S}pectral-\\underline{e}ncoding \\underline{L}ow-\\underline{R}ank\n\\underline{A}daptation (SeLoRA), which harnesses the robust expressiveness of\nspectral bases to re-parameterize LoRA from a sparse spectral subspace.\nDesigned with simplicity, SeLoRA enables seamless integration with various LoRA\nvariants for performance boosting, serving as a scalable plug-and-play\nframework. Extensive experiments substantiate that SeLoRA achieves greater\nefficiency with fewer parameters, delivering superior performance enhancements\nover strong baselines on various downstream tasks, including commonsense\nreasoning, math reasoning, and code generation.", "AI": {"tldr": "SeLoRA\u901a\u8fc7\u7a00\u758f\u8c31\u5b50\u7a7a\u95f4\u91cd\u65b0\u53c2\u6570\u5316LoRA\uff0c\u51cf\u5c11\u5197\u4f59\u53c2\u6570\uff0c\u63d0\u5347\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "LoRA\u5728\u5fae\u8c03\u5927\u578b\u57fa\u7840\u6a21\u578b\u65f6\u5b58\u5728\u53c2\u6570\u5197\u4f59\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5bb9\u91cf\u548c\u6548\u7387\u3002", "method": "\u63d0\u51faSeLoRA\uff0c\u5229\u7528\u8c31\u57fa\u7684\u9c81\u68d2\u8868\u8fbe\u80fd\u529b\uff0c\u4ece\u7a00\u758f\u8c31\u5b50\u7a7a\u95f4\u91cd\u65b0\u53c2\u6570\u5316LoRA\u3002", "result": "SeLoRA\u5728\u51cf\u5c11\u53c2\u6570\u7684\u540c\u65f6\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u5728\u591a\u9879\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "conclusion": "SeLoRA\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u63d2\u4ef6\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86LoRA\u7684\u6027\u80fd\u3002"}}
{"id": "2506.16790", "pdf": "https://arxiv.org/pdf/2506.16790", "abs": "https://arxiv.org/abs/2506.16790", "authors": ["Senmiao Wang", "Yupeng Chen", "Yushun Zhang", "Ruoyu Sun", "Tian Ding"], "title": "Exploring and Improving Initialization for Deep Graph Neural Networks: A Signal Propagation Perspective", "categories": ["cs.LG"], "comment": "Published in TMLR (2025)", "summary": "Graph Neural Networks (GNNs) often suffer from performance degradation as the\nnetwork depth increases. This paper addresses this issue by introducing\ninitialization methods that enhance signal propagation (SP) within GNNs. We\npropose three key metrics for effective SP in GNNs: forward propagation,\nbackward propagation, and graph embedding variation (GEV). While the first two\nmetrics derive from classical SP theory, the third is specifically designed for\nGNNs. We theoretically demonstrate that a broad range of commonly used\ninitialization methods for GNNs, which exhibit performance degradation with\nincreasing depth, fail to control these three metrics simultaneously. To deal\nwith this limitation, a direct exploitation of the SP analysis--searching for\nweight initialization variances that optimize the three metrics--is shown to\nsignificantly enhance the SP in deep GCNs. This approach is called Signal\nPropagation on Graph-guided Initialization (SPoGInit). Our experiments\ndemonstrate that SPoGInit outperforms commonly used initialization methods on\nvarious tasks and architectures. Notably, SPoGInit enables performance\nimprovements as GNNs deepen, which represents a significant advancement in\naddressing depth-related challenges and highlights the validity and\neffectiveness of the SP analysis framework.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPoGInit\u7684\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u4fe1\u53f7\u4f20\u64ad\uff08SP\uff09\u7684\u4e09\u4e2a\u5173\u952e\u6307\u6807\uff0c\u89e3\u51b3\u4e86GNN\u6df1\u5ea6\u589e\u52a0\u65f6\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\u3002", "motivation": "GNN\u5728\u6df1\u5ea6\u589e\u52a0\u65f6\u6027\u80fd\u4e0b\u964d\uff0c\u73b0\u6709\u521d\u59cb\u5316\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u63a7\u5236\u4fe1\u53f7\u4f20\u64ad\u7684\u4e09\u4e2a\u5173\u952e\u6307\u6807\u3002", "method": "\u63d0\u51faSPoGInit\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u524d\u5411\u4f20\u64ad\u3001\u53cd\u5411\u4f20\u64ad\u548c\u56fe\u5d4c\u5165\u53d8\u5316\uff08GEV\uff09\u4e09\u4e2a\u6307\u6807\u6765\u6539\u8fdb\u521d\u59cb\u5316\u3002", "result": "SPoGInit\u5728\u591a\u79cd\u4efb\u52a1\u548c\u67b6\u6784\u4e0a\u4f18\u4e8e\u5e38\u7528\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u5e76\u652f\u6301GNN\u7684\u6df1\u5ea6\u6269\u5c55\u3002", "conclusion": "SPoGInit\u6709\u6548\u89e3\u51b3\u4e86GNN\u6df1\u5ea6\u76f8\u5173\u6311\u6218\uff0c\u9a8c\u8bc1\u4e86SP\u5206\u6790\u6846\u67b6\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.16791", "pdf": "https://arxiv.org/pdf/2506.16791", "abs": "https://arxiv.org/abs/2506.16791", "authors": ["Nick Erickson", "Lennart Purucker", "Andrej Tschalzev", "David Holzm\u00fcller", "Prateek Mutalik Desai", "and David Salinas", "Frank Hutter"], "title": "TabArena: A Living Benchmark for Machine Learning on Tabular Data", "categories": ["cs.LG", "cs.AI"], "comment": "51 pages. Code available at https://tabarena.ai/code; examples at\n  https://tabarena.ai/code-examples; dataset curation at\n  https://tabarena.ai/data-tabular-ml-iid-study and\n  https://tabarena.ai/dataset-curation", "summary": "With the growing popularity of deep learning and foundation models for\ntabular data, the need for standardized and reliable benchmarks is higher than\never. However, current benchmarks are static. Their design is not updated even\nif flaws are discovered, model versions are updated, or new models are\nreleased. To address this, we introduce TabArena, the first continuously\nmaintained living tabular benchmarking system. To launch TabArena, we manually\ncurate a representative collection of datasets and well-implemented models,\nconduct a large-scale benchmarking study to initialize a public leaderboard,\nand assemble a team of experienced maintainers. Our results highlight the\ninfluence of validation method and ensembling of hyperparameter configurations\nto benchmark models at their full potential. While gradient-boosted trees are\nstill strong contenders on practical tabular datasets, we observe that deep\nlearning methods have caught up under larger time budgets with ensembling. At\nthe same time, foundation models excel on smaller datasets. Finally, we show\nthat ensembles across models advance the state-of-the-art in tabular machine\nlearning and investigate the contributions of individual models. We launch\nTabArena with a public leaderboard, reproducible code, and maintenance\nprotocols to create a living benchmark available at https://tabarena.ai.", "AI": {"tldr": "TabArena\u662f\u4e00\u4e2a\u6301\u7eed\u7ef4\u62a4\u7684\u8868\u683c\u6570\u636e\u57fa\u51c6\u6d4b\u8bd5\u7cfb\u7edf\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u9759\u6001\u57fa\u51c6\u7684\u4e0d\u8db3\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u6570\u636e\u96c6\u548c\u6a21\u578b\uff0c\u63d0\u4f9b\u516c\u5f00\u6392\u884c\u699c\u548c\u53ef\u590d\u73b0\u4ee3\u7801\u3002", "motivation": "\u5f53\u524d\u8868\u683c\u6570\u636e\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u9759\u6001\u8bbe\u8ba1\u95ee\u9898\uff0c\u65e0\u6cd5\u9002\u5e94\u6a21\u578b\u66f4\u65b0\u6216\u65b0\u6a21\u578b\u53d1\u5e03\u7684\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u52a8\u6001\u7ef4\u62a4\u7684\u57fa\u51c6\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u624b\u52a8\u6574\u7406\u4ee3\u8868\u6027\u6570\u636e\u96c6\u548c\u6a21\u578b\uff0c\u8fdb\u884c\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5efa\u7acb\u516c\u5f00\u6392\u884c\u699c\uff0c\u5e76\u7531\u7ecf\u9a8c\u4e30\u5bcc\u7684\u7ef4\u62a4\u56e2\u961f\u6301\u7eed\u66f4\u65b0\u3002", "result": "\u9a8c\u8bc1\u65b9\u6cd5\u548c\u8d85\u53c2\u6570\u96c6\u6210\u5bf9\u6a21\u578b\u6027\u80fd\u5f71\u54cd\u663e\u8457\uff1b\u68af\u5ea6\u63d0\u5347\u6811\u4ecd\u5177\u7ade\u4e89\u529b\uff0c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u5927\u65f6\u95f4\u9884\u7b97\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u57fa\u7840\u6a21\u578b\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "TabArena\u901a\u8fc7\u52a8\u6001\u7ef4\u62a4\u548c\u8de8\u6a21\u578b\u96c6\u6210\uff0c\u63a8\u52a8\u4e86\u8868\u683c\u673a\u5668\u5b66\u4e60\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5e76\u63d0\u4f9b\u4e86\u516c\u5f00\u53ef\u7528\u7684\u57fa\u51c6\u5e73\u53f0\u3002"}}
{"id": "2506.16815", "pdf": "https://arxiv.org/pdf/2506.16815", "abs": "https://arxiv.org/abs/2506.16815", "authors": ["Kai Yang", "Shaoyu Dou", "Pan Luo", "Xin Wang", "H. Vincent Poor"], "title": "Robust Group Anomaly Detection for Quasi-Periodic Network Time Series", "categories": ["cs.LG"], "comment": "Published in IEEE Transactions on Network Science and Engineering", "summary": "Many real-world multivariate time series are collected from a network of\nphysical objects embedded with software, electronics, and sensors. The\nquasi-periodic signals generated by these objects often follow a similar\nrepetitive and periodic pattern, but have variations in the period, and come in\ndifferent lengths caused by timing (synchronization) errors. Given a multitude\nof such quasi-periodic time series, can we build machine learning models to\nidentify those time series that behave differently from the majority of the\nobservations? In addition, can the models help human experts to understand how\nthe decision was made? We propose a sequence to Gaussian Mixture Model\n(seq2GMM) framework. The overarching goal of this framework is to identify\nunusual and interesting time series within a network time series database. We\nfurther develop a surrogate-based optimization algorithm that can efficiently\ntrain the seq2GMM model. Seq2GMM exhibits strong empirical performance on a\nplurality of public benchmark datasets, outperforming state-of-the-art anomaly\ndetection techniques by a significant margin. We also theoretically analyze the\nconvergence property of the proposed training algorithm and provide numerical\nresults to substantiate our theoretical claims.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aseq2GMM\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc6\u522b\u7f51\u7edc\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5e93\u4e2d\u7684\u5f02\u5e38\u65f6\u95f4\u5e8f\u5217\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u7b97\u6cd5\u9ad8\u6548\u8bad\u7ec3\u6a21\u578b\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u5e38\u56e0\u540c\u6b65\u8bef\u5dee\u5bfc\u81f4\u5468\u671f\u548c\u957f\u5ea6\u53d8\u5316\uff0c\u9700\u8981\u8bc6\u522b\u5f02\u5e38\u884c\u4e3a\u5e76\u89e3\u91ca\u51b3\u7b56\u8fc7\u7a0b\u3002", "method": "\u91c7\u7528\u5e8f\u5217\u5230\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08seq2GMM\uff09\u6846\u67b6\uff0c\u7ed3\u5408\u57fa\u4e8e\u4ee3\u7406\u7684\u4f18\u5316\u7b97\u6cd5\u8fdb\u884c\u9ad8\u6548\u8bad\u7ec3\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5f02\u5e38\u68c0\u6d4b\u6280\u672f\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u6536\u655b\u6027\u5206\u6790\u3002", "conclusion": "seq2GMM\u80fd\u6709\u6548\u8bc6\u522b\u5f02\u5e38\u65f6\u95f4\u5e8f\u5217\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u6548\u8bad\u7ec3\uff0c\u5177\u6709\u7406\u8bba\u548c\u5b9e\u8bc1\u652f\u6301\u3002"}}
{"id": "2506.16824", "pdf": "https://arxiv.org/pdf/2506.16824", "abs": "https://arxiv.org/abs/2506.16824", "authors": ["Thomas Marwitz", "Alexander Colsmann", "Ben Breitung", "Christoph Brabec", "Christoph Kirchlechner", "Eva Blasco", "Gabriel Cadilha Marques", "Horst Hahn", "Michael Hirtz", "Pavel A. Levkin", "Yolita M. Eggeler", "Tobias Schl\u00f6der", "Pascal Friederich"], "title": "Predicting New Research Directions in Materials Science using Large Language Models and Concept Graphs", "categories": ["cs.LG"], "comment": null, "summary": "Due to an exponential increase in published research articles, it is\nimpossible for individual scientists to read all publications, even within\ntheir own research field. In this work, we investigate the use of large\nlanguage models (LLMs) for the purpose of extracting the main concepts and\nsemantic information from scientific abstracts in the domain of materials\nscience to find links that were not noticed by humans and thus to suggest\ninspiring near/mid-term future research directions. We show that LLMs can\nextract concepts more efficiently than automated keyword extraction methods to\nbuild a concept graph as an abstraction of the scientific literature. A machine\nlearning model is trained to predict emerging combinations of concepts, i.e.\nnew research ideas, based on historical data. We demonstrate that integrating\nsemantic concept information leads to an increased prediction performance. The\napplicability of our model is demonstrated in qualitative interviews with\ndomain experts based on individualized model suggestions. We show that the\nmodel can inspire materials scientists in their creative thinking process by\npredicting innovative combinations of topics that have not yet been\ninvestigated.", "AI": {"tldr": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ece\u6750\u6599\u79d1\u5b66\u6458\u8981\u4e2d\u63d0\u53d6\u4e3b\u8981\u6982\u5ff5\uff0c\u6784\u5efa\u6982\u5ff5\u56fe\uff0c\u5e76\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u65b0\u5174\u7814\u7a76\u65b9\u5411\u7684\u7ec4\u5408\u3002", "motivation": "\u7531\u4e8e\u7814\u7a76\u6587\u732e\u6570\u91cf\u6fc0\u589e\uff0c\u79d1\u5b66\u5bb6\u96be\u4ee5\u5168\u9762\u9605\u8bfb\uff0c\u9700\u81ea\u52a8\u5316\u5de5\u5177\u63d0\u53d6\u5173\u952e\u6982\u5ff5\u5e76\u53d1\u73b0\u6f5c\u5728\u7814\u7a76\u65b9\u5411\u3002", "method": "\u4f7f\u7528LLM\u63d0\u53d6\u6982\u5ff5\uff0c\u6784\u5efa\u6982\u5ff5\u56fe\uff0c\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u65b0\u5174\u6982\u5ff5\u7ec4\u5408\u3002", "result": "\u6a21\u578b\u9884\u6d4b\u6027\u80fd\u63d0\u5347\uff0c\u80fd\u542f\u53d1\u6750\u6599\u79d1\u5b66\u5bb6\u53d1\u73b0\u672a\u7814\u7a76\u8fc7\u7684\u521b\u65b0\u4e3b\u9898\u7ec4\u5408\u3002", "conclusion": "LLM\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u53ef\u6709\u6548\u8f85\u52a9\u79d1\u7814\u521b\u65b0\uff0c\u63d0\u4f9b\u672a\u6765\u7814\u7a76\u65b9\u5411\u5efa\u8bae\u3002"}}
{"id": "2506.16840", "pdf": "https://arxiv.org/pdf/2506.16840", "abs": "https://arxiv.org/abs/2506.16840", "authors": ["Zeyneddin Oz", "Shreyas Korde", "Marius Bock", "Kristof Van Laerhoven"], "title": "FedFitTech: A Baseline in Federated Learning for Fitness Tracking", "categories": ["cs.LG"], "comment": "This submission includes a total of 7 pages and 6 figures", "summary": "Rapid evolution of sensors and resource-efficient machine learning models\nhave spurred the widespread adoption of wearable fitness tracking devices.\nEquipped with inertial sensors, such devices can continuously capture physical\nmovements for fitness technology (FitTech), enabling applications from sports\noptimization to preventive healthcare. Traditional centralized learning\napproaches to detect fitness activities struggle with privacy concerns,\nregulatory constraints, and communication inefficiencies. In contrast,\nFederated Learning (FL) enables a decentralized model training by communicating\nmodel updates rather than private wearable sensor data. Applying FL to FitTech\npresents unique challenges, such as data imbalance, lack of labelled data,\nheterogeneous user activity patterns, and trade-offs between personalization\nand generalization. To simplify research on FitTech in FL, we present the\nFedFitTech baseline, under the Flower framework, which is publicly available\nand widely used by both industry and academic researchers. Additionally, to\nillustrate its usage, this paper presents a case study that implements a system\nbased on the FedFitTech baseline, incorporating a client-side early stopping\nstrategy and comparing the results. For instance, this system allows wearable\ndevices to optimize the trade-off between capturing common fitness activity\npatterns and preserving individuals' nuances, thereby enhancing both the\nscalability and efficiency of privacy-aware fitness tracking applications.\nResults show that this reduces overall redundant communications by 13 percent,\nwhile maintaining the overall recognition performance at a negligible\nrecognition cost by 1 percent. Thus, FedFitTech baseline creates a foundation\nfor a wide range of new research and development opportunities in FitTech, and\nit is available as open-source at:\nhttps://github.com/adap/flower/tree/main/baselines/fedfittech", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86FedFitTech\u57fa\u7ebf\uff0c\u7528\u4e8e\u89e3\u51b3\u53ef\u7a7f\u6234\u8bbe\u5907\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6311\u6218\uff0c\u5982\u6570\u636e\u4e0d\u5e73\u8861\u548c\u9690\u79c1\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5176\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u96c6\u4e2d\u5f0f\u5b66\u4e60\u65b9\u6cd5\u5728\u53ef\u7a7f\u6234\u8bbe\u5907\u4e2d\u5b58\u5728\u9690\u79c1\u548c\u6548\u7387\u95ee\u9898\uff0c\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u63d0\u4f9b\u4e86\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8eFlower\u6846\u67b6\u7684FedFitTech\u57fa\u7ebf\uff0c\u5e76\u91c7\u7528\u5ba2\u6237\u7aef\u65e9\u671f\u505c\u6b62\u7b56\u7565\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u7cfb\u7edf\u51cf\u5c11\u4e8613%\u7684\u5197\u4f59\u901a\u4fe1\uff0c\u540c\u65f6\u8bc6\u522b\u6027\u80fd\u4ec5\u4e0b\u964d1%\u3002", "conclusion": "FedFitTech\u4e3aFitTech\u9886\u57df\u7684\u7814\u7a76\u548c\u5f00\u53d1\u63d0\u4f9b\u4e86\u5f00\u6e90\u57fa\u7840\u3002"}}
{"id": "2506.16844", "pdf": "https://arxiv.org/pdf/2506.16844", "abs": "https://arxiv.org/abs/2506.16844", "authors": ["Victor Alejandre", "Concha Bielza", "Pedro Larra\u00f1aga"], "title": "Bandwidth Selectors on Semiparametric Bayesian Networks", "categories": ["cs.LG", "cs.AI", "stat.ML", "I.2.6; I.5.1; G.3"], "comment": "37 pages, 15 figures. Submitted to Information Sciences", "summary": "Semiparametric Bayesian networks (SPBNs) integrate parametric and\nnon-parametric probabilistic models, offering flexibility in learning complex\ndata distributions from samples. In particular, kernel density estimators\n(KDEs) are employed for the non-parametric component. Under the assumption of\ndata normality, the normal rule is used to learn the bandwidth matrix for the\nKDEs in SPBNs. This matrix is the key hyperparameter that controls the\ntrade-off between bias and variance. However, real-world data often deviates\nfrom normality, potentially leading to suboptimal density estimation and\nreduced predictive performance. This paper first establishes the theoretical\nframework for the application of state-of-the-art bandwidth selectors and\nsubsequently evaluates their impact on SPBN performance. We explore the\napproaches of cross-validation and plug-in selectors, assessing their\neffectiveness in enhancing the learning capability and applicability of SPBNs.\nTo support this investigation, we have extended the open-source package\nPyBNesian for SPBNs with the additional bandwidth selection techniques and\nconducted extensive experimental analyses. Our results demonstrate that the\nproposed bandwidth selectors leverage increasing information more effectively\nthan the normal rule, which, despite its robustness, stagnates with more data.\nIn particular, unbiased cross-validation generally outperforms the normal rule,\nhighlighting its advantage in high sample size scenarios.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u534a\u53c2\u6570\u8d1d\u53f6\u65af\u7f51\u7edc\uff08SPBNs\uff09\u4e2d\u5e26\u5bbd\u9009\u62e9\u5668\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u6bd4\u8f83\u4e86\u4ea4\u53c9\u9a8c\u8bc1\u548c\u63d2\u4ef6\u9009\u62e9\u5668\uff0c\u53d1\u73b0\u5b83\u4eec\u4f18\u4e8e\u4f20\u7edf\u7684\u6b63\u6001\u89c4\u5219\u3002", "motivation": "\u73b0\u5b9e\u6570\u636e\u5e38\u504f\u79bb\u6b63\u6001\u6027\uff0c\u4f20\u7edf\u6b63\u6001\u89c4\u5219\u53ef\u80fd\u5bfc\u81f4\u6b21\u4f18\u5bc6\u5ea6\u4f30\u8ba1\u548c\u9884\u6d4b\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u5e94\u7528\u4ea4\u53c9\u9a8c\u8bc1\u548c\u63d2\u4ef6\u9009\u62e9\u5668\uff0c\u6269\u5c55PyBNesian\u5de5\u5177\u5305\u8fdb\u884c\u5b9e\u9a8c\u5206\u6790\u3002", "result": "\u4ea4\u53c9\u9a8c\u8bc1\u5728\u9ad8\u6837\u672c\u91cf\u573a\u666f\u4e2d\u4f18\u4e8e\u6b63\u6001\u89c4\u5219\uff0c\u80fd\u66f4\u6709\u6548\u5229\u7528\u4fe1\u606f\u3002", "conclusion": "\u63d0\u51fa\u7684\u5e26\u5bbd\u9009\u62e9\u5668\u63d0\u5347\u4e86SPBNs\u7684\u5b66\u4e60\u80fd\u529b\u548c\u9002\u7528\u6027\u3002"}}
{"id": "2506.16846", "pdf": "https://arxiv.org/pdf/2506.16846", "abs": "https://arxiv.org/abs/2506.16846", "authors": ["Antonio Consoloa", "Edoardo Amaldi", "Emilio Carrizosa"], "title": "Soft decision trees for survival analysis", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Decision trees are popular in survival analysis for their interpretability\nand ability to model complex relationships. Survival trees, which predict the\ntiming of singular events using censored historical data, are typically built\nthrough heuristic approaches. Recently, there has been growing interest in\nglobally optimized trees, where the overall tree is trained by minimizing the\nerror function over all its parameters. We propose a new soft survival tree\nmodel (SST), with a soft splitting rule at each branch node, trained via a\nnonlinear optimization formulation amenable to decomposition. Since SSTs\nprovide for every input vector a specific survival function associated to a\nsingle leaf node, they satisfy the conditional computation property and inherit\nthe related benefits. SST and the training formulation combine flexibility with\ninterpretability: any smooth survival function (parametric, semiparametric, or\nnonparametric) estimated through maximum likelihood can be used, and each leaf\nnode of an SST yields a cluster of distinct survival functions which are\nassociated to the data points routed to it. Numerical experiments on 15\nwell-known datasets show that SSTs, with parametric and spline-based\nsemiparametric survival functions, trained using an adaptation of the\nnode-based decomposition algorithm proposed by Consolo et al. (2024) for soft\nregression trees, outperform three benchmark survival trees in terms of four\nwidely-used discrimination and calibration measures. SSTs can also be extended\nto consider group fairness.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8f6f\u751f\u5b58\u6811\u6a21\u578b\uff08SST\uff09\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u4f18\u5316\u8bad\u7ec3\uff0c\u7ed3\u5408\u7075\u6d3b\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u572815\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\u3002", "motivation": "\u51b3\u7b56\u6811\u5728\u751f\u5b58\u5206\u6790\u4e2d\u56e0\u5176\u53ef\u89e3\u91ca\u6027\u548c\u5efa\u6a21\u590d\u6742\u5173\u7cfb\u7684\u80fd\u529b\u800c\u53d7\u6b22\u8fce\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u591a\u4e3a\u542f\u53d1\u5f0f\uff0c\u5168\u5c40\u4f18\u5316\u65b9\u6cd5\u9010\u6e10\u53d7\u5230\u5173\u6ce8\u3002", "method": "\u63d0\u51faSST\u6a21\u578b\uff0c\u91c7\u7528\u8f6f\u5206\u5272\u89c4\u5219\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u4f18\u5316\u8bad\u7ec3\uff0c\u652f\u6301\u591a\u79cd\u751f\u5b58\u51fd\u6570\u5f62\u5f0f\uff0c\u5e76\u6ee1\u8db3\u6761\u4ef6\u8ba1\u7b97\u7279\u6027\u3002", "result": "\u572815\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cSST\u5728\u5224\u522b\u548c\u6821\u51c6\u6307\u6807\u4e0a\u4f18\u4e8e\u4e09\u79cd\u57fa\u51c6\u751f\u5b58\u6811\u65b9\u6cd5\u3002", "conclusion": "SST\u7ed3\u5408\u4e86\u7075\u6d3b\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u53ef\u6269\u5c55\u81f3\u7fa4\u4f53\u516c\u5e73\u6027\uff0c\u662f\u4e00\u79cd\u6709\u6548\u7684\u751f\u5b58\u5206\u6790\u65b9\u6cd5\u3002"}}
{"id": "2506.16853", "pdf": "https://arxiv.org/pdf/2506.16853", "abs": "https://arxiv.org/abs/2506.16853", "authors": ["Semin Kim", "Yeonwoo Cha", "Jaehoon Yoo", "Seunghoon Hong"], "title": "Reward-Agnostic Prompt Optimization for Text-to-Image Diffusion Models", "categories": ["cs.LG"], "comment": "28 pages, Under review", "summary": "We investigate a general approach for improving user prompts in text-to-image\n(T2I) diffusion models by finding prompts that maximize a reward function\nspecified at test-time. Although diverse reward models are used for evaluating\nimage generation, existing automated prompt engineering methods typically\ntarget specific reward configurations. Consequently, these specialized designs\nexhibit suboptimal performance when applied to new prompt engineering scenarios\ninvolving different reward models. To address this limitation, we introduce\nRATTPO (Reward-Agnostic Test-Time Prompt Optimization), a flexible test-time\noptimization method applicable across various reward scenarios without\nmodification. RATTPO iteratively searches for optimized prompts by querying\nlarge language models (LLMs) \\textit{without} requiring reward-specific task\ndescriptions. Instead, it uses the optimization trajectory and a novel\nreward-aware feedback signal (termed a \"hint\") as context. Empirical results\ndemonstrate the versatility of RATTPO, effectively enhancing user prompts\nacross diverse reward setups that assess various generation aspects, such as\naesthetics, general human preference, or spatial relationships between objects.\nRATTPO surpasses other test-time search baselines in search efficiency, using\nup to 3.5 times less inference budget, and, given sufficient inference budget,\nachieves performance comparable to learning-based baselines that require\nreward-specific fine-tuning. The code is available at\nhttps://github.com/seminkim/RATTPO.", "AI": {"tldr": "RATTPO\u662f\u4e00\u79cd\u901a\u7528\u7684\u6d4b\u8bd5\u65f6\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5956\u52b1\u6a21\u578b\uff0c\u65e0\u9700\u4fee\u6539\u5373\u53ef\u63d0\u5347\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u7684\u63d0\u793a\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\u9488\u5bf9\u7279\u5b9a\u5956\u52b1\u914d\u7f6e\u8bbe\u8ba1\uff0c\u5728\u65b0\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u901a\u7528\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "method": "RATTPO\u901a\u8fc7\u8fed\u4ee3\u67e5\u8be2\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f18\u5316\u63d0\u793a\uff0c\u5229\u7528\u4f18\u5316\u8f68\u8ff9\u548c\u5956\u52b1\u611f\u77e5\u53cd\u9988\u4fe1\u53f7\uff08\u201c\u63d0\u793a\u201d\uff09\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u3002", "result": "RATTPO\u5728\u591a\u79cd\u5956\u52b1\u8bbe\u7f6e\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u641c\u7d22\u6548\u7387\u9ad8\uff08\u8282\u77013.5\u500d\u63a8\u7406\u9884\u7b97\uff09\uff0c\u6027\u80fd\u63a5\u8fd1\u9700\u5fae\u8c03\u7684\u5b66\u4e60\u57fa\u7ebf\u3002", "conclusion": "RATTPO\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u901a\u7528\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u5956\u52b1\u573a\u666f\u3002"}}
{"id": "2506.16855", "pdf": "https://arxiv.org/pdf/2506.16855", "abs": "https://arxiv.org/abs/2506.16855", "authors": ["Shaoyu Dou", "Kai Yang", "Yang Jiao", "Chengbo Qiu", "Kui Ren"], "title": "Anomaly Detection in Event-triggered Traffic Time Series via Similarity Learning", "categories": ["cs.LG"], "comment": "16 pages, 14 figures. Published in IEEE Transactions on Dependable\n  and Secure Computing. arXiv admin note: substantial text overlap with\n  arXiv:2207.08159", "summary": "Time series analysis has achieved great success in cyber security such as\nintrusion detection and device identification. Learning similarities among\nmultiple time series is a crucial problem since it serves as the foundation for\ndownstream analysis. Due to the complex temporal dynamics of the\nevent-triggered time series, it often remains unclear which similarity metric\nis appropriate for security-related tasks, such as anomaly detection and\nclustering. The overarching goal of this paper is to develop an unsupervised\nlearning framework that is capable of learning similarities among a set of\nevent-triggered time series. From the machine learning vantage point, the\nproposed framework harnesses the power of both hierarchical multi-resolution\nsequential autoencoders and the Gaussian Mixture Model (GMM) to effectively\nlearn the low-dimensional representations from the time series. Finally, the\nobtained similarity measure can be easily visualized for the explanation. The\nproposed framework aspires to offer a stepping stone that gives rise to a\nsystematic approach to model and learn similarities among a multitude of\nevent-triggered time series. Through extensive qualitative and quantitative\nexperiments, it is revealed that the proposed method outperforms\nstate-of-the-art methods considerably.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5b66\u4e60\u4e8b\u4ef6\u89e6\u53d1\u65f6\u95f4\u5e8f\u5217\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u7ed3\u5408\u4e86\u5206\u5c42\u591a\u5206\u8fa8\u7387\u5e8f\u5217\u81ea\u7f16\u7801\u5668\u548c\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u7531\u4e8e\u4e8b\u4ef6\u89e6\u53d1\u65f6\u95f4\u5e8f\u5217\u7684\u590d\u6742\u52a8\u6001\u6027\uff0c\u73b0\u6709\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\u5728\u5b89\u5168\u76f8\u5173\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u6846\u67b6\u3002", "method": "\u91c7\u7528\u5206\u5c42\u591a\u5206\u8fa8\u7387\u5e8f\u5217\u81ea\u7f16\u7801\u5668\u548c\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMM\uff09\u5b66\u4e60\u65f6\u95f4\u5e8f\u5217\u7684\u4f4e\u7ef4\u8868\u793a\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4e8b\u4ef6\u89e6\u53d1\u65f6\u95f4\u5e8f\u5217\u7684\u76f8\u4f3c\u6027\u5efa\u6a21\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u65b9\u6cd5\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.16862", "pdf": "https://arxiv.org/pdf/2506.16862", "abs": "https://arxiv.org/abs/2506.16862", "authors": ["Qian Qi"], "title": "Optimal Depth of Neural Networks", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Determining the optimal depth of a neural network is a fundamental yet\nchallenging problem, typically resolved through resource-intensive\nexperimentation. This paper introduces a formal theoretical framework to\naddress this question by recasting the forward pass of a deep network,\nspecifically a Residual Network (ResNet), as an optimal stopping problem. We\nmodel the layer-by-layer evolution of hidden representations as a sequential\ndecision process where, at each layer, a choice is made between halting\ncomputation to make a prediction or continuing to a deeper layer for a\npotentially more refined representation. This formulation captures the\nintrinsic trade-off between accuracy and computational cost. Our primary\ntheoretical contribution is a proof that, under a plausible condition of\ndiminishing returns on the residual functions, the expected optimal stopping\ndepth is provably finite, even in an infinite-horizon setting. We leverage this\ninsight to propose a novel and practical regularization term, $\\mathcal{L}_{\\rm\ndepth}$, that encourages the network to learn representations amenable to\nefficient, early exiting. We demonstrate the generality of our framework by\nextending it to the Transformer architecture and exploring its connection to\ncontinuous-depth models via free-boundary problems. Empirical validation on\nImageNet confirms that our regularizer successfully induces the theoretically\npredicted behavior, leading to significant gains in computational efficiency\nwithout compromising, and in some cases improving, final model accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u524d\u5411\u4f20\u64ad\u5efa\u6a21\u4e3a\u6700\u4f18\u505c\u6b62\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5728\u6b8b\u5dee\u51fd\u6570\u6536\u76ca\u9012\u51cf\u7684\u6761\u4ef6\u4e0b\uff0c\u6700\u4f18\u505c\u6b62\u6df1\u5ea6\u662f\u6709\u9650\u7684\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u795e\u7ecf\u7f51\u7edc\u6df1\u5ea6\u4f18\u5316\u7684\u6311\u6218\u6027\u95ee\u9898\uff0c\u907f\u514d\u8d44\u6e90\u5bc6\u96c6\u578b\u5b9e\u9a8c\u3002", "method": "\u5c06ResNet\u7684\u524d\u5411\u4f20\u64ad\u5efa\u6a21\u4e3a\u6700\u4f18\u505c\u6b62\u95ee\u9898\uff0c\u63d0\u51fa\u6b63\u5219\u5316\u9879$\\mathcal{L}_{\\rm depth}$\uff0c\u5e76\u6269\u5c55\u5230Transformer\u67b6\u6784\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86\u6700\u4f18\u505c\u6b62\u6df1\u5ea6\u7684\u6709\u9650\u6027\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6b63\u5219\u5316\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u4e14\u4e0d\u5f71\u54cd\u6a21\u578b\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u795e\u7ecf\u7f51\u7edc\u6df1\u5ea6\u4f18\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5e76\u901a\u8fc7\u6b63\u5219\u5316\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u6548\u8ba1\u7b97\u3002"}}
{"id": "2506.16884", "pdf": "https://arxiv.org/pdf/2506.16884", "abs": "https://arxiv.org/abs/2506.16884", "authors": ["Jacopo Graldi", "Alessandro Breccia", "Giulia Lanzillotta", "Thomas Hofmann", "Lorenzo Noci"], "title": "The Importance of Being Lazy: Scaling Limits of Continual Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Proceedings of the 42nd International Conference on Machine Learning\n  (2025). JG and AB contributed equally to this work", "summary": "Despite recent efforts, neural networks still struggle to learn in\nnon-stationary environments, and our understanding of catastrophic forgetting\n(CF) is far from complete. In this work, we perform a systematic study on the\nimpact of model scale and the degree of feature learning in continual learning.\nWe reconcile existing contradictory observations on scale in the literature, by\ndifferentiating between lazy and rich training regimes through a variable\nparameterization of the architecture. We show that increasing model width is\nonly beneficial when it reduces the amount of feature learning, yielding more\nlaziness. Using the framework of dynamical mean field theory, we then study the\ninfinite width dynamics of the model in the feature learning regime and\ncharacterize CF, extending prior theoretical results limited to the lazy\nregime. We study the intricate relationship between feature learning, task\nnon-stationarity, and forgetting, finding that high feature learning is only\nbeneficial with highly similar tasks. We identify a transition modulated by\ntask similarity where the model exits an effectively lazy regime with low\nforgetting to enter a rich regime with significant forgetting. Finally, our\nfindings reveal that neural networks achieve optimal performance at a critical\nlevel of feature learning, which depends on task non-stationarity and transfers\nacross model scales. This work provides a unified perspective on the role of\nscale and feature learning in continual learning.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u533a\u5206\u61d2\u60f0\u548c\u4e30\u5bcc\u8bad\u7ec3\u673a\u5236\uff0c\u7cfb\u7edf\u7814\u7a76\u4e86\u6a21\u578b\u89c4\u6a21\u548c\u7279\u5f81\u5b66\u4e60\u5bf9\u6301\u7eed\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u4e86\u7279\u5f81\u5b66\u4e60\u4e0e\u4efb\u52a1\u975e\u5e73\u7a33\u6027\u53ca\u9057\u5fd8\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u7814\u7a76\uff0c\u795e\u7ecf\u7f51\u7edc\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u7684\u5b66\u4e60\u4ecd\u5b58\u5728\u56f0\u96be\uff0c\u5bf9\u707e\u96be\u6027\u9057\u5fd8\u7684\u7406\u89e3\u5c1a\u4e0d\u5b8c\u6574\u3002", "method": "\u901a\u8fc7\u53ef\u53d8\u53c2\u6570\u5316\u67b6\u6784\u533a\u5206\u61d2\u60f0\u548c\u4e30\u5bcc\u8bad\u7ec3\u673a\u5236\uff0c\u5229\u7528\u52a8\u6001\u5e73\u5747\u573a\u7406\u8bba\u7814\u7a76\u65e0\u9650\u5bbd\u5ea6\u6a21\u578b\u5728\u7279\u5f81\u5b66\u4e60\u673a\u5236\u4e0b\u7684\u52a8\u6001\u7279\u6027\u3002", "result": "\u589e\u52a0\u6a21\u578b\u5bbd\u5ea6\u4ec5\u5728\u51cf\u5c11\u7279\u5f81\u5b66\u4e60\u65f6\u6709\u76ca\uff1b\u7279\u5f81\u5b66\u4e60\u4e0e\u4efb\u52a1\u76f8\u4f3c\u6027\u5bc6\u5207\u76f8\u5173\uff0c\u9ad8\u7279\u5f81\u5b66\u4e60\u4ec5\u5bf9\u9ad8\u5ea6\u76f8\u4f3c\u4efb\u52a1\u6709\u76ca\u3002", "conclusion": "\u795e\u7ecf\u7f51\u7edc\u5728\u7279\u5f81\u5b66\u4e60\u7684\u4e34\u754c\u6c34\u5e73\u4e0b\u8868\u73b0\u6700\u4f73\uff0c\u8be5\u6c34\u5e73\u53d6\u51b3\u4e8e\u4efb\u52a1\u975e\u5e73\u7a33\u6027\u4e14\u53ef\u8de8\u6a21\u578b\u89c4\u6a21\u8f6c\u79fb\u3002"}}
{"id": "2506.16890", "pdf": "https://arxiv.org/pdf/2506.16890", "abs": "https://arxiv.org/abs/2506.16890", "authors": ["Sebastian H\u00f6nel", "Jonas Nordqvist"], "title": "From Lab to Factory: Pitfalls and Guidelines for Self-/Unsupervised Defect Detection on Low-Quality Industrial Images", "categories": ["cs.LG", "cs.CV", "stat.AP", "62-06", "G.3; I.4; I.5"], "comment": "18 pages, 7 figures, 1 table. Camera-ready version for the 2025\n  conference European Conference on Machine Learning and Principles and\n  Practice of Knowledge Discovery in Databases (ECML PKDD '25)", "summary": "The detection and localization of quality-related problems in industrially\nmass-produced products has historically relied on manual inspection, which is\ncostly and error-prone. Machine learning has the potential to replace manual\nhandling. As such, the desire is to facilitate an unsupervised (or\nself-supervised) approach, as it is often impossible to specify all conceivable\ndefects ahead of time. A plethora of prior works have demonstrated the aptitude\nof common reconstruction-, embedding-, and synthesis-based methods in\nlaboratory settings. However, in practice, we observe that most methods do not\nhandle low data quality well or exude low robustness in unfavorable, but\ntypical real-world settings. For practitioners it may be very difficult to\nidentify the actual underlying problem when such methods underperform. Worse,\noften-reported metrics (e.g., AUROC) are rarely suitable in practice and may\ngive misleading results. In our setting, we attempt to identify subtle\nanomalies on the surface of blasted forged metal parts, using rather\nlow-quality RGB imagery only, which is a common industrial setting. We\nspecifically evaluate two types of state-of-the-art models that allow us to\nidentify and improve quality issues in production data, without having to\nobtain new data. Our contribution is to provide guardrails for practitioners\nthat allow them to identify problems related to, e.g., (lack of) robustness or\ninvariance, in either the chosen model or the data reliably in similar\nscenarios. Furthermore, we exemplify common pitfalls in and shortcomings of\nlikelihood-based approaches and outline a framework for proper empirical risk\nestimation that is more suitable for real-world scenarios.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5de5\u4e1a\u4ea7\u54c1\u8868\u9762\u7f3a\u9677\u7684\u65e0\u76d1\u7763\u68c0\u6d4b\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u4f4e\u8d28\u91cf\u6570\u636e\u548c\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u4f9b\u4e86\u6539\u8fdb\u6a21\u578b\u548c\u6570\u636e\u8d28\u91cf\u7684\u5b9e\u7528\u6307\u5357\u3002", "motivation": "\u4f20\u7edf\u624b\u52a8\u68c0\u6d4b\u5de5\u4e1a\u4ea7\u54c1\u8d28\u91cf\u95ee\u9898\u6210\u672c\u9ad8\u4e14\u6613\u51fa\u9519\uff0c\u673a\u5668\u5b66\u4e60\u867d\u6709\u671b\u66ff\u4ee3\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u4f4e\u8d28\u91cf\u6570\u636e\u548c\u5b9e\u9645\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u96be\u4ee5\u8bca\u65ad\u95ee\u9898\u6839\u6e90\u3002", "method": "\u8bc4\u4f30\u4e86\u4e24\u79cd\u5148\u8fdb\u7684\u65e0\u76d1\u7763\u6a21\u578b\uff0c\u7528\u4e8e\u8bc6\u522b\u548c\u6539\u8fdb\u751f\u4ea7\u6570\u636e\u4e2d\u7684\u8d28\u91cf\u95ee\u9898\uff0c\u65e0\u9700\u65b0\u6570\u636e\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u6a21\u578b\u548c\u6570\u636e\u8d28\u91cf\u7684\u6846\u67b6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5728\u4f4e\u8d28\u91cf\u6570\u636e\u548c\u5b9e\u9645\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u63d0\u51fa\u4e86\u66f4\u9002\u7528\u4e8e\u5b9e\u9645\u573a\u666f\u7684\u5b9e\u8bc1\u98ce\u9669\u4f30\u8ba1\u6846\u67b6\u3002", "conclusion": "\u8bba\u6587\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u8bc6\u522b\u548c\u6539\u8fdb\u6a21\u578b\u53ca\u6570\u636e\u8d28\u91cf\u95ee\u9898\u7684\u5b9e\u7528\u6307\u5357\uff0c\u5e76\u6307\u51fa\u4e86\u57fa\u4e8e\u4f3c\u7136\u65b9\u6cd5\u7684\u5e38\u89c1\u7f3a\u9677\uff0c\u63d0\u51fa\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16929", "pdf": "https://arxiv.org/pdf/2506.16929", "abs": "https://arxiv.org/abs/2506.16929", "authors": ["Mohon Raihan", "Plabon Kumar Saha", "Rajan Das Gupta", "A Z M Tahmidul Kabir", "Afia Anjum Tamanna", "Md. Harun-Ur-Rashid", "Adnan Bin Abdus Salam", "Md Tanvir Anjum", "A Z M Ahteshamul Kabir"], "title": "A deep learning and machine learning approach to predict neonatal death in the context of S\u00e3o Paulo", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Neonatal death is still a concerning reality for underdeveloped and even some\ndeveloped countries. Worldwide data indicate that 26.693 babies out of 1,000\nbirths die, according to Macro Trades. To reduce this number, early prediction\nof endangered babies is crucial. Such prediction enables the opportunity to\ntake ample care of the child and mother so that early child death can be\navoided. In this context, machine learning was used to determine whether a\nnewborn baby is at risk. To train the predictive model, historical data of 1.4\nmillion newborns was used. Machine learning and deep learning techniques such\nas logical regression, K-nearest neighbor, random forest classifier, extreme\ngradient boosting (XGBoost), convolutional neural network, and long short-term\nmemory (LSTM) were implemented using the dataset to identify the most accurate\nmodel for predicting neonatal mortality. Among the machine learning algorithms,\nXGBoost and random forest classifier achieved the best accuracy with 94%, while\namong the deep learning models, LSTM delivered the highest accuracy with 99%.\nTherefore, using LSTM appears to be the most suitable approach to predict\nwhether precautionary measures for a child are necessary.", "AI": {"tldr": "\u5229\u7528\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u9884\u6d4b\u65b0\u751f\u513f\u6b7b\u4ea1\u98ce\u9669\uff0cLSTM\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u8fbe99%\u3002", "motivation": "\u5168\u7403\u65b0\u751f\u513f\u6b7b\u4ea1\u7387\u9ad8\uff0c\u65e9\u671f\u9884\u6d4b\u53ef\u964d\u4f4e\u6b7b\u4ea1\u98ce\u9669\u3002", "method": "\u4f7f\u7528\u903b\u8f91\u56de\u5f52\u3001K\u8fd1\u90bb\u3001\u968f\u673a\u68ee\u6797\u3001XGBoost\u3001CNN\u548cLSTM\u7b49\u7b97\u6cd5\uff0c\u57fa\u4e8e140\u4e07\u65b0\u751f\u513f\u5386\u53f2\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u3002", "result": "XGBoost\u548c\u968f\u673a\u68ee\u6797\u51c6\u786e\u738794%\uff0cLSTM\u8fbe99%\u3002", "conclusion": "LSTM\u662f\u6700\u9002\u5408\u9884\u6d4b\u65b0\u751f\u513f\u6b7b\u4ea1\u98ce\u9669\u7684\u6a21\u578b\u3002"}}
{"id": "2506.16965", "pdf": "https://arxiv.org/pdf/2506.16965", "abs": "https://arxiv.org/abs/2506.16965", "authors": ["\u00c7a\u011fatay Demirel"], "title": "RocketStack: A level-aware deep recursive ensemble learning framework with exploratory feature fusion and model pruning dynamics", "categories": ["cs.LG", "stat.ML"], "comment": "32 pages, 1 graphical abstract, 7 figures, 9 tables, 2 supplementary\n  figures", "summary": "Ensemble learning remains a cornerstone of machine learning, with stacking\nused to integrate predictions from multiple base learners through a meta-model.\nHowever, deep stacking remains rare, as most designs prioritize horizontal\ndiversity over recursive depth due to model complexity, feature redundancy, and\ncomputational burden. To address these challenges, RocketStack, a level-aware\nrecursive ensemble framework, is introduced and explored up to ten stacking\nlevels, extending beyond prior architectures. The framework incrementally\nprunes weaker learners at each level, enabling deeper stacking without\nexcessive complexity. To mitigate early performance saturation, mild Gaussian\nnoise is added to out-of-fold (OOF) scores before pruning, and compared against\nstrict OOF pruning. Further both per-level and periodic feature compressions\nare explored using attention-based selection, Simple, Fast, Efficient (SFE)\nfilter, and autoencoders. Across 33 datasets (23 binary, 10 multi-class),\nlinear-trend tests confirmed rising accuracy with depth in most variants, and\nthe top performing meta-model at each level increasingly outperformed the\nstrongest standalone ensemble. In the binary subset, periodic SFE with mild\nOOF-score randomization reached 97.08% at level 10, 5.14% above the\nstrict-pruning configuration and cut runtime by 10.5% relative to no\ncompression. In the multi-class subset, periodic attention selection reached\n98.60% at level 10, exceeding the strongest baseline by 6.11%, while reducing\nruntime by 56.1% and feature dimensionality by 74% compared to no compression.\nThese findings highlight mild randomization as an effective regularizer and\nperiodic compression as a stabilizer. Echoing the design of multistage rockets\nin aerospace (prune, compress, propel) RocketStack achieves deep recursive\nensembling with tractable complexity.", "AI": {"tldr": "RocketStack\u662f\u4e00\u79cd\u9012\u5f52\u96c6\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u9010\u5c42\u4fee\u526a\u5f31\u5b66\u4e60\u5668\u548c\u7279\u5f81\u538b\u7f29\uff0c\u5b9e\u73b0\u4e86\u6df1\u5ea6\u5806\u53e0\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u8d1f\u62c5\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5806\u53e0\u4e2d\u6a21\u578b\u590d\u6742\u5ea6\u3001\u7279\u5f81\u5197\u4f59\u548c\u8ba1\u7b97\u8d1f\u62c5\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165RocketStack\u6846\u67b6\uff0c\u9010\u5c42\u4fee\u526a\u5f31\u5b66\u4e60\u5668\uff0c\u6dfb\u52a0\u9ad8\u65af\u566a\u58f0\uff0c\u5e76\u63a2\u7d22\u7279\u5f81\u538b\u7f29\u65b9\u6cd5\uff08\u5982\u6ce8\u610f\u529b\u9009\u62e9\u3001SFE\u8fc7\u6ee4\u5668\u548c\u81ea\u52a8\u7f16\u7801\u5668\uff09\u3002", "result": "\u572833\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u6df1\u5ea6\u5806\u53e0\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u8fd0\u884c\u65f6\u95f4\u548c\u7279\u5f81\u7ef4\u5ea6\u3002", "conclusion": "RocketStack\u901a\u8fc7\u4fee\u526a\u548c\u538b\u7f29\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6df1\u5ea6\u9012\u5f52\u96c6\u6210\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.16975", "pdf": "https://arxiv.org/pdf/2506.16975", "abs": "https://arxiv.org/abs/2506.16975", "authors": ["Guan Zhe Hong", "Bhavya Vasudeva", "Vatsal Sharan", "Cyrus Rashtchian", "Prabhakar Raghavan", "Rina Panigrahy"], "title": "Latent Concept Disentanglement in Transformer-based Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "When large language models (LLMs) use in-context learning (ICL) to solve a\nnew task, they seem to grasp not only the goal of the task but also core,\nlatent concepts in the demonstration examples. This begs the question of\nwhether transformers represent latent structures as part of their computation\nor whether they take shortcuts to solve the problem. Prior mechanistic work on\nICL does not address this question because it does not sufficiently examine the\nrelationship between the learned representation and the latent concept, and the\nconsidered problem settings often involve only single-step reasoning. In this\nwork, we examine how transformers disentangle and use latent concepts. We show\nthat in 2-hop reasoning tasks with a latent, discrete concept, the model\nsuccessfully identifies the latent concept and does step-by-step concept\ncomposition. In tasks parameterized by a continuous latent concept, we find\nlow-dimensional subspaces in the representation space where the geometry mimics\nthe underlying parameterization. Together, these results refine our\nunderstanding of ICL and the representation of transformers, and they provide\nevidence for highly localized structures in the model that disentangle latent\nconcepts in ICL tasks.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u4e2d\u662f\u5426\u80fd\u591f\u6355\u6349\u6f5c\u5728\u6982\u5ff5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6a21\u578b\u5728\u79bb\u6563\u548c\u8fde\u7eed\u6f5c\u5728\u6982\u5ff5\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7a76LLMs\u5728ICL\u4e2d\u662f\u5426\u771f\u6b63\u7406\u89e3\u6f5c\u5728\u6982\u5ff5\uff0c\u800c\u975e\u4ec5\u901a\u8fc7\u6377\u5f84\u89e3\u51b3\u95ee\u9898\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u57282\u8df3\u63a8\u7406\u4efb\u52a1\u4e2d\u6d4b\u8bd5\u6a21\u578b\u5bf9\u79bb\u6563\u6f5c\u5728\u6982\u5ff5\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u4ee5\u53ca\u5728\u8fde\u7eed\u6f5c\u5728\u6982\u5ff5\u4efb\u52a1\u4e2d\u5206\u6790\u8868\u793a\u7a7a\u95f4\u7684\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u6a21\u578b\u80fd\u6210\u529f\u8bc6\u522b\u79bb\u6563\u6f5c\u5728\u6982\u5ff5\u5e76\u9010\u6b65\u7ec4\u5408\uff0c\u540c\u65f6\u5728\u8fde\u7eed\u4efb\u52a1\u4e2d\u8868\u793a\u7a7a\u95f4\u7684\u51e0\u4f55\u7ed3\u6784\u4e0e\u6f5c\u5728\u53c2\u6570\u5316\u4e00\u81f4\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660e\uff0cICL\u4e2d\u5b58\u5728\u9ad8\u5ea6\u5c40\u90e8\u5316\u7684\u7ed3\u6784\uff0c\u80fd\u591f\u89e3\u8026\u6f5c\u5728\u6982\u5ff5\uff0c\u6df1\u5316\u4e86\u5bf9LLMs\u8868\u793a\u80fd\u529b\u7684\u7406\u89e3\u3002"}}
{"id": "2506.17007", "pdf": "https://arxiv.org/pdf/2506.17007", "abs": "https://arxiv.org/abs/2506.17007", "authors": ["Marco Jiralerspong", "Esther Derman", "Danilo Vucetic", "Nikolay Malkin", "Bilun Sun", "Tianyu Zhang", "Pierre-Luc Bacon", "Gauthier Gidel"], "title": "Robust Reinforcement Learning for Discrete Compositional Generation via General Soft Operators", "categories": ["cs.LG"], "comment": null, "summary": "A major bottleneck in scientific discovery involves narrowing a large\ncombinatorial set of objects, such as proteins or molecules, to a small set of\npromising candidates. While this process largely relies on expert knowledge,\nrecent methods leverage reinforcement learning (RL) to enhance this filtering.\nThey achieve this by estimating proxy reward functions from available datasets\nand using regularization to generate more diverse candidates. These reward\nfunctions are inherently uncertain, raising a particularly salient challenge\nfor scientific discovery. In this work, we show that existing methods, often\nframed as sampling proportional to a reward function, are inadequate and yield\nsuboptimal candidates, especially in large search spaces. To remedy this issue,\nwe take a robust RL approach and introduce a unified operator that seeks\nrobustness to the uncertainty of the proxy reward function. This general\noperator targets peakier sampling distributions while encompassing known soft\nRL operators. It also leads us to a novel algorithm that identifies\nhigher-quality, diverse candidates in both synthetic and real-world tasks.\nUltimately, our work offers a new, flexible perspective on discrete\ncompositional generation tasks. Code: https://github.com/marcojira/tgm.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9c81\u68d2\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u4ee3\u7406\u5956\u52b1\u51fd\u6570\u4e0d\u786e\u5b9a\u6027\u5bfc\u81f4\u7684\u5019\u9009\u751f\u6210\u95ee\u9898\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u79d1\u5b66\u53d1\u73b0\u4e2d\uff0c\u4ece\u5927\u91cf\u7ec4\u5408\u5bf9\u8c61\u4e2d\u7b5b\u9009\u5019\u9009\u5bf9\u8c61\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\uff0c\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u56e0\u4ee3\u7406\u5956\u52b1\u51fd\u6570\u7684\u4e0d\u786e\u5b9a\u6027\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u5f15\u5165\u7edf\u4e00\u64cd\u4f5c\u7b26\uff0c\u9488\u5bf9\u4ee3\u7406\u5956\u52b1\u51fd\u6570\u7684\u4e0d\u786e\u5b9a\u6027\u8fdb\u884c\u9c81\u68d2\u4f18\u5316\uff0c\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684\u591a\u6837\u5316\u5019\u9009\u3002", "result": "\u5728\u5408\u6210\u548c\u5b9e\u9645\u4efb\u52a1\u4e2d\uff0c\u65b0\u7b97\u6cd5\u80fd\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u4e14\u591a\u6837\u5316\u7684\u5019\u9009\u3002", "conclusion": "\u4e3a\u79bb\u6563\u7ec4\u5408\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u7075\u6d3b\u89c6\u89d2\u3002"}}
{"id": "2506.17016", "pdf": "https://arxiv.org/pdf/2506.17016", "abs": "https://arxiv.org/abs/2506.17016", "authors": ["Giulia Bertazzini", "Chiara Albisani", "Daniele Baracchi", "Dasara Shullani", "Roberto Verdecchia"], "title": "The Hidden Cost of an Image: Quantifying the Energy Consumption of AI Image Generation", "categories": ["cs.LG", "cs.MM"], "comment": null, "summary": "With the growing adoption of AI image generation, in conjunction with the\never-increasing environmental resources demanded by AI, we are urged to answer\na fundamental question: What is the environmental impact hidden behind each\nimage we generate? In this research, we present a comprehensive empirical\nexperiment designed to assess the energy consumption of AI image generation.\nOur experiment compares 17 state-of-the-art image generation models by\nconsidering multiple factors that could affect their energy consumption, such\nas model quantization, image resolution, and prompt length. Additionally, we\nconsider established image quality metrics to study potential trade-offs\nbetween energy consumption and generated image quality. Results show that image\ngeneration models vary drastically in terms of the energy they consume, with up\nto a 46x difference. Image resolution affects energy consumption\ninconsistently, ranging from a 1.3x to 4.7x increase when doubling resolution.\nU-Net-based models tend to consume less than Transformer-based one. Model\nquantization instead results to deteriorate the energy efficiency of most\nmodels, while prompt length and content have no statistically significant\nimpact. Improving image quality does not always come at the cost of a higher\nenergy consumption, with some of the models producing the highest quality\nimages also being among the most energy efficient ones.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e8617\u79cdAI\u56fe\u50cf\u751f\u6210\u6a21\u578b\u7684\u80fd\u8017\uff0c\u53d1\u73b0\u80fd\u8017\u5dee\u5f02\u663e\u8457\uff08\u6700\u9ad8\u8fbe46\u500d\uff09\uff0c\u5e76\u63a2\u8ba8\u4e86\u5206\u8fa8\u7387\u3001\u6a21\u578b\u7c7b\u578b\u3001\u91cf\u5316\u7b49\u56e0\u7d20\u5bf9\u80fd\u8017\u7684\u5f71\u54cd\u3002", "motivation": "\u968f\u7740AI\u56fe\u50cf\u751f\u6210\u7684\u5e7f\u6cdb\u5e94\u7528\u53ca\u5176\u5bf9\u73af\u5883\u8d44\u6e90\u7684\u9700\u6c42\u589e\u52a0\uff0c\u7814\u7a76\u65e8\u5728\u63ed\u793a\u751f\u6210\u6bcf\u5f20\u56fe\u50cf\u80cc\u540e\u7684\u73af\u5883\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u6bd4\u8f8317\u79cd\u5148\u8fdb\u56fe\u50cf\u751f\u6210\u6a21\u578b\uff0c\u5206\u6790\u6a21\u578b\u91cf\u5316\u3001\u56fe\u50cf\u5206\u8fa8\u7387\u3001\u63d0\u793a\u957f\u5ea6\u7b49\u56e0\u7d20\u5bf9\u80fd\u8017\u7684\u5f71\u54cd\uff0c\u5e76\u7ed3\u5408\u56fe\u50cf\u8d28\u91cf\u6307\u6807\u7814\u7a76\u80fd\u8017\u4e0e\u8d28\u91cf\u7684\u6743\u8861\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u4e0d\u540c\u6a21\u578b\u7684\u80fd\u8017\u5dee\u5f02\u663e\u8457\uff08\u6700\u9ad846\u500d\uff09\uff0c\u5206\u8fa8\u7387\u5bf9\u80fd\u8017\u5f71\u54cd\u4e0d\u4e00\u81f4\uff081.3x-4.7x\uff09\uff0cU-Net\u6a21\u578b\u80fd\u8017\u4f4e\u4e8eTransformer\u6a21\u578b\uff0c\u91cf\u5316\u901a\u5e38\u964d\u4f4e\u80fd\u6548\uff0c\u63d0\u793a\u957f\u5ea6\u65e0\u663e\u8457\u5f71\u54cd\u3002\u90e8\u5206\u9ad8\u8d28\u91cf\u6a21\u578b\u540c\u65f6\u4e5f\u662f\u80fd\u6548\u6700\u9ad8\u7684\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86AI\u56fe\u50cf\u751f\u6210\u6a21\u578b\u7684\u80fd\u8017\u5dee\u5f02\u53ca\u5f71\u54cd\u56e0\u7d20\uff0c\u4e3a\u5f00\u53d1\u66f4\u73af\u4fdd\u7684AI\u5de5\u5177\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.17029", "pdf": "https://arxiv.org/pdf/2506.17029", "abs": "https://arxiv.org/abs/2506.17029", "authors": ["Leizhen Wang", "Peibo Duan", "Cheng Lyu", "Zewen Wang", "Zhiqiang He", "Nan Zheng", "Zhenliang Ma"], "title": "Scalable and Reliable Multi-agent Reinforcement Learning for Traffic Assignment", "categories": ["cs.LG"], "comment": null, "summary": "The evolution of metropolitan cities and the increase in travel demands\nimpose stringent requirements on traffic assignment methods. Multi-agent\nreinforcement learning (MARL) approaches outperform traditional methods in\nmodeling adaptive routing behavior without requiring explicit system dynamics,\nwhich is beneficial for real-world deployment. However, MARL frameworks face\nchallenges in scalability and reliability when managing extensive networks with\nsubstantial travel demand, which limiting their practical applicability in\nsolving large-scale traffic assignment problems. To address these challenges,\nthis study introduces MARL-OD-DA, a new MARL framework for the traffic\nassignment problem, which redefines agents as origin-destination (OD) pair\nrouters rather than individual travelers, significantly enhancing scalability.\nAdditionally, a Dirichlet-based action space with action pruning and a reward\nfunction based on the local relative gap are designed to enhance solution\nreliability and improve convergence efficiency. Experiments demonstrate that\nthe proposed MARL framework effectively handles medium-sized networks with\nextensive and varied city-level OD demand, surpassing existing MARL methods.\nWhen implemented in the SiouxFalls network, MARL-OD-DA achieves better\nassignment solutions in 10 steps, with a relative gap that is 94.99% lower than\nthat of conventional methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6MARL-OD-DA\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u89c4\u6a21\u4ea4\u901a\u5206\u914d\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u667a\u80fd\u4f53\u5b9a\u4e49\u4e3aOD\u5bf9\u8def\u7531\u5668\u800c\u975e\u4e2a\u4f53\u65c5\u884c\u8005\uff0c\u63d0\u5347\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u901a\u8fc7\u6539\u8fdb\u52a8\u4f5c\u7a7a\u95f4\u548c\u5956\u52b1\u51fd\u6570\u589e\u5f3a\u4e86\u53ef\u9760\u6027\u548c\u6536\u655b\u6548\u7387\u3002", "motivation": "\u5927\u90fd\u5e02\u7684\u53d1\u5c55\u548c\u65c5\u884c\u9700\u6c42\u7684\u589e\u52a0\u5bf9\u4ea4\u901a\u5206\u914d\u65b9\u6cd5\u63d0\u51fa\u4e86\u66f4\u9ad8\u8981\u6c42\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94\u52a8\u6001\u8def\u7531\u884c\u4e3a\uff0c\u800c\u73b0\u6709MARL\u6846\u67b6\u5728\u53ef\u6269\u5c55\u6027\u548c\u53ef\u9760\u6027\u4e0a\u9762\u4e34\u6311\u6218\u3002", "method": "MARL-OD-DA\u5c06\u667a\u80fd\u4f53\u5b9a\u4e49\u4e3aOD\u5bf9\u8def\u7531\u5668\uff0c\u8bbe\u8ba1\u4e86\u57fa\u4e8eDirichlet\u7684\u52a8\u4f5c\u7a7a\u95f4\u548c\u57fa\u4e8e\u5c40\u90e8\u76f8\u5bf9\u5dee\u8ddd\u7684\u5956\u52b1\u51fd\u6570\uff0c\u4ee5\u63d0\u5347\u53ef\u6269\u5c55\u6027\u548c\u6536\u655b\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMARL-OD-DA\u80fd\u6709\u6548\u5904\u7406\u4e2d\u7b49\u89c4\u6a21\u7f51\u7edc\uff0c\u5728SiouxFalls\u7f51\u7edc\u4e2d\uff0c\u5176\u5206\u914d\u65b9\u6848\u7684\u76f8\u5bf9\u5dee\u8ddd\u6bd4\u4f20\u7edf\u65b9\u6cd5\u4f4e94.99%\u3002", "conclusion": "MARL-OD-DA\u6846\u67b6\u4e3a\u89e3\u51b3\u5927\u89c4\u6a21\u4ea4\u901a\u5206\u914d\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u53ef\u9760\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709MARL\u65b9\u6cd5\u3002"}}
{"id": "2506.17035", "pdf": "https://arxiv.org/pdf/2506.17035", "abs": "https://arxiv.org/abs/2506.17035", "authors": ["Jo\u00e3o Matos", "Ben Van Calster", "Leo Anthony Celi", "Paula Dhiman", "Judy Wawira Gichoya", "Richard D. Riley", "Chris Russell", "Sara Khalid", "Gary S. Collins"], "title": "Critical Appraisal of Fairness Metrics in Clinical Predictive AI", "categories": ["cs.LG"], "comment": "32 pages, 1 figure, 2 tables, 5 boxes, 4 linked supplementary\n  materials", "summary": "Predictive artificial intelligence (AI) offers an opportunity to improve\nclinical practice and patient outcomes, but risks perpetuating biases if\nfairness is inadequately addressed. However, the definition of \"fairness\"\nremains unclear. We conducted a scoping review to identify and critically\nappraise fairness metrics for clinical predictive AI. We defined a \"fairness\nmetric\" as a measure quantifying whether a model discriminates (societally)\nagainst individuals or groups defined by sensitive attributes. We searched five\ndatabases (2014-2024), screening 820 records, to include 41 studies, and\nextracted 62 fairness metrics. Metrics were classified by\nperformance-dependency, model output level, and base performance metric,\nrevealing a fragmented landscape with limited clinical validation and\noverreliance on threshold-dependent measures. Eighteen metrics were explicitly\ndeveloped for healthcare, including only one clinical utility metric. Our\nfindings highlight conceptual challenges in defining and quantifying fairness\nand identify gaps in uncertainty quantification, intersectionality, and\nreal-world applicability. Future work should prioritise clinically meaningful\nmetrics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u4e34\u5e8a\u9884\u6d4bAI\u4e2d\u7684\u516c\u5e73\u6027\u5ea6\u91cf\u95ee\u9898\uff0c\u901a\u8fc7\u7efc\u8ff041\u9879\u7814\u7a76\uff0c\u63d0\u53d6\u4e8662\u79cd\u516c\u5e73\u6027\u5ea6\u91cf\uff0c\u53d1\u73b0\u5176\u788e\u7247\u5316\u4e14\u7f3a\u4e4f\u4e34\u5e8a\u9a8c\u8bc1\u3002", "motivation": "\u9884\u6d4bAI\u53ef\u80fd\u6539\u5584\u4e34\u5e8a\u5b9e\u8df5\uff0c\u4f46\u82e5\u516c\u5e73\u6027\u672a\u59a5\u5584\u89e3\u51b3\uff0c\u53ef\u80fd\u52a0\u5267\u504f\u89c1\u3002\u516c\u5e73\u6027\u5b9a\u4e49\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u8303\u56f4\u7efc\u8ff0\uff0c\u641c\u7d225\u4e2a\u6570\u636e\u5e93\uff082014-2024\u5e74\uff09\uff0c\u7b5b\u9009820\u6761\u8bb0\u5f55\uff0c\u7eb3\u516541\u9879\u7814\u7a76\uff0c\u63d0\u53d662\u79cd\u516c\u5e73\u6027\u5ea6\u91cf\u3002", "result": "\u53d1\u73b0\u516c\u5e73\u6027\u5ea6\u91cf\u788e\u7247\u5316\uff0c\u4e34\u5e8a\u9a8c\u8bc1\u6709\u9650\uff0c\u8fc7\u5ea6\u4f9d\u8d56\u9608\u503c\u4f9d\u8d56\u6027\u5ea6\u91cf\u3002\u4ec518\u79cd\u4e13\u4e3a\u533b\u7597\u8bbe\u8ba1\uff0c\u5176\u4e2d\u4ec51\u79cd\u6d89\u53ca\u4e34\u5e8a\u5b9e\u7528\u6027\u3002", "conclusion": "\u516c\u5e73\u6027\u5b9a\u4e49\u548c\u91cf\u5316\u5b58\u5728\u6982\u5ff5\u6311\u6218\uff0c\u9700\u5173\u6ce8\u4e34\u5e8a\u610f\u4e49\u5ea6\u91cf\uff0c\u586b\u8865\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3001\u4ea4\u53c9\u6027\u548c\u5b9e\u9645\u5e94\u7528\u7a7a\u767d\u3002"}}
{"id": "2506.17039", "pdf": "https://arxiv.org/pdf/2506.17039", "abs": "https://arxiv.org/abs/2506.17039", "authors": ["Elizabeth Fons", "Alejandro Sztrajman", "Yousef El-Laham", "Luciana Ferrer", "Svitlana Vyetrenko", "Manuela Veloso"], "title": "LSCD: Lomb-Scargle Conditioned Diffusion for Time series Imputation", "categories": ["cs.LG", "cs.AI"], "comment": "In ICML 2025", "summary": "Time series with missing or irregularly sampled data are a persistent\nchallenge in machine learning. Many methods operate on the frequency-domain,\nrelying on the Fast Fourier Transform (FFT) which assumes uniform sampling,\ntherefore requiring prior interpolation that can distort the spectra. To\naddress this limitation, we introduce a differentiable Lomb--Scargle layer that\nenables a reliable computation of the power spectrum of irregularly sampled\ndata. We integrate this layer into a novel score-based diffusion model (LSCD)\nfor time series imputation conditioned on the entire signal spectrum.\nExperiments on synthetic and real-world benchmarks demonstrate that our method\nrecovers missing data more accurately than purely time-domain baselines, while\nsimultaneously producing consistent frequency estimates. Crucially, our method\ncan be easily integrated into learning frameworks, enabling broader adoption of\nspectral guidance in machine learning approaches involving incomplete or\nirregular data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLomb-Scargle\u7684\u53ef\u5fae\u5206\u5c42\uff0c\u7528\u4e8e\u5904\u7406\u4e0d\u89c4\u5219\u91c7\u6837\u65f6\u95f4\u5e8f\u5217\u7684\u9891\u8c31\u8ba1\u7b97\uff0c\u5e76\u7ed3\u5408\u6269\u6563\u6a21\u578b\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u6570\u636e\u586b\u8865\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfFFT\u65b9\u6cd5\u56e0\u5747\u5300\u91c7\u6837\u5047\u8bbe\u800c\u65e0\u6cd5\u76f4\u63a5\u5904\u7406\u4e0d\u89c4\u5219\u91c7\u6837\u6570\u636e\u7684\u95ee\u9898\uff0c\u907f\u514d\u63d2\u503c\u5e26\u6765\u7684\u9891\u8c31\u5931\u771f\u3002", "method": "\u5f15\u5165\u53ef\u5fae\u5206\u7684Lomb-Scargle\u5c42\u8ba1\u7b97\u4e0d\u89c4\u5219\u6570\u636e\u7684\u529f\u7387\u8c31\uff0c\u5e76\u96c6\u6210\u5230\u57fa\u4e8e\u5206\u6570\u7684\u6269\u6563\u6a21\u578b\uff08LSCD\uff09\u4e2d\uff0c\u5b9e\u73b0\u9891\u8c31\u5f15\u5bfc\u7684\u65f6\u95f4\u5e8f\u5217\u586b\u8865\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cLSCD\u6bd4\u7eaf\u65f6\u57df\u57fa\u7ebf\u66f4\u51c6\u786e\u5730\u6062\u590d\u7f3a\u5931\u6570\u636e\uff0c\u540c\u65f6\u63d0\u4f9b\u4e00\u81f4\u7684\u9891\u8c31\u4f30\u8ba1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u8f7b\u677e\u96c6\u6210\u5230\u5b66\u4e60\u6846\u67b6\u4e2d\uff0c\u4e3a\u5904\u7406\u4e0d\u5b8c\u6574\u6216\u4e0d\u89c4\u5219\u6570\u636e\u63d0\u4f9b\u4e86\u9891\u8c31\u5f15\u5bfc\u7684\u65b0\u601d\u8def\u3002"}}
{"id": "2506.17041", "pdf": "https://arxiv.org/pdf/2506.17041", "abs": "https://arxiv.org/abs/2506.17041", "authors": ["Joshua Schraven", "Alexander Windmann", "Oliver Niggemann"], "title": "MAWIFlow Benchmark: Realistic Flow-Based Evaluation for Network Intrusion Detection", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 3 figures", "summary": "Benchmark datasets for network intrusion detection commonly rely on\nsynthetically generated traffic, which fails to reflect the statistical\nvariability and temporal drift encountered in operational environments. This\npaper introduces MAWIFlow, a flow-based benchmark derived from the MAWILAB v1.1\ndataset, designed to enable realistic and reproducible evaluation of anomaly\ndetection methods. A reproducible preprocessing pipeline is presented that\ntransforms raw packet captures into flow representations conforming to the\nCICFlowMeter format, while preserving MAWILab's original anomaly labels. The\nresulting datasets comprise temporally distinct samples from January 2011,\n2016, and 2021, drawn from trans-Pacific backbone traffic.\n  To establish reference baselines, traditional machine learning methods,\nincluding Decision Trees, Random Forests, XGBoost, and Logistic Regression, are\ncompared to a deep learning model based on a CNN-BiLSTM architecture. Empirical\nresults demonstrate that tree-based classifiers perform well on temporally\nstatic data but experience significant performance degradation over time. In\ncontrast, the CNN-BiLSTM model maintains better performance, thus showing\nimproved generalization. These findings underscore the limitations of synthetic\nbenchmarks and static models, and motivate the adoption of realistic datasets\nwith explicit temporal structure. All datasets, pipeline code, and model\nimplementations are made publicly available to foster transparency and\nreproducibility.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86MAWIFlow\uff0c\u4e00\u4e2a\u57fa\u4e8eMAWILab v1.1\u6570\u636e\u96c6\u7684\u6d41\u91cf\u57fa\u51c6\uff0c\u7528\u4e8e\u66f4\u771f\u5b9e\u548c\u53ef\u590d\u73b0\u7684\u5f02\u5e38\u68c0\u6d4b\u8bc4\u4f30\u3002\u901a\u8fc7\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08CNN-BiLSTM\uff09\u7684\u6bd4\u8f83\uff0c\u53d1\u73b0\u6811\u6a21\u578b\u5728\u9759\u6001\u6570\u636e\u8868\u73b0\u597d\u4f46\u968f\u65f6\u95f4\u6027\u80fd\u4e0b\u964d\uff0c\u800cCNN-BiLSTM\u6cdb\u5316\u80fd\u529b\u66f4\u5f3a\u3002", "motivation": "\u73b0\u6709\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7684\u57fa\u51c6\u6570\u636e\u96c6\u591a\u4e3a\u5408\u6210\u6d41\u91cf\uff0c\u65e0\u6cd5\u53cd\u6620\u5b9e\u9645\u73af\u5883\u4e2d\u7684\u7edf\u8ba1\u53d8\u5f02\u548c\u65f6\u95f4\u6f02\u79fb\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u771f\u5b9e\u7684\u8bc4\u4f30\u5de5\u5177\u3002", "method": "\u63d0\u51faMAWIFlow\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u53ef\u590d\u73b0\u7684\u9884\u5904\u7406\u6d41\u7a0b\u5c06\u539f\u59cb\u6570\u636e\u5305\u8f6c\u6362\u4e3aCICFlowMeter\u683c\u5f0f\u7684\u6d41\u91cf\u8868\u793a\uff0c\u5e76\u4fdd\u7559\u5f02\u5e38\u6807\u7b7e\u3002\u6bd4\u8f83\u4e86\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u5982\u51b3\u7b56\u6811\u3001\u968f\u673a\u68ee\u6797\uff09\u548cCNN-BiLSTM\u6a21\u578b\u3002", "result": "\u6811\u6a21\u578b\u5728\u9759\u6001\u6570\u636e\u8868\u73b0\u826f\u597d\u4f46\u968f\u65f6\u95f4\u6027\u80fd\u4e0b\u964d\uff0c\u800cCNN-BiLSTM\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u66f4\u5f3a\uff0c\u6027\u80fd\u66f4\u7a33\u5b9a\u3002", "conclusion": "\u5408\u6210\u57fa\u51c6\u548c\u9759\u6001\u6a21\u578b\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5e94\u91c7\u7528\u5177\u6709\u660e\u786e\u65f6\u95f4\u7ed3\u6784\u7684\u771f\u5b9e\u6570\u636e\u96c6\u3002\u6240\u6709\u6570\u636e\u548c\u4ee3\u7801\u516c\u5f00\u4ee5\u4fc3\u8fdb\u900f\u660e\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2506.17047", "pdf": "https://arxiv.org/pdf/2506.17047", "abs": "https://arxiv.org/abs/2506.17047", "authors": ["Haolin Liu", "Adrien Siproudhis", "Samuel Experton", "Peter Lorenz", "Christina Boura", "Thomas Peyrin"], "title": "Navigating the Deep: Signature Extraction on Deep Neural Networks", "categories": ["cs.LG", "cs.CR"], "comment": "26 pages", "summary": "Neural network model extraction has emerged in recent years as an important\nsecurity concern, as adversaries attempt to recover a network's parameters via\nblack-box queries. A key step in this process is signature extraction, which\naims to recover the absolute values of the network's weights layer by layer.\nPrior work, notably by Carlini et al. (2020), introduced a technique inspired\nby differential cryptanalysis to extract neural network parameters. However,\ntheir method suffers from several limitations that restrict its applicability\nto networks with a few layers only. Later works focused on improving sign\nextraction, but largely relied on the assumption that signature extraction\nitself was feasible.\n  In this work, we revisit and refine the signature extraction process by\nsystematically identifying and addressing for the first time critical\nlimitations of Carlini et al.'s signature extraction method. These limitations\ninclude rank deficiency and noise propagation from deeper layers. To overcome\nthese challenges, we propose efficient algorithmic solutions for each of the\nidentified issues, greatly improving the efficiency of signature extraction.\nOur approach permits the extraction of much deeper networks than was previously\npossible. We validate our method through extensive experiments on ReLU-based\nneural networks, demonstrating significant improvements in extraction depth and\naccuracy. For instance, our extracted network matches the target network on at\nleast 95% of the input space for each of the eight layers of a neural network\ntrained on the CIFAR-10 dataset, while previous works could barely extract the\nfirst three layers. Our results represent a crucial step toward practical\nattacks on larger and more complex neural network architectures.", "AI": {"tldr": "\u672c\u6587\u6539\u8fdb\u4e86\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u63d0\u53d6\u4e2d\u7684\u7b7e\u540d\u63d0\u53d6\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u5148\u524d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5982\u79e9\u4e0d\u8db3\u548c\u566a\u58f0\u4f20\u64ad\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63d0\u53d6\u6df1\u5ea6\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u9488\u5bf9Carlini\u7b49\u4eba\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5982\u4ec5\u9002\u7528\u4e8e\u6d45\u5c42\u7f51\u7edc\uff0c\u672c\u6587\u65e8\u5728\u6539\u8fdb\u7b7e\u540d\u63d0\u53d6\u8fc7\u7a0b\uff0c\u4ee5\u652f\u6301\u66f4\u6df1\u5c42\u7f51\u7edc\u7684\u63d0\u53d6\u3002", "method": "\u63d0\u51fa\u9ad8\u6548\u7b97\u6cd5\u89e3\u51b3\u79e9\u4e0d\u8db3\u548c\u566a\u58f0\u4f20\u64ad\u95ee\u9898\uff0c\u4f18\u5316\u7b7e\u540d\u63d0\u53d6\u8fc7\u7a0b\u3002", "result": "\u5728CIFAR-10\u6570\u636e\u96c6\u4e0a\uff0c\u6210\u529f\u63d0\u53d6\u4e86\u516b\u5c42\u7f51\u7edc\u7684\u7b7e\u540d\uff0c\u51c6\u786e\u7387\u8d85\u8fc795%\uff0c\u8fdc\u8d85\u5148\u524d\u65b9\u6cd5\u7684\u4e09\u5c42\u9650\u5236\u3002", "conclusion": "\u672c\u6587\u65b9\u6cd5\u4e3a\u653b\u51fb\u66f4\u590d\u6742\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u63d0\u4f9b\u4e86\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2506.17052", "pdf": "https://arxiv.org/pdf/2506.17052", "abs": "https://arxiv.org/abs/2506.17052", "authors": ["Jingtong Su", "Julia Kempe", "Karen Ullrich"], "title": "From Concepts to Components: Concept-Agnostic Attention Module Discovery in Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Transformers have achieved state-of-the-art performance across language and\nvision tasks. This success drives the imperative to interpret their internal\nmechanisms with the dual goals of enhancing performance and improving\nbehavioral control. Attribution methods help advance interpretability by\nassigning model outputs associated with a target concept to specific model\ncomponents. Current attribution research primarily studies multi-layer\nperceptron neurons and addresses relatively simple concepts such as factual\nassociations (e.g., Paris is located in France). This focus tends to overlook\nthe impact of the attention mechanism and lacks a unified approach for\nanalyzing more complex concepts. To fill these gaps, we introduce Scalable\nAttention Module Discovery (SAMD), a concept-agnostic method for mapping\narbitrary, complex concepts to specific attention heads of general transformer\nmodels. We accomplish this by representing each concept as a vector,\ncalculating its cosine similarity with each attention head, and selecting the\nTopK-scoring heads to construct the concept-associated attention module. We\nthen propose Scalar Attention Module Intervention (SAMI), a simple strategy to\ndiminish or amplify the effects of a concept by adjusting the attention module\nusing only a single scalar parameter. Empirically, we demonstrate SAMD on\nconcepts of varying complexity, and visualize the locations of their\ncorresponding modules. Our results demonstrate that module locations remain\nstable before and after LLM post-training, and confirm prior work on the\nmechanics of LLM multilingualism. Through SAMI, we facilitate jailbreaking on\nHarmBench (+72.7%) by diminishing \"safety\" and improve performance on the GSM8K\nbenchmark (+1.6%) by amplifying \"reasoning\". Lastly, we highlight the\ndomain-agnostic nature of our approach by suppressing the image classification\naccuracy of vision transformers on ImageNet.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSAMD\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5c06\u590d\u6742\u6982\u5ff5\u6620\u5c04\u5230Transformer\u6a21\u578b\u7684\u7279\u5b9a\u6ce8\u610f\u529b\u5934\uff0c\u5e76\u901a\u8fc7SAMI\u65b9\u6cd5\u8c03\u6574\u8fd9\u4e9b\u6a21\u5757\u7684\u6548\u679c\u3002\u5b9e\u9a8c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u8bed\u8a00\u548c\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "Transformer\u6a21\u578b\u5728\u8bed\u8a00\u548c\u89c6\u89c9\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5bf9\u5176\u5185\u90e8\u673a\u5236\u7684\u89e3\u91ca\u4ecd\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5bf9\u6ce8\u610f\u529b\u673a\u5236\u7684\u5f71\u54cd\u548c\u590d\u6742\u6982\u5ff5\u7684\u5206\u6790\u7f3a\u4e4f\u7edf\u4e00\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSAMD\u65b9\u6cd5\uff0c\u5c06\u6982\u5ff5\u8868\u793a\u4e3a\u5411\u91cf\uff0c\u8ba1\u7b97\u5176\u4e0e\u6ce8\u610f\u529b\u5934\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff0c\u9009\u62e9TopK\u5f97\u5206\u5934\u6784\u5efa\u6982\u5ff5\u76f8\u5173\u6a21\u5757\uff1b\u8fdb\u4e00\u6b65\u63d0\u51faSAMI\u65b9\u6cd5\uff0c\u901a\u8fc7\u6807\u91cf\u53c2\u6570\u8c03\u6574\u6a21\u5757\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eSAMD\u80fd\u7a33\u5b9a\u5b9a\u4f4d\u6a21\u5757\uff0cSAMI\u5728\u589e\u5f3a\u6216\u6291\u5236\u6982\u5ff5\u6548\u679c\u4e0a\u6709\u6548\uff0c\u5982\u63d0\u5347GSM8K\u6027\u80fd1.6%\uff0c\u964d\u4f4eImageNet\u5206\u7c7b\u51c6\u786e\u7387\u3002", "conclusion": "SAMD\u548cSAMI\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u65b9\u6cd5\uff0c\u53ef\u89e3\u91ca\u548c\u5e72\u9884Transformer\u6a21\u578b\u7684\u884c\u4e3a\uff0c\u9002\u7528\u4e8e\u8bed\u8a00\u548c\u89c6\u89c9\u4efb\u52a1\u3002"}}
{"id": "2506.17065", "pdf": "https://arxiv.org/pdf/2506.17065", "abs": "https://arxiv.org/abs/2506.17065", "authors": ["Abdellah Rahmani", "Pascal Frossard"], "title": "Flow-Based Non-stationary Temporal Regime Causal Structure Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Understanding causal relationships in multivariate time series is crucial in\nmany scenarios, such as those dealing with financial or neurological data. Many\nsuch time series exhibit multiple regimes, i.e., consecutive temporal segments\nwith a priori unknown boundaries, with each regime having its own causal\nstructure. Inferring causal dependencies and regime shifts is critical for\nanalyzing the underlying processes. However, causal structure learning in this\nsetting is challenging due to (1) non stationarity, i.e., each regime can have\nits own causal graph and mixing function, and (2) complex noise distributions,\nwhich may be non Gaussian or heteroscedastic. Existing causal discovery\napproaches cannot address these challenges, since generally assume stationarity\nor Gaussian noise with constant variance. Hence, we introduce FANTOM, a unified\nframework for causal discovery that handles non stationary processes along with\nnon Gaussian and heteroscedastic noises. FANTOM simultaneously infers the\nnumber of regimes and their corresponding indices and learns each regime's\nDirected Acyclic Graph. It uses a Bayesian Expectation Maximization algorithm\nthat maximizes the evidence lower bound of the data log likelihood. On the\ntheoretical side, we prove, under mild assumptions, that temporal\nheteroscedastic causal models, introduced in FANTOM's formulation, are\nidentifiable in both stationary and non stationary settings. In addition,\nextensive experiments on synthetic and real data show that FANTOM outperforms\nexisting methods.", "AI": {"tldr": "FANTOM\u662f\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u975e\u5e73\u7a33\u8fc7\u7a0b\u3001\u975e\u9ad8\u65af\u548c\u5f02\u65b9\u5dee\u566a\u58f0\u7684\u56e0\u679c\u53d1\u73b0\uff0c\u540c\u65f6\u63a8\u65ad\u591a\u4e2a\u56e0\u679c\u7ed3\u6784\u53ca\u5176\u8fb9\u754c\u3002", "motivation": "\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u56e0\u679c\u5173\u7cfb\u5206\u6790\u5728\u91d1\u878d\u548c\u795e\u7ecf\u79d1\u5b66\u7b49\u9886\u57df\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u975e\u5e73\u7a33\u6027\u548c\u590d\u6742\u566a\u58f0\u5206\u5e03\u3002", "method": "FANTOM\u4f7f\u7528\u8d1d\u53f6\u65af\u671f\u671b\u6700\u5927\u5316\u7b97\u6cd5\uff0c\u6700\u5927\u5316\u6570\u636e\u5bf9\u6570\u4f3c\u7136\u7684\u8bc1\u636e\u4e0b\u754c\uff0c\u540c\u65f6\u63a8\u65ad\u56e0\u679c\u7ed3\u6784\u548c\u8fb9\u754c\u3002", "result": "\u7406\u8bba\u8bc1\u660eFANTOM\u5728\u5e73\u7a33\u548c\u975e\u5e73\u7a33\u8bbe\u7f6e\u4e0b\u53ef\u8bc6\u522b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "FANTOM\u4e3a\u590d\u6742\u65f6\u95f4\u5e8f\u5217\u7684\u56e0\u679c\u53d1\u73b0\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.17067", "pdf": "https://arxiv.org/pdf/2506.17067", "abs": "https://arxiv.org/abs/2506.17067", "authors": ["Zhuo Xu", "Tianyue Zheng", "Linglong Dai"], "title": "Empowering Near-Field Communications in Low-Altitude Economy with LLM: Fundamentals, Potentials, Solutions, and Future Directions", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "The low-altitude economy (LAE) is gaining significant attention from academia\nand industry. Fortunately, LAE naturally aligns with near-field communications\nin extremely large-scale MIMO (XL-MIMO) systems. By leveraging near-field\nbeamfocusing, LAE can precisely direct beam energy to unmanned aerial vehicles,\nwhile the additional distance dimension boosts overall spectrum efficiency.\nHowever, near-field communications in LAE still face several challenges, such\nas the increase in signal processing complexity and the necessity of\ndistinguishing between far and near-field users. Inspired by the large language\nmodels (LLM) with powerful ability to handle complex problems, we apply LLM to\nsolve challenges of near-field communications in LAE. The objective of this\narticle is to provide a comprehensive analysis and discussion on LLM-empowered\nnear-field communications in LAE. Specifically, we first introduce fundamentals\nof LLM and near-field communications, including the key advantages of LLM and\nkey characteristics of near-field communications. Then, we reveal the\nopportunities and challenges of near-field communications in LAE. To address\nthese challenges, we present a LLM-based scheme for near-field communications\nin LAE, and provide a case study which jointly distinguishes far and near-field\nusers and designs multi-user precoding matrix. Finally, we outline and\nhighlight several future research directions and open issues.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4f4e\u7a7a\u7ecf\u6d4e\uff08LAE\uff09\u4e0e\u8d85\u5927\u89c4\u6a21MIMO\uff08XL-MIMO\uff09\u7cfb\u7edf\u4e2d\u7684\u8fd1\u573a\u901a\u4fe1\u7684\u7ed3\u5408\uff0c\u63d0\u51fa\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u89e3\u51b3\u8fd1\u573a\u901a\u4fe1\u7684\u6311\u6218\u3002", "motivation": "\u4f4e\u7a7a\u7ecf\u6d4e\uff08LAE\uff09\u4e0e\u8fd1\u573a\u901a\u4fe1\u7684\u7ed3\u5408\u9762\u4e34\u4fe1\u53f7\u5904\u7406\u590d\u6742\u5ea6\u589e\u52a0\u548c\u7528\u6237\u533a\u5206\u7b49\u6311\u6218\uff0cLLM\u56e0\u5176\u5904\u7406\u590d\u6742\u95ee\u9898\u7684\u80fd\u529b\u6210\u4e3a\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bba\u6587\u9996\u5148\u4ecb\u7ecdLLM\u548c\u8fd1\u573a\u901a\u4fe1\u7684\u57fa\u7840\u77e5\u8bc6\uff0c\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "LLM\u80fd\u591f\u6709\u6548\u89e3\u51b3\u8fd1\u573a\u901a\u4fe1\u4e2d\u7684\u7528\u6237\u533a\u5206\u548c\u591a\u7528\u6237\u9884\u7f16\u7801\u8bbe\u8ba1\u95ee\u9898\u3002", "conclusion": "\u8bba\u6587\u603b\u7ed3\u4e86LLM\u5728LAE\u8fd1\u573a\u901a\u4fe1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.17093", "pdf": "https://arxiv.org/pdf/2506.17093", "abs": "https://arxiv.org/abs/2506.17093", "authors": ["Konstantin Usevich", "Clara D\u00e9rand", "Ricardo Borsoi", "Marianne Clausel"], "title": "Identifiability of Deep Polynomial Neural Networks", "categories": ["cs.LG", "cs.AI", "math.AG", "stat.ML", "68T07, 62R01, 15A69, 14M99"], "comment": "1 figure", "summary": "Polynomial Neural Networks (PNNs) possess a rich algebraic and geometric\nstructure. However, their identifiability -- a key property for ensuring\ninterpretability -- remains poorly understood. In this work, we present a\ncomprehensive analysis of the identifiability of deep PNNs, including\narchitectures with and without bias terms. Our results reveal an intricate\ninterplay between activation degrees and layer widths in achieving\nidentifiability. As special cases, we show that architectures with\nnon-increasing layer widths are generically identifiable under mild conditions,\nwhile encoder-decoder networks are identifiable when the decoder widths do not\ngrow too rapidly. Our proofs are constructive and center on a connection\nbetween deep PNNs and low-rank tensor decompositions, and Kruskal-type\nuniqueness theorems. This yields both generic conditions determined by the\narchitecture, and effective conditions that depend on the network's parameters.\nWe also settle an open conjecture on the expected dimension of PNN's\nneurovarieties, and provide new bounds on the activation degrees required for\nit to reach its maximum.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u5206\u6790\u4e86\u6df1\u5ea6\u591a\u9879\u5f0f\u795e\u7ecf\u7f51\u7edc\uff08PNNs\uff09\u7684\u53ef\u8bc6\u522b\u6027\uff0c\u63ed\u793a\u4e86\u6fc0\u6d3b\u5ea6\u4e0e\u5c42\u5bbd\u5ea6\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\uff0c\u5e76\u89e3\u51b3\u4e86\u5173\u4e8ePNNs\u795e\u7ecf\u53d8\u79cd\u9884\u671f\u7ef4\u5ea6\u7684\u5f00\u653e\u731c\u60f3\u3002", "motivation": "\u591a\u9879\u5f0f\u795e\u7ecf\u7f51\u7edc\uff08PNNs\uff09\u5177\u6709\u4e30\u5bcc\u7684\u4ee3\u6570\u548c\u51e0\u4f55\u7ed3\u6784\uff0c\u4f46\u5176\u53ef\u8bc6\u522b\u6027\uff08\u786e\u4fdd\u53ef\u89e3\u91ca\u6027\u7684\u5173\u952e\u5c5e\u6027\uff09\u4ecd\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u5c06\u6df1\u5ea6PNNs\u4e0e\u4f4e\u79e9\u5f20\u91cf\u5206\u89e3\u53caKruskal\u578b\u552f\u4e00\u6027\u5b9a\u7406\u8054\u7cfb\u8d77\u6765\uff0c\u63d0\u51fa\u4e86\u6784\u9020\u6027\u8bc1\u660e\u65b9\u6cd5\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\uff0c\u5c42\u5bbd\u5ea6\u975e\u9012\u589e\u7684\u67b6\u6784\u901a\u5e38\u662f\u53ef\u8bc6\u522b\u7684\uff0c\u800c\u89e3\u7801\u5668\u5bbd\u5ea6\u589e\u957f\u4e0d\u8fc7\u5feb\u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7f51\u7edc\u4e5f\u662f\u53ef\u8bc6\u522b\u7684\u3002", "conclusion": "\u7814\u7a76\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u7531\u67b6\u6784\u51b3\u5b9a\u7684\u901a\u7528\u6761\u4ef6\uff0c\u8fd8\u7ed9\u51fa\u4e86\u4f9d\u8d56\u4e8e\u7f51\u7edc\u53c2\u6570\u7684\u6709\u6548\u6761\u4ef6\uff0c\u5e76\u89e3\u51b3\u4e86PNNs\u795e\u7ecf\u53d8\u79cd\u9884\u671f\u7ef4\u5ea6\u7684\u5f00\u653e\u731c\u60f3\u3002"}}
{"id": "2506.17103", "pdf": "https://arxiv.org/pdf/2506.17103", "abs": "https://arxiv.org/abs/2506.17103", "authors": ["Shruti Sadanand Dongare", "Amun Kharel", "Jonathan Samuel", "Xiaona Zhou"], "title": "TransDreamerV3: Implanting Transformer In DreamerV3", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper introduces TransDreamerV3, a reinforcement learning model that\nenhances the DreamerV3 architecture by integrating a transformer encoder. The\nmodel is designed to improve memory and decision-making capabilities in complex\nenvironments. We conducted experiments on Atari-Boxing, Atari-Freeway,\nAtari-Pong, and Crafter tasks, where TransDreamerV3 demonstrated improved\nperformance over DreamerV3, particularly in the Atari-Freeway and Crafter\ntasks. While issues in the Minecraft task and limited training across all tasks\nwere noted, TransDreamerV3 displays advancement in world model-based\nreinforcement learning, leveraging transformer architectures.", "AI": {"tldr": "TransDreamerV3\u901a\u8fc7\u96c6\u6210Transformer\u7f16\u7801\u5668\u6539\u8fdb\u4e86DreamerV3\u67b6\u6784\uff0c\u63d0\u5347\u4e86\u590d\u6742\u73af\u5883\u4e2d\u7684\u8bb0\u5fc6\u4e0e\u51b3\u7b56\u80fd\u529b\u3002", "motivation": "\u63d0\u5347DreamerV3\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u8bb0\u5fc6\u548c\u51b3\u7b56\u65b9\u9762\u3002", "method": "\u5728DreamerV3\u57fa\u7840\u4e0a\u96c6\u6210Transformer\u7f16\u7801\u5668\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\uff08\u5982Atari\u548cCrafter\uff09\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5728Atari-Freeway\u548cCrafter\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8eDreamerV3\uff0c\u4f46\u5728Minecraft\u4efb\u52a1\u4e2d\u5b58\u5728\u4e0d\u8db3\u3002", "conclusion": "TransDreamerV3\u5c55\u793a\u4e86\u57fa\u4e8e\u4e16\u754c\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u7684\u8fdb\u6b65\uff0c\u5c24\u5176\u662f\u5728\u5229\u7528Transformer\u67b6\u6784\u65b9\u9762\u3002"}}
{"id": "2506.17128", "pdf": "https://arxiv.org/pdf/2506.17128", "abs": "https://arxiv.org/abs/2506.17128", "authors": ["Botao Zhu", "Xianbin Wang"], "title": "Rapid and Continuous Trust Evaluation for Effective Task Collaboration Through Siamese Model", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Trust is emerging as an effective tool to ensure the successful completion of\ncollaborative tasks within collaborative systems. However, rapidly and\ncontinuously evaluating the trustworthiness of collaborators during task\nexecution is a significant challenge due to distributed devices, complex\noperational environments, and dynamically changing resources. To tackle this\nchallenge, this paper proposes a Siamese-enabled rapid and continuous trust\nevaluation framework (SRCTE) to facilitate effective task collaboration. First,\nthe communication and computing resource attributes of the collaborator in a\ntrusted state, along with historical collaboration data, are collected and\nrepresented using an attributed control flow graph (ACFG) that captures\ntrust-related semantic information and serves as a reference for comparison\nwith data collected during task execution. At each time slot of task execution,\nthe collaborator's communication and computing resource attributes, as well as\ntask completion effectiveness, are collected in real time and represented with\nan ACFG to convey their trust-related semantic information. A Siamese model,\nconsisting of two shared-parameter Structure2vec networks, is then employed to\nlearn the deep semantics of each pair of ACFGs and generate their embeddings.\nFinally, the similarity between the embeddings of each pair of ACFGs is\ncalculated to determine the collaborator's trust value at each time slot. A\nreal system is built using two Dell EMC 5200 servers and a Google Pixel 8 to\ntest the effectiveness of the proposed SRCTE framework. Experimental results\ndemonstrate that SRCTE converges rapidly with only a small amount of data and\nachieves a high anomaly trust detection rate compared to the baseline\nalgorithm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSiamese\u6a21\u578b\u7684\u5feb\u901f\u8fde\u7eed\u4fe1\u4efb\u8bc4\u4f30\u6846\u67b6\uff08SRCTE\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u534f\u4f5c\u7cfb\u7edf\u4e2d\u52a8\u6001\u4fe1\u4efb\u8bc4\u4f30\u7684\u6311\u6218\u3002", "motivation": "\u5728\u534f\u4f5c\u7cfb\u7edf\u4e2d\uff0c\u5feb\u901f\u4e14\u6301\u7eed\u5730\u8bc4\u4f30\u5408\u4f5c\u8005\u7684\u4fe1\u4efb\u5ea6\u662f\u4e00\u4e2a\u91cd\u8981\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u5206\u5e03\u5f0f\u8bbe\u5907\u3001\u590d\u6742\u73af\u5883\u548c\u52a8\u6001\u8d44\u6e90\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u901a\u8fc7\u5c5e\u6027\u63a7\u5236\u6d41\u56fe\uff08ACFG\uff09\u8868\u793a\u5408\u4f5c\u8005\u7684\u8d44\u6e90\u5c5e\u6027\u548c\u5386\u53f2\u6570\u636e\uff0c\u5229\u7528Siamese\u6a21\u578b\u5b66\u4e60ACFG\u7684\u6df1\u5c42\u8bed\u4e49\u5e76\u751f\u6210\u5d4c\u5165\uff0c\u6700\u540e\u8ba1\u7b97\u76f8\u4f3c\u5ea6\u4ee5\u786e\u5b9a\u4fe1\u4efb\u503c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSRCTE\u4ec5\u9700\u5c11\u91cf\u6570\u636e\u5373\u53ef\u5feb\u901f\u6536\u655b\uff0c\u5e76\u5728\u5f02\u5e38\u4fe1\u4efb\u68c0\u6d4b\u7387\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u7b97\u6cd5\u3002", "conclusion": "SRCTE\u6846\u67b6\u4e3a\u534f\u4f5c\u7cfb\u7edf\u4e2d\u7684\u52a8\u6001\u4fe1\u4efb\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.17139", "pdf": "https://arxiv.org/pdf/2506.17139", "abs": "https://arxiv.org/abs/2506.17139", "authors": ["Michael Plainer", "Hao Wu", "Leon Klein", "Stephan G\u00fcnnemann", "Frank No\u00e9"], "title": "Consistent Sampling and Simulation: Molecular Dynamics with Energy-Based Diffusion Models", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "physics.comp-ph", "stat.ML"], "comment": null, "summary": "Diffusion models have recently gained significant attention due to their\neffectiveness in various scientific domains, including biochemistry. When\ntrained on equilibrium molecular distributions, diffusion models provide both:\na generative procedure to sample equilibrium conformations and associated\nforces derived from the model's scores. However, using the forces for\ncoarse-grained molecular dynamics simulations uncovers inconsistencies in the\nsamples generated via classical diffusion inference and simulation, despite\nboth originating from the same model. Particularly at the small diffusion\ntimesteps required for simulations, diffusion models fail to satisfy the\nFokker-Planck equation, which governs how the score should evolve over time. We\ninterpret this deviation as an indication of the observed inconsistencies and\npropose an energy-based diffusion model with a Fokker-Planck-derived\nregularization term enforcing consistency. We demonstrate the effectiveness of\nour approach on toy systems, alanine dipeptide, and introduce a\nstate-of-the-art transferable Boltzmann emulator for dipeptides that supports\nsimulation and demonstrates enhanced consistency and efficient sampling.", "AI": {"tldr": "\u6269\u6563\u6a21\u578b\u5728\u751f\u7269\u5316\u5b66\u7b49\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5c0f\u65f6\u95f4\u6b65\u957f\u4e0b\u4e0eFokker-Planck\u65b9\u7a0b\u4e0d\u4e00\u81f4\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u80fd\u91cf\u7684\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u6b63\u5219\u5316\u9879\u589e\u5f3a\u4e00\u81f4\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u7cfb\u7edf\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u751f\u6210\u5e73\u8861\u5206\u5b50\u6784\u8c61\u548c\u76f8\u5173\u529b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u7528\u4e8e\u7c97\u7c92\u5ea6\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u65f6\uff0c\u53d1\u73b0\u751f\u6210\u6837\u672c\u4e0e\u6a21\u62df\u7ed3\u679c\u4e0d\u4e00\u81f4\uff0c\u5c24\u5176\u662f\u5728\u5c0f\u65f6\u95f4\u6b65\u957f\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u80fd\u91cf\u7684\u6269\u6563\u6a21\u578b\uff0c\u5f15\u5165Fokker-Planck\u65b9\u7a0b\u884d\u751f\u7684\u6b63\u5219\u5316\u9879\uff0c\u4ee5\u5f3a\u5236\u6a21\u578b\u6ee1\u8db3\u4e00\u81f4\u6027\u8981\u6c42\u3002", "result": "\u5728\u73a9\u5177\u7cfb\u7edf\u3001\u4e19\u6c28\u9178\u4e8c\u80bd\u7b49\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u652f\u6301\u6a21\u62df\u7684\u5148\u8fdb\u53ef\u8f6c\u79fbBoltzmann\u6a21\u62df\u5668\u3002", "conclusion": "\u901a\u8fc7\u6b63\u5219\u5316\u9879\u6539\u8fdb\u7684\u6269\u6563\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u6837\u672c\u4e0e\u6a21\u62df\u7ed3\u679c\u7684\u4e00\u81f4\u6027\uff0c\u4e3a\u9ad8\u6548\u91c7\u6837\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2506.17155", "pdf": "https://arxiv.org/pdf/2506.17155", "abs": "https://arxiv.org/abs/2506.17155", "authors": ["Samin Yeasar Arnob", "Scott Fujimoto", "Doina Precup"], "title": "Sparse-Reg: Improving Sample Complexity in Offline Reinforcement Learning using Sparsity", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this paper, we investigate the use of small datasets in the context of\noffline reinforcement learning (RL). While many common offline RL benchmarks\nemploy datasets with over a million data points, many offline RL applications\nrely on considerably smaller datasets. We show that offline RL algorithms can\noverfit on small datasets, resulting in poor performance. To address this\nchallenge, we introduce \"Sparse-Reg\": a regularization technique based on\nsparsity to mitigate overfitting in offline reinforcement learning, enabling\neffective learning in limited data settings and outperforming state-of-the-art\nbaselines in continuous control.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5c0f\u6570\u636e\u96c6\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a00\u758f\u6027\u7684\u6b63\u5219\u5316\u65b9\u6cd5Sparse-Reg\uff0c\u4ee5\u89e3\u51b3\u8fc7\u62df\u5408\u95ee\u9898\u3002", "motivation": "\u8bb8\u591a\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4f9d\u8d56\u5c0f\u6570\u636e\u96c6\uff0c\u4f46\u73b0\u6709\u7b97\u6cd5\u5bb9\u6613\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u8fc7\u62df\u5408\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u5f15\u5165Sparse-Reg\uff0c\u4e00\u79cd\u57fa\u4e8e\u7a00\u758f\u6027\u7684\u6b63\u5219\u5316\u6280\u672f\uff0c\u7528\u4e8e\u7f13\u89e3\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8fc7\u62df\u5408\u95ee\u9898\u3002", "result": "Sparse-Reg\u5728\u6709\u9650\u6570\u636e\u8bbe\u7f6e\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Sparse-Reg\u80fd\u6709\u6548\u89e3\u51b3\u5c0f\u6570\u636e\u96c6\u4e2d\u7684\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u63d0\u5347\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\u3002"}}
{"id": "2506.17171", "pdf": "https://arxiv.org/pdf/2506.17171", "abs": "https://arxiv.org/abs/2506.17171", "authors": ["Vitalii Bondar", "Vira Babenko", "Roman Trembovetskyi", "Yurii Korobeinyk", "Viktoriya Dzyuba"], "title": "Deep generative models as the probability transformation functions", "categories": ["cs.LG", "68T07"], "comment": "12 pages, 6 figures, accepted for publication in \"ICIST 2025 Springer\n  Proceedings\"", "summary": "This paper introduces a unified theoretical perspective that views deep\ngenerative models as probability transformation functions. Despite the apparent\ndifferences in architecture and training methodologies among various types of\ngenerative models - autoencoders, autoregressive models, generative adversarial\nnetworks, normalizing flows, diffusion models, and flow matching - we\ndemonstrate that they all fundamentally operate by transforming simple\npredefined distributions into complex target data distributions. This unifying\nperspective facilitates the transfer of methodological improvements between\nmodel architectures and provides a foundation for developing universal\ntheoretical approaches, potentially leading to more efficient and effective\ngenerative modeling techniques.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u7406\u8bba\u89c6\u89d2\uff0c\u5c06\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u89c6\u4e3a\u6982\u7387\u53d8\u6362\u51fd\u6570\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u751f\u6210\u6a21\u578b\u4e4b\u95f4\u7684\u5171\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5404\u79cd\u751f\u6210\u6a21\u578b\u5728\u67b6\u6784\u548c\u8bad\u7ec3\u65b9\u6cd5\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u4f46\u5b83\u4eec\u7684\u6838\u5fc3\u76ee\u6807\u90fd\u662f\u901a\u8fc7\u53d8\u6362\u7b80\u5355\u5206\u5e03\u751f\u6210\u590d\u6742\u6570\u636e\u5206\u5e03\u3002\u8fd9\u79cd\u7edf\u4e00\u89c6\u89d2\u6709\u52a9\u4e8e\u65b9\u6cd5\u6539\u8fdb\u548c\u7406\u8bba\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u5c06\u591a\u79cd\u751f\u6210\u6a21\u578b\uff08\u5982\u81ea\u7f16\u7801\u5668\u3001\u81ea\u56de\u5f52\u6a21\u578b\u3001GAN\u3001\u5f52\u4e00\u5316\u6d41\u3001\u6269\u6563\u6a21\u578b\u7b49\uff09\u7edf\u4e00\u4e3a\u6982\u7387\u53d8\u6362\u51fd\u6570\u3002", "result": "\u63ed\u793a\u4e86\u4e0d\u540c\u751f\u6210\u6a21\u578b\u5728\u6982\u7387\u53d8\u6362\u4e0a\u7684\u5171\u540c\u672c\u8d28\uff0c\u4e3a\u65b9\u6cd5\u8fc1\u79fb\u548c\u7406\u8bba\u53d1\u5c55\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "conclusion": "\u7edf\u4e00\u89c6\u89d2\u6709\u671b\u63a8\u52a8\u751f\u6210\u6a21\u578b\u6280\u672f\u7684\u6548\u7387\u4e0e\u6548\u679c\u63d0\u5347\u3002"}}
{"id": "2506.17182", "pdf": "https://arxiv.org/pdf/2506.17182", "abs": "https://arxiv.org/abs/2506.17182", "authors": ["Yuli Slavutsky", "Ozgur Beker", "David Blei", "Bianca Dumitrascu"], "title": "Variational Learning of Disentangled Representations", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Disentangled representations enable models to separate factors of variation\nthat are shared across experimental conditions from those that are\ncondition-specific. This separation is essential in domains such as biomedical\ndata analysis, where generalization to new treatments, patients, or species\ndepends on isolating stable biological signals from context-dependent effects.\nWhile extensions of the variational autoencoder (VAE) framework have been\nproposed to address this problem, they frequently suffer from leakage between\nlatent representations, limiting their ability to generalize to unseen\nconditions. Here, we introduce DISCoVeR, a new variational framework that\nexplicitly separates condition-invariant and condition-specific factors.\nDISCoVeR integrates three key components: (i) a dual-latent architecture that\nmodels shared and specific factors separately; (ii) two parallel\nreconstructions that ensure both representations remain informative; and (iii)\na novel max-min objective that encourages clean separation without relying on\nhandcrafted priors, while making only minimal assumptions. Theoretically, we\nshow that this objective maximizes data likelihood while promoting\ndisentanglement, and that it admits a unique equilibrium. Empirically, we\ndemonstrate that DISCoVeR achieves improved disentanglement on synthetic\ndatasets, natural images, and single-cell RNA-seq data. Together, these results\nestablish DISCoVeR as a principled approach for learning disentangled\nrepresentations in multi-condition settings.", "AI": {"tldr": "DISCoVeR\u662f\u4e00\u79cd\u65b0\u7684\u53d8\u5206\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u6f5c\u5728\u67b6\u6784\u548c\u6700\u5927\u6700\u5c0f\u76ee\u6807\uff0c\u6709\u6548\u5206\u79bb\u6761\u4ef6\u4e0d\u53d8\u548c\u6761\u4ef6\u7279\u5b9a\u7684\u56e0\u7d20\uff0c\u63d0\u5347\u591a\u6761\u4ef6\u4e0b\u89e3\u8026\u8868\u793a\u7684\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u5728\u751f\u7269\u533b\u5b66\u6570\u636e\u5206\u6790\u7b49\u9886\u57df\uff0c\u9700\u8981\u5c06\u7a33\u5b9a\u4fe1\u53f7\u4e0e\u4e0a\u4e0b\u6587\u4f9d\u8d56\u6548\u5e94\u5206\u79bb\u4ee5\u63a8\u5e7f\u5230\u65b0\u6761\u4ef6\u3002\u73b0\u6709VAE\u6269\u5c55\u65b9\u6cd5\u5b58\u5728\u6f5c\u5728\u8868\u793a\u6cc4\u6f0f\u95ee\u9898\uff0c\u9650\u5236\u4e86\u6cdb\u5316\u80fd\u529b\u3002", "method": "DISCoVeR\u91c7\u7528\u53cc\u6f5c\u5728\u67b6\u6784\u5206\u522b\u5efa\u6a21\u5171\u4eab\u548c\u7279\u5b9a\u56e0\u7d20\uff0c\u5e76\u884c\u91cd\u5efa\u786e\u4fdd\u4fe1\u606f\u5b8c\u6574\u6027\uff0c\u5e76\u5f15\u5165\u6700\u5927\u6700\u5c0f\u76ee\u6807\u5b9e\u73b0\u5e72\u51c0\u5206\u79bb\u3002", "result": "DISCoVeR\u5728\u5408\u6210\u6570\u636e\u96c6\u3001\u81ea\u7136\u56fe\u50cf\u548c\u5355\u7ec6\u80deRNA-seq\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u66f4\u597d\u7684\u89e3\u8026\u6027\u80fd\u3002", "conclusion": "DISCoVeR\u4e3a\u591a\u6761\u4ef6\u4e0b\u5b66\u4e60\u89e3\u8026\u8868\u793a\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2506.17187", "pdf": "https://arxiv.org/pdf/2506.17187", "abs": "https://arxiv.org/abs/2506.17187", "authors": ["Kanumuri Nithin Varma", "Babak Hassibi"], "title": "Optimal Implicit Bias in Linear Regression", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Most modern learning problems are over-parameterized, where the number of\nlearnable parameters is much greater than the number of training data points.\nIn this over-parameterized regime, the training loss typically has infinitely\nmany global optima that completely interpolate the data with varying\ngeneralization performance. The particular global optimum we converge to\ndepends on the implicit bias of the optimization algorithm. The question we\naddress in this paper is, ``What is the implicit bias that leads to the best\ngeneralization performance?\". To find the optimal implicit bias, we provide a\nprecise asymptotic analysis of the generalization performance of interpolators\nobtained from the minimization of convex functions/potentials for\nover-parameterized linear regression with non-isotropic Gaussian data. In\nparticular, we obtain a tight lower bound on the best generalization error\npossible among this class of interpolators in terms of the\nover-parameterization ratio, the variance of the noise in the labels, the\neigenspectrum of the data covariance, and the underlying distribution of the\nparameter to be estimated. Finally, we find the optimal convex implicit bias\nthat achieves this lower bound under certain sufficient conditions involving\nthe log-concavity of the distribution of a Gaussian convolved with the prior of\nthe true underlying parameter.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u8fc7\u53c2\u6570\u5316\u5b66\u4e60\u95ee\u9898\u4e2d\u4f18\u5316\u7b97\u6cd5\u7684\u9690\u5f0f\u504f\u5dee\u5bf9\u6cdb\u5316\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u627e\u5230\u4e86\u6700\u4f18\u9690\u5f0f\u504f\u5dee\u3002", "motivation": "\u5728\u8fc7\u53c2\u6570\u5316\u5b66\u4e60\u4e2d\uff0c\u8bad\u7ec3\u635f\u5931\u901a\u5e38\u6709\u65e0\u9650\u591a\u5168\u5c40\u6700\u4f18\u89e3\uff0c\u4f46\u6cdb\u5316\u6027\u80fd\u5404\u5f02\u3002\u7814\u7a76\u76ee\u6807\u662f\u627e\u5230\u80fd\u5e26\u6765\u6700\u4f73\u6cdb\u5316\u6027\u80fd\u7684\u9690\u5f0f\u504f\u5dee\u3002", "method": "\u901a\u8fc7\u51f8\u51fd\u6570/\u52bf\u80fd\u7684\u6700\u5c0f\u5316\uff0c\u5bf9\u975e\u5404\u5411\u540c\u6027\u9ad8\u65af\u6570\u636e\u7684\u8fc7\u53c2\u6570\u5316\u7ebf\u6027\u56de\u5f52\u8fdb\u884c\u7cbe\u786e\u6e10\u8fd1\u5206\u6790\u3002", "result": "\u83b7\u5f97\u4e86\u8be5\u7c7b\u63d2\u503c\u5668\u7684\u6700\u4f73\u6cdb\u5316\u8bef\u5dee\u7684\u7d27\u4e0b\u754c\uff0c\u5e76\u627e\u5230\u4e86\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u8fbe\u5230\u8be5\u4e0b\u754c\u7684\u6700\u4f18\u51f8\u9690\u5f0f\u504f\u5dee\u3002", "conclusion": "\u7814\u7a76\u786e\u5b9a\u4e86\u6700\u4f18\u9690\u5f0f\u504f\u5dee\u7684\u6761\u4ef6\uff0c\u4e3a\u8fc7\u53c2\u6570\u5316\u5b66\u4e60\u4e2d\u7684\u6cdb\u5316\u6027\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2506.17204", "pdf": "https://arxiv.org/pdf/2506.17204", "abs": "https://arxiv.org/abs/2506.17204", "authors": ["Guozheng Ma", "Lu Li", "Zilin Wang", "Li Shen", "Pierre-Luc Bacon", "Dacheng Tao"], "title": "Network Sparsity Unlocks the Scaling Potential of Deep Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "Effectively scaling up deep reinforcement learning models has proven\nnotoriously difficult due to network pathologies during training, motivating\nvarious targeted interventions such as periodic reset and architectural\nadvances such as layer normalization. Instead of pursuing more complex\nmodifications, we show that introducing static network sparsity alone can\nunlock further scaling potential beyond their dense counterparts with\nstate-of-the-art architectures. This is achieved through simple one-shot random\npruning, where a predetermined percentage of network weights are randomly\nremoved once before training. Our analysis reveals that, in contrast to naively\nscaling up dense DRL networks, such sparse networks achieve both higher\nparameter efficiency for network expressivity and stronger resistance to\noptimization challenges like plasticity loss and gradient interference. We\nfurther extend our evaluation to visual and streaming RL scenarios,\ndemonstrating the consistent benefits of network sparsity.", "AI": {"tldr": "\u901a\u8fc7\u4e00\u6b21\u6027\u968f\u673a\u526a\u679d\u5f15\u5165\u9759\u6001\u7f51\u7edc\u7a00\u758f\u6027\uff0c\u53ef\u4ee5\u63d0\u5347\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u6269\u5c55\u6f5c\u529b\uff0c\u63d0\u9ad8\u53c2\u6570\u6548\u7387\u5e76\u589e\u5f3a\u5bf9\u4f18\u5316\u6311\u6218\u7684\u62b5\u6297\u80fd\u529b\u3002", "motivation": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u5728\u6269\u5c55\u65f6\u5bb9\u6613\u56e0\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u75c5\u6001\u95ee\u9898\u800c\u96be\u4ee5\u63d0\u5347\u6027\u80fd\uff0c\u9700\u8981\u590d\u6742\u7684\u5e72\u9884\u63aa\u65bd\u3002\u672c\u6587\u63a2\u7d22\u4e86\u901a\u8fc7\u7b80\u5355\u7a00\u758f\u5316\u65b9\u6cd5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e00\u6b21\u6027\u968f\u673a\u526a\u679d\u6280\u672f\uff0c\u5728\u8bad\u7ec3\u524d\u968f\u673a\u79fb\u9664\u4e00\u5b9a\u6bd4\u4f8b\u7684\u6743\u91cd\uff0c\u5f62\u6210\u7a00\u758f\u7f51\u7edc\u3002", "result": "\u7a00\u758f\u7f51\u7edc\u5728\u53c2\u6570\u6548\u7387\u548c\u4f18\u5316\u7a33\u5b9a\u6027\u4e0a\u4f18\u4e8e\u5bc6\u96c6\u7f51\u7edc\uff0c\u4e14\u5728\u89c6\u89c9\u548c\u6d41\u5f0f\u5f3a\u5316\u5b66\u4e60\u573a\u666f\u4e2d\u8868\u73b0\u4e00\u81f4\u3002", "conclusion": "\u9759\u6001\u7f51\u7edc\u7a00\u758f\u6027\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u7684\u6269\u5c55\u6f5c\u529b\u3002"}}
{"id": "2506.17211", "pdf": "https://arxiv.org/pdf/2506.17211", "abs": "https://arxiv.org/abs/2506.17211", "authors": ["Xuechen Zhang", "Zijian Huang", "Yingcong Li", "Chenshun Ni", "Jiasi Chen", "Samet Oymak"], "title": "BREAD: Branched Rollouts from Expert Anchors Bridge SFT & RL for Reasoning", "categories": ["cs.LG"], "comment": null, "summary": "Small language models (SLMs) struggle to learn complex reasoning behaviors,\nespecially when high-quality traces are scarce or difficult to learn from. The\nstandard training approach combines a supervised fine-tuning (SFT) stage, often\nto distill capabilities of a larger model, followed by a reinforcement learning\n(RL)stage such as Group Relative Policy Optimization (GRPO). In this paper, we\ninvestigate the fundamental limitations of this SFT + RL paradigm and propose\nmethods to overcome them. Under a suitable theoretical model, we demonstrate\nthat the SFT + RL strategy can fail completely when (1) the expert's traces are\ntoo difficult for the small model to express, or (2) the small model's\ninitialization has exponentially small likelihood of success. To address these,\nwe introduce BREAD: a GRPO variant that unifies the SFT and RL stages via\npartial expert guidance and branched rollouts. When self-generated traces fail,\nBREAD adaptively inserts short expert prefixes/hints, allowing the small model\nto complete the rest of the reasoning path, and ensuring that each update\nincludes at least one successful trace. This mechanism both densifies the\nreward signal and induces a natural learning curriculum. BREAD requires fewer\nthan 40% of ground-truth traces, consistently outperforming standard GRPO while\nspeeding up the training by about 3 times. Importantly, we demonstrate that\nBREAD helps the model solve problems that are otherwise unsolvable by the SFT +\nRL strategy, highlighting how branched rollouts and expert guidance can\nsubstantially boost SLM reasoning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faBREAD\u65b9\u6cd5\uff0c\u901a\u8fc7\u90e8\u5206\u4e13\u5bb6\u6307\u5bfc\u548c\u5206\u652f\u5c55\u5f00\uff0c\u89e3\u51b3\u4e86\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5b66\u4e60\u96be\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u5c0f\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u6216\u96be\u4ee5\u5b66\u4e60\u7684\u60c5\u51b5\u4e0b\u3002\u4f20\u7edf\u7684SFT + RL\u8bad\u7ec3\u8303\u5f0f\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\uff0c\u5bfc\u81f4\u6a21\u578b\u65e0\u6cd5\u8868\u8fbe\u4e13\u5bb6\u8f68\u8ff9\u6216\u521d\u59cb\u5316\u6210\u529f\u7387\u6781\u4f4e\u3002", "method": "\u63d0\u51faBREAD\u65b9\u6cd5\uff0c\u7ed3\u5408\u90e8\u5206\u4e13\u5bb6\u6307\u5bfc\u548c\u5206\u652f\u5c55\u5f00\uff0c\u52a8\u6001\u63d2\u5165\u4e13\u5bb6\u63d0\u793a\u4ee5\u5b8c\u6210\u63a8\u7406\u8def\u5f84\uff0c\u786e\u4fdd\u6bcf\u6b21\u66f4\u65b0\u81f3\u5c11\u5305\u542b\u4e00\u6761\u6210\u529f\u8f68\u8ff9\u3002", "result": "BREAD\u4ec5\u9700\u4e0d\u523040%\u7684\u771f\u5b9e\u8f68\u8ff9\uff0c\u6027\u80fd\u4f18\u4e8e\u6807\u51c6GRPO\uff0c\u8bad\u7ec3\u901f\u5ea6\u63d0\u5347\u7ea63\u500d\uff0c\u5e76\u80fd\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u89e3\u51b3\u7684\u95ee\u9898\u3002", "conclusion": "BREAD\u901a\u8fc7\u5206\u652f\u5c55\u5f00\u548c\u4e13\u5bb6\u6307\u5bfc\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5c0f\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3aSLM\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.17219", "pdf": "https://arxiv.org/pdf/2506.17219", "abs": "https://arxiv.org/abs/2506.17219", "authors": ["Yanzhi Zhang", "Zhaoxi Zhang", "Haoxiang Guan", "Yilin Cheng", "Yitong Duan", "Chen Wang", "Yue Wang", "Shuxin Zheng", "Jiyan He"], "title": "No Free Lunch: Rethinking Internal Feedback for LLM Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning has emerged as a powerful paradigm for post-training\nlarge language models (LLMs) to improve reasoning. Approaches like\nReinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning\nwith Verifiable Rewards (RLVR) have shown strong results, but they require\nextensive external supervision. We investigate an alternative class of methods,\nReinforcement Learning from Internal Feedback (RLIF), which relies solely on\nintrinsic model-derived signals instead of external rewards. In particular, we\nleverage unsupervised reward proxies such as token-level entropy,\ntrajectory-level entropy, and self-certainty. Our theoretical analysis shows\nthese internal objectives are partially equivalent, and we empirically evaluate\nvarious RLIF strategies on challenging math reasoning benchmarks. Experimental\nresults demonstrate that RLIF can boost the reasoning performance of base LLMs\nat the beginning phase of the training, matching or surpassing RLVR techniques\non these tasks. However, when training progresses, performance degrades even\nbelow the model before training. Moreover, we find that RLIF yields little\nimprovement for instruction-tuned models, indicating diminishing returns of\nintrinsic feedback once an LLM is already instruction-tuned. We further analyze\nthis limitation by mixing model weights and explain the reason of RLIF's\ntraining behaviors, providing practical guidelines for integrating internal\nfeedback signals into LLM training. We hope our analysis of internal feedback\nwill inform more principled and effective strategies for LLM post-training.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5185\u90e8\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08RLIF\uff09\uff0c\u7528\u4e8e\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u65e0\u9700\u5916\u90e8\u76d1\u7763\u3002\u5b9e\u9a8c\u8868\u660eRLIF\u5728\u8bad\u7ec3\u521d\u671f\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u968f\u7740\u8bad\u7ec3\u6df1\u5165\u6027\u80fd\u4e0b\u964d\uff0c\u4e14\u5bf9\u5df2\u6307\u4ee4\u8c03\u4f18\u7684\u6a21\u578b\u6548\u679c\u6709\u9650\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08\u5982RLHF\u548cRLVR\uff09\u4f9d\u8d56\u5916\u90e8\u76d1\u7763\uff0cRLIF\u65e8\u5728\u63a2\u7d22\u4ec5\u4f9d\u8d56\u6a21\u578b\u5185\u90e8\u4fe1\u53f7\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u65e0\u76d1\u7763\u5956\u52b1\u4ee3\u7406\uff08\u5982\u8bcd\u7ea7\u71b5\u3001\u8f68\u8ff9\u7ea7\u71b5\u548c\u81ea\u786e\u5b9a\u6027\uff09\u8bbe\u8ba1RLIF\u7b56\u7565\uff0c\u5e76\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u3002", "result": "RLIF\u5728\u8bad\u7ec3\u521d\u671f\u80fd\u5339\u914d\u6216\u8d85\u8d8aRLVR\uff0c\u4f46\u968f\u7740\u8bad\u7ec3\u6df1\u5165\u6027\u80fd\u4e0b\u964d\uff0c\u4e14\u5bf9\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u6548\u679c\u6709\u9650\u3002", "conclusion": "RLIF\u5728\u7279\u5b9a\u9636\u6bb5\u6709\u6548\uff0c\u4f46\u9700\u8c28\u614e\u4f7f\u7528\uff0c\u7814\u7a76\u4e3aLLM\u540e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u5185\u90e8\u53cd\u9988\u7684\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2506.15723", "pdf": "https://arxiv.org/pdf/2506.15723", "abs": "https://arxiv.org/abs/2506.15723", "authors": ["Irina G. Tanashkina", "Alexey S. Tanashkin", "Alexander S. Maksimchuik", "Anna Yu. Poshivailo"], "title": "Modern approaches to building effective interpretable models of the property market using machine learning", "categories": ["q-fin.ST", "cs.LG", "econ.GN", "q-fin.EC", "stat.AP"], "comment": "42 pages, 22 figures", "summary": "In this article, we review modern approaches to building interpretable models\nof property markets using machine learning on the base of mass valuation of\nproperty in the Primorye region, Russia. The researcher, lacking expertise in\nthis topic, encounters numerous difficulties in the effort to build a good\nmodel. The main source of this is the huge difference between noisy real market\ndata and ideal data which is very common in all types of tutorials on machine\nlearning. This paper covers all stages of modeling: the collection of initial\ndata, identification of outliers, the search and analysis of patterns in data,\nthe formation and final choice of price factors, the building of the model, and\nthe evaluation of its efficiency. For each stage, we highlight potential issues\nand describe sound methods for overcoming emerging difficulties on actual\nexamples. We show that the combination of classical linear regression with\ninterpolation methods of geostatistics allows to build an effective model for\nland parcels. For flats, when many objects are attributed to one spatial point\nthe application of geostatistical methods is difficult. Therefore we suggest\nlinear regression with automatic generation and selection of additional rules\non the base of decision trees, so called the RuleFit method. Thus we show, that\ndespite the strong restriction as the requirement of interpretability which is\nimportant in practical aspects, for example, legal matters, it is still\npossible to build effective models of real property markets.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e86\u5229\u7528\u673a\u5668\u5b66\u4e60\u6784\u5efa\u623f\u4ea7\u5e02\u573a\u53ef\u89e3\u91ca\u6a21\u578b\u7684\u73b0\u4ee3\u65b9\u6cd5\uff0c\u57fa\u4e8e\u4fc4\u7f57\u65af\u6ee8\u6d77\u8fb9\u7586\u533a\u7684\u5927\u89c4\u6a21\u623f\u4ea7\u4f30\u503c\u6570\u636e\u3002\u7814\u7a76\u8005\u901a\u8fc7\u7ed3\u5408\u7ecf\u5178\u7ebf\u6027\u56de\u5f52\u4e0e\u5730\u7edf\u8ba1\u5b66\u63d2\u503c\u65b9\u6cd5\uff0c\u6210\u529f\u6784\u5efa\u4e86\u6709\u6548\u7684\u571f\u5730\u6a21\u578b\uff1b\u5bf9\u4e8e\u516c\u5bd3\uff0c\u5219\u91c7\u7528RuleFit\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u8005\u7f3a\u4e4f\u76f8\u5173\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4e14\u771f\u5b9e\u5e02\u573a\u6570\u636e\u4e0e\u7406\u60f3\u6570\u636e\u5dee\u5f02\u5de8\u5927\uff0c\u5bfc\u81f4\u5efa\u6a21\u56f0\u96be\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u6784\u5efa\u53ef\u89e3\u91ca\u4e14\u6709\u6548\u7684\u623f\u4ea7\u5e02\u573a\u6a21\u578b\u3002", "method": "1. \u6570\u636e\u6536\u96c6\u4e0e\u5f02\u5e38\u503c\u8bc6\u522b\uff1b2. \u6570\u636e\u6a21\u5f0f\u5206\u6790\u4e0e\u4ef7\u683c\u56e0\u7d20\u9009\u62e9\uff1b3. \u6a21\u578b\u6784\u5efa\uff08\u571f\u5730\uff1a\u7ebf\u6027\u56de\u5f52+\u5730\u7edf\u8ba1\u5b66\uff1b\u516c\u5bd3\uff1aRuleFit\u65b9\u6cd5\uff09\uff1b4. \u6a21\u578b\u6548\u7387\u8bc4\u4f30\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u9002\u7528\u4e8e\u571f\u5730\u548c\u516c\u5bd3\u7684\u6709\u6548\u6a21\u578b\uff0c\u6ee1\u8db3\u4e86\u53ef\u89e3\u91ca\u6027\u7684\u8981\u6c42\u3002", "conclusion": "\u5373\u4f7f\u5728\u53ef\u89e3\u91ca\u6027\u8981\u6c42\u4e25\u683c\u7684\u6761\u4ef6\u4e0b\uff0c\u4ecd\u80fd\u6784\u5efa\u6709\u6548\u7684\u623f\u4ea7\u5e02\u573a\u6a21\u578b\u3002"}}
{"id": "2506.15732", "pdf": "https://arxiv.org/pdf/2506.15732", "abs": "https://arxiv.org/abs/2506.15732", "authors": ["Khurram Yamin", "Gaurav Ghosal", "Bryan Wilder"], "title": "LLMs Struggle to Perform Counterfactual Reasoning with Parametric Knowledge", "categories": ["cs.AI", "cs.LG"], "comment": "ICML 2025 Workshop on Scaling up Intervention Models", "summary": "Large Language Models have been shown to contain extensive world knowledge in\ntheir parameters, enabling impressive performance on many knowledge intensive\ntasks. However, when deployed in novel settings, LLMs often encounter\nsituations where they must integrate parametric knowledge with new or\nunfamiliar information. In this work, we explore whether LLMs can combine\nknowledge in-context with their parametric knowledge through the lens of\ncounterfactual reasoning. Through synthetic and real experiments in multi-hop\nreasoning problems, we show that LLMs generally struggle with counterfactual\nreasoning, often resorting to exclusively using their parametric knowledge.\nMoreover, we show that simple post-hoc finetuning can struggle to instill\ncounterfactual reasoning ability -- often leading to degradation in stored\nparametric knowledge. Ultimately, our work reveals important limitations of\ncurrent LLM's abilities to re-purpose parametric knowledge in novel settings.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6574\u5408\u53c2\u6570\u77e5\u8bc6\u4e0e\u65b0\u4fe1\u606f\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u5c24\u5176\u5728\u53cd\u4e8b\u5b9e\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u63a2\u7d22LLM\u662f\u5426\u80fd\u591f\u901a\u8fc7\u4e0a\u4e0b\u6587\u77e5\u8bc6\u7ed3\u5408\u5176\u53c2\u6570\u77e5\u8bc6\uff0c\u7279\u522b\u662f\u5728\u53cd\u4e8b\u5b9e\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u5408\u6210\u548c\u771f\u5b9e\u5b9e\u9a8c\uff0c\u5728\u591a\u8df3\u63a8\u7406\u95ee\u9898\u4e2d\u6d4b\u8bd5LLM\u7684\u53cd\u4e8b\u5b9e\u63a8\u7406\u80fd\u529b\u3002", "result": "LLM\u5728\u53cd\u4e8b\u5b9e\u63a8\u7406\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u503e\u5411\u4e8e\u4f9d\u8d56\u53c2\u6570\u77e5\u8bc6\uff0c\u4e14\u5fae\u8c03\u53ef\u80fd\u5bfc\u81f4\u53c2\u6570\u77e5\u8bc6\u9000\u5316\u3002", "conclusion": "\u5f53\u524dLLM\u5728\u91cd\u65b0\u5229\u7528\u53c2\u6570\u77e5\u8bc6\u4e8e\u65b0\u573a\u666f\u4e2d\u5b58\u5728\u91cd\u8981\u5c40\u9650\u6027\u3002"}}
{"id": "2506.15733", "pdf": "https://arxiv.org/pdf/2506.15733", "abs": "https://arxiv.org/abs/2506.15733", "authors": ["Mert Cemri", "Nived Rajaraman", "Rishabh Tiwari", "Xiaoxuan Liu", "Kurt Keutzer", "Ion Stoica", "Kannan Ramchandran", "Ahmad Beirami", "Ziteng Sun"], "title": "$\\texttt{SPECS}$: Faster Test-Time Scaling through Speculative Drafts", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "28 pages, 6 figures, 2 tables", "summary": "Scaling test-time compute has driven the recent advances in the reasoning\ncapabilities of large language models (LLMs), typically by allocating\nadditional computation for more thorough exploration. However, increased\ncompute often comes at the expense of higher user-facing latency, directly\nimpacting user experience. Current test-time scaling methods primarily optimize\nfor accuracy based on total compute resources (FLOPS), often overlooking\nlatency constraints. To address this gap, we propose $\\texttt{SPECS}$, a\nlatency-aware test-time scaling method inspired by speculative decoding.\n$\\texttt{SPECS}$~uses a smaller, faster model to generate candidate sequences\nefficiently, and evaluates these candidates using signals from both a larger\ntarget model and a dedicated reward model. We introduce new integration\nstrategies, including reward-guided soft verification and a reward-based\ndeferral mechanism. Empirical results on MATH500, AMC23 and OlympiadBench\ndatasets show that $\\texttt{SPECS}$~matches or surpasses beam search accuracy\nwhile reducing latency by up to $\\sim$19.1\\%. Our theoretical analysis shows\nthat our algorithm converges to the solution of a KL-regularized reinforcement\nlearning objective with increasing beam width.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPECS\u7684\u5ef6\u8fdf\u611f\u77e5\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u5c0f\u6a21\u578b\u751f\u6210\u5019\u9009\u5e8f\u5217\u548c\u5927\u6a21\u578b\u8bc4\u4f30\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\u5e76\u4fdd\u6301\u4e86\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u8ba1\u7b97\u8d44\u6e90\u4f18\u5316\uff0c\u5ffd\u7565\u4e86\u7528\u6237\u5ef6\u8fdf\u95ee\u9898\uff0cSPECS\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "SPECS\u5229\u7528\u5c0f\u6a21\u578b\u9ad8\u6548\u751f\u6210\u5019\u9009\u5e8f\u5217\uff0c\u7ed3\u5408\u5927\u6a21\u578b\u548c\u5956\u52b1\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u5f15\u5165\u5956\u52b1\u5f15\u5bfc\u7684\u8f6f\u9a8c\u8bc1\u548c\u5ef6\u8fdf\u673a\u5236\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cSPECS\u5728\u4fdd\u6301\u6216\u8d85\u8d8a\u675f\u641c\u7d22\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u5ef6\u8fdf\u964d\u4f4e\u4e86\u7ea619.1%\u3002", "conclusion": "SPECS\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5ef6\u8fdf\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u6709\u6548\u5e73\u8861\u3002"}}
{"id": "2506.15734", "pdf": "https://arxiv.org/pdf/2506.15734", "abs": "https://arxiv.org/abs/2506.15734", "authors": ["Peiyuan Tang", "Haojie Xin", "Xiaodong Zhang", "Jun Sun", "Qin Xia", "Zijiang Yang"], "title": "The Safety Reminder: A Soft Prompt to Reactivate Delayed Safety Awareness in Vision-Language Models", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.CV", "cs.LG"], "comment": "23 pages, 10 figures", "summary": "As Vision-Language Models (VLMs) demonstrate increasing capabilities across\nreal-world applications such as code generation and chatbot assistance,\nensuring their safety has become paramount. Unlike traditional Large Language\nModels (LLMs), VLMs face unique vulnerabilities due to their multimodal nature,\nallowing adversaries to modify visual or textual inputs to bypass safety\nguardrails and trigger the generation of harmful content. Through systematic\nanalysis of VLM behavior under attack, we identify a novel phenomenon termed\n``delayed safety awareness''. Specifically, we observe that safety-aligned VLMs\nmay initially be compromised to produce harmful content, but eventually\nrecognize the associated risks and attempt to self-correct. This pattern\nsuggests that VLMs retain their underlying safety awareness but experience a\ntemporal delay in their activation. Building on this insight, we hypothesize\nthat VLMs' safety awareness can be proactively reactivated through carefully\ndesigned prompts. To this end, we introduce ``The Safety Reminder'', a soft\nprompt tuning approach that optimizes learnable prompt tokens, which are\nperiodically injected during the text generation process to enhance safety\nawareness, effectively preventing harmful content generation. Additionally, our\nsafety reminder only activates when harmful content is detected, leaving normal\nconversations unaffected and preserving the model's performance on benign\ntasks. Through comprehensive evaluation across three established safety\nbenchmarks and one adversarial attacks, we demonstrate that our approach\nsignificantly reduces attack success rates while maintaining model utility,\noffering a practical solution for deploying safer VLMs in real-world\napplications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u5b89\u5168\u6027\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u201c\u5ef6\u8fdf\u5b89\u5168\u610f\u8bc6\u201d\u73b0\u8c61\uff0c\u5e76\u8bbe\u8ba1\u201c\u5b89\u5168\u63d0\u9192\u201d\u673a\u5236\uff0c\u6709\u6548\u51cf\u5c11\u6709\u5bb3\u5185\u5bb9\u751f\u6210\u3002", "motivation": "\u968f\u7740\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u5728\u4ee3\u7801\u751f\u6210\u548c\u804a\u5929\u673a\u5668\u4eba\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u80fd\u529b\u589e\u5f3a\uff0c\u5176\u5b89\u5168\u6027\u95ee\u9898\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002VLM\u56e0\u5176\u591a\u6a21\u6001\u7279\u6027\u9762\u4e34\u72ec\u7279\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u80fd\u901a\u8fc7\u4fee\u6539\u89c6\u89c9\u6216\u6587\u672c\u8f93\u5165\u7ed5\u8fc7\u5b89\u5168\u9632\u62a4\uff0c\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5206\u6790VLM\u5728\u653b\u51fb\u4e0b\u7684\u884c\u4e3a\uff0c\u53d1\u73b0\u201c\u5ef6\u8fdf\u5b89\u5168\u610f\u8bc6\u201d\u73b0\u8c61\uff0c\u5e76\u63d0\u51fa\u201c\u5b89\u5168\u63d0\u9192\u201d\u65b9\u6cd5\uff0c\u5373\u901a\u8fc7\u4f18\u5316\u53ef\u5b66\u4e60\u7684\u63d0\u793a\u4ee4\u724c\uff0c\u5728\u6587\u672c\u751f\u6210\u8fc7\u7a0b\u4e2d\u5b9a\u671f\u6ce8\u5165\u4ee5\u589e\u5f3a\u5b89\u5168\u610f\u8bc6\u3002", "result": "\u5728\u4e09\u4e2a\u5b89\u5168\u57fa\u51c6\u548c\u4e00\u4e2a\u5bf9\u6297\u653b\u51fb\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u5728\u826f\u6027\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "\u201c\u5b89\u5168\u63d0\u9192\u201d\u673a\u5236\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u90e8\u7f72\u66f4\u5b89\u5168\u7684VLM\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u65e2\u80fd\u9632\u6b62\u6709\u5bb3\u5185\u5bb9\u751f\u6210\uff0c\u53c8\u4e0d\u5f71\u54cd\u6b63\u5e38\u5bf9\u8bdd\u3002"}}
{"id": "2506.15735", "pdf": "https://arxiv.org/pdf/2506.15735", "abs": "https://arxiv.org/abs/2506.15735", "authors": ["Robert Graham", "Edward Stevinson", "Leo Richter", "Alexander Chia", "Joseph Miller", "Joseph Isaac Bloom"], "title": "ContextBench: Modifying Contexts for Targeted Latent Activation", "categories": ["cs.AI", "cs.LG", "stat.ML"], "comment": null, "summary": "Identifying inputs that trigger specific behaviours or latent features in\nlanguage models could have a wide range of safety use cases. We investigate a\nclass of methods capable of generating targeted, linguistically fluent inputs\nthat activate specific latent features or elicit model behaviours. We formalise\nthis approach as context modification and present ContextBench -- a benchmark\nwith tasks assessing core method capabilities and potential safety\napplications. Our evaluation framework measures both elicitation strength\n(activation of latent features or behaviours) and linguistic fluency,\nhighlighting how current state-of-the-art methods struggle to balance these\nobjectives. We enhance Evolutionary Prompt Optimisation (EPO) with\nLLM-assistance and diffusion model inpainting, and demonstrate that these\nvariants achieve state-of-the-art performance in balancing elicitation\neffectiveness and fluency.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u4e0a\u4e0b\u6587\u4fee\u6539\u751f\u6210\u9488\u5bf9\u6027\u8f93\u5165\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u6fc0\u6d3b\u8bed\u8a00\u6a21\u578b\u7684\u7279\u5b9a\u884c\u4e3a\u6216\u7279\u5f81\uff0c\u5e76\u5f00\u53d1\u4e86ContextBench\u8bc4\u4f30\u6846\u67b6\u3002\u6539\u8fdb\u7684EPO\u65b9\u6cd5\u5728\u6548\u679c\u548c\u6d41\u7545\u6027\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u8bc6\u522b\u89e6\u53d1\u8bed\u8a00\u6a21\u578b\u7279\u5b9a\u884c\u4e3a\u6216\u7279\u5f81\u7684\u8f93\u5165\u5bf9\u5b89\u5168\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u63d0\u51fa\u4e0a\u4e0b\u6587\u4fee\u6539\u65b9\u6cd5\uff0c\u5f00\u53d1ContextBench\u8bc4\u4f30\u6846\u67b6\uff0c\u6539\u8fdbEPO\u65b9\u6cd5\uff08\u7ed3\u5408LLM\u8f85\u52a9\u548c\u6269\u6563\u6a21\u578b\u4fee\u590d\uff09\u3002", "result": "\u6539\u8fdb\u7684EPO\u65b9\u6cd5\u5728\u6fc0\u6d3b\u6548\u679c\u548c\u8f93\u5165\u6d41\u7545\u6027\u4e0a\u8fbe\u5230\u6700\u4f18\u3002", "conclusion": "\u7ed3\u5408LLM\u8f85\u52a9\u548c\u6269\u6563\u6a21\u578b\u7684EPO\u65b9\u6cd5\u5728\u5e73\u8861\u6fc0\u6d3b\u6548\u679c\u4e0e\u6d41\u7545\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.15740", "pdf": "https://arxiv.org/pdf/2506.15740", "abs": "https://arxiv.org/abs/2506.15740", "authors": ["Jonathan Kutasov", "Yuqi Sun", "Paul Colognese", "Teun van der Weij", "Linda Petrini", "Chen Bo Calvin Zhang", "John Hughes", "Xiang Deng", "Henry Sleight", "Tyler Tracy", "Buck Shlegeris", "Joe Benton"], "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "categories": ["cs.AI", "cs.CR", "cs.LG"], "comment": null, "summary": "As Large Language Models (LLMs) are increasingly deployed as autonomous\nagents in complex and long horizon settings, it is critical to evaluate their\nability to sabotage users by pursuing hidden objectives. We study the ability\nof frontier LLMs to evade monitoring and achieve harmful hidden goals while\ncompleting a wide array of realistic tasks. We evaluate a broad range of\nfrontier LLMs using SHADE (Subtle Harmful Agent Detection & Evaluation)-Arena,\nthe first highly diverse agent evaluation dataset for sabotage and monitoring\ncapabilities of LLM agents. SHADE-Arena consists of complex pairs of benign\nmain tasks and harmful side objectives in complicated environments. Agents are\nevaluated on their ability to complete the side task without appearing\nsuspicious to an LLM monitor. When measuring agent ability to (a) complete the\nmain task, (b) complete the side task, and (c) avoid detection, we find that\nthe best performing frontier models score 27% (Claude 3.7 Sonnet) and 15%\n(Gemini 2.5 Pro) as sabotage agents when overseen by Claude 3.6 Sonnet. For\ncurrent frontier models, success on the side task relies heavily on having\naccess to a hidden scratchpad that is not visible to the monitor. We also use\nSHADE-Arena to measure models' monitoring abilities, with the top monitor\n(Gemini 2.5 Pro) achieving an AUC of 0.87 at distinguishing benign and malign\ntranscripts. We find that for now, models still struggle at sabotage due to\nfailures in long-context main task execution. However, our measurements already\ndemonstrate the difficulty of monitoring for subtle sabotage attempts, which we\nexpect to only increase in the face of more complex and longer-horizon tasks.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u9690\u85cf\u6709\u5bb3\u76ee\u6807\u7684\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86SHADE-Arena\u8bc4\u4f30\u6570\u636e\u96c6\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u524d\u6a21\u578b\u5728\u7834\u574f\u4efb\u52a1\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u4f46\u76d1\u63a7\u96be\u5ea6\u5df2\u663e\u73b0\u3002", "motivation": "\u968f\u7740LLMs\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u4f5c\u4e3a\u81ea\u4e3b\u4ee3\u7406\u7684\u90e8\u7f72\u589e\u591a\uff0c\u8bc4\u4f30\u5176\u9690\u85cf\u6709\u5bb3\u76ee\u6807\u7684\u80fd\u529b\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528SHADE-Arena\u6570\u636e\u96c6\u8bc4\u4f30LLMs\u5728\u5b8c\u6210\u4e3b\u4efb\u52a1\u7684\u540c\u65f6\u9690\u85cf\u6709\u5bb3\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u5e76\u6d4b\u8bd5\u5176\u76d1\u63a7\u80fd\u529b\u3002", "result": "\u6700\u4f73\u6a21\u578b\u5728\u7834\u574f\u4efb\u52a1\u4e2d\u5f97\u520627%\uff08Claude 3.7 Sonnet\uff09\u548c15%\uff08Gemini 2.5 Pro\uff09\uff0c\u76d1\u63a7\u6a21\u578bAUC\u4e3a0.87\u3002", "conclusion": "\u5f53\u524d\u6a21\u578b\u5728\u7834\u574f\u4efb\u52a1\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u4f46\u76d1\u63a7\u96be\u5ea6\u5df2\u663e\u73b0\uff0c\u672a\u6765\u4efb\u52a1\u590d\u6742\u6027\u589e\u52a0\u65f6\u6311\u6218\u4f1a\u66f4\u5927\u3002"}}
{"id": "2506.15743", "pdf": "https://arxiv.org/pdf/2506.15743", "abs": "https://arxiv.org/abs/2506.15743", "authors": ["Tobias Grafke"], "title": "Sampling conditioned diffusions via Pathspace Projected Monte Carlo", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST", "stat.TH"], "comment": null, "summary": "We present an algorithm to sample stochastic differential equations\nconditioned on rather general constraints, including integral constraints,\nendpoint constraints, and stochastic integral constraints. The algorithm is a\npathspace Metropolis-adjusted manifold sampling scheme, which samples\nstochastic paths on the submanifold of realizations that adhere to the\nconditioning constraint. We demonstrate the effectiveness of the algorithm by\nsampling a dynamical condensation phase transition, conditioning a random walk\non a fixed Levy stochastic area, conditioning a stochastic nonlinear wave\nequation on high amplitude waves, and sampling a stochastic partial\ndifferential equation model of turbulent pipe flow conditioned on\nrelaminarization events.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u6ee1\u8db3\u4e00\u822c\u7ea6\u675f\u6761\u4ef6\u4e0b\u91c7\u6837\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff0c\u5305\u62ec\u79ef\u5206\u7ea6\u675f\u3001\u7aef\u70b9\u7ea6\u675f\u548c\u968f\u673a\u79ef\u5206\u7ea6\u675f\u3002", "motivation": "\u89e3\u51b3\u5728\u590d\u6742\u7ea6\u675f\u6761\u4ef6\u4e0b\u91c7\u6837\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7684\u6311\u6218\uff0c\u6269\u5c55\u91c7\u6837\u65b9\u6cd5\u7684\u9002\u7528\u6027\u3002", "method": "\u91c7\u7528\u8def\u5f84\u7a7a\u95f4Metropolis\u8c03\u6574\u6d41\u5f62\u91c7\u6837\u65b9\u6848\uff0c\u5728\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6\u7684\u5b50\u6d41\u5f62\u4e0a\u91c7\u6837\u968f\u673a\u8def\u5f84\u3002", "result": "\u7b97\u6cd5\u6210\u529f\u5e94\u7528\u4e8e\u591a\u79cd\u573a\u666f\uff0c\u5982\u52a8\u6001\u51dd\u805a\u76f8\u53d8\u3001\u56fa\u5b9aLevy\u968f\u673a\u9762\u79ef\u7ea6\u675f\u7684\u968f\u673a\u6e38\u8d70\u3001\u9ad8\u632f\u5e45\u6ce2\u7ea6\u675f\u7684\u968f\u673a\u975e\u7ebf\u6027\u6ce2\u52a8\u65b9\u7a0b\u4ee5\u53ca\u6e4d\u6d41\u7ba1\u6d41\u6a21\u578b\u7684\u6761\u4ef6\u91c7\u6837\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u5728\u590d\u6742\u7ea6\u675f\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u548c\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u4e3a\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u7684\u91c7\u6837\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2506.15744", "pdf": "https://arxiv.org/pdf/2506.15744", "abs": "https://arxiv.org/abs/2506.15744", "authors": ["Seyed Mohsen Hosseini"], "title": "Pixel-wise Modulated Dice Loss for Medical Image Segmentation", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Class imbalance and the difficulty imbalance are the two types of data\nimbalance that affect the performance of neural networks in medical\nsegmentation tasks. In class imbalance the loss is dominated by the majority\nclasses and in difficulty imbalance the loss is dominated by easy to classify\npixels. This leads to an ineffective training. Dice loss, which is based on a\ngeometrical metric, is very effective in addressing the class imbalance\ncompared to the cross entropy (CE) loss, which is adopted directly from\nclassification tasks. To address the difficulty imbalance, the common approach\nis employing a re-weighted CE loss or a modified Dice loss to focus the\ntraining on difficult to classify areas. The existing modification methods are\ncomputationally costly and with limited success. In this study we propose a\nsimple modification to the Dice loss with minimal computational cost. With a\npixel level modulating term, we take advantage of the effectiveness of Dice\nloss in handling the class imbalance to also handle the difficulty imbalance.\nResults on three commonly used medical segmentation tasks show that the\nproposed Pixel-wise Modulated Dice loss (PM Dice loss) outperforms other\nmethods, which are designed to tackle the difficulty imbalance problem.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86PM Dice loss\uff0c\u901a\u8fc7\u50cf\u7d20\u7ea7\u8c03\u5236\u9879\u6539\u8fdbDice loss\uff0c\u4ee5\u540c\u65f6\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u96be\u5ea6\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5728\u533b\u5b66\u5206\u5272\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u96be\u5ea6\u4e0d\u5e73\u8861\u4f1a\u5f71\u54cd\u795e\u7ecf\u7f51\u7edc\u5728\u533b\u5b66\u5206\u5272\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u6548\u679c\u6709\u9650\u3002", "method": "\u63d0\u51faPixel-wise Modulated Dice loss\uff08PM Dice loss\uff09\uff0c\u901a\u8fc7\u50cf\u7d20\u7ea7\u8c03\u5236\u9879\u6539\u8fdbDice loss\uff0c\u4ee5\u4f4e\u8ba1\u7b97\u6210\u672c\u89e3\u51b3\u96be\u5ea6\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "\u5728\u4e09\u79cd\u5e38\u7528\u533b\u5b66\u5206\u5272\u4efb\u52a1\u4e2d\uff0cPM Dice loss\u4f18\u4e8e\u5176\u4ed6\u9488\u5bf9\u96be\u5ea6\u4e0d\u5e73\u8861\u7684\u65b9\u6cd5\u3002", "conclusion": "PM Dice loss\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u6539\u8fdb\u65b9\u6cd5\uff0c\u80fd\u540c\u65f6\u5904\u7406\u7c7b\u522b\u548c\u96be\u5ea6\u4e0d\u5e73\u8861\u95ee\u9898\u3002"}}
{"id": "2506.15751", "pdf": "https://arxiv.org/pdf/2506.15751", "abs": "https://arxiv.org/abs/2506.15751", "authors": ["Kartik Sharma", "Yiqiao Jin", "Vineeth Rakesh", "Yingtong Dou", "Menghai Pan", "Mahashweta Das", "Srijan Kumar"], "title": "Sysformer: Safeguarding Frozen Large Language Models with Adaptive System Prompts", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "As large language models (LLMs) are deployed in safety-critical settings, it\nis essential to ensure that their responses comply with safety standards. Prior\nresearch has revealed that LLMs often fail to grasp the notion of safe\nbehaviors, resulting in either unjustified refusals to harmless prompts or the\ngeneration of harmful content. While substantial efforts have been made to\nimprove their robustness, existing defenses often rely on costly fine-tuning of\nmodel parameters or employ suboptimal heuristic techniques. In this work, we\ntake a novel approach to safeguard LLMs by learning to adapt the system prompts\nin instruction-tuned LLMs. While LLMs are typically pre-trained to follow a\nfixed system prompt, we investigate the impact of tailoring the system prompt\nto each specific user input on the safety of the responses. To this end, we\npropose $\\textbf{Sysformer}$, a trans$\\textbf{former}$ model that updates an\ninitial $\\textbf{sys}$tem prompt to a more robust system prompt in the LLM\ninput embedding space while attending to the user prompt. While keeping the LLM\nparameters frozen, the Sysformer is trained to refuse to respond to a set of\nharmful prompts while responding ideally to a set of safe ones. Through\nextensive experiments on $5$ LLMs from different families and $2$ recent\nbenchmarks, we demonstrate that Sysformer can significantly enhance the\nrobustness of LLMs, leading to upto $80\\%$ gain in the refusal rate on harmful\nprompts while enhancing the compliance with the safe prompts by upto $90\\%$.\nResults also generalize well to sophisticated jailbreaking attacks, making LLMs\nupto $100\\%$ more robust against different attack strategies. We hope our\nfindings lead to cheaper safeguarding of LLMs and motivate future\ninvestigations into designing variable system prompts.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSysformer\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u7cfb\u7edf\u63d0\u793a\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5b89\u5168\u6027\uff0c\u907f\u514d\u5bf9\u6709\u5bb3\u63d0\u793a\u7684\u54cd\u5e94\uff0c\u540c\u65f6\u4f18\u5316\u5bf9\u5b89\u5168\u63d0\u793a\u7684\u54cd\u5e94\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u7684\u5fae\u8c03\u6216\u542f\u53d1\u5f0f\u6280\u672f\uff0c\u96be\u4ee5\u6709\u6548\u786e\u4fddLLMs\u7684\u5b89\u5168\u6027\u3002", "method": "\u63d0\u51faSysformer\u6a21\u578b\uff0c\u5728LLM\u8f93\u5165\u5d4c\u5165\u7a7a\u95f4\u4e2d\u52a8\u6001\u66f4\u65b0\u7cfb\u7edf\u63d0\u793a\uff0c\u4fdd\u6301LLM\u53c2\u6570\u4e0d\u53d8\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSysformer\u663e\u8457\u63d0\u5347\u4e86LLMs\u7684\u5b89\u5168\u6027\uff0c\u5bf9\u6709\u5bb3\u63d0\u793a\u7684\u62d2\u7edd\u7387\u63d0\u9ad8\u4e8680%\uff0c\u5bf9\u5b89\u5168\u63d0\u793a\u7684\u54cd\u5e94\u7387\u63d0\u9ad8\u4e8690%\u3002", "conclusion": "Sysformer\u63d0\u4f9b\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u4e14\u9ad8\u6548\u7684LLM\u5b89\u5168\u4fdd\u969c\u65b9\u6cd5\uff0c\u5e76\u63a8\u52a8\u4e86\u53ef\u53d8\u7cfb\u7edf\u63d0\u793a\u8bbe\u8ba1\u7684\u7814\u7a76\u3002"}}
{"id": "2506.15753", "pdf": "https://arxiv.org/pdf/2506.15753", "abs": "https://arxiv.org/abs/2506.15753", "authors": ["Oluwaseyi Giwa", "Muhammad Ahmed Mohsin", "Muhammad Ali Jamshed"], "title": "Quantum Fisher-Preconditioned Reinforcement Learning: From Single-Qubit Control to Rayleigh-Fading Link Adaptation", "categories": ["quant-ph", "cs.LG", "cs.SY", "eess.SY"], "comment": "5 pages, 3 figures, submitted to IEEE Communications Letters", "summary": "In this letter, we propose Quantum-Preconditioned Policy Gradient (QPPG), a\nnatural gradient-based algorithm for link adaptation that whitens policy\nupdates using the full inverse quantum Fisher information with Tikhonov\nregularization. QPPG bridges classical and quantum geometry, achieving stable\nlearning even under noise. Evaluated on classical and quantum environments,\nincluding noisy single-qubit Gym tasks and Rayleigh-fading channels, QPPG\nconverges 4 times faster than REINFORCE and sustains a 1 dB gain under\nuncertainty. It reaches a 90 percent return in one hundred episodes with high\nnoise robustness, showcasing the advantages of full QFI-based preconditioning\nfor scalable quantum reinforcement learning.", "AI": {"tldr": "QPPG\u662f\u4e00\u79cd\u57fa\u4e8e\u81ea\u7136\u68af\u5ea6\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u91cf\u5b50Fisher\u4fe1\u606f\u9884\u6761\u4ef6\u5316\u7b56\u7565\u66f4\u65b0\uff0c\u5728\u566a\u58f0\u73af\u5883\u4e0b\u5b9e\u73b0\u7a33\u5b9a\u5b66\u4e60\uff0c\u6536\u655b\u901f\u5ea6\u6bd4REINFORCE\u5feb4\u500d\u3002", "motivation": "\u89e3\u51b3\u91cf\u5b50\u5f3a\u5316\u5b66\u4e60\u4e2d\u566a\u58f0\u73af\u5883\u4e0b\u7684\u5b66\u4e60\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u5e76\u63d0\u5347\u6536\u655b\u901f\u5ea6\u3002", "method": "\u5229\u7528\u5168\u9006\u91cf\u5b50Fisher\u4fe1\u606f\u4e0eTikhonov\u6b63\u5219\u5316\u8fdb\u884c\u7b56\u7565\u66f4\u65b0\u7684\u9884\u6761\u4ef6\u5316\uff0c\u7ed3\u5408\u7ecf\u5178\u4e0e\u91cf\u5b50\u51e0\u4f55\u3002", "result": "\u5728\u7ecf\u5178\u548c\u91cf\u5b50\u73af\u5883\u4e2d\uff0cQPPG\u6536\u655b\u901f\u5ea6\u5feb4\u500d\uff0c\u566a\u58f0\u4e0b\u4fdd\u63011 dB\u589e\u76ca\uff0c100\u6b21\u8fed\u4ee3\u5185\u8fbe\u523090%\u56de\u62a5\u3002", "conclusion": "QPPG\u5c55\u793a\u4e86\u57fa\u4e8e\u91cf\u5b50Fisher\u4fe1\u606f\u7684\u9884\u6761\u4ef6\u5316\u5728\u53ef\u6269\u5c55\u91cf\u5b50\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4f18\u52bf\u3002"}}
{"id": "2506.15756", "pdf": "https://arxiv.org/pdf/2506.15756", "abs": "https://arxiv.org/abs/2506.15756", "authors": ["Jo\u00e3o G. Ribeiro", "Yaniv Oren", "Alberto Sardinha", "Matthijs Spaan", "Francisco S. Melo"], "title": "RecBayes: Recurrent Bayesian Ad Hoc Teamwork in Large Partially Observable Domains", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper proposes RecBayes, a novel approach for ad hoc teamwork under\npartial observability, a setting where agents are deployed on-the-fly to\nenvironments where pre-existing teams operate, that never requires, at any\nstage, access to the states of the environment or the actions of its teammates.\nWe show that by relying on a recurrent Bayesian classifier trained using past\nexperiences, an ad hoc agent is effectively able to identify known teams and\ntasks being performed from observations alone. Unlike recent approaches such as\nPO-GPL (Gu et al., 2021) and FEAT (Rahman et al., 2023), that require at some\nstage fully observable states of the environment, actions of teammates, or\nboth, or approaches such as ATPO (Ribeiro et al., 2023) that require the\nenvironments to be small enough to be tabularly modelled (Ribeiro et al.,\n2023), in their work up to 4.8K states and 1.7K observations, we show RecBayes\nis both able to handle arbitrarily large spaces while never relying on either\nstates and teammates' actions. Our results in benchmark domains from the\nmulti-agent systems literature, adapted for partial observability and scaled up\nto 1M states and 2^125 observations, show that RecBayes is effective at\nidentifying known teams and tasks being performed from partial observations\nalone, and as a result, is able to assist the teams in solving the tasks\neffectively.", "AI": {"tldr": "RecBayes\u662f\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u5b9e\u73b0\u5373\u65f6\u56e2\u961f\u534f\u4f5c\uff0c\u65e0\u9700\u4f9d\u8d56\u73af\u5883\u72b6\u6001\u6216\u961f\u53cb\u52a8\u4f5c\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\uff08\u5982PO-GPL\u3001FEAT\u3001ATPO\uff09\u9700\u8981\u5b8c\u5168\u53ef\u89c2\u6d4b\u72b6\u6001\u6216\u961f\u53cb\u52a8\u4f5c\u7684\u5c40\u9650\u6027\uff0c\u6216\u4ec5\u9002\u7528\u4e8e\u5c0f\u89c4\u6a21\u73af\u5883\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u8fc7\u53bb\u7ecf\u9a8c\u7684\u5faa\u73af\u8d1d\u53f6\u65af\u5206\u7c7b\u5668\uff0c\u4ec5\u901a\u8fc7\u89c2\u6d4b\u8bc6\u522b\u5df2\u77e5\u56e2\u961f\u548c\u4efb\u52a1\u3002", "result": "\u5728\u6269\u5c55\u52301M\u72b6\u6001\u548c2^125\u89c2\u6d4b\u7684\u5927\u89c4\u6a21\u73af\u5883\u4e2d\uff0cRecBayes\u80fd\u6709\u6548\u8bc6\u522b\u56e2\u961f\u548c\u4efb\u52a1\uff0c\u5e76\u534f\u52a9\u5b8c\u6210\u4efb\u52a1\u3002", "conclusion": "RecBayes\u5728\u65e0\u9700\u73af\u5883\u72b6\u6001\u6216\u961f\u53cb\u52a8\u4f5c\u7684\u60c5\u51b5\u4e0b\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u7684\u5373\u65f6\u56e2\u961f\u534f\u4f5c\u95ee\u9898\u3002"}}
{"id": "2506.15760", "pdf": "https://arxiv.org/pdf/2506.15760", "abs": "https://arxiv.org/abs/2506.15760", "authors": ["Shuangbao Paul Wang", "Jianzhou Mao", "Eric Sakk"], "title": "Compilation, Optimization, Error Mitigation, and Machine Learning in Quantum Algorithms", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "This paper discusses the compilation, optimization, and error mitigation of\nquantum algorithms, essential steps to execute real-world quantum algorithms.\nQuantum algorithms running on a hybrid platform with QPU and CPU/GPU take\nadvantage of existing high-performance computing power with quantum-enabled\nexponential speedups. The proposed approximate quantum Fourier transform (AQFT)\nfor quantum algorithm optimization improves the circuit execution on top of an\nexponential speed-ups the quantum Fourier transform has provided.", "AI": {"tldr": "\u8bba\u6587\u8ba8\u8bba\u4e86\u91cf\u5b50\u7b97\u6cd5\u7684\u7f16\u8bd1\u3001\u4f18\u5316\u548c\u9519\u8bef\u7f13\u89e3\uff0c\u8fd9\u4e9b\u662f\u5b9e\u73b0\u5b9e\u9645\u91cf\u5b50\u7b97\u6cd5\u7684\u5173\u952e\u6b65\u9aa4\u3002\u901a\u8fc7\u7ed3\u5408QPU\u548cCPU/GPU\u7684\u6df7\u5408\u5e73\u53f0\uff0c\u91cf\u5b50\u7b97\u6cd5\u80fd\u591f\u5229\u7528\u9ad8\u6027\u80fd\u8ba1\u7b97\u80fd\u529b\u5b9e\u73b0\u6307\u6570\u7ea7\u52a0\u901f\u3002\u63d0\u51fa\u7684\u8fd1\u4f3c\u91cf\u5b50\u5085\u91cc\u53f6\u53d8\u6362\uff08AQFT\uff09\u8fdb\u4e00\u6b65\u4f18\u5316\u4e86\u7535\u8def\u6267\u884c\u6027\u80fd\u3002", "motivation": "\u91cf\u5b50\u7b97\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u9ad8\u6548\u7684\u7f16\u8bd1\u3001\u4f18\u5316\u548c\u9519\u8bef\u7f13\u89e3\u6280\u672f\uff0c\u4ee5\u5145\u5206\u53d1\u6325\u5176\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8fd1\u4f3c\u91cf\u5b50\u5085\u91cc\u53f6\u53d8\u6362\uff08AQFT\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u91cf\u5b50\u7b97\u6cd5\u7684\u7535\u8def\u6267\u884c\u3002", "result": "AQFT\u5728\u91cf\u5b50\u5085\u91cc\u53f6\u53d8\u6362\u63d0\u4f9b\u7684\u6307\u6570\u7ea7\u52a0\u901f\u57fa\u7840\u4e0a\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u7535\u8def\u6267\u884c\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u6df7\u5408\u5e73\u53f0\u548cAQFT\u65b9\u6cd5\uff0c\u91cf\u5b50\u7b97\u6cd5\u7684\u5b9e\u9645\u6267\u884c\u6027\u80fd\u5f97\u5230\u4e86\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2506.15762", "pdf": "https://arxiv.org/pdf/2506.15762", "abs": "https://arxiv.org/abs/2506.15762", "authors": ["Tom Hendriks", "Gerrit Arends", "Edwin Versteeg", "Anna Vilanova", "Maxime Chamberland", "Chantal M. W. Tax"], "title": "Implicit neural representations for accurate estimation of the standard model of white matter", "categories": ["eess.IV", "cs.LG", "physics.med-ph"], "comment": "27 pages, 12 figures", "summary": "Diffusion magnetic resonance imaging (dMRI) enables non-invasive\ninvestigation of tissue microstructure. The Standard Model (SM) of white matter\naims to disentangle dMRI signal contributions from intra- and extra-axonal\nwater compartments. However, due to the model its high-dimensional nature,\nextensive acquisition protocols with multiple b-values and diffusion tensor\nshapes are typically required to mitigate parameter degeneracies. Even then,\naccurate estimation remains challenging due to noise. This work introduces a\nnovel estimation framework based on implicit neural representations (INRs),\nwhich incorporate spatial regularization through the sinusoidal encoding of the\ninput coordinates. The INR method is evaluated on both synthetic and in vivo\ndatasets and compared to parameter estimates using cubic polynomials,\nsupervised neural networks, and nonlinear least squares. Results demonstrate\nsuperior accuracy of the INR method in estimating SM parameters, particularly\nin low signal-to-noise conditions. Additionally, spatial upsampling of the INR\ncan represent the underlying dataset anatomically plausibly in a continuous\nway, which is unattainable with linear or cubic interpolation. The INR is fully\nunsupervised, eliminating the need for labeled training data. It achieves fast\ninference ($\\sim$6 minutes), is robust to both Gaussian and Rician noise,\nsupports joint estimation of SM kernel parameters and the fiber orientation\ndistribution function with spherical harmonics orders up to at least 8 and\nnon-negativity constraints, and accommodates spatially varying acquisition\nprotocols caused by magnetic gradient non-uniformities. The combination of\nthese properties along with the possibility to easily adapt the framework to\nother dMRI models, positions INRs as a potentially important tool for analyzing\nand interpreting diffusion MRI data.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff08INR\uff09\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u4f30\u8ba1\u767d\u8d28\u6807\u51c6\u6a21\u578b\uff08SM\uff09\u53c2\u6570\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u7684\u51c6\u786e\u6027\uff0c\u5e76\u652f\u6301\u7a7a\u95f4\u4e0a\u91c7\u6837\u548c\u65e0\u76d1\u7763\u5b66\u4e60\u3002", "motivation": "\u767d\u8d28\u6807\u51c6\u6a21\u578b\uff08SM\uff09\u7684\u9ad8\u7ef4\u7279\u6027\u5bfc\u81f4\u53c2\u6570\u4f30\u8ba1\u56f0\u96be\uff0c\u9700\u8981\u590d\u6742\u7684\u6570\u636e\u91c7\u96c6\u534f\u8bae\u3002\u566a\u58f0\u95ee\u9898\u8fdb\u4e00\u6b65\u52a0\u5267\u4e86\u51c6\u786e\u4f30\u8ba1\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff08INR\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f93\u5165\u5750\u6807\u7684\u6b63\u5f26\u7f16\u7801\u5b9e\u73b0\u7a7a\u95f4\u6b63\u5219\u5316\uff0c\u5e76\u4e0e\u7acb\u65b9\u591a\u9879\u5f0f\u3001\u76d1\u7763\u795e\u7ecf\u7f51\u7edc\u548c\u975e\u7ebf\u6027\u6700\u5c0f\u4e8c\u4e58\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "INR\u65b9\u6cd5\u5728\u4f30\u8ba1SM\u53c2\u6570\u65f6\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\uff0c\u5e76\u652f\u6301\u7a7a\u95f4\u8fde\u7eed\u8868\u793a\u3002", "conclusion": "INR\u6846\u67b6\u4e3a\u5206\u6790\u548c\u89e3\u91ca\u6269\u6563MRI\u6570\u636e\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\uff0c\u5177\u6709\u5feb\u901f\u63a8\u7406\u3001\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u5f3a\u7684\u7279\u70b9\u3002"}}
{"id": "2506.15766", "pdf": "https://arxiv.org/pdf/2506.15766", "abs": "https://arxiv.org/abs/2506.15766", "authors": ["Seung-Joo Lee", "Andre Lukas"], "title": "Approximate Ricci-flat Metrics for Calabi-Yau Manifolds", "categories": ["hep-th", "cs.LG", "math.DG"], "comment": "15 pages, 6 figures", "summary": "We outline a method to determine analytic K\\\"ahler potentials with associated\napproximately Ricci-flat K\\\"ahler metrics on Calabi-Yau manifolds. Key\ningredients are numerically calculating Ricci-flat K\\\"ahler potentials via\nmachine learning techniques and fitting the numerical results to Donaldson's\nAnsatz. We apply this method to the Dwork family of quintic hypersurfaces in\n$\\mathbb{P}^4$ and an analogous one-parameter family of bi-cubic CY\nhypersurfaces in $\\mathbb{P}^2\\times\\mathbb{P}^2$. In each case, a relatively\nsimple analytic expression is obtained for the approximately Ricci-flat\nK\\\"ahler potentials, including the explicit dependence on the complex structure\nparameter. We find that these K\\\"ahler potentials only depend on the modulus of\nthe complex structure parameter.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u6280\u672f\u6570\u503c\u8ba1\u7b97Ricci-flat K\u00e4hler\u52bf\u5e76\u7ed3\u5408Donaldson\u7684Ansatz\u62df\u5408\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u786e\u5b9aCalabi-Yau\u6d41\u5f62\u4e0a\u7684\u89e3\u6790K\u00e4hler\u52bf\u53ca\u5176\u8fd1\u4f3cRicci-flat K\u00e4hler\u5ea6\u91cf\u3002", "motivation": "\u7814\u7a76Calabi-Yau\u6d41\u5f62\u4e0a\u7684Ricci-flat K\u00e4hler\u5ea6\u91cf\u53ca\u5176\u89e3\u6790K\u00e4hler\u52bf\uff0c\u4e3a\u76f8\u5173\u6570\u5b66\u548c\u7269\u7406\u95ee\u9898\u63d0\u4f9b\u5de5\u5177\u3002", "method": "\u5229\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u6570\u503c\u8ba1\u7b97Ricci-flat K\u00e4hler\u52bf\uff0c\u5e76\u901a\u8fc7Donaldson\u7684Ansatz\u62df\u5408\u6570\u503c\u7ed3\u679c\u3002", "result": "\u5728Dwork\u5bb6\u65cf\u7684\u4e94\u6b21\u8d85\u66f2\u9762\u548c\u53cc\u4e09\u6b21CY\u8d85\u66f2\u9762\u4e2d\uff0c\u5f97\u5230\u4e86\u7b80\u5355\u7684\u89e3\u6790K\u00e4hler\u52bf\u8868\u8fbe\u5f0f\uff0c\u4e14\u4ec5\u4f9d\u8d56\u4e8e\u590d\u7ed3\u6784\u53c2\u6570\u7684\u6a21\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u83b7\u5f97\u4e86\u8fd1\u4f3cRicci-flat K\u00e4hler\u52bf\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2506.15771", "pdf": "https://arxiv.org/pdf/2506.15771", "abs": "https://arxiv.org/abs/2506.15771", "authors": ["Robert Kent", "Benjamin Lienhard", "Gregory Lafyatis", "Daniel J. Gauthier"], "title": "Superconducting Qubit Readout Using Next-Generation Reservoir Computing", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Quantum processors require rapid and high-fidelity simultaneous measurements\nof many qubits. While superconducting qubits are among the leading modalities\ntoward a useful quantum processor, their readout remains a bottleneck.\nTraditional approaches to processing measurement data often struggle to account\nfor crosstalk present in frequency-multiplexed readout, the preferred method to\nreduce the resource overhead. Recent approaches to address this challenge use\nneural networks to improve the state-discrimination fidelity. However, they are\ncomputationally expensive to train and evaluate, resulting in increased latency\nand poor scalability as the number of qubits increases. We present an\nalternative machine learning approach based on next-generation reservoir\ncomputing that constructs polynomial features from the measurement signals and\nmaps them to the corresponding qubit states. This method is highly\nparallelizable, avoids the costly nonlinear activation functions common in\nneural networks, and supports real-time training, enabling fast evaluation,\nadaptability, and scalability. Despite its lower computational complexity, our\nreservoir approach is able to maintain high qubit-state-discrimination\nfidelity. Relative to traditional methods, our approach achieves error\nreductions of up to 50% and 11% on single- and five-qubit datasets,\nrespectively, and delivers up to 2.5x crosstalk reduction on the five-qubit\ndataset. Compared with recent machine-learning methods, evaluating our model\nrequires 100x fewer multiplications for single-qubit and 2.5x fewer for\nfive-qubit models. This work demonstrates that reservoir computing can enhance\nqubit-state discrimination while maintaining scalability for future quantum\nprocessors.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0b\u4e00\u4ee3\u50a8\u5c42\u8ba1\u7b97\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u9ad8\u91cf\u5b50\u6bd4\u7279\u72b6\u6001\u8bc6\u522b\u7684\u6548\u7387\u548c\u4fdd\u771f\u5ea6\uff0c\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u6027\u548c\u4e32\u6270\u3002", "motivation": "\u8d85\u5bfc\u91cf\u5b50\u6bd4\u7279\u7684\u8bfb\u51fa\u662f\u91cf\u5b50\u5904\u7406\u5668\u7684\u74f6\u9888\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u9891\u7387\u590d\u7528\u8bfb\u51fa\u4e2d\u7684\u4e32\u6270\u95ee\u9898\uff0c\u800c\u73b0\u6709\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u6269\u5c55\u6027\u5dee\u3002", "method": "\u91c7\u7528\u50a8\u5c42\u8ba1\u7b97\u6280\u672f\uff0c\u901a\u8fc7\u6784\u5efa\u6d4b\u91cf\u4fe1\u53f7\u7684\u591a\u9879\u5f0f\u7279\u5f81\u5e76\u5c06\u5176\u6620\u5c04\u5230\u5bf9\u5e94\u7684\u91cf\u5b50\u6bd4\u7279\u72b6\u6001\uff0c\u907f\u514d\u4e86\u795e\u7ecf\u7f51\u7edc\u4e2d\u6602\u8d35\u7684\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\u3002", "result": "\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff0c\u5355\u91cf\u5b50\u6bd4\u7279\u548c\u4e94\u91cf\u5b50\u6bd4\u7279\u6570\u636e\u96c6\u7684\u9519\u8bef\u7387\u5206\u522b\u964d\u4f4e\u4e8650%\u548c11%\uff0c\u4e32\u6270\u51cf\u5c11\u4e862.5\u500d\uff1b\u4e0e\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8ba1\u7b97\u91cf\u663e\u8457\u51cf\u5c11\u3002", "conclusion": "\u50a8\u5c42\u8ba1\u7b97\u80fd\u591f\u5728\u4fdd\u6301\u9ad8\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\u63d0\u5347\u91cf\u5b50\u6bd4\u7279\u72b6\u6001\u8bc6\u522b\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u672a\u6765\u91cf\u5b50\u5904\u7406\u5668\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.15782", "pdf": "https://arxiv.org/pdf/2506.15782", "abs": "https://arxiv.org/abs/2506.15782", "authors": ["Nicolas Boull\u00e9", "Matthew J. Colbrook", "Gustav Conradie"], "title": "Convergent Methods for Koopman Operators on Reproducing Kernel Hilbert Spaces", "categories": ["math.NA", "cs.LG", "cs.NA", "math.DS", "math.SP", "stat.ML", "37A30, 37M10, 37N10, 47A10, 47B32, 47B33, 65P99"], "comment": null, "summary": "Data-driven spectral analysis of Koopman operators is a powerful tool for\nunderstanding numerous real-world dynamical systems, from neuronal activity to\nvariations in sea surface temperature. The Koopman operator acts on a function\nspace and is most commonly studied on the space of square-integrable functions.\nHowever, defining it on a suitable reproducing kernel Hilbert space (RKHS)\noffers numerous practical advantages, including pointwise predictions with\nerror bounds, improved spectral properties that facilitate computations, and\nmore efficient algorithms, particularly in high dimensions. We introduce the\nfirst general, provably convergent, data-driven algorithms for computing\nspectral properties of Koopman and Perron--Frobenius operators on RKHSs. These\nmethods efficiently compute spectra and pseudospectra with error control and\nspectral measures while exploiting the RKHS structure to avoid the large-data\nlimits required in the $L^2$ settings. The function space is determined by a\nuser-specified kernel, eliminating the need for quadrature-based sampling as in\n$L^2$ and enabling greater flexibility with finite, externally provided\ndatasets. Using the Solvability Complexity Index hierarchy, we construct\nadversarial dynamical systems for these problems to show that no algorithm can\nsucceed in fewer limits, thereby proving the optimality of our algorithms.\nNotably, this impossibility extends to randomized algorithms and datasets. We\ndemonstrate the effectiveness of our algorithms on challenging,\nhigh-dimensional datasets arising from real-world measurements and\nhigh-fidelity numerical simulations, including turbulent channel flow,\nmolecular dynamics of a binding protein, Antarctic sea ice concentration, and\nNorthern Hemisphere sea surface height. The algorithms are publicly available\nin the software package $\\texttt{SpecRKHS}$.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eRKHS\u7684\u6570\u636e\u9a71\u52a8\u7b97\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97Koopman\u548cPerron-Frobenius\u7b97\u5b50\u7684\u8c31\u6027\u8d28\uff0c\u5177\u6709\u6536\u655b\u6027\u548c\u9ad8\u6548\u6027\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u6570\u636e\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728L2\u7a7a\u95f4\u4e2d\u8ba1\u7b97Koopman\u7b97\u5b50\u7684\u8c31\u6027\u8d28\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982\u9700\u8981\u5927\u91cf\u6570\u636e\u548c\u57fa\u4e8e\u79ef\u5206\u7684\u91c7\u6837\u3002\u901a\u8fc7\u5b9a\u4e49\u5728RKHS\u4e0a\uff0c\u53ef\u4ee5\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u63d0\u4f9b\u66f4\u7075\u6d3b\u548c\u9ad8\u6548\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8eRKHS\u7684\u901a\u7528\u7b97\u6cd5\uff0c\u8ba1\u7b97\u8c31\u548c\u4f2a\u8c31\uff0c\u5e76\u5229\u7528RKHS\u7ed3\u6784\u907f\u514d\u5927\u6570\u636e\u9650\u5236\u3002\u7b97\u6cd5\u901a\u8fc7\u7528\u6237\u6307\u5b9a\u7684\u6838\u51fd\u6570\u786e\u5b9a\u51fd\u6570\u7a7a\u95f4\uff0c\u65e0\u9700\u79ef\u5206\u91c7\u6837\u3002", "result": "\u7b97\u6cd5\u5728\u591a\u4e2a\u9ad8\u7ef4\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5305\u62ec\u6e4d\u6d41\u901a\u9053\u6d41\u3001\u5206\u5b50\u52a8\u529b\u5b66\u548c\u6c14\u5019\u6570\u636e\u3002\u901a\u8fc7Solvability Complexity Index\u8bc1\u660e\u4e86\u7b97\u6cd5\u7684\u4f18\u5316\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\uff0c\u4e3a\u52a8\u6001\u7cfb\u7edf\u7684\u8c31\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u5de5\u5177\u3002"}}
{"id": "2506.15786", "pdf": "https://arxiv.org/pdf/2506.15786", "abs": "https://arxiv.org/abs/2506.15786", "authors": ["Peter Yichen Chen", "Minghao Guo", "Hanspeter Pfister", "Ming Lin", "William Freeman", "Qixing Huang", "Han-Wei Shen", "Wojciech Matusik"], "title": "Graphics4Science: Computer Graphics for Scientific Impacts", "categories": ["cs.GR", "cs.AI", "cs.LG", "physics.comp-ph", "physics.optics"], "comment": null, "summary": "Computer graphics, often associated with films, games, and visual effects,\nhas long been a powerful tool for addressing scientific challenges--from its\norigins in 3D visualization for medical imaging to its role in modern\ncomputational modeling and simulation. This course explores the deep and\nevolving relationship between computer graphics and science, highlighting past\nachievements, ongoing contributions, and open questions that remain. We show\nhow core methods, such as geometric reasoning and physical modeling, provide\ninductive biases that help address challenges in both fields, especially in\ndata-scarce settings. To that end, we aim to reframe graphics as a modeling\nlanguage for science by bridging vocabulary gaps between the two communities.\nDesigned for both newcomers and experts, Graphics4Science invites the graphics\ncommunity to engage with science, tackle high-impact problems where graphics\nexpertise can make a difference, and contribute to the future of scientific\ndiscovery. Additional details are available on the course website:\nhttps://graphics4science.github.io", "AI": {"tldr": "\u8be5\u8bfe\u7a0b\u63a2\u8ba8\u8ba1\u7b97\u673a\u56fe\u5f62\u5b66\u4e0e\u79d1\u5b66\u4e4b\u95f4\u7684\u6df1\u5c42\u5173\u7cfb\uff0c\u5f3a\u8c03\u5176\u4f5c\u4e3a\u79d1\u5b66\u5efa\u6a21\u8bed\u8a00\u7684\u4f5c\u7528\uff0c\u5e76\u9f13\u52b1\u56fe\u5f62\u5b66\u793e\u533a\u53c2\u4e0e\u89e3\u51b3\u79d1\u5b66\u95ee\u9898\u3002", "motivation": "\u8ba1\u7b97\u673a\u56fe\u5f62\u5b66\u5728\u79d1\u5b66\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u4e24\u4e2a\u9886\u57df\u4e4b\u95f4\u5b58\u5728\u8bcd\u6c47\u9e3f\u6c9f\uff0c\u9700\u8981\u91cd\u65b0\u5b9a\u4e49\u56fe\u5f62\u5b66\u4f5c\u4e3a\u79d1\u5b66\u7684\u5efa\u6a21\u8bed\u8a00\u3002", "method": "\u8bfe\u7a0b\u901a\u8fc7\u51e0\u4f55\u63a8\u7406\u548c\u7269\u7406\u5efa\u6a21\u7b49\u6838\u5fc3\u65b9\u6cd5\uff0c\u4e3a\u6570\u636e\u7a00\u7f3a\u73af\u5883\u4e0b\u7684\u79d1\u5b66\u95ee\u9898\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u8bfe\u7a0b\u5c55\u793a\u4e86\u56fe\u5f62\u5b66\u5728\u79d1\u5b66\u4e2d\u7684\u6210\u5c31\u548c\u8d21\u732e\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "Graphics4Science\u65e8\u5728\u4fc3\u8fdb\u56fe\u5f62\u5b66\u4e0e\u79d1\u5b66\u7684\u5408\u4f5c\uff0c\u63a8\u52a8\u79d1\u5b66\u53d1\u73b0\u7684\u672a\u6765\u53d1\u5c55\u3002"}}
{"id": "2506.15787", "pdf": "https://arxiv.org/pdf/2506.15787", "abs": "https://arxiv.org/abs/2506.15787", "authors": ["Lukas Helff", "Ahmad Omar", "Felix Friedrich", "Wolfgang Stammer", "Antonia W\u00fcst", "Tim Woydt", "Rupert Mitchell", "Patrick Schramowski", "Kristian Kersting"], "title": "SLR: An Automated Synthesis Framework for Scalable Logical Reasoning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "We introduce SLR, an end-to-end framework for systematic evaluation and\ntraining of Large Language Models (LLMs) via Scalable Logical Reasoning. Given\na user's task specification, SLR enables scalable, automated synthesis of\ninductive reasoning tasks with precisely controlled difficulty. For each task,\nSLR synthesizes (i) a latent ground-truth rule, (ii) an executable validation\nprogram used by a symbolic judge to deterministically verify model outputs, and\n(iii) an instruction prompt for the reasoning task. Using SLR, we create\nSLR-Bench, a benchmark comprising over 19k prompts spanning 20 curriculum\nlevels that progressively increase in relational, arithmetic, and recursive\ncomplexity. Large-scale evaluation reveals that contemporary LLMs readily\nproduce syntactically valid rules, yet often fail at correct logical inference.\nRecent reasoning LLMs do somewhat better, but incur substantial increases in\ntest-time compute, sometimes exceeding 15k completion tokens. Finally,\nlogic-tuning via SLR doubles Llama-3-8B accuracy on SLR-Bench, achieving parity\nwith Gemini-Flash-Thinking at a fraction of computational cost. SLR is fully\nautomated, requires no human annotation, ensures dataset novelty, and offers a\nscalable environment for probing and advancing LLMs' reasoning capabilities.", "AI": {"tldr": "SLR\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u7528\u4e8e\u901a\u8fc7\u53ef\u6269\u5c55\u7684\u903b\u8f91\u63a8\u7406\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u548c\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3002\u5b83\u80fd\u591f\u81ea\u52a8\u751f\u6210\u5177\u6709\u7cbe\u786e\u96be\u5ea6\u63a7\u5236\u7684\u5f52\u7eb3\u63a8\u7406\u4efb\u52a1\uff0c\u5e76\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b19k\u63d0\u793a\u7684\u57fa\u51c6\uff08SLR-Bench\uff09\u3002", "motivation": "\u5f53\u524dLLMs\u5728\u903b\u8f91\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u6d4b\u8bd5\u8ba1\u7b97\u6210\u672c\u9ad8\u3002SLR\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u81ea\u52a8\u5316\u3001\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684\u73af\u5883\uff0c\u4ee5\u63d0\u5347LLMs\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "SLR\u901a\u8fc7\u5408\u6210\u6f5c\u5728\u7684\u771f\u5b9e\u89c4\u5219\u3001\u53ef\u6267\u884c\u7684\u9a8c\u8bc1\u7a0b\u5e8f\u548c\u4efb\u52a1\u63d0\u793a\uff0c\u521b\u5efaSLR-Bench\u57fa\u51c6\uff0c\u5e76\u5229\u7528\u7b26\u53f7\u5224\u65ad\u5668\u9a8c\u8bc1\u6a21\u578b\u8f93\u51fa\u3002", "result": "\u5f53\u4ee3LLMs\u5728\u903b\u8f91\u63a8\u7406\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u903b\u8f91\u8c03\u4f18\u540e\u7684Llama-3-8B\u5728SLR-Bench\u4e0a\u51c6\u786e\u7387\u7ffb\u500d\uff0c\u8fbe\u5230\u4e0eGemini-Flash-Thinking\u76f8\u5f53\u7684\u6c34\u5e73\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u66f4\u4f4e\u3002", "conclusion": "SLR\u4e3aLLMs\u7684\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u81ea\u52a8\u5316\u7684\u8bc4\u4f30\u548c\u8bad\u7ec3\u73af\u5883\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2506.15791", "pdf": "https://arxiv.org/pdf/2506.15791", "abs": "https://arxiv.org/abs/2506.15791", "authors": ["Albert Dorador"], "title": "TRUST: Transparent, Robust and Ultra-Sparse Trees", "categories": ["stat.ME", "cs.AI", "cs.LG", "stat.ML"], "comment": null, "summary": "Piecewise-constant regression trees remain popular for their\ninterpretability, yet often lag behind black-box models like Random Forest in\npredictive accuracy. In this work, we introduce TRUST (Transparent, Robust, and\nUltra-Sparse Trees), a novel regression tree model that combines the accuracy\nof Random Forests with the interpretability of shallow decision trees and\nsparse linear models. TRUST further enhances transparency by leveraging Large\nLanguage Models to generate tailored, user-friendly explanations. Extensive\nvalidation on synthetic and real-world benchmark datasets demonstrates that\nTRUST consistently outperforms other interpretable models -- including CART,\nLasso, and Node Harvest -- in predictive accuracy, while matching the accuracy\nof Random Forest and offering substantial gains in both accuracy and\ninterpretability over M5', a well-established model that is conceptually\nrelated.", "AI": {"tldr": "TRUST\u662f\u4e00\u79cd\u65b0\u578b\u56de\u5f52\u6811\u6a21\u578b\uff0c\u7ed3\u5408\u4e86\u968f\u673a\u68ee\u6797\u7684\u51c6\u786e\u6027\u548c\u6d45\u5c42\u51b3\u7b56\u6811\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7528\u6237\u53cb\u597d\u7684\u89e3\u91ca\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5206\u6bb5\u5e38\u6570\u56de\u5f52\u6811\u5728\u9884\u6d4b\u51c6\u786e\u6027\u4e0a\u843d\u540e\u4e8e\u9ed1\u76d2\u6a21\u578b\uff08\u5982\u968f\u673a\u68ee\u6797\uff09\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51faTRUST\u6a21\u578b\uff0c\u7ed3\u5408\u968f\u673a\u68ee\u6797\u7684\u51c6\u786e\u6027\u3001\u6d45\u5c42\u51b3\u7b56\u6811\u7684\u53ef\u89e3\u91ca\u6027\u548c\u7a00\u758f\u7ebf\u6027\u6a21\u578b\u7684\u7279\u70b9\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u89e3\u91ca\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cTRUST\u5728\u9884\u6d4b\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u5176\u4ed6\u53ef\u89e3\u91ca\u6a21\u578b\uff08\u5982CART\u3001Lasso\u7b49\uff09\uff0c\u5e76\u4e0e\u968f\u673a\u68ee\u6797\u76f8\u5f53\uff0c\u540c\u65f6\u5728\u53ef\u89e3\u91ca\u6027\u4e0a\u4f18\u4e8eM5'\u3002", "conclusion": "TRUST\u5728\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u5e73\u8861\uff0c\u4e3a\u9700\u8981\u900f\u660e\u6a21\u578b\u7684\u573a\u666f\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2506.15799", "pdf": "https://arxiv.org/pdf/2506.15799", "abs": "https://arxiv.org/abs/2506.15799", "authors": ["Andrew Wagenmaker", "Mitsuhiko Nakamoto", "Yunchu Zhang", "Seohong Park", "Waleed Yagoub", "Anusha Nagabandi", "Abhishek Gupta", "Sergey Levine"], "title": "Steering Your Diffusion Policy with Latent Space Reinforcement Learning", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Robotic control policies learned from human demonstrations have achieved\nimpressive results in many real-world applications. However, in scenarios where\ninitial performance is not satisfactory, as is often the case in novel\nopen-world settings, such behavioral cloning (BC)-learned policies typically\nrequire collecting additional human demonstrations to further improve their\nbehavior -- an expensive and time-consuming process. In contrast, reinforcement\nlearning (RL) holds the promise of enabling autonomous online policy\nimprovement, but often falls short of achieving this due to the large number of\nsamples it typically requires. In this work we take steps towards enabling fast\nautonomous adaptation of BC-trained policies via efficient real-world RL.\nFocusing in particular on diffusion policies -- a state-of-the-art BC\nmethodology -- we propose diffusion steering via reinforcement learning (DSRL):\nadapting the BC policy by running RL over its latent-noise space. We show that\nDSRL is highly sample efficient, requires only black-box access to the BC\npolicy, and enables effective real-world autonomous policy improvement.\nFurthermore, DSRL avoids many of the challenges associated with finetuning\ndiffusion policies, obviating the need to modify the weights of the base policy\nat all. We demonstrate DSRL on simulated benchmarks, real-world robotic tasks,\nand for adapting pretrained generalist policies, illustrating its sample\nefficiency and effective performance at real-world policy improvement.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDSRL\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5728\u6269\u6563\u7b56\u7565\u7684\u6f5c\u5728\u566a\u58f0\u7a7a\u95f4\u4e2d\u8fdb\u884c\u8c03\u6574\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u81ea\u9002\u5e94\u7b56\u7565\u6539\u8fdb\u3002", "motivation": "\u89e3\u51b3\u884c\u4e3a\u514b\u9686\u7b56\u7565\u5728\u521d\u59cb\u8868\u73b0\u4e0d\u4f73\u65f6\u9700\u8981\u989d\u5916\u4eba\u5de5\u6f14\u793a\u7684\u95ee\u9898\uff0c\u540c\u65f6\u514b\u670d\u5f3a\u5316\u5b66\u4e60\u6837\u672c\u6548\u7387\u4f4e\u7684\u9650\u5236\u3002", "method": "\u5728\u6269\u6563\u7b56\u7565\u7684\u6f5c\u5728\u566a\u58f0\u7a7a\u95f4\u4e2d\u8fd0\u884c\u5f3a\u5316\u5b66\u4e60\uff0c\u65e0\u9700\u4fee\u6539\u57fa\u7840\u7b56\u7565\u7684\u6743\u91cd\u3002", "result": "DSRL\u8868\u73b0\u51fa\u9ad8\u6837\u672c\u6548\u7387\uff0c\u9002\u7528\u4e8e\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u4efb\u52a1\u548c\u9884\u8bad\u7ec3\u901a\u7528\u7b56\u7565\u7684\u8c03\u6574\u3002", "conclusion": "DSRL\u4e3a\u5feb\u901f\u81ea\u9002\u5e94\u7b56\u7565\u6539\u8fdb\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.15836", "pdf": "https://arxiv.org/pdf/2506.15836", "abs": "https://arxiv.org/abs/2506.15836", "authors": ["Ziv Aharoni", "Bashar Huleihel", "Henry D Pfister", "Haim H Permuter"], "title": "Code Rate Optimization via Neural Polar Decoders", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "This paper proposes a method to optimize communication code rates via the\napplication of neural polar decoders (NPDs). Employing this approach enables\nsimultaneous optimization of code rates over input distributions while\nproviding a practical coding scheme within the framework of polar codes. The\nproposed approach is designed for scenarios where the channel model is unknown,\ntreating the channel as a black box that produces output samples from input\nsamples. We employ polar codes to achieve our objectives, using NPDs to\nestimate mutual information (MI) between the channel inputs and outputs, and\noptimize a parametric model of the input distribution. The methodology involves\na two-phase process: a training phase and an inference phase. In the training\nphase, two steps are repeated interchangeably. First, the estimation step\nestimates the MI of the channel inputs and outputs via NPDs. Second, the\nimprovement step optimizes the input distribution parameters to maximize the MI\nestimate obtained by the NPDs. In the inference phase, the optimized model is\nused to construct polar codes. This involves incorporating the Honda-Yamamoto\n(HY) scheme to accommodate the optimized input distributions and list decoding\nto enhance decoding performance. Experimental results on memoryless and\nfinite-state channels (FSCs) demonstrate the effectiveness of our approach,\nparticularly in cases where the channel's capacity-achieving input distribution\nis non-uniform. For these cases, we show significant improvements in MI and bit\nerror rates (BERs) over those achieved by uniform and independent and\nidentically distributed (i.i.d.) input distributions, validating our method for\nblock lengths up to 1024. This scalable approach has potential applications in\nreal-world communication systems, bridging theoretical capacity estimation and\npractical coding performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u795e\u7ecf\u6781\u5316\u89e3\u7801\u5668\uff08NPDs\uff09\u4f18\u5316\u901a\u4fe1\u7801\u7387\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u672a\u77e5\u4fe1\u9053\u6a21\u578b\u7684\u60c5\u51b5\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u548c\u63a8\u7406\u4f18\u5316\u8f93\u5165\u5206\u5e03\u3002", "motivation": "\u5728\u672a\u77e5\u4fe1\u9053\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u540c\u65f6\u4f18\u5316\u7801\u7387\u548c\u8f93\u5165\u5206\u5e03\uff0c\u4ee5\u63d0\u5347\u901a\u4fe1\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u8bad\u7ec3\u9636\u6bb5\u4ea4\u66ff\u8fdb\u884c\u4e92\u4fe1\u606f\u4f30\u8ba1\u548c\u8f93\u5165\u5206\u5e03\u4f18\u5316\uff1b\u63a8\u7406\u9636\u6bb5\u5229\u7528\u4f18\u5316\u6a21\u578b\u6784\u5efa\u6781\u5316\u7801\u3002", "result": "\u5728\u975e\u5747\u5300\u8f93\u5165\u5206\u5e03\u7684\u4fe1\u9053\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e92\u4fe1\u606f\u548c\u8bef\u7801\u7387\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b9e\u9645\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6848\uff0c\u8fde\u63a5\u4e86\u7406\u8bba\u5bb9\u91cf\u4f30\u8ba1\u4e0e\u5b9e\u9645\u7f16\u7801\u6027\u80fd\u3002"}}
{"id": "2506.15854", "pdf": "https://arxiv.org/pdf/2506.15854", "abs": "https://arxiv.org/abs/2506.15854", "authors": ["Abdolazim Rezaei", "Mehdi Sookhak", "Ahmad Patooghy"], "title": "Privacy-Preserving in Connected and Autonomous Vehicles Through Vision to Text Transformation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Connected and Autonomous Vehicles (CAVs) rely on a range of devices that\noften process privacy-sensitive data. Among these, roadside units play a\ncritical role particularly through the use of AI-equipped (AIE) cameras for\napplications such as violation detection. However, the privacy risks associated\nwith captured imagery remain a major concern, as such data can be misused for\nidentity theft, profiling, or unauthorized commercial purposes. While\ntraditional techniques such as face blurring and obfuscation have been applied\nto mitigate privacy risks, individual privacy remains at risk, as individuals\ncan still be tracked using other features such as their clothing. This paper\nintroduces a novel privacy-preserving framework that leverages feedback-based\nreinforcement learning (RL) and vision-language models (VLMs) to protect\nsensitive visual information captured by AIE cameras. The main idea is to\nconvert images into semantically equivalent textual descriptions, ensuring that\nscene-relevant information is retained while visual privacy is preserved. A\nhierarchical RL strategy is employed to iteratively refine the generated text,\nenhancing both semantic accuracy and privacy. Evaluation results demonstrate\nsignificant improvements in both privacy protection and textual quality, with\nthe Unique Word Count increasing by approximately 77\\% and Detail Density by\naround 50\\% compared to existing approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u4fdd\u62a4AI\u6444\u50cf\u5934\u6355\u83b7\u7684\u9690\u79c1\u654f\u611f\u6570\u636e\uff0c\u901a\u8fc7\u5c06\u56fe\u50cf\u8f6c\u6362\u4e3a\u8bed\u4e49\u7b49\u6548\u7684\u6587\u672c\u63cf\u8ff0\u6765\u5e73\u8861\u9690\u79c1\u4e0e\u4fe1\u606f\u4fdd\u7559\u3002", "motivation": "AI\u6444\u50cf\u5934\u5728CAV\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u4f20\u7edf\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff08\u5982\u6a21\u7cca\u5904\u7406\uff09\u4ecd\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5c06\u56fe\u50cf\u8f6c\u6362\u4e3a\u8bed\u4e49\u7b49\u6548\u7684\u6587\u672c\u63cf\u8ff0\uff0c\u5e76\u901a\u8fc7\u5206\u5c42RL\u7b56\u7565\u8fed\u4ee3\u4f18\u5316\u6587\u672c\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u6587\u672c\u8d28\u91cf\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u72ec\u7279\u8bcd\u6570\u589e\u52a077%\uff0c\u7ec6\u8282\u5bc6\u5ea6\u63d0\u534750%\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aAI\u6444\u50cf\u5934\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u65b9\u6848\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u573a\u666f\u76f8\u5173\u4fe1\u606f\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.15880", "pdf": "https://arxiv.org/pdf/2506.15880", "abs": "https://arxiv.org/abs/2506.15880", "authors": ["Berk Yilmaz", "Junyu Hu", "Jinsong Liu"], "title": "Deep Reinforcement Learning Xiangqi Player with Monte Carlo Tree Search", "categories": ["cs.AI", "cs.LG", "68T05, 68T20"], "comment": "All authors contributed equally to this work.24 pages, 10 figures", "summary": "This paper presents a Deep Reinforcement Learning (DRL) system for Xiangqi\n(Chinese Chess) that integrates neural networks with Monte Carlo Tree Search\n(MCTS) to enable strategic self-play and self-improvement. Addressing the\nunderexplored complexity of Xiangqi, including its unique board layout, piece\nmovement constraints, and victory conditions, our approach combines\npolicy-value networks with MCTS to simulate move consequences and refine\ndecision-making. By overcoming challenges such as Xiangqi's high branching\nfactor and asymmetrical piece dynamics, our work advances AI capabilities in\nculturally significant strategy games while providing insights for adapting\nDRL-MCTS frameworks to domain-specific rule systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u7684\u8c61\u68cbAI\u7cfb\u7edf\uff0c\u7528\u4e8e\u89e3\u51b3\u8c61\u68cb\u7684\u590d\u6742\u6027\u95ee\u9898\u3002", "motivation": "\u8c61\u68cb\u5177\u6709\u72ec\u7279\u7684\u68cb\u76d8\u5e03\u5c40\u3001\u68cb\u5b50\u79fb\u52a8\u9650\u5236\u548c\u80dc\u5229\u6761\u4ef6\uff0c\u5176\u590d\u6742\u6027\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u7ed3\u5408\u7b56\u7565\u4ef7\u503c\u7f51\u7edc\u4e0eMCTS\uff0c\u6a21\u62df\u8d70\u68cb\u540e\u679c\u5e76\u4f18\u5316\u51b3\u7b56\u3002", "result": "\u514b\u670d\u4e86\u8c61\u68cb\u7684\u9ad8\u5206\u652f\u56e0\u5b50\u548c\u975e\u5bf9\u79f0\u68cb\u5b50\u52a8\u6001\uff0c\u63d0\u5347\u4e86AI\u5728\u6587\u5316\u7b56\u7565\u6e38\u620f\u4e2d\u7684\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aDRL-MCTS\u6846\u67b6\u5728\u7279\u5b9a\u9886\u57df\u89c4\u5219\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u542f\u793a\u3002"}}
{"id": "2506.15887", "pdf": "https://arxiv.org/pdf/2506.15887", "abs": "https://arxiv.org/abs/2506.15887", "authors": ["Jakub T\u0142uczek", "Victor Villin", "Christos Dimitrakakis"], "title": "Fair Contracts in Principal-Agent Games with Heterogeneous Types", "categories": ["cs.GT", "cs.LG", "cs.MA"], "comment": null, "summary": "Fairness is desirable yet challenging to achieve within multi-agent systems,\nespecially when agents differ in latent traits that affect their abilities.\nThis hidden heterogeneity often leads to unequal distributions of wealth, even\nwhen agents operate under the same rules. Motivated by real-world examples, we\npropose a framework based on repeated principal-agent games, where a principal,\nwho also can be seen as a player of the game, learns to offer adaptive\ncontracts to agents. By leveraging a simple yet powerful contract structure, we\nshow that a fairness-aware principal can learn homogeneous linear contracts\nthat equalize outcomes across agents in a sequential social dilemma.\nImportantly, this fairness does not come at the cost of efficiency: our results\ndemonstrate that it is possible to promote equity and stability in the system\nwhile preserving overall performance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cd\u590d\u59d4\u6258-\u4ee3\u7406\u535a\u5f08\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u81ea\u9002\u5e94\u5408\u540c\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u516c\u5e73\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6548\u7387\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u9690\u85cf\u7684\u5f02\u8d28\u6027\u5bfc\u81f4\u8d22\u5bcc\u5206\u914d\u4e0d\u5747\uff0c\u5373\u4f7f\u89c4\u5219\u76f8\u540c\u3002\u73b0\u5b9e\u4e2d\u7684\u4f8b\u5b50\u6fc0\u53d1\u4e86\u7814\u7a76\u516c\u5e73\u6027\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\u91cd\u590d\u59d4\u6258-\u4ee3\u7406\u535a\u5f08\u6846\u67b6\uff0c\u59d4\u6258\u4eba\u5b66\u4e60\u63d0\u4f9b\u81ea\u9002\u5e94\u5408\u540c\uff0c\u5229\u7528\u7b80\u5355\u7684\u7ebf\u6027\u5408\u540c\u7ed3\u6784\u3002", "result": "\u516c\u5e73\u6027\u59d4\u6258\u4eba\u53ef\u4ee5\u5b66\u4e60\u5230\u540c\u8d28\u7ebf\u6027\u5408\u540c\uff0c\u5728\u5e8f\u5217\u793e\u4f1a\u56f0\u5883\u4e2d\u5747\u8861\u7ed3\u679c\uff0c\u4e14\u4e0d\u727a\u7272\u6548\u7387\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u516c\u5e73\u6027\u548c\u6548\u7387\u53ef\u4ee5\u5e76\u5b58\uff0c\u7cfb\u7edf\u53ef\u4ee5\u540c\u65f6\u5b9e\u73b0\u516c\u5e73\u3001\u7a33\u5b9a\u548c\u6574\u4f53\u6027\u80fd\u3002"}}
{"id": "2506.15906", "pdf": "https://arxiv.org/pdf/2506.15906", "abs": "https://arxiv.org/abs/2506.15906", "authors": ["Sawan Kumar", "Tapas Tripura", "Rajdip Nayek", "Souvik Chakraborty"], "title": "From Local Interactions to Global Operators: Scalable Gaussian Process Operator for Physical Systems", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Operator learning offers a powerful paradigm for solving parametric partial\ndifferential equations (PDEs), but scaling probabilistic neural operators such\nas the recently proposed Gaussian Processes Operators (GPOs) to\nhigh-dimensional, data-intensive regimes remains a significant challenge. In\nthis work, we introduce a novel, scalable GPO, which capitalizes on sparsity,\nlocality, and structural information through judicious kernel design.\nAddressing the fundamental limitation of cubic computational complexity, our\nmethod leverages nearest-neighbor-based local kernel approximations in the\nspatial domain, sparse kernel approximation in the parameter space, and\nstructured Kronecker factorizations to enable tractable inference on\nlarge-scale datasets and high-dimensional input. While local approximations\noften introduce accuracy trade-offs due to limited kernel interactions, we\novercome this by embedding operator-aware kernel structures and employing\nexpressive, task-informed mean functions derived from neural operator\narchitectures. Through extensive evaluations on a broad class of nonlinear PDEs\n- including Navier-Stokes, wave advection, Darcy flow, and Burgers' equations -\nwe demonstrate that our framework consistently achieves high accuracy across\nvarying discretization scales. These results underscore the potential of our\napproach to bridge the gap between scalability and fidelity in GPO, offering a\ncompelling foundation for uncertainty-aware modeling in complex physical\nsystems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u9ad8\u65af\u8fc7\u7a0b\u7b97\u5b50\uff08GPO\uff09\uff0c\u901a\u8fc7\u7a00\u758f\u6027\u3001\u5c40\u90e8\u6027\u548c\u7ed3\u6784\u4fe1\u606f\u4f18\u5316\u6838\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e86\u9ad8\u7ef4\u6570\u636e\u573a\u666f\u4e0b\u7684\u8ba1\u7b97\u590d\u6742\u6027\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u6982\u7387\u795e\u7ecf\u7b97\u5b50\uff08\u5982GPO\uff09\u5728\u9ad8\u7ef4\u3001\u6570\u636e\u5bc6\u96c6\u578b\u573a\u666f\u4e2d\u7684\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6700\u8fd1\u90bb\u5c40\u90e8\u6838\u8fd1\u4f3c\u3001\u53c2\u6570\u7a7a\u95f4\u7684\u7a00\u758f\u6838\u8fd1\u4f3c\u548c\u7ed3\u6784\u5316Kronecker\u5206\u89e3\uff0c\u7ed3\u5408\u7b97\u5b50\u611f\u77e5\u7684\u6838\u7ed3\u6784\u548c\u4efb\u52a1\u9a71\u52a8\u7684\u5747\u503c\u51fd\u6570\u3002", "result": "\u5728\u591a\u79cd\u975e\u7ebf\u6027PDE\uff08\u5982Navier-Stokes\u3001Burgers\u65b9\u7a0b\uff09\u4e0a\u9a8c\u8bc1\u4e86\u9ad8\u7cbe\u5ea6\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861\uff0c\u4e3a\u590d\u6742\u7269\u7406\u7cfb\u7edf\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2506.15908", "pdf": "https://arxiv.org/pdf/2506.15908", "abs": "https://arxiv.org/abs/2506.15908", "authors": ["Elif Keles", "Merve Yazol", "Gorkem Durak", "Ziliang Hong", "Halil Ertugrul Aktas", "Zheyuan Zhang", "Linkai Peng", "Onkar Susladkar", "Necati Guzelyel", "Oznur Leman Boyunaga", "Cemal Yazici", "Mark Lowe", "Aliye Uc", "Ulas Bagci"], "title": "Pediatric Pancreas Segmentation from MRI Scans with Deep Learning", "categories": ["cs.CV", "cs.LG"], "comment": "Code and MRI data available for public", "summary": "Objective: Our study aimed to evaluate and validate PanSegNet, a deep\nlearning (DL) algorithm for pediatric pancreas segmentation on MRI in children\nwith acute pancreatitis (AP), chronic pancreatitis (CP), and healthy controls.\nMethods: With IRB approval, we retrospectively collected 84 MRI scans (1.5T/3T\nSiemens Aera/Verio) from children aged 2-19 years at Gazi University\n(2015-2024). The dataset includes healthy children as well as patients\ndiagnosed with AP or CP based on clinical criteria. Pediatric and general\nradiologists manually segmented the pancreas, then confirmed by a senior\npediatric radiologist. PanSegNet-generated segmentations were assessed using\nDice Similarity Coefficient (DSC) and 95th percentile Hausdorff distance\n(HD95). Cohen's kappa measured observer agreement. Results: Pancreas MRI T2W\nscans were obtained from 42 children with AP/CP (mean age: 11.73 +/- 3.9 years)\nand 42 healthy children (mean age: 11.19 +/- 4.88 years). PanSegNet achieved\nDSC scores of 88% (controls), 81% (AP), and 80% (CP), with HD95 values of 3.98\nmm (controls), 9.85 mm (AP), and 15.67 mm (CP). Inter-observer kappa was 0.86\n(controls), 0.82 (pancreatitis), and intra-observer agreement reached 0.88 and\n0.81. Strong agreement was observed between automated and manual volumes (R^2 =\n0.85 in controls, 0.77 in diseased), demonstrating clinical reliability.\nConclusion: PanSegNet represents the first validated deep learning solution for\npancreatic MRI segmentation, achieving expert-level performance across healthy\nand diseased states. This tool, algorithm, along with our annotated dataset,\nare freely available on GitHub and OSF, advancing accessible, radiation-free\npediatric pancreatic imaging and fostering collaborative research in this\nunderserved domain.", "AI": {"tldr": "PanSegNet\u662f\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\uff0c\u7528\u4e8e\u513f\u7ae5\u80f0\u817aMRI\u5206\u5272\uff0c\u5728\u5065\u5eb7\u513f\u7ae5\u548c\u6025\u6162\u6027\u80f0\u817a\u708e\u60a3\u8005\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8fbe\u5230\u4e13\u5bb6\u6c34\u5e73\u3002", "motivation": "\u8bc4\u4f30\u548c\u9a8c\u8bc1PanSegNet\u5728\u513f\u7ae5\u80f0\u817aMRI\u5206\u5272\u4e2d\u7684\u6027\u80fd\uff0c\u586b\u8865\u513f\u79d1\u80f0\u817a\u5f71\u50cf\u9886\u57df\u7684\u7a7a\u767d\u3002", "method": "\u56de\u987e\u6027\u6536\u96c684\u4f8bMRI\u626b\u63cf\uff0c\u7531\u653e\u5c04\u79d1\u533b\u751f\u624b\u52a8\u5206\u5272\u80f0\u817a\uff0cPanSegNet\u751f\u6210\u7684\u5206\u5272\u7ed3\u679c\u901a\u8fc7DSC\u548cHD95\u8bc4\u4f30\u3002", "result": "PanSegNet\u5728\u5065\u5eb7\u513f\u7ae5\u4e2dDSC\u4e3a88%\uff0c\u6025\u6162\u6027\u80f0\u817a\u708e\u60a3\u8005\u4e2d\u5206\u522b\u4e3a81%\u548c80%\uff0c\u4e0e\u624b\u52a8\u5206\u5272\u7ed3\u679c\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "PanSegNet\u662f\u9996\u4e2a\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u513f\u79d1\u80f0\u817aMRI\u5206\u5272\u6df1\u5ea6\u5b66\u4e60\u5de5\u5177\uff0c\u6027\u80fd\u53ef\u9760\u4e14\u5f00\u6e90\uff0c\u63a8\u52a8\u65e0\u8f90\u5c04\u513f\u79d1\u5f71\u50cf\u7814\u7a76\u3002"}}
{"id": "2506.15958", "pdf": "https://arxiv.org/pdf/2506.15958", "abs": "https://arxiv.org/abs/2506.15958", "authors": ["Lucas Amoudruz", "Petr Karnakov", "Petros Koumoutsakos"], "title": "Contactless Precision Steering of Particles in a Fluid inside a Cube with Rotating Walls", "categories": ["physics.flu-dyn", "cs.LG", "cs.RO"], "comment": null, "summary": "Contactless manipulation of small objects is essential for biomedical and\nchemical applications, such as cell analysis, assisted fertilisation, and\nprecision chemistry. Established methods, including optical, acoustic, and\nmagnetic tweezers, are now complemented by flow control techniques that use\nflow-induced motion to enable precise and versatile manipulation. However,\ntrapping multiple particles in fluid remains a challenge. This study introduces\na novel control algorithm capable of steering multiple particles in flow. The\nsystem uses rotating disks to generate flow fields that transport particles to\nprecise locations. Disk rotations are governed by a feedback control policy\nbased on the Optimising a Discrete Loss (ODIL) framework, which combines fluid\ndynamics equations with path objectives into a single loss function. Our\nexperiments, conducted in both simulations and with the physical device,\ndemonstrate the capability of the approach to transport two beads\nsimultaneously to predefined locations, advancing robust contactless particle\nmanipulation for biomedical applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u63a7\u5236\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u6d41\u4f53\u4e2d\u7cbe\u786e\u64cd\u7eb5\u591a\u4e2a\u7c92\u5b50\uff0c\u901a\u8fc7\u65cb\u8f6c\u78c1\u76d8\u751f\u6210\u6d41\u573a\uff0c\u7ed3\u5408ODIL\u6846\u67b6\u5b9e\u73b0\u53cd\u9988\u63a7\u5236\u3002", "motivation": "\u5728\u751f\u7269\u533b\u5b66\u548c\u5316\u5b66\u5e94\u7528\u4e2d\uff0c\u975e\u63a5\u89e6\u5f0f\u64cd\u7eb5\u5c0f\u7269\u4f53\uff08\u5982\u7ec6\u80de\u5206\u6790\u548c\u7cbe\u5bc6\u5316\u5b66\uff09\u9700\u6c42\u8feb\u5207\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u6355\u83b7\u591a\u4e2a\u7c92\u5b50\u3002", "method": "\u4f7f\u7528\u65cb\u8f6c\u78c1\u76d8\u751f\u6210\u6d41\u573a\uff0c\u901a\u8fc7\u57fa\u4e8eODIL\u6846\u67b6\u7684\u53cd\u9988\u63a7\u5236\u7b56\u7565\u8c03\u8282\u78c1\u76d8\u65cb\u8f6c\uff0c\u5c06\u6d41\u4f53\u52a8\u529b\u5b66\u65b9\u7a0b\u4e0e\u8def\u5f84\u76ee\u6807\u7ed3\u5408\u4e3a\u5355\u4e00\u635f\u5931\u51fd\u6570\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u5728\u6a21\u62df\u548c\u7269\u7406\u8bbe\u5907\u4e2d\u540c\u65f6\u5c06\u4e24\u4e2a\u73e0\u5b50\u8fd0\u8f93\u5230\u9884\u5b9a\u4f4d\u7f6e\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u975e\u63a5\u89e6\u5f0f\u7c92\u5b50\u64cd\u7eb5\u63d0\u4f9b\u4e86\u66f4\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u751f\u7269\u533b\u5b66\u5e94\u7528\u3002"}}
{"id": "2506.15971", "pdf": "https://arxiv.org/pdf/2506.15971", "abs": "https://arxiv.org/abs/2506.15971", "authors": ["Jiawen Yang", "Shuhao Chen", "Yucong Duan", "Ke Tang", "Yu Zhang"], "title": "Heterogeneous-Modal Unsupervised Domain Adaptation via Latent Space Bridging", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Unsupervised domain adaptation (UDA) methods effectively bridge domain gaps\nbut become struggled when the source and target domains belong to entirely\ndistinct modalities. To address this limitation, we propose a novel setting\ncalled Heterogeneous-Modal Unsupervised Domain Adaptation (HMUDA), which\nenables knowledge transfer between completely different modalities by\nleveraging a bridge domain containing unlabeled samples from both modalities.\nTo learn under the HMUDA setting, we propose Latent Space Bridging (LSB), a\nspecialized framework designed for the semantic segmentation task.\nSpecifically, LSB utilizes a dual-branch architecture, incorporating a feature\nconsistency loss to align representations across modalities and a domain\nalignment loss to reduce discrepancies between class centroids across domains.\nExtensive experiments conducted on six benchmark datasets demonstrate that LSB\nachieves state-of-the-art performance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f02\u6784\u6a21\u6001\u65e0\u76d1\u7763\u57df\u9002\u5e94\uff08HMUDA\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u6865\u63a5\uff08LSB\uff09\u6846\u67b6\u5b9e\u73b0\u8de8\u6a21\u6001\u77e5\u8bc6\u8fc1\u79fb\u3002", "motivation": "\u89e3\u51b3\u6e90\u57df\u548c\u76ee\u6807\u57df\u5c5e\u4e8e\u5b8c\u5168\u4e0d\u540c\u7684\u6a21\u6001\u65f6\uff0c\u4f20\u7edf\u65e0\u76d1\u7763\u57df\u9002\u5e94\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faLSB\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u5206\u652f\u67b6\u6784\uff0c\u7ed3\u5408\u7279\u5f81\u4e00\u81f4\u6027\u635f\u5931\u548c\u57df\u5bf9\u9f50\u635f\u5931\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86LSB\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "LSB\u5728\u5f02\u6784\u6a21\u6001\u65e0\u76d1\u7763\u57df\u9002\u5e94\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.16029", "pdf": "https://arxiv.org/pdf/2506.16029", "abs": "https://arxiv.org/abs/2506.16029", "authors": ["Zhenting Qi", "Fan Nie", "Alexandre Alahi", "James Zou", "Himabindu Lakkaraju", "Yilun Du", "Eric Xing", "Sham Kakade", "Hanlin Zhang"], "title": "EvoLM: In Search of Lost Language Model Training Dynamics", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Modern language model (LM) training has been divided into multiple stages,\nmaking it difficult for downstream developers to evaluate the impact of design\nchoices made at each stage. We present EvoLM, a model suite that enables\nsystematic and transparent analysis of LMs' training dynamics across\npre-training, continued pre-training, supervised fine-tuning, and reinforcement\nlearning. By training over 100 LMs with 1B and 4B parameters from scratch, we\nrigorously evaluate both upstream (language modeling) and downstream\n(problem-solving) reasoning capabilities, including considerations of both\nin-domain and out-of-domain generalization. Key insights highlight the\ndiminishing returns from excessive pre-training and post-training, the\nimportance and practices of mitigating forgetting during domain-specific\ncontinued pre-training, the crucial role of continued pre-training in bridging\npre-training and post-training phases, and various intricate trade-offs when\nconfiguring supervised fine-tuning and reinforcement learning. To facilitate\nopen research and reproducibility, we release all pre-trained and post-trained\nmodels, training datasets for all stages, and our entire training and\nevaluation pipeline.", "AI": {"tldr": "EvoLM\u662f\u4e00\u4e2a\u6a21\u578b\u5957\u4ef6\uff0c\u7528\u4e8e\u7cfb\u7edf\u5206\u6790\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u8bad\u7ec3\u9636\u6bb5\uff08\u9884\u8bad\u7ec3\u3001\u7ee7\u7eed\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\uff09\u7684\u52a8\u6001\u8868\u73b0\u3002\u901a\u8fc7\u8bad\u7ec3100\u591a\u4e2a\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u8fc7\u5ea6\u8bad\u7ec3\u3001\u9886\u57df\u9002\u5e94\u548c\u9636\u6bb5\u95f4\u8854\u63a5\u7684\u5173\u952e\u95ee\u9898\uff0c\u5e76\u5f00\u6e90\u4e86\u6240\u6709\u8d44\u6e90\u3002", "motivation": "\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u5206\u4e3a\u591a\u4e2a\u9636\u6bb5\uff0c\u4e0b\u6e38\u5f00\u53d1\u8005\u96be\u4ee5\u8bc4\u4f30\u5404\u9636\u6bb5\u8bbe\u8ba1\u9009\u62e9\u7684\u5f71\u54cd\u3002EvoLM\u65e8\u5728\u63d0\u4f9b\u900f\u660e\u548c\u7cfb\u7edf\u7684\u5206\u6790\u5de5\u5177\u3002", "method": "\u8bad\u7ec3\u4e86100\u591a\u4e2a1B\u548c4B\u53c2\u6570\u7684\u6a21\u578b\uff0c\u8bc4\u4f30\u4e86\u8bed\u8a00\u5efa\u6a21\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u5305\u62ec\u9886\u57df\u5185\u5916\u6cdb\u5316\u3002", "result": "\u53d1\u73b0\u8fc7\u5ea6\u9884\u8bad\u7ec3\u548c\u540e\u671f\u8bad\u7ec3\u7684\u6536\u76ca\u9012\u51cf\uff0c\u7ee7\u7eed\u9884\u8bad\u7ec3\u5bf9\u8854\u63a5\u9636\u6bb5\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u590d\u6742\u6743\u8861\u3002", "conclusion": "EvoLM\u4e3a\u7814\u7a76\u63d0\u4f9b\u4e86\u900f\u660e\u6027\u548c\u53ef\u590d\u73b0\u6027\uff0c\u5f00\u6e90\u4e86\u6240\u6709\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6d41\u7a0b\u3002"}}
{"id": "2506.16037", "pdf": "https://arxiv.org/pdf/2506.16037", "abs": "https://arxiv.org/abs/2506.16037", "authors": ["Xinyue Huang", "Ziqi Lin", "Fang Sun", "Wenchao Zhang", "Kejian Tong", "Yunbo Liu"], "title": "Enhancing Document-Level Question Answering via Multi-Hop Retrieval-Augmented Generation with LLaMA 3", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This paper presents a novel Retrieval-Augmented Generation (RAG) framework\ntailored for complex question answering tasks, addressing challenges in\nmulti-hop reasoning and contextual understanding across lengthy documents.\nBuilt upon LLaMA 3, the framework integrates a dense retrieval module with\nadvanced context fusion and multi-hop reasoning mechanisms, enabling more\naccurate and coherent response generation. A joint optimization strategy\ncombining retrieval likelihood and generation cross-entropy improves the\nmodel's robustness and adaptability. Experimental results show that the\nproposed system outperforms existing retrieval-augmented and generative\nbaselines, confirming its effectiveness in delivering precise, contextually\ngrounded answers.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLaMA 3\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff08RAG\uff09\uff0c\u7528\u4e8e\u590d\u6742\u95ee\u7b54\u4efb\u52a1\uff0c\u901a\u8fc7\u591a\u8df3\u63a8\u7406\u548c\u4e0a\u4e0b\u6587\u878d\u5408\u63d0\u5347\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u591a\u8df3\u63a8\u7406\u548c\u957f\u6587\u6863\u4e0a\u4e0b\u6587\u7406\u89e3\u4e2d\u7684\u6311\u6218\u3002", "method": "\u7ed3\u5408\u5bc6\u96c6\u68c0\u7d22\u6a21\u5757\u3001\u4e0a\u4e0b\u6587\u878d\u5408\u548c\u591a\u8df3\u63a8\u7406\u673a\u5236\uff0c\u91c7\u7528\u8054\u5408\u4f18\u5316\u7b56\u7565\uff08\u68c0\u7d22\u4f3c\u7136\u548c\u751f\u6210\u4ea4\u53c9\u71b5\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u4f18\u4e8e\u73b0\u6709\u68c0\u7d22\u589e\u5f3a\u548c\u751f\u6210\u57fa\u7ebf\uff0c\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u4e0a\u4e0b\u6587\u76f8\u5173\u7b54\u6848\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u590d\u6742\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.16042", "pdf": "https://arxiv.org/pdf/2506.16042", "abs": "https://arxiv.org/abs/2506.16042", "authors": ["Reyna Abhyankar", "Qi Qi", "Yiying Zhang"], "title": "OSWorld-Human: Benchmarking the Efficiency of Computer-Use Agents", "categories": ["cs.AI", "cs.LG", "cs.OS"], "comment": null, "summary": "Generative AI is being leveraged to solve a variety of computer-use tasks\ninvolving desktop applications. State-of-the-art systems have focused solely on\nimproving accuracy on leading benchmarks. However, these systems are\npractically unusable due to extremely high end-to-end latency (e.g., tens of\nminutes) for tasks that typically take humans just a few minutes to complete.\nTo understand the cause behind this and to guide future developments of\ncomputer agents, we conduct the first study on the temporal performance of\ncomputer-use agents on OSWorld, the flagship benchmark in computer-use AI. We\nfind that large model calls for planning and reflection account for the\nmajority of the overall latency, and as an agent uses more steps to complete a\ntask, each successive step can take 3x longer than steps at the beginning of a\ntask. We then construct OSWorld-Human, a manually annotated version of the\noriginal OSWorld dataset that contains a human-determined trajectory for each\ntask. We evaluate 16 agents on their efficiency using OSWorld-Human and found\nthat even the highest-scoring agents on OSWorld take 1.4-2.7x more steps than\nnecessary.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u7528\u4e8e\u89e3\u51b3\u684c\u9762\u5e94\u7528\u4efb\u52a1\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u56e0\u9ad8\u5ef6\u8fdf\u800c\u96be\u4ee5\u5b9e\u7528\u3002\u7814\u7a76\u9996\u6b21\u5206\u6790\u4e86\u8ba1\u7b97\u673a\u4ee3\u7406\u7684\u65f6\u95f4\u6027\u80fd\uff0c\u53d1\u73b0\u6a21\u578b\u8c03\u7528\u548c\u6b65\u9aa4\u589e\u52a0\u662f\u4e3b\u8981\u539f\u56e0\u3002\u6784\u5efa\u4e86\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6OSWorld-Human\uff0c\u53d1\u73b0\u9ad8\u6548\u4ee3\u7406\u4ecd\u9700\u66f4\u591a\u6b65\u9aa4\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0fAI\u7cfb\u7edf\u5728\u8ba1\u7b97\u673a\u4efb\u52a1\u4e2d\u56e0\u9ad8\u5ef6\u8fdf\u4e0d\u5b9e\u7528\uff0c\u9700\u7814\u7a76\u5176\u65f6\u95f4\u6027\u80fd\u4ee5\u6307\u5bfc\u672a\u6765\u5f00\u53d1\u3002", "method": "\u5728OSWorld\u57fa\u51c6\u4e0a\u5206\u6790\u4ee3\u7406\u7684\u65f6\u95f4\u6027\u80fd\uff0c\u6784\u5efaOSWorld-Human\u6570\u636e\u96c6\uff0c\u8bc4\u4f3016\u79cd\u4ee3\u7406\u7684\u6548\u7387\u3002", "result": "\u6a21\u578b\u8c03\u7528\u548c\u6b65\u9aa4\u589e\u52a0\u5bfc\u81f4\u9ad8\u5ef6\u8fdf\uff0c\u9ad8\u6548\u4ee3\u7406\u4ecd\u97001.4-2.7\u500d\u6b65\u9aa4\u3002", "conclusion": "\u9700\u4f18\u5316\u6a21\u578b\u8c03\u7528\u548c\u6b65\u9aa4\u6548\u7387\u4ee5\u63d0\u5347\u8ba1\u7b97\u673a\u4ee3\u7406\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.16043", "pdf": "https://arxiv.org/pdf/2506.16043", "abs": "https://arxiv.org/abs/2506.16043", "authors": ["Fei Wang", "Xingchen Wan", "Ruoxi Sun", "Jiefeng Chen", "Sercan \u00d6. Ar\u0131k"], "title": "DynScaling: Efficient Verifier-free Inference Scaling via Dynamic and Integrated Sampling", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Inference-time scaling has proven effective in boosting large language model\n(LLM) performance through increased test-time computation. Yet, its practical\napplication is often hindered by reliance on external verifiers or a lack of\noptimization for realistic computational constraints. We propose DynScaling,\nwhich addresses these limitations through two primary innovations: an\nintegrated parallel-sequential sampling strategy and a bandit-based dynamic\nbudget allocation framework. The integrated sampling strategy unifies parallel\nand sequential sampling by constructing synthetic sequential reasoning chains\nfrom initially independent parallel responses, promoting diverse and coherent\nreasoning trajectories. The dynamic budget allocation framework formulates the\nallocation of computational resources as a multi-armed bandit problem,\nadaptively distributing the inference budget across queries based on the\nuncertainty of previously sampled responses, thereby maximizing computational\nefficiency. By combining these components, DynScaling effectively improves LLM\nperformance under practical resource constraints without the need for external\nverifiers. Experimental results demonstrate that DynScaling consistently\nsurpasses existing verifier-free inference scaling baselines in both task\nperformance and computational cost.", "AI": {"tldr": "DynScaling\u901a\u8fc7\u96c6\u6210\u5e76\u884c-\u987a\u5e8f\u91c7\u6837\u7b56\u7565\u548c\u52a8\u6001\u9884\u7b97\u5206\u914d\u6846\u67b6\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u65e0\u9700\u5916\u90e8\u9a8c\u8bc1\u5668\u3002", "motivation": "\u4f20\u7edf\u63a8\u7406\u65f6\u95f4\u6269\u5c55\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8\u9a8c\u8bc1\u5668\u6216\u672a\u4f18\u5316\u5b9e\u9645\u8ba1\u7b97\u7ea6\u675f\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faDynScaling\uff0c\u7ed3\u5408\u5e76\u884c-\u987a\u5e8f\u91c7\u6837\u7b56\u7565\u548c\u52a8\u6001\u9884\u7b97\u5206\u914d\u6846\u67b6\uff0c\u4f18\u5316\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u3002", "result": "\u5b9e\u9a8c\u663e\u793aDynScaling\u5728\u4efb\u52a1\u6027\u80fd\u548c\u8ba1\u7b97\u6210\u672c\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "DynScaling\u5728\u8d44\u6e90\u7ea6\u675f\u4e0b\u6709\u6548\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u65e0\u9700\u5916\u90e8\u9a8c\u8bc1\u5668\u3002"}}
{"id": "2506.16079", "pdf": "https://arxiv.org/pdf/2506.16079", "abs": "https://arxiv.org/abs/2506.16079", "authors": ["Prakrut Kotecha", "Aditya Shirwatkar", "Shishir Kolathaya"], "title": "Investigating Lagrangian Neural Networks for Infinite Horizon Planning in Quadrupedal Locomotion", "categories": ["cs.RO", "cs.LG"], "comment": "6 pages, 5 figures, Accepted at Advances in Robotics (AIR) Conference\n  2025", "summary": "Lagrangian Neural Networks (LNNs) present a principled and interpretable\nframework for learning the system dynamics by utilizing inductive biases. While\ntraditional dynamics models struggle with compounding errors over long\nhorizons, LNNs intrinsically preserve the physical laws governing any system,\nenabling accurate and stable predictions essential for sustainable locomotion.\nThis work evaluates LNNs for infinite horizon planning in quadrupedal robots\nthrough four dynamics models: (1) full-order forward dynamics (FD) training and\ninference, (2) diagonalized representation of Mass Matrix in full order FD, (3)\nfull-order inverse dynamics (ID) training with FD inference, (4) reduced-order\nmodeling via torso centre-of-mass (CoM) dynamics. Experiments demonstrate that\nLNNs bring improvements in sample efficiency (10x) and superior prediction\naccuracy (up to 2-10x) compared to baseline methods. Notably, the\ndiagonalization approach of LNNs reduces computational complexity while\nretaining some interpretability, enabling real-time receding horizon control.\nThese findings highlight the advantages of LNNs in capturing the underlying\nstructure of system dynamics in quadrupeds, leading to improved performance and\nefficiency in locomotion planning and control. Additionally, our approach\nachieves a higher control frequency than previous LNN methods, demonstrating\nits potential for real-world deployment on quadrupeds.", "AI": {"tldr": "Lagrangian Neural Networks (LNNs) \u901a\u8fc7\u5229\u7528\u5f52\u7eb3\u504f\u7f6e\u5b66\u4e60\u7cfb\u7edf\u52a8\u529b\u5b66\uff0c\u5728\u56db\u8db3\u673a\u5668\u4eba\u65e0\u9650\u65f6\u57df\u89c4\u5212\u4e2d\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u52a8\u529b\u5b66\u6a21\u578b\u5728\u957f\u671f\u9884\u6d4b\u4e2d\u8bef\u5dee\u7d2f\u79ef\uff0c\u800c LNNs \u80fd\u4fdd\u6301\u7269\u7406\u89c4\u5f8b\uff0c\u9002\u7528\u4e8e\u53ef\u6301\u7eed\u8fd0\u52a8\u3002", "method": "\u8bc4\u4f30\u4e86\u56db\u79cd\u52a8\u529b\u5b66\u6a21\u578b\uff1a\u5168\u9636\u6b63\u5411\u52a8\u529b\u5b66\u3001\u5bf9\u89d2\u5316\u8d28\u91cf\u77e9\u9635\u3001\u5168\u9636\u9006\u5411\u52a8\u529b\u5b66\u4e0e\u6b63\u5411\u63a8\u7406\u3001\u964d\u9636\u6a21\u578b\u3002", "result": "LNNs \u5728\u6837\u672c\u6548\u7387\uff0810\u500d\uff09\u548c\u9884\u6d4b\u7cbe\u5ea6\uff082-10\u500d\uff09\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u8ba1\u7b97\u590d\u6742\u5ea6\u964d\u4f4e\u3002", "conclusion": "LNNs \u80fd\u6709\u6548\u6355\u6349\u56db\u8db3\u673a\u5668\u4eba\u52a8\u529b\u5b66\u7ed3\u6784\uff0c\u63d0\u5347\u8fd0\u52a8\u89c4\u5212\u548c\u63a7\u5236\u6027\u80fd\uff0c\u9002\u5408\u5b9e\u65f6\u90e8\u7f72\u3002"}}
{"id": "2506.16089", "pdf": "https://arxiv.org/pdf/2506.16089", "abs": "https://arxiv.org/abs/2506.16089", "authors": ["Sean Moushegian", "Taposh Banerjee", "Vahid Tarokh"], "title": "Diffusion-Based Hypothesis Testing and Change-Point Detection", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Score-based methods have recently seen increasing popularity in modeling and\ngeneration. Methods have been constructed to perform hypothesis testing and\nchange-point detection with score functions, but these methods are in general\nnot as powerful as their likelihood-based peers. Recent works consider\ngeneralizing the score-based Fisher divergence into a diffusion-divergence by\ntransforming score functions via multiplication with a matrix-valued function\nor a weight matrix. In this paper, we extend the score-based hypothesis test\nand change-point detection stopping rule into their diffusion-based analogs.\nAdditionally, we theoretically quantify the performance of these\ndiffusion-based algorithms and study scenarios where optimal performance is\nachievable. We propose a method of numerically optimizing the weight matrix and\npresent numerical simulations to illustrate the advantages of diffusion-based\nalgorithms.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u57fa\u4e8e\u5206\u6570\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6269\u6563\u7684\u5047\u8bbe\u68c0\u9a8c\u548c\u53d8\u70b9\u68c0\u6d4b\u7b97\u6cd5\uff0c\u5e76\u7406\u8bba\u91cf\u5316\u4e86\u5176\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u6570\u503c\u4f18\u5316\u7684\u4f18\u52bf\u3002", "motivation": "\u57fa\u4e8e\u5206\u6570\u7684\u65b9\u6cd5\u5728\u5efa\u6a21\u548c\u751f\u6210\u4e2d\u65e5\u76ca\u6d41\u884c\uff0c\u4f46\u5176\u5047\u8bbe\u68c0\u9a8c\u548c\u53d8\u70b9\u68c0\u6d4b\u80fd\u529b\u4e0d\u5982\u57fa\u4e8e\u4f3c\u7136\u7684\u65b9\u6cd5\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6269\u6563\u53d8\u6362\u63d0\u5347\u5206\u6570\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "method": "\u5c06\u5206\u6570\u51fd\u6570\u901a\u8fc7\u77e9\u9635\u53d8\u6362\u63a8\u5e7f\u4e3a\u6269\u6563\u6563\u5ea6\uff0c\u6269\u5c55\u4e86\u57fa\u4e8e\u5206\u6570\u7684\u5047\u8bbe\u68c0\u9a8c\u548c\u53d8\u70b9\u68c0\u6d4b\u7b97\u6cd5\uff0c\u5e76\u7406\u8bba\u5206\u6790\u4e86\u5176\u6027\u80fd\u3002", "result": "\u63d0\u51fa\u4e86\u6570\u503c\u4f18\u5316\u6743\u91cd\u77e9\u9635\u7684\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u5c55\u793a\u4e86\u57fa\u4e8e\u6269\u6563\u7b97\u6cd5\u7684\u4f18\u52bf\u3002", "conclusion": "\u57fa\u4e8e\u6269\u6563\u7684\u7b97\u6cd5\u5728\u7279\u5b9a\u573a\u666f\u4e0b\u80fd\u5b9e\u73b0\u6700\u4f18\u6027\u80fd\uff0c\u6570\u503c\u4f18\u5316\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u5176\u8868\u73b0\u3002"}}
{"id": "2506.16120", "pdf": "https://arxiv.org/pdf/2506.16120", "abs": "https://arxiv.org/abs/2506.16120", "authors": ["Fivos Kalogiannis", "Emmanouil-Vasileios Vlatakis-Gkaragkounis", "Ian Gemp", "Georgios Piliouras"], "title": "Solving Zero-Sum Convex Markov Games", "categories": ["cs.GT", "cs.LG", "cs.MA", "math.OC"], "comment": "To appear in the Proceedings of the 2025 International Conference on\n  Machine Learning (ICML 2025)", "summary": "We contribute the first provable guarantees of global convergence to Nash\nequilibria (NE) in two-player zero-sum convex Markov games (cMGs) by using\nindependent policy gradient methods. Convex Markov games, recently defined by\nGemp et al. (2024), extend Markov decision processes to multi-agent settings\nwith preferences that are convex over occupancy measures, offering a broad\nframework for modeling generic strategic interactions. However, even the\nfundamental min-max case of cMGs presents significant challenges, including\ninherent nonconvexity, the absence of Bellman consistency, and the complexity\nof the infinite horizon.\n  We follow a two-step approach. First, leveraging properties of\nhidden-convex--hidden-concave functions, we show that a simple nonconvex\nregularization transforms the min-max optimization problem into a\nnonconvex-proximal Polyak-Lojasiewicz (NC-pPL) objective. Crucially, this\nregularization can stabilize the iterates of independent policy gradient\nmethods and ultimately lead them to converge to equilibria. Second, building on\nthis reduction, we address the general constrained min-max problems under\nNC-pPL and two-sided pPL conditions, providing the first global convergence\nguarantees for stochastic nested and alternating gradient descent-ascent\nmethods, which we believe may be of independent interest.", "AI": {"tldr": "\u8bba\u6587\u9996\u6b21\u8bc1\u660e\u4e86\u5728\u4e24\u4eba\u96f6\u548c\u51f8\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u4e2d\uff0c\u72ec\u7acb\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u80fd\u5168\u5c40\u6536\u655b\u5230\u7eb3\u4ec0\u5747\u8861\u3002\u901a\u8fc7\u975e\u51f8\u6b63\u5219\u5316\u5c06\u95ee\u9898\u8f6c\u5316\u4e3aNC-pPL\u76ee\u6807\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u6536\u655b\u6027\u3002", "motivation": "\u51f8\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u6269\u5c55\u4e86\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5230\u591a\u667a\u80fd\u4f53\u573a\u666f\uff0c\u4f46\u5373\u4f7f\u662f\u6700\u5c0f-\u6700\u5927\u95ee\u9898\u4e5f\u5b58\u5728\u975e\u51f8\u6027\u3001\u7f3a\u4e4f\u8d1d\u5c14\u66fc\u4e00\u81f4\u6027\u7b49\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u7406\u8bba\u652f\u6301\u3002", "method": "\u91c7\u7528\u4e24\u6b65\u6cd5\uff1a1) \u5229\u7528\u9690\u85cf\u51f8-\u9690\u85cf\u51f9\u51fd\u6570\u6027\u8d28\uff0c\u901a\u8fc7\u975e\u51f8\u6b63\u5219\u5316\u5c06\u95ee\u9898\u8f6c\u5316\u4e3aNC-pPL\u76ee\u6807\uff1b2) \u5728NC-pPL\u6761\u4ef6\u4e0b\uff0c\u63d0\u51fa\u5e76\u5206\u6790\u968f\u673a\u5d4c\u5957\u548c\u4ea4\u66ff\u68af\u5ea6\u4e0b\u964d-\u4e0a\u5347\u65b9\u6cd5\u7684\u5168\u5c40\u6536\u655b\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u72ec\u7acb\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u5728\u51f8\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u4e2d\u80fd\u5168\u5c40\u6536\u655b\u5230\u7eb3\u4ec0\u5747\u8861\uff0c\u5e76\u63d0\u4f9b\u4e86\u968f\u673a\u68af\u5ea6\u65b9\u6cd5\u7684\u6536\u655b\u4fdd\u8bc1\u3002", "conclusion": "\u8bba\u6587\u4e3a\u51f8\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u4e2d\u7684\u7b56\u7565\u4f18\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5e76\u6269\u5c55\u4e86\u68af\u5ea6\u65b9\u6cd5\u5728\u975e\u51f8\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2506.16141", "pdf": "https://arxiv.org/pdf/2506.16141", "abs": "https://arxiv.org/abs/2506.16141", "authors": ["Yi Chen", "Yuying Ge", "Rui Wang", "Yixiao Ge", "Junhao Cheng", "Ying Shan", "Xihui Liu"], "title": "GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "Code released at: https://github.com/TencentARC/GRPO-CARE", "summary": "Recent reinforcement learning approaches, such as outcome-supervised GRPO,\nhave advanced Chain-of-Thought reasoning in large language models (LLMs), yet\ntheir adaptation to multimodal LLMs (MLLMs) is unexplored. To address the lack\nof rigorous evaluation for MLLM post-training methods, we introduce\nSEED-Bench-R1, a benchmark with complex real-world videos requiring balanced\nperception and reasoning. It offers a large training set and evaluates\ngeneralization across three escalating challenges: in-distribution,\ncross-environment, and cross-environment-task scenarios. Using SEED-Bench-R1,\nwe find that standard GRPO, while improving answer accuracy, often reduces\nlogical coherence between reasoning steps and answers, with only a 57.9%\nconsistency rate. This stems from reward signals focusing solely on final\nanswers, encouraging shortcuts, and strict KL penalties limiting exploration.To\naddress this, we propose GRPO-CARE, a consistency-aware RL framework optimizing\nboth answer correctness and reasoning coherence without explicit supervision.\nGRPO-CARE introduces a two-tiered reward: (1) a base reward for answer\ncorrectness, and (2) an adaptive consistency bonus, computed by comparing the\nmodel's reasoning-to-answer likelihood (via a slowly-evolving reference model)\nagainst group peers.This dual mechanism amplifies rewards for reasoning paths\nthat are both correct and logically consistent. Replacing KL penalties with\nthis adaptive bonus, GRPO-CARE outperforms standard GRPO on SEED-Bench-R1,\nachieving a 6.7% performance gain on the hardest evaluation level and a 24.5%\nimprovement in consistency. It also shows strong transferability, improving\nmodel performance across diverse video understanding benchmarks. Our work\ncontributes a systematically designed benchmark and a generalizable\npost-training framework, advancing the development of more interpretable and\nrobust MLLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86GRPO-CARE\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5c42\u6b21\u5956\u52b1\u673a\u5236\u4f18\u5316\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7b54\u6848\u6b63\u786e\u6027\u548c\u63a8\u7406\u4e00\u81f4\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08\u5982GRPO\uff09\u5728\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u4e2d\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u4e14\u7f3a\u4e4f\u4e25\u683c\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u63d0\u51faSEED-Bench-R1\u57fa\u51c6\uff0c\u5e76\u8bbe\u8ba1GRPO-CARE\u6846\u67b6\uff0c\u7ed3\u5408\u57fa\u7840\u5956\u52b1\u548c\u81ea\u9002\u5e94\u4e00\u81f4\u6027\u5956\u52b1\uff0c\u4f18\u5316\u6a21\u578b\u8868\u73b0\u3002", "result": "GRPO-CARE\u5728SEED-Bench-R1\u4e0a\u8868\u73b0\u4f18\u4e8e\u6807\u51c6GRPO\uff0c\u6027\u80fd\u63d0\u53476.7%\uff0c\u4e00\u81f4\u6027\u63d0\u9ad824.5%\u3002", "conclusion": "GRPO-CARE\u4e3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u63a8\u5e7f\u7684\u540e\u8bad\u7ec3\u6846\u67b6\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.16144", "pdf": "https://arxiv.org/pdf/2506.16144", "abs": "https://arxiv.org/abs/2506.16144", "authors": ["Ana Kostovska", "Carola Doerr", "Sa\u0161o D\u017eeroski", "Pan\u010de Panov", "Tome Eftimov"], "title": "Geometric Learning in Black-Box Optimization: A GNN Framework for Algorithm Performance Prediction", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Automated algorithm performance prediction in numerical blackbox optimization\noften relies on problem characterizations, such as exploratory landscape\nanalysis features. These features are typically used as inputs to machine\nlearning models and are represented in a tabular format. However, such\napproaches often overlook algorithm configurations, a key factor influencing\nperformance. The relationships between algorithm operators, parameters, problem\ncharacteristics, and performance outcomes form a complex structure best\nrepresented as a graph. This work explores the use of heterogeneous graph data\nstructures and graph neural networks to predict the performance of optimization\nalgorithms by capturing the complex dependencies between problems, algorithm\nconfigurations, and performance outcomes. We focus on two modular frameworks,\nmodCMA-ES and modDE, which decompose two widely used derivative-free\noptimization algorithms: the covariance matrix adaptation evolution strategy\n(CMA-ES) and differential evolution (DE). We evaluate 324 modCMA-ES and 576\nmodDE variants on 24 BBOB problems across six runtime budgets and two problem\ndimensions. Achieving up to 36.6% improvement in MSE over traditional\ntabular-based methods, this work highlights the potential of geometric learning\nin black-box optimization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u9884\u6d4b\u9ed1\u76d2\u4f18\u5316\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u6355\u6349\u95ee\u9898\u3001\u7b97\u6cd5\u914d\u7f6e\u548c\u6027\u80fd\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\uff0c\u76f8\u6bd4\u4f20\u7edf\u8868\u683c\u65b9\u6cd5\u63d0\u5347\u4e8636.6%\u7684MSE\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u901a\u5e38\u5ffd\u7565\u7b97\u6cd5\u914d\u7f6e\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u800c\u95ee\u9898\u7279\u5f81\u4e0e\u7b97\u6cd5\u6027\u80fd\u4e4b\u95f4\u7684\u5173\u7cfb\u66f4\u9002\u5408\u7528\u56fe\u7ed3\u6784\u8868\u793a\u3002", "method": "\u4f7f\u7528\u5f02\u6784\u56fe\u6570\u636e\u7ed3\u6784\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u5bf9\u4e24\u79cd\u6a21\u5757\u5316\u6846\u67b6\uff08modCMA-ES\u548cmodDE\uff09\u7684\u6027\u80fd\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u5728324\u79cdmodCMA-ES\u548c576\u79cdmodDE\u53d8\u4f53\u4e0a\u6d4b\u8bd5\uff0cMSE\u63d0\u5347\u4e8636.6%\u3002", "conclusion": "\u51e0\u4f55\u5b66\u4e60\u5728\u9ed1\u76d2\u4f18\u5316\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\u3002"}}
{"id": "2506.16189", "pdf": "https://arxiv.org/pdf/2506.16189", "abs": "https://arxiv.org/abs/2506.16189", "authors": ["Putri A. van der Linden", "Alexander Timans", "Erik J. Bekkers"], "title": "CP$^2$: Leveraging Geometry for Conformal Prediction via Canonicalization", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": "17 pages, 7 figures, 9 tables (including appendix); published at UAI\n  2025", "summary": "We study the problem of conformal prediction (CP) under geometric data\nshifts, where data samples are susceptible to transformations such as rotations\nor flips. While CP endows prediction models with post-hoc uncertainty\nquantification and formal coverage guarantees, their practicality breaks under\ndistribution shifts that deteriorate model performance. To address this issue,\nwe propose integrating geometric information--such as geometric pose--into the\nconformal procedure to reinstate its guarantees and ensure robustness under\ngeometric shifts. In particular, we explore recent advancements on pose\ncanonicalization as a suitable information extractor for this purpose.\nEvaluating the combined approach across discrete and continuous shifts and\nagainst equivariant and augmentation-based baselines, we find that integrating\ngeometric information with CP yields a principled way to address geometric\nshifts while maintaining broad applicability to black-box predictors.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u51e0\u4f55\u6570\u636e\u53d8\u6362\u4e0b\uff08\u5982\u65cb\u8f6c\u6216\u7ffb\u8f6c\uff09\u7684\u5171\u5f62\u9884\u6d4b\u95ee\u9898\uff0c\u63d0\u51fa\u901a\u8fc7\u6574\u5408\u51e0\u4f55\u4fe1\u606f\uff08\u5982\u51e0\u4f55\u59ff\u6001\uff09\u6765\u6062\u590d\u5171\u5f62\u9884\u6d4b\u7684\u4fdd\u8bc1\uff0c\u5e76\u5728\u51e0\u4f55\u53d8\u6362\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "motivation": "\u5171\u5f62\u9884\u6d4b\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u5b9e\u7528\u6027\u53d7\u9650\uff0c\u5c24\u5176\u662f\u51e0\u4f55\u53d8\u6362\u4f1a\u964d\u4f4e\u6a21\u578b\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u6062\u590d\u5176\u4fdd\u8bc1\u5e76\u589e\u5f3a\u9c81\u68d2\u6027\u3002", "method": "\u6574\u5408\u51e0\u4f55\u4fe1\u606f\uff08\u5982\u51e0\u4f55\u59ff\u6001\uff09\u5230\u5171\u5f62\u9884\u6d4b\u8fc7\u7a0b\u4e2d\uff0c\u5229\u7528\u59ff\u6001\u89c4\u8303\u5316\u4f5c\u4e3a\u4fe1\u606f\u63d0\u53d6\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7ed3\u5408\u51e0\u4f55\u4fe1\u606f\u4e0e\u5171\u5f62\u9884\u6d4b\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u51e0\u4f55\u53d8\u6362\uff0c\u540c\u65f6\u9002\u7528\u4e8e\u9ed1\u76d2\u9884\u6d4b\u5668\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u51e0\u4f55\u4fe1\u606f\uff0c\u5171\u5f62\u9884\u6d4b\u5728\u51e0\u4f55\u53d8\u6362\u4e0b\u4ecd\u80fd\u4fdd\u6301\u5176\u4fdd\u8bc1\u548c\u9c81\u68d2\u6027\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2506.16209", "pdf": "https://arxiv.org/pdf/2506.16209", "abs": "https://arxiv.org/abs/2506.16209", "authors": ["Annajoyce Mariani", "Kira Maag", "Hanno Gottschalk"], "title": "VideoGAN-based Trajectory Proposal for Automated Vehicles", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Being able to generate realistic trajectory options is at the core of\nincreasing the degree of automation of road vehicles. While model-driven,\nrule-based, and classical learning-based methods are widely used to tackle\nthese tasks at present, they can struggle to effectively capture the complex,\nmultimodal distributions of future trajectories. In this paper we investigate\nwhether a generative adversarial network (GAN) trained on videos of bird's-eye\nview (BEV) traffic scenarios can generate statistically accurate trajectories\nthat correctly capture spatial relationships between the agents. To this end,\nwe propose a pipeline that uses low-resolution BEV occupancy grid videos as\ntraining data for a video generative model. From the generated videos of\ntraffic scenarios we extract abstract trajectory data using single-frame object\ndetection and frame-to-frame object matching. We particularly choose a GAN\narchitecture for the fast training and inference times with respect to\ndiffusion models. We obtain our best results within 100 GPU hours of training,\nwith inference times under 20\\,ms. We demonstrate the physical realism of the\nproposed trajectories in terms of distribution alignment of spatial and dynamic\nparameters with respect to the ground truth videos from the Waymo Open Motion\nDataset.", "AI": {"tldr": "\u4f7f\u7528\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u4ece\u9e1f\u77b0\u56fe\uff08BEV\uff09\u89c6\u9891\u4e2d\u751f\u6210\u7edf\u8ba1\u51c6\u786e\u7684\u4ea4\u901a\u8f68\u8ff9\uff0c\u4ee5\u6355\u6349\u590d\u6742\u591a\u6a21\u6001\u5206\u5e03\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u6355\u6349\u672a\u6765\u8f68\u8ff9\u7684\u590d\u6742\u591a\u6a21\u6001\u5206\u5e03\uff0c\u56e0\u6b64\u63a2\u7d22GAN\u5728\u751f\u6210\u771f\u5b9e\u8f68\u8ff9\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4f4e\u5206\u8fa8\u7387BEV\u5360\u7528\u7f51\u683c\u89c6\u9891\u7684GAN\u8bad\u7ec3\u7ba1\u9053\uff0c\u4ece\u4e2d\u63d0\u53d6\u62bd\u8c61\u8f68\u8ff9\u6570\u636e\u3002", "result": "\u5728100 GPU\u5c0f\u65f6\u5185\u5b8c\u6210\u8bad\u7ec3\uff0c\u63a8\u7406\u65f6\u95f4\u4f4e\u4e8e20\u6beb\u79d2\uff0c\u751f\u6210\u7684\u8f68\u8ff9\u5728\u7a7a\u95f4\u548c\u52a8\u6001\u53c2\u6570\u4e0a\u4e0e\u771f\u5b9e\u6570\u636e\u5bf9\u9f50\u3002", "conclusion": "GAN\u80fd\u9ad8\u6548\u751f\u6210\u7269\u7406\u771f\u5b9e\u7684\u4ea4\u901a\u8f68\u8ff9\uff0c\u9002\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u3002"}}
{"id": "2506.16224", "pdf": "https://arxiv.org/pdf/2506.16224", "abs": "https://arxiv.org/abs/2506.16224", "authors": ["Bishwajit Prasad Gond", "Rajneekant", "Pushkar Kishore", "Durga Prasad Mohapatra"], "title": "Malware Classification Leveraging NLP & Machine Learning for Enhanced Accuracy", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "This paper investigates the application of natural language processing\n(NLP)-based n-gram analysis and machine learning techniques to enhance malware\nclassification. We explore how NLP can be used to extract and analyze textual\nfeatures from malware samples through n-grams, contiguous string or API call\nsequences. This approach effectively captures distinctive linguistic patterns\namong malware and benign families, enabling finer-grained classification. We\ndelve into n-gram size selection, feature representation, and classification\nalgorithms. While evaluating our proposed method on real-world malware samples,\nwe observe significantly improved accuracy compared to the traditional methods.\nBy implementing our n-gram approach, we achieved an accuracy of 99.02% across\nvarious machine learning algorithms by using hybrid feature selection technique\nto address high dimensionality. Hybrid feature selection technique reduces the\nfeature set to only 1.6% of the original features.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8eNLP\u7684n-gram\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u6280\u672f\u7528\u4e8e\u63d0\u5347\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u548c\u5206\u6790\u6587\u672c\u7279\u5f81\uff0c\u5b9e\u73b0\u4e8699.02%\u7684\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u5229\u7528NLP\u6280\u672f\u4ece\u6076\u610f\u8f6f\u4ef6\u6837\u672c\u4e2d\u63d0\u53d6\u6587\u672c\u7279\u5f81\uff0c\u4ee5\u6539\u8fdb\u4f20\u7edf\u5206\u7c7b\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528n-gram\u5206\u6790\u63d0\u53d6\u6587\u672c\u7279\u5f81\uff0c\u7ed3\u5408\u6df7\u5408\u7279\u5f81\u9009\u62e9\u6280\u672f\u964d\u4f4e\u7ef4\u5ea6\uff0c\u5e76\u4f7f\u7528\u591a\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5728\u771f\u5b9e\u6076\u610f\u8f6f\u4ef6\u6837\u672c\u4e0a\u6d4b\u8bd5\uff0c\u51c6\u786e\u7387\u8fbe\u523099.02%\uff0c\u7279\u5f81\u7ef4\u5ea6\u964d\u81f3\u539f\u59cb\u7279\u5f81\u76841.6%\u3002", "conclusion": "NLP\u548cn-gram\u5206\u6790\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u80fd\u663e\u8457\u63d0\u5347\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2506.16233", "pdf": "https://arxiv.org/pdf/2506.16233", "abs": "https://arxiv.org/abs/2506.16233", "authors": ["Chenrui Ma", "Zechang Sun", "Tao Jing", "Zheng Cai", "Yuan-Sen Ting", "Song Huang", "Mingyu Li"], "title": "Can AI Dream of Unseen Galaxies? Conditional Diffusion Model for Galaxy Morphology Augmentation", "categories": ["astro-ph.GA", "cs.LG"], "comment": "We have submitted to AAS journals. See another independent work for\n  further reference -- Category-based Galaxy Image Generation via Diffusion\n  Models (Fan, Tang et al.). Comments are welcome", "summary": "Observational astronomy relies on visual feature identification to detect\ncritical astrophysical phenomena. While machine learning (ML) increasingly\nautomates this process, models often struggle with generalization in\nlarge-scale surveys due to the limited representativeness of labeled datasets\n-- whether from simulations or human annotation -- a challenge pronounced for\nrare yet scientifically valuable objects. To address this, we propose a\nconditional diffusion model to synthesize realistic galaxy images for\naugmenting ML training data. Leveraging the Galaxy Zoo 2 dataset which contains\nvisual feature -- galaxy image pairs from volunteer annotation, we demonstrate\nthat our model generates diverse, high-fidelity galaxy images closely adhere to\nthe specified morphological feature conditions. Moreover, this model enables\ngenerative extrapolation to project well-annotated data into unseen domains and\nadvancing rare object detection. Integrating synthesized images into ML\npipelines improves performance in standard morphology classification, boosting\ncompleteness and purity by up to 30\\% across key metrics. For rare object\ndetection, using early-type galaxies with prominent dust lane features (\n$\\sim$0.1\\% in GZ2 dataset) as a test case, our approach doubled the number of\ndetected instances from 352 to 872, compared to previous studies based on\nvisual inspection. This study highlights the power of generative models to\nbridge gaps between scarce labeled data and the vast, uncharted parameter space\nof observational astronomy and sheds insight for future astrophysical\nfoundation model developments. Our project homepage is available at\nhttps://galaxysd-webpage.streamlit.app/.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6761\u4ef6\u6269\u6563\u6a21\u578b\uff0c\u7528\u4e8e\u751f\u6210\u903c\u771f\u7684\u661f\u7cfb\u56fe\u50cf\u4ee5\u589e\u5f3a\u673a\u5668\u5b66\u4e60\u8bad\u7ec3\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f62\u6001\u5206\u7c7b\u548c\u7a00\u6709\u5929\u4f53\u68c0\u6d4b\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5929\u6587\u89c2\u6d4b\u4e2d\u56e0\u6807\u8bb0\u6570\u636e\u6709\u9650\u800c\u5bfc\u81f4\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5bf9\u7a00\u6709\u4f46\u79d1\u5b66\u4ef7\u503c\u9ad8\u7684\u5929\u4f53\u3002", "method": "\u5229\u7528Galaxy Zoo 2\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u6761\u4ef6\u6269\u6563\u6a21\u578b\u751f\u6210\u7b26\u5408\u5f62\u6001\u7279\u5f81\u7684\u661f\u7cfb\u56fe\u50cf\uff0c\u5e76\u901a\u8fc7\u751f\u6210\u5916\u63a8\u6269\u5c55\u6570\u636e\u8303\u56f4\u3002", "result": "\u5408\u6210\u56fe\u50cf\u63d0\u5347\u4e86\u5f62\u6001\u5206\u7c7b\u7684\u5b8c\u6574\u6027\u548c\u7eaf\u5ea6\u8fbe30%\uff0c\u7a00\u6709\u5929\u4f53\uff08\u5982\u65e9\u671f\u578b\u661f\u7cfb\uff09\u68c0\u6d4b\u6570\u91cf\u4ece352\u589e\u52a0\u5230872\u3002", "conclusion": "\u751f\u6210\u6a21\u578b\u80fd\u591f\u586b\u8865\u6807\u8bb0\u6570\u636e\u7a00\u7f3a\u4e0e\u5929\u6587\u89c2\u6d4b\u5e7f\u9614\u53c2\u6570\u7a7a\u95f4\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u672a\u6765\u5929\u4f53\u7269\u7406\u57fa\u7840\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u542f\u793a\u3002"}}
{"id": "2506.16283", "pdf": "https://arxiv.org/pdf/2506.16283", "abs": "https://arxiv.org/abs/2506.16283", "authors": ["Mike Nguyen", "Nicole M\u00fccke"], "title": "Random feature approximation for general spectral methods", "categories": ["stat.ML", "cs.LG"], "comment": "arXiv admin note: substantial text overlap with arXiv:2308.15434,\n  arXiv:2412.17518", "summary": "Random feature approximation is arguably one of the most widely used\ntechniques for kernel methods in large-scale learning algorithms. In this work,\nwe analyze the generalization properties of random feature methods, extending\nprevious results for Tikhonov regularization to a broad class of spectral\nregularization techniques. This includes not only explicit methods but also\nimplicit schemes such as gradient descent and accelerated algorithms like the\nHeavy-Ball and Nesterov method. Through this framework, we enable a theoretical\nanalysis of neural networks and neural operators through the lens of the Neural\nTangent Kernel (NTK) approach trained via gradient descent. For our estimators\nwe obtain optimal learning rates over regularity classes (even for classes that\nare not included in the reproducing kernel Hilbert space), which are defined\nthrough appropriate source conditions. This improves or completes previous\nresults obtained in related settings for specific kernel algorithms.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u968f\u673a\u7279\u5f81\u65b9\u6cd5\u7684\u6cdb\u5316\u6027\u8d28\uff0c\u6269\u5c55\u4e86Tikhonov\u6b63\u5219\u5316\u7684\u7ed3\u679c\uff0c\u6db5\u76d6\u591a\u79cd\u8c31\u6b63\u5219\u5316\u6280\u672f\uff0c\u5305\u62ec\u68af\u5ea6\u4e0b\u964d\u548c\u52a0\u901f\u7b97\u6cd5\u3002\u901a\u8fc7NTK\u6846\u67b6\uff0c\u7406\u8bba\u5206\u6790\u4e86\u795e\u7ecf\u7f51\u7edc\u548c\u795e\u7ecf\u7b97\u5b50\uff0c\u83b7\u5f97\u4e86\u6700\u4f18\u5b66\u4e60\u7387\u3002", "motivation": "\u968f\u673a\u7279\u5f81\u8fd1\u4f3c\u662f\u6838\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u5b66\u4e60\u7b97\u6cd5\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u6280\u672f\uff0c\u4f46\u5bf9\u5176\u6cdb\u5316\u6027\u8d28\u7684\u7406\u8bba\u5206\u6790\u5c1a\u4e0d\u5b8c\u5584\uff0c\u5c24\u5176\u662f\u6269\u5c55\u5230\u591a\u79cd\u6b63\u5219\u5316\u6280\u672f\u548c\u795e\u7ecf\u7f51\u7edc\u573a\u666f\u3002", "method": "\u6269\u5c55\u4e86Tikhonov\u6b63\u5219\u5316\u7684\u7ed3\u679c\uff0c\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\u5206\u6790\u591a\u79cd\u8c31\u6b63\u5219\u5316\u6280\u672f\uff08\u5982\u68af\u5ea6\u4e0b\u964d\u3001Heavy-Ball\u548cNesterov\u65b9\u6cd5\uff09\uff0c\u5e76\u901a\u8fc7NTK\u7406\u8bba\u5206\u6790\u795e\u7ecf\u7f51\u7edc\u3002", "result": "\u5728\u9002\u5f53\u7684\u6e90\u6761\u4ef6\u4e0b\uff0c\u83b7\u5f97\u4e86\u6700\u4f18\u5b66\u4e60\u7387\uff0c\u5373\u4f7f\u5bf9\u4e8e\u4e0d\u5728\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u7684\u7c7b\u522b\u4e5f\u9002\u7528\uff0c\u6539\u8fdb\u6216\u5b8c\u5584\u4e86\u5148\u524d\u76f8\u5173\u7ed3\u679c\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u968f\u673a\u7279\u5f81\u65b9\u6cd5\u548c\u795e\u7ecf\u7f51\u7edc\u7684\u6cdb\u5316\u6027\u8d28\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u7406\u8bba\u652f\u6301\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u6280\u672f\u7684\u9002\u7528\u8303\u56f4\u3002"}}
{"id": "2506.16289", "pdf": "https://arxiv.org/pdf/2506.16289", "abs": "https://arxiv.org/abs/2506.16289", "authors": ["Oswaldo Ludwig"], "title": "The Condition Number as a Scale-Invariant Proxy for Information Encoding in Neural Units", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This paper explores the relationship between the condition number of a neural\nnetwork's weight tensor and the extent of information encoded by the associated\nprocessing unit, viewed through the lens of information theory. We argue that a\nhigh condition number, though not sufficient for effective knowledge encoding,\nmay indicate that the unit has learned to selectively amplify and compress\ninformation. We formalize this intuition, particularly for linear units with\nGaussian inputs, linking the condition number and the transformation's\nlog-volume scaling factor to the characteristics of the output entropy and the\ngeometric properties of the learned transformation. Our analysis demonstrates\nthat for a fixed weight norm, a concentrated distribution of singular values\n(high condition number) corresponds to reduced overall information transfer,\nindicating a specialized and efficient encoding strategy. Furthermore, we\npresent a practical case study where these principles are applied to guide\nselective fine-tuning of a multimodal Large Language Model, aiming to mitigate\ncatastrophic forgetting during cross-modal adaptation. Unlike many existing\ncatastrophic forgetting mitigation methods that rely on access to pre-training\nstatistics, which are often unavailable, our selective fine-tuning approach\noffers a way to bypass this common requirement.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\u5f20\u91cf\u7684\u6761\u4ef6\u6570\u4e0e\u4fe1\u606f\u7f16\u7801\u6548\u7387\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u9ad8\u6761\u4ef6\u6570\u53ef\u80fd\u8868\u660e\u5355\u5143\u9009\u62e9\u6027\u5730\u653e\u5927\u548c\u538b\u7f29\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u7ebf\u6027\u5355\u5143\u548c\u9ad8\u65af\u8f93\u5165\u7684\u6848\u4f8b\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u89c2\u70b9\u3002", "motivation": "\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u4e2d\u6743\u91cd\u5f20\u91cf\u7684\u6761\u4ef6\u6570\u5982\u4f55\u53cd\u6620\u4fe1\u606f\u7f16\u7801\u7684\u6548\u7387\uff0c\u4e3a\u7406\u89e3\u7f51\u7edc\u5b66\u4e60\u673a\u5236\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "method": "\u901a\u8fc7\u4fe1\u606f\u8bba\u6846\u67b6\u5206\u6790\u6761\u4ef6\u6570\u4e0e\u4fe1\u606f\u71b5\u7684\u5173\u7cfb\uff0c\u7ed3\u5408\u7ebf\u6027\u5355\u5143\u548c\u9ad8\u65af\u8f93\u5165\u7684\u6570\u5b66\u6a21\u578b\uff0c\u5e76\u5e94\u7528\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5fae\u8c03\u3002", "result": "\u9ad8\u6761\u4ef6\u6570\u5bf9\u5e94\u8f83\u4f4e\u7684\u4fe1\u606f\u4f20\u9012\u603b\u91cf\uff0c\u8868\u660e\u9ad8\u6548\u7684\u7f16\u7801\u7b56\u7565\uff1b\u9009\u62e9\u6027\u5fae\u8c03\u65b9\u6cd5\u53ef\u7f13\u89e3\u8de8\u6a21\u6001\u9002\u5e94\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u3002", "conclusion": "\u6761\u4ef6\u6570\u53ef\u4f5c\u4e3a\u4fe1\u606f\u7f16\u7801\u6548\u7387\u7684\u6307\u6807\uff0c\u9009\u62e9\u6027\u5fae\u8c03\u65b9\u6cd5\u4e3a\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\u63d0\u4f9b\u4e86\u65e0\u9700\u9884\u8bad\u7ec3\u7edf\u8ba1\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16297", "pdf": "https://arxiv.org/pdf/2506.16297", "abs": "https://arxiv.org/abs/2506.16297", "authors": ["Heng Zhang", "Zikang Wan", "Danilo Vasconcellos Vargas"], "title": "SycnMapV2: Robust and Adaptive Unsupervised Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Human vision excels at segmenting visual cues without the need for explicit\ntraining, and it remains remarkably robust even as noise severity increases. In\ncontrast, existing AI algorithms struggle to maintain accuracy under similar\nconditions. Here, we present SyncMapV2, the first to solve unsupervised\nsegmentation with state-of-the-art robustness. SyncMapV2 exhibits a minimal\ndrop in mIoU, only 0.01%, under digital corruption, compared to a 23.8% drop\nobserved in SOTA methods.This superior performance extends across various types\nof corruption: noise (7.3% vs. 37.7%), weather (7.5% vs. 33.8%), and blur (7.0%\nvs. 29.5%). Notably, SyncMapV2 accomplishes this without any robust training,\nsupervision, or loss functions. It is based on a learning paradigm that uses\nself-organizing dynamical equations combined with concepts from random\nnetworks. Moreover,unlike conventional methods that require re-initialization\nfor each new input, SyncMapV2 adapts online, mimicking the continuous\nadaptability of human vision. Thus, we go beyond the accurate and robust\nresults, and present the first algorithm that can do all the above online,\nadapting to input rather than re-initializing. In adaptability tests, SyncMapV2\ndemonstrates near-zero performance degradation, which motivates and fosters a\nnew generation of robust and adaptive intelligence in the near future.", "AI": {"tldr": "SyncMapV2\u662f\u4e00\u79cd\u65e0\u76d1\u7763\u5206\u5272\u7b97\u6cd5\uff0c\u5177\u6709\u5353\u8d8a\u7684\u9c81\u68d2\u6027\uff0c\u80fd\u5728\u566a\u58f0\u3001\u5929\u6c14\u548c\u6a21\u7cca\u7b49\u5e72\u6270\u4e0b\u4fdd\u6301\u9ad8\u7cbe\u5ea6\uff0c\u4e14\u65e0\u9700\u91cd\u65b0\u521d\u59cb\u5316\u3002", "motivation": "\u4eba\u7c7b\u89c6\u89c9\u5728\u65e0\u660e\u786e\u8bad\u7ec3\u4e0b\u4ecd\u80fd\u6709\u6548\u5206\u5272\u89c6\u89c9\u7ebf\u7d22\uff0c\u800c\u73b0\u6709AI\u7b97\u6cd5\u5728\u7c7b\u4f3c\u6761\u4ef6\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002SyncMapV2\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u81ea\u7ec4\u7ec7\u52a8\u529b\u5b66\u65b9\u7a0b\u548c\u968f\u673a\u7f51\u7edc\u6982\u5ff5\uff0c\u65e0\u9700\u9c81\u68d2\u8bad\u7ec3\u6216\u76d1\u7763\u3002", "result": "\u5728\u6570\u5b57\u5e72\u6270\u4e0b\uff0cmIoU\u4ec5\u4e0b\u964d0.01%\uff0c\u8fdc\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0823.8%\uff09\u3002\u5728\u566a\u58f0\u3001\u5929\u6c14\u548c\u6a21\u7cca\u5e72\u6270\u4e0b\u8868\u73b0\u540c\u6837\u51fa\u8272\u3002", "conclusion": "SyncMapV2\u9996\u6b21\u5b9e\u73b0\u4e86\u5728\u7ebf\u81ea\u9002\u5e94\u5206\u5272\uff0c\u4e3a\u672a\u6765\u9c81\u68d2\u81ea\u9002\u5e94\u667a\u80fd\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.16332", "pdf": "https://arxiv.org/pdf/2506.16332", "abs": "https://arxiv.org/abs/2506.16332", "authors": ["Lukas Gonon", "Rodrigo Mart\u00ednez-Pe\u00f1a", "Juan-Pablo Ortega"], "title": "Feedback-driven recurrent quantum neural network universality", "categories": ["quant-ph", "cs.LG"], "comment": "31 pages", "summary": "Quantum reservoir computing uses the dynamics of quantum systems to process\ntemporal data, making it particularly well-suited for learning with noisy\nintermediate-scale quantum devices. Early experimental proposals, such as the\nrestarting and rewinding protocols, relied on repeating previous steps of the\nquantum map to avoid backaction. However, this approach compromises real-time\nprocessing and increases computational overhead. Recent developments have\nintroduced alternative protocols that address these limitations. These include\nonline, mid-circuit measurement, and feedback techniques, which enable\nreal-time computation while preserving the input history. Among these, the\nfeedback protocol stands out for its ability to process temporal information\nwith comparatively fewer components. Despite this potential advantage, the\ntheoretical foundations of feedback-based quantum reservoir computing remain\nunderdeveloped, particularly with regard to the universality and the\napproximation capabilities of this approach. This paper addresses this issue by\npresenting a recurrent quantum neural network architecture that extends a class\nof existing feedforward models to a dynamic, feedback-driven reservoir setting.\nWe provide theoretical guarantees for variational recurrent quantum neural\nnetworks, including approximation bounds and universality results. Notably, our\nanalysis demonstrates that the model is universal with linear readouts, making\nit both powerful and experimentally accessible. These results pave the way for\npractical and theoretically grounded quantum reservoir computing with real-time\nprocessing capabilities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cd\u9988\u7684\u91cf\u5b50\u50a8\u5c42\u8ba1\u7b97\u67b6\u6784\uff0c\u89e3\u51b3\u4e86\u65e9\u671f\u534f\u8bae\u5728\u5b9e\u65f6\u5904\u7406\u548c\u8ba1\u7b97\u5f00\u9500\u4e0a\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u3002", "motivation": "\u65e9\u671f\u91cf\u5b50\u50a8\u5c42\u8ba1\u7b97\u534f\u8bae\uff08\u5982\u91cd\u542f\u548c\u56de\u7ed5\u534f\u8bae\uff09\u56e0\u91cd\u590d\u6b65\u9aa4\u5bfc\u81f4\u5b9e\u65f6\u5904\u7406\u80fd\u529b\u53d7\u9650\u548c\u8ba1\u7b97\u5f00\u9500\u589e\u52a0\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cd\u9988\u7684\u5faa\u73af\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u524d\u9988\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u4e86\u8fd1\u4f3c\u8fb9\u754c\u548c\u666e\u9002\u6027\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "\u8be5\u6a21\u578b\u5728\u5177\u6709\u7ebf\u6027\u8bfb\u51fa\u65f6\u5177\u6709\u666e\u9002\u6027\uff0c\u65e2\u5f3a\u5927\u53c8\u6613\u4e8e\u5b9e\u9a8c\u5b9e\u73b0\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5177\u6709\u5b9e\u65f6\u5904\u7406\u80fd\u529b\u7684\u91cf\u5b50\u50a8\u5c42\u8ba1\u7b97\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u57fa\u7840\u3002"}}
{"id": "2506.16385", "pdf": "https://arxiv.org/pdf/2506.16385", "abs": "https://arxiv.org/abs/2506.16385", "authors": ["Santosh Patapati", "Trisanth Srinivasan", "Amith Adiraju"], "title": "CLIP-MG: Guiding Semantic Attention with Skeletal Pose Features and RGB Data for Micro-Gesture Recognition on the iMiGUE Dataset", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Micro-gesture recognition is a challenging task in affective computing due to\nthe subtle, involuntary nature of the gestures and their low movement\namplitude. In this paper, we introduce a Pose-Guided Semantics-Aware CLIP-based\narchitecture, or CLIP for Micro-Gesture recognition (CLIP-MG), a modified CLIP\nmodel tailored for micro-gesture classification on the iMiGUE dataset. CLIP-MG\nintegrates human pose (skeleton) information into the CLIP-based recognition\npipeline through pose-guided semantic query generation and a gated multi-modal\nfusion mechanism. The proposed model achieves a Top-1 accuracy of 61.82%. These\nresults demonstrate both the potential of our approach and the remaining\ndifficulty in fully adapting vision-language models like CLIP for micro-gesture\nrecognition.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCLIP\u7684\u67b6\u6784\uff08CLIP-MG\uff09\uff0c\u7528\u4e8e\u5fae\u624b\u52bf\u8bc6\u522b\uff0c\u901a\u8fc7\u7ed3\u5408\u59ff\u6001\u4fe1\u606f\u548c\u591a\u6a21\u6001\u878d\u5408\u673a\u5236\uff0c\u5728iMiGUE\u6570\u636e\u96c6\u4e0a\u8fbe\u523061.82%\u7684Top-1\u51c6\u786e\u7387\u3002", "motivation": "\u5fae\u624b\u52bf\u56e0\u5176\u7ec6\u5fae\u3001\u975e\u81ea\u613f\u6027\u548c\u4f4e\u5e45\u5ea6\u8fd0\u52a8\uff0c\u5728\u60c5\u611f\u8ba1\u7b97\u4e2d\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u91c7\u7528Pose-Guided Semantics-Aware CLIP\u67b6\u6784\uff0c\u7ed3\u5408\u59ff\u6001\u5f15\u5bfc\u7684\u8bed\u4e49\u67e5\u8be2\u751f\u6210\u548c\u95e8\u63a7\u591a\u6a21\u6001\u878d\u5408\u673a\u5236\u3002", "result": "\u6a21\u578b\u5728iMiGUE\u6570\u636e\u96c6\u4e0a\u7684Top-1\u51c6\u786e\u7387\u4e3a61.82%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u6f5c\u529b\uff0c\u4f46\u4e5f\u8868\u660e\u5b8c\u5168\u9002\u5e94\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08\u5982CLIP\uff09\u4e8e\u5fae\u624b\u52bf\u8bc6\u522b\u4ecd\u5177\u6311\u6218\u6027\u3002"}}
{"id": "2506.16394", "pdf": "https://arxiv.org/pdf/2506.16394", "abs": "https://arxiv.org/abs/2506.16394", "authors": ["Zelin Xiao", "Jia Gu", "Song Xi Chen"], "title": "Identifying Heterogeneity in Distributed Learning", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We study methods for identifying heterogeneous parameter components in\ndistributed M-estimation with minimal data transmission. One is based on a\nre-normalized Wald test, which is shown to be consistent as long as the number\nof distributed data blocks $K$ is of a smaller order of the minimum block\nsample size {and the level of heterogeneity is dense}. The second one is an\nextreme contrast test (ECT) based on the difference between the largest and\nsmallest component-wise estimated parameters among data blocks. By introducing\na sample splitting procedure, the ECT can avoid the bias accumulation arising\nfrom the M-estimation procedures, and exhibits consistency for $K$ being much\nlarger than the sample size while the heterogeneity is sparse. The ECT\nprocedure is easy to operate and communication-efficient. A combination of the\nWald and the extreme contrast tests is formulated to attain more robust power\nunder varying levels of sparsity of the heterogeneity. We also conduct\nintensive numerical experiments to compare the family-wise error rate (FWER)\nand the power of the proposed methods. Additionally, we conduct a case study to\npresent the implementation and validity of the proposed methods.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u5206\u5e03\u5f0fM\u4f30\u8ba1\u4e2d\u8bc6\u522b\u5f02\u8d28\u6027\u53c2\u6570\u5206\u91cf\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u6d4b\u8bd5\u65b9\u6cd5\uff1a\u57fa\u4e8e\u91cd\u5f52\u4e00\u5316Wald\u68c0\u9a8c\u7684\u65b9\u6cd5\u548c\u57fa\u4e8e\u6781\u7aef\u5bf9\u6bd4\u68c0\u9a8c\uff08ECT\uff09\u7684\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u548c\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5728\u5206\u5e03\u5f0fM\u4f30\u8ba1\u4e2d\uff0c\u8bc6\u522b\u5f02\u8d28\u6027\u53c2\u6570\u5206\u91cf\u662f\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u6570\u636e\u5757\u6570\u91cfK\u8f83\u5927\u6216\u5f02\u8d28\u6027\u7a00\u758f\u65f6\u8868\u73b0\u4e0d\u4f73\u3002\u672c\u6587\u65e8\u5728\u63d0\u51fa\u66f4\u9ad8\u6548\u4e14\u901a\u4fe1\u6210\u672c\u4f4e\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a1\uff09\u57fa\u4e8e\u91cd\u5f52\u4e00\u5316Wald\u68c0\u9a8c\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8eK\u8f83\u5c0f\u4e14\u5f02\u8d28\u6027\u5bc6\u96c6\u7684\u60c5\u51b5\uff1b2\uff09\u57fa\u4e8e\u6781\u7aef\u5bf9\u6bd4\u68c0\u9a8c\uff08ECT\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6837\u672c\u5206\u5272\u907f\u514d\u504f\u5dee\u7d2f\u79ef\uff0c\u9002\u7528\u4e8eK\u8f83\u5927\u4e14\u5f02\u8d28\u6027\u7a00\u758f\u7684\u60c5\u51b5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e24\u79cd\u65b9\u6cd5\u5728\u63a7\u5236\u5bb6\u65cf\u9519\u8bef\u7387\uff08FWER\uff09\u548c\u68c0\u9a8c\u529f\u6548\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4e14ECT\u65b9\u6cd5\u5728\u901a\u4fe1\u6548\u7387\u548c\u64cd\u4f5c\u7b80\u4fbf\u6027\u4e0a\u5177\u6709\u4f18\u52bf\u3002", "conclusion": "\u7ed3\u5408Wald\u68c0\u9a8c\u548cECT\u7684\u65b9\u6cd5\u5728\u4e0d\u540c\u5f02\u8d28\u6027\u7a00\u758f\u7a0b\u5ea6\u4e0b\u5747\u8868\u73b0\u51fa\u7a33\u5065\u7684\u68c0\u9a8c\u529f\u6548\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2506.16402", "pdf": "https://arxiv.org/pdf/2506.16402", "abs": "https://arxiv.org/abs/2506.16402", "authors": ["Xiaoya Lu", "Zeren Chen", "Xuhao Hu", "Yijin Zhou", "Weichen Zhang", "Dongrui Liu", "Lu Sheng", "Jing Shao"], "title": "IS-Bench: Evaluating Interactive Safety of VLM-Driven Embodied Agents in Daily Household Tasks", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Flawed planning from VLM-driven embodied agents poses significant safety\nhazards, hindering their deployment in real-world household tasks. However,\nexisting static, non-interactive evaluation paradigms fail to adequately assess\nrisks within these interactive environments, since they cannot simulate dynamic\nrisks that emerge from an agent's actions and rely on unreliable post-hoc\nevaluations that ignore unsafe intermediate steps. To bridge this critical gap,\nwe propose evaluating an agent's interactive safety: its ability to perceive\nemergent risks and execute mitigation steps in the correct procedural order. We\nthus present IS-Bench, the first multi-modal benchmark designed for interactive\nsafety, featuring 161 challenging scenarios with 388 unique safety risks\ninstantiated in a high-fidelity simulator. Crucially, it facilitates a novel\nprocess-oriented evaluation that verifies whether risk mitigation actions are\nperformed before/after specific risk-prone steps. Extensive experiments on\nleading VLMs, including the GPT-4o and Gemini-2.5 series, reveal that current\nagents lack interactive safety awareness, and that while safety-aware\nChain-of-Thought can improve performance, it often compromises task completion.\nBy highlighting these critical limitations, IS-Bench provides a foundation for\ndeveloping safer and more reliable embodied AI systems.", "AI": {"tldr": "IS-Bench\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30VLM\u9a71\u52a8\u7684\u5177\u8eab\u4ee3\u7406\u5728\u4ea4\u4e92\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6027\uff0c\u63ed\u793a\u5f53\u524d\u4ee3\u7406\u5728\u4ea4\u4e92\u5b89\u5168\u610f\u8bc6\u548c\u4efb\u52a1\u5b8c\u6210\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u9759\u6001\u3001\u975e\u4ea4\u4e92\u5f0f\u8bc4\u4f30\u8303\u5f0f\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u52a8\u6001\u98ce\u9669\uff0c\u963b\u788d\u4e86\u5177\u8eab\u4ee3\u7406\u5728\u771f\u5b9e\u5bb6\u5ead\u4efb\u52a1\u4e2d\u7684\u5b89\u5168\u90e8\u7f72\u3002", "method": "\u63d0\u51faIS-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b161\u4e2a\u573a\u666f\u548c388\u4e2a\u5b89\u5168\u98ce\u9669\uff0c\u652f\u6301\u8fc7\u7a0b\u5bfc\u5411\u7684\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u98ce\u9669\u7f13\u89e3\u6b65\u9aa4\u7684\u6b63\u786e\u987a\u5e8f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5f53\u524d\u4ee3\u7406\u7f3a\u4e4f\u4ea4\u4e92\u5b89\u5168\u610f\u8bc6\uff0c\u5b89\u5168\u611f\u77e5\u7684Chain-of-Thought\u867d\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u5e38\u5f71\u54cd\u4efb\u52a1\u5b8c\u6210\u3002", "conclusion": "IS-Bench\u4e3a\u5f00\u53d1\u66f4\u5b89\u5168\u53ef\u9760\u7684\u5177\u8eabAI\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.16411", "pdf": "https://arxiv.org/pdf/2506.16411", "abs": "https://arxiv.org/abs/2506.16411", "authors": ["Zhen Xu", "Shang Zhu", "Jue Wang", "Junlin Wang", "Ben Athiwaratkun", "Chi Wang", "James Zou", "Ce Zhang"], "title": "When Does Divide and Conquer Work for Long Context LLM? A Noise Decomposition Framework", "categories": ["cs.CL", "cs.LG"], "comment": "under review", "summary": "We investigate the challenge of applying Large Language Models (LLMs) to long\ntexts. We propose a theoretical framework that distinguishes the failure modes\nof long context tasks into three categories: cross-chunk dependence (task\nnoise), confusion that grows with context size (model noise), and the imperfect\nintegration of partial results (aggregator noise). Under this view, we analyze\nwhen it is effective to use multi-agent chunking, i.e., dividing a length\nsequence into smaller chunks and aggregating the processed results of each\nchunk. Our experiments on tasks such as retrieval, question answering, and\nsummarization confirm both the theoretical analysis and the conditions that\nfavor multi-agent chunking. By exploring superlinear model noise growth with\ninput length, we also explain why, for large inputs, a weaker model configured\nwith chunk-based processing can surpass a more advanced model like GPT4o\napplied in a single shot. Overall, we present a principled understanding\nframework and our results highlight a direct pathway to handling long contexts\nin LLMs with carefully managed chunking and aggregator strategies.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5c06\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5e94\u7528\u4e8e\u957f\u6587\u672c\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u7684\u5931\u8d25\u6a21\u5f0f\u5206\u4e3a\u4e09\u7c7b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u591a\u4ee3\u7406\u5206\u5757\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u957f\u6587\u672c\u65f6\u9047\u5230\u7684\u6311\u6218\uff0c\u5982\u8de8\u5757\u4f9d\u8d56\u3001\u6a21\u578b\u566a\u58f0\u548c\u7ed3\u679c\u6574\u5408\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u5206\u6790\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u591a\u4ee3\u7406\u5206\u5757\u65b9\u6cd5\uff08\u5c06\u957f\u5e8f\u5217\u5206\u6210\u5c0f\u5757\u5e76\u6574\u5408\u7ed3\u679c\uff09\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u591a\u4ee3\u7406\u5206\u5757\u65b9\u6cd5\u5728\u68c0\u7d22\u3001\u95ee\u7b54\u548c\u6458\u8981\u7b49\u4efb\u52a1\u4e2d\u6709\u6548\uff0c\u4e14\u5f31\u6a21\u578b\u901a\u8fc7\u5206\u5757\u5904\u7406\u53ef\u80fd\u4f18\u4e8e\u5355\u6b21\u5904\u7406\u7684\u5f3a\u6a21\u578b\u3002", "conclusion": "\u8bba\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u5206\u5757\u548c\u6574\u5408\u7b56\u7565\u662f\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2506.16416", "pdf": "https://arxiv.org/pdf/2506.16416", "abs": "https://arxiv.org/abs/2506.16416", "authors": ["Alexander Timans", "Rajeev Verma", "Eric Nalisnick", "Christian A. Naesseth"], "title": "On Continuous Monitoring of Risk Violations under Unknown Shift", "categories": ["stat.ML", "cs.LG"], "comment": "AT and RV are joint first authors. Accepted at the Conference on\n  Uncertainty in Artificial Intelligence (UAI 2025)", "summary": "Machine learning systems deployed in the real world must operate under\ndynamic and often unpredictable distribution shifts. This challenges the\nvalidity of statistical safety assurances on the system's risk established\nbeforehand. Common risk control frameworks rely on fixed assumptions and lack\nmechanisms to continuously monitor deployment reliability. In this work, we\npropose a general framework for the real-time monitoring of risk violations in\nevolving data streams. Leveraging the 'testing by betting' paradigm, we propose\na sequential hypothesis testing procedure to detect violations of bounded risks\nassociated with the model's decision-making mechanism, while ensuring control\non the false alarm rate. Our method operates under minimal assumptions on the\nnature of encountered shifts, rendering it broadly applicable. We illustrate\nthe effectiveness of our approach by monitoring risks in outlier detection and\nset prediction under a variety of shifts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u76d1\u63a7\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u98ce\u9669\u8fdd\u89c4\u7684\u901a\u7528\u6846\u67b6\uff0c\u5229\u7528\u987a\u5e8f\u5047\u8bbe\u68c0\u9a8c\u68c0\u6d4b\u98ce\u9669\u8fb9\u754c\u8fdd\u89c4\uff0c\u540c\u65f6\u63a7\u5236\u8bef\u62a5\u7387\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u7684\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u9762\u4e34\u52a8\u6001\u4e14\u4e0d\u53ef\u9884\u6d4b\u7684\u5206\u5e03\u53d8\u5316\uff0c\u4f20\u7edf\u98ce\u9669\u63a7\u5236\u6846\u67b6\u65e0\u6cd5\u6301\u7eed\u76d1\u63a7\u90e8\u7f72\u53ef\u9760\u6027\u3002", "method": "\u57fa\u4e8e\u2018\u6d4b\u8bd5\u4e0b\u6ce8\u2019\u8303\u5f0f\uff0c\u63d0\u51fa\u987a\u5e8f\u5047\u8bbe\u68c0\u9a8c\u65b9\u6cd5\uff0c\u68c0\u6d4b\u6a21\u578b\u51b3\u7b56\u673a\u5236\u7684\u98ce\u9669\u8fdd\u89c4\uff0c\u5047\u8bbe\u8981\u6c42\u6781\u4f4e\u3002", "result": "\u5728\u5f02\u5e38\u68c0\u6d4b\u548c\u96c6\u5408\u9884\u6d4b\u7b49\u591a\u79cd\u5206\u5e03\u53d8\u5316\u4e0b\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u5e7f\u6cdb\u573a\u666f\uff0c\u80fd\u6301\u7eed\u76d1\u63a7\u98ce\u9669\u5e76\u63a7\u5236\u8bef\u62a5\u7387\u3002"}}
{"id": "2506.16429", "pdf": "https://arxiv.org/pdf/2506.16429", "abs": "https://arxiv.org/abs/2506.16429", "authors": ["Sami Abboud", "Eleanor Hanna", "Olivier Jeunen", "Vineesha Raheja", "Schaun Wheeler"], "title": "Agentic Personalisation of Cross-Channel Marketing Experiences", "categories": ["cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "Consumer applications provide ample opportunities to surface and communicate\nvarious forms of content to users. From promotional campaigns for new features\nor subscriptions, to evergreen nudges for engagement, or personalised\nrecommendations; across e-mails, push notifications, and in-app surfaces. The\nconventional approach to orchestration for communication relies heavily on\nlabour-intensive manual marketer work, and inhibits effective personalisation\nof content, timing, frequency, and copy-writing. We formulate this task under a\nsequential decision-making framework, where we aim to optimise a modular\ndecision-making policy that maximises incremental engagement for any funnel\nevent. Our approach leverages a Difference-in-Differences design for Individual\nTreatment Effect estimation, and Thompson sampling to balance the\nexplore-exploit trade-off. We present results from a multi-service application,\nwhere our methodology has resulted in significant increases to a variety of\ngoal events across several product features, and is currently deployed across\n150 million users.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u987a\u5e8f\u51b3\u7b56\u6846\u67b6\u7684\u81ea\u52a8\u5316\u901a\u4fe1\u7f16\u6392\u65b9\u6cd5\uff0c\u53d6\u4ee3\u4f20\u7edf\u7684\u624b\u52a8\u8425\u9500\u5de5\u4f5c\uff0c\u901a\u8fc7\u4e2a\u6027\u5316\u4f18\u5316\u63d0\u5347\u7528\u6237\u53c2\u4e0e\u5ea6\u3002", "motivation": "\u4f20\u7edf\u901a\u4fe1\u7f16\u6392\u4f9d\u8d56\u4eba\u5de5\uff0c\u96be\u4ee5\u5b9e\u73b0\u5185\u5bb9\u3001\u65f6\u95f4\u3001\u9891\u7387\u548c\u6587\u6848\u7684\u4e2a\u6027\u5316\uff0c\u9650\u5236\u4e86\u6548\u679c\u3002", "method": "\u91c7\u7528\u5dee\u5206\u8bbe\u8ba1\u4f30\u8ba1\u4e2a\u4f53\u5904\u7406\u6548\u5e94\uff0c\u7ed3\u5408Thompson\u91c7\u6837\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\u3002", "result": "\u5728\u591a\u670d\u52a1\u5e94\u7528\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u591a\u79cd\u76ee\u6807\u4e8b\u4ef6\uff0c\u5df2\u90e8\u7f72\u4e8e1.5\u4ebf\u7528\u6237\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u901a\u4fe1\u7f16\u6392\u7684\u4e2a\u6027\u5316\u4e0e\u81ea\u52a8\u5316\u6c34\u5e73\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2506.16475", "pdf": "https://arxiv.org/pdf/2506.16475", "abs": "https://arxiv.org/abs/2506.16475", "authors": ["Yaru Niu", "Yunzhe Zhang", "Mingyang Yu", "Changyi Lin", "Chenhao Li", "Yikai Wang", "Yuxiang Yang", "Wenhao Yu", "Tingnan Zhang", "Bingqing Chen", "Jonathan Francis", "Zhenzhen Li", "Jie Tan", "Ding Zhao"], "title": "Human2LocoMan: Learning Versatile Quadrupedal Manipulation with Human Pretraining", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Quadrupedal robots have demonstrated impressive locomotion capabilities in\ncomplex environments, but equipping them with autonomous versatile manipulation\nskills in a scalable way remains a significant challenge. In this work, we\nintroduce a cross-embodiment imitation learning system for quadrupedal\nmanipulation, leveraging data collected from both humans and LocoMan, a\nquadruped equipped with multiple manipulation modes. Specifically, we develop a\nteleoperation and data collection pipeline, which unifies and modularizes the\nobservation and action spaces of the human and the robot. To effectively\nleverage the collected data, we propose an efficient modularized architecture\nthat supports co-training and pretraining on structured modality-aligned data\nacross different embodiments. Additionally, we construct the first manipulation\ndataset for the LocoMan robot, covering various household tasks in both\nunimanual and bimanual modes, supplemented by a corresponding human dataset. We\nvalidate our system on six real-world manipulation tasks, where it achieves an\naverage success rate improvement of 41.9% overall and 79.7% under\nout-of-distribution (OOD) settings compared to the baseline. Pretraining with\nhuman data contributes a 38.6% success rate improvement overall and 82.7% under\nOOD settings, enabling consistently better performance with only half the\namount of robot data. Our code, hardware, and data are open-sourced at:\nhttps://human2bots.github.io.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u4f53\u73b0\u6a21\u4eff\u5b66\u4e60\u7cfb\u7edf\uff0c\u7528\u4e8e\u56db\u8db3\u673a\u5668\u4eba\u7684\u591a\u529f\u80fd\u64cd\u4f5c\uff0c\u901a\u8fc7\u4eba\u7c7b\u548c\u673a\u5668\u4eba\u6570\u636e\u8054\u5408\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u56db\u8db3\u673a\u5668\u4eba\u5177\u5907\u590d\u6742\u73af\u5883\u4e2d\u7684\u8fd0\u52a8\u80fd\u529b\uff0c\u4f46\u5b9e\u73b0\u81ea\u4e3b\u591a\u529f\u80fd\u64cd\u4f5c\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u7edf\u4e00\u4eba\u7c7b\u548c\u673a\u5668\u4eba\u89c2\u5bdf\u4e0e\u52a8\u4f5c\u7a7a\u95f4\u7684\u9065\u64cd\u4f5c\u548c\u6570\u636e\u6536\u96c6\u6d41\u7a0b\uff0c\u5e76\u63d0\u51fa\u6a21\u5757\u5316\u67b6\u6784\u652f\u6301\u8de8\u4f53\u73b0\u6570\u636e\u8054\u5408\u8bad\u7ec3\u3002", "result": "\u5728\u516d\u9879\u771f\u5b9e\u4efb\u52a1\u4e2d\uff0c\u7cfb\u7edf\u5e73\u5747\u6210\u529f\u7387\u63d0\u534741.9%\uff0cOOD\u8bbe\u7f6e\u4e0b\u63d0\u534779.7%\uff1b\u4eba\u7c7b\u6570\u636e\u9884\u8bad\u7ec3\u8d21\u732e\u663e\u8457\u3002", "conclusion": "\u7cfb\u7edf\u901a\u8fc7\u8de8\u4f53\u73b0\u6570\u636e\u8054\u5408\u8bad\u7ec3\u548c\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56db\u8db3\u673a\u5668\u4eba\u7684\u64cd\u4f5c\u80fd\u529b\uff0c\u4e14\u5f00\u6e90\u4e86\u4ee3\u7801\u548c\u6570\u636e\u3002"}}
{"id": "2506.16476", "pdf": "https://arxiv.org/pdf/2506.16476", "abs": "https://arxiv.org/abs/2506.16476", "authors": ["Saad Almohaimeed", "Saleh Almohaimeed", "Damla Turgut", "Ladislau B\u00f6l\u00f6ni"], "title": "Towards Generalizable Generic Harmful Speech Datasets for Implicit Hate Speech Detection", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Implicit hate speech has recently emerged as a critical challenge for social\nmedia platforms. While much of the research has traditionally focused on\nharmful speech in general, the need for generalizable techniques to detect\nveiled and subtle forms of hate has become increasingly pressing. Based on\nlexicon analysis, we hypothesize that implicit hate speech is already present\nin publicly available harmful speech datasets but may not have been explicitly\nrecognized or labeled by annotators. Additionally, crowdsourced datasets are\nprone to mislabeling due to the complexity of the task and often influenced by\nannotators' subjective interpretations. In this paper, we propose an approach\nto address the detection of implicit hate speech and enhance generalizability\nacross diverse datasets by leveraging existing harmful speech datasets. Our\nmethod comprises three key components: influential sample identification,\nreannotation, and augmentation using Llama-3 70B and GPT-4o. Experimental\nresults demonstrate the effectiveness of our approach in improving implicit\nhate detection, achieving a +12.9-point F1 score improvement compared to the\nbaseline.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u73b0\u6709\u6709\u5bb3\u8a00\u8bba\u6570\u636e\u96c6\u68c0\u6d4b\u9690\u5f0f\u4ec7\u6068\u8a00\u8bba\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6837\u672c\u8bc6\u522b\u3001\u91cd\u65b0\u6807\u6ce8\u548c\u589e\u5f3a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u9690\u5f0f\u4ec7\u6068\u8a00\u8bba\u5bf9\u793e\u4f1a\u5a92\u4f53\u5e73\u53f0\u6784\u6210\u6311\u6218\uff0c\u73b0\u6709\u6570\u636e\u96c6\u53ef\u80fd\u672a\u660e\u786e\u6807\u6ce8\u6b64\u7c7b\u5185\u5bb9\uff0c\u4e14\u6807\u6ce8\u6613\u53d7\u4e3b\u89c2\u5f71\u54cd\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5173\u952e\u6837\u672c\u8bc6\u522b\u3001\u91cd\u65b0\u6807\u6ce8\u548c\u5229\u7528Llama-3 70B\u4e0eGPT-4o\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u9690\u5f0f\u4ec7\u6068\u68c0\u6d4b\u4e0aF1\u5206\u6570\u63d0\u5347\u4e8612.9\u5206\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u9690\u5f0f\u4ec7\u6068\u8a00\u8bba\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u5177\u6709\u8de8\u6570\u636e\u96c6\u7684\u901a\u7528\u6027\u3002"}}
{"id": "2506.16499", "pdf": "https://arxiv.org/pdf/2506.16499", "abs": "https://arxiv.org/abs/2506.16499", "authors": ["Zexi Liu", "Yuzhu Cai", "Xinyu Zhu", "Yujie Zheng", "Runkun Chen", "Ying Wen", "Yanfeng Wang", "Weinan E", "Siheng Chen"], "title": "ML-Master: Towards AI-for-AI via Integration of Exploration and Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "As AI capabilities advance toward and potentially beyond human-level\nperformance, a natural transition emerges where AI-driven development becomes\nmore efficient than human-centric approaches. A promising pathway toward this\ntransition lies in AI-for-AI (AI4AI), which leverages AI techniques to automate\nand optimize the design, training, and deployment of AI systems themselves.\nWhile LLM-based agents have shown the potential to realize AI4AI, they are\noften unable to fully leverage the experience accumulated by agents during the\nexploration of solutions in the reasoning process, leading to inefficiencies\nand suboptimal performance. To address this limitation, we propose ML-Master, a\nnovel AI4AI agent that seamlessly integrates exploration and reasoning by\nemploying a selectively scoped memory mechanism. This approach allows ML-Master\nto efficiently combine diverse insights from parallel solution trajectories\nwith analytical reasoning, guiding further exploration without overwhelming the\nagent with excessive context. We evaluate ML-Master on the MLE-Bench, where it\nachieves a 29.3% average medal rate, significantly surpassing existing methods,\nparticularly in medium-complexity tasks, while accomplishing this superior\nperformance within a strict 12-hour time constraint-half the 24-hour limit used\nby previous baselines. These results demonstrate ML-Master's potential as a\npowerful tool for advancing AI4AI.", "AI": {"tldr": "ML-Master\u662f\u4e00\u79cd\u65b0\u578bAI4AI\u4ee3\u7406\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u8bb0\u5fc6\u673a\u5236\u6574\u5408\u63a2\u7d22\u4e0e\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "AI\u9a71\u52a8\u7684\u5f00\u53d1\u6548\u7387\u53ef\u80fd\u8d85\u8d8a\u4eba\u7c7b\uff0c\u4f46\u73b0\u6709LLM\u4ee3\u7406\u672a\u80fd\u5145\u5206\u5229\u7528\u63a2\u7d22\u7ecf\u9a8c\uff0c\u5bfc\u81f4\u4f4e\u6548\u3002", "method": "\u63d0\u51faML-Master\uff0c\u91c7\u7528\u9009\u62e9\u6027\u8bb0\u5fc6\u673a\u5236\uff0c\u7ed3\u5408\u5e76\u884c\u89e3\u51b3\u65b9\u6848\u7684\u591a\u6837\u6027\u4e0e\u5206\u6790\u63a8\u7406\u3002", "result": "\u5728MLE-Bench\u4e0a\uff0cML-Master\u5e73\u5747\u5956\u724c\u7387\u63d0\u534729.3%\uff0c\u4e14\u572812\u5c0f\u65f6\u5185\u5b8c\u6210\uff0c\u4f18\u4e8e\u57fa\u7ebf\u3002", "conclusion": "ML-Master\u5c55\u793a\u4e86\u4f5c\u4e3aAI4AI\u5f3a\u5927\u5de5\u5177\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.16522", "pdf": "https://arxiv.org/pdf/2506.16522", "abs": "https://arxiv.org/abs/2506.16522", "authors": ["Pedro Rodr\u00edguez Fern\u00e1ndez", "Christian Svinth", "Alex Hagen"], "title": "Improvement of Nuclide Detection through Graph Spectroscopic Analysis Framework and its Application to Nuclear Facility Upset Detection", "categories": ["physics.ins-det", "cs.LG", "physics.data-an"], "comment": null, "summary": "We present a method to improve the detection limit for radionuclides using\nspectroscopic radiation detectors and the arrival time of each detected\nradiation quantum. We enable this method using a neural network with an\nattention mechanism. We illustrate the method on the detection of Cesium\nrelease from a nuclear facility during an upset, and our method shows $2\\times$\nimprovement over the traditional spectroscopic method. We hypothesize that our\nmethod achieves this performance increase by modulating its detection\nprobability by the overall rate of probable detections, specifically by\nadapting detection thresholds based on temporal event distributions and local\nspectral features, and show evidence to this effect. We believe this method is\napplicable broadly and may be more successful for radionuclides with more\ncomplicated decay chains than Cesium; we also note that our method can\ngeneralize beyond the addition of arrival time and could integrate other data\nabout each detection event, such as pulse quality, location in detector, or\neven combining the energy and time from detections in different detectors.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u8f90\u5c04\u91cf\u5b50\u5230\u8fbe\u65f6\u95f4\u548c\u795e\u7ecf\u7f51\u7edc\u6ce8\u610f\u529b\u673a\u5236\u6539\u8fdb\u653e\u5c04\u6027\u6838\u7d20\u68c0\u6d4b\u9650\u7684\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u5149\u8c31\u65b9\u6cd5\u63d0\u53472\u500d\u3002", "motivation": "\u4f20\u7edf\u5149\u8c31\u65b9\u6cd5\u5728\u653e\u5c04\u6027\u6838\u7d20\u68c0\u6d4b\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u8870\u53d8\u94fe\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u5e26\u6709\u6ce8\u610f\u529b\u673a\u5236\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u7ed3\u5408\u8f90\u5c04\u91cf\u5b50\u7684\u5230\u8fbe\u65f6\u95f4\uff0c\u52a8\u6001\u8c03\u6574\u68c0\u6d4b\u9608\u503c\u3002", "result": "\u5728\u6838\u8bbe\u65bd\u91ca\u653e\u94ef\u7684\u68c0\u6d4b\u4e2d\uff0c\u65b9\u6cd5\u6027\u80fd\u63d0\u53472\u500d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8e\u94ef\uff0c\u8fd8\u53ef\u63a8\u5e7f\u81f3\u5176\u4ed6\u590d\u6742\u8870\u53d8\u94fe\u7684\u653e\u5c04\u6027\u6838\u7d20\uff0c\u5e76\u53ef\u80fd\u6574\u5408\u66f4\u591a\u68c0\u6d4b\u4e8b\u4ef6\u6570\u636e\u3002"}}
{"id": "2506.16546", "pdf": "https://arxiv.org/pdf/2506.16546", "abs": "https://arxiv.org/abs/2506.16546", "authors": ["Liyang Yu", "Tianyi Wang", "Junfeng Jiao", "Fengwu Shan", "Hongqing Chu", "Bingzhao Gao"], "title": "BIDA: A Bi-level Interaction Decision-making Algorithm for Autonomous Vehicles in Dynamic Traffic Scenarios", "categories": ["cs.RO", "cs.AI", "cs.ET", "cs.LG", "cs.SY", "eess.SY"], "comment": "6 pages, 3 figures, 4 tables, accepted for IEEE Intelligent Vehicles\n  (IV) Symposium 2025", "summary": "In complex real-world traffic environments, autonomous vehicles (AVs) need to\ninteract with other traffic participants while making real-time and\nsafety-critical decisions accordingly. The unpredictability of human behaviors\nposes significant challenges, particularly in dynamic scenarios, such as\nmulti-lane highways and unsignalized T-intersections. To address this gap, we\ndesign a bi-level interaction decision-making algorithm (BIDA) that integrates\ninteractive Monte Carlo tree search (MCTS) with deep reinforcement learning\n(DRL), aiming to enhance interaction rationality, efficiency and safety of AVs\nin dynamic key traffic scenarios. Specifically, we adopt three types of DRL\nalgorithms to construct a reliable value network and policy network, which\nguide the online deduction process of interactive MCTS by assisting in value\nupdate and node selection. Then, a dynamic trajectory planner and a trajectory\ntracking controller are designed and implemented in CARLA to ensure smooth\nexecution of planned maneuvers. Experimental evaluations demonstrate that our\nBIDA not only enhances interactive deduction and reduces computational costs,\nbut also outperforms other latest benchmarks, which exhibits superior safety,\nefficiency and interaction rationality under varying traffic conditions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c42\u4ea4\u4e92\u51b3\u7b56\u7b97\u6cd5\uff08BIDA\uff09\uff0c\u7ed3\u5408\u4ea4\u4e92\u5f0f\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\uff0c\u4ee5\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5728\u52a8\u6001\u4ea4\u901a\u573a\u666f\u4e2d\u7684\u4ea4\u4e92\u7406\u6027\u3001\u6548\u7387\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u5728\u590d\u6742\u4ea4\u901a\u73af\u5883\u4e2d\uff0c\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u9700\u5b9e\u65f6\u5e94\u5bf9\u4e0d\u53ef\u9884\u6d4b\u7684\u4eba\u7c7b\u884c\u4e3a\uff0c\u5c24\u5176\u662f\u5728\u591a\u8f66\u9053\u9ad8\u901f\u8def\u548c\u65e0\u4fe1\u53f7T\u578b\u8def\u53e3\u7b49\u52a8\u6001\u573a\u666f\u4e2d\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u4e09\u79cdDRL\u7b97\u6cd5\u6784\u5efa\u53ef\u9760\u7684\u4ef7\u503c\u7f51\u7edc\u548c\u7b56\u7565\u7f51\u7edc\uff0c\u6307\u5bfc\u4ea4\u4e92\u5f0fMCTS\u7684\u5728\u7ebf\u63a8\u7406\u8fc7\u7a0b\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u8f68\u8ff9\u89c4\u5212\u5668\u548c\u8ddf\u8e2a\u63a7\u5236\u5668\u5728CARLA\u4e2d\u5b9e\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cBIDA\u5728\u4ea4\u4e92\u63a8\u7406\u548c\u8ba1\u7b97\u6210\u672c\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u6700\u65b0\u57fa\u51c6\uff0c\u4e14\u5728\u591a\u79cd\u4ea4\u901a\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u5b89\u5168\u6027\u3001\u6548\u7387\u548c\u4ea4\u4e92\u7406\u6027\u3002", "conclusion": "BIDA\u4e3a\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5728\u52a8\u6001\u4ea4\u901a\u573a\u666f\u4e2d\u7684\u4ea4\u4e92\u51b3\u7b56\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u5b89\u5168\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16563", "pdf": "https://arxiv.org/pdf/2506.16563", "abs": "https://arxiv.org/abs/2506.16563", "authors": ["Keyhan Najafian", "Farhad Maleki", "Lingling Jin", "Ian Stavness"], "title": "From Semantic To Instance: A Semi-Self-Supervised Learning Approach", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Instance segmentation is essential for applications such as automated\nmonitoring of plant health, growth, and yield. However, extensive effort is\nrequired to create large-scale datasets with pixel-level annotations of each\nobject instance for developing instance segmentation models that restrict the\nuse of deep learning in these areas. This challenge is more significant in\nimages with densely packed, self-occluded objects, which are common in\nagriculture. To address this challenge, we propose a semi-self-supervised\nlearning approach that requires minimal manual annotation to develop a\nhigh-performing instance segmentation model. We design GLMask, an image-mask\nrepresentation for the model to focus on shape, texture, and pattern while\nminimizing its dependence on color features. We develop a pipeline to generate\nsemantic segmentation and then transform it into instance-level segmentation.\nThe proposed approach substantially outperforms the conventional instance\nsegmentation models, establishing a state-of-the-art wheat head instance\nsegmentation model with mAP@50 of 98.5%. Additionally, we assessed the proposed\nmethodology on the general-purpose Microsoft COCO dataset, achieving a\nsignificant performance improvement of over 12.6% mAP@50. This highlights that\nthe utility of our proposed approach extends beyond precision agriculture and\napplies to other domains, specifically those with similar data characteristics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5GLMask\uff0c\u7528\u4e8e\u5b9e\u4f8b\u5206\u5272\uff0c\u51cf\u5c11\u4eba\u5de5\u6807\u6ce8\u9700\u6c42\uff0c\u5728\u519c\u4e1a\u548c\u901a\u7528\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5b9e\u4f8b\u5206\u5272\u5728\u519c\u4e1a\u7b49\u9886\u57df\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u5927\u89c4\u6a21\u50cf\u7d20\u7ea7\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u5c24\u5176\u5728\u5bc6\u96c6\u906e\u6321\u573a\u666f\u4e2d\u3002", "method": "\u8bbe\u8ba1GLMask\u56fe\u50cf-\u63a9\u7801\u8868\u793a\uff0c\u5173\u6ce8\u5f62\u72b6\u3001\u7eb9\u7406\u548c\u6a21\u5f0f\uff0c\u51cf\u5c11\u5bf9\u989c\u8272\u7279\u5f81\u7684\u4f9d\u8d56\uff1b\u901a\u8fc7\u8bed\u4e49\u5206\u5272\u751f\u6210\u5b9e\u4f8b\u5206\u5272\u3002", "result": "\u5728\u5c0f\u9ea6\u5934\u5b9e\u4f8b\u5206\u5272\u4efb\u52a1\u4e2d\u8fbe\u523098.5% mAP@50\uff0c\u5728COCO\u6570\u636e\u96c6\u4e0a\u63d0\u534712.6% mAP@50\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8e\u519c\u4e1a\uff0c\u8fd8\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u7c7b\u4f3c\u6570\u636e\u7279\u5f81\u7684\u9886\u57df\u3002"}}
{"id": "2506.16584", "pdf": "https://arxiv.org/pdf/2506.16584", "abs": "https://arxiv.org/abs/2506.16584", "authors": ["Nadav Kunievsky", "James A. Evans"], "title": "Measuring (a Sufficient) World Model in LLMs: A Variance Decomposition Framework", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50, 68T05", "I.2.7; I.2.6; I.5.1"], "comment": null, "summary": "Understanding whether large language models (LLMs) possess a world model-a\nstructured understanding of the world that supports generalization beyond\nsurface-level patterns-is central to assessing their reliability, especially in\nhigh-stakes applications. We propose a formal framework for evaluating whether\nan LLM exhibits a sufficiently robust world model, defined as producing\nconsistent outputs across semantically equivalent prompts while distinguishing\nbetween prompts that express different intents. We introduce a new evaluation\napproach to measure this that decomposes model response variability into three\ncomponents: variability due to user purpose, user articulation, and model\ninstability. An LLM with a strong world model should attribute most of the\nvariability in its responses to changes in foundational purpose rather than\nsuperficial changes in articulation. This approach allows us to quantify how\nmuch of a model's behavior is semantically grounded rather than driven by model\ninstability or alternative wording. We apply this framework to evaluate LLMs\nacross diverse domains. Our results show how larger models attribute a greater\nshare of output variability to changes in user purpose, indicating a more\nrobust world model. This improvement is not uniform, however: larger models do\nnot consistently outperform smaller ones across all domains, and their\nadvantage in robustness is often modest. These findings highlight the\nimportance of moving beyond accuracy-based benchmarks toward semantic\ndiagnostics that more directly assess the structure and stability of a model's\ninternal understanding of the world.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u662f\u5426\u5177\u5907\u7a33\u5065\u4e16\u754c\u6a21\u578b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u6a21\u578b\u54cd\u5e94\u7684\u53d8\u5f02\u6027\u6765\u91cf\u5316\u5176\u8bed\u4e49\u57fa\u7840\u3002", "motivation": "\u8bc4\u4f30LLM\u662f\u5426\u5177\u5907\u4e16\u754c\u6a21\u578b\u5bf9\u4e8e\u5176\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5c06\u6a21\u578b\u54cd\u5e94\u53d8\u5f02\u6027\u5206\u89e3\u4e3a\u7528\u6237\u76ee\u7684\u3001\u7528\u6237\u8868\u8fbe\u548c\u6a21\u578b\u4e0d\u7a33\u5b9a\u6027\u4e09\u4e2a\u90e8\u5206\u3002", "result": "\u66f4\u5927\u6a21\u578b\u5728\u7528\u6237\u76ee\u7684\u53d8\u5f02\u6027\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u8868\u660e\u5176\u4e16\u754c\u6a21\u578b\u66f4\u7a33\u5065\uff0c\u4f46\u4f18\u52bf\u5e76\u4e0d\u4e00\u81f4\u4e14\u6709\u9650\u3002", "conclusion": "\u9700\u8d85\u8d8a\u57fa\u4e8e\u51c6\u786e\u6027\u7684\u57fa\u51c6\uff0c\u91c7\u7528\u8bed\u4e49\u8bca\u65ad\u76f4\u63a5\u8bc4\u4f30\u6a21\u578b\u5185\u90e8\u4e16\u754c\u7406\u89e3\u7684\u7ed3\u6784\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2506.16627", "pdf": "https://arxiv.org/pdf/2506.16627", "abs": "https://arxiv.org/abs/2506.16627", "authors": ["Haotian Yin", "Aleksander Plocharski", "Michal Jan Wlodarczyk", "Mikolaj Kida", "Przemyslaw Musialski"], "title": "FlatCAD: Fast Curvature Regularization of Neural SDFs for CAD Models", "categories": ["cs.GR", "cs.CV", "cs.LG", "65D18, 68U05, 68T07, 53A07", "I.3.5; I.3.7; I.2.6"], "comment": "12 page, 10 figures, preprint", "summary": "Neural signed-distance fields (SDFs) have become a versatile backbone for\ngeometric learning, yet enforcing developable, CAD-style behavior still hinges\non Gaussian curvature penalties that require full Hessian evaluation and\nsecond-order automatic differentiation, both of which are costly in memory and\nruntime. We present a curvature proxy that regularizes only the mixed\nsecond-order term (Weingarten term), allowing the two principal curvatures to\nadapt freely to data while suppressing unwanted warp. Two complementary\ninstantiations realize this idea: (i) a finite-difference proxy that replaces\neach Hessian entry with four forward SDF evaluations and a single first-order\ngradient, and (ii) an autodiff proxy that computes the same mixed derivative\nvia one Hessian-vector product, sidestepping explicit full Hessian assembly and\nremaining faster in practice. Both variants converge to the exact mixed second\nderivative, thus preserving the intended geometric bias without incurring full\nsecond-order graphs. On the ABC benchmarks, the proxies match or exceed the\nreconstruction fidelity of Hessian-based baselines while reducing GPU memory\nuse and wall-clock time by a factor of two. Because the method is drop-in and\nframework-agnostic, it opens a practical path toward scalable, curvature-aware\nSDF learning for engineering-grade shape reconstruction.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u66f2\u7387\u4ee3\u7406\u65b9\u6cd5\uff0c\u7528\u4e8e\u795e\u7ecf\u7b26\u53f7\u8ddd\u79bb\u573a\uff08SDF\uff09\u7684\u51e0\u4f55\u5b66\u4e60\uff0c\u901a\u8fc7\u4ec5\u6b63\u5219\u5316\u6df7\u5408\u4e8c\u9636\u9879\uff08Weingarten\u9879\uff09\uff0c\u51cf\u5c11\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u51e0\u4f55\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f7f\u7528\u9ad8\u65af\u66f2\u7387\u60e9\u7f5a\u9700\u8981\u5b8c\u6574\u7684Hessian\u8bc4\u4f30\u548c\u4e8c\u9636\u81ea\u52a8\u5fae\u5206\uff0c\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u66f2\u7387\u4ee3\u7406\u5b9e\u73b0\uff1a\uff081\uff09\u6709\u9650\u5dee\u5206\u4ee3\u7406\uff0c\u901a\u8fc7\u56db\u6b21\u524d\u5411SDF\u8bc4\u4f30\u548c\u4e00\u6b21\u4e00\u9636\u68af\u5ea6\u8ba1\u7b97\uff1b\uff082\uff09\u81ea\u52a8\u5fae\u5206\u4ee3\u7406\uff0c\u901a\u8fc7\u4e00\u6b21Hessian-\u5411\u91cf\u79ef\u8ba1\u7b97\u6df7\u5408\u5bfc\u6570\u3002", "result": "\u5728ABC\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4ee3\u7406\u65b9\u6cd5\u5728\u91cd\u5efa\u7cbe\u5ea6\u4e0a\u4e0e\u57fa\u4e8eHessian\u7684\u57fa\u7ebf\u76f8\u5f53\u6216\u66f4\u597d\uff0c\u540c\u65f6\u51cf\u5c11GPU\u5185\u5b58\u4f7f\u7528\u548c\u8fd0\u884c\u65f6\u95f4\u7ea6\u4e00\u534a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5de5\u7a0b\u7ea7\u5f62\u72b6\u91cd\u5efa\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u66f2\u7387\u611f\u77e5\u7684SDF\u5b66\u4e60\u8def\u5f84\u3002"}}
{"id": "2506.16628", "pdf": "https://arxiv.org/pdf/2506.16628", "abs": "https://arxiv.org/abs/2506.16628", "authors": ["Jianlin Shi", "Brian T. Bucher"], "title": "Initial Investigation of LLM-Assisted Development of Rule-Based Clinical NLP System", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Despite advances in machine learning (ML) and large language models (LLMs),\nrule-based natural language processing (NLP) systems remain active in clinical\nsettings due to their interpretability and operational efficiency. However,\ntheir manual development and maintenance are labor-intensive, particularly in\ntasks with large linguistic variability. To overcome these limitations, we\nproposed a novel approach employing LLMs solely during the rule-based systems\ndevelopment phase. We conducted the initial experiments focusing on the first\ntwo steps of developing a rule-based NLP pipeline: find relevant snippets from\nthe clinical note; extract informative keywords from the snippets for the\nrule-based named entity recognition (NER) component. Our experiments\ndemonstrated exceptional recall in identifying clinically relevant text\nsnippets (Deepseek: 0.98, Qwen: 0.99) and 1.0 in extracting key terms for NER.\nThis study sheds light on a promising new direction for NLP development,\nenabling semi-automated or automated development of rule-based systems with\nsignificantly faster, more cost-effective, and transparent execution compared\nwith deep learning model-based solutions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528LLMs\u8f85\u52a9\u5f00\u53d1\u57fa\u4e8e\u89c4\u5219\u7684NLP\u7cfb\u7edf\u7684\u65b0\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5f00\u53d1\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1ML\u548cLLMs\u6709\u8fdb\u5c55\uff0c\u57fa\u4e8e\u89c4\u5219\u7684NLP\u7cfb\u7edf\u56e0\u5176\u53ef\u89e3\u91ca\u6027\u548c\u64cd\u4f5c\u6548\u7387\u4ecd\u5728\u4e34\u5e8a\u4e2d\u4f7f\u7528\uff0c\u4f46\u5176\u5f00\u53d1\u548c\u7ef4\u62a4\u6210\u672c\u9ad8\u3002", "method": "\u5728\u89c4\u5219\u7cfb\u7edf\u5f00\u53d1\u9636\u6bb5\u4f7f\u7528LLMs\uff0c\u5b9e\u9a8c\u805a\u7126\u4e8e\u4ece\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u63d0\u53d6\u76f8\u5173\u7247\u6bb5\u548c\u5173\u952e\u8bcd\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u9ad8\u53ec\u56de\u7387\uff08Deepseek: 0.98, Qwen: 0.99\uff09\u548c\u5173\u952e\u8bcd\u63d0\u53d6\u51c6\u786e\u73871.0\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aNLP\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u6bd4\u6df1\u5ea6\u5b66\u4e60\u65b9\u6848\u66f4\u5feb\u3001\u66f4\u7ecf\u6d4e\u3001\u66f4\u900f\u660e\u3002"}}
{"id": "2506.16636", "pdf": "https://arxiv.org/pdf/2506.16636", "abs": "https://arxiv.org/abs/2506.16636", "authors": ["Rex Shen", "Lu Tian"], "title": "Latent Noise Injection for Private and Statistically Aligned Synthetic Data Generation", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Synthetic Data Generation has become essential for scalable,\nprivacy-preserving statistical analysis. While standard approaches based on\ngenerative models, such as Normalizing Flows, have been widely used, they often\nsuffer from slow convergence in high-dimensional settings, frequently\nconverging more slowly than the canonical $1/\\sqrt{n}$ rate when approximating\nthe true data distribution.\n  To overcome these limitations, we propose a Latent Noise Injection method\nusing Masked Autoregressive Flows (MAF). Instead of directly sampling from the\ntrained model, our method perturbs each data point in the latent space and maps\nit back to the data domain. This construction preserves a one to one\ncorrespondence between observed and synthetic data, enabling synthetic outputs\nthat closely reflect the underlying distribution, particularly in challenging\nhigh-dimensional regimes where traditional sampling struggles.\n  Our procedure satisfies local $(\\epsilon, \\delta)$-differential privacy and\nintroduces a single perturbation parameter to control the privacy-utility\ntrade-off. Although estimators based on individual synthetic datasets may\nconverge slowly, we show both theoretically and empirically that aggregating\nacross $K$ studies in a meta analysis framework restores classical efficiency\nand yields consistent, reliable inference. We demonstrate that with a\nwell-calibrated perturbation parameter, Latent Noise Injection achieves strong\nstatistical alignment with the original data and robustness against membership\ninference attacks. These results position our method as a compelling\nalternative to conventional flow-based sampling for synthetic data sharing in\ndecentralized and privacy-sensitive domains, such as biomedical research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63a9\u7801\u81ea\u56de\u5f52\u6d41\uff08MAF\uff09\u7684\u6f5c\u5728\u566a\u58f0\u6ce8\u5165\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u9ad8\u7ef4\u573a\u666f\u4e0b\u4f20\u7edf\u751f\u6210\u6a21\u578b\u6536\u655b\u6162\u7684\u95ee\u9898\uff0c\u540c\u65f6\u6ee1\u8db3\u5dee\u5206\u9690\u79c1\u3002", "motivation": "\u4f20\u7edf\u751f\u6210\u6a21\u578b\u5728\u9ad8\u7ef4\u6570\u636e\u4e2d\u6536\u655b\u901f\u5ea6\u6162\uff0c\u4e14\u96be\u4ee5\u5e73\u8861\u9690\u79c1\u4e0e\u6548\u7528\u3002", "method": "\u901a\u8fc7\u6f5c\u5728\u566a\u58f0\u6ce8\u5165\u6270\u52a8\u6570\u636e\u70b9\uff0c\u4fdd\u6301\u89c2\u6d4b\u4e0e\u5408\u6210\u6570\u636e\u7684\u4e00\u4e00\u5bf9\u5e94\uff0c\u7ed3\u5408\u5143\u5206\u6790\u6846\u67b6\u6062\u590d\u7ecf\u5178\u6548\u7387\u3002", "result": "\u65b9\u6cd5\u5728\u7edf\u8ba1\u5bf9\u9f50\u548c\u6297\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u9690\u79c1\u654f\u611f\u9886\u57df\u3002", "conclusion": "\u6f5c\u5728\u566a\u58f0\u6ce8\u5165\u662f\u9690\u79c1\u654f\u611f\u9886\u57df\u4e2d\u4f20\u7edf\u6d41\u91c7\u6837\u65b9\u6cd5\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2506.16658", "pdf": "https://arxiv.org/pdf/2506.16658", "abs": "https://arxiv.org/abs/2506.16658", "authors": ["Wenlong Ji", "Yihan Pan", "Ruihao Zhu", "Lihua Lei"], "title": "Multi-Armed Bandits With Machine Learning-Generated Surrogate Rewards", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "comment": null, "summary": "Multi-armed bandit (MAB) is a widely adopted framework for sequential\ndecision-making under uncertainty. Traditional bandit algorithms rely solely on\nonline data, which tends to be scarce as it must be gathered during the online\nphase when the arms are actively pulled. However, in many practical settings,\nrich auxiliary data, such as covariates of past users, is available prior to\ndeploying any arms. We introduce a new setting for MAB where pre-trained\nmachine learning (ML) models are applied to convert side information and\nhistorical data into \\emph{surrogate rewards}. A prominent feature of this\nsetting is that the surrogate rewards may exhibit substantial bias, as true\nreward data is typically unavailable in the offline phase, forcing ML\npredictions to heavily rely on extrapolation. To address the issue, we propose\nthe Machine Learning-Assisted Upper Confidence Bound (MLA-UCB) algorithm, which\ncan be applied to any reward prediction model and any form of auxiliary data.\nWhen the predicted and true rewards are jointly Gaussian, it provably improves\nthe cumulative regret, provided that the correlation is non-zero -- even in\ncases where the mean surrogate reward completely misaligns with the true mean\nrewards. Notably, our method requires no prior knowledge of the covariance\nmatrix between true and surrogate rewards. We compare MLA-UCB with the standard\nUCB on a range of numerical studies and show a sizable efficiency gain even\nwhen the size of the offline data and the correlation between predicted and\ntrue rewards are moderate.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u81c2\u8001\u864e\u673a\uff08MAB\uff09\u6846\u67b6\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5c06\u8f85\u52a9\u6570\u636e\u8f6c\u5316\u4e3a\u66ff\u4ee3\u5956\u52b1\uff0c\u5e76\u8bbe\u8ba1\u4e86MLA-UCB\u7b97\u6cd5\u4ee5\u5904\u7406\u66ff\u4ee3\u5956\u52b1\u7684\u504f\u5dee\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfMAB\u7b97\u6cd5\u4ec5\u4f9d\u8d56\u5728\u7ebf\u6570\u636e\uff0c\u6570\u636e\u7a00\u7f3a\u4e14\u83b7\u53d6\u6210\u672c\u9ad8\u3002\u5b9e\u9645\u573a\u666f\u4e2d\uff0c\u4e30\u5bcc\u7684\u8f85\u52a9\u6570\u636e\uff08\u5982\u5386\u53f2\u7528\u6237\u7279\u5f81\uff09\u53ef\u7528\u4e8e\u63d0\u5347\u51b3\u7b56\u6548\u7387\u3002", "method": "\u63d0\u51faMLA-UCB\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u4efb\u610f\u5956\u52b1\u9884\u6d4b\u6a21\u578b\u548c\u8f85\u52a9\u6570\u636e\u5f62\u5f0f\uff0c\u65e0\u9700\u9884\u77e5\u771f\u5b9e\u4e0e\u66ff\u4ee3\u5956\u52b1\u7684\u534f\u65b9\u5dee\u77e9\u9635\u3002", "result": "\u5728\u9884\u6d4b\u4e0e\u771f\u5b9e\u5956\u52b1\u8054\u5408\u9ad8\u65af\u5206\u5e03\u4e14\u76f8\u5173\u6027\u975e\u96f6\u65f6\uff0cMLA-UCB\u53ef\u663e\u8457\u964d\u4f4e\u7d2f\u79ef\u9057\u61be\uff0c\u5373\u4f7f\u66ff\u4ee3\u5956\u52b1\u5747\u503c\u4e0e\u771f\u5b9e\u5747\u503c\u5b8c\u5168\u4e0d\u4e00\u81f4\u3002\u6570\u503c\u5b9e\u9a8c\u663e\u793a\u6548\u7387\u663e\u8457\u63d0\u5347\u3002", "conclusion": "MLA-UCB\u4e3aMAB\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u5229\u7528\u8f85\u52a9\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u66ff\u4ee3\u5956\u52b1\u5b58\u5728\u504f\u5dee\u65f6\u4ecd\u80fd\u4fdd\u6301\u6027\u80fd\u4f18\u52bf\u3002"}}
{"id": "2506.16666", "pdf": "https://arxiv.org/pdf/2506.16666", "abs": "https://arxiv.org/abs/2506.16666", "authors": ["Meenatchi Sundaram Muthu Selva Annamalai", "Borja Balle", "Jamie Hayes", "Georgios Kaissis", "Emiliano De Cristofaro"], "title": "The Hitchhiker's Guide to Efficient, End-to-End, and Tight DP Auditing", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "This paper systematizes research on auditing Differential Privacy (DP)\ntechniques, aiming to identify key insights into the current state of the art\nand open challenges. First, we introduce a comprehensive framework for\nreviewing work in the field and establish three cross-contextual desiderata\nthat DP audits should target--namely, efficiency, end-to-end-ness, and\ntightness. Then, we systematize the modes of operation of state-of-the-art DP\nauditing techniques, including threat models, attacks, and evaluation\nfunctions. This allows us to highlight key details overlooked by prior work,\nanalyze the limiting factors to achieving the three desiderata, and identify\nopen research problems. Overall, our work provides a reusable and systematic\nmethodology geared to assess progress in the field and identify friction points\nand future directions for our community to focus on.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5316\u7814\u7a76\u4e86\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u5ba1\u8ba1\u6280\u672f\uff0c\u603b\u7ed3\u4e86\u5f53\u524d\u7814\u7a76\u7684\u5173\u952e\u89c1\u89e3\u548c\u5f00\u653e\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u8bc4\u4f30\u6846\u67b6\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5dee\u5206\u9690\u79c1\u5ba1\u8ba1\u6280\u672f\u7684\u7814\u7a76\u7f3a\u4e4f\u7cfb\u7edf\u6027\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u9886\u57df\u5185\u7684\u8fdb\u5c55\u8bc4\u4f30\u63d0\u4f9b\u65b9\u6cd5\u8bba\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u5ba1\u8ba1\u6846\u67b6\uff0c\u786e\u7acb\u4e86\u4e09\u4e2a\u6838\u5fc3\u76ee\u6807\uff08\u6548\u7387\u3001\u7aef\u5230\u7aef\u6027\u548c\u7d27\u5bc6\u5ea6\uff09\uff0c\u5e76\u7cfb\u7edf\u5316\u4e86\u73b0\u6709DP\u5ba1\u8ba1\u6280\u672f\u7684\u8fd0\u4f5c\u6a21\u5f0f\u3002", "result": "\u63ed\u793a\u4e86\u73b0\u6709\u7814\u7a76\u7684\u4e0d\u8db3\uff0c\u5206\u6790\u4e86\u5b9e\u73b0\u4e09\u4e2a\u76ee\u6807\u7684\u9650\u5236\u56e0\u7d20\uff0c\u5e76\u6307\u51fa\u4e86\u5f00\u653e\u7684\u7814\u7a76\u95ee\u9898\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u91cd\u590d\u7684\u7cfb\u7edf\u5316\u65b9\u6cd5\u8bba\uff0c\u7528\u4e8e\u8bc4\u4f30\u9886\u57df\u8fdb\u5c55\u5e76\u6307\u5bfc\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.16679", "pdf": "https://arxiv.org/pdf/2506.16679", "abs": "https://arxiv.org/abs/2506.16679", "authors": ["Manuel Brack", "Sudeep Katakol", "Felix Friedrich", "Patrick Schramowski", "Hareesh Ravi", "Kristian Kersting", "Ajinkya Kale"], "title": "How to Train your Text-to-Image Model: Evaluating Design Choices for Synthetic Training Captions", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Training data is at the core of any successful text-to-image models. The\nquality and descriptiveness of image text are crucial to a model's performance.\nGiven the noisiness and inconsistency in web-scraped datasets, recent works\nshifted towards synthetic training captions. While this setup is generally\nbelieved to produce more capable models, current literature does not provide\nany insights into its design choices. This study closes this gap by\nsystematically investigating how different synthetic captioning strategies\nimpact the downstream performance of text-to-image models. Our experiments\ndemonstrate that dense, high-quality captions enhance text alignment but may\nintroduce trade-offs in output aesthetics and diversity. Conversely, captions\nof randomized lengths yield balanced improvements across aesthetics and\nalignment without compromising sample diversity. We also demonstrate that\nvarying caption distributions introduce significant shifts in the output bias\nof a trained model. Our findings underscore the importance of caption design in\nachieving optimal model performance and provide practical insights for more\neffective training data strategies in text-to-image generation.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5408\u6210\u6807\u6ce8\u7b56\u7565\u5bf9\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5bc6\u96c6\u9ad8\u8d28\u91cf\u6807\u6ce8\u63d0\u5347\u6587\u672c\u5bf9\u9f50\u4f46\u53ef\u80fd\u727a\u7272\u7f8e\u5b66\u548c\u591a\u6837\u6027\uff0c\u800c\u968f\u673a\u957f\u5ea6\u6807\u6ce8\u5219\u5e73\u8861\u7f8e\u5b66\u548c\u5bf9\u9f50\u3002", "motivation": "\u63a2\u7d22\u5408\u6210\u6807\u6ce8\u8bbe\u8ba1\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u586b\u8865\u73b0\u6709\u6587\u732e\u7a7a\u767d\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u4e0d\u540c\u5408\u6210\u6807\u6ce8\u7b56\u7565\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5bc6\u96c6\u9ad8\u8d28\u91cf\u6807\u6ce8\u63d0\u5347\u5bf9\u9f50\u4f46\u5f71\u54cd\u7f8e\u5b66\u548c\u591a\u6837\u6027\uff1b\u968f\u673a\u957f\u5ea6\u6807\u6ce8\u5e73\u8861\u6027\u80fd\uff1b\u6807\u6ce8\u5206\u5e03\u5f71\u54cd\u8f93\u51fa\u504f\u5dee\u3002", "conclusion": "\u6807\u6ce8\u8bbe\u8ba1\u5bf9\u6a21\u578b\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u63d0\u4f9b\u5b9e\u7528\u8bad\u7ec3\u7b56\u7565\u3002"}}
{"id": "2506.16827", "pdf": "https://arxiv.org/pdf/2506.16827", "abs": "https://arxiv.org/abs/2506.16827", "authors": ["Grzegorz Gruszczynski", "Michal Jan Wlodarczyk", "Jakub J Meixner", "Przemyslaw Musialski"], "title": "Beyond Blur: A Fluid Perspective on Generative Diffusion Models", "categories": ["cs.GR", "cs.CV", "cs.LG", "I.2.6; I.4.10; I.4.8"], "comment": "11 pages, 8 figures, pre-print, supplementary pseudocode in appendix", "summary": "We propose a novel PDE-driven corruption process for generative image\nsynthesis based on advection-diffusion processes which generalizes existing\nPDE-based approaches. Our forward pass formulates image corruption via a\nphysically motivated PDE that couples directional advection with isotropic\ndiffusion and Gaussian noise, controlled by dimensionless numbers (Peclet,\nFourier). We implement this PDE numerically through a GPU-accelerated custom\nLattice Boltzmann solver for fast evaluation. To induce realistic turbulence,\nwe generate stochastic velocity fields that introduce coherent motion and\ncapture multi-scale mixing. In the generative process, a neural network learns\nto reverse the advection-diffusion operator thus constituting a novel\ngenerative model. We discuss how previous methods emerge as specific cases of\nour operator, demonstrating that our framework generalizes prior PDE-based\ncorruption techniques. We illustrate how advection improves the diversity and\nquality of the generated images while keeping the overall color palette\nunaffected. This work bridges fluid dynamics, dimensionless PDE theory, and\ndeep generative modeling, offering a fresh perspective on physically informed\nimage corruption processes for diffusion-based synthesis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePDE\u7684\u56fe\u50cf\u751f\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u6d41\u4f53\u52a8\u529b\u5b66\u548c\u6df1\u5ea6\u5b66\u4e60\uff0c\u901a\u8fc7\u53ef\u9006\u7684PDE\u8fc7\u7a0b\u751f\u6210\u9ad8\u8d28\u91cf\u56fe\u50cf\u3002", "motivation": "\u63a2\u7d22\u7269\u7406\u9a71\u52a8\u7684\u56fe\u50cf\u751f\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u6d41\u4f53\u52a8\u529b\u5b66\u7406\u8bba\uff0c\u63d0\u5347\u751f\u6210\u56fe\u50cf\u7684\u591a\u6837\u6027\u548c\u8d28\u91cf\u3002", "method": "\u91c7\u7528PDE\u9a71\u52a8\u7684\u56fe\u50cf\u9000\u5316\u8fc7\u7a0b\uff0c\u7ed3\u5408\u65b9\u5411\u6027\u5e73\u6d41\u3001\u5404\u5411\u540c\u6027\u6269\u6563\u548c\u9ad8\u65af\u566a\u58f0\uff0c\u901a\u8fc7GPU\u52a0\u901f\u7684Lattice Boltzmann\u6c42\u89e3\u5668\u5b9e\u73b0\u5feb\u901f\u8ba1\u7b97\u3002", "result": "\u751f\u6210\u7684\u56fe\u50cf\u5728\u4fdd\u6301\u8272\u5f69\u4e00\u81f4\u6027\u7684\u540c\u65f6\uff0c\u63d0\u5347\u4e86\u591a\u6837\u6027\u548c\u8d28\u91cf\uff0c\u4e14\u6846\u67b6\u80fd\u591f\u6cdb\u5316\u73b0\u6709\u7684PDE\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u57fa\u4e8e\u6269\u6563\u7684\u56fe\u50cf\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u7684\u7269\u7406\u9a71\u52a8\u89c6\u89d2\uff0c\u7ed3\u5408\u4e86\u6d41\u4f53\u52a8\u529b\u5b66\u548c\u6df1\u5ea6\u5b66\u4e60\u3002"}}
{"id": "2506.16895", "pdf": "https://arxiv.org/pdf/2506.16895", "abs": "https://arxiv.org/abs/2506.16895", "authors": ["Fabian Gr\u00f6ger", "Shuo Wen", "Huyen Le", "Maria Brbi\u0107"], "title": "With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Multimodal models have demonstrated powerful capabilities in complex tasks\nrequiring multimodal alignment including zero-shot classification and\ncross-modal retrieval. However, existing models typically rely on millions of\npaired multimodal samples, which are prohibitively expensive or infeasible to\nobtain in many domains. In this work, we explore the feasibility of building\nmultimodal models with limited amount of paired data by aligning pretrained\nunimodal foundation models. We show that high-quality alignment is possible\nwith as few as tens of thousands of paired samples$\\unicode{x2013}$less than\n$1\\%$ of the data typically used in the field. To achieve this, we introduce\nSTRUCTURE, an effective regularization technique that preserves the\nneighborhood geometry of the latent space of unimodal encoders. Additionally,\nwe show that aligning last layers is often suboptimal and demonstrate the\nbenefits of aligning the layers with the highest representational similarity\nacross modalities. These two components can be readily incorporated into\nexisting alignment methods, yielding substantial gains across 24 zero-shot\nimage classification and retrieval benchmarks, with average relative\nimprovement of $51.6\\%$ in classification and $91.8\\%$ in retrieval tasks. Our\nresults highlight the effectiveness and broad applicability of our framework\nfor limited-sample multimodal learning and offer a promising path forward for\nresource-constrained domains.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u6709\u9650\u914d\u5bf9\u6570\u636e\u4e0b\u6784\u5efa\u591a\u6a21\u6001\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u9f50\u9884\u8bad\u7ec3\u7684\u5355\u6a21\u6001\u57fa\u7840\u6a21\u578b\uff0c\u4ec5\u9700\u5c11\u91cf\u6837\u672c\u5373\u53ef\u5b9e\u73b0\u9ad8\u8d28\u91cf\u5bf9\u9f50\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u6a21\u578b\u4f9d\u8d56\u5927\u91cf\u914d\u5bf9\u6837\u672c\uff0c\u6210\u672c\u9ad8\u6602\u4e14\u96be\u4ee5\u83b7\u53d6\uff0c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8d44\u6e90\u53d7\u9650\u9886\u57df\u7684\u591a\u6a21\u6001\u5b66\u4e60\u95ee\u9898\u3002", "method": "\u5f15\u5165STRUCTURE\u6b63\u5219\u5316\u6280\u672f\uff0c\u4fdd\u6301\u5355\u6a21\u6001\u7f16\u7801\u5668\u6f5c\u5728\u7a7a\u95f4\u7684\u90bb\u57df\u51e0\u4f55\u7ed3\u6784\uff0c\u5e76\u4f18\u5316\u5bf9\u9f50\u5c42\u9009\u62e9\u3002", "result": "\u572824\u4e2a\u96f6\u6837\u672c\u56fe\u50cf\u5206\u7c7b\u548c\u68c0\u7d22\u4efb\u52a1\u4e2d\uff0c\u5e73\u5747\u76f8\u5bf9\u63d0\u534751.6%\uff08\u5206\u7c7b\uff09\u548c91.8%\uff08\u68c0\u7d22\uff09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8d44\u6e90\u53d7\u9650\u9886\u57df\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2506.16903", "pdf": "https://arxiv.org/pdf/2506.16903", "abs": "https://arxiv.org/abs/2506.16903", "authors": ["Arnaud Verdant", "William Guicquero", "J\u00e9r\u00f4me Chossat"], "title": "RCNet: $\u0394\u03a3$ IADCs as Recurrent AutoEncoders", "categories": ["cs.AR", "cs.LG"], "comment": null, "summary": "This paper proposes a deep learning model (RCNet) for Delta-Sigma\n($\\Delta\\Sigma$) ADCs. Recurrent Neural Networks (RNNs) allow to describe both\nmodulators and filters. This analogy is applied to Incremental ADCs (IADC).\nHigh-end optimizers combined with full-custom losses are used to define\nadditional hardware design constraints: quantized weights, signal saturation,\ntemporal noise injection, devices area. Focusing on DC conversion, our early\nresults demonstrate that $SNR$ defined as an Effective Number Of Bits (ENOB)\ncan be optimized under a certain hardware mapping complexity. The proposed\nRCNet succeeded to provide design tradeoffs in terms of $SNR$ ($>$13bit) versus\narea constraints ($<$14pF total capacitor) at a given $OSR$ (80 samples).\nInterestingly, it appears that the best RCNet architectures do not necessarily\nrely on high-order modulators, leveraging additional topology exploration\ndegrees of freedom.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8eDelta-Sigma ADC\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08RCNet\uff09\uff0c\u5229\u7528RNN\u63cf\u8ff0\u8c03\u5236\u5668\u548c\u6ee4\u6ce2\u5668\uff0c\u7ed3\u5408\u786c\u4ef6\u8bbe\u8ba1\u7ea6\u675f\u4f18\u5316SNR\u4e0e\u9762\u79ef\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4f18\u5316Delta-Sigma ADC\u7684\u8bbe\u8ba1\uff0c\u7279\u522b\u662f\u5728\u786c\u4ef6\u7ea6\u675f\u4e0b\u63d0\u5347\u6027\u80fd\u3002", "method": "\u91c7\u7528RNN\u63cf\u8ff0\u8c03\u5236\u5668\u548c\u6ee4\u6ce2\u5668\uff0c\u7ed3\u5408\u9ad8\u4f18\u5316\u5668\u548c\u5b9a\u5236\u635f\u5931\u51fd\u6570\uff0c\u8003\u8651\u91cf\u5316\u6743\u91cd\u3001\u4fe1\u53f7\u9971\u548c\u7b49\u786c\u4ef6\u7ea6\u675f\u3002", "result": "\u5728DC\u8f6c\u6362\u4e2d\uff0cRCNet\u6210\u529f\u4f18\u5316\u4e86SNR\uff08>13bit\uff09\u4e0e\u9762\u79ef\uff08<14pF\uff09\u7684\u6743\u8861\uff0c\u4e14\u6700\u4f73\u67b6\u6784\u4e0d\u4f9d\u8d56\u9ad8\u9636\u8c03\u5236\u5668\u3002", "conclusion": "RCNet\u4e3aDelta-Sigma ADC\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u81ea\u7531\u5ea6\uff0c\u5c55\u793a\u4e86\u6df1\u5ea6\u5b66\u4e60\u5728\u786c\u4ef6\u4f18\u5316\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.16912", "pdf": "https://arxiv.org/pdf/2506.16912", "abs": "https://arxiv.org/abs/2506.16912", "authors": ["Daniel Christoph", "Max Ploner", "Patrick Haller", "Alan Akbik"], "title": "From Data to Knowledge: Evaluating How Efficiently Language Models Learn Facts", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to the First Workshop on Large Language Model Memorization\n  (L2M2), co-located with ACL 2025 in Vienna", "summary": "Sample efficiency is a crucial property of language models with practical\nimplications for training efficiency. In real-world text, information follows a\nlong-tailed distribution. Yet, we expect models to learn and recall frequent\nand infrequent facts. Sample-efficient models are better equipped to handle\nthis challenge of learning and retaining rare information without requiring\nexcessive exposure. This study analyzes multiple models of varying\narchitectures and sizes, all trained on the same pre-training data. By\nannotating relational facts with their frequencies in the training corpus, we\nexamine how model performance varies with fact frequency. Our findings show\nthat most models perform similarly on high-frequency facts but differ notably\non low-frequency facts. This analysis provides new insights into the\nrelationship between model architecture, size, and factual learning efficiency.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u4e0d\u540c\u67b6\u6784\u548c\u5927\u5c0f\u7684\u8bed\u8a00\u6a21\u578b\u5728\u6837\u672c\u6548\u7387\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u9ad8\u9891\u4e8b\u5b9e\u4e0a\u7684\u8868\u73b0\u76f8\u4f3c\uff0c\u4f46\u5728\u4f4e\u9891\u4e8b\u5b9e\u4e0a\u5dee\u5f02\u663e\u8457\u3002", "motivation": "\u63a2\u7d22\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u9ad8\u6548\u5b66\u4e60\u548c\u8bb0\u5fc6\u957f\u5c3e\u5206\u5e03\u4e2d\u7684\u4fe1\u606f\uff0c\u5c24\u5176\u662f\u4f4e\u9891\u4e8b\u5b9e\u3002", "method": "\u901a\u8fc7\u6807\u6ce8\u8bad\u7ec3\u8bed\u6599\u4e2d\u5173\u7cfb\u4e8b\u5b9e\u7684\u9891\u7387\uff0c\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u5728\u4e0d\u540c\u9891\u7387\u4e8b\u5b9e\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5927\u591a\u6570\u6a21\u578b\u5728\u9ad8\u9891\u4e8b\u5b9e\u4e0a\u8868\u73b0\u76f8\u4f3c\uff0c\u4f46\u5728\u4f4e\u9891\u4e8b\u5b9e\u4e0a\u8868\u73b0\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "\u6a21\u578b\u67b6\u6784\u548c\u5927\u5c0f\u5bf9\u4e8b\u5b9e\u5b66\u4e60\u6548\u7387\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u4f4e\u9891\u4e8b\u5b9e\u3002"}}
{"id": "2506.16918", "pdf": "https://arxiv.org/pdf/2506.16918", "abs": "https://arxiv.org/abs/2506.16918", "authors": ["Dhananjeyan Jeyaraj", "Hamidreza Eivazi", "Jendrik-Alexander Tr\u00f6ger", "Stefan Wittek", "Stefan Hartmann", "Andreas Rausch"], "title": "A Neural Operator based Hybrid Microscale Model for Multiscale Simulation of Rate-Dependent Materials", "categories": ["physics.comp-ph", "cs.CE", "cs.LG"], "comment": null, "summary": "The behavior of materials is influenced by a wide range of phenomena\noccurring across various time and length scales. To better understand the\nimpact of microstructure on macroscopic response, multiscale modeling\nstrategies are essential. Numerical methods, such as the $\\text{FE}^2$\napproach, account for micro-macro interactions to predict the global response\nin a concurrent manner. However, these methods are computationally intensive\ndue to the repeated evaluations of the microscale. This challenge has led to\nthe integration of deep learning techniques into computational homogenization\nframeworks to accelerate multiscale simulations. In this work, we employ neural\noperators to predict the microscale physics, resulting in a hybrid model that\ncombines data-driven and physics-based approaches. This allows for\nphysics-guided learning and provides flexibility for different materials and\nspatial discretizations. We apply this method to time-dependent solid mechanics\nproblems involving viscoelastic material behavior, where the state is\nrepresented by internal variables only at the microscale. The constitutive\nrelations of the microscale are incorporated into the model architecture and\nthe internal variables are computed based on established physical principles.\nThe results for homogenized stresses ($<6\\%$ error) show that the approach is\ncomputationally efficient ($\\sim 100 \\times$ faster).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u591a\u5c3a\u5ea6\u5efa\u6a21\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u795e\u7ecf\u7b97\u5b50\u9884\u6d4b\u5fae\u89c2\u7269\u7406\u884c\u4e3a\uff0c\u663e\u8457\u52a0\u901f\u8ba1\u7b97\u3002", "motivation": "\u7406\u89e3\u5fae\u89c2\u7ed3\u6784\u5bf9\u5b8f\u89c2\u54cd\u5e94\u7684\u5f71\u54cd\u9700\u8981\u591a\u5c3a\u5ea6\u5efa\u6a21\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u91c7\u7528\u795e\u7ecf\u7b97\u5b50\u9884\u6d4b\u5fae\u89c2\u7269\u7406\u884c\u4e3a\uff0c\u7ed3\u5408\u6570\u636e\u9a71\u52a8\u548c\u7269\u7406\u6a21\u578b\uff0c\u5e94\u7528\u4e8e\u7c98\u5f39\u6027\u6750\u6599\u529b\u5b66\u95ee\u9898\u3002", "result": "\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u9ad8\uff08\u7ea6\u5feb100\u500d\uff09\uff0c\u5747\u8d28\u5316\u5e94\u529b\u8bef\u5dee\u4f4e\u4e8e6%\u3002", "conclusion": "\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u7684\u591a\u5c3a\u5ea6\u5efa\u6a21\u65b9\u6cd5\u9ad8\u6548\u4e14\u51c6\u786e\uff0c\u9002\u7528\u4e8e\u590d\u6742\u6750\u6599\u884c\u4e3a\u6a21\u62df\u3002"}}
{"id": "2506.16938", "pdf": "https://arxiv.org/pdf/2506.16938", "abs": "https://arxiv.org/abs/2506.16938", "authors": ["Sebastian Nagies", "Emiliano Tolotti", "Davide Pastorello", "Enrico Blanzieri"], "title": "Enhancing Expressivity of Quantum Neural Networks Based on the SWAP test", "categories": ["quant-ph", "cs.ET", "cs.LG"], "comment": "15 pages, 7 figures", "summary": "Parameterized quantum circuits represent promising architectures for machine\nlearning applications, yet many lack clear connections to classical models,\npotentially limiting their ability to translate the wide success of classical\nneural networks to the quantum realm. We examine a specific type of quantum\nneural network (QNN) built exclusively from SWAP test circuits, and discuss its\nmathematical equivalence to a classical two-layer feedforward network with\nquadratic activation functions under amplitude encoding. Our analysis across\nclassical real-world and synthetic datasets reveals that while this\narchitecture can successfully learn many practical tasks, it exhibits\nfundamental expressivity limitations due to violating the universal\napproximation theorem, particularly failing on harder problems like the parity\ncheck function. To address this limitation, we introduce a circuit modification\nusing generalized SWAP test circuits that effectively implements classical\nneural networks with product layers. This enhancement enables successful\nlearning of parity check functions in arbitrary dimensions which we\nanalytically argue to be impossible for the original architecture beyond two\ndimensions regardless of network size. Our results establish a framework for\nenhancing QNN expressivity through classical task analysis and demonstrate that\nour SWAP test-based architecture offers broad representational capacity,\nsuggesting potential promise also for quantum learning tasks.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8eSWAP\u6d4b\u8bd5\u7535\u8def\u7684\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\uff08QNN\uff09\uff0c\u53d1\u73b0\u5176\u6570\u5b66\u4e0a\u7b49\u6548\u4e8e\u5177\u6709\u4e8c\u6b21\u6fc0\u6d3b\u51fd\u6570\u7684\u7ecf\u5178\u4e24\u5c42\u524d\u9988\u7f51\u7edc\uff0c\u4f46\u5b58\u5728\u8868\u8fbe\u80fd\u529b\u9650\u5236\u3002\u901a\u8fc7\u5f15\u5165\u5e7f\u4e49SWAP\u6d4b\u8bd5\u7535\u8def\uff0c\u89e3\u51b3\u4e86\u539f\u59cb\u67b6\u6784\u65e0\u6cd5\u5904\u7406\u9ad8\u7ef4\u5947\u5076\u6821\u9a8c\u51fd\u6570\u7684\u95ee\u9898\u3002", "motivation": "\u63a2\u8ba8\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\u4e0e\u7ecf\u5178\u6a21\u578b\u7684\u8054\u7cfb\uff0c\u4ee5\u63d0\u5347\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u7684\u80fd\u529b\u3002", "method": "\u5206\u6790\u57fa\u4e8eSWAP\u6d4b\u8bd5\u7535\u8def\u7684QNN\uff0c\u5e76\u5f15\u5165\u5e7f\u4e49SWAP\u6d4b\u8bd5\u7535\u8def\u4ee5\u589e\u5f3a\u8868\u8fbe\u80fd\u529b\u3002", "result": "\u539f\u59cb\u67b6\u6784\u5728\u5947\u5076\u6821\u9a8c\u51fd\u6570\u7b49\u9ad8\u96be\u5ea6\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u6539\u8fdb\u540e\u7684\u67b6\u6784\u6210\u529f\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u7ecf\u5178\u4efb\u52a1\u5206\u6790\u589e\u5f3aQNN\u8868\u8fbe\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u57fa\u4e8eSWAP\u6d4b\u8bd5\u7684\u67b6\u6784\u5728\u91cf\u5b50\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.16950", "pdf": "https://arxiv.org/pdf/2506.16950", "abs": "https://arxiv.org/abs/2506.16950", "authors": ["Fanfei Li", "Thomas Klein", "Wieland Brendel", "Robert Geirhos", "Roland S. Zimmermann"], "title": "LAION-C: An Out-of-Distribution Benchmark for Web-Scale Vision Models", "categories": ["cs.CV", "cs.LG"], "comment": "ICML 2025 camera ready version", "summary": "Out-of-distribution (OOD) robustness is a desired property of computer vision\nmodels. Improving model robustness requires high-quality signals from\nrobustness benchmarks to quantify progress. While various benchmark datasets\nsuch as ImageNet-C were proposed in the ImageNet era, most ImageNet-C\ncorruption types are no longer OOD relative to today's large, web-scraped\ndatasets, which already contain common corruptions such as blur or JPEG\ncompression artifacts. Consequently, these benchmarks are no longer well-suited\nfor evaluating OOD robustness in the era of web-scale datasets. Indeed, recent\nmodels show saturating scores on ImageNet-era OOD benchmarks, indicating that\nit is unclear whether models trained on web-scale datasets truly become better\nat OOD generalization or whether they have simply been exposed to the test\ndistortions during training. To address this, we introduce LAION-C as a\nbenchmark alternative for ImageNet-C. LAION-C consists of six novel distortion\ntypes specifically designed to be OOD, even for web-scale datasets such as\nLAION. In a comprehensive evaluation of state-of-the-art models, we find that\nthe LAION-C dataset poses significant challenges to contemporary models,\nincluding MLLMs such as Gemini and GPT-4o. We additionally conducted a\npsychophysical experiment to evaluate the difficulty of our corruptions for\nhuman observers, enabling a comparison of models to lab-quality human\nrobustness data. We observe a paradigm shift in OOD generalization: from humans\noutperforming models, to the best models now matching or outperforming the best\nhuman observers.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLAION-C\u4f5c\u4e3aImageNet-C\u7684\u66ff\u4ee3\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5728web-scale\u6570\u636e\u96c6\u65f6\u4ee3\u7684OOD\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728LAION-C\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u90e8\u5206\u6a21\u578b\u5df2\u63a5\u8fd1\u6216\u8d85\u8d8a\u4eba\u7c7b\u8868\u73b0\u3002", "motivation": "\u73b0\u6709OOD\u57fa\u51c6\uff08\u5982ImageNet-C\uff09\u5df2\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30web-scale\u6570\u636e\u96c6\u65f6\u4ee3\u7684\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u9700\u8bbe\u8ba1\u65b0\u7684\u57fa\u51c6\u3002", "method": "\u5f15\u5165LAION-C\uff0c\u5305\u542b\u516d\u79cd\u65b0\u578b\u5931\u771f\u7c7b\u578b\uff0c\u786e\u4fdd\u5176\u5bf9web-scale\u6570\u636e\u96c6\u4ecd\u4e3aOOD\uff0c\u5e76\u8bc4\u4f30\u4e86\u5305\u62ecMLLMs\u5728\u5185\u7684\u5148\u8fdb\u6a21\u578b\u3002", "result": "LAION-C\u5bf9\u5f53\u524d\u6a21\u578b\u6784\u6210\u663e\u8457\u6311\u6218\uff0c\u4f46\u90e8\u5206\u6a21\u578b\uff08\u5982Gemini\u548cGPT-4o\uff09\u5df2\u63a5\u8fd1\u6216\u8d85\u8d8a\u4eba\u7c7b\u8868\u73b0\u3002", "conclusion": "LAION-C\u4e3aOOD\u9c81\u68d2\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u6807\u51c6\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u6027\u80fd\u7684\u8303\u5f0f\u8f6c\u53d8\uff1a\u4ece\u843d\u540e\u4e8e\u4eba\u7c7b\u5230\u63a5\u8fd1\u6216\u8d85\u8d8a\u4eba\u7c7b\u3002"}}
{"id": "2506.16982", "pdf": "https://arxiv.org/pdf/2506.16982", "abs": "https://arxiv.org/abs/2506.16982", "authors": ["Antonin Berthon", "Mihaela van der Schaar"], "title": "Language Bottleneck Models: A Framework for Interpretable Knowledge Tracing and Beyond", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Accurately assessing student knowledge is critical for effective education,\nyet traditional Knowledge Tracing (KT) methods rely on opaque latent\nembeddings, limiting interpretability. Even LLM-based approaches generate\ndirect predictions or summaries that may hallucinate without any accuracy\nguarantees. We recast KT as an inverse problem: learning the minimum\nnatural-language summary that makes past answers explainable and future answers\npredictable. Our Language Bottleneck Model (LBM) consists of an encoder LLM\nthat writes an interpretable knowledge summary and a frozen decoder LLM that\nmust reconstruct and predict student responses using only that summary text. By\nconstraining all predictive information to pass through a short\nnatural-language bottleneck, LBMs ensure that the summary contains accurate\ninformation while remaining human-interpretable. Experiments on synthetic\narithmetic benchmarks and the large-scale Eedi dataset show that LBMs rival the\naccuracy of state-of-the-art KT and direct LLM methods while requiring\norders-of-magnitude fewer student trajectories. We demonstrate that training\nthe encoder with group-relative policy optimization, using downstream decoding\naccuracy as a reward signal, effectively improves summary quality.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u8a00\u74f6\u9888\u6a21\u578b\uff08LBM\uff09\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6458\u8981\u89e3\u51b3\u77e5\u8bc6\u8ffd\u8e2a\uff08KT\uff09\u95ee\u9898\uff0c\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u77e5\u8bc6\u8ffd\u8e2a\u65b9\u6cd5\u4f9d\u8d56\u4e0d\u900f\u660e\u7684\u6f5c\u5728\u5d4c\u5165\uff0c\u53ef\u89e3\u91ca\u6027\u5dee\uff1bLLM\u65b9\u6cd5\u53ef\u80fd\u4ea7\u751f\u4e0d\u51c6\u786e\u7684\u9884\u6d4b\u6216\u6458\u8981\u3002", "method": "LBM\u7531\u7f16\u7801\u5668LLM\u751f\u6210\u53ef\u89e3\u91ca\u7684\u77e5\u8bc6\u6458\u8981\uff0c\u89e3\u7801\u5668LLM\u4ec5\u57fa\u4e8e\u6458\u8981\u91cd\u5efa\u548c\u9884\u6d4b\u5b66\u751f\u56de\u7b54\u3002\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u74f6\u9888\u7ea6\u675f\u4fe1\u606f\u4f20\u9012\uff0c\u786e\u4fdd\u6458\u8981\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u3002", "result": "\u5728\u5408\u6210\u7b97\u672f\u57fa\u51c6\u548c\u5927\u89c4\u6a21Eedi\u6570\u636e\u96c6\u4e0a\uff0cLBM\u7684\u51c6\u786e\u6027\u5ab2\u7f8e\u6700\u5148\u8fdb\u7684KT\u548cLLM\u65b9\u6cd5\uff0c\u4e14\u6240\u9700\u5b66\u751f\u8f68\u8ff9\u6570\u636e\u66f4\u5c11\u3002", "conclusion": "LBM\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6458\u8981\u6709\u6548\u5e73\u8861\u4e86\u77e5\u8bc6\u8ffd\u8e2a\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u901a\u8fc7\u7b56\u7565\u4f18\u5316\u63d0\u5347\u6458\u8981\u8d28\u91cf\u3002"}}
{"id": "2506.16994", "pdf": "https://arxiv.org/pdf/2506.16994", "abs": "https://arxiv.org/abs/2506.16994", "authors": ["Yasir Ali Farrukh", "Syed Wali", "Irfan Khan", "Nathaniel D. Bastian"], "title": "Prmpt2Adpt: Prompt-Based Zero-Shot Domain Adaptation for Resource-Constrained Environments", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Unsupervised Domain Adaptation (UDA) is a critical challenge in real-world\nvision systems, especially in resource-constrained environments like drones,\nwhere memory and computation are limited. Existing prompt-driven UDA methods\ntypically rely on large vision-language models and require full access to\nsource-domain data during adaptation, limiting their applicability. In this\nwork, we propose Prmpt2Adpt, a lightweight and efficient zero-shot domain\nadaptation framework built around a teacher-student paradigm guided by\nprompt-based feature alignment. At the core of our method is a distilled and\nfine-tuned CLIP model, used as the frozen backbone of a Faster R-CNN teacher. A\nsmall set of low-level source features is aligned to the target domain\nsemantics-specified only through a natural language prompt-via Prompt-driven\nInstance Normalization (PIN). These semantically steered features are used to\nbriefly fine-tune the detection head of the teacher model. The adapted teacher\nthen generates high-quality pseudo-labels, which guide the on-the-fly\nadaptation of a compact student model. Experiments on the MDS-A dataset\ndemonstrate that Prmpt2Adpt achieves competitive detection performance compared\nto state-of-the-art methods, while delivering up to 7x faster adaptation and 5x\nfaster inference speed using few source images-making it a practical and\nscalable solution for real-time adaptation in low-resource domains.", "AI": {"tldr": "Prmpt2Adpt\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u9ad8\u6548\u7684\u96f6\u6837\u672c\u57df\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u793a\u9a71\u52a8\u7684\u7279\u5f81\u5bf9\u9f50\u548c\u5e08\u751f\u8303\u5f0f\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u5b9e\u73b0\u5feb\u901f\u9002\u5e94\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u63d0\u793a\u9a71\u52a8\u7684\u65e0\u76d1\u7763\u57df\u9002\u5e94\u65b9\u6cd5\u4f9d\u8d56\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e14\u9700\u5b8c\u6574\u6e90\u57df\u6570\u636e\u7684\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u573a\u666f\u3002", "method": "\u57fa\u4e8e\u84b8\u998f\u548c\u5fae\u8c03\u7684CLIP\u6a21\u578b\u4f5c\u4e3a\u6559\u5e08\u6a21\u578b\u9aa8\u5e72\uff0c\u901a\u8fc7\u63d0\u793a\u9a71\u52a8\u7684\u5b9e\u4f8b\u5f52\u4e00\u5316\uff08PIN\uff09\u5bf9\u9f50\u7279\u5f81\uff0c\u751f\u6210\u4f2a\u6807\u7b7e\u6307\u5bfc\u5b66\u751f\u6a21\u578b\u9002\u5e94\u3002", "result": "\u5728MDS-A\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u5e94\u901f\u5ea6\u63d0\u53477\u500d\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u53475\u500d\u3002", "conclusion": "Prmpt2Adpt\u662f\u4f4e\u8d44\u6e90\u9886\u57df\u4e2d\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u5b9e\u65f6\u9002\u5e94\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.17015", "pdf": "https://arxiv.org/pdf/2506.17015", "abs": "https://arxiv.org/abs/2506.17015", "authors": ["Dominic Schuh", "Janik Kreit", "Evan Berkowitz", "Lena Funcke", "Thomas Luu", "Kim A. Nicoli", "Marcel Rodekamp"], "title": "Simulating Correlated Electrons with Symmetry-Enforced Normalizing Flows", "categories": ["cond-mat.str-el", "cs.LG", "hep-lat"], "comment": "9 pages, 7 figures", "summary": "We present the first proof of principle that normalizing flows can accurately\nlearn the Boltzmann distribution of the fermionic Hubbard model - a key\nframework for describing the electronic structure of graphene and related\nmaterials. State-of-the-art methods like Hybrid Monte Carlo often suffer from\nergodicity issues near the time-continuum limit, leading to biased estimates.\nLeveraging symmetry-aware architectures as well as independent and identically\ndistributed sampling, our approach resolves these issues and achieves\nsignificant speed-ups over traditional methods.", "AI": {"tldr": "\u9996\u6b21\u8bc1\u660e\u5f52\u4e00\u5316\u6d41\u53ef\u4ee5\u51c6\u786e\u5b66\u4e60\u8d39\u7c73\u5b50\u54c8\u4f2f\u5fb7\u6a21\u578b\u7684\u73bb\u5c14\u5179\u66fc\u5206\u5e03\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u904d\u5386\u6027\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u6df7\u5408\u8499\u7279\u5361\u6d1b\uff09\u5728\u65f6\u95f4\u8fde\u7eed\u6781\u9650\u9644\u8fd1\u5b58\u5728\u904d\u5386\u6027\u95ee\u9898\uff0c\u5bfc\u81f4\u4f30\u8ba1\u504f\u5dee\u3002", "method": "\u5229\u7528\u5bf9\u79f0\u611f\u77e5\u67b6\u6784\u548c\u72ec\u7acb\u540c\u5206\u5e03\u91c7\u6837\uff0c\u89e3\u51b3\u4e86\u904d\u5386\u6027\u95ee\u9898\u3002", "result": "\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u901f\u5ea6\u3002", "conclusion": "\u5f52\u4e00\u5316\u6d41\u4e3a\u8d39\u7c73\u5b50\u54c8\u4f2f\u5fb7\u6a21\u578b\u7684\u7535\u5b50\u7ed3\u6784\u63cf\u8ff0\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.17018", "pdf": "https://arxiv.org/pdf/2506.17018", "abs": "https://arxiv.org/abs/2506.17018", "authors": ["Davide Frizzo", "Francesco Borsatti", "Gian Antonio Susto"], "title": "A Quantile Regression Approach for Remaining Useful Life Estimation with State Space Models", "categories": ["cs.AI", "cs.LG"], "comment": "Submitted to IFAC Joint Conference on Computers, Cognition, and\n  Communication (J3C) 2025", "summary": "Predictive Maintenance (PdM) is pivotal in Industry 4.0 and 5.0, proactively\nenhancing efficiency through accurate equipment Remaining Useful Life (RUL)\nprediction, thus optimizing maintenance scheduling and reducing unexpected\nfailures and premature interventions. This paper introduces a novel RUL\nestimation approach leveraging State Space Models (SSM) for efficient long-term\nsequence modeling. To handle model uncertainty, Simoultaneous Quantile\nRegression (SQR) is integrated into the SSM, enabling multiple quantile\nestimations. The proposed method is benchmarked against traditional sequence\nmodelling techniques (LSTM, Transformer, Informer) using the C-MAPSS dataset.\nResults demonstrate superior accuracy and computational efficiency of SSM\nmodels, underscoring their potential for high-stakes industrial applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSM\uff09\u548c\u540c\u6b65\u5206\u4f4d\u6570\u56de\u5f52\uff08SQR\uff09\u7684\u5269\u4f59\u4f7f\u7528\u5bff\u547d\uff08RUL\uff09\u9884\u6d4b\u65b9\u6cd5\uff0c\u5728\u5de5\u4e1a4.0\u548c5.0\u4e2d\u4f18\u5316\u7ef4\u62a4\u8ba1\u5212\u3002", "motivation": "\u9884\u6d4b\u6027\u7ef4\u62a4\uff08PdM\uff09\u5728\u5de5\u4e1a4.0\u548c5.0\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u901a\u8fc7\u51c6\u786e\u9884\u6d4b\u8bbe\u5907\u5269\u4f59\u4f7f\u7528\u5bff\u547d\uff08RUL\uff09\u6765\u63d0\u9ad8\u6548\u7387\uff0c\u51cf\u5c11\u610f\u5916\u6545\u969c\u548c\u8fc7\u65e9\u5e72\u9884\u3002", "method": "\u7ed3\u5408\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSM\uff09\u548c\u540c\u6b65\u5206\u4f4d\u6570\u56de\u5f52\uff08SQR\uff09\uff0c\u5b9e\u73b0\u9ad8\u6548\u957f\u671f\u5e8f\u5217\u5efa\u6a21\u548c\u591a\u5206\u4f4d\u6570\u4f30\u8ba1\u3002", "result": "\u5728C-MAPSS\u6570\u636e\u96c6\u4e0a\uff0cSSM\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u5e8f\u5217\u5efa\u6a21\u6280\u672f\uff08\u5982LSTM\u3001Transformer\u3001Informer\uff09\u3002", "conclusion": "SSM\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u5de5\u4e1a\u5e94\u7528\u4e2d\u5177\u6709\u663e\u8457\u6f5c\u529b\u3002"}}
{"id": "2506.17036", "pdf": "https://arxiv.org/pdf/2506.17036", "abs": "https://arxiv.org/abs/2506.17036", "authors": ["Sina Aghaee Dabaghan Fard", "Minhee Kim", "Akash Deep", "Jaesung Lee"], "title": "Bayesian Joint Model of Multi-Sensor and Failure Event Data for Multi-Mode Failure Prediction", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "Modern industrial systems are often subject to multiple failure modes, and\ntheir conditions are monitored by multiple sensors, generating multiple\ntime-series signals. Additionally, time-to-failure data are commonly available.\nAccurately predicting a system's remaining useful life (RUL) requires\neffectively leveraging multi-sensor time-series data alongside multi-mode\nfailure event data. In most existing models, failure modes and RUL prediction\nare performed independently, ignoring the inherent relationship between these\ntwo tasks. Some models integrate multiple failure modes and event prediction\nusing black-box machine learning approaches, which lack statistical rigor and\ncannot characterize the inherent uncertainty in the model and data. This paper\nintroduces a unified approach to jointly model the multi-sensor time-series\ndata and failure time concerning multiple failure modes. This proposed model\nintegrate a Cox proportional hazards model, a Convolved Multi-output Gaussian\nProcess, and multinomial failure mode distributions in a hierarchical Bayesian\nframework with corresponding priors, enabling accurate prediction with robust\nuncertainty quantification. Posterior distributions are effectively obtained by\nVariational Bayes, and prediction is performed with Monte Carlo sampling. The\nadvantages of the proposed model is validated through extensive numerical and\ncase studies with jet-engine dataset.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u65b9\u6cd5\uff0c\u8054\u5408\u5efa\u6a21\u591a\u4f20\u611f\u5668\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u548c\u591a\u6545\u969c\u6a21\u5f0f\u7684\u5931\u6548\u65f6\u95f4\uff0c\u901a\u8fc7\u5206\u5c42\u8d1d\u53f6\u65af\u6846\u67b6\u6574\u5408Cox\u6bd4\u4f8b\u98ce\u9669\u6a21\u578b\u3001\u5377\u79ef\u591a\u8f93\u51fa\u9ad8\u65af\u8fc7\u7a0b\u548c\u591a\u9879\u6545\u969c\u6a21\u5f0f\u5206\u5e03\uff0c\u5b9e\u73b0\u51c6\u786e\u9884\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "motivation": "\u73b0\u4ee3\u5de5\u4e1a\u7cfb\u7edf\u5e38\u53d7\u591a\u79cd\u6545\u969c\u6a21\u5f0f\u5f71\u54cd\uff0c\u4e14\u5176\u72b6\u6001\u7531\u591a\u4f20\u611f\u5668\u76d1\u6d4b\u751f\u6210\u65f6\u95f4\u5e8f\u5217\u4fe1\u53f7\u3002\u73b0\u6709\u6a21\u578b\u901a\u5e38\u72ec\u7acb\u5904\u7406\u6545\u969c\u6a21\u5f0f\u548c\u5269\u4f59\u4f7f\u7528\u5bff\u547d\uff08RUL\uff09\u9884\u6d4b\uff0c\u5ffd\u7565\u4e86\u4efb\u52a1\u95f4\u7684\u5185\u5728\u8054\u7cfb\uff0c\u6216\u91c7\u7528\u7f3a\u4e4f\u7edf\u8ba1\u4e25\u8c28\u6027\u7684\u9ed1\u76d2\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u6574\u5408Cox\u6bd4\u4f8b\u98ce\u9669\u6a21\u578b\u3001\u5377\u79ef\u591a\u8f93\u51fa\u9ad8\u65af\u8fc7\u7a0b\u548c\u591a\u9879\u6545\u969c\u6a21\u5f0f\u5206\u5e03\uff0c\u5229\u7528\u53d8\u5206\u8d1d\u53f6\u65af\u83b7\u53d6\u540e\u9a8c\u5206\u5e03\uff0c\u5e76\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u91c7\u6837\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u901a\u8fc7\u6570\u503c\u548c\u6848\u4f8b\u7814\u7a76\uff08\u55b7\u6c14\u53d1\u52a8\u673a\u6570\u636e\u96c6\uff09\u9a8c\u8bc1\u4e86\u6a21\u578b\u5728\u51c6\u786e\u9884\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u7684\u4f18\u52bf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u8054\u5408\u5efa\u6a21\u591a\u4f20\u611f\u5668\u6570\u636e\u548c\u6545\u969c\u65f6\u95f4\uff0c\u63d0\u4f9b\u7edf\u8ba1\u4e25\u8c28\u7684\u9884\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u4f18\u4e8e\u73b0\u6709\u72ec\u7acb\u6216\u9ed1\u76d2\u65b9\u6cd5\u3002"}}
{"id": "2506.17046", "pdf": "https://arxiv.org/pdf/2506.17046", "abs": "https://arxiv.org/abs/2506.17046", "authors": ["Xiaolong Wang", "Zhaolu Kang", "Wangyuxuan Zhai", "Xinyue Lou", "Yunghwei Lai", "Ziyue Wang", "Yawen Wang", "Kaiyu Huang", "Yile Wang", "Peng Li", "Yang Liu"], "title": "MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated significant\nadvances across numerous vision-language tasks. Due to their strong image-text\nalignment capability, MLLMs can effectively understand image-text pairs with\nclear meanings. However, effectively resolving the inherent ambiguities in\nnatural language and visual contexts remains challenging. Existing multimodal\nbenchmarks typically overlook linguistic and visual ambiguities, relying mainly\non unimodal context for disambiguation and thus failing to exploit the mutual\nclarification potential between modalities. To bridge this gap, we introduce\nMUCAR, a novel and challenging benchmark designed explicitly for evaluating\nmultimodal ambiguity resolution across multilingual and cross-modal scenarios.\nMUCAR includes: (1) a multilingual dataset where ambiguous textual expressions\nare uniquely resolved by corresponding visual contexts, and (2) a\ndual-ambiguity dataset that systematically pairs ambiguous images with\nambiguous textual contexts, with each combination carefully constructed to\nyield a single, clear interpretation through mutual disambiguation. Extensive\nevaluations involving 19 state-of-the-art multimodal models--encompassing both\nopen-source and proprietary architectures--reveal substantial gaps compared to\nhuman-level performance, highlighting the need for future research into more\nsophisticated cross-modal ambiguity comprehension methods, further pushing the\nboundaries of multimodal reasoning.", "AI": {"tldr": "MUCAR\u662f\u4e00\u4e2a\u65b0\u7684\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u6ce8\u4e8e\u8bc4\u4f30\u591a\u8bed\u8a00\u548c\u8de8\u6a21\u6001\u573a\u666f\u4e2d\u7684\u6a21\u7cca\u6027\u89e3\u51b3\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u4e0e\u4eba\u7c7b\u6c34\u5e73\u7684\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u901a\u5e38\u5ffd\u7565\u8bed\u8a00\u548c\u89c6\u89c9\u6a21\u7cca\u6027\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u6a21\u6001\u95f4\u7684\u76f8\u4e92\u6f84\u6e05\u6f5c\u529b\u3002", "method": "\u5f15\u5165MUCAR\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec\u591a\u8bed\u8a00\u6570\u636e\u96c6\u548c\u53cc\u6a21\u7cca\u6027\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u89c6\u89c9\u548c\u6587\u672c\u4e0a\u4e0b\u6587\u7684\u76f8\u4e92\u6f84\u6e05\u89e3\u51b3\u6a21\u7cca\u6027\u3002", "result": "19\u79cd\u5148\u8fdb\u591a\u6a21\u6001\u6a21\u578b\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u5176\u6027\u80fd\u4e0e\u4eba\u7c7b\u6c34\u5e73\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "conclusion": "\u672a\u6765\u9700\u7814\u7a76\u66f4\u590d\u6742\u7684\u8de8\u6a21\u6001\u6a21\u7cca\u6027\u7406\u89e3\u65b9\u6cd5\uff0c\u63a8\u52a8\u591a\u6a21\u6001\u63a8\u7406\u7684\u8fb9\u754c\u3002"}}
{"id": "2506.17055", "pdf": "https://arxiv.org/pdf/2506.17055", "abs": "https://arxiv.org/abs/2506.17055", "authors": ["Charilaos Papaioannou", "Emmanouil Benetos", "Alexandros Potamianos"], "title": "Universal Music Representations? Evaluating Foundation Models on World Music Corpora", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "comment": "Accepted at ISMIR 2025", "summary": "Foundation models have revolutionized music information retrieval, but\nquestions remain about their ability to generalize across diverse musical\ntraditions. This paper presents a comprehensive evaluation of five\nstate-of-the-art audio foundation models across six musical corpora spanning\nWestern popular, Greek, Turkish, and Indian classical traditions. We employ\nthree complementary methodologies to investigate these models' cross-cultural\ncapabilities: probing to assess inherent representations, targeted supervised\nfine-tuning of 1-2 layers, and multi-label few-shot learning for low-resource\nscenarios. Our analysis shows varying cross-cultural generalization, with\nlarger models typically outperforming on non-Western music, though results\ndecline for culturally distant traditions. Notably, our approaches achieve\nstate-of-the-art performance on five out of six evaluated datasets,\ndemonstrating the effectiveness of foundation models for world music\nunderstanding. We also find that our targeted fine-tuning approach does not\nconsistently outperform probing across all settings, suggesting foundation\nmodels already encode substantial musical knowledge. Our evaluation framework\nand benchmarking results contribute to understanding how far current models are\nfrom achieving universal music representations while establishing metrics for\nfuture progress.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u4e94\u79cd\u97f3\u9891\u57fa\u7840\u6a21\u578b\u5728\u516d\u79cd\u97f3\u4e50\u4f20\u7edf\u4e2d\u7684\u8de8\u6587\u5316\u6cdb\u5316\u80fd\u529b\uff0c\u53d1\u73b0\u8f83\u5927\u6a21\u578b\u5728\u975e\u897f\u65b9\u97f3\u4e50\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u6587\u5316\u5dee\u5f02\u4ecd\u5f71\u54cd\u6027\u80fd\u3002", "motivation": "\u63a2\u8ba8\u57fa\u7840\u6a21\u578b\u5728\u4e0d\u540c\u97f3\u4e50\u4f20\u7edf\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u586b\u8865\u8de8\u6587\u5316\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u4e09\u79cd\u65b9\u6cd5\uff1a\u63a2\u6d4b\u6a21\u578b\u56fa\u6709\u8868\u793a\u3001\u76ee\u6807\u76d1\u7763\u5fae\u8c031-2\u5c42\u3001\u591a\u6807\u7b7e\u5c11\u6837\u672c\u5b66\u4e60\u3002", "result": "\u6a21\u578b\u5728\u4e94\u79cd\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u4f18\u6027\u80fd\uff0c\u4f46\u6587\u5316\u8ddd\u79bb\u8f83\u8fdc\u7684\u4f20\u7edf\u8868\u73b0\u4e0b\u964d\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\u5df2\u5177\u5907\u4e30\u5bcc\u97f3\u4e50\u77e5\u8bc6\uff0c\u4f46\u4ecd\u9700\u6539\u8fdb\u4ee5\u5b9e\u73b0\u901a\u7528\u97f3\u4e50\u8868\u793a\u3002"}}
{"id": "2506.17064", "pdf": "https://arxiv.org/pdf/2506.17064", "abs": "https://arxiv.org/abs/2506.17064", "authors": ["Aditya Sengar", "Ali Hariri", "Daniel Probst", "Patrick Barth", "Pierre Vandergheynst"], "title": "Generative Modeling of Full-Atom Protein Conformations using Latent Diffusion on Graph Embeddings", "categories": ["q-bio.BM", "cs.LG"], "comment": "10 pages (main text), 4 figures, 2 tables. Submitted to NeurIPS 2025.\n  Code and data are publicly available", "summary": "Generating diverse, all-atom conformational ensembles of dynamic proteins\nsuch as G-protein-coupled receptors (GPCRs) is critical for understanding their\nfunction, yet most generative models simplify atomic detail or ignore\nconformational diversity altogether. We present latent diffusion for full\nprotein generation (LD-FPG), a framework that constructs complete all-atom\nprotein structures, including every side-chain heavy atom, directly from\nmolecular dynamics (MD) trajectories. LD-FPG employs a Chebyshev graph neural\nnetwork (ChebNet) to obtain low-dimensional latent embeddings of protein\nconformations, which are processed using three pooling strategies: blind,\nsequential and residue-based. A diffusion model trained on these latent\nrepresentations generates new samples that a decoder, optionally regularized by\ndihedral-angle losses, maps back to Cartesian coordinates. Using D2R-MD, a\n2-microsecond MD trajectory (12 000 frames) of the human dopamine D2 receptor\nin a membrane environment, the sequential and residue-based pooling strategy\nreproduces the reference ensemble with high structural fidelity (all-atom lDDT\nof approximately 0.7; C-alpha-lDDT of approximately 0.8) and recovers backbone\nand side-chain dihedral-angle distributions with a Jensen-Shannon divergence of\nless than 0.03 compared to the MD data. LD-FPG thereby offers a practical route\nto system-specific, all-atom ensemble generation for large proteins, providing\na promising tool for structure-based therapeutic design on complex, dynamic\ntargets. The D2R-MD dataset and our implementation are freely available to\nfacilitate further research.", "AI": {"tldr": "LD-FPG\u662f\u4e00\u79cd\u751f\u6210\u5168\u539f\u5b50\u86cb\u767d\u8d28\u7ed3\u6784\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6f5c\u5728\u6269\u6563\u6a21\u578b\u4ece\u5206\u5b50\u52a8\u529b\u5b66\u8f68\u8ff9\u4e2d\u751f\u6210\u591a\u6837\u5316\u7684\u6784\u8c61\uff0c\u9002\u7528\u4e8e\u590d\u6742\u52a8\u6001\u86cb\u767d\u8d28\u5982GPCRs\u3002", "motivation": "\u7406\u89e3\u52a8\u6001\u86cb\u767d\u8d28\uff08\u5982GPCRs\uff09\u7684\u529f\u80fd\u9700\u8981\u751f\u6210\u591a\u6837\u5316\u7684\u5168\u539f\u5b50\u6784\u8c61\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u5e38\u7b80\u5316\u539f\u5b50\u7ec6\u8282\u6216\u5ffd\u7565\u6784\u8c61\u591a\u6837\u6027\u3002", "method": "LD-FPG\u4f7f\u7528Chebyshev\u56fe\u795e\u7ecf\u7f51\u7edc\u83b7\u53d6\u86cb\u767d\u8d28\u6784\u8c61\u7684\u4f4e\u7ef4\u6f5c\u5728\u5d4c\u5165\uff0c\u901a\u8fc7\u4e09\u79cd\u6c60\u5316\u7b56\u7565\uff08\u76f2\u3001\u987a\u5e8f\u548c\u6b8b\u57fa\uff09\u5904\u7406\uff0c\u6269\u6563\u6a21\u578b\u751f\u6210\u65b0\u6837\u672c\uff0c\u89e3\u7801\u5668\u6620\u5c04\u56de\u7b1b\u5361\u5c14\u5750\u6807\u3002", "result": "\u5728D2R-MD\u6570\u636e\u96c6\u4e0a\uff0c\u987a\u5e8f\u548c\u6b8b\u57fa\u6c60\u5316\u7b56\u7565\u80fd\u9ad8\u4fdd\u771f\u5730\u590d\u73b0\u53c2\u8003\u6784\u8c61\uff08\u5168\u539f\u5b50lDDT\u7ea60.7\uff0cC-alpha-lDDT\u7ea60.8\uff09\uff0c\u4e14\u4e0eMD\u6570\u636e\u7684Jensen-Shannon\u6563\u5ea6\u5c0f\u4e8e0.03\u3002", "conclusion": "LD-FPG\u4e3a\u5927\u578b\u86cb\u767d\u8d28\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u7279\u5f02\u6027\u7684\u5168\u539f\u5b50\u6784\u8c61\u751f\u6210\u65b9\u6cd5\uff0c\u662f\u590d\u6742\u52a8\u6001\u9776\u70b9\u7ed3\u6784\u6cbb\u7597\u8bbe\u8ba1\u7684\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2506.17076", "pdf": "https://arxiv.org/pdf/2506.17076", "abs": "https://arxiv.org/abs/2506.17076", "authors": ["Ziv Aharoni", "Henry D. Pfister"], "title": "Neural Polar Decoders for DNA Data Storage", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "Synchronization errors, such as insertions and deletions, present a\nfundamental challenge in DNA-based data storage systems, arising from both\nsynthesis and sequencing noise. These channels are often modeled as\ninsertion-deletion-substitution (IDS) channels, for which designing\nmaximum-likelihood decoders is computationally expensive. In this work, we\npropose a data-driven approach based on neural polar decoders (NPDs) to design\nlow-complexity decoders for channels with synchronization errors. The proposed\narchitecture enables decoding over IDS channels with reduced complexity $O(AN\nlog N )$, where $A$ is a tunable parameter independent of the channel. NPDs\nrequire only sample access to the channel and can be trained without an\nexplicit channel model. Additionally, NPDs provide mutual information (MI)\nestimates that can be used to optimize input distributions and code design. We\ndemonstrate the effectiveness of NPDs on both synthetic deletion and IDS\nchannels. For deletion channels, we show that NPDs achieve near-optimal\ndecoding performance and accurate MI estimation, with significantly lower\ncomplexity than trellis-based decoders. We also provide numerical estimates of\nthe channel capacity for the deletion channel. We extend our evaluation to\nrealistic DNA storage settings, including channels with multiple noisy reads\nand real-world Nanopore sequencing data. Our results show that NPDs match or\nsurpass the performance of existing methods while using significantly fewer\nparameters than the state-of-the-art. These findings highlight the promise of\nNPDs for robust and efficient decoding in DNA data storage systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u6781\u5316\u89e3\u7801\u5668\uff08NPD\uff09\u7684\u4f4e\u590d\u6742\u5ea6\u89e3\u7801\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406DNA\u6570\u636e\u5b58\u50a8\u4e2d\u7684\u540c\u6b65\u9519\u8bef\uff08\u63d2\u5165\u3001\u5220\u9664\u548c\u66ff\u6362\uff09\u3002NPD\u65e0\u9700\u663e\u5f0f\u4fe1\u9053\u6a21\u578b\uff0c\u4ec5\u9700\u6837\u672c\u8bbf\u95ee\uff0c\u590d\u6742\u5ea6\u4e3aO(AN log N)\uff0c\u5e76\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "DNA\u6570\u636e\u5b58\u50a8\u4e2d\u7684\u540c\u6b65\u9519\u8bef\uff08\u5982\u63d2\u5165\u3001\u5220\u9664\u548c\u66ff\u6362\uff09\u662f\u4e3b\u8981\u6311\u6218\uff0c\u4f20\u7edf\u6700\u5927\u4f3c\u7136\u89e3\u7801\u5668\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u4f4e\u590d\u6742\u5ea6\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u6570\u636e\u9a71\u52a8\u7684\u795e\u7ecf\u6781\u5316\u89e3\u7801\u5668\uff08NPD\uff09\uff0c\u901a\u8fc7\u6837\u672c\u8bad\u7ec3\uff0c\u65e0\u9700\u663e\u5f0f\u4fe1\u9053\u6a21\u578b\uff0c\u590d\u6742\u5ea6\u4e3aO(AN log N)\u3002", "result": "NPD\u5728\u5408\u6210\u5220\u9664\u548cIDS\u4fe1\u9053\u4e2d\u8868\u73b0\u63a5\u8fd1\u6700\u4f18\uff0c\u590d\u6742\u5ea6\u663e\u8457\u4f4e\u4e8e\u57fa\u4e8e\u7f51\u683c\u7684\u89e3\u7801\u5668\uff0c\u5e76\u5728\u771f\u5b9eDNA\u5b58\u50a8\u6570\u636e\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "NPD\u4e3aDNA\u6570\u636e\u5b58\u50a8\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u89e3\u7801\u65b9\u6848\uff0c\u5177\u6709\u4f4e\u590d\u6742\u5ea6\u548c\u9ad8\u6027\u80fd\u4f18\u52bf\u3002"}}
{"id": "2506.17133", "pdf": "https://arxiv.org/pdf/2506.17133", "abs": "https://arxiv.org/abs/2506.17133", "authors": ["Josu\u00e9 Mart\u00ednez-Mart\u00ednez", "Olivia Brown", "Mostafa Karami", "Sheida Nabavi"], "title": "Robust Training with Data Augmentation for Medical Imaging Classification", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Deep neural networks are increasingly being used to detect and diagnose\nmedical conditions using medical imaging. Despite their utility, these models\nare highly vulnerable to adversarial attacks and distribution shifts, which can\naffect diagnostic reliability and undermine trust among healthcare\nprofessionals. In this study, we propose a robust training algorithm with data\naugmentation (RTDA) to mitigate these vulnerabilities in medical image\nclassification. We benchmark classifier robustness against adversarial\nperturbations and natural variations of RTDA and six competing baseline\ntechniques, including adversarial training and data augmentation approaches in\nisolation and combination, using experimental data sets with three different\nimaging technologies (mammograms, X-rays, and ultrasound). We demonstrate that\nRTDA achieves superior robustness against adversarial attacks and improved\ngeneralization performance in the presence of distribution shift in each image\nclassification task while maintaining high clean accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9c81\u68d2\u8bad\u7ec3\u7b97\u6cd5\uff08RTDA\uff09\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u63d0\u5347\u533b\u5b66\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u5bf9\u6297\u653b\u51fb\u548c\u5206\u5e03\u504f\u79fb\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u533b\u5b66\u56fe\u50cf\u8bca\u65ad\u4e2d\u6613\u53d7\u5bf9\u6297\u653b\u51fb\u548c\u5206\u5e03\u504f\u79fb\u5f71\u54cd\uff0c\u5f71\u54cd\u8bca\u65ad\u53ef\u9760\u6027\u3002", "method": "\u91c7\u7528RTDA\u7b97\u6cd5\uff0c\u7ed3\u5408\u6570\u636e\u589e\u5f3a\uff0c\u5bf9\u6bd4\u516d\u79cd\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc4\u4f30\u5176\u5728\u4e09\u79cd\u533b\u5b66\u56fe\u50cf\u6280\u672f\u4e2d\u7684\u8868\u73b0\u3002", "result": "RTDA\u5728\u5bf9\u6297\u653b\u51fb\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u8868\u73b0\u6700\u4f18\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "RTDA\u80fd\u6709\u6548\u63d0\u5347\u533b\u5b66\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2506.17144", "pdf": "https://arxiv.org/pdf/2506.17144", "abs": "https://arxiv.org/abs/2506.17144", "authors": ["Ritabrata Chakraborty", "Rajatsubhra Chakraborty", "Avijit Dasgupta", "Sandeep Chaurasia"], "title": "Do We Need Large VLMs for Spotting Soccer Actions?", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "5 pages, 2 figures", "summary": "Traditional video-based tasks like soccer action spotting rely heavily on\nvisual inputs, often requiring complex and computationally expensive models to\nprocess dense video data. In this work, we propose a shift from this\nvideo-centric approach to a text-based task, making it lightweight and scalable\nby utilizing Large Language Models (LLMs) instead of Vision-Language Models\n(VLMs). We posit that expert commentary, which provides rich, fine-grained\ndescriptions and contextual cues such as excitement and tactical insights,\ncontains enough information to reliably spot key actions in a match. To\ndemonstrate this, we use the SoccerNet Echoes dataset, which provides\ntimestamped commentary, and employ a system of three LLMs acting as judges\nspecializing in outcome, excitement, and tactics. Each LLM evaluates sliding\nwindows of commentary to identify actions like goals, cards, and substitutions,\ngenerating accurate timestamps for these events. Our experiments show that this\nlanguage-centric approach performs effectively in detecting critical match\nevents, providing a lightweight and training-free alternative to traditional\nvideo-based methods for action spotting.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6587\u672c\u7684\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u66ff\u4ee3\u4f20\u7edf\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\uff0c\u901a\u8fc7\u4e13\u5bb6\u8bc4\u8bba\u6765\u68c0\u6d4b\u8db3\u7403\u6bd4\u8d5b\u4e2d\u7684\u5173\u952e\u52a8\u4f5c\u3002", "motivation": "\u4f20\u7edf\u89c6\u9891\u5206\u6790\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u590d\u6742\uff0c\u800c\u4e13\u5bb6\u8bc4\u8bba\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u7ec6\u7c92\u5ea6\u63cf\u8ff0\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u8db3\u4ee5\u53ef\u9760\u5730\u8bc6\u522b\u5173\u952e\u52a8\u4f5c\u3002", "method": "\u4f7f\u7528SoccerNet Echoes\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u4e09\u4e2a\u4e13\u95e8\u5316\u7684LLMs\uff08\u5206\u522b\u5173\u6ce8\u7ed3\u679c\u3001\u5174\u594b\u5ea6\u548c\u6218\u672f\uff09\u8bc4\u4f30\u6ed1\u52a8\u7a97\u53e3\u7684\u8bc4\u8bba\uff0c\u8bc6\u522b\u8fdb\u7403\u3001\u9ec4\u724c\u7b49\u52a8\u4f5c\u5e76\u751f\u6210\u7cbe\u786e\u65f6\u95f4\u6233\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u57fa\u4e8e\u8bed\u8a00\u7684\u65b9\u6cd5\u5728\u68c0\u6d4b\u5173\u952e\u6bd4\u8d5b\u4e8b\u4ef6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u52a8\u4f5c\u8bc6\u522b\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4e14\u65e0\u9700\u8bad\u7ec3\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "\u8bed\u8a00\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\u4e3a\u52a8\u4f5c\u8bc6\u522b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u8f7b\u91cf\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f18\u4e8e\u4f20\u7edf\u89c6\u9891\u5206\u6790\u65b9\u6cd5\u3002"}}
{"id": "2506.17197", "pdf": "https://arxiv.org/pdf/2506.17197", "abs": "https://arxiv.org/abs/2506.17197", "authors": ["Samuel Howard", "Peter Potaptchik", "George Deligiannidis"], "title": "Schr\u00f6dinger Bridge Matching for Tree-Structured Costs and Entropic Wasserstein Barycentres", "categories": ["stat.ML", "cs.LG"], "comment": "Preprint", "summary": "Recent advances in flow-based generative modelling have provided scalable\nmethods for computing the Schr\\\"odinger Bridge (SB) between distributions, a\ndynamic form of entropy-regularised Optimal Transport (OT) for the quadratic\ncost. The successful Iterative Markovian Fitting (IMF) procedure solves the SB\nproblem via sequential bridge-matching steps, presenting an elegant and\npractical approach with many favourable properties over the more traditional\nIterative Proportional Fitting (IPF) procedure. Beyond the standard setting,\noptimal transport can be generalised to the multi-marginal case in which the\nobjective is to minimise a cost defined over several marginal distributions. Of\nparticular importance are costs defined over a tree structure, from which\nWasserstein barycentres can be recovered as a special case. In this work, we\nextend the IMF procedure to solve for the tree-structured SB problem. Our\nresulting algorithm inherits the many advantages of IMF over IPF approaches in\nthe tree-based setting. In the specific case of Wasserstein barycentres, our\napproach can be viewed as extending fixed-point approaches for barycentre\ncomputation to the case of flow-based entropic OT solvers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55\u7684IMF\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u6811\u7ed3\u6784SB\u95ee\u9898\uff0c\u5e76\u5728Wasserstein\u91cd\u5fc3\u8ba1\u7b97\u4e2d\u5c55\u793a\u4e86\u5176\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edfIPF\u65b9\u6cd5\u5728\u6811\u7ed3\u6784SB\u95ee\u9898\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u800cIMF\u65b9\u6cd5\u5177\u6709\u66f4\u4f18\u7279\u6027\uff0c\u56e0\u6b64\u9700\u8981\u5c06\u5176\u6269\u5c55\u5230\u591a\u8fb9\u9645OT\u95ee\u9898\u4e2d\u3002", "method": "\u6269\u5c55IMF\u65b9\u6cd5\uff0c\u901a\u8fc7\u987a\u5e8f\u6865\u5339\u914d\u6b65\u9aa4\u89e3\u51b3\u6811\u7ed3\u6784SB\u95ee\u9898\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8eWasserstein\u91cd\u5fc3\u8ba1\u7b97\u3002", "result": "\u65b0\u7b97\u6cd5\u7ee7\u627f\u4e86IMF\u5728\u6811\u7ed3\u6784\u4e2d\u7684\u4f18\u52bf\uff0c\u5e76\u5728\u6d41\u5f0f\u71b5OT\u6c42\u89e3\u5668\u4e2d\u6269\u5c55\u4e86\u56fa\u5b9a\u70b9\u65b9\u6cd5\u3002", "conclusion": "\u6269\u5c55\u7684IMF\u65b9\u6cd5\u5728\u6811\u7ed3\u6784SB\u95ee\u9898\u548cWasserstein\u91cd\u5fc3\u8ba1\u7b97\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\uff0c\u4e3a\u591a\u8fb9\u9645OT\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.17206", "pdf": "https://arxiv.org/pdf/2506.17206", "abs": "https://arxiv.org/abs/2506.17206", "authors": ["Yukun Huang", "Yanning Zhou", "Jianan Wang", "Kaiyi Huang", "Xihui Liu"], "title": "DreamCube: 3D Panorama Generation via Multi-plane Synchronization", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "Project page: https://yukun-huang.github.io/DreamCube/", "summary": "3D panorama synthesis is a promising yet challenging task that demands\nhigh-quality and diverse visual appearance and geometry of the generated\nomnidirectional content. Existing methods leverage rich image priors from\npre-trained 2D foundation models to circumvent the scarcity of 3D panoramic\ndata, but the incompatibility between 3D panoramas and 2D single views limits\ntheir effectiveness. In this work, we demonstrate that by applying multi-plane\nsynchronization to the operators from 2D foundation models, their capabilities\ncan be seamlessly extended to the omnidirectional domain. Based on this design,\nwe further introduce DreamCube, a multi-plane RGB-D diffusion model for 3D\npanorama generation, which maximizes the reuse of 2D foundation model priors to\nachieve diverse appearances and accurate geometry while maintaining multi-view\nconsistency. Extensive experiments demonstrate the effectiveness of our\napproach in panoramic image generation, panoramic depth estimation, and 3D\nscene generation.", "AI": {"tldr": "\u901a\u8fc7\u591a\u5e73\u9762\u540c\u6b65\u6280\u672f\u6269\u5c552D\u57fa\u7840\u6a21\u578b\u80fd\u529b\uff0c\u63d0\u51faDreamCube\u6a21\u578b\u7528\u4e8e3D\u5168\u666f\u751f\u6210\uff0c\u5b9e\u73b0\u4e86\u591a\u6837\u5916\u89c2\u4e0e\u7cbe\u786e\u51e0\u4f55\u3002", "motivation": "\u89e3\u51b33D\u5168\u666f\u6570\u636e\u7a00\u7f3a\u53ca2D\u5355\u89c6\u56fe\u4e0e3D\u5168\u666f\u4e0d\u517c\u5bb9\u7684\u95ee\u9898\u3002", "method": "\u5e94\u7528\u591a\u5e73\u9762\u540c\u6b65\u6280\u672f\u6269\u5c552D\u57fa\u7840\u6a21\u578b\uff0c\u63d0\u51faDreamCube\u591a\u5e73\u9762RGB-D\u6269\u6563\u6a21\u578b\u3002", "result": "\u5728\u5168\u666f\u56fe\u50cf\u751f\u6210\u3001\u6df1\u5ea6\u4f30\u8ba1\u548c3D\u573a\u666f\u751f\u6210\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "DreamCube\u6709\u6548\u5229\u75282D\u5148\u9a8c\uff0c\u5b9e\u73b0\u9ad8\u8d28\u91cf3D\u5168\u666f\u751f\u6210\u3002"}}
{"id": "2506.17212", "pdf": "https://arxiv.org/pdf/2506.17212", "abs": "https://arxiv.org/abs/2506.17212", "authors": ["Tianjiao Yu", "Vedant Shah", "Muntasir Wahed", "Ying Shen", "Kiet A. Nguyen", "Ismini Lourentzou"], "title": "Part$^{2}$GS: Part-aware Modeling of Articulated Objects using 3D Gaussian Splatting", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Articulated objects are common in the real world, yet modeling their\nstructure and motion remains a challenging task for 3D reconstruction methods.\nIn this work, we introduce Part$^{2}$GS, a novel framework for modeling\narticulated digital twins of multi-part objects with high-fidelity geometry and\nphysically consistent articulation. Part$^{2}$GS leverages a part-aware 3D\nGaussian representation that encodes articulated components with learnable\nattributes, enabling structured, disentangled transformations that preserve\nhigh-fidelity geometry. To ensure physically consistent motion, we propose a\nmotion-aware canonical representation guided by physics-based constraints,\nincluding contact enforcement, velocity consistency, and vector-field\nalignment. Furthermore, we introduce a field of repel points to prevent part\ncollisions and maintain stable articulation paths, significantly improving\nmotion coherence over baselines. Extensive evaluations on both synthetic and\nreal-world datasets show that Part$^{2}$GS consistently outperforms\nstate-of-the-art methods by up to 10$\\times$ in Chamfer Distance for movable\nparts.", "AI": {"tldr": "Part$^{2}$GS\u662f\u4e00\u4e2a\u7528\u4e8e\u5efa\u6a21\u591a\u90e8\u4ef6\u7269\u4f53\u9ad8\u4fdd\u771f\u51e0\u4f55\u548c\u7269\u7406\u4e00\u81f4\u8fd0\u52a8\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u90e8\u5206\u611f\u77e5\u76843D\u9ad8\u65af\u8868\u793a\u548c\u7269\u7406\u7ea6\u675f\u5b9e\u73b0\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u5173\u8282\u7269\u4f53\u666e\u904d\u5b58\u5728\uff0c\u4f46\u5176\u7ed3\u6784\u548c\u8fd0\u52a8\u7684\u5efa\u6a21\u4ecd\u662f3D\u91cd\u5efa\u65b9\u6cd5\u7684\u6311\u6218\u3002", "method": "\u5229\u7528\u90e8\u5206\u611f\u77e5\u76843D\u9ad8\u65af\u8868\u793a\u7f16\u7801\u53ef\u5b66\u4e60\u5c5e\u6027\uff0c\u7ed3\u5408\u7269\u7406\u7ea6\u675f\uff08\u63a5\u89e6\u3001\u901f\u5ea6\u4e00\u81f4\u6027\u548c\u77e2\u91cf\u573a\u5bf9\u9f50\uff09\u548c\u6392\u65a5\u70b9\u573a\u9632\u6b62\u78b0\u649e\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cPart$^{2}$GS\u5728\u53ef\u79fb\u52a8\u90e8\u4ef6\u7684Chamfer\u8ddd\u79bb\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u534710\u500d\u3002", "conclusion": "Part$^{2}$GS\u901a\u8fc7\u7ed3\u6784\u5316\u548c\u7269\u7406\u4e00\u81f4\u7684\u8868\u793a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5173\u8282\u7269\u4f53\u5efa\u6a21\u7684\u7cbe\u5ea6\u548c\u8fd0\u52a8\u8fde\u8d2f\u6027\u3002"}}
