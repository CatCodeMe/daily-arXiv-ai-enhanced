{"id": "2507.01079", "pdf": "https://arxiv.org/pdf/2507.01079", "abs": "https://arxiv.org/abs/2507.01079", "authors": ["Taehwan Park", "Geonho Lee", "Min-Soo Kim"], "title": "MobileRAG: A Fast, Memory-Efficient, and Energy-Efficient Method for On-Device RAG", "categories": ["cs.DB"], "comment": "14 pages", "summary": "Retrieval-Augmented Generation (RAG) has proven effective on server\ninfrastructures, but its application on mobile devices is still underexplored\ndue to limited memory and power resources. Existing vector search and RAG\nsolutions largely assume abundant computation resources, making them\nimpractical for on-device scenarios. In this paper, we propose MobileRAG, a\nfully on-device pipeline that overcomes these limitations by combining a\nmobile-friendly vector search algorithm, \\textit{EcoVector}, with a lightweight\n\\textit{Selective Content Reduction} (SCR) method. By partitioning and\npartially loading index data, EcoVector drastically reduces both memory\nfootprint and CPU usage, while the SCR method filters out irrelevant text to\ndiminish Language Model (LM) input size without degrading accuracy. Extensive\nexperiments demonstrated that MobileRAG significantly outperforms conventional\nvector search and RAG methods in terms of latency, memory usage, and power\nconsumption, while maintaining accuracy and enabling offline operation to\nsafeguard privacy in resource-constrained environments.", "AI": {"tldr": "MobileRAG\u662f\u4e00\u79cd\u5b8c\u5168\u5728\u8bbe\u5907\u4e0a\u8fd0\u884c\u7684RAG\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u5411\u91cf\u641c\u7d22\u7b97\u6cd5\u548c\u9009\u62e9\u6027\u5185\u5bb9\u51cf\u5c11\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u5360\u7528\u548c\u529f\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u5047\u8bbe\u8ba1\u7b97\u8d44\u6e90\u5145\u8db3\uff0c\u4e0d\u9002\u7528\u4e8e\u79fb\u52a8\u8bbe\u5907\u3002MobileRAG\u65e8\u5728\u89e3\u51b3\u79fb\u52a8\u8bbe\u5907\u4e0a\u8d44\u6e90\u53d7\u9650\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u79bb\u7ebf\u64cd\u4f5c\u3002", "method": "\u7ed3\u5408\u79fb\u52a8\u53cb\u597d\u7684EcoVector\u7b97\u6cd5\uff08\u5206\u533a\u52a0\u8f7d\u7d22\u5f15\u6570\u636e\uff09\u548c\u9009\u62e9\u6027\u5185\u5bb9\u51cf\u5c11\uff08SCR\uff09\u65b9\u6cd5\uff0c\u51cf\u5c11\u5185\u5b58\u548cCPU\u4f7f\u7528\uff0c\u540c\u65f6\u8fc7\u6ee4\u65e0\u5173\u6587\u672c\u3002", "result": "MobileRAG\u5728\u5ef6\u8fdf\u3001\u5185\u5b58\u4f7f\u7528\u548c\u529f\u8017\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u652f\u6301\u79bb\u7ebf\u64cd\u4f5c\u3002", "conclusion": "MobileRAG\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u9690\u79c1\u4fdd\u62a4\u7684RAG\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01461", "pdf": "https://arxiv.org/pdf/2507.01461", "abs": "https://arxiv.org/abs/2507.01461", "authors": ["Styliani Kyrama", "Anastasios Gounaris"], "title": "Handling out-of-order input arrival in CEP engines on the edge combining optimistic, pessimistic and lazy evaluation", "categories": ["cs.DB"], "comment": null, "summary": "In Complex Event Processing, handling out-of-order, late, and duplicate\nevents is critical for real-time analytics, especially on resource-constrained\ndevices that process heterogeneous data from multiple sources. We present\nLimeCEP, a hybrid CEP approach that combines lazy evaluation, buffering, and\nspeculative processing to efficiently handle data inconsistencies while\nsupporting multi-pattern detection under relaxed semantics. LimeCEP integrates\nKafka for efficient message ordering, retention, and duplicate elimination, and\noffers configurable strategies to trade off between accuracy, latency, and\nresource consumption. Compared to state-of-the-art systems like SASE and\nFlinkCEP, LimeCEP achieves up to six orders of magnitude lower latency, with up\nto 10 times lower memory usage and 6 times lower CPU utilization, while\nmaintaining near-perfect precision and recall under high-disorder input\nstreams, making it well-suited for non-cloud deployments.", "AI": {"tldr": "LimeCEP\u662f\u4e00\u79cd\u6df7\u5408CEP\u65b9\u6cd5\uff0c\u901a\u8fc7\u61d2\u8bc4\u4f30\u3001\u7f13\u51b2\u548c\u63a8\u6d4b\u5904\u7406\u9ad8\u6548\u5904\u7406\u6570\u636e\u4e0d\u4e00\u81f4\u6027\uff0c\u652f\u6301\u591a\u6a21\u5f0f\u68c0\u6d4b\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u3002", "motivation": "\u5728\u590d\u6742\u4e8b\u4ef6\u5904\u7406\u4e2d\uff0c\u5904\u7406\u4e71\u5e8f\u3001\u5ef6\u8fdf\u548c\u91cd\u590d\u4e8b\u4ef6\u5bf9\u5b9e\u65f6\u5206\u6790\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u5904\u7406\u591a\u6e90\u5f02\u6784\u6570\u636e\u65f6\u3002", "method": "LimeCEP\u7ed3\u5408\u61d2\u8bc4\u4f30\u3001\u7f13\u51b2\u548c\u63a8\u6d4b\u5904\u7406\uff0c\u96c6\u6210Kafka\u5b9e\u73b0\u9ad8\u6548\u6d88\u606f\u6392\u5e8f\u3001\u4fdd\u7559\u548c\u53bb\u91cd\uff0c\u5e76\u63d0\u4f9b\u53ef\u914d\u7f6e\u7b56\u7565\u4ee5\u5e73\u8861\u51c6\u786e\u6027\u3001\u5ef6\u8fdf\u548c\u8d44\u6e90\u6d88\u8017\u3002", "result": "\u76f8\u6bd4SASE\u548cFlinkCEP\uff0cLimeCEP\u5ef6\u8fdf\u964d\u4f4e\u516d\u4e2a\u6570\u91cf\u7ea7\uff0c\u5185\u5b58\u548cCPU\u4f7f\u7528\u5206\u522b\u964d\u4f4e10\u500d\u548c6\u500d\uff0c\u540c\u65f6\u5728\u9ad8\u4e71\u5e8f\u8f93\u5165\u6d41\u4e0b\u4fdd\u6301\u63a5\u8fd1\u5b8c\u7f8e\u7684\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u3002", "conclusion": "LimeCEP\u7279\u522b\u9002\u5408\u975e\u4e91\u90e8\u7f72\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.01599", "pdf": "https://arxiv.org/pdf/2507.01599", "abs": "https://arxiv.org/abs/2507.01599", "authors": ["Zhaoyan Sun", "Jiayi Wang", "Xinyang Zhao", "Jiachi Wang", "Guoliang Li"], "title": "Data Agent: A Holistic Architecture for Orchestrating Data+AI Ecosystems", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Traditional Data+AI systems utilize data-driven techniques to optimize\nperformance, but they rely heavily on human experts to orchestrate system\npipelines, enabling them to adapt to changes in data, queries, tasks, and\nenvironments. For instance, while there are numerous data science tools\navailable, developing a pipeline planning system to coordinate these tools\nremains challenging. This difficulty arises because existing Data+AI systems\nhave limited capabilities in semantic understanding, reasoning, and planning.\nFortunately, we have witnessed the success of large language models (LLMs) in\nenhancing semantic understanding, reasoning, and planning abilities. It is\ncrucial to incorporate LLM techniques to revolutionize data systems for\norchestrating Data+AI applications effectively.\n  To achieve this, we propose the concept of a 'Data Agent' - a comprehensive\narchitecture designed to orchestrate Data+AI ecosystems, which focuses on\ntackling data-related tasks by integrating knowledge comprehension, reasoning,\nand planning capabilities. We delve into the challenges involved in designing\ndata agents, such as understanding data/queries/environments/tools,\norchestrating pipelines/workflows, optimizing and executing pipelines, and\nfostering pipeline self-reflection. Furthermore, we present examples of data\nagent systems, including a data science agent, data analytics agents (such as\nunstructured data analytics agent, semantic structured data analytics agent,\ndata lake analytics agent, and multi-modal data analytics agent), and a\ndatabase administrator (DBA) agent. We also outline several open challenges\nassociated with designing data agent systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u201c\u6570\u636e\u4ee3\u7406\u201d\u6982\u5ff5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f18\u5316Data+AI\u7cfb\u7edf\u7684\u8bed\u4e49\u7406\u89e3\u3001\u63a8\u7406\u548c\u89c4\u5212\u80fd\u529b\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u7cfb\u7edf\u4f9d\u8d56\u4eba\u5de5\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfData+AI\u7cfb\u7edf\u4f9d\u8d56\u4eba\u5de5\u534f\u8c03\uff0c\u7f3a\u4e4f\u8bed\u4e49\u7406\u89e3\u548c\u89c4\u5212\u80fd\u529b\uff0c\u800cLLMs\u7684\u6210\u529f\u4e3a\u7cfb\u7edf\u9769\u65b0\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "method": "\u63d0\u51fa\u201c\u6570\u636e\u4ee3\u7406\u201d\u67b6\u6784\uff0c\u6574\u5408\u77e5\u8bc6\u7406\u89e3\u3001\u63a8\u7406\u548c\u89c4\u5212\u80fd\u529b\uff0c\u89e3\u51b3\u6570\u636e\u4efb\u52a1\u534f\u8c03\u95ee\u9898\u3002", "result": "\u5c55\u793a\u4e86\u591a\u79cd\u6570\u636e\u4ee3\u7406\u7cfb\u7edf\uff08\u5982\u6570\u636e\u79d1\u5b66\u4ee3\u7406\u3001\u6570\u636e\u5206\u6790\u4ee3\u7406\u7b49\uff09\uff0c\u5e76\u63a2\u8ba8\u4e86\u8bbe\u8ba1\u4e2d\u7684\u6311\u6218\u3002", "conclusion": "\u6570\u636e\u4ee3\u7406\u6709\u671b\u9769\u65b0Data+AI\u7cfb\u7edf\uff0c\u4f46\u4ecd\u9762\u4e34\u8bbe\u8ba1\u6311\u6218\u3002"}}
{"id": "2507.01755", "pdf": "https://arxiv.org/pdf/2507.01755", "abs": "https://arxiv.org/abs/2507.01755", "authors": ["Roberto Garc\u00eda", "Renzo Angles", "Vicente Rojas", "Sebasti\u00e1n Ferrada"], "title": "PathDB: A system for evaluating regular path queries", "categories": ["cs.DB"], "comment": null, "summary": "PathDB is a Java-based graph database designed for in-memory data loading and\nquerying. By utilizing Regular Path Queries (RPQ) and a closed path algebra,\nPathDB processes paths through its three main components: the parser, the\nlogical plan, and the physical plan. This modular design allows for targeted\noptimizations and modifications without impacting overall functionality.\nBenchmark experiments illustrate PathDB's execution times and flexibility in\nhandling dynamic and complex path queries, compared to baseline methods like\nDepth-First Search (DFS) and Breadth-First Search (BFS) guided by an automaton,\nhighlighting its optimizations that contribute to its performance.", "AI": {"tldr": "PathDB\u662f\u4e00\u4e2a\u57fa\u4e8eJava\u7684\u56fe\u6570\u636e\u5e93\uff0c\u4e13\u6ce8\u4e8e\u5185\u5b58\u6570\u636e\u52a0\u8f7d\u548c\u67e5\u8be2\uff0c\u901a\u8fc7\u6b63\u5219\u8def\u5f84\u67e5\u8be2\uff08RPQ\uff09\u548c\u5c01\u95ed\u8def\u5f84\u4ee3\u6570\u4f18\u5316\u6027\u80fd\u3002", "motivation": "\u8bbe\u8ba1PathDB\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u9ad8\u6548\u5904\u7406\u52a8\u6001\u548c\u590d\u6742\u7684\u8def\u5f84\u67e5\u8be2\uff0c\u540c\u65f6\u652f\u6301\u6a21\u5757\u5316\u4f18\u5316\u3002", "method": "PathDB\u901a\u8fc7\u89e3\u6790\u5668\u3001\u903b\u8f91\u8ba1\u5212\u548c\u7269\u7406\u8ba1\u5212\u4e09\u4e2a\u4e3b\u8981\u7ec4\u4ef6\u5904\u7406\u8def\u5f84\u67e5\u8be2\uff0c\u5e76\u652f\u6301\u6b63\u5219\u8def\u5f84\u67e5\u8be2\u548c\u5c01\u95ed\u8def\u5f84\u4ee3\u6570\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0cPathDB\u5728\u6267\u884c\u65f6\u95f4\u548c\u7075\u6d3b\u6027\u4e0a\u4f18\u4e8eDFS\u548cBFS\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "PathDB\u7684\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u4f18\u5316\u7b56\u7565\u4f7f\u5176\u5728\u590d\u6742\u8def\u5f84\u67e5\u8be2\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.01239", "pdf": "https://arxiv.org/pdf/2507.01239", "abs": "https://arxiv.org/abs/2507.01239", "authors": ["Matthew Scott", "Jeremy Pitt"], "title": "A Full-Stack Platform Architecture for Self-Organised Social Coordination", "categories": ["cs.NI"], "comment": "10 pages, 10 figures, 2 tables", "summary": "To mitigate the restrictive centralising and monopolistic tendencies of\nplatformisation, we aim to empower local communities by democratising platforms\nfor self-organised social coordination. Our approach is to develop an\nopen-source, full-stack architecture for platform development that supports\nease of distribution and cloning, generativity, and a variety of hosting\noptions. The architecture consists of a meta-platform that is used to\ninstantiate a base platform with supporting libraries for generic functions,\nand plugins (intended to be supplied by third parties) for customisation of\napplication-specification functionality for self-organised social coordination.\nAssociated developer- and user-oriented toolchains support the instantiation\nand customisation of a platform in a two-stage process. This is demonstrated\nthrough the proof-of-concept implementation of two case studies: a platform for\nregular sporting association, and a platform for collective group study. We\nconclude by arguing that self-organisation at the application layer can be\nachieved by the specific supporting functionality of a full-stack architecture\nwith complimentary developer and user toolchains.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f00\u6e90\u7684\u5168\u6808\u67b6\u6784\uff0c\u65e8\u5728\u901a\u8fc7\u6c11\u4e3b\u5316\u5e73\u53f0\u6765\u652f\u6301\u672c\u5730\u793e\u533a\u7684\u81ea\u6211\u7ec4\u7ec7\u793e\u4ea4\u534f\u8c03\uff0c\u4ee5\u5bf9\u6297\u5e73\u53f0\u5316\u7684\u5784\u65ad\u8d8b\u52bf\u3002", "motivation": "\u5e94\u5bf9\u5e73\u53f0\u5316\u5e26\u6765\u7684\u4e2d\u5fc3\u5316\u548c\u5784\u65ad\u95ee\u9898\uff0c\u8d4b\u80fd\u672c\u5730\u793e\u533a\u901a\u8fc7\u81ea\u6211\u7ec4\u7ec7\u8fdb\u884c\u793e\u4ea4\u534f\u8c03\u3002", "method": "\u5f00\u53d1\u4e00\u4e2a\u652f\u6301\u5206\u53d1\u3001\u514b\u9686\u3001\u751f\u6210\u6027\u548c\u591a\u79cd\u6258\u7ba1\u9009\u9879\u7684\u5f00\u6e90\u5168\u6808\u67b6\u6784\uff0c\u5305\u62ec\u5143\u5e73\u53f0\u3001\u57fa\u7840\u5e73\u53f0\u3001\u63d2\u4ef6\u548c\u5f00\u53d1\u8005/\u7528\u6237\u5de5\u5177\u94fe\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\uff08\u4f53\u80b2\u534f\u4f1a\u5e73\u53f0\u548c\u96c6\u4f53\u5b66\u4e60\u5e73\u53f0\uff09\u9a8c\u8bc1\u4e86\u8be5\u67b6\u6784\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u901a\u8fc7\u5168\u6808\u67b6\u6784\u548c\u914d\u5957\u5de5\u5177\u94fe\uff0c\u53ef\u4ee5\u5728\u5e94\u7528\u5c42\u5b9e\u73b0\u81ea\u6211\u7ec4\u7ec7\u3002"}}
{"id": "2507.01113", "pdf": "https://arxiv.org/pdf/2507.01113", "abs": "https://arxiv.org/abs/2507.01113", "authors": ["Vairavan Palaniappan", "Adam H. Ross", "Amit Ranjan Trivedi", "Debjit Pal"], "title": "HERCULES: Hardware accElerator foR stoChastic schedULing in hEterogeneous Systems", "categories": ["cs.DC", "cs.SY", "eess.SY"], "comment": "10 pages, 10 figures, accepted for publication in in Int'l Conference\n  on Computer Aided Design (ICCAD) 2025", "summary": "Efficient workload scheduling is a critical challenge in modern heterogeneous\ncomputing environments, particularly in high-performance computing (HPC)\nsystems. Traditional software-based schedulers struggle to efficiently balance\nworkload distribution due to high scheduling overhead, lack of adaptability to\ndynamic workloads, and suboptimal resource utilization. These pitfalls are\ncompounded in heterogeneous systems, where differing computational elements can\nhave vastly different performance profiles. To resolve these hindrances, we\npresent a novel FPGA-based accelerator for stochastic online scheduling (SOS).\nWe modify a greedy cost selection assignment policy by adapting existing cost\nequations to engage with discretized time before implementing them into a\nhardware accelerator design. Our design leverages hardware parallelism,\nprecalculation, and precision quantization to reduce job scheduling latency. By\nintroducing a hardware-accelerated approach to real-time scheduling, this paper\nestablishes a new paradigm for adaptive scheduling mechanisms in heterogeneous\ncomputing systems. The proposed design achieves high throughput, low latency,\nand energy-efficient operation, offering a scalable alternative to traditional\nsoftware scheduling methods. Experimental results demonstrate consistent\nworkload distribution, fair machine utilization, and up to 1060x speedup over\nsingle-threaded software scheduling policy implementations. This makes the SOS\naccelerator a strong candidate for deployment in high-performance computing\nsystem, deeplearning pipelines, and other performance-critical applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFPGA\u7684\u968f\u673a\u5728\u7ebf\u8c03\u5ea6\uff08SOS\uff09\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u786c\u4ef6\u5e76\u884c\u5316\u548c\u9884\u8ba1\u7b97\u964d\u4f4e\u8c03\u5ea6\u5ef6\u8fdf\uff0c\u663e\u8457\u63d0\u5347\u5f02\u6784\u8ba1\u7b97\u7cfb\u7edf\u7684\u8c03\u5ea6\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u8c03\u5ea6\u5668\u5728\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u7cfb\u7edf\u4e2d\u56e0\u9ad8\u5f00\u9500\u548c\u52a8\u6001\u8d1f\u8f7d\u9002\u5e94\u6027\u95ee\u9898\u8868\u73b0\u4e0d\u4f73\uff0c\u5c24\u5176\u5728\u5f02\u6784\u7cfb\u7edf\u4e2d\u8d44\u6e90\u5229\u7528\u7387\u4f4e\u3002", "method": "\u4fee\u6539\u8d2a\u5fc3\u6210\u672c\u9009\u62e9\u7b56\u7565\uff0c\u5229\u7528\u786c\u4ef6\u5e76\u884c\u5316\u548c\u7cbe\u5ea6\u91cf\u5316\u8bbe\u8ba1FPGA\u52a0\u901f\u5668\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8c03\u5ea6\u5ef6\u8fdf\u663e\u8457\u964d\u4f4e\uff0c\u541e\u5410\u91cf\u9ad8\uff0c\u80fd\u6548\u63d0\u5347\uff0c\u6bd4\u5355\u7ebf\u7a0b\u8f6f\u4ef6\u5b9e\u73b0\u5feb1060\u500d\u3002", "conclusion": "SOS\u52a0\u901f\u5668\u4e3a\u5f02\u6784\u8ba1\u7b97\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01065", "pdf": "https://arxiv.org/pdf/2507.01065", "abs": "https://arxiv.org/abs/2507.01065", "authors": ["Christiaan Verwijs", "Evelien Acun-Roos", "Daniel Russo"], "title": "Is It Safe To Learn And Share? On Psychological Safety and Social Learning in (Agile) Communities of Practice", "categories": ["cs.SE"], "comment": null, "summary": "As hybrid, distributed, and asynchronous work models become more prevalent,\ncontinuous learning in Agile Software Development (ASD) gains renewed\nimportance. Communities of Practice (CoPs) are increasingly adopted to support\nsocial learning beyond formal education, often relying on virtual\ncommunication. Psychological safety, a prerequisite for effective learning,\nremains insufficiently understood in these settings. This mixed-methods study\ninvestigates psychological safety within Agile CoPs through survey data from\n143 participants. Results indicate that psychological safety is significantly\nlower in online interactions compared to face-to-face settings. Moreover, low\npsychological safety reduces participants' intent to continue contributing and\navoidance of interpersonal risk. No significant differences emerged based on\ngender, community seniority, or content creation activity. However, differences\nby role and age group suggest potential generational or role-related effects.\nThematic analysis revealed exclusionary behavior, negative interaction\npatterns, and hostility as primary threats to psychological safety, often\nreinforced by tribalism and specific community dynamics. Suggested\ninterventions include establishing explicit norms, structured facilitation, and\nactive moderation. The findings were validated through member checking with 30\nparticipants. This study provides a comparative perspective on interaction\nmodalities and offers practical guidance for organizers seeking to cultivate\ninclusive, high-impact CoPs and similarly structured virtual or hybrid work\nenvironments.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u654f\u6377\u793e\u533a\u5b9e\u8df5\u4e2d\uff0c\u7ebf\u4e0a\u4e92\u52a8\u7684\u5fc3\u7406\u5b89\u5168\u611f\u663e\u8457\u4f4e\u4e8e\u9762\u5bf9\u9762\u4e92\u52a8\uff0c\u4e14\u4f4e\u5fc3\u7406\u5b89\u5168\u611f\u4f1a\u964d\u4f4e\u53c2\u4e0e\u8005\u7684\u6301\u7eed\u8d21\u732e\u610f\u613f\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22\u5728\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u4e2d\uff0c\u865a\u62df\u793e\u533a\u5b9e\u8df5\u4e2d\u5fc3\u7406\u5b89\u5168\u611f\u7684\u5f71\u54cd\u53ca\u5176\u91cd\u8981\u6027\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\uff0c\u901a\u8fc7143\u540d\u53c2\u4e0e\u8005\u7684\u8c03\u67e5\u6570\u636e\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u7ebf\u4e0a\u4e92\u52a8\u7684\u5fc3\u7406\u5b89\u5168\u611f\u8f83\u4f4e\uff0c\u4e14\u4f4e\u5fc3\u7406\u5b89\u5168\u611f\u4e0e\u53c2\u4e0e\u8005\u7684\u6301\u7eed\u8d21\u732e\u610f\u613f\u548c\u98ce\u9669\u89c4\u907f\u884c\u4e3a\u76f8\u5173\u3002", "conclusion": "\u7ed3\u8bba\u5efa\u8bae\u901a\u8fc7\u660e\u786e\u89c4\u8303\u3001\u7ed3\u6784\u5316\u5f15\u5bfc\u548c\u79ef\u6781\u7ba1\u7406\u6765\u63d0\u5347\u5fc3\u7406\u5b89\u5168\u611f\uff0c\u4e3a\u865a\u62df\u6216\u6df7\u5408\u5de5\u4f5c\u73af\u5883\u63d0\u4f9b\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2507.01366", "pdf": "https://arxiv.org/pdf/2507.01366", "abs": "https://arxiv.org/abs/2507.01366", "authors": ["Surender Baswana", "Koustav Bhanja", "Anupam Roy"], "title": "Faster Algorithm for Second (s,t)-mincut and Breaking Quadratic barrier for Dual Edge Sensitivity for (s,t)-mincut", "categories": ["cs.DS"], "comment": "Accepted in ESA 2025", "summary": "We study (s,t)-cuts of second minimum capacity and present the following\nalgorithmic and graph-theoretic results.\n  1. Vazirani and Yannakakis [ICALP 1992] designed the first algorithm for\ncomputing an (s,t)-cut of second minimum capacity using $O(n^2)$ maximum\n(s,t)-flow computations. For directed integer-weighted graphs, we significantly\nimprove this bound by designing an algorithm that computes an $(s,t)$-cut of\nsecond minimum capacity using $O(\\sqrt{n})$ maximum (s,t)-flow computations\nw.h.p. To achieve this result, a close relationship of independent interest is\nestablished between $(s,t)$-cuts of second minimum capacity and global mincuts\nin directed weighted graphs.\n  2. Minimum+1 (s,t)-cuts have been studied quite well recently [Baswana,\nBhanja, and Pandey, ICALP 2022], which is a special case of second\n(s,t)-mincut.\n  (a) For directed multi-graphs, we design an algorithm that, given any maximum\n(s,t)-flow, computes a minimum+1 (s,t)-cut, if it exists, in $O(m)$ time.\n  (b) The existing structures for storing and characterizing all minimum+1\n(s,t)-cuts occupy $O(mn)$ space. For undirected multi-graphs, we design a DAG\noccupying only $O(m)$ space that stores and characterizes all minimum+1\n(s,t)-cuts.\n  3. The study of minimum+1 (s,t)-cuts often turns out to be useful in\ndesigning dual edge sensitivity oracles -- a compact data structure for\nefficiently reporting an (s,t)-mincut after insertion/failure of any given pair\nof query edges. It has been shown recently [Bhanja, ICALP 2025] that any dual\nedge sensitivity oracle for (s,t)-mincut in undirected multi-graphs must occupy\n${\\Omega}(n^2)$ space in the worst-case, irrespective of the query time. For\nsimple graphs, we break this quadratic barrier while achieving a non-trivial\nquery time.", "AI": {"tldr": "\u7814\u7a76\u7b2c\u4e8c\u6700\u5c0f\u5bb9\u91cf\u7684(s,t)-\u5272\uff0c\u63d0\u51fa\u6539\u8fdb\u7b97\u6cd5\u548c\u7406\u8bba\u7ed3\u679c\uff0c\u5305\u62ec\u66f4\u9ad8\u6548\u7684\u8ba1\u7b97\u65b9\u6cd5\u548c\u7a7a\u95f4\u4f18\u5316\u7ed3\u6784\u3002", "motivation": "\u63a2\u7d22\u7b2c\u4e8c\u6700\u5c0f\u5bb9\u91cf\u7684(s,t)-\u5272\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u4ee5\u6539\u8fdb\u73b0\u6709\u7b97\u6cd5\u7684\u6548\u7387\uff0c\u5e76\u7814\u7a76\u5176\u5728\u53cc\u8fb9\u654f\u611f\u6027\u67e5\u8be2\u4e2d\u7684\u5e94\u7528\u3002", "method": "1. \u6539\u8fdb\u7b97\u6cd5\u51cf\u5c11\u6700\u5927\u6d41\u8ba1\u7b97\u6b21\u6570\uff1b2. \u8bbe\u8ba1\u7a7a\u95f4\u4f18\u5316\u7684\u6570\u636e\u7ed3\u6784\u5b58\u50a8\u6700\u5c0f+1\u5272\uff1b3. \u7814\u7a76\u7b80\u5355\u56fe\u4e2d\u7684\u53cc\u8fb9\u654f\u611f\u6027\u67e5\u8be2\u3002", "result": "1. \u7b97\u6cd5\u590d\u6742\u5ea6\u4eceO(n^2)\u964d\u81f3O(\u221an)\uff1b2. \u7a7a\u95f4\u5360\u7528\u4eceO(mn)\u964d\u81f3O(m)\uff1b3. \u5728\u7b80\u5355\u56fe\u4e2d\u7a81\u7834\u4e8c\u6b21\u7a7a\u95f4\u9650\u5236\u3002", "conclusion": "\u7814\u7a76\u4e3a\u7b2c\u4e8c\u6700\u5c0f(s,t)-\u5272\u63d0\u4f9b\u4e86\u9ad8\u6548\u7b97\u6cd5\u548c\u7d27\u51d1\u6570\u636e\u7ed3\u6784\uff0c\u62d3\u5c55\u4e86\u5176\u5728\u56fe\u8bba\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2507.01026", "pdf": "https://arxiv.org/pdf/2507.01026", "abs": "https://arxiv.org/abs/2507.01026", "authors": ["Md Shakil Ahamed Shohag", "Q. M. Jonathan Wu", "Farhad Pourpanah"], "title": "Few-Shot Inspired Generative Zero-Shot Learning", "categories": ["cs.LG"], "comment": null, "summary": "Generative zero-shot learning (ZSL) methods typically synthesize visual\nfeatures for unseen classes using predefined semantic attributes, followed by\ntraining a fully supervised classification model. While effective, these\nmethods require substantial computational resources and extensive synthetic\ndata, thereby relaxing the original ZSL assumptions. In this paper, we propose\nFSIGenZ, a few-shot-inspired generative ZSL framework that reduces reliance on\nlarge-scale feature synthesis. Our key insight is that class-level attributes\nexhibit instance-level variability, i.e., some attributes may be absent or\npartially visible, yet conventional ZSL methods treat them as uniformly\npresent. To address this, we introduce Model-Specific Attribute Scoring (MSAS),\nwhich dynamically re-scores class attributes based on model-specific\noptimization to approximate instance-level variability without access to unseen\ndata. We further estimate group-level prototypes as clusters of instances based\non MSAS-adjusted attribute scores, which serve as representative synthetic\nfeatures for each unseen class. To mitigate the resulting data imbalance, we\nintroduce a Dual-Purpose Semantic Regularization (DPSR) strategy while training\na semantic-aware contrastive classifier (SCC) using these prototypes.\nExperiments on SUN, AwA2, and CUB benchmarks demonstrate that FSIGenZ achieves\ncompetitive performance using far fewer synthetic features.", "AI": {"tldr": "FSIGenZ\u63d0\u51fa\u4e86\u4e00\u79cd\u5c11\u6837\u672c\u542f\u53d1\u7684\u751f\u6210\u5f0f\u96f6\u6837\u672c\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u5c5e\u6027\u8bc4\u5206\u548c\u539f\u578b\u4f30\u8ba1\uff0c\u51cf\u5c11\u5bf9\u5927\u89c4\u6a21\u7279\u5f81\u5408\u6210\u7684\u4f9d\u8d56\u3002", "motivation": "\u4f20\u7edf\u751f\u6210\u5f0f\u96f6\u6837\u672c\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u548c\u5408\u6210\u6570\u636e\uff0c\u8fdd\u80cc\u4e86\u96f6\u6837\u672c\u5b66\u4e60\u7684\u521d\u8877\u3002FSIGenZ\u65e8\u5728\u901a\u8fc7\u52a8\u6001\u5c5e\u6027\u8bc4\u5206\u548c\u539f\u578b\u4f30\u8ba1\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5f15\u5165\u6a21\u578b\u7279\u5b9a\u5c5e\u6027\u8bc4\u5206\uff08MSAS\uff09\u52a8\u6001\u8c03\u6574\u5c5e\u6027\uff0c\u4f30\u8ba1\u7ec4\u7ea7\u539f\u578b\u4f5c\u4e3a\u672a\u89c1\u7c7b\u7684\u4ee3\u8868\u6027\u7279\u5f81\uff0c\u5e76\u4f7f\u7528\u53cc\u91cd\u76ee\u7684\u8bed\u4e49\u6b63\u5219\u5316\uff08DPSR\uff09\u8bad\u7ec3\u8bed\u4e49\u611f\u77e5\u5bf9\u6bd4\u5206\u7c7b\u5668\uff08SCC\uff09\u3002", "result": "\u5728SUN\u3001AwA2\u548cCUB\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFSIGenZ\u4f7f\u7528\u66f4\u5c11\u7684\u5408\u6210\u7279\u5f81\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u6027\u80fd\u3002", "conclusion": "FSIGenZ\u901a\u8fc7\u52a8\u6001\u5c5e\u6027\u8bc4\u5206\u548c\u539f\u578b\u4f30\u8ba1\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u751f\u6210\u5f0f\u96f6\u6837\u672c\u5b66\u4e60\u5bf9\u5927\u89c4\u6a21\u7279\u5f81\u5408\u6210\u7684\u4f9d\u8d56\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u6027\u80fd\u3002"}}
{"id": "2507.01053", "pdf": "https://arxiv.org/pdf/2507.01053", "abs": "https://arxiv.org/abs/2507.01053", "authors": ["Rafi Al Attrach", "Pedro Moreira", "Rajna Fani", "Renato Umeton", "Leo Anthony Celi"], "title": "Conversational LLMs Simplify Secure Clinical Data Access, Understanding, and Analysis", "categories": ["cs.IR", "cs.AI", "cs.DB", "68T50, 68P15", "H.2.3; I.2.7; J.3"], "comment": "10 pages, 4 figures", "summary": "As ever-larger clinical datasets become available, they have the potential to\nunlock unprecedented opportunities for medical research. Foremost among them is\nMedical Information Mart for Intensive Care (MIMIC-IV), the world's largest\nopen-source EHR database. However, the inherent complexity of these datasets,\nparticularly the need for sophisticated querying skills and the need to\nunderstand the underlying clinical settings, often presents a significant\nbarrier to their effective use. M3 lowers the technical barrier to\nunderstanding and querying MIMIC-IV data. With a single command it retrieves\nMIMIC-IV from PhysioNet, launches a local SQLite instance (or hooks into the\nhosted BigQuery), and-via the Model Context Protocol (MCP)-lets researchers\nconverse with the database in plain English. Ask a clinical question in natural\nlanguage; M3 uses a language model to translate it into SQL, executes the query\nagainst the MIMIC-IV dataset, and returns structured results alongside the\nunderlying query for verifiability and reproducibility. Demonstrations show\nthat minutes of dialogue with M3 yield the kind of nuanced cohort analyses that\nonce demanded hours of handcrafted SQL and relied on understanding the\ncomplexities of clinical workflows. By simplifying access, M3 invites the\nbroader research community to mine clinical critical-care data and accelerates\nthe translation of raw records into actionable insight.", "AI": {"tldr": "M3\u662f\u4e00\u4e2a\u5de5\u5177\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u7b80\u5316\u4e86\u5bf9MIMIC-IV\u4e34\u5e8a\u6570\u636e\u5e93\u7684\u8bbf\u95ee\uff0c\u964d\u4f4e\u4e86\u6280\u672f\u95e8\u69db\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u4e34\u5e8a\u6570\u636e\u96c6\uff08\u5982MIMIC-IV\uff09\u56e0\u6280\u672f\u590d\u6742\u6027\u548c\u4e34\u5e8a\u80cc\u666f\u77e5\u8bc6\u9700\u6c42\u800c\u96be\u4ee5\u6709\u6548\u5229\u7528\u7684\u95ee\u9898\u3002", "method": "M3\u901a\u8fc7\u5355\u547d\u4ee4\u83b7\u53d6MIMIC-IV\u6570\u636e\uff0c\u5229\u7528\u8bed\u8a00\u6a21\u578b\u5c06\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u8f6c\u6362\u4e3aSQL\u67e5\u8be2\uff0c\u5e76\u63d0\u4f9b\u7ed3\u6784\u5316\u7ed3\u679c\u548c\u67e5\u8be2\u9a8c\u8bc1\u3002", "result": "\u6f14\u793a\u8868\u660e\uff0cM3\u80fd\u5728\u51e0\u5206\u949f\u5185\u5b8c\u6210\u4ee5\u5f80\u9700\u8981\u6570\u5c0f\u65f6\u624b\u5de5SQL\u7f16\u5199\u7684\u590d\u6742\u961f\u5217\u5206\u6790\u3002", "conclusion": "M3\u7b80\u5316\u4e86\u4e34\u5e8a\u6570\u636e\u7684\u8bbf\u95ee\uff0c\u52a0\u901f\u4e86\u4ece\u539f\u59cb\u8bb0\u5f55\u5230\u53ef\u64cd\u4f5c\u89c1\u89e3\u7684\u8f6c\u5316\uff0c\u4fc3\u8fdb\u4e86\u66f4\u5e7f\u6cdb\u7684\u7814\u7a76\u793e\u533a\u53c2\u4e0e\u3002"}}
{"id": "2507.01289", "pdf": "https://arxiv.org/pdf/2507.01289", "abs": "https://arxiv.org/abs/2507.01289", "authors": ["Enzhi Zhou", "Yue Xiao", "Ziyue Liu", "Sotiris A. Tegos", "Panagiotis D. Diamantoulakis", "George K. Karagiannidis"], "title": "Fluid Aerial Networks: UAV Rotation for Inter-Cell Interference Mitigation", "categories": ["cs.NI", "eess.SP"], "comment": null, "summary": "With the rapid development of aerial infrastructure, unmanned aerial vehicles\n(UAVs) that function as aerial base stations (ABSs) extend terrestrial network\nservices into the sky, enabling on-demand connectivity and enhancing emergency\ncommunication capabilities in cellular networks by leveraging the flexibility\nand mobility of UAVs. In such a UAV-assisted network, this paper investigates\nposition-based beamforming between ABSs and ground users (GUs). To mitigate\ninter-cell interference, we propose a novel fluid aerial network that leverages\nABS rotation to increase multi-cell capacity and overall network efficiency.\nSpecifically, considering the line-of-sight channel model, the spatial\nbeamforming weights are determined by the orientation angles of the GUs. In\nthis direction, we examine the beamforming gain of a two-dimensional\nmultiple-input multiple-output (MIMO) array at various ground positions,\nrevealing that ABS rotation significantly affects multi-user channel\ncorrelation and inter-cell interference. Based on these findings, we propose an\nalternative low-complexity algorithm to design the optimal rotation angle for\nABSs, aiming to reduce inter-cell interference and thus maximize the sum rate\nof multi-cell systems. In simulations, exhaustive search serves as a benchmark\nto validate the optimization performance of the proposed sequential ABS\nrotation scheme. Moreover, simulation results demonstrate that, in\ninterference-limited regions, the proposed ABS rotation paradigm can\nsignificantly reduce inter-cell interference in terrestrial networks and\nimprove the multi-cell sum rate by approximately 10\\% compared to\nfixed-direction ABSs without rotation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u65e0\u4eba\u673a\u8f85\u52a9\u7f51\u7edc\u4e2d\u57fa\u4e8e\u4f4d\u7f6e\u7684\u6ce2\u675f\u6210\u5f62\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u65e0\u4eba\u673a\u65cb\u8f6c\u51cf\u5c11\u5c0f\u533a\u95f4\u5e72\u6270\u7684\u65b0\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u5c0f\u533a\u7cfb\u7edf\u5bb9\u91cf\u3002", "motivation": "\u968f\u7740\u65e0\u4eba\u673a\u4f5c\u4e3a\u7a7a\u4e2d\u57fa\u7ad9\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5982\u4f55\u5229\u7528\u5176\u7075\u6d3b\u6027\u548c\u79fb\u52a8\u6027\u63d0\u5347\u5730\u9762\u7f51\u7edc\u670d\u52a1\u8d28\u91cf\u548c\u5e94\u6025\u901a\u4fe1\u80fd\u529b\u6210\u4e3a\u7814\u7a76\u91cd\u70b9\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6d41\u4f53\u7a7a\u4e2d\u7f51\u7edc\uff0c\u5229\u7528\u65e0\u4eba\u673a\u65cb\u8f6c\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u6743\u91cd\uff0c\u5e76\u901a\u8fc7\u4f4e\u590d\u6742\u5ea6\u7b97\u6cd5\u8bbe\u8ba1\u6700\u4f18\u65cb\u8f6c\u89d2\u5ea6\u4ee5\u51cf\u5c11\u5e72\u6270\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65e0\u4eba\u673a\u65cb\u8f6c\u65b9\u6848\u5728\u5e72\u6270\u53d7\u9650\u533a\u57df\u80fd\u663e\u8457\u51cf\u5c11\u5e72\u6270\uff0c\u591a\u5c0f\u533a\u603b\u901f\u7387\u6bd4\u56fa\u5b9a\u65b9\u5411\u65e0\u4eba\u673a\u63d0\u5347\u7ea610%\u3002", "conclusion": "\u65e0\u4eba\u673a\u65cb\u8f6c\u662f\u4e00\u79cd\u6709\u6548\u51cf\u5c11\u5c0f\u533a\u95f4\u5e72\u6270\u5e76\u63d0\u5347\u7f51\u7edc\u6548\u7387\u7684\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u5e72\u6270\u53d7\u9650\u533a\u57df\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2507.01224", "pdf": "https://arxiv.org/pdf/2507.01224", "abs": "https://arxiv.org/abs/2507.01224", "authors": ["Wenqi Jia", "Ying Huang", "Jian Xu", "Zhewen Hu", "Sian Jin", "Jiannan Tian", "Yuede Ji", "Miao Yin"], "title": "FLARE: A Dataflow-Aware and Scalable Hardware Architecture for Neural-Hybrid Scientific Lossy Compression", "categories": ["cs.DC"], "comment": null, "summary": "Scientific simulation leveraging high-performance computing (HPC) systems is\ncrucial for modeling complex systems and phenomena in fields such as\nastrophysics, climate science, and fluid dynamics, generating massive datasets\nthat often reach petabyte to exabyte scales. However, managing these vast data\nvolumes introduces significant I/O and network bottlenecks, limiting practical\nperformance and scalability. While cutting-edge lossy compression frameworks\npowered by deep neural networks (DNNs) have demonstrated superior compression\nratios by capturing complex data correlations, their integration into HPC\nworkflows poses substantial challenges due to the hybrid non-neural and neural\ncomputation patterns, causing excessive memory access overhead, large\nsequential stalls, and limited adaptability to varying data sizes and workloads\nin existing hardware platforms. To overcome these challenges and push the limit\nof high-performance scientific computing, we for the first time propose FLARE,\na dataflow-aware and scalable hardware architecture for neural-hybrid\nscientific lossy compression. FLARE minimizes off-chip data access, reduces\nbubble overhead through efficient dataflow, and adopts a modular design that\nprovides both scalability and flexibility, significantly enhancing throughput\nand energy efficiency on modern HPC systems. Particularly, the proposed FLARE\nachieves runtime speedups ranging from $3.50 \\times$ to $96.07 \\times$, and\nenergy efficiency improvements ranging from $24.51 \\times$ to $520.68 \\times$,\nacross various datasets and hardware platforms.", "AI": {"tldr": "FLARE\u662f\u4e00\u79cd\u65b0\u578b\u786c\u4ef6\u67b6\u6784\uff0c\u7528\u4e8e\u9ad8\u6027\u80fd\u79d1\u5b66\u8ba1\u7b97\u4e2d\u7684\u795e\u7ecf\u6df7\u5408\u6709\u635f\u538b\u7f29\uff0c\u663e\u8457\u63d0\u5347\u4e86\u541e\u5410\u91cf\u548c\u80fd\u6548\u3002", "motivation": "\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u7cfb\u7edf\u5728\u79d1\u5b66\u6a21\u62df\u4e2d\u751f\u6210\u6d77\u91cf\u6570\u636e\uff0c\u4f46\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\u56e0\u6df7\u5408\u8ba1\u7b97\u6a21\u5f0f\u5bfc\u81f4\u6027\u80fd\u74f6\u9888\u3002", "method": "\u63d0\u51faFLARE\u67b6\u6784\uff0c\u901a\u8fc7\u6570\u636e\u6d41\u611f\u77e5\u548c\u6a21\u5757\u5316\u8bbe\u8ba1\u51cf\u5c11\u5185\u5b58\u8bbf\u95ee\u5f00\u9500\u548c\u6c14\u6ce1\u65f6\u95f4\u3002", "result": "FLARE\u5728\u8fd0\u884c\u65f6\u548c\u80fd\u6548\u4e0a\u5206\u522b\u5b9e\u73b0\u4e863.50\u00d7\u81f396.07\u00d7\u548c24.51\u00d7\u81f3520.68\u00d7\u7684\u63d0\u5347\u3002", "conclusion": "FLARE\u4e3aHPC\u7cfb\u7edf\u4e2d\u7684\u795e\u7ecf\u6df7\u5408\u538b\u7f29\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01103", "pdf": "https://arxiv.org/pdf/2507.01103", "abs": "https://arxiv.org/abs/2507.01103", "authors": ["Jonhnanthan Oliveira", "Rohit Gheyi", "M\u00e1rcio Ribeiro", "Alessandro Garcia"], "title": "Bugs in the Shadows: Static Detection of Faulty Python Refactorings", "categories": ["cs.SE"], "comment": "Accepted at Brazilian Symposium on Software Engineering (SBES 2025)", "summary": "Python is a widely adopted programming language, valued for its simplicity\nand flexibility. However, its dynamic type system poses significant challenges\nfor automated refactoring - an essential practice in software evolution aimed\nat improving internal code structure without changing external behavior.\nUnderstanding how type errors are introduced during refactoring is crucial, as\nsuch errors can compromise software reliability and reduce developer\nproductivity. In this work, we propose a static analysis technique to detect\ntype errors introduced by refactoring implementations for Python. We evaluated\nour technique on Rope refactoring implementations, applying them to open-source\nPython projects. Our analysis uncovered 29 bugs across four refactoring types\nfrom a total of 1,152 refactoring attempts. Several of these issues were also\nfound in widely used IDEs such as PyCharm and PyDev. All reported bugs were\nsubmitted to the respective developers, and some of them were acknowledged and\naccepted. These results highlight the need to improve the robustness of current\nPython refactoring tools to ensure the correctness of automated code\ntransformations and support reliable software maintenance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9759\u6001\u5206\u6790\u6280\u672f\uff0c\u7528\u4e8e\u68c0\u6d4bPython\u91cd\u6784\u8fc7\u7a0b\u4e2d\u5f15\u5165\u7684\u7c7b\u578b\u9519\u8bef\uff0c\u5e76\u5728\u5f00\u6e90\u9879\u76ee\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "Python\u7684\u52a8\u6001\u7c7b\u578b\u7cfb\u7edf\u5728\u81ea\u52a8\u5316\u91cd\u6784\u4e2d\u5bb9\u6613\u5f15\u5165\u7c7b\u578b\u9519\u8bef\uff0c\u5f71\u54cd\u8f6f\u4ef6\u53ef\u9760\u6027\u548c\u5f00\u53d1\u6548\u7387\u3002", "method": "\u91c7\u7528\u9759\u6001\u5206\u6790\u6280\u672f\uff0c\u8bc4\u4f30\u4e86Rope\u91cd\u6784\u5b9e\u73b0\uff0c\u5e76\u5728\u5f00\u6e90Python\u9879\u76ee\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "result": "\u57281,152\u6b21\u91cd\u6784\u5c1d\u8bd5\u4e2d\u53d1\u73b0\u4e8629\u4e2a\u9519\u8bef\uff0c\u90e8\u5206\u95ee\u9898\u4e5f\u5b58\u5728\u4e8e\u4e3b\u6d41IDE\u4e2d\u3002", "conclusion": "\u5f53\u524dPython\u91cd\u6784\u5de5\u5177\u7684\u5065\u58ee\u6027\u9700\u63d0\u5347\uff0c\u4ee5\u786e\u4fdd\u4ee3\u7801\u8f6c\u6362\u7684\u6b63\u786e\u6027\u548c\u8f6f\u4ef6\u7ef4\u62a4\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2507.01696", "pdf": "https://arxiv.org/pdf/2507.01696", "abs": "https://arxiv.org/abs/2507.01696", "authors": ["Steinar Laenen", "Peter Macgregor", "He Sun"], "title": "Dynamic Similarity Graph Construction with Kernel Density Estimation", "categories": ["cs.DS", "cs.LG"], "comment": "ICML'25", "summary": "In the kernel density estimation (KDE) problem, we are given a set $X$ of\ndata points in $\\mathbb{R}^d$, a kernel function $k: \\mathbb{R}^d \\times\n\\mathbb{R}^d \\rightarrow \\mathbb{R}$, and a query point $\\mathbf{q} \\in\n\\mathbb{R}^d$, and the objective is to quickly output an estimate of\n$\\sum_{\\mathbf{x} \\in X} k(\\mathbf{q}, \\mathbf{x})$. In this paper, we consider\n$\\textsf{KDE}$ in the dynamic setting, and introduce a data structure that\nefficiently maintains the estimates for a set of query points as data points\nare added to $X$ over time. Based on this, we design a dynamic data structure\nthat maintains a sparse approximation of the fully connected similarity graph\non $X$, and develop a fast dynamic spectral clustering algorithm. We further\nevaluate the effectiveness of our algorithms on both synthetic and real-world\ndatasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u6838\u5bc6\u5ea6\u4f30\u8ba1\uff08KDE\uff09\u6570\u636e\u7ed3\u6784\uff0c\u7528\u4e8e\u9ad8\u6548\u7ef4\u62a4\u67e5\u8be2\u70b9\u7684\u4f30\u8ba1\u503c\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u4e86\u52a8\u6001\u8c31\u805a\u7c7b\u7b97\u6cd5\u3002", "motivation": "\u89e3\u51b3\u52a8\u6001\u73af\u5883\u4e0bKDE\u95ee\u9898\u7684\u9ad8\u6548\u8ba1\u7b97\u9700\u6c42\uff0c\u5e76\u6269\u5c55\u81f3\u52a8\u6001\u8c31\u805a\u7c7b\u3002", "method": "\u8bbe\u8ba1\u52a8\u6001\u6570\u636e\u7ed3\u6784\u7ef4\u62a4KDE\u4f30\u8ba1\uff0c\u6784\u5efa\u7a00\u758f\u76f8\u4f3c\u56fe\uff0c\u5f00\u53d1\u52a8\u6001\u8c31\u805a\u7c7b\u7b97\u6cd5\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u52a8\u6001\u73af\u5883\u4e0b\u9ad8\u6548\u4e14\u5b9e\u7528\u3002"}}
{"id": "2507.01027", "pdf": "https://arxiv.org/pdf/2507.01027", "abs": "https://arxiv.org/abs/2507.01027", "authors": ["Zijian Ye", "Wei Huang", "Yifei Yu", "Tianhe Ren", "Zhongrui Wang", "Xiaojuan Qi"], "title": "DBellQuant: Breaking the Bell with Double-Bell Transformation for LLMs Post Training Binarization", "categories": ["cs.LG"], "comment": "19 pages; Appendix added", "summary": "Large language models (LLMs) demonstrate remarkable performance but face\nsubstantial computational and memory challenges that limit their practical\ndeployment. Quantization has emerged as a promising solution; however, its\neffectiveness is often limited by quantization errors arising from weight\ndistributions that are not quantization-friendly and the presence of activation\noutliers. To address these challenges, we introduce DBellQuant, an innovative\npost-training quantization (PTQ) framework that achieves nearly 1-bit weight\ncompression and 6-bit activation quantization with minimal performance\ndegradation. DBellQuant uses Learnable Transformation for Dual-Bell (LTDB)\nalgorithm, which transforms single-bell weight distributions into dual-bell\nforms to reduce binarization errors and applies inverse transformations to\nsmooth activations. DBellQuant sets a new state-of-the-art by preserving\nsuperior model performance under aggressive weight and activation quantization.\nFor example, on the Wikitext2 dataset, DBellQuant achieves a perplexity of\n14.39 on LLaMA2-13B with 6-bit activation quantization, significantly\noutperforming BiLLM's 21.35 without activation quantization, underscoring its\npotential in compressing LLMs for real-world applications.", "AI": {"tldr": "DBellQuant\u662f\u4e00\u79cd\u521b\u65b0\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u949f\u5f62\u5206\u5e03\u53d8\u6362\u51cf\u5c11\u91cf\u5316\u8bef\u5dee\uff0c\u5b9e\u73b01\u4f4d\u6743\u91cd\u538b\u7f29\u548c6\u4f4d\u6fc0\u6d3b\u91cf\u5316\uff0c\u6027\u80fd\u635f\u5931\u6781\u5c0f\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u9762\u4e34\u8ba1\u7b97\u548c\u5185\u5b58\u6311\u6218\uff0c\u91cf\u5316\u662f\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u91cf\u5316\u8bef\u5dee\u548c\u6fc0\u6d3b\u5f02\u5e38\u503c\u9650\u5236\u4e86\u5176\u6548\u679c\u3002", "method": "DBellQuant\u91c7\u7528\u53ef\u5b66\u4e60\u7684\u53cc\u949f\u5f62\u53d8\u6362\uff08LTDB\uff09\u7b97\u6cd5\uff0c\u5c06\u5355\u949f\u5f62\u6743\u91cd\u5206\u5e03\u8f6c\u6362\u4e3a\u53cc\u949f\u5f62\u4ee5\u51cf\u5c11\u4e8c\u503c\u5316\u8bef\u5dee\uff0c\u5e76\u901a\u8fc7\u9006\u53d8\u6362\u5e73\u6ed1\u6fc0\u6d3b\u3002", "result": "\u5728Wikitext2\u6570\u636e\u96c6\u4e0a\uff0cDBellQuant\u5728LLaMA2-13B\u4e0a\u5b9e\u73b014.39\u7684\u56f0\u60d1\u5ea6\uff0c\u4f18\u4e8eBiLLM\u768421.35\u3002", "conclusion": "DBellQuant\u5728\u6fc0\u8fdb\u91cf\u5316\u7684\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\uff0c\u4e3aLLMs\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u538b\u7f29\u65b9\u6848\u3002"}}
{"id": "2507.01267", "pdf": "https://arxiv.org/pdf/2507.01267", "abs": "https://arxiv.org/abs/2507.01267", "authors": ["Michelle Si", "Jian Pei"], "title": "Counterfactual Explanation of Shapley Value in Data Coalitions", "categories": ["cs.GT", "cs.DB"], "comment": null, "summary": "The Shapley value is widely used for data valuation in data markets. However,\nexplaining the Shapley value of an owner in a data coalition is an unexplored\nand challenging task. To tackle this, we formulate the problem of finding the\ncounterfactual explanation of Shapley value in data coalitions. Essentially,\ngiven two data owners $A$ and $B$ such that $A$ has a higher Shapley value than\n$B$, a counterfactual explanation is a smallest subset of data entries in $A$\nsuch that transferring the subset from $A$ to $B$ makes the Shapley value of\n$A$ less than that of $B$. We show that counterfactual explanations always\nexist, but finding an exact counterfactual explanation is NP-hard. Using Monte\nCarlo estimation to approximate counterfactual explanations directly according\nto the definition is still very costly, since we have to estimate the Shapley\nvalues of owners $A$ and $B$ after each possible subset shift. We develop a\nseries of heuristic techniques to speed up computation by estimating\ndifferential Shapley values, computing the power of singular data entries, and\nshifting subsets greedily, culminating in the SV-Exp algorithm. Our\nexperimental results on real datasets clearly demonstrate the efficiency of our\nmethod and the effectiveness of counterfactuals in interpreting the Shapley\nvalue of an owner.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u89e3\u91ca\u6570\u636e\u8054\u76df\u4e2dShapley\u503c\u7684\u53cd\u4e8b\u5b9e\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7SV-Exp\u7b97\u6cd5\u9ad8\u6548\u5b9e\u73b0\u3002", "motivation": "Shapley\u503c\u5728\u6570\u636e\u5e02\u573a\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5982\u4f55\u89e3\u91ca\u6570\u636e\u6240\u6709\u8005\u5728\u8054\u76df\u4e2d\u7684Shapley\u503c\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u6311\u6218\u3002", "method": "\u901a\u8fc7\u53cd\u4e8b\u5b9e\u89e3\u91ca\u95ee\u9898\uff0c\u63d0\u51faSV-Exp\u7b97\u6cd5\uff0c\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u548c\u542f\u53d1\u5f0f\u6280\u672f\uff08\u5982\u5dee\u5206Shapley\u503c\u4f30\u8ba1\u548c\u8d2a\u5fc3\u5b50\u96c6\u8f6c\u79fb\uff09\u52a0\u901f\u8ba1\u7b97\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eSV-Exp\u7b97\u6cd5\u9ad8\u6548\uff0c\u53cd\u4e8b\u5b9e\u89e3\u91ca\u80fd\u6709\u6548\u89e3\u8bfbShapley\u503c\u3002", "conclusion": "\u53cd\u4e8b\u5b9e\u89e3\u91ca\u662f\u53ef\u884c\u7684\uff0cSV-Exp\u7b97\u6cd5\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u5de5\u5177\u3002"}}
{"id": "2507.01333", "pdf": "https://arxiv.org/pdf/2507.01333", "abs": "https://arxiv.org/abs/2507.01333", "authors": ["Jiayi Lu", "Wanting Yang", "Zehui Xiong", "Rahim Tafazolli", "Tony Q. S. Quek", "M\u00e9rouane Debbah", "Dong In Kim"], "title": "Multi-User Generative Semantic Communication with Intent-Aware Semantic-Splitting Multiple Access", "categories": ["cs.NI", "cs.IT", "math.IT"], "comment": null, "summary": "With the booming development of generative artificial intelligence (GAI),\nsemantic communication (SemCom) has emerged as a new paradigm for reliable and\nefficient communication. This paper considers a multi-user downlink SemCom\nsystem, using vehicular networks as the representative scenario for multi-user\ncontent dissemination. To address diverse yet overlapping user demands, we\npropose a multi-user Generative SemCom-enhanced intent-aware semantic-splitting\nmultiple access (SS-MGSC) framework. In the framework, we construct an\nintent-aware shared knowledge base (SKB) that incorporates prior knowledge of\nsemantic information (SI) and user-specific preferences. Then, we designate the\ncommon SI as a one-hot semantic map that is broadcast to all users, while the\nprivate SI is delivered as personalized text for each user. On the receiver\nside, a diffusion model enhanced with ControlNet is adopted to generate\nhigh-quality personalized images. To capture both semantic relevance and\nperceptual similarity, we design a novel semantic efficiency score (SES) metric\nas the optimization objective. Building on this, we formulate a joint\noptimization problem for multi-user semantic extraction and beamforming, solved\nusing a reinforcement learning-based algorithm due to its robustness in\nhigh-dimensional settings. Simulation results demonstrate the effectiveness of\nthe proposed scheme.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u7528\u6237\u751f\u6210\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff08SS-MGSC\uff09\uff0c\u7528\u4e8e\u8f66\u8f86\u7f51\u7edc\u4e2d\u7684\u5185\u5bb9\u5206\u53d1\uff0c\u901a\u8fc7\u5171\u4eab\u77e5\u8bc6\u5e93\u548c\u4e2a\u6027\u5316\u8bed\u4e49\u4fe1\u606f\u4f20\u8f93\uff0c\u7ed3\u5408\u6269\u6563\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u56fe\u50cf\uff0c\u5e76\u8bbe\u8ba1\u4e86\u65b0\u7684\u8bed\u4e49\u6548\u7387\u8bc4\u5206\uff08SES\uff09\u4f5c\u4e3a\u4f18\u5316\u76ee\u6807\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u8bed\u4e49\u901a\u4fe1\uff08SemCom\uff09\u6210\u4e3a\u53ef\u9760\u9ad8\u6548\u901a\u4fe1\u7684\u65b0\u8303\u5f0f\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u591a\u7528\u6237\u5185\u5bb9\u5206\u53d1\u4e2d\u9700\u6c42\u591a\u6837\u4e14\u91cd\u53e0\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faSS-MGSC\u6846\u67b6\uff0c\u6784\u5efa\u610f\u56fe\u611f\u77e5\u5171\u4eab\u77e5\u8bc6\u5e93\uff08SKB\uff09\uff0c\u5e7f\u64ad\u516c\u5171\u8bed\u4e49\u4fe1\u606f\u5e76\u4f20\u8f93\u4e2a\u6027\u5316\u8bed\u4e49\u4fe1\u606f\u3002\u63a5\u6536\u7aef\u91c7\u7528ControlNet\u589e\u5f3a\u7684\u6269\u6563\u6a21\u578b\u751f\u6210\u56fe\u50cf\uff0c\u8bbe\u8ba1SES\u4f5c\u4e3a\u4f18\u5316\u76ee\u6807\uff0c\u5e76\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u89e3\u51b3\u8054\u5408\u4f18\u5316\u95ee\u9898\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6848\u5728\u591a\u7528\u6237\u8bed\u4e49\u63d0\u53d6\u548c\u6ce2\u675f\u6210\u5f62\u4e2d\u5177\u6709\u6709\u6548\u6027\u3002", "conclusion": "SS-MGSC\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u8bed\u4e49\u901a\u4fe1\u548c\u751f\u6210\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u7528\u6237\u5185\u5bb9\u5206\u53d1\u7684\u6548\u7387\u548c\u4e2a\u6027\u5316\u4f53\u9a8c\u3002"}}
{"id": "2507.01225", "pdf": "https://arxiv.org/pdf/2507.01225", "abs": "https://arxiv.org/abs/2507.01225", "authors": ["Sunandita Patra", "Mehtab Pathan", "Mahmoud Mahfouz", "Parisa Zehtabi", "Wided Ouaja", "Daniele Magazzeni", "Manuela Veloso"], "title": "Capacity Planning and Scheduling for Jobs with Uncertainty in Resource Usage and Duration", "categories": ["cs.DC", "cs.AI"], "comment": "Please cite as: Sunandita Patra, Mehtab Pathan, Mahmoud Mahfouz,\n  Parisa Zehtabi, Wided Ouaja, Daniele Magazzeni, and Manuela Veloso. \"Capacity\n  planning and scheduling for jobs with uncertainty in resource usage and\n  duration.\" The Journal of Supercomputing 80, no. 15 (2024): 22428-22461", "summary": "Organizations around the world schedule jobs (programs) regularly to perform\nvarious tasks dictated by their end users. With the major movement towards\nusing a cloud computing infrastructure, our organization follows a hybrid\napproach with both cloud and on-prem servers. The objective of this work is to\nperform capacity planning, i.e., estimate resource requirements, and job\nscheduling for on-prem grid computing environments. A key contribution of our\napproach is handling uncertainty in both resource usage and duration of the\njobs, a critical aspect in the finance industry where stochastic market\nconditions significantly influence job characteristics. For capacity planning\nand scheduling, we simultaneously balance two conflicting objectives: (a)\nminimize resource usage, and (b) provide high quality-of-service to the end\nusers by completing jobs by their requested deadlines. We propose approximate\napproaches using deterministic estimators and pair sampling-based constraint\nprogramming. Our best approach (pair sampling-based) achieves much lower peak\nresource usage compared to manual scheduling without compromising on the\nquality-of-service.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u4e91\u548c\u672c\u5730\u670d\u52a1\u5668\u7684\u8d44\u6e90\u89c4\u5212\u4e0e\u4efb\u52a1\u8c03\u5ea6\u65b9\u6cd5\uff0c\u91cd\u70b9\u89e3\u51b3\u91d1\u878d\u884c\u4e1a\u4e2d\u4efb\u52a1\u8d44\u6e90\u4f7f\u7528\u548c\u6301\u7eed\u65f6\u95f4\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u968f\u7740\u4e91\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u7684\u666e\u53ca\uff0c\u7ec4\u7ec7\u9700\u8981\u540c\u65f6\u7ba1\u7406\u4e91\u548c\u672c\u5730\u670d\u52a1\u5668\u7684\u8d44\u6e90\u3002\u91d1\u878d\u884c\u4e1a\u7684\u4efb\u52a1\u7279\u6027\u53d7\u5e02\u573a\u6761\u4ef6\u5f71\u54cd\u5927\uff0c\u8d44\u6e90\u9700\u6c42\u548c\u4efb\u52a1\u65f6\u957f\u5177\u6709\u4e0d\u786e\u5b9a\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u5bb9\u91cf\u89c4\u5212\u548c\u8c03\u5ea6\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u786e\u5b9a\u6027\u4f30\u8ba1\u5668\u548c\u57fa\u4e8e\u914d\u5bf9\u91c7\u6837\u7684\u7ea6\u675f\u7f16\u7a0b\u65b9\u6cd5\uff0c\u5e73\u8861\u8d44\u6e90\u4f7f\u7528\u6700\u5c0f\u5316\u548c\u670d\u52a1\u8d28\u91cf\uff08\u6309\u65f6\u5b8c\u6210\u4efb\u52a1\uff09\u4e24\u4e2a\u51b2\u7a81\u76ee\u6807\u3002", "result": "\u57fa\u4e8e\u914d\u5bf9\u91c7\u6837\u7684\u65b9\u6cd5\u5728\u964d\u4f4e\u5cf0\u503c\u8d44\u6e90\u4f7f\u7528\u7684\u540c\u65f6\uff0c\u672a\u5f71\u54cd\u670d\u52a1\u8d28\u91cf\uff0c\u4f18\u4e8e\u4eba\u5de5\u8c03\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u91d1\u878d\u884c\u4e1a\u7b49\u4e0d\u786e\u5b9a\u6027\u9ad8\u7684\u73af\u5883\u4e2d\uff0c\u80fd\u6709\u6548\u5b9e\u73b0\u8d44\u6e90\u4f18\u5316\u548c\u670d\u52a1\u8d28\u91cf\u4fdd\u969c\u3002"}}
{"id": "2507.01315", "pdf": "https://arxiv.org/pdf/2507.01315", "abs": "https://arxiv.org/abs/2507.01315", "authors": ["Taiming Wang", "Yanjie Jiang", "Chunhao Dong", "Yuxia Zhang", "Hui Liu"], "title": "Context-Aware Code Wiring Recommendation with LLM-based Agent", "categories": ["cs.SE"], "comment": null, "summary": "Copy-paste-modify is a widespread and pragmatic practice in software\ndevelopment, where developers adapt reused code snippets, sourced from\nplatforms such as Stack Overflow, GitHub, or LLM outputs, into their local\ncodebase. A critical yet underexplored aspect of this adaptation is code\nwiring, which involves substituting unresolved variables in the pasted code\nwith suitable ones from the surrounding context. Existing solutions either rely\non heuristic rules or historical templates, often failing to effectively\nutilize contextual information, despite studies showing that over half of\nadaptation cases are context-dependent. In this paper, we introduce WIRL, an\nLLM-based agent for code wiring framed as a Retrieval-Augmented Generation\n(RAG) infilling task. WIRL combines an LLM, a customized toolkit, and an\norchestration module to identify unresolved variables, retrieve context, and\nperform context-aware substitutions. To balance efficiency and autonomy, the\nagent adopts a mixed strategy: deterministic rule-based steps for common\npatterns, and a state-machine-guided decision process for intelligent\nexploration. We evaluate WIRL on a carefully curated, high-quality dataset\nconsisting of real-world code adaptation scenarios. Our approach achieves an\nexact match precision of 91.7% and a recall of 90.0%, outperforming advanced\nLLMs by 22.6 and 13.7 percentage points in precision and recall, respectively,\nand surpassing IntelliJ IDEA by 54.3 and 49.9 percentage points. These results\nunderscore its practical utility, particularly in contexts with complex\nvariable dependencies or multiple unresolved variables. We believe WIRL paves\nthe way for more intelligent and context-aware developer assistance in modern\nIDEs.", "AI": {"tldr": "WIRL\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u63a5\u7ebf\u4ee3\u7406\uff0c\u901a\u8fc7\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\uff0c\u6709\u6548\u89e3\u51b3\u4ee3\u7801\u7c98\u8d34\u4e2d\u7684\u53d8\u91cf\u66ff\u6362\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4ee3\u7801\u7c98\u8d34\u4fee\u6539\u662f\u5e38\u89c1\u5b9e\u8df5\uff0c\u4f46\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u672a\u80fd\u5145\u5206\u5229\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5bfc\u81f4\u53d8\u91cf\u66ff\u6362\u6548\u679c\u4e0d\u4f73\u3002", "method": "WIRL\u7ed3\u5408LLM\u3001\u5b9a\u5236\u5de5\u5177\u548c\u534f\u8c03\u6a21\u5757\uff0c\u91c7\u7528\u6df7\u5408\u7b56\u7565\uff08\u89c4\u5219\u6b65\u9aa4\u548c\u72b6\u6001\u673a\u51b3\u7b56\uff09\u8fdb\u884c\u667a\u80fd\u53d8\u91cf\u66ff\u6362\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cWIRL\u7684\u7cbe\u786e\u5339\u914d\u7cbe\u5ea6\u8fbe91.7%\uff0c\u53ec\u56de\u738790.0%\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "WIRL\u4e3a\u73b0\u4ee3IDE\u63d0\u4f9b\u4e86\u66f4\u667a\u80fd\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5f00\u53d1\u8f85\u52a9\u5de5\u5177\uff0c\u5177\u6709\u5e7f\u6cdb\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.01830", "pdf": "https://arxiv.org/pdf/2507.01830", "abs": "https://arxiv.org/abs/2507.01830", "authors": ["Mina Dalirrooyfard", "Konstantin Makarychev", "Slobodan Mitrovi\u0107"], "title": "SPARSE-PIVOT: Dynamic correlation clustering for node insertions", "categories": ["cs.DS"], "comment": "ICML 2025", "summary": "We present a new Correlation Clustering algorithm for a dynamic setting where\nnodes are added one at a time. In this model, proposed by Cohen-Addad,\nLattanzi, Maggiori, and Parotsidis (ICML 2024), the algorithm uses database\nqueries to access the input graph and updates the clustering as each new node\nis added. Our algorithm has the amortized update time of\n$O_{\\epsilon}(\\log^{O(1)}(n))$. Its approximation factor is $20+\\varepsilon$,\nwhich is a substantial improvement over the approximation factor of the\nalgorithm by Cohen-Addad et al. We complement our theoretical findings by\nempirically evaluating the approximation guarantee of our algorithm. The\nresults show that it outperforms the algorithm by Cohen-Addad et al.~in\npractice.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u76f8\u5173\u6027\u805a\u7c7b\u7b97\u6cd5\uff0c\u6539\u8fdb\u73b0\u6709\u65b9\u6cd5\u7684\u8fd1\u4f3c\u56e0\u5b50\uff0c\u5e76\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u89e3\u51b3\u52a8\u6001\u56fe\u4e2d\u8282\u70b9\u9010\u6b65\u6dfb\u52a0\u65f6\u7684\u805a\u7c7b\u95ee\u9898\uff0c\u63d0\u5347\u7b97\u6cd5\u6548\u7387\u548c\u8fd1\u4f3c\u7cbe\u5ea6\u3002", "method": "\u4f7f\u7528\u6570\u636e\u5e93\u67e5\u8be2\u8bbf\u95ee\u8f93\u5165\u56fe\uff0c\u9010\u6b65\u66f4\u65b0\u805a\u7c7b\uff0c\u5b9e\u73b0\u4f4e\u644a\u9500\u66f4\u65b0\u65f6\u95f4\u548c\u9ad8\u8fd1\u4f3c\u56e0\u5b50\u3002", "result": "\u7b97\u6cd5\u644a\u9500\u66f4\u65b0\u65f6\u95f4\u4e3a$O_{\\epsilon}(\\log^{O(1)}(n))$\uff0c\u8fd1\u4f3c\u56e0\u5b50\u4e3a$20+\\varepsilon$\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u76f8\u5173\u6027\u805a\u7c7b\u95ee\u9898\u3002"}}
{"id": "2507.01028", "pdf": "https://arxiv.org/pdf/2507.01028", "abs": "https://arxiv.org/abs/2507.01028", "authors": ["Jean Ponce", "Martial Hebert", "Basile Terver"], "title": "Dual Perspectives on Non-Contrastive Self-Supervised Learning", "categories": ["cs.LG"], "comment": null, "summary": "The objective of non-contrastive approaches to self-supervised learning is to\ntrain on pairs of different views of the data an encoder and a predictor that\nminimize the mean discrepancy between the code predicted from the embedding of\nthe first view and the embedding of the second one. In this setting, the stop\ngradient and exponential moving average iterative procedures are commonly used\nto avoid representation collapse, with excellent performance in downstream\nsupervised applications. This presentation investigates these procedures from\nthe dual theoretical viewpoints of optimization and dynamical systems. We first\nshow that, in general, although they do not optimize the original objective, or\nfor that matter, any other smooth function, they do avoid collapse. Following\nTian et al. [2021], but without any of the extra assumptions used in their\nproofs, we then show using a dynamical system perspective that, in the linear\ncase, minimizing the original objective function without the use of a stop\ngradient or exponential moving average always leads to collapse. Conversely, we\nfinally show that the limit points of the dynamical systems associated with\nthese two procedures are, in general, asymptotically stable equilibria, with no\nrisk of degenerating to trivial solutions.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u81ea\u76d1\u7763\u5b66\u4e60\u4e2d\u975e\u5bf9\u6bd4\u65b9\u6cd5\u7684\u4f18\u5316\u548c\u52a8\u6001\u7cfb\u7edf\u89c6\u89d2\uff0c\u8bc1\u660e\u505c\u6b62\u68af\u5ea6\u548c\u6307\u6570\u79fb\u52a8\u5e73\u5747\u80fd\u907f\u514d\u8868\u793a\u5d29\u6e83\uff0c\u5e76\u5728\u7406\u8bba\u4e0a\u9a8c\u8bc1\u5176\u7a33\u5b9a\u6027\u3002", "motivation": "\u63a2\u8ba8\u81ea\u76d1\u7763\u5b66\u4e60\u4e2d\u975e\u5bf9\u6bd4\u65b9\u6cd5\u7684\u4f18\u5316\u548c\u52a8\u6001\u7cfb\u7edf\u884c\u4e3a\uff0c\u907f\u514d\u8868\u793a\u5d29\u6e83\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u4ece\u4f18\u5316\u548c\u52a8\u6001\u7cfb\u7edf\u7406\u8bba\u89d2\u5ea6\u5206\u6790\u505c\u6b62\u68af\u5ea6\u548c\u6307\u6570\u79fb\u52a8\u5e73\u5747\u7684\u4f5c\u7528\uff0c\u9a8c\u8bc1\u5176\u5728\u907f\u514d\u5d29\u6e83\u4e2d\u7684\u6709\u6548\u6027\u3002", "result": "\u8bc1\u660e\u8fd9\u4e9b\u65b9\u6cd5\u867d\u4e0d\u4f18\u5316\u539f\u59cb\u76ee\u6807\u51fd\u6570\uff0c\u4f46\u80fd\u907f\u514d\u5d29\u6e83\uff0c\u5e76\u5728\u7ebf\u6027\u60c5\u51b5\u4e0b\u9a8c\u8bc1\u5176\u7a33\u5b9a\u6027\u3002", "conclusion": "\u505c\u6b62\u68af\u5ea6\u548c\u6307\u6570\u79fb\u52a8\u5e73\u5747\u662f\u907f\u514d\u8868\u793a\u5d29\u6e83\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4e14\u5176\u6781\u9650\u70b9\u662f\u7a33\u5b9a\u7684\u5e73\u8861\u70b9\u3002"}}
{"id": "2507.01520", "pdf": "https://arxiv.org/pdf/2507.01520", "abs": "https://arxiv.org/abs/2507.01520", "authors": ["Yiran Zheng", "Yue Quan", "Su Yan", "Xinting Lv", "Yuguanmin Cao", "Minjie Fu", "Mingji Jin"], "title": "A bibliometric analysis on the current situation and hot trends of the impact of microplastics on soil based on CiteSpace", "categories": ["cs.DL", "cs.DB"], "comment": null, "summary": "This paper aims to comprehensively grasp the research status and development\ntrends of soil microplastics (MPs). It collects studies from the Web of Science\nCore Collection covering the period from 2013 to 2024. Employing CiteSpace and\nVOSviewer, the paper conducts in - depth analyses of literature regarding the\nenvironmental impacts of microplastics. These analyses involve keyword co -\noccurrence, clustering, burst term identification, as well as co - occurrence\nanalysis of authors and institutions. Microplastics can accumulate in soil,\ntransfer through food chains, and ultimately affect human health, making the\nresearch on them essential for effective pollution control. Focusing on the\ninternational research on the impacts of microplastics on soil and ecosystems,\nthe study reveals a steadily increasing trend in the number of publications\neach year, reaching a peak of 956 articles in 2024. A small number of highly\nproductive authors contribute significantly to the overall research output. The\nkeyword clustering analysis results in ten major clusters, including topics\nsuch as plastic pollution and microbial communities. The research on soil\nmicroplastics has evolved through three distinct stages: the preliminary\nexploration phase from 2013 to 2016, the expansion phase from 2017 to 2020, and\nthe integration phase from 2021 to 2024. For future research, multi - level\nassessments of the impacts of microplastics on soil ecosystems and organisms\nshould be emphasized, in order to fully uncover the associated hazards and\ndevelop practical solutions.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e862013-2024\u5e74\u571f\u58e4\u5fae\u5851\u6599\uff08MPs\uff09\u7684\u7814\u7a76\u73b0\u72b6\u4e0e\u53d1\u5c55\u8d8b\u52bf\uff0c\u901a\u8fc7\u6587\u732e\u8ba1\u91cf\u5206\u6790\u63ed\u793a\u4e86\u7814\u7a76\u70ed\u70b9\u3001\u9ad8\u4ea7\u4f5c\u8005\u53ca\u673a\u6784\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5fae\u5851\u6599\u5728\u571f\u58e4\u4e2d\u7684\u79ef\u7d2f\u53ca\u5176\u5bf9\u751f\u6001\u7cfb\u7edf\u548c\u4eba\u7c7b\u5065\u5eb7\u7684\u6f5c\u5728\u5f71\u54cd\uff0c\u4fc3\u4f7f\u7814\u7a76\u5176\u6c61\u67d3\u63a7\u5236\u7684\u91cd\u8981\u6027\u3002", "method": "\u5229\u7528CiteSpace\u548cVOSviewer\u5bf9Web of Science\u6587\u732e\u8fdb\u884c\u5173\u952e\u8bcd\u5171\u73b0\u3001\u805a\u7c7b\u3001\u7a81\u73b0\u8bcd\u5206\u6790\u53ca\u4f5c\u8005\u673a\u6784\u5171\u73b0\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6587\u732e\u6570\u91cf\u9010\u5e74\u589e\u957f\uff0c2024\u5e74\u8fbe956\u7bc7\uff1b\u9ad8\u4ea7\u4f5c\u8005\u8d21\u732e\u663e\u8457\uff1b\u5173\u952e\u8bcd\u805a\u7c7b\u5f62\u621010\u5927\u4e3b\u9898\uff1b\u7814\u7a76\u5206\u4e3a\u63a2\u7d22\u3001\u6269\u5c55\u548c\u6574\u5408\u4e09\u9636\u6bb5\u3002", "conclusion": "\u672a\u6765\u9700\u591a\u5c42\u9762\u8bc4\u4f30\u5fae\u5851\u6599\u5bf9\u571f\u58e4\u751f\u6001\u7684\u5f71\u54cd\uff0c\u4ee5\u63ed\u793a\u5371\u5bb3\u5e76\u5236\u5b9a\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01360", "pdf": "https://arxiv.org/pdf/2507.01360", "abs": "https://arxiv.org/abs/2507.01360", "authors": ["Yijie Li", "Weichong Ling", "Taiting Lu", "Yi-Chao Chen", "Vaishnavi Ranganathan", "Lili Qiu", "Jingxian Wang"], "title": "MmBack: Clock-free Multi-Sensor Backscatter with Synchronous Acquisition and Multiplexing", "categories": ["cs.NI", "eess.SP"], "comment": "16 pages, 14 figures", "summary": "Backscatter tags provide a low-power solution for sensor applications, yet\nmany real-world scenarios require multiple sensors-often of different types-for\ncomplex sensing tasks. However, existing designs support only a single sensor\nper tag, increasing spatial overhead. State-of-the-art approaches to\nmultiplexing multiple sensor streams on a single tag rely on onboard clocks or\nmultiple modulation chains, which add cost, enlarge form factor, and remain\nprone to timing drift-disrupting synchronization across sensors.\n  We present mmBack, a low-power, clock-free backscatter tag that enables\nsynchronous multi-sensor data acquisition and multiplexing over a single\nmodulation chain. mmBack synchronizes sensor inputs in parallel using a shared\nreference signal extracted from ambient RF excitation, eliminating the need for\nan onboard timing source. To efficiently multiplex sensor data, mmBack designs\na voltage-division scheme to multiplex multiple sensor inputs as backscatter\nfrequency shifts through a single oscillator and RF switch. At the receiver,\nmmBack develops a frequency tracking algorithm and a finite-state machine for\naccurate demultiplexing. mmBack's ASIC design consumes 25.56uW, while its\nprototype supports 5 concurrent sensor streams with bandwidths of up to 5kHz\nand 3 concurrent sensor streams with bandwidth of up to 18kHz. Evaluation shows\nthat mmBack achieves an average SNR surpassing 15dB in signal reconstruction.", "AI": {"tldr": "mmBack\u662f\u4e00\u79cd\u4f4e\u529f\u8017\u3001\u65e0\u65f6\u949f\u7684\u53cd\u5411\u6563\u5c04\u6807\u7b7e\uff0c\u901a\u8fc7\u5171\u4eab\u53c2\u8003\u4fe1\u53f7\u5b9e\u73b0\u591a\u4f20\u611f\u5668\u540c\u6b65\u6570\u636e\u91c7\u96c6\u548c\u590d\u7528\uff0c\u65e0\u9700\u677f\u8f7d\u65f6\u949f\u3002", "motivation": "\u73b0\u6709\u53cd\u5411\u6563\u5c04\u6807\u7b7e\u8bbe\u8ba1\u4ec5\u652f\u6301\u5355\u4e2a\u4f20\u611f\u5668\uff0c\u589e\u52a0\u4e86\u7a7a\u95f4\u5f00\u9500\uff1b\u800c\u591a\u4f20\u611f\u5668\u590d\u7528\u65b9\u6cd5\u4f9d\u8d56\u677f\u8f7d\u65f6\u949f\u6216\u591a\u8c03\u5236\u94fe\uff0c\u589e\u52a0\u4e86\u6210\u672c\u548c\u4f53\u79ef\uff0c\u4e14\u6613\u53d7\u65f6\u95f4\u6f02\u79fb\u5f71\u54cd\u3002", "method": "mmBack\u5229\u7528\u73af\u5883\u5c04\u9891\u6fc0\u52b1\u63d0\u53d6\u5171\u4eab\u53c2\u8003\u4fe1\u53f7\u540c\u6b65\u4f20\u611f\u5668\u8f93\u5165\uff0c\u5e76\u901a\u8fc7\u7535\u538b\u5206\u914d\u65b9\u6848\u5c06\u591a\u4f20\u611f\u5668\u8f93\u5165\u590d\u7528\u5230\u5355\u4e00\u8c03\u5236\u94fe\u4e2d\u3002\u63a5\u6536\u7aef\u91c7\u7528\u9891\u7387\u8ddf\u8e2a\u7b97\u6cd5\u548c\u6709\u9650\u72b6\u6001\u673a\u8fdb\u884c\u89e3\u590d\u7528\u3002", "result": "mmBack\u7684ASIC\u8bbe\u8ba1\u529f\u8017\u4e3a25.56uW\uff0c\u539f\u578b\u652f\u63015\u4e2a5kHz\u5e26\u5bbd\u62163\u4e2a18kHz\u5e26\u5bbd\u7684\u5e76\u53d1\u4f20\u611f\u5668\u6d41\uff0c\u4fe1\u53f7\u91cd\u6784\u5e73\u5747SNR\u8d85\u8fc715dB\u3002", "conclusion": "mmBack\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u4f4e\u529f\u8017\u7684\u591a\u4f20\u611f\u5668\u540c\u6b65\u6570\u636e\u91c7\u96c6\u548c\u590d\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2507.01298", "pdf": "https://arxiv.org/pdf/2507.01298", "abs": "https://arxiv.org/abs/2507.01298", "authors": ["Debasish Pattanayak", "Ajay D. Kshemkalyani", "Manish Kumar", "Anisur Rahaman Molla", "Gokarna Sharma"], "title": "Optimal Dispersion Under Asynchrony", "categories": ["cs.DC", "cs.DS", "cs.MA", "cs.RO"], "comment": "35 pages, 5 figures, 2 tables, and 6 pseudocodes", "summary": "We study the dispersion problem in anonymous port-labeled graphs: $k \\leq n$\nmobile agents, each with a unique ID and initially located arbitrarily on the\nnodes of an $n$-node graph with maximum degree $\\Delta$, must autonomously\nrelocate so that no node hosts more than one agent. Dispersion serves as a\nfundamental task in distributed computing of mobile agents, and its complexity\nstems from key challenges in local coordination under anonymity and limited\nmemory.\n  The goal is to minimize both the time to achieve dispersion and the memory\nrequired per agent. It is known that any algorithm requires $\\Omega(k)$ time in\nthe worst case, and $\\Omega(\\log k)$ bits of memory per agent. A recent result\n[SPAA'25] gives an optimal $O(k)$-time algorithm in the synchronous setting and\nan $O(k \\log k)$-time algorithm in the asynchronous setting, both using\n$O(\\log(k+\\Delta))$ bits.\n  In this paper, we close the complexity gap in the asynchronous setting by\npresenting the first dispersion algorithm that runs in optimal $O(k)$ time\nusing $O(\\log(k+\\Delta))$ bits of memory per agent. Our solution is based on a\nnovel technique we develop in this paper that constructs a port-one tree in\nanonymous graphs, which may be of independent interest.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5f02\u6b65\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u6700\u4f18\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u5206\u6563\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u533f\u540d\u7aef\u53e3\u6807\u8bb0\u56fe\u4e2d\u7684\u5206\u6563\u95ee\u9898\u3002", "motivation": "\u5206\u6563\u95ee\u9898\u662f\u79fb\u52a8\u4ee3\u7406\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u57fa\u7840\u4efb\u52a1\uff0c\u5176\u590d\u6742\u6027\u6e90\u4e8e\u533f\u540d\u6027\u548c\u6709\u9650\u5185\u5b58\u4e0b\u7684\u672c\u5730\u534f\u8c03\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u4e00\u79cd\u65b0\u9896\u7684\u6280\u672f\uff0c\u6784\u5efa\u533f\u540d\u56fe\u4e2d\u7684\u7aef\u53e3\u4e00\u6811\uff0c\u4ee5\u5b9e\u73b0\u6700\u4f18\u65f6\u95f4\u548c\u5185\u5b58\u590d\u6742\u5ea6\u3002", "result": "\u63d0\u51fa\u4e86\u9996\u4e2a\u5728\u5f02\u6b65\u8bbe\u7f6e\u4e0b\u8fd0\u884c\u65f6\u95f4\u4e3aO(k)\u3001\u5185\u5b58\u4e3aO(log(k+\u0394))\u7684\u5206\u6563\u7b97\u6cd5\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u586b\u8865\u4e86\u5f02\u6b65\u8bbe\u7f6e\u4e0b\u7684\u590d\u6742\u5ea6\u7a7a\u767d\uff0c\u4e14\u5176\u6280\u672f\u53ef\u80fd\u5177\u6709\u72ec\u7acb\u7684\u7814\u7a76\u4ef7\u503c\u3002"}}
{"id": "2507.01477", "pdf": "https://arxiv.org/pdf/2507.01477", "abs": "https://arxiv.org/abs/2507.01477", "authors": ["Lukas Krodinger", "Stephan Lukasczyk", "Gordon Fraser"], "title": "Combining Type Inference and Automated Unit Test Generation for Python", "categories": ["cs.SE"], "comment": null, "summary": "Automated unit test generation is an established research field that has so\nfar focused on statically-typed programming languages. The lack of type\ninformation in dynamically-typed programming languages, such as Python,\ninhibits test generators, which heavily rely on information about parameter and\nreturn types of functions to select suitable arguments when constructing test\ncases. Since automated test generators inherently rely on frequent execution of\ncandidate tests, we make use of these frequent executions to address this\nproblem by introducing type tracing, which extracts type-related information\nduring execution and gradually refines the available type information. We\nimplement type tracing as an extension of the Pynguin test-generation framework\nfor Python, allowing it (i) to infer parameter types by observing how\nparameters are used during runtime, (ii) to record the types of values that\nfunction calls return, and (iii) to use this type information to increase code\ncoverage. The approach leads to up to 90.0% more branch coverage, improved\nmutation scores, and to type information of similar quality to that produced by\nother state-of-the-art type-inference tools.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u8fd0\u884c\u65f6\u7c7b\u578b\u8ffd\u8e2a\uff08type tracing\uff09\u89e3\u51b3\u52a8\u6001\u7c7b\u578b\u8bed\u8a00\uff08\u5982Python\uff09\u4e2d\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u95ee\u9898\u7684\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u8986\u76d6\u7387\u548c\u6d4b\u8bd5\u8d28\u91cf\u3002", "motivation": "\u52a8\u6001\u7c7b\u578b\u8bed\u8a00\u7f3a\u4e4f\u9759\u6001\u7c7b\u578b\u4fe1\u606f\uff0c\u963b\u788d\u4e86\u4f20\u7edf\u6d4b\u8bd5\u751f\u6210\u5668\u7684\u6548\u679c\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u8fd0\u884c\u65f6\u7c7b\u578b\u4fe1\u606f\u63d0\u53d6\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5728Pynguin\u6d4b\u8bd5\u751f\u6210\u6846\u67b6\u4e2d\u5f15\u5165\u7c7b\u578b\u8ffd\u8e2a\u6280\u672f\uff0c\u901a\u8fc7\u8fd0\u884c\u65f6\u89c2\u5bdf\u53c2\u6570\u4f7f\u7528\u548c\u8fd4\u56de\u503c\u7c7b\u578b\uff0c\u9010\u6b65\u4f18\u5316\u7c7b\u578b\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u4f7f\u5206\u652f\u8986\u76d6\u7387\u63d0\u5347\u9ad8\u8fbe90.0%\uff0c\u7a81\u53d8\u5206\u6570\u63d0\u9ad8\uff0c\u4e14\u7c7b\u578b\u4fe1\u606f\u8d28\u91cf\u4e0e\u5148\u8fdb\u7c7b\u578b\u63a8\u65ad\u5de5\u5177\u76f8\u5f53\u3002", "conclusion": "\u7c7b\u578b\u8ffd\u8e2a\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u7c7b\u578b\u8bed\u8a00\u6d4b\u8bd5\u751f\u6210\u7684\u7c7b\u578b\u4fe1\u606f\u7f3a\u5931\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u6548\u679c\u3002"}}
{"id": "2507.01873", "pdf": "https://arxiv.org/pdf/2507.01873", "abs": "https://arxiv.org/abs/2507.01873", "authors": ["Anders Aamand", "Justin Y. Chen", "Mina Dalirrooyfard", "Slobodan Mitrovi\u0107", "Yuriy Nevmyvaka", "Sandeep Silwal", "Yinzhan Xu"], "title": "Breaking the $n^{1.5}$ Additive Error Barrier for Private and Efficient Graph Sparsification via Private Expander Decomposition", "categories": ["cs.DS"], "comment": "ICML 2025", "summary": "We study differentially private algorithms for graph cut sparsification, a\nfundamental problem in algorithms, privacy, and machine learning. While\nsignificant progress has been made, the best-known private and efficient cut\nsparsifiers on $n$-node graphs approximate each cut within\n$\\widetilde{O}(n^{1.5})$ additive error and $1+\\gamma$ multiplicative error for\nany $\\gamma > 0$ [Gupta, Roth, Ullman TCC'12]. In contrast, \"inefficient\"\nalgorithms, i.e., those requiring exponential time, can achieve an\n$\\widetilde{O}(n)$ additive error and $1+\\gamma$ multiplicative error\n[Eli{\\'a}{\\v{s}}, Kapralov, Kulkarni, Lee SODA'20]. In this work, we break the\n$n^{1.5}$ additive error barrier for private and efficient cut sparsification.\nWe present an $(\\varepsilon,\\delta)$-DP polynomial time algorithm that, given a\nnon-negative weighted graph, outputs a private synthetic graph approximating\nall cuts with multiplicative error $1+\\gamma$ and additive error $n^{1.25 +\no(1)}$ (ignoring dependencies on $\\varepsilon, \\delta, \\gamma$).\n  At the heart of our approach lies a private algorithm for expander\ndecomposition, a popular and powerful technique in (non-private) graph\nalgorithms.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5dee\u5206\u9690\u79c1\u4e0b\u7684\u56fe\u5272\u7a00\u758f\u5316\u7b97\u6cd5\uff0c\u7a81\u7834\u4e86\u73b0\u6709\u9ad8\u6548\u7b97\u6cd5\u5728\u52a0\u6027\u8bef\u5dee\u4e0a\u7684\u9650\u5236\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bef\u5dee\u3002", "motivation": "\u56fe\u5272\u7a00\u758f\u5316\u5728\u7b97\u6cd5\u3001\u9690\u79c1\u548c\u673a\u5668\u5b66\u4e60\u4e2d\u5177\u6709\u57fa\u7840\u6027\u610f\u4e49\uff0c\u4f46\u73b0\u6709\u9ad8\u6548\u9690\u79c1\u7b97\u6cd5\u7684\u52a0\u6027\u8bef\u5dee\u8f83\u9ad8\uff0c\u9700\u8981\u7a81\u7834\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u5c55\u5206\u89e3\u7684\u5dee\u5206\u9690\u79c1\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u79c1\u6709\u5408\u6210\u56fe\uff0c\u8fd1\u4f3c\u6240\u6709\u5272\u3002", "result": "\u7b97\u6cd5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u5b9e\u73b0\u4e861+\u03b3\u7684\u4e58\u6027\u8bef\u5dee\u548cn^1.25+o(1)\u7684\u52a0\u6027\u8bef\u5dee\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u9ad8\u6548\u7b97\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u9ad8\u6548\u9690\u79c1\u56fe\u5272\u7a00\u758f\u5316\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u7a81\u7834\u4e86\u52a0\u6027\u8bef\u5dee\u7684\u74f6\u9888\u3002"}}
{"id": "2507.01029", "pdf": "https://arxiv.org/pdf/2507.01029", "abs": "https://arxiv.org/abs/2507.01029", "authors": ["Junjie Zhou", "Yingli Zuo", "Shichang Feng", "Peng Wan", "Qi Zhu", "Daoqiang Zhang", "Wei Shao"], "title": "PathCoT: Chain-of-Thought Prompting for Zero-shot Pathology Visual Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "With the development of generative artificial intelligence and instruction\ntuning techniques, multimodal large language models (MLLMs) have made\nimpressive progress on general reasoning tasks. Benefiting from the\nchain-of-thought (CoT) methodology, MLLMs can solve the visual reasoning\nproblem step-by-step. However, existing MLLMs still face significant challenges\nwhen applied to pathology visual reasoning tasks: (1) LLMs often underperforms\nbecause they lack domain-specific information, which can lead to model\nhallucinations. (2) The additional reasoning steps in CoT may introduce errors,\nleading to the divergence of answers. To address these limitations, we propose\nPathCoT, a novel zero-shot CoT prompting method which integrates the pathology\nexpert-knowledge into the reasoning process of MLLMs and incorporates\nself-evaluation to mitigate divergence of answers. Specifically, PathCoT guides\nthe MLLM with prior knowledge to perform as pathology experts, and provides\ncomprehensive analysis of the image with their domain-specific knowledge. By\nincorporating the experts' knowledge, PathCoT can obtain the answers with CoT\nreasoning. Furthermore, PathCoT incorporates a self-evaluation step that\nassesses both the results generated directly by MLLMs and those derived through\nCoT, finally determining the reliable answer. The experimental results on the\nPathMMU dataset demonstrate the effectiveness of our method on pathology visual\nunderstanding and reasoning.", "AI": {"tldr": "PathCoT\u662f\u4e00\u79cd\u65b0\u7684\u96f6\u6837\u672cCoT\u63d0\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u75c5\u7406\u5b66\u4e13\u5bb6\u77e5\u8bc6\u548c\u81ea\u8bc4\u4f30\u6b65\u9aa4\uff0c\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u75c5\u7406\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u75c5\u7406\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u56e0\u4e3a\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\u548cCoT\u63a8\u7406\u6b65\u9aa4\u53ef\u80fd\u5f15\u5165\u9519\u8bef\u3002", "method": "PathCoT\u7ed3\u5408\u75c5\u7406\u5b66\u4e13\u5bb6\u77e5\u8bc6\u6307\u5bfc\u6a21\u578b\u63a8\u7406\uff0c\u5e76\u5f15\u5165\u81ea\u8bc4\u4f30\u6b65\u9aa4\u4ee5\u51cf\u5c11\u7b54\u6848\u504f\u5dee\u3002", "result": "\u5728PathMMU\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86PathCoT\u5728\u75c5\u7406\u89c6\u89c9\u7406\u89e3\u548c\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "PathCoT\u901a\u8fc7\u6574\u5408\u4e13\u5bb6\u77e5\u8bc6\u548c\u81ea\u8bc4\u4f30\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u75c5\u7406\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2507.01616", "pdf": "https://arxiv.org/pdf/2507.01616", "abs": "https://arxiv.org/abs/2507.01616", "authors": ["Chengkun He", "Xiangmin Zhou", "Chen Wang", "Longbing Cao", "Jie Shao", "Xiaodong Li", "Guang Xu", "Carrie Jinqiu Hu", "Zahir Tari"], "title": "Enhanced Influence-aware Group Recommendation for Online Media Propagation", "categories": ["cs.IR", "cs.AI", "cs.DB"], "comment": null, "summary": "Group recommendation over social media streams has attracted significant\nattention due to its wide applications in domains such as e-commerce,\nentertainment, and online news broadcasting. By leveraging social connections\nand group behaviours, group recommendation (GR) aims to provide more accurate\nand engaging content to a set of users rather than individuals. Recently,\ninfluence-aware GR has emerged as a promising direction, as it considers the\nimpact of social influence on group decision-making. In earlier work, we\nproposed Influence-aware Group Recommendation (IGR) to solve this task.\nHowever, this task remains challenging due to three key factors: the large and\never-growing scale of social graphs, the inherently dynamic nature of influence\npropagation within user groups, and the high computational overhead of\nreal-time group-item matching.\n  To tackle these issues, we propose an Enhanced Influence-aware Group\nRecommendation (EIGR) framework. First, we introduce a Graph Extraction-based\nSampling (GES) strategy to minimise redundancy across multiple temporal social\ngraphs and effectively capture the evolving dynamics of both groups and items.\nSecond, we design a novel DYnamic Independent Cascade (DYIC) model to predict\nhow influence propagates over time across social items and user groups.\nFinally, we develop a two-level hash-based User Group Index (UG-Index) to\nefficiently organise user groups and enable real-time recommendation\ngeneration. Extensive experiments on real-world datasets demonstrate that our\nproposed framework, EIGR, consistently outperforms state-of-the-art baselines\nin both effectiveness and efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u578b\u5f71\u54cd\u611f\u77e5\u7fa4\u7ec4\u63a8\u8350\u6846\u67b6\uff08EIGR\uff09\uff0c\u901a\u8fc7\u56fe\u63d0\u53d6\u91c7\u6837\u7b56\u7565\u3001\u52a8\u6001\u72ec\u7acb\u7ea7\u8054\u6a21\u578b\u548c\u4e24\u7ea7\u54c8\u5e0c\u7528\u6237\u7fa4\u7ec4\u7d22\u5f15\uff0c\u89e3\u51b3\u4e86\u793e\u4ea4\u56fe\u89c4\u6a21\u5927\u3001\u5f71\u54cd\u4f20\u64ad\u52a8\u6001\u53d8\u5316\u53ca\u5b9e\u65f6\u5339\u914d\u8ba1\u7b97\u5f00\u9500\u9ad8\u7684\u6311\u6218\u3002", "motivation": "\u7fa4\u7ec4\u63a8\u8350\u5728\u793e\u4ea4\u5a92\u4f53\u6d41\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u793e\u4ea4\u56fe\u89c4\u6a21\u5927\u3001\u5f71\u54cd\u4f20\u64ad\u52a8\u6001\u53d8\u5316\u548c\u5b9e\u65f6\u5339\u914d\u8ba1\u7b97\u5f00\u9500\u9ad8\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faEIGR\u6846\u67b6\uff0c\u5305\u62ec\u56fe\u63d0\u53d6\u91c7\u6837\u7b56\u7565\uff08GES\uff09\u3001\u52a8\u6001\u72ec\u7acb\u7ea7\u8054\u6a21\u578b\uff08DYIC\uff09\u548c\u4e24\u7ea7\u54c8\u5e0c\u7528\u6237\u7fa4\u7ec4\u7d22\u5f15\uff08UG-Index\uff09\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEIGR\u5728\u6548\u679c\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "EIGR\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u7fa4\u7ec4\u63a8\u8350\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u63d0\u5347\u4e86\u63a8\u8350\u6548\u679c\u548c\u6548\u7387\u3002"}}
{"id": "2507.01773", "pdf": "https://arxiv.org/pdf/2507.01773", "abs": "https://arxiv.org/abs/2507.01773", "authors": ["Bo Yang", "Ruihuai Liang", "Weixin Li", "Han Wang", "Xuelin Cao", "Zhiwen Yu", "Samson Lasaulce", "M\u00e9rouane Debbah", "Mohamed-Slim Alouini", "H. Vincent Poor", "Chau Yuen"], "title": "Frontiers of Generative AI for Network Optimization: Theories, Limits, and Visions", "categories": ["cs.NI"], "comment": null, "summary": "While interest in the application of generative AI (GenAI) in network\noptimization has surged in recent years, its rapid progress has often\novershadowed critical limitations intrinsic to generative models that remain\ninsufficiently examined in existing literature. This survey provides a\ncomprehensive review and critical analysis of GenAI in network optimization. We\nfocus on the two dominant paradigms of GenAI including generative diffusion\nmodels (GDMs) and large pre-trained models (LPTMs), and organize our discussion\naround a categorization we introduce, dividing network optimization problems\ninto two primary formulations: one-shot optimization and Markov decision\nprocess (MDP). We first trace key works, including foundational contributions\nfrom the AI community, and categorize current efforts in network optimization.\nWe also review frontier applications of GDMs and LPTMs in other networking\ntasks, providing additional context. Furthermore, we present theoretical\ngeneralization bounds for GDMs in both one-shot and MDP settings, offering\ninsights into the fundamental factors affecting model performance. Most\nimportantly, we reflect on the overestimated perception of GenAI's general\ncapabilities and caution against the all-in-one illusion it may convey. We\nhighlight critical limitations, including difficulties in constraint\nsatisfying, limited concept understanding, and the inherent probabilistic\nnature of outputs. We also propose key future directions, such as bridging the\ngap between generation and optimization. Although they are increasingly\nintegrated in implementations, they differ fundamentally in both objectives and\nunderlying mechanisms, necessitating a deeper understanding of their\ntheoretical connections. Ultimately, this survey aims to provide a structured\noverview and a deeper insight into the strengths, limitations, and potential of\nGenAI in network optimization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u751f\u6210\u5f0fAI\u5728\u7f51\u7edc\u4f18\u5316\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u6790\u4e86\u5176\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5728\u7f51\u7edc\u4f18\u5316\u4e2d\u7684\u6f5c\u529b\u4e0e\u4e0d\u8db3\uff0c\u586b\u8865\u73b0\u6709\u6587\u732e\u4e2d\u5bf9\u751f\u6210\u6a21\u578b\u5173\u952e\u9650\u5236\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5206\u7c7b\u7f51\u7edc\u4f18\u5316\u95ee\u9898\u4e3a\u4e00\u6b21\u6027\u4f18\u5316\u548c\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u56de\u987e\u4e86\u751f\u6210\u6269\u6563\u6a21\u578b\u548c\u5927\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u5e94\u7528\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u6cdb\u5316\u754c\u9650\u3002", "result": "\u63ed\u793a\u4e86\u751f\u6210\u5f0fAI\u5728\u7ea6\u675f\u6ee1\u8db3\u3001\u6982\u5ff5\u7406\u89e3\u548c\u8f93\u51fa\u6982\u7387\u6027\u7b49\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5728\u7f51\u7edc\u4f18\u5316\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u89e3\u51b3\u5176\u5c40\u9650\u6027\uff0c\u5e76\u6df1\u5165\u7406\u89e3\u751f\u6210\u4e0e\u4f18\u5316\u7684\u7406\u8bba\u8054\u7cfb\u3002"}}
{"id": "2507.01438", "pdf": "https://arxiv.org/pdf/2507.01438", "abs": "https://arxiv.org/abs/2507.01438", "authors": ["Zheyu Shen", "Yexiao He", "Ziyao Wang", "Yuning Zhang", "Guoheng Sun", "Wanghao Ye", "Ang Li"], "title": "EdgeLoRA: An Efficient Multi-Tenant LLM Serving System on Edge Devices", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have gained significant attention due to their\nversatility across a wide array of applications. Fine-tuning LLMs with\nparameter-efficient adapters, such as Low-Rank Adaptation (LoRA), enables these\nmodels to efficiently adapt to downstream tasks without extensive retraining.\nDeploying fine-tuned LLMs on multi-tenant edge devices offers substantial\nbenefits, such as reduced latency, enhanced privacy, and personalized\nresponses. However, serving LLMs efficiently on resource-constrained edge\ndevices presents critical challenges, including the complexity of adapter\nselection for different tasks and memory overhead from frequent adapter\nswapping. Moreover, given the multiple requests in multi-tenant settings,\nprocessing requests sequentially results in underutilization of computational\nresources and increased latency. This paper introduces EdgeLoRA, an efficient\nsystem for serving LLMs on edge devices in multi-tenant environments. EdgeLoRA\nincorporates three key innovations: (1) an adaptive adapter selection mechanism\nto streamline the adapter configuration process; (2) heterogeneous memory\nmanagement, leveraging intelligent adapter caching and pooling to mitigate\nmemory operation overhead; and (3) batch LoRA inference, enabling efficient\nbatch processing to significantly reduce computational latency. Comprehensive\nevaluations using the Llama3.1-8B model demonstrate that EdgeLoRA significantly\noutperforms the status quo (i.e., llama.cpp) in terms of both latency and\nthroughput. The results demonstrate that EdgeLoRA can achieve up to a 4 times\nboost in throughput. Even more impressively, it can serve several orders of\nmagnitude more adapters simultaneously. These results highlight EdgeLoRA's\npotential to transform edge deployment of LLMs in multi-tenant scenarios,\noffering a scalable and efficient solution for resource-constrained\nenvironments.", "AI": {"tldr": "EdgeLoRA\u662f\u4e00\u4e2a\u9ad8\u6548\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u591a\u79df\u6237\u73af\u5883\u4e2d\u90e8\u7f72LLMs\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9002\u914d\u5668\u9009\u62e9\u3001\u5f02\u6784\u5185\u5b58\u7ba1\u7406\u548c\u6279\u91cfLoRA\u63a8\u7406\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u9ad8\u6548\u90e8\u7f72LLMs\u7684\u6311\u6218\uff0c\u5982\u9002\u914d\u5668\u9009\u62e9\u590d\u6742\u6027\u548c\u5185\u5b58\u5f00\u9500\u95ee\u9898\u3002", "method": "\u63d0\u51faEdgeLoRA\u7cfb\u7edf\uff0c\u5305\u542b\u81ea\u9002\u5e94\u9002\u914d\u5668\u9009\u62e9\u3001\u5f02\u6784\u5185\u5b58\u7ba1\u7406\u548c\u6279\u91cfLoRA\u63a8\u7406\u4e09\u9879\u521b\u65b0\u3002", "result": "\u5728Llama3.1-8B\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0cEdgeLoRA\u5728\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\uff0c\u541e\u5410\u91cf\u63d0\u53474\u500d\uff0c\u53ef\u540c\u65f6\u670d\u52a1\u66f4\u591a\u9002\u914d\u5668\u3002", "conclusion": "EdgeLoRA\u4e3a\u591a\u79df\u6237\u8fb9\u7f18\u73af\u5883\u4e2d\u7684LLMs\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01628", "pdf": "https://arxiv.org/pdf/2507.01628", "abs": "https://arxiv.org/abs/2507.01628", "authors": ["Zilong He", "Pengfei Chen", "Hongyu Zhang", "Xiaoyun Li", "Guangba Yu", "Hongyang Chen", "Zibin Zheng"], "title": "DaiFu: In-Situ Crash Recovery for Deep Learning Systems", "categories": ["cs.SE"], "comment": null, "summary": "Deep learning (DL) systems have been widely adopted in many areas, and are\nbecoming even more popular with the emergence of large language models.\nHowever, due to the complex software stacks involved in their development and\nexecution, crashes are unavoidable and common. Crashes severely waste computing\nresources and hinder development productivity, so efficient crash recovery is\ncrucial. Existing solutions, such as checkpoint-retry, are too heavyweight for\nfast recovery from crashes caused by minor programming errors or transient\nruntime errors. Therefore, we present DaiFu, an in-situ recovery framework for\nDL systems. Through a lightweight code transformation to a given DL system,\nDaiFu augments it to intercept crashes in situ and enables dynamic and instant\nupdates to its program running context (e.g., code, configurations, and other\ndata) for agile crash recovery. Our evaluation shows that DaiFu helps reduce\nthe restore time for crash recovery, achieving a 1372x speedup compared with\nstate-of-the-art solutions. Meanwhile, the overhead of DaiFu is negligible\n(under 0.40%). We also construct a benchmark spanning 7 distinct crash\nscenarios in DL systems, and show the effectiveness of DaiFu in diverse\nsituations.", "AI": {"tldr": "DaiFu\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u5d29\u6e83\u6062\u590d\u6846\u67b6\uff0c\u901a\u8fc7\u4ee3\u7801\u8f6c\u6362\u5b9e\u73b0\u5373\u65f6\u6062\u590d\uff0c\u663e\u8457\u51cf\u5c11\u6062\u590d\u65f6\u95f4\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u5d29\u6e83\u9891\u7e41\u4e14\u6d6a\u8d39\u8d44\u6e90\uff0c\u73b0\u6709\u6062\u590d\u65b9\u6848\uff08\u5982\u68c0\u67e5\u70b9\u91cd\u8bd5\uff09\u8fc7\u4e8e\u7b28\u91cd\uff0c\u65e0\u6cd5\u9ad8\u6548\u5e94\u5bf9\u5c0f\u9519\u8bef\u6216\u77ac\u65f6\u9519\u8bef\u3002", "method": "DaiFu\u901a\u8fc7\u8f7b\u91cf\u7ea7\u4ee3\u7801\u8f6c\u6362\uff0c\u62e6\u622a\u5d29\u6e83\u5e76\u52a8\u6001\u66f4\u65b0\u8fd0\u884c\u4e0a\u4e0b\u6587\uff08\u5982\u4ee3\u7801\u3001\u914d\u7f6e\u7b49\uff09\uff0c\u5b9e\u73b0\u5373\u65f6\u6062\u590d\u3002", "result": "DaiFu\u5c06\u6062\u590d\u65f6\u95f4\u7f29\u77ed1372\u500d\uff0c\u5f00\u9500\u4f4e\u4e8e0.40%\uff0c\u5e76\u57287\u79cd\u5d29\u6e83\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "DaiFu\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5d29\u6e83\u6062\u590d\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u5f00\u53d1\u6548\u7387\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2507.01030", "pdf": "https://arxiv.org/pdf/2507.01030", "abs": "https://arxiv.org/abs/2507.01030", "authors": ["Reza Lotfi Navaei", "Mohammad Safarzadeh", "Seyed Mohammad Jafar Sobhani"], "title": "Optimizing Flamelet Generated Manifold Models: A Machine Learning Performance Study", "categories": ["cs.LG"], "comment": "It has been submitted to ASME Journal of Heat and Mass Transfer", "summary": "In chemistry tabulations and Flamelet combustion models, the Flamelet\nGenerated Manifold (FGM) is recognized for its precision and physical\nrepresentation. The practical implementation of FGM requires a significant\nallocation of memory resources. FGM libraries are developed specifically for a\nspecific fuel and subsequently utilized for all numerical problems using\nmachine learning techniques. This research aims to develop libraries of Laminar\nFGM utilizing machine learning algorithms for application in combustion\nsimulations of methane fuel. This study employs four Machine Learning\nalgorithms to regenerate Flamelet libraries, based on an understanding of data\nsources, techniques, and data-driven concepts. 1. Multi-Layer Perceptron; 2.\nRandom Forest; 3. Linear Regression; 4. Support Vector Machine. Seven libraries\nwere identified as appropriate for constructing a database for training machine\nlearning models, giving an error rate of 2.30%. The default architectures of\neach method were evaluated to determine the optimal approach, leading to the\nselection of the MLP method as the primary choice. The method was enhanced\nthrough hyperparameter tuning to improve accuracy. The quantity of hidden\nlayers and neurons significantly influences method performance. The optimal\nmodel, comprising four hidden layers with 10, 15, 20, and 25 neurons\nrespectively, achieved an accuracy of 99.81%.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528\u56db\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff08MLP\u3001\u968f\u673a\u68ee\u6797\u3001\u7ebf\u6027\u56de\u5f52\u3001SVM\uff09\u91cd\u5efa\u7532\u70f7\u71c3\u6599\u71c3\u70e7\u6a21\u62df\u4e2d\u7684FGM\u5e93\uff0c\u6700\u7ec8\u9009\u62e9MLP\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u8d85\u53c2\u6570\u8c03\u4f18\u8fbe\u523099.81%\u7684\u51c6\u786e\u7387\u3002", "motivation": "FGM\u5728\u71c3\u70e7\u6a21\u578b\u4e2d\u7cbe\u5ea6\u9ad8\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u9700\u8981\u5927\u91cf\u5185\u5b58\u8d44\u6e90\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u4f18\u5316FGM\u5e93\u7684\u6784\u5efa\u3002", "method": "\u4f7f\u7528\u56db\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff08MLP\u3001\u968f\u673a\u68ee\u6797\u3001\u7ebf\u6027\u56de\u5f52\u3001SVM\uff09\u91cd\u5efaFGM\u5e93\uff0c\u5e76\u901a\u8fc7\u8d85\u53c2\u6570\u8c03\u4f18\u4f18\u5316MLP\u6a21\u578b\u3002", "result": "MLP\u65b9\u6cd5\u8868\u73b0\u6700\u4f73\uff0c\u4f18\u5316\u540e\u7684\u6a21\u578b\uff08\u56db\u9690\u85cf\u5c42\uff0c\u795e\u7ecf\u5143\u6570\u5206\u522b\u4e3a10\u300115\u300120\u300125\uff09\u51c6\u786e\u7387\u8fbe99.81%\u3002", "conclusion": "MLP\u662f\u91cd\u5efaFGM\u5e93\u7684\u6700\u4f73\u9009\u62e9\uff0c\u8d85\u53c2\u6570\u8c03\u4f18\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u7532\u70f7\u71c3\u70e7\u6a21\u62df\u63d0\u4f9b\u9ad8\u6548\u5de5\u5177\u3002"}}
{"id": "2507.01571", "pdf": "https://arxiv.org/pdf/2507.01571", "abs": "https://arxiv.org/abs/2507.01571", "authors": ["Koen T. W. Teuwen", "Sam Baggen", "Emmanuele Zambon", "Luca Allodi"], "title": "On the Effect of Ruleset Tuning and Data Imbalance on Explainable Network Security Alert Classifications: a Case-Study on DeepCASE", "categories": ["cs.CR", "cs.LG", "cs.NI"], "comment": null, "summary": "Automation in Security Operations Centers (SOCs) plays a prominent role in\nalert classification and incident escalation. However, automated methods must\nbe robust in the presence of imbalanced input data, which can negatively affect\nperformance. Additionally, automated methods should make explainable decisions.\nIn this work, we evaluate the effect of label imbalance on the classification\nof network intrusion alerts. As our use-case we employ DeepCASE, the\nstate-of-the-art method for automated alert classification. We show that label\nimbalance impacts both classification performance and correctness of the\nclassification explanations offered by DeepCASE. We conclude tuning the\ndetection rules used in SOCs can significantly reduce imbalance and may benefit\nthe performance and explainability offered by alert post-processing methods\nsuch as DeepCASE. Therefore, our findings suggest that traditional methods to\nimprove the quality of input data can benefit automation.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u6807\u7b7e\u4e0d\u5e73\u8861\u5bf9\u7f51\u7edc\u5165\u4fb5\u8b66\u62a5\u5206\u7c7b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5176\u5f71\u54cd\u5206\u7c7b\u6027\u80fd\u548c\u89e3\u91ca\u6027\uff0c\u5efa\u8bae\u901a\u8fc7\u8c03\u6574SOC\u68c0\u6d4b\u89c4\u5219\u51cf\u5c11\u4e0d\u5e73\u8861\u3002", "motivation": "\u81ea\u52a8\u5316\u5728SOC\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u9700\u89e3\u51b3\u6570\u636e\u4e0d\u5e73\u8861\u548c\u53ef\u89e3\u91ca\u6027\u95ee\u9898\u3002", "method": "\u4f7f\u7528DeepCASE\u8bc4\u4f30\u6807\u7b7e\u4e0d\u5e73\u8861\u5bf9\u8b66\u62a5\u5206\u7c7b\u7684\u5f71\u54cd\u3002", "result": "\u6807\u7b7e\u4e0d\u5e73\u8861\u5f71\u54cd\u5206\u7c7b\u6027\u80fd\u548c\u89e3\u91ca\u6027\u3002", "conclusion": "\u8c03\u6574SOC\u68c0\u6d4b\u89c4\u5219\u53ef\u51cf\u5c11\u4e0d\u5e73\u8861\uff0c\u63d0\u5347\u81ea\u52a8\u5316\u7684\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.01615", "pdf": "https://arxiv.org/pdf/2507.01615", "abs": "https://arxiv.org/abs/2507.01615", "authors": ["Alper Alimoglu", "Kamil Erdayandi", "Mustafa A. Mustafa", "\u00dcmit Cali"], "title": "EDGChain-E: A Decentralized Git-Based Framework for Versioning Encrypted Energy Data", "categories": ["cs.DC"], "comment": null, "summary": "This paper proposes a new decentralized framework, named EDGChain-E\n(Encrypted-Data-Git Chain for Energy), designed to manage version-controlled,\nencrypted energy data using blockchain and the InterPlanetary File System. The\nframework incorporates a Decentralized Autonomous Organization (DAO) to\norchestrate collaborative data governance across the lifecycle of energy\nresearch and operations, such as smart grid monitoring, demand forecasting, and\npeer-to-peer energy trading. In EDGChain-E, initial commits capture the full\nencrypted datasets-such as smart meter readings or grid telemetry-while\nsubsequent updates are tracked as encrypted Git patches, ensuring integrity,\ntraceability, and privacy. This versioning mechanism supports secure\ncollaboration across multiple stakeholders (e.g., utilities, researchers,\nregulators) without compromising sensitive or regulated information. We\nhighlight the framework's capability to maintain FAIR-compliant (Findable,\nAccessible, Interoperable, Reusable) provenance of encrypted data. By embedding\nhash-based content identifiers in Merkle trees, the system enables transparent,\nauditable, and immutable tracking of data changes, thereby supporting\nreproducibility and trust in decentralized energy applications.", "AI": {"tldr": "EDGChain-E\u662f\u4e00\u4e2a\u57fa\u4e8e\u533a\u5757\u94fe\u548cIPFS\u7684\u53bb\u4e2d\u5fc3\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u7ba1\u7406\u52a0\u5bc6\u80fd\u6e90\u6570\u636e\uff0c\u652f\u6301\u7248\u672c\u63a7\u5236\u548c\u591a\u65b9\u534f\u4f5c\uff0c\u786e\u4fdd\u6570\u636e\u5b8c\u6574\u6027\u3001\u53ef\u8ffd\u6eaf\u6027\u548c\u9690\u79c1\u3002", "motivation": "\u89e3\u51b3\u80fd\u6e90\u6570\u636e\u7ba1\u7406\u4e2d\u7684\u9690\u79c1\u3001\u534f\u4f5c\u548c\u53ef\u8ffd\u6eaf\u6027\u95ee\u9898\uff0c\u652f\u6301\u667a\u80fd\u7535\u7f51\u76d1\u63a7\u3001\u9700\u6c42\u9884\u6d4b\u548c\u70b9\u5bf9\u70b9\u80fd\u6e90\u4ea4\u6613\u7b49\u5e94\u7528\u3002", "method": "\u7ed3\u5408\u533a\u5757\u94fe\u3001IPFS\u548cGit\u7248\u672c\u63a7\u5236\uff0c\u901a\u8fc7\u52a0\u5bc6\u6570\u636e\u96c6\u548c\u66f4\u65b0\u8865\u4e01\uff0c\u5229\u7528DAO\u5b9e\u73b0\u534f\u4f5c\u6cbb\u7406\uff0c\u5d4c\u5165\u54c8\u5e0c\u6807\u8bc6\u7b26\u786e\u4fdd\u900f\u660e\u548c\u4e0d\u53ef\u53d8\u7684\u6570\u636e\u8ffd\u8e2a\u3002", "result": "\u6846\u67b6\u652f\u6301FAIR\u5408\u89c4\u7684\u6570\u636e\u6eaf\u6e90\uff0c\u5b9e\u73b0\u5b89\u5168\u534f\u4f5c\u548c\u53ef\u4fe1\u7684\u6570\u636e\u53d8\u66f4\u8ffd\u8e2a\uff0c\u9002\u7528\u4e8e\u53bb\u4e2d\u5fc3\u5316\u80fd\u6e90\u5e94\u7528\u3002", "conclusion": "EDGChain-E\u4e3a\u80fd\u6e90\u6570\u636e\u7ba1\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b89\u5168\u3001\u900f\u660e\u4e14\u53ef\u534f\u4f5c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u589e\u5f3a\u4e86\u6570\u636e\u7684\u53ef\u91cd\u73b0\u6027\u548c\u4fe1\u4efb\u3002"}}
{"id": "2507.01827", "pdf": "https://arxiv.org/pdf/2507.01827", "abs": "https://arxiv.org/abs/2507.01827", "authors": ["Haichuan Hu", "Congqing He", "Hao Zhang", "Xiaochen Xie", "Quanjun Zhang"], "title": "APRMCTS: Improving LLM-based Automated Program Repair with Iterative Tree Search", "categories": ["cs.SE"], "comment": null, "summary": "Automated Program Repair (APR) attempts to fix software bugs without human\nintervention, which plays a crucial role in software development and\nmaintenance. Recently, with the advances in Large Language Models (LLMs), a\nrapidly increasing number of APR techniques have been proposed with remarkable\nperformance. However, existing LLM-based APR techniques typically adopt\ntrial-and-error strategies, which suffer from two major drawbacks: (1)\ninherently limited patch effectiveness due to local exploration, and (2) low\nsearch efficiency due to redundant exploration. In this paper, we propose\nAPRMCTS, which uses iterative tree search to improve LLM-based APR. APRMCTS\nincorporates Monte Carlo Tree Search (MCTS) into patch searching by performing\na global evaluation of the explored patches and selecting the most promising\none for subsequent refinement and generation. APRMCTS effectively resolves the\nproblems of falling into local optima and thus helps improve the efficiency of\npatch searching. Our experiments on 835 bugs from Defects4J demonstrate that,\nwhen integrated with GPT-3.5, APRMCTS can fix a total of 201 bugs, which\noutperforms all state-of-the-art baselines. Besides, APRMCTS helps GPT-4o-mini,\nGPT-3.5, Yi-Coder-9B, and Qwen2.5-Coder-7B to fix 30, 27, 37, and 28 more bugs,\nrespectively. More importantly, APRMCTS boasts a significant performance\nadvantage while employing small patch size (16 and 32), notably fewer than the\n500 and 10,000 patches adopted in previous studies. In terms of cost, compared\nto existing state-of-the-art LLM-based APR methods, APRMCTS has time and\nmonetary costs of less than 20% and 50%, respectively. Our extensive study\ndemonstrates that APRMCTS exhibits good effectiveness and efficiency, with\nparticular advantages in addressing complex bugs.", "AI": {"tldr": "APRMCTS\u5229\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u6539\u8fdb\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5c40\u90e8\u63a2\u7d22\u548c\u5197\u4f59\u641c\u7d22\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fee\u590d\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684APR\u6280\u672f\u91c7\u7528\u8bd5\u9519\u7b56\u7565\uff0c\u5b58\u5728\u5c40\u90e8\u63a2\u7d22\u5bfc\u81f4\u7684\u4fee\u590d\u6548\u679c\u6709\u9650\u548c\u5197\u4f59\u641c\u7d22\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "method": "APRMCTS\u901a\u8fc7\u8fed\u4ee3\u6811\u641c\u7d22\u5168\u5c40\u8bc4\u4f30\u8865\u4e01\u5e76\u9009\u62e9\u6700\u6709\u6f5c\u529b\u7684\u8fdb\u884c\u7ec6\u5316\uff0c\u7ed3\u5408MCTS\u4f18\u5316\u641c\u7d22\u8fc7\u7a0b\u3002", "result": "\u5728Defects4J\u7684835\u4e2a\u9519\u8bef\u4e0a\uff0cAPRMCTS\u4e0eGPT-3.5\u7ed3\u5408\u4fee\u590d\u4e86201\u4e2a\u9519\u8bef\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5728\u8f83\u5c0f\u8865\u4e01\u89c4\u6a21\u4e0b\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "APRMCTS\u5728\u4fee\u590d\u590d\u6742\u9519\u8bef\u65f6\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u548c\u4f4e\u6210\u672c\u4f18\u52bf\uff0c\u662fLLM-based APR\u7684\u6709\u6548\u6539\u8fdb\u3002"}}
{"id": "2507.01775", "pdf": "https://arxiv.org/pdf/2507.01775", "abs": "https://arxiv.org/abs/2507.01775", "authors": ["Haitao Wang"], "title": "A Deterministic Partition Tree and Applications", "categories": ["cs.CG", "cs.DS"], "comment": "To appear in ESA 2025", "summary": "In this paper, we present a deterministic variant of Chan's randomized\npartition tree [Discret. Comput. Geom., 2012]. This result leads to numerous\napplications. In particular, for $d$-dimensional simplex range counting (for\nany constant $d \\ge 2$), we construct a data structure using $O(n)$ space and\n$O(n^{1+\\epsilon})$ preprocessing time, such that each query can be answered in\n$o(n^{1-1/d})$ time (specifically, $O(n^{1-1/d} / \\log^{\\Omega(1)} n)$ time),\nthereby breaking an $\\Omega(n^{1-1/d})$ lower bound known for the semigroup\nsetting. Notably, our approach does not rely on any bit-packing techniques. We\nalso obtain deterministic improvements for several other classical problems,\nincluding simplex range stabbing counting and reporting, segment intersection\ndetection, counting and reporting, ray-shooting among segments, and more.\nSimilar to Chan's original randomized partition tree, we expect that additional\napplications will emerge in the future, especially in situations where\ndeterministic results are preferred.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u786e\u5b9a\u6027\u7248\u672c\u7684Chan\u968f\u673a\u5212\u5206\u6811\uff0c\u7528\u4e8e\u89e3\u51b3\u9ad8\u7ef4\u5355\u7eaf\u5f62\u8303\u56f4\u8ba1\u6570\u7b49\u95ee\u9898\uff0c\u7a81\u7834\u4e86\u5df2\u77e5\u7684\u4e0b\u754c\u9650\u5236\u3002", "motivation": "\u6539\u8fdbChan\u7684\u968f\u673a\u5212\u5206\u6811\uff0c\u63d0\u4f9b\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u9700\u8981\u786e\u5b9a\u6027\u7ed3\u679c\u7684\u573a\u666f\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3aO(n)\u3001\u9884\u5904\u7406\u65f6\u95f4\u4e3aO(n^{1+\u03b5})\u7684\u6570\u636e\u7ed3\u6784\uff0c\u67e5\u8be2\u65f6\u95f4\u4e3ao(n^{1-1/d})\u3002", "result": "\u5728d\u7ef4\u5355\u7eaf\u5f62\u8303\u56f4\u8ba1\u6570\u7b49\u95ee\u9898\u4e2d\uff0c\u7a81\u7834\u4e86\u03a9(n^{1-1/d})\u7684\u4e0b\u754c\u9650\u5236\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u4f4d\u538b\u7f29\u6280\u672f\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u7ecf\u5178\u95ee\u9898\uff0c\u672a\u6765\u53ef\u80fd\u6709\u66f4\u591a\u5e94\u7528\u3002"}}
{"id": "2507.01031", "pdf": "https://arxiv.org/pdf/2507.01031", "abs": "https://arxiv.org/abs/2507.01031", "authors": ["Fanchen Bu", "Kijung Shin"], "title": "PyTorch-based Geometric Learning with Non-CUDA Processing Units: Experiences from Intel Gaudi-v2 HPUs", "categories": ["cs.LG", "cs.SE"], "comment": "Conference paper: Accepted in Korea Computer Congress (KCC) 2025. The\n  library is available at https://github.com/bokveizen/gaudi-geometric-learning", "summary": "Geometric learning has emerged as a powerful paradigm for modeling\nnon-Euclidean data, especially graph-structured ones, with applications\nspanning social networks, molecular structures, knowledge graphs, and\nrecommender systems. While Nvidia's CUDA-enabled graphics processing units\n(GPUs) largely dominate the hardware landscape, emerging accelerators such as\nIntel's Gaudi Habana Processing Units (HPUs) offer competitive performance and\nenergy efficiency. However, the usage of such non-CUDA processing units\nrequires significant engineering effort and novel software adaptations. In this\nwork, we present our experiences porting PyTorch-based geometric learning\nframeworks to Gaudi-v2 HPUs. We introduce a collection of core utilities that\nrestore essential operations (e.g., scatter, sparse indexing, k-nearest\nneighbors) on Gaudi-v2 HPUs, and we consolidate sixteen guided tutorials and\neleven real-world examples with diagnostic analyses of encountered failures and\ndetailed workarounds. We collect all our experiences into a publicly accessible\nGitHub repository. Our contributions lower the barrier for researchers to\nexperiment with geometric-learning algorithms and models on non-CUDA hardware,\nproviding a foundation for further optimization and cross-platform portability.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u5c06\u57fa\u4e8ePyTorch\u7684\u51e0\u4f55\u5b66\u4e60\u6846\u67b6\u79fb\u690d\u5230Gaudi-v2 HPU\u7684\u7ecf\u9a8c\uff0c\u63d0\u4f9b\u4e86\u6838\u5fc3\u5de5\u5177\u548c\u6559\u7a0b\uff0c\u964d\u4f4e\u4e86\u975eCUDA\u786c\u4ef6\u4e0a\u7684\u7814\u7a76\u95e8\u69db\u3002", "motivation": "\u89e3\u51b3\u5728\u975eCUDA\u786c\u4ef6\uff08\u5982Gaudi-v2 HPU\uff09\u4e0a\u8fd0\u884c\u51e0\u4f55\u5b66\u4e60\u6846\u67b6\u7684\u5de5\u7a0b\u6311\u6218\uff0c\u4fc3\u8fdb\u8de8\u5e73\u53f0\u7814\u7a76\u3002", "method": "\u5f00\u53d1\u6838\u5fc3\u5de5\u5177\u6062\u590d\u5173\u952e\u64cd\u4f5c\uff0c\u63d0\u4f9b\u6559\u7a0b\u548c\u5b9e\u4f8b\u5206\u6790\uff0c\u6574\u7406\u4e3a\u516c\u5f00GitHub\u4ed3\u5e93\u3002", "result": "\u6210\u529f\u79fb\u690d\u6846\u67b6\uff0c\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u548c\u8d44\u6e90\uff0c\u652f\u6301\u975eCUDA\u786c\u4ef6\u4e0a\u7684\u51e0\u4f55\u5b66\u4e60\u7814\u7a76\u3002", "conclusion": "\u5de5\u4f5c\u4e3a\u51e0\u4f55\u5b66\u4e60\u5728\u975eCUDA\u786c\u4ef6\u4e0a\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u4fc3\u8fdb\u4e86\u8fdb\u4e00\u6b65\u4f18\u5316\u548c\u8de8\u5e73\u53f0\u517c\u5bb9\u6027\u3002"}}
{"id": "2507.01676", "pdf": "https://arxiv.org/pdf/2507.01676", "abs": "https://arxiv.org/abs/2507.01676", "authors": ["Giuseppe Ruggeri", "Renzo Andri", "Daniele Jahier Pagliari", "Lukas Cavigelli"], "title": "Deep Recommender Models Inference: Automatic Asymmetric Data Flow Optimization", "categories": ["cs.DC", "cs.AI", "cs.AR", "cs.IR", "C.4; D.1.3; H.3.3; H.3.4"], "comment": "5 pages, 4 figures, conference: IEEE ICCD24", "summary": "Deep Recommender Models (DLRMs) inference is a fundamental AI workload\naccounting for more than 79% of the total AI workload in Meta's data centers.\nDLRMs' performance bottleneck is found in the embedding layers, which perform\nmany random memory accesses to retrieve small embedding vectors from tables of\nvarious sizes. We propose the design of tailored data flows to speedup\nembedding look-ups. Namely, we propose four strategies to look up an embedding\ntable effectively on one core, and a framework to automatically map the tables\nasymmetrically to the multiple cores of a SoC. We assess the effectiveness of\nour method using the Huawei Ascend AI accelerators, comparing it with the\ndefault Ascend compiler, and we perform high-level comparisons with Nvidia\nA100. Results show a speed-up varying from 1.5x up to 6.5x for real workload\ndistributions, and more than 20x for extremely unbalanced distributions.\nFurthermore, the method proves to be much more independent of the query\ndistribution than the baseline.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u6df1\u5ea6\u63a8\u8350\u6a21\u578b\uff08DLRM\uff09\u5d4c\u5165\u5c42\u6027\u80fd\u74f6\u9888\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9a\u5236\u6570\u636e\u6d41\u548c\u4e0d\u5bf9\u79f0\u6620\u5c04\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5d4c\u5165\u67e5\u627e\u901f\u5ea6\u3002", "motivation": "DLRM\u7684\u5d4c\u5165\u5c42\u56e0\u5176\u968f\u673a\u5185\u5b58\u8bbf\u95ee\u6210\u4e3a\u6027\u80fd\u74f6\u9888\uff0c\u5f71\u54cd\u4e86Meta\u6570\u636e\u4e2d\u5fc379%\u7684AI\u5de5\u4f5c\u8d1f\u8f7d\u3002", "method": "\u63d0\u51fa\u4e86\u56db\u79cd\u5355\u6838\u5d4c\u5165\u8868\u67e5\u627e\u7b56\u7565\u548c\u4e00\u4e2a\u591a\u6838SoC\u4e0d\u5bf9\u79f0\u6620\u5c04\u6846\u67b6\u3002", "result": "\u5728\u534e\u4e3aAscend AI\u52a0\u901f\u5668\u4e0a\u6d4b\u8bd5\uff0c\u901f\u5ea6\u63d0\u53471.5x\u81f36.5x\uff0c\u6781\u7aef\u4e0d\u5e73\u8861\u5206\u5e03\u4e0b\u53ef\u8fbe20x\u4ee5\u4e0a\uff0c\u4e14\u5bf9\u67e5\u8be2\u5206\u5e03\u66f4\u9c81\u68d2\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86DLRM\u5d4c\u5165\u5c42\u7684\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\u3002"}}
{"id": "2507.01032", "pdf": "https://arxiv.org/pdf/2507.01032", "abs": "https://arxiv.org/abs/2507.01032", "authors": ["Nan Mu", "Hongbo Yang", "Chen Zhao"], "title": "An Uncertainty-Aware Dynamic Decision Framework for Progressive Multi-Omics Integration in Classification Tasks", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "Background and Objective: High-throughput multi-omics technologies have\nproven invaluable for elucidating disease mechanisms and enabling early\ndiagnosis. However, the high cost of multi-omics profiling imposes a\nsignificant economic burden, with over reliance on full omics data potentially\nleading to unnecessary resource consumption. To address these issues, we\npropose an uncertainty-aware, multi-view dynamic decision framework for omics\ndata classification that aims to achieve high diagnostic accuracy while\nminimizing testing costs. Methodology: At the single-omics level, we refine the\nactivation functions of neural networks to generate Dirichlet distribution\nparameters, utilizing subjective logic to quantify both the belief masses and\nuncertainty mass of classification results. Belief mass reflects the support of\na specific omics modality for a disease class, while the uncertainty parameter\ncaptures limitations in data quality and model discriminability, providing a\nmore trustworthy basis for decision-making. At the multi omics level, we employ\na fusion strategy based on Dempster-Shafer theory to integrate heterogeneous\nmodalities, leveraging their complementarity to boost diagnostic accuracy and\nrobustness. A dynamic decision mechanism is then applied that omics data are\nincrementally introduced for each patient until either all data sources are\nutilized or the model confidence exceeds a predefined threshold, potentially\nbefore all data sources are utilized. Results and Conclusion: We evaluate our\napproach on four benchmark multi-omics datasets, ROSMAP, LGG, BRCA, and KIPAN.\nIn three datasets, over 50% of cases achieved accurate classification using a\nsingle omics modality, effectively reducing redundant testing. Meanwhile, our\nmethod maintains diagnostic performance comparable to full-omics models and\npreserves essential biological insights.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u591a\u89c6\u56fe\u52a8\u6001\u51b3\u7b56\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u7ec4\u5b66\u6570\u636e\u5206\u7c7b\uff0c\u65e8\u5728\u964d\u4f4e\u6d4b\u8bd5\u6210\u672c\u7684\u540c\u65f6\u4fdd\u6301\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u3002", "motivation": "\u591a\u7ec4\u5b66\u6280\u672f\u6210\u672c\u9ad8\u6602\u4e14\u53ef\u80fd\u5bfc\u81f4\u8d44\u6e90\u6d6a\u8d39\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5728\u51cf\u5c11\u5197\u4f59\u6d4b\u8bd5\u7684\u540c\u65f6\u4fdd\u6301\u8bca\u65ad\u51c6\u786e\u6027\u3002", "method": "\u5728\u5355\u7ec4\u5b66\u5c42\u9762\uff0c\u901a\u8fc7\u6539\u8fdb\u795e\u7ecf\u7f51\u7edc\u6fc0\u6d3b\u51fd\u6570\u751f\u6210Dirichlet\u5206\u5e03\u53c2\u6570\uff0c\u91cf\u5316\u5206\u7c7b\u7ed3\u679c\u7684\u4fe1\u5ea6\u548c\u4e0d\u786e\u5b9a\u6027\uff1b\u5728\u591a\u7ec4\u5b66\u5c42\u9762\uff0c\u57fa\u4e8eDempster-Shafer\u7406\u8bba\u878d\u5408\u5f02\u6784\u6a21\u6001\uff0c\u52a8\u6001\u51b3\u7b56\u673a\u5236\u9010\u6b65\u5f15\u5165\u6570\u636e\u76f4\u81f3\u6ee1\u8db3\u7f6e\u4fe1\u5ea6\u9608\u503c\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08ROSMAP\u3001LGG\u3001BRCA\u3001KIPAN\uff09\u4e0a\uff0c50%\u4ee5\u4e0a\u75c5\u4f8b\u4ec5\u9700\u5355\u7ec4\u5b66\u6570\u636e\u5373\u53ef\u51c6\u786e\u5206\u7c7b\uff0c\u540c\u65f6\u8bca\u65ad\u6027\u80fd\u4e0e\u5168\u7ec4\u5b66\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u51cf\u5c11\u4e86\u5197\u4f59\u6d4b\u8bd5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8bca\u65ad\u51c6\u786e\u6027\u548c\u751f\u7269\u5b66\u6d1e\u5bdf\u529b\u3002"}}
{"id": "2507.01880", "pdf": "https://arxiv.org/pdf/2507.01880", "abs": "https://arxiv.org/abs/2507.01880", "authors": ["Stefano Schuppli", "Fawzi Mohamed", "Henrique Mendon\u00e7a", "Nina Mujkanovic", "Elia Palme", "Dino Conciatore", "Lukas Drescher", "Miguel Gila", "Pim Witlox", "Joost VandeVondele", "Maxime Martinasso", "Thomas C. Schulthess", "Torsten Hoefler"], "title": "Evolving HPC services to enable ML workloads on HPE Cray EX", "categories": ["cs.DC", "cs.LG"], "comment": "Presented at the Cray User Group 2025 (CUG'25)", "summary": "The Alps Research Infrastructure leverages GH200 technology at scale,\nfeaturing 10,752 GPUs. Accessing Alps provides a significant computational\nadvantage for researchers in Artificial Intelligence (AI) and Machine Learning\n(ML). While Alps serves a broad range of scientific communities, traditional\nHPC services alone are not sufficient to meet the dynamic needs of the ML\ncommunity. This paper presents an initial investigation into extending HPC\nservice capabilities to better support ML workloads. We identify key challenges\nand gaps we have observed since the early-access phase (2023) of Alps by the\nSwiss AI community and propose several technological enhancements. These\ninclude a user environment designed to facilitate the adoption of HPC for ML\nworkloads, balancing performance with flexibility; a utility for rapid\nperformance screening of ML applications during development; observability\ncapabilities and data products for inspecting ongoing large-scale ML workloads;\na utility to simplify the vetting of allocated nodes for compute readiness; a\nservice plane infrastructure to deploy various types of workloads, including\nsupport and inference services; and a storage infrastructure tailored to the\nspecific needs of ML workloads. These enhancements aim to facilitate the\nexecution of ML workloads on HPC systems, increase system usability and\nresilience, and better align with the needs of the ML community. We also\ndiscuss our current approach to security aspects. This paper concludes by\nplacing these proposals in the broader context of changes in the communities\nserved by HPC infrastructure like ours.", "AI": {"tldr": "Alps\u7814\u7a76\u57fa\u7840\u8bbe\u65bd\u5229\u7528GH200\u6280\u672f\uff0c\u63d0\u4f9b10,752\u4e2aGPU\uff0c\u4e3aAI\u548cML\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u663e\u8457\u8ba1\u7b97\u4f18\u52bf\u3002\u672c\u6587\u63a2\u8ba8\u5982\u4f55\u6269\u5c55HPC\u670d\u52a1\u4ee5\u66f4\u597d\u652f\u6301ML\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5e76\u63d0\u51fa\u6280\u672f\u589e\u5f3a\u65b9\u6848\u3002", "motivation": "\u4f20\u7edfHPC\u670d\u52a1\u65e0\u6cd5\u6ee1\u8db3ML\u793e\u533a\u7684\u52a8\u6001\u9700\u6c42\uff0c\u9700\u6269\u5c55\u670d\u52a1\u80fd\u529b\u4ee5\u652f\u6301ML\u5de5\u4f5c\u8d1f\u8f7d\u3002", "method": "\u63d0\u51fa\u591a\u9879\u6280\u672f\u589e\u5f3a\uff0c\u5305\u62ec\u7528\u6237\u73af\u5883\u8bbe\u8ba1\u3001\u6027\u80fd\u7b5b\u67e5\u5de5\u5177\u3001\u53ef\u89c2\u5bdf\u6027\u80fd\u529b\u3001\u8282\u70b9\u5ba1\u67e5\u5de5\u5177\u3001\u670d\u52a1\u5e73\u9762\u57fa\u7840\u8bbe\u65bd\u548c\u5b58\u50a8\u57fa\u7840\u8bbe\u65bd\u3002", "result": "\u8fd9\u4e9b\u589e\u5f3a\u65e8\u5728\u63d0\u5347ML\u5de5\u4f5c\u8d1f\u8f7d\u5728HPC\u7cfb\u7edf\u4e0a\u7684\u6267\u884c\u6548\u7387\u3001\u7cfb\u7edf\u53ef\u7528\u6027\u548c\u5f39\u6027\uff0c\u5e76\u66f4\u597d\u5730\u6ee1\u8db3ML\u793e\u533a\u9700\u6c42\u3002", "conclusion": "\u672c\u6587\u5c06\u8fd9\u4e9b\u63d0\u6848\u7f6e\u4e8eHPC\u57fa\u7840\u8bbe\u65bd\u670d\u52a1\u793e\u533a\u53d8\u5316\u7684\u66f4\u5e7f\u6cdb\u80cc\u666f\u4e0b\u8ba8\u8bba\u3002"}}
{"id": "2507.01069", "pdf": "https://arxiv.org/pdf/2507.01069", "abs": "https://arxiv.org/abs/2507.01069", "authors": ["Nishant A. Parikh"], "title": "Agentic AI in Product Management: A Co-Evolutionary Model", "categories": ["cs.CE", "cs.SE"], "comment": "41 pages, 2 figures", "summary": "This study explores agentic AI's transformative role in product management,\nproposing a conceptual co-evolutionary framework to guide its integration\nacross the product lifecycle. Agentic AI, characterized by autonomy,\ngoal-driven behavior, and multi-agent collaboration, redefines product managers\n(PMs) as orchestrators of socio-technical ecosystems. Using systems theory,\nco-evolutionary theory, and human-AI interaction theory, the framework maps\nagentic AI capabilities in discovery, scoping, business case development,\ndevelopment, testing, and launch. An integrative review of 70+ sources,\nincluding case studies from leading tech firms, highlights PMs' evolving roles\nin AI orchestration, supervision, and strategic alignment. Findings emphasize\nmutual adaptation between PMs and AI, requiring skills in AI literacy,\ngovernance, and systems thinking. Addressing gaps in traditional frameworks,\nthis study provides a foundation for future research and practical\nimplementation to ensure responsible, effective agentic AI integration in\nsoftware organizations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6982\u5ff5\u6027\u534f\u540c\u8fdb\u5316\u6846\u67b6\uff0c\u63a2\u8ba8\u4e86\u81ea\u4e3bAI\u5728\u4ea7\u54c1\u7ba1\u7406\u4e2d\u7684\u53d8\u9769\u4f5c\u7528\uff0c\u5e76\u6307\u5bfc\u5176\u5728\u6574\u4e2a\u4ea7\u54c1\u751f\u547d\u5468\u671f\u4e2d\u7684\u6574\u5408\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u586b\u8865\u4f20\u7edf\u6846\u67b6\u7684\u7a7a\u767d\uff0c\u63a2\u7d22\u81ea\u4e3bAI\u5982\u4f55\u91cd\u65b0\u5b9a\u4e49\u4ea7\u54c1\u7ecf\u7406\u7684\u89d2\u8272\uff0c\u5e76\u63a8\u52a8\u5176\u4e0eAI\u7684\u534f\u540c\u8fdb\u5316\u3002", "method": "\u7ed3\u5408\u7cfb\u7edf\u7406\u8bba\u3001\u534f\u540c\u8fdb\u5316\u7406\u8bba\u548c\u4eba\u673a\u4ea4\u4e92\u7406\u8bba\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u5e76\u901a\u8fc770\u591a\u4e2a\u6765\u6e90\u7684\u7efc\u8ff0\u548c\u6848\u4f8b\u7814\u7a76\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4ea7\u54c1\u7ecf\u7406\u9700\u5177\u5907AI\u7d20\u517b\u3001\u6cbb\u7406\u80fd\u529b\u548c\u7cfb\u7edf\u601d\u7ef4\uff0c\u4ee5\u5b9e\u73b0\u4e0eAI\u7684\u76f8\u4e92\u9002\u5e94\u3002", "conclusion": "\u7814\u7a76\u4e3a\u672a\u6765\u7814\u7a76\u548c\u5b9e\u8df5\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u4ee5\u786e\u4fdd\u81ea\u4e3bAI\u5728\u8f6f\u4ef6\u7ec4\u7ec7\u4e2d\u7684\u8d1f\u8d23\u4efb\u548c\u6709\u6548\u6574\u5408\u3002"}}
{"id": "2507.01034", "pdf": "https://arxiv.org/pdf/2507.01034", "abs": "https://arxiv.org/abs/2507.01034", "authors": ["Asma Agaal", "Mansour Essgaer", "Hend M. Farkash", "Zulaiha Ali Othman"], "title": "Data-driven Insights for Informed Decision-Making: Applying LSTM Networks for Robust Electricity Forecasting in Libya", "categories": ["cs.LG", "cs.AI"], "comment": "This article was published in International Journal of Intelligent\n  Systems and Applications (IJISA) (MECS Press), Vol. 17, No. 3, 8 Jun. 2025,\n  DOI: https://doi.org/10.5815/ijisa.2025.03.05", "summary": "Accurate electricity forecasting is crucial for grid stability and energy\nplanning, especially in Benghazi, Libya, where frequent load shedding,\ngeneration deficits, and infrastructure limitations persist. This study\nproposes a data-driven approach to forecast electricity load, generation, and\ndeficits for 2025 using historical data from 2019 (a year marked by\ninstability) and 2023 (a more stable year). Multiple time series models were\napplied, including ARIMA, seasonal ARIMA, dynamic regression ARIMA, exponential\nsmoothing, extreme gradient boosting, and Long Short-Term Memory (LSTM) neural\nnetworks. The dataset was enhanced through missing value imputation, outlier\nsmoothing, and log transformation. Performance was assessed using mean squared\nerror, root mean squared error, mean absolute error, and mean absolute\npercentage error. LSTM outperformed all other models, showing strong\ncapabilities in modeling non-stationary and seasonal patterns. A key\ncontribution of this work is an optimized LSTM framework that integrates\nexogenous factors such as temperature and humidity, offering robust performance\nin forecasting multiple electricity indicators. These results provide practical\ninsights for policymakers and grid operators to enable proactive load\nmanagement and resource planning in data-scarce, volatile regions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u5386\u53f2\u6570\u636e\u9884\u6d4b2025\u5e74\u5229\u6bd4\u4e9a\u73ed\u52a0\u897f\u7684\u7535\u529b\u8d1f\u8377\u3001\u53d1\u7535\u91cf\u548c\u7f3a\u53e3\uff0cLSTM\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u73ed\u52a0\u897f\u7535\u529b\u4f9b\u5e94\u4e0d\u7a33\u5b9a\uff0c\u57fa\u7840\u8bbe\u65bd\u6709\u9650\uff0c\u51c6\u786e\u7684\u7535\u529b\u9884\u6d4b\u5bf9\u7535\u7f51\u7a33\u5b9a\u548c\u80fd\u6e90\u89c4\u5212\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u591a\u79cd\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\uff08\u5982ARIMA\u3001\u5b63\u8282\u6027ARIMA\u3001LSTM\u7b49\uff09\uff0c\u5e76\u5bf9\u6570\u636e\u8fdb\u884c\u7f3a\u5931\u503c\u586b\u8865\u3001\u5f02\u5e38\u503c\u5e73\u6ed1\u548c\u5bf9\u6570\u8f6c\u6362\u3002", "result": "LSTM\u6a21\u578b\u5728\u9884\u6d4b\u975e\u5e73\u7a33\u548c\u5b63\u8282\u6027\u6a21\u5f0f\u65b9\u9762\u8868\u73b0\u6700\u4f18\uff0c\u6574\u5408\u4e86\u6e29\u5ea6\u548c\u6e7f\u5ea6\u7b49\u5916\u751f\u56e0\u7d20\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u548c\u7535\u7f51\u8fd0\u8425\u5546\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u5728\u6570\u636e\u7a00\u7f3a\u3001\u4e0d\u7a33\u5b9a\u7684\u5730\u533a\u8fdb\u884c\u4e3b\u52a8\u8d1f\u8377\u7ba1\u7406\u548c\u8d44\u6e90\u89c4\u5212\u3002"}}
{"id": "2507.01067", "pdf": "https://arxiv.org/pdf/2507.01067", "abs": "https://arxiv.org/abs/2507.01067", "authors": ["Keun Soo Yim"], "title": "Evaluation of a Foundational Model and Stochastic Models for Forecasting Sporadic or Spiky Production Outages of High-Performance Machine Learning Services", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.SY", "eess.SY"], "comment": null, "summary": "Time series forecasting models have diverse real world applications (e.g.,\nfrom electricity metrics to software workload). Latest foundational models\ntrained for time series forecasting show strengths (e.g., for long sequences\nand in zero-shot settings). However, foundational model was not yet used for\nforecasting rare, spiky events, i.e., a challenging target because those are a\ncorner case of extreme events. In this paper, we optimize a state-of-the-art\nfoundational model to forecast sporadic or spiky production outages of\nhigh-performance machine learning services powering billions of client devices.\nWe evaluate the forecasting errors of the foundational model compared with\nclassical stochastic forecasting models (e.g., moving average and\nautoregressive). The analysis helps us understand how each of the evaluated\nmodels performs for the sporadic or spiky events. For example, it identifies\nthe key patterns in the target data that are well tracked by the foundational\nmodel vs. each of the stochastic models. We use the models with optimal\nparameters to estimate a year-long outage statistics of a particular root cause\nwith less than 6% value errors.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u4f18\u5316\u57fa\u7840\u6a21\u578b\u4ee5\u9884\u6d4b\u7f55\u89c1\u3001\u5c16\u5cf0\u4e8b\u4ef6\uff08\u5982\u751f\u4ea7\u4e2d\u65ad\uff09\uff0c\u5e76\u4e0e\u7ecf\u5178\u968f\u673a\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\uff0c\u53d1\u73b0\u57fa\u7840\u6a21\u578b\u5728\u7279\u5b9a\u573a\u666f\u4e0b\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5c1a\u672a\u7528\u4e8e\u7f55\u89c1\u3001\u5c16\u5cf0\u4e8b\u4ef6\u7684\u9884\u6d4b\uff0c\u8fd9\u662f\u6781\u7aef\u4e8b\u4ef6\u7684\u7279\u6b8a\u60c5\u51b5\uff0c\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u4f18\u5316\u4e00\u79cd\u5148\u8fdb\u7684\u57fa\u7840\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u9ad8\u6027\u80fd\u673a\u5668\u5b66\u4e60\u670d\u52a1\u7684\u5076\u53d1\u6027\u751f\u4ea7\u4e2d\u65ad\uff0c\u5e76\u4e0e\u7ecf\u5178\u968f\u673a\u6a21\u578b\uff08\u5982\u79fb\u52a8\u5e73\u5747\u548c\u81ea\u56de\u5f52\uff09\u8fdb\u884c\u8bef\u5dee\u6bd4\u8f83\u3002", "result": "\u57fa\u7840\u6a21\u578b\u5728\u7279\u5b9a\u6570\u636e\u6a21\u5f0f\u4e0a\u8868\u73b0\u4f18\u4e8e\u968f\u673a\u6a21\u578b\uff0c\u7528\u4e8e\u4f30\u8ba1\u67d0\u6839\u56e0\u7684\u5e74\u4e2d\u65ad\u7edf\u8ba1\u65f6\uff0c\u8bef\u5dee\u4f4e\u4e8e6%\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\u5728\u9884\u6d4b\u7f55\u89c1\u3001\u5c16\u5cf0\u4e8b\u4ef6\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u5c24\u5176\u5728\u7279\u5b9a\u6570\u636e\u6a21\u5f0f\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2507.01457", "pdf": "https://arxiv.org/pdf/2507.01457", "abs": "https://arxiv.org/abs/2507.01457", "authors": ["Federico Nicolas Peccia", "Frederik Haxel", "Oliver Bringmann"], "title": "Tensor Program Optimization for the RISC-V Vector Extension Using Probabilistic Programs", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": "9 pages, 10 figures, 2 algorithms", "summary": "RISC-V provides a flexible and scalable platform for applications ranging\nfrom embedded devices to high-performance computing clusters. Particularly, its\nRISC-V Vector Extension (RVV) becomes of interest for the acceleration of AI\nworkloads. But writing software that efficiently utilizes the vector units of\nRISC-V CPUs without expert knowledge requires the programmer to rely on the\nautovectorization features of compilers or hand-crafted libraries like\nmuRISCV-NN. Smarter approaches, like autotuning frameworks, have been missing\nthe integration with the RISC-V RVV extension, thus heavily limiting the\nefficient deployment of complex AI workloads. In this paper, we present a\nworkflow based on the TVM compiler to efficiently map AI workloads onto RISC-V\nvector units. Instead of relying on hand-crafted libraries, we integrated the\nRVV extension into TVM's MetaSchedule framework, a probabilistic program\nframework for tensor operation tuning. We implemented different RISC-V SoCs on\nan FPGA and tuned a wide range of AI workloads on them. We found that our\nproposal shows a mean improvement of 46% in execution latency when compared\nagainst the autovectorization feature of GCC, and 29% against muRISCV-NN.\nMoreover, the binary resulting from our proposal has a smaller code memory\nfootprint, making it more suitable for embedded devices. Finally, we also\nevaluated our solution on a commercially available RISC-V SoC implementing the\nRVV 1.0 Vector Extension and found our solution is able to find mappings that\nare 35% faster on average than the ones proposed by LLVM. We open-sourced our\nproposal for the community to expand it to target other RISC-V extensions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTVM\u7f16\u8bd1\u5668\u7684\u5de5\u4f5c\u6d41\uff0c\u7528\u4e8e\u9ad8\u6548\u5730\u5c06AI\u5de5\u4f5c\u8d1f\u8f7d\u6620\u5c04\u5230RISC-V\u5411\u91cf\u5355\u5143\uff0c\u76f8\u6bd4GCC\u81ea\u52a8\u5411\u91cf\u5316\u548cmuRISCV-NN\uff0c\u5206\u522b\u63d0\u5347\u4e8646%\u548c29%\u7684\u6267\u884c\u5ef6\u8fdf\u3002", "motivation": "RISC-V\u5411\u91cf\u6269\u5c55\uff08RVV\uff09\u5728AI\u5de5\u4f5c\u8d1f\u8f7d\u52a0\u901f\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u9ad8\u6548\u7684\u81ea\u52a8\u8c03\u4f18\u6846\u67b6\uff0c\u9650\u5236\u4e86\u590d\u6742AI\u5de5\u4f5c\u8d1f\u8f7d\u7684\u90e8\u7f72\u3002", "method": "\u5c06RVV\u6269\u5c55\u96c6\u6210\u5230TVM\u7684MetaSchedule\u6846\u67b6\u4e2d\uff0c\u901a\u8fc7\u6982\u7387\u7a0b\u5e8f\u6846\u67b6\u8c03\u4f18\u5f20\u91cf\u64cd\u4f5c\uff0c\u5e76\u5728FPGA\u4e0a\u5b9e\u73b0\u591a\u79cdRISC-V SoC\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u76f8\u6bd4GCC\u81ea\u52a8\u5411\u91cf\u5316\u548cmuRISCV-NN\uff0c\u6267\u884c\u5ef6\u8fdf\u5206\u522b\u5e73\u5747\u63d0\u534746%\u548c29%\uff0c\u4e14\u4ee3\u7801\u5185\u5b58\u5360\u7528\u66f4\u5c0f\u3002\u5728\u5546\u7528RISC-V SoC\u4e0a\uff0c\u6bd4LLVM\u5feb35%\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86RISC-V RVV\u6269\u5c55\u7684AI\u5de5\u4f5c\u8d1f\u8f7d\u6548\u7387\uff0c\u9002\u5408\u5d4c\u5165\u5f0f\u8bbe\u5907\uff0c\u5e76\u5f00\u6e90\u4f9b\u793e\u533a\u6269\u5c55\u3002"}}
{"id": "2507.01035", "pdf": "https://arxiv.org/pdf/2507.01035", "abs": "https://arxiv.org/abs/2507.01035", "authors": ["Yushang Zhao", "Haotian Lyu", "Yike Peng", "Aijia Sun", "Feng Jiang", "Xinyue Han"], "title": "Research on Low-Latency Inference and Training Efficiency Optimization for Graph Neural Network and Large Language Model-Based Recommendation Systems", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": null, "summary": "The incessant advent of online services demands high speed and efficient\nrecommender systems (ReS) that can maintain real-time performance along with\nprocessing very complex user-item interactions. The present study, therefore,\nconsiders computational bottlenecks involved in hybrid Graph Neural Network\n(GNN) and Large Language Model (LLM)-based ReS with the aim optimizing their\ninference latency and training efficiency. An extensive methodology was used:\nhybrid GNN-LLM integrated architecture-optimization strategies(quantization,\nLoRA, distillation)-hardware acceleration (FPGA, DeepSpeed)-all under R 4.4.2.\nExperimental improvements were significant, with the optimal Hybrid + FPGA +\nDeepSpeed configuration reaching 13.6% more accuracy (NDCG@10: 0.75) at 40-60ms\nof latency, while LoRA brought down training time by 66% (3.8 hours) in\ncomparison to the non-optimized baseline. Irrespective of domain, such as\naccuracy or efficiency, it can be established that hardware-software co-design\nand parameter-efficient tuning permit hybrid models to outperform GNN or LLM\napproaches implemented independently. It recommends the use of FPGA as well as\nLoRA for real-time deployment. Future work should involve federated learning\nalong with advanced fusion architectures for better scalability and privacy\npreservation. Thus, this research marks the fundamental groundwork concerning\nnext-generation ReS balancing low-latency response with cutting-edge\npersonalization.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7ed3\u5408GNN\u548cLLM\u7684\u6df7\u5408\u63a8\u8350\u7cfb\u7edf\uff0c\u4f18\u5316\u63a8\u7406\u5ef6\u8fdf\u548c\u8bad\u7ec3\u6548\u7387\uff0c\u91c7\u7528\u91cf\u5316\u3001LoRA\u3001\u84b8\u998f\u7b49\u6280\u672f\uff0c\u7ed3\u5408\u786c\u4ef6\u52a0\u901f\uff08FPGA\u3001DeepSpeed\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u5728\u7ebf\u670d\u52a1\u5bf9\u9ad8\u6548\u5b9e\u65f6\u63a8\u8350\u7cfb\u7edf\u7684\u9700\u6c42\u63a8\u52a8\u4e86\u7814\u7a76\uff0c\u65e8\u5728\u89e3\u51b3\u6df7\u5408GNN-LLM\u7cfb\u7edf\u7684\u8ba1\u7b97\u74f6\u9888\u3002", "method": "\u91c7\u7528\u6df7\u5408GNN-LLM\u67b6\u6784\uff0c\u7ed3\u5408\u91cf\u5316\u3001LoRA\u3001\u84b8\u998f\u7b49\u4f18\u5316\u7b56\u7565\uff0c\u5e76\u4f7f\u7528FPGA\u548cDeepSpeed\u8fdb\u884c\u786c\u4ef6\u52a0\u901f\u3002", "result": "\u6700\u4f18\u914d\u7f6e\uff08Hybrid + FPGA + DeepSpeed\uff09\u5728NDCG@10\u4e0a\u63d0\u534713.6%\uff080.75\uff09\uff0c\u5ef6\u8fdf40-60ms\uff1bLoRA\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f466%\uff083.8\u5c0f\u65f6\uff09\u3002", "conclusion": "\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u548c\u53c2\u6570\u9ad8\u6548\u8c03\u4f18\u4f7f\u6df7\u5408\u6a21\u578b\u4f18\u4e8e\u72ec\u7acbGNN\u6216LLM\u65b9\u6cd5\uff0c\u63a8\u8350\u4f7f\u7528FPGA\u548cLoRA\u8fdb\u884c\u5b9e\u65f6\u90e8\u7f72\uff0c\u672a\u6765\u53ef\u63a2\u7d22\u8054\u90a6\u5b66\u4e60\u548c\u9ad8\u7ea7\u878d\u5408\u67b6\u6784\u3002"}}
{"id": "2507.01075", "pdf": "https://arxiv.org/pdf/2507.01075", "abs": "https://arxiv.org/abs/2507.01075", "authors": ["Gabriele Padovani", "Valentine Anantharaj", "Sandro Fiore"], "title": "Provenance Tracking in Large-Scale Machine Learning Systems", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "As the demand for large scale AI models continues to grow, the optimization\nof their training to balance computational efficiency, execution time, accuracy\nand energy consumption represents a critical multidimensional challenge.\nAchieving this balance requires not only innovative algorithmic techniques and\nhardware architectures but also comprehensive tools for monitoring, analyzing,\nand understanding the underlying processes involved in model training and\ndeployment. Provenance data information about the origins, context, and\ntransformations of data and processes has become a key component in this\npursuit. By leveraging provenance, researchers and engineers can gain insights\ninto resource usage patterns, identify inefficiencies, and ensure\nreproducibility and accountability in AI development workflows. For this\nreason, the question of how distributed resources can be optimally utilized to\nscale large AI models in an energy efficient manner is a fundamental one. To\nsupport this effort, we introduce the yProv4ML library, a tool designed to\ncollect provenance data in JSON format, compliant with the W3C PROV and ProvML\nstandards. yProv4ML focuses on flexibility and extensibility, and enables users\nto integrate additional data collection tools via plugins. The library is fully\nintegrated with the yProv framework, allowing for higher level pairing in tasks\nrun also through workflow management systems.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86yProv4ML\u5e93\uff0c\u7528\u4e8e\u6536\u96c6\u7b26\u5408W3C PROV\u548cProvML\u6807\u51c6\u7684JSON\u683c\u5f0f\u6eaf\u6e90\u6570\u636e\uff0c\u4ee5\u4f18\u5316\u5927\u89c4\u6a21AI\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u7387\u3001\u6267\u884c\u65f6\u95f4\u3001\u51c6\u786e\u6027\u548c\u80fd\u8017\u3002", "motivation": "\u968f\u7740\u5927\u89c4\u6a21AI\u6a21\u578b\u9700\u6c42\u7684\u589e\u957f\uff0c\u5982\u4f55\u5728\u8ba1\u7b97\u6548\u7387\u3001\u6267\u884c\u65f6\u95f4\u3001\u51c6\u786e\u6027\u548c\u80fd\u8017\u4e4b\u95f4\u5b9e\u73b0\u5e73\u8861\u6210\u4e3a\u5173\u952e\u6311\u6218\u3002\u6eaf\u6e90\u6570\u636e\u4e3a\u7406\u89e3\u8d44\u6e90\u4f7f\u7528\u6a21\u5f0f\u3001\u8bc6\u522b\u4f4e\u6548\u73af\u8282\u53ca\u786e\u4fddAI\u5f00\u53d1\u7684\u53ef\u91cd\u590d\u6027\u548c\u95ee\u8d23\u6027\u63d0\u4f9b\u4e86\u652f\u6301\u3002", "method": "\u63d0\u51fayProv4ML\u5e93\uff0c\u652f\u6301\u7075\u6d3b\u6269\u5c55\uff0c\u5141\u8bb8\u901a\u8fc7\u63d2\u4ef6\u96c6\u6210\u5176\u4ed6\u6570\u636e\u6536\u96c6\u5de5\u5177\uff0c\u5e76\u4e0eyProv\u6846\u67b6\u5b8c\u5168\u96c6\u6210\uff0c\u9002\u7528\u4e8e\u5de5\u4f5c\u6d41\u7ba1\u7406\u7cfb\u7edf\u3002", "result": "yProv4ML\u5e93\u80fd\u591f\u9ad8\u6548\u6536\u96c6\u548c\u5206\u6790\u6eaf\u6e90\u6570\u636e\uff0c\u5e2e\u52a9\u4f18\u5316\u8d44\u6e90\u5229\u7528\u548c\u80fd\u6e90\u6548\u7387\u3002", "conclusion": "yProv4ML\u4e3a\u5927\u89c4\u6a21AI\u6a21\u578b\u7684\u5206\u5e03\u5f0f\u8d44\u6e90\u4f18\u5316\u548c\u80fd\u6e90\u9ad8\u6548\u5229\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u652f\u6301AI\u5f00\u53d1\u7684\u900f\u660e\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2507.01037", "pdf": "https://arxiv.org/pdf/2507.01037", "abs": "https://arxiv.org/abs/2507.01037", "authors": ["Wenbin Ouyang", "Sirui Li", "Yining Ma", "Cathy Wu"], "title": "Learning to Segment for Vehicle Routing Problems", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Iterative search heuristics are widely recognized as state-of-the-art for\nsolving Vehicle Routing Problems (VRPs). In this work, we identify and exploit\na critical observation: within these solvers, a large portion of the solution\nremains stable, i.e., unchanged across search iterations, causing redundant\ncomputations, especially for large-scale VRPs with long subtours. To address\nthis, we pioneer the formal study of the First-Segment-Then-Aggregate (FSTA)\ndecomposition technique to accelerate iterative solvers. Specifically, FSTA\npreserves stable solution segments during the search, aggregates nodes within\neach segment into fixed hypernodes, and focuses the search only on unstable\nportions. Yet, a key challenge lies in identifying which segments should be\naggregated by FSTA. To this end, we then introduce Learning-to-Segment (L2Seg),\na novel neural framework to intelligently differentiate potentially stable and\nunstable portions for FSTA decomposition. We present three L2Seg variants:\nnon-autoregressive (globally comprehensive but locally indiscriminate),\nautoregressive (locally refined but globally deficient), and their synergy,\nwith bespoke training and inference strategies. Empirical results on CVRP and\nVRPTW suggest that L2Seg accelerates state-of-the-art iterative solvers by up\nto 7x. Additionally, we provide in-depth analysis showing NAR and AR synergy\nachieves best performance by combining their complementary strengths. Notably,\nL2Seg is a flexible framework that is compatible with traditional,\nlearning-based, and hybrid solvers, while supporting a broad class of VRPs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFSTA\u7684\u5206\u89e3\u6280\u672f\uff0c\u7ed3\u5408L2Seg\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u663e\u8457\u52a0\u901f\u4e86\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff08VRP\uff09\u7684\u8fed\u4ee3\u6c42\u89e3\u5668\u3002", "motivation": "\u73b0\u6709\u8fed\u4ee3\u6c42\u89e3\u5668\u5728\u89e3\u51b3\u5927\u89c4\u6a21VRP\u65f6\u5b58\u5728\u5197\u4f59\u8ba1\u7b97\u95ee\u9898\uff0c\u56e0\u4e3a\u89e3\u7684\u5927\u90e8\u5206\u5728\u8fed\u4ee3\u4e2d\u4fdd\u6301\u7a33\u5b9a\u3002", "method": "\u91c7\u7528FSTA\u6280\u672f\u4fdd\u7559\u7a33\u5b9a\u89e3\u6bb5\uff0c\u5e76\u901a\u8fc7L2Seg\u795e\u7ecf\u7f51\u7edc\u667a\u80fd\u8bc6\u522b\u7a33\u5b9a\u4e0e\u4e0d\u7a33\u5b9a\u90e8\u5206\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cL2Seg\u80fd\u5c06\u6c42\u89e3\u5668\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe7\u500d\uff0c\u4e14\u5176\u975e\u81ea\u56de\u5f52\u4e0e\u81ea\u56de\u5f52\u53d8\u4f53\u7684\u534f\u540c\u6548\u679c\u6700\u4f73\u3002", "conclusion": "L2Seg\u662f\u4e00\u4e2a\u7075\u6d3b\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u591a\u79cdVRP\u6c42\u89e3\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2507.01078", "pdf": "https://arxiv.org/pdf/2507.01078", "abs": "https://arxiv.org/abs/2507.01078", "authors": ["Gabriele Padovani", "Valentine Anantharaj", "Sandro Fiore"], "title": "yProv4ML: Effortless Provenance Tracking for Machine Learning Systems", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "The rapid growth of interest in large language models (LLMs) reflects their\npotential for flexibility and generalization, and attracted the attention of a\ndiverse range of researchers. However, the advent of these techniques has also\nbrought to light the lack of transparency and rigor with which development is\npursued. In particular, the inability to determine the number of epochs and\nother hyperparameters in advance presents challenges in identifying the best\nmodel. To address this challenge, machine learning frameworks such as MLFlow\ncan automate the collection of this type of information. However, these tools\ncapture data using proprietary formats and pose little attention to lineage.\nThis paper proposes yProv4ML, a framework to capture provenance information\ngenerated during machine learning processes in PROV-JSON format, with minimal\ncode modifications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fayProv4ML\u6846\u67b6\uff0c\u7528\u4e8e\u4ee5PROV-JSON\u683c\u5f0f\u6355\u83b7\u673a\u5668\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u6eaf\u6e90\u4fe1\u606f\uff0c\u89e3\u51b3\u73b0\u6709\u5de5\u5177\u5728\u900f\u660e\u5ea6\u548c\u6570\u636e\u683c\u5f0f\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u53d1\u5c55\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u4e25\u8c28\u6027\uff0c\u7279\u522b\u662f\u5728\u8d85\u53c2\u6570\u9009\u62e9\u548c\u6570\u636e\u6eaf\u6e90\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002\u73b0\u6709\u5de5\u5177\u5982MLFlow\u867d\u80fd\u81ea\u52a8\u5316\u6536\u96c6\u4fe1\u606f\uff0c\u4f46\u4f7f\u7528\u4e13\u6709\u683c\u5f0f\u4e14\u5ffd\u89c6\u6570\u636e\u6eaf\u6e90\u3002", "method": "\u63d0\u51fayProv4ML\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u4ee3\u7801\u4fee\u6539\u6355\u83b7\u673a\u5668\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u6eaf\u6e90\u4fe1\u606f\uff0c\u5e76\u4ee5PROV-JSON\u683c\u5f0f\u5b58\u50a8\u3002", "result": "yProv4ML\u80fd\u591f\u6709\u6548\u8bb0\u5f55\u673a\u5668\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u5173\u952e\u4fe1\u606f\uff0c\u63d0\u5347\u900f\u660e\u5ea6\u548c\u53ef\u8ffd\u6eaf\u6027\u3002", "conclusion": "yProv4ML\u4e3a\u673a\u5668\u5b66\u4e60\u5f00\u53d1\u63d0\u4f9b\u4e86\u66f4\u900f\u660e\u548c\u6807\u51c6\u5316\u7684\u6eaf\u6e90\u89e3\u51b3\u65b9\u6848\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u5de5\u5177\u7684\u4e0d\u8db3\u3002"}}
{"id": "2507.01039", "pdf": "https://arxiv.org/pdf/2507.01039", "abs": "https://arxiv.org/abs/2507.01039", "authors": ["Kaaustaaub Shankar", "Wilhelm Louw", "Kelly Cohen"], "title": "On-Policy Optimization of ANFIS Policies Using Proximal Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to NAFIPS 2025", "summary": "We propose a reinforcement learning (RL) approach for training neuro-fuzzy\ncontrollers using Proximal Policy Optimization (PPO). Building on prior work\nthat applied Deep Q-Learning to Adaptive Neuro-Fuzzy Inference Systems (ANFIS),\nour method replaces the off-policy value-based framework with a stable\non-policy actor-critic loop. We evaluate this approach in the CartPole-v1\nenvironment using multiple random seeds and compare its learning performance\nagainst ANFIS-Deep Q-Network (DQN) baselines. It was found that PPO-trained\nfuzzy agents achieved a mean return of 500 +/- 0 on CartPole-v1 after 20000\nupdates, showcasing less variance than prior DQN-based methods during training\nand overall faster convergence. These findings suggest that PPO offers a\npromising pathway for training explainable neuro-fuzzy controllers in\nreinforcement learning tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePPO\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8bad\u7ec3\u795e\u7ecf\u6a21\u7cca\u63a7\u5236\u5668\uff0c\u76f8\u6bd4\u4e4b\u524d\u7684DQN\u65b9\u6cd5\uff0c\u8868\u73b0\u51fa\u66f4\u4f4e\u7684\u65b9\u5dee\u548c\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u6539\u8fdb\u73b0\u6709\u7684\u57fa\u4e8eDQN\u7684\u795e\u7ecf\u6a21\u7cca\u63a7\u5236\u5668\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5229\u7528PPO\u7684\u7a33\u5b9a\u6027\u548c\u6548\u7387\u63d0\u5347\u6027\u80fd\u3002", "method": "\u4f7f\u7528PPO\u4ee3\u66ffDQN\uff0c\u6784\u5efa\u4e00\u4e2a\u7a33\u5b9a\u7684on-policy actor-critic\u5faa\u73af\uff0c\u5e76\u5728CartPole-v1\u73af\u5883\u4e2d\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "PPO\u8bad\u7ec3\u7684\u6a21\u7cca\u63a7\u5236\u5668\u5728CartPole-v1\u4e0a\u5b9e\u73b0\u4e86500 +/- 0\u7684\u5e73\u5747\u56de\u62a5\uff0c\u65b9\u5dee\u66f4\u5c0f\u4e14\u6536\u655b\u66f4\u5feb\u3002", "conclusion": "PPO\u4e3a\u8bad\u7ec3\u53ef\u89e3\u91ca\u7684\u795e\u7ecf\u6a21\u7cca\u63a7\u5236\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.01090", "pdf": "https://arxiv.org/pdf/2507.01090", "abs": "https://arxiv.org/abs/2507.01090", "authors": ["Riccardo Mengoni", "Walter Nadalin", "Mathys Rennela", "Jimmy Rotureau", "Tom Darras", "Julien Laurat", "Eleni Diamanti", "Ioannis Lavdas"], "title": "Efficient Gate Reordering for Distributed Quantum Compiling in Data Centers", "categories": ["quant-ph", "cs.DC"], "comment": null, "summary": "Just as classical computing relies on distributed systems, the quantum\ncomputing era requires new kinds of infrastructure and software tools. Quantum\nnetworks will become the backbone of hybrid, quantum-augmented data centers, in\nwhich quantum algorithms are distributed over a local network of quantum\nprocessing units (QPUs) interconnected via shared entanglement. In this\ncontext, it is crucial to develop methods and software that minimize the number\nof inter-QPU communications. Here we describe key features of the quantum\ncompiler araQne, which is designed to minimize distribution cost, measured by\nthe number of entangled pairs required to distribute a monolithic quantum\ncircuit using gate teleportation protocols. We establish the crucial role\nplayed by circuit reordering strategies, which strongly reduce the distribution\ncost compared to a baseline approach.", "AI": {"tldr": "\u91cf\u5b50\u7f16\u8bd1\u5668araQne\u901a\u8fc7\u7535\u8def\u91cd\u6392\u5e8f\u7b56\u7565\u51cf\u5c11\u91cf\u5b50\u7535\u8def\u5206\u5e03\u6210\u672c\uff0c\u4f18\u5316\u91cf\u5b50\u7f51\u7edc\u4e2d\u7684\u901a\u4fe1\u9700\u6c42\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u65f6\u4ee3\u9700\u8981\u65b0\u7684\u57fa\u7840\u8bbe\u65bd\u548c\u8f6f\u4ef6\u5de5\u5177\uff0c\u91cf\u5b50\u7f51\u7edc\u5c06\u6210\u4e3a\u6df7\u5408\u91cf\u5b50\u589e\u5f3a\u6570\u636e\u4e2d\u5fc3\u7684\u6838\u5fc3\uff0c\u56e0\u6b64\u9700\u8981\u51cf\u5c11\u91cf\u5b50\u5904\u7406\u5355\u5143\u95f4\u7684\u901a\u4fe1\u3002", "method": "\u5f00\u53d1\u91cf\u5b50\u7f16\u8bd1\u5668araQne\uff0c\u901a\u8fc7\u7535\u8def\u91cd\u6392\u5e8f\u7b56\u7565\u6700\u5c0f\u5316\u5206\u5e03\u6210\u672c\uff08\u4ee5\u7ea0\u7f20\u5bf9\u6570\u91cf\u8861\u91cf\uff09\u3002", "result": "\u7535\u8def\u91cd\u6392\u5e8f\u7b56\u7565\u663e\u8457\u964d\u4f4e\u4e86\u5206\u5e03\u6210\u672c\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "araQne\u7f16\u8bd1\u5668\u5728\u4f18\u5316\u91cf\u5b50\u7f51\u7edc\u901a\u4fe1\u65b9\u9762\u5177\u6709\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2507.01040", "pdf": "https://arxiv.org/pdf/2507.01040", "abs": "https://arxiv.org/abs/2507.01040", "authors": ["Tianxiang Xia", "Max Neuwinger", "Lin Xiao"], "title": "Fast Clifford Neural Layers", "categories": ["cs.LG", "cs.AI", "cs.NE", "cs.PF"], "comment": "7 pages content-wise", "summary": "Clifford Neural Layers improve PDE modeling by introducing Clifford Algebra\ninto neural networks. In this project we focus on optimizing the inference of\n2/3D Clifford convolutional layers and multivector activation layers for one\ncore CPU performance.\n  Overall, by testing on a real network block involving Clifford convolutional\nlayers and multivector activation layers, we observe that our implementation is\n30% faster than standard PyTorch implementation in relatively large data +\nnetwork size (>L2 cache).\n  We open source our code base at\nhttps://github.com/egretwAlker/c-opt-clifford-layers", "AI": {"tldr": "Clifford Neural Layers\u901a\u8fc7\u5f15\u5165Clifford\u4ee3\u6570\u4f18\u5316PDE\u5efa\u6a21\uff0c\u5728CPU\u4e0a\u5b9e\u73b0\u4e86\u6bd4\u6807\u51c6PyTorch\u5feb30%\u7684\u6027\u80fd\u3002", "motivation": "\u63d0\u5347PDE\u5efa\u6a21\u6548\u7387\uff0c\u4f18\u5316\u795e\u7ecf\u7f51\u7edc\u4e2dClifford\u5377\u79ef\u5c42\u548c\u591a\u5411\u91cf\u6fc0\u6d3b\u5c42\u7684\u63a8\u7406\u6027\u80fd\u3002", "method": "\u5728CPU\u4e0a\u4f18\u53162/3D Clifford\u5377\u79ef\u5c42\u548c\u591a\u5411\u91cf\u6fc0\u6d3b\u5c42\u7684\u5b9e\u73b0\u3002", "result": "\u5728\u8f83\u5927\u6570\u636e\u548c\u7f51\u7edc\u89c4\u6a21\u4e0b\uff0c\u6027\u80fd\u6bd4\u6807\u51c6PyTorch\u5b9e\u73b0\u5feb30%\u3002", "conclusion": "Clifford Neural Layers\u5728PDE\u5efa\u6a21\u4e2d\u5177\u6709\u663e\u8457\u6027\u80fd\u4f18\u52bf\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.01285", "pdf": "https://arxiv.org/pdf/2507.01285", "abs": "https://arxiv.org/abs/2507.01285", "authors": ["Aymen Rayane Khouas", "Mohamed Reda Bouadjenek", "Hakim Hacid", "Sunil Aryal"], "title": "Far From Sight, Far From Mind: Inverse Distance Weighting for Graph Federated Recommendation", "categories": ["cs.LG", "cs.DC", "cs.IR"], "comment": "17 pages, 5 figures", "summary": "Graph federated recommendation systems offer a privacy-preserving alternative\nto traditional centralized recommendation architectures, which often raise\nconcerns about data security. While federated learning enables personalized\nrecommendations without exposing raw user data, existing aggregation methods\noverlook the unique properties of user embeddings in this setting. Indeed,\ntraditional aggregation methods fail to account for their complexity and the\ncritical role of user similarity in recommendation effectiveness. Moreover,\nevolving user interactions require adaptive aggregation while preserving the\ninfluence of high-relevance anchor users (the primary users before expansion in\ngraph-based frameworks). To address these limitations, we introduce\nDist-FedAvg, a novel distance-based aggregation method designed to enhance\npersonalization and aggregation efficiency in graph federated learning. Our\nmethod assigns higher aggregation weights to users with similar embeddings,\nwhile ensuring that anchor users retain significant influence in local updates.\nEmpirical evaluations on multiple datasets demonstrate that Dist-FedAvg\nconsistently outperforms baseline aggregation techniques, improving\nrecommendation accuracy while maintaining seamless integration into existing\nfederated learning frameworks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8ddd\u79bb\u7684\u805a\u5408\u65b9\u6cd5Dist-FedAvg\uff0c\u7528\u4e8e\u63d0\u5347\u56fe\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u4e2a\u6027\u5316\u548c\u805a\u5408\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u805a\u5408\u65b9\u6cd5\u5ffd\u89c6\u4e86\u7528\u6237\u5d4c\u5165\u7684\u72ec\u7279\u6027\u548c\u7528\u6237\u76f8\u4f3c\u6027\u5bf9\u63a8\u8350\u6548\u679c\u7684\u5173\u952e\u4f5c\u7528\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u52a8\u6001\u7528\u6237\u4ea4\u4e92\u7684\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51faDist-FedAvg\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e3a\u76f8\u4f3c\u5d4c\u5165\u7528\u6237\u5206\u914d\u66f4\u9ad8\u6743\u91cd\uff0c\u5e76\u4fdd\u7559\u951a\u7528\u6237\u7684\u5f71\u54cd\u529b\uff0c\u4f18\u5316\u805a\u5408\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDist-FedAvg\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u63a8\u8350\u51c6\u786e\u6027\u3002", "conclusion": "Dist-FedAvg\u5728\u4fdd\u6301\u4e0e\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u517c\u5bb9\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2507.01041", "pdf": "https://arxiv.org/pdf/2507.01041", "abs": "https://arxiv.org/abs/2507.01041", "authors": ["Zuguang Li", "Wen Wu", "Shaohua Wu", "Songge Zhang", "Ye Wang", "Xuemin", "Shen"], "title": "Fast AI Model Splitting over Edge Networks", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 14 figures", "summary": "Split learning (SL) has emerged as a computationally efficient approach for\nartificial intelligence (AI) model training, which can alleviate device-side\ncomputational workloads. However, complex AI model architectures pose high\ncomputational complexity to obtain the optimal model splitting. In this paper,\nwe represent an arbitrary AI model as a directed acyclic graph (DAG), and then\nreformulate the optimal model splitting problem as a minimum s-t cut search\nproblem. To solve the problem, we propose a fast DAG-based model splitting\nalgorithm, which restructures the DAG to enable the optimal model splitting\nidentification via a maximum flow method. Theoretical analysis indicates that\nthe proposed algorithm is optimal. Furthermore, considering AI models with\nblock structures, we propose a block-wise model splitting algorithm to reduce\ncomputational complexity. The algorithm abstracts each block, i.e., a component\nconsisting of multiple layers, into a single vertex, thereby obtaining the\noptimal model splitting via a simplified DAG. Extensive experimental results\ndemonstrate that the proposed algorithms can determine the optimal model\nsplitting within milliseconds, as well as reduce training delay by\n24.62%-38.95% in dynamic edge networks as compared to the state-of-the-art\nbenchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u7684\u5feb\u901f\u6a21\u578b\u5206\u5272\u7b97\u6cd5\uff0c\u901a\u8fc7\u6700\u5927\u6d41\u65b9\u6cd5\u627e\u5230\u6700\u4f18\u5206\u5272\uff0c\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u5ef6\u8fdf\u3002", "motivation": "\u89e3\u51b3\u590d\u6742AI\u6a21\u578b\u5206\u5272\u7684\u9ad8\u8ba1\u7b97\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u63d0\u5347\u8bbe\u5907\u7aef\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u5c06AI\u6a21\u578b\u8868\u793a\u4e3aDAG\uff0c\u91cd\u65b0\u5efa\u6a21\u4e3a\u6700\u5c0fs-t\u5272\u95ee\u9898\uff0c\u63d0\u51fa\u5feb\u901fDAG\u5206\u5272\u7b97\u6cd5\u548c\u5757\u72b6\u5206\u5272\u7b97\u6cd5\u3002", "result": "\u7b97\u6cd5\u5728\u6beb\u79d2\u5185\u627e\u5230\u6700\u4f18\u5206\u5272\uff0c\u52a8\u6001\u8fb9\u7f18\u7f51\u7edc\u4e2d\u8bad\u7ec3\u5ef6\u8fdf\u964d\u4f4e24.62%-38.95%\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u8fb9\u7f18\u7f51\u7edc\u3002"}}
{"id": "2507.01453", "pdf": "https://arxiv.org/pdf/2507.01453", "abs": "https://arxiv.org/abs/2507.01453", "authors": ["Michelle Yeo", "Haoqian Zhang"], "title": "Rational Censorship Attack: Breaking Blockchain with a Blackboard", "categories": ["cs.GT", "cs.CR", "cs.DC"], "comment": null, "summary": "Censorship resilience is a fundamental assumption underlying the security of\nblockchain protocols. Additionally, the analysis of blockchain security from an\neconomic and game theoretic perspective has been growing in popularity in\nrecent years. In this work, we present a surprising rational censorship attack\non blockchain censorship resilience when we adopt the analysis of blockchain\nsecurity from a game theoretic lens and assume all users are rational. In our\nattack, a colluding group with sufficient voting power censors the remainder\nnodes such that the group alone can gain all the rewards from maintaining the\nblockchain. We show that if nodes are rational, coordinating this attack just\nrequires a public read and write blackboard and we formally model the attack\nusing a game theoretic framework. Furthermore, we note that to ensure the\nsuccess of the attack, nodes need to know the total true voting power held by\nthe colluding group. We prove that the strategy to join the rational censorship\nattack and also for nodes to honestly declare their power is a subgame perfect\nequilibrium in the corresponding extensive form game induced by our attack.\nFinally, we discuss the implications of the attack on blockchain users and\nprotocol designers as well as some potential countermeasures.", "AI": {"tldr": "\u8bba\u6587\u63ed\u793a\u4e86\u4e00\u79cd\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u7406\u6027\u5ba1\u67e5\u653b\u51fb\uff0c\u8868\u660e\u5728\u533a\u5757\u94fe\u4e2d\uff0c\u7406\u6027\u8282\u70b9\u53ef\u80fd\u901a\u8fc7\u5408\u8c0b\u5ba1\u67e5\u5176\u4ed6\u8282\u70b9\u4ee5\u72ec\u5360\u5956\u52b1\uff0c\u5e76\u8bc1\u660e\u8fd9\u79cd\u653b\u51fb\u7b56\u7565\u662f\u5b50\u535a\u5f08\u5b8c\u7f8e\u5747\u8861\u3002", "motivation": "\u7814\u7a76\u533a\u5757\u94fe\u7684\u5ba1\u67e5\u97e7\u6027\uff0c\u5e76\u4ece\u535a\u5f08\u8bba\u89d2\u5ea6\u5206\u6790\u5176\u5b89\u5168\u6027\uff0c\u63ed\u793a\u7406\u6027\u8282\u70b9\u53ef\u80fd\u7684\u884c\u4e3a\u6a21\u5f0f\u3002", "method": "\u901a\u8fc7\u535a\u5f08\u8bba\u6846\u67b6\u5efa\u6a21\uff0c\u5047\u8bbe\u6240\u6709\u8282\u70b9\u4e3a\u7406\u6027\uff0c\u63d0\u51fa\u4e00\u79cd\u5408\u8c0b\u5ba1\u67e5\u653b\u51fb\u7b56\u7565\uff0c\u5e76\u5206\u6790\u5176\u5747\u8861\u6027\u3002", "result": "\u8bc1\u660e\u5408\u8c0b\u653b\u51fb\u7b56\u7565\u662f\u5b50\u535a\u5f08\u5b8c\u7f8e\u5747\u8861\uff0c\u4e14\u653b\u51fb\u6210\u529f\u9700\u77e5\u6653\u5408\u8c0b\u8282\u70b9\u7684\u771f\u5b9e\u6295\u7968\u6743\u3002", "conclusion": "\u653b\u51fb\u5bf9\u533a\u5757\u94fe\u7528\u6237\u548c\u534f\u8bae\u8bbe\u8ba1\u8005\u5177\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u9700\u63a2\u7d22\u6f5c\u5728\u9632\u5fa1\u63aa\u65bd\u3002"}}
{"id": "2507.01043", "pdf": "https://arxiv.org/pdf/2507.01043", "abs": "https://arxiv.org/abs/2507.01043", "authors": ["Szymon \u015awiderski", "Agnieszka Jastrz\u0119bska"], "title": "Data Classification with Dynamically Growing and Shrinking Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": "Paper submitted to Journal of Computational Science", "summary": "The issue of data-driven neural network model construction is one of the core\nproblems in the domain of Artificial Intelligence. A standard approach assumes\na fixed architecture with trainable weights. A conceptually more advanced\nassumption is that we not only train the weights, but also find out the optimal\nmodel architecture. We present a new method that realizes just that. This\narticle is an extended version of our conference paper titled \"Dynamic Growing\nand Shrinking of Neural Networks with Monte Carlo Tree Search [26]\". In the\npaper, we show in detail how to create a neural network with a procedure that\nallows dynamic shrinking and growing of the model while it is being trained.\nThe decision-making mechanism for the architectural design is governed by a\nMonte Carlo tree search procedure which simulates network behavior and allows\nto compare several candidate architecture changes to choose the best one. The\nproposed method was validated using both visual and time series datasets,\ndemonstrating its particular effectiveness in multivariate time series\nclassification. This is attributed to the architecture's ability to adapt\ndynamically, allowing independent modifications for each time series. The\napproach is supplemented by Python source code for reproducibility.\nExperimental evaluations in visual pattern and multivariate time series\nclassification tasks revealed highly promising performance, underscoring the\nmethod's robustness and adaptability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u8c03\u6574\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u5b9e\u73b0\u8bad\u7ec3\u4e2d\u7684\u67b6\u6784\u4f18\u5316\uff0c\u9002\u7528\u4e8e\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u56fa\u5b9a\u67b6\u6784\u795e\u7ecf\u7f51\u7edc\u7684\u5c40\u9650\u6027\uff0c\u63a2\u7d22\u52a8\u6001\u8c03\u6574\u67b6\u6784\u4ee5\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6a21\u62df\u7f51\u7edc\u884c\u4e3a\uff0c\u52a8\u6001\u8c03\u6574\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff08\u6269\u5c55\u6216\u6536\u7f29\uff09\u3002", "result": "\u5728\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "\u52a8\u6001\u67b6\u6784\u8c03\u6574\u65b9\u6cd5\u5728\u89c6\u89c9\u548c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u9002\u5408\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u3002"}}
{"id": "2507.01770", "pdf": "https://arxiv.org/pdf/2507.01770", "abs": "https://arxiv.org/abs/2507.01770", "authors": ["Guanglu Zhang", "Qihang Shan", "Jonathan Cagan"], "title": "GPU-based complete search for nonlinear minimization subject to bounds", "categories": ["math.NA", "cs.AI", "cs.DC", "cs.MS", "cs.NA", "math.OC", "65G20, 65G30, 65G40, 90C06, 90C26, 90C30", "G.1.6; G.4"], "comment": "36 pages, 3 figures", "summary": "This paper introduces a GPU-based complete search method to enclose the\nglobal minimum of a nonlinear function subject to simple bounds on the\nvariables. Using interval analysis, coupled with the computational power and\narchitecture of GPU, the method iteratively rules out the regions in the search\ndomain where the global minimum cannot exist and leaves a finite set of regions\nwhere the global minimum must exist. For effectiveness, because of the rigor of\ninterval analysis, the method is guaranteed to enclose the global minimum of\nthe nonlinear function even in the presence of rounding errors. For efficiency,\nthe method employs a novel GPU-based single program, single data parallel\nprogramming style to circumvent major GPU performance bottlenecks, and a\nvariable cycling technique is also integrated into the method to reduce\ncomputational cost when minimizing large-scale nonlinear functions. The method\nis validated by minimizing 10 multimodal benchmark test functions with scalable\ndimensions, including the well-known Ackley function, Griewank function, Levy\nfunction, and Rastrigin function. These benchmark test functions represent\ngrand challenges of global optimization, and enclosing the guaranteed global\nminimum of these benchmark test functions with more than 80 dimensions has not\nbeen reported in the literature. Our method completely searches the feasible\ndomain and successfully encloses the guaranteed global minimum of these 10\nbenchmark test functions with up to 10,000 dimensions using only one GPU in a\nreasonable computation time, far exceeding the reported results in the\nliterature due to the unique method design and implementation based on GPU\narchitecture.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eGPU\u7684\u5168\u5c40\u641c\u7d22\u65b9\u6cd5\uff0c\u5229\u7528\u533a\u95f4\u5206\u6790\u548cGPU\u8ba1\u7b97\u80fd\u529b\uff0c\u786e\u4fdd\u5728\u975e\u7ebf\u6027\u51fd\u6570\u4e2d\u5305\u56f4\u5168\u5c40\u6700\u5c0f\u503c\u3002", "motivation": "\u89e3\u51b3\u9ad8\u7ef4\u975e\u7ebf\u6027\u51fd\u6570\u7684\u5168\u5c40\u4f18\u5316\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u5b58\u5728\u820d\u5165\u8bef\u5dee\u65f6\u4ecd\u80fd\u4fdd\u8bc1\u7ed3\u679c\u51c6\u786e\u6027\u3002", "method": "\u7ed3\u5408\u533a\u95f4\u5206\u6790\u548cGPU\u5e76\u884c\u8ba1\u7b97\uff0c\u901a\u8fc7\u6392\u9664\u4e0d\u53ef\u80fd\u533a\u57df\u548c\u53d8\u91cf\u5faa\u73af\u6280\u672f\u63d0\u9ad8\u6548\u7387\u3002", "result": "\u6210\u529f\u5305\u56f4\u4e8610\u4e2a\u9ad8\u7ef4\uff08\u6700\u9ad810,000\u7ef4\uff09\u591a\u6a21\u6001\u57fa\u51c6\u51fd\u6570\u7684\u5168\u5c40\u6700\u5c0f\u503c\uff0c\u8ba1\u7b97\u65f6\u95f4\u5408\u7406\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728GPU\u67b6\u6784\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6587\u732e\u7ed3\u679c\u3002"}}
{"id": "2507.01045", "pdf": "https://arxiv.org/pdf/2507.01045", "abs": "https://arxiv.org/abs/2507.01045", "authors": ["Xiao Gu", "Wei Tang", "Jinpei Han", "Veer Sangha", "Fenglin Liu", "Shreyank N Gowda", "Antonio H. Ribeiro", "Patrick Schwab", "Kim Branson", "Lei Clifton", "Antonio Luiz P. Ribeiro", "Zhangdaihong Liu", "David A. Clifton"], "title": "Sensing Cardiac Health Across Scenarios and Devices: A Multi-Modal Foundation Model Pretrained on Heterogeneous Data from 1.7 Million Individuals", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Cardiac biosignals, such as electrocardiograms (ECG) and photoplethysmograms\n(PPG), are of paramount importance for the diagnosis, prevention, and\nmanagement of cardiovascular diseases, and have been extensively used in a\nvariety of clinical tasks. Conventional deep learning approaches for analyzing\nthese signals typically rely on homogeneous datasets and static bespoke models,\nlimiting their robustness and generalizability across diverse clinical settings\nand acquisition protocols. In this study, we present a cardiac sensing\nfoundation model (CSFM) that leverages advanced transformer architectures and a\ngenerative, masked pretraining strategy to learn unified representations from\nvast, heterogeneous health records. Our model is pretrained on an innovative\nmulti-modal integration of data from multiple large-scale datasets (including\nMIMIC-III-WDB, MIMIC-IV-ECG, and CODE), comprising cardiac signals and the\ncorresponding clinical or machine-generated text reports from approximately 1.7\nmillion individuals. We demonstrate that the embeddings derived from our CSFM\nnot only serve as effective feature extractors across diverse cardiac sensing\nscenarios, but also enable seamless transfer learning across varying input\nconfigurations and sensor modalities. Extensive evaluations across diagnostic\ntasks, demographic information recognition, vital sign measurement, clinical\noutcome prediction, and ECG question answering reveal that CSFM consistently\noutperforms traditional one-modal-one-task approaches. Notably, CSFM exhibits\nrobust performance across multiple ECG lead configurations from standard\n12-lead systems to single-lead setups, and in scenarios where only ECG, only\nPPG, or a combination thereof is available. These findings highlight the\npotential of CSFM as a versatile and scalable solution, for comprehensive\ncardiac monitoring.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u67b6\u6784\u7684\u5fc3\u810f\u611f\u77e5\u57fa\u7840\u6a21\u578b\uff08CSFM\uff09\uff0c\u901a\u8fc7\u751f\u6210\u5f0f\u63a9\u7801\u9884\u8bad\u7ec3\u7b56\u7565\uff0c\u4ece\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6570\u636e\u4e2d\u5b66\u4e60\u7edf\u4e00\u8868\u793a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5fc3\u810f\u4fe1\u53f7\u5206\u6790\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4f9d\u8d56\u4e8e\u540c\u8d28\u6570\u636e\u96c6\u548c\u9759\u6001\u5b9a\u5236\u6a21\u578b\uff0c\u96be\u4ee5\u9002\u5e94\u591a\u6837\u5316\u7684\u4e34\u5e8a\u73af\u5883\u548c\u91c7\u96c6\u534f\u8bae\uff0c\u9650\u5236\u4e86\u5176\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u5229\u7528Transformer\u67b6\u6784\u548c\u751f\u6210\u5f0f\u63a9\u7801\u9884\u8bad\u7ec3\u7b56\u7565\uff0c\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\uff08\u5305\u62ecMIMIC-III-WDB\u3001MIMIC-IV-ECG\u548cCODE\u7b49\u6570\u636e\u96c6\uff09\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u3002", "result": "CSFM\u5728\u8bca\u65ad\u4efb\u52a1\u3001\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u8bc6\u522b\u3001\u751f\u547d\u4f53\u5f81\u6d4b\u91cf\u3001\u4e34\u5e8a\u7ed3\u679c\u9884\u6d4b\u548cECG\u95ee\u7b54\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u5355\u6a21\u6001\u5355\u4efb\u52a1\u65b9\u6cd5\uff0c\u4e14\u5728\u4e0d\u540cECG\u5bfc\u8054\u914d\u7f6e\u548c\u4f20\u611f\u5668\u6a21\u6001\u4e0b\u5747\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "CSFM\u4f5c\u4e3a\u4e00\u79cd\u591a\u529f\u80fd\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u5168\u9762\u5fc3\u810f\u76d1\u6d4b\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002"}}
{"id": "2507.01902", "pdf": "https://arxiv.org/pdf/2507.01902", "abs": "https://arxiv.org/abs/2507.01902", "authors": ["Grier M. Jones", "Hans-Arno Jacobsen"], "title": "Analyzing Common Electronic Structure Theory Algorithms for Distributed Quantum Computing", "categories": ["quant-ph", "cs.DC", "physics.chem-ph"], "comment": null, "summary": "To move towards the utility era of quantum computing, many corporations have\nposed distributed quantum computing (DQC) as a framework for scaling the\ncurrent generation of devices for practical applications. One of these\napplications is quantum chemistry, also known as electronic structure theory,\nwhich has been poised as a \"killer application\" of quantum computing, To this\nend, we analyze five electronic structure methods, found in common packages\nsuch as Tequila and ffsim, which can be easily interfaced with the Qiskit\nCircuit Cutting addon. Herein, we provide insights into cutting these\nalgorithms using local operations (LO) to determine their aptitude for\ndistribution. The key findings of our work are that many of these algorithms\ncannot be efficiently parallelized using LO, and new methods must be developed\nto apply electronic structure theory within a DQC framework.", "AI": {"tldr": "\u5206\u6790\u4e86\u4e94\u79cd\u7535\u5b50\u7ed3\u6784\u65b9\u6cd5\u5728\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\uff08DQC\uff09\u4e2d\u7684\u9002\u7528\u6027\uff0c\u53d1\u73b0\u591a\u6570\u65b9\u6cd5\u65e0\u6cd5\u901a\u8fc7\u5c40\u90e8\u64cd\u4f5c\uff08LO\uff09\u9ad8\u6548\u5e76\u884c\u5316\uff0c\u9700\u5f00\u53d1\u65b0\u65b9\u6cd5\u3002", "motivation": "\u63a8\u52a8\u91cf\u5b50\u8ba1\u7b97\u8fdb\u5165\u5b9e\u7528\u9636\u6bb5\uff0c\u63a2\u7d22\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\uff08DQC\uff09\u5728\u91cf\u5b50\u5316\u5b66\uff08\u7535\u5b50\u7ed3\u6784\u7406\u8bba\uff09\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u5206\u6790\u4e94\u79cd\u5e38\u89c1\u7535\u5b50\u7ed3\u6784\u65b9\u6cd5\uff08\u5982Tequila\u548cffsim\u4e2d\u7684\u65b9\u6cd5\uff09\uff0c\u7ed3\u5408Qiskit Circuit Cutting\u63d2\u4ef6\uff0c\u8bc4\u4f30\u5176\u901a\u8fc7\u5c40\u90e8\u64cd\u4f5c\uff08LO\uff09\u5207\u5272\u548c\u5206\u5e03\u7684\u80fd\u529b\u3002", "result": "\u591a\u6570\u7535\u5b50\u7ed3\u6784\u65b9\u6cd5\u65e0\u6cd5\u901a\u8fc7LO\u9ad8\u6548\u5e76\u884c\u5316\uff0c\u9650\u5236\u4e86\u5176\u5728DQC\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "\u9700\u5f00\u53d1\u65b0\u65b9\u6cd5\u4ee5\u5b9e\u73b0\u7535\u5b50\u7ed3\u6784\u7406\u8bba\u5728DQC\u6846\u67b6\u4e2d\u7684\u6709\u6548\u5e94\u7528\u3002"}}
{"id": "2507.01047", "pdf": "https://arxiv.org/pdf/2507.01047", "abs": "https://arxiv.org/abs/2507.01047", "authors": ["Logan A. Burnett", "Umme Mahbuba Nabila", "Majdi I. Radaideh"], "title": "Variational Digital Twins", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "33 pages, 14 figures, and 7 tables", "summary": "While digital twins (DT) hold promise for providing real-time insights into\ncomplex energy assets, much of the current literature either does not offer a\nclear framework for information exchange between the model and the asset, lacks\nkey features needed for real-time implementation, or gives limited attention to\nmodel uncertainty. Here, we aim to solve these gaps by proposing a variational\ndigital twin (VDT) framework that augments standard neural architectures with a\nsingle Bayesian output layer. This lightweight addition, along with a novel VDT\nupdating algorithm, lets a twin update in seconds on commodity GPUs while\nproducing calibrated uncertainty bounds that can inform experiment design,\ncontrol algorithms, and model reliability. The VDT is evaluated on four\nenergy-sector problems. For critical-heat-flux prediction, uncertainty-driven\nactive learning reaches R2 = 0.98 using 47 % fewer experiments and one-third\nthe training time of random sampling. A three-year renewable-generation twin\nmaintains R2 > 0.95 for solar output and curbs error growth for volatile wind\nforecasts via monthly updates that process only one month of data at a time. A\nnuclear reactor transient cooldown twin reconstructs thermocouple signals with\nR2 > 0.99 and preserves accuracy after 50 % sensor loss, demonstrating\nrobustness to degraded instrumentation. Finally, a physics-informed Li-ion\nbattery twin, retrained after every ten discharges, lowers voltage mean-squared\nerror by an order of magnitude relative to the best static model while adapting\nits credible intervals as the cell approaches end-of-life. These results\ndemonstrate that combining modest Bayesian augmentation with efficient update\nschemes turns conventional surrogates into uncertainty-aware, data-efficient,\nand computationally tractable DTs, paving the way for dependable models across\nindustrial and scientific energy systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53d8\u5206\u6570\u5b57\u5b6a\u751f\uff08VDT\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u8f93\u51fa\u5c42\u548c\u9ad8\u6548\u66f4\u65b0\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u5b57\u5b6a\u751f\u5728\u5b9e\u65f6\u6027\u3001\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u548c\u4fe1\u606f\u4ea4\u6362\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524d\u6570\u5b57\u5b6a\u751f\u6280\u672f\u7f3a\u4e4f\u5b9e\u65f6\u5b9e\u73b0\u7684\u5173\u952e\u7279\u6027\u3001\u4fe1\u606f\u4ea4\u6362\u6846\u67b6\u6216\u5bf9\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u5173\u6ce8\uff0cVDT\u65e8\u5728\u586b\u8865\u8fd9\u4e9b\u7a7a\u767d\u3002", "method": "VDT\u6846\u67b6\u5728\u6807\u51c6\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4e2d\u589e\u52a0\u4e86\u4e00\u4e2a\u8d1d\u53f6\u65af\u8f93\u51fa\u5c42\uff0c\u5e76\u91c7\u7528\u65b0\u578b\u66f4\u65b0\u7b97\u6cd5\uff0c\u4f7f\u5176\u80fd\u5728\u666e\u901aGPU\u4e0a\u5feb\u901f\u66f4\u65b0\u5e76\u63d0\u4f9b\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\u8fb9\u754c\u3002", "result": "\u5728\u56db\u4e2a\u80fd\u6e90\u9886\u57df\u95ee\u9898\u4e2d\u9a8c\u8bc1\u4e86VDT\u7684\u6709\u6548\u6027\uff0c\u5305\u62ec\u4e34\u754c\u70ed\u901a\u91cf\u9884\u6d4b\u3001\u53ef\u518d\u751f\u80fd\u6e90\u53d1\u7535\u9884\u6d4b\u3001\u6838\u53cd\u5e94\u5806\u77ac\u6001\u51b7\u5374\u548c\u9502\u79bb\u5b50\u7535\u6c60\u5efa\u6a21\uff0c\u5747\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "VDT\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8d1d\u53f6\u65af\u589e\u5f3a\u548c\u9ad8\u6548\u66f4\u65b0\u65b9\u6848\uff0c\u5c06\u4f20\u7edf\u4ee3\u7406\u6a21\u578b\u8f6c\u5316\u4e3a\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u3001\u6570\u636e\u9ad8\u6548\u548c\u8ba1\u7b97\u53ef\u884c\u7684\u6570\u5b57\u5b6a\u751f\uff0c\u4e3a\u80fd\u6e90\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u9760\u6a21\u578b\u3002"}}
{"id": "2507.01048", "pdf": "https://arxiv.org/pdf/2507.01048", "abs": "https://arxiv.org/abs/2507.01048", "authors": ["Ricardo Emanuel Vaz Vargas", "Afr\u00e2nio Jos\u00e9 de Melo Junior", "Celso Jos\u00e9 Munaro", "Cl\u00e1udio Benevenuto de Campos Lima", "Eduardo Toledo de Lima Junior", "Felipe Muntzberg Barrocas", "Fl\u00e1vio Miguel Varej\u00e3o", "Guilherme Fidelis Peixer", "Igor de Melo Nery Oliveira", "Jader Riso Barbosa Jr.", "Jaime Andr\u00e9s Lozano Cadena", "Jean Carlos Dias de Ara\u00fajo", "Jo\u00e3o Neuenschwander Escosteguy Carneiro", "Lucas Gouveia Omena Lopes", "Lucas Pereira de Gouveia", "Mateus de Araujo Fernandes", "Matheus Lima Scramignon", "Patrick Marques Ciarelli", "Rodrigo Castello Branco", "Rog\u00e9rio Leite Alves Pinto"], "title": "3W Dataset 2.0.0: a realistic and public dataset with rare undesirable real events in oil wells", "categories": ["cs.LG"], "comment": "21 pages, 10 figures, and 7 tables", "summary": "In the oil industry, undesirable events in oil wells can cause economic\nlosses, environmental accidents, and human casualties. Solutions based on\nArtificial Intelligence and Machine Learning for Early Detection of such events\nhave proven valuable for diverse applications across industries. In 2019,\nrecognizing the importance and the lack of public datasets related to\nundesirable events in oil wells, Petrobras developed and publicly released the\nfirst version of the 3W Dataset, which is essentially a set of Multivariate\nTime Series labeled by experts. Since then, the 3W Dataset has been developed\ncollaboratively and has become a foundational reference for numerous works in\nthe field. This data article describes the current publicly available version\nof the 3W Dataset, which contains structural modifications and additional\nlabeled data. The detailed description provided encourages and supports the 3W\ncommunity and new 3W users to improve previous published results and to develop\nnew robust methodologies, digital products and services capable of detecting\nundesirable events in oil wells with enough anticipation to enable corrective\nor mitigating actions.", "AI": {"tldr": "Petrobras\u53d1\u5e03\u76843W\u6570\u636e\u96c6\u662f\u7528\u4e8e\u77f3\u6cb9\u4e95\u4e0d\u826f\u4e8b\u4ef6\u65e9\u671f\u68c0\u6d4b\u7684\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\uff0c\u7ecf\u8fc7\u4e13\u5bb6\u6807\u6ce8\uff0c\u652f\u6301AI\u548c\u673a\u5668\u5b66\u4e60\u7814\u7a76\u3002", "motivation": "\u77f3\u6cb9\u4e95\u4e0d\u826f\u4e8b\u4ef6\u53ef\u80fd\u5bfc\u81f4\u7ecf\u6d4e\u635f\u5931\u3001\u73af\u5883\u4e8b\u6545\u548c\u4eba\u5458\u4f24\u4ea1\uff0c\u9700\u8981\u65e9\u671f\u68c0\u6d4b\u6280\u672f\u3002\u7f3a\u4e4f\u516c\u5f00\u6570\u636e\u96c6\u4fc3\u4f7fPetrobras\u5f00\u53d1\u5e76\u516c\u5f003W\u6570\u636e\u96c6\u3002", "method": "3W\u6570\u636e\u96c6\u662f\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u7531\u4e13\u5bb6\u6807\u6ce8\uff0c\u5e76\u901a\u8fc7\u534f\u4f5c\u5f00\u53d1\u4e0d\u65ad\u6539\u8fdb\u3002", "result": "3W\u6570\u636e\u96c6\u5df2\u6210\u4e3a\u8be5\u9886\u57df\u7684\u57fa\u7840\u53c2\u8003\uff0c\u652f\u6301\u65b0\u65b9\u6cd5\u548c\u6570\u5b57\u4ea7\u54c1\u7684\u5f00\u53d1\u3002", "conclusion": "3W\u6570\u636e\u96c6\u7684\u8be6\u7ec6\u63cf\u8ff0\u9f13\u52b1\u793e\u533a\u6539\u8fdb\u73b0\u6709\u6210\u679c\u5e76\u5f00\u53d1\u65b0\u65b9\u6cd5\uff0c\u4ee5\u63d0\u524d\u68c0\u6d4b\u4e0d\u826f\u4e8b\u4ef6\u3002"}}
{"id": "2507.01050", "pdf": "https://arxiv.org/pdf/2507.01050", "abs": "https://arxiv.org/abs/2507.01050", "authors": ["Jing Yu", "Yibo Zhao", "Jiapeng Zhu", "Wenming Shao", "Bo Pang", "Zhao Zhang", "Xiang Li"], "title": "Text Detoxification: Data Efficiency, Semantic Preservation and Model Generalization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The widespread dissemination of toxic content on social media poses a serious\nthreat to both online environments and public discourse, highlighting the\nurgent need for detoxification methods that effectively remove toxicity while\npreserving the original semantics. However, existing approaches often struggle\nto simultaneously achieve strong detoxification performance, semantic\npreservation, and robustness to out-of-distribution data. Moreover, they\ntypically rely on costly, manually annotated parallel corpora while showing\npoor data efficiency. To address these challenges, we propose a two-stage\ntraining framework that jointly optimizes for data efficiency, semantic\npreservation, and model generalization. We first perform supervised fine-tuning\non a small set of high-quality, filtered parallel data to establish a strong\ninitialization. Then, we leverage unlabeled toxic inputs and a custom-designed\nreward model to train the LLM using Group Relative Policy Optimization.\nExperimental results demonstrate that our method effectively mitigates the\ntrade-offs faced by previous work, achieving state-of-the-art performance with\nimproved generalization and significantly reduced dependence on annotated data.\nOur code is available at:\nhttps://anonymous.4open.science/r/Detoxification-of-Text-725F/", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u53bb\u6bd2\u5316\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\uff0c\u540c\u65f6\u4fdd\u6301\u8bed\u4e49\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e2d\u5e7f\u6cdb\u4f20\u64ad\u7684\u6709\u6bd2\u5185\u5bb9\u5bf9\u73af\u5883\u548c\u516c\u5171\u8ba8\u8bba\u6784\u6210\u5a01\u80c1\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u53bb\u6bd2\u5316\u6027\u80fd\u3001\u8bed\u4e49\u4fdd\u7559\u548c\u6570\u636e\u6548\u7387\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1a\u5148\u7528\u9ad8\u8d28\u91cf\u5e76\u884c\u6570\u636e\u76d1\u7763\u5fae\u8c03\uff0c\u518d\u7528\u65e0\u6807\u7b7e\u6570\u636e\u548c\u5956\u52b1\u6a21\u578b\u901a\u8fc7Group Relative Policy Optimization\u8bad\u7ec3LLM\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u5e73\u8861\u4e86\u53bb\u6bd2\u5316\u3001\u8bed\u4e49\u4fdd\u7559\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u51cf\u5c11\u4e86\u5bf9\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u53bb\u6bd2\u5316\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u6570\u636e\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.01052", "pdf": "https://arxiv.org/pdf/2507.01052", "abs": "https://arxiv.org/abs/2507.01052", "authors": ["Ahmed Farooq"], "title": "Long-Sequence Memory with Temporal Kernels and Dense Hopfield Functionals", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "In this study we introduce a novel energy functional for long-sequence\nmemory, building upon the framework of dense Hopfield networks which achieves\nexponential storage capacity through higher-order interactions. Building upon\nearlier work on long-sequence Hopfield memory models, we propose a temporal\nkernal $K(m, k)$ to incorporate temporal dependencies, enabling efficient\nsequential retrieval of patterns over extended sequences. We demonstrate the\nsuccessful application of this technique for the storage and sequential\nretrieval of movies frames which are well suited for this because of the high\ndimensional vectors that make up each frame creating enough variation between\neven sequential frames in the high dimensional space. The technique has\napplications in modern transformer architectures, including efficient\nlong-sequence modeling, memory augmentation, improved attention with temporal\nbias, and enhanced handling of long-term dependencies in time-series data. Our\nmodel offers a promising approach to address the limitations of transformers in\nlong-context tasks, with potential implications for natural language\nprocessing, forecasting, and beyond.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u80fd\u91cf\u51fd\u6570\uff0c\u7528\u4e8e\u957f\u5e8f\u5217\u8bb0\u5fc6\uff0c\u57fa\u4e8e\u5bc6\u96c6Hopfield\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u9636\u4ea4\u4e92\u5b9e\u73b0\u6307\u6570\u5b58\u50a8\u5bb9\u91cf\u3002", "motivation": "\u89e3\u51b3\u957f\u5e8f\u5217\u4efb\u52a1\u4e2dTransformer\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5982\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u548c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u957f\u671f\u4f9d\u8d56\u5904\u7406\u3002", "method": "\u5f15\u5165\u65f6\u95f4\u6838$K(m, k)$\u4ee5\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u5b9e\u73b0\u9ad8\u6548\u5e8f\u5217\u6a21\u5f0f\u68c0\u7d22\u3002", "result": "\u6210\u529f\u5e94\u7528\u4e8e\u7535\u5f71\u5e27\u7684\u5b58\u50a8\u548c\u5e8f\u5217\u68c0\u7d22\uff0c\u5c55\u793a\u4e86\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5bf9\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6709\u6f5c\u5728\u5f71\u54cd\u3002"}}
{"id": "2507.01054", "pdf": "https://arxiv.org/pdf/2507.01054", "abs": "https://arxiv.org/abs/2507.01054", "authors": ["Jithendaraa Subramanian", "Linda Hung", "Daniel Schweigert", "Santosh Suram", "Weike Ye"], "title": "XxaCT-NN: Structure Agnostic Multimodal Learning for Materials Science", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI"], "comment": "10 pages, 6 figures", "summary": "Recent advances in materials discovery have been driven by structure-based\nmodels, particularly those using crystal graphs. While effective for\ncomputational datasets, these models are impractical for real-world\napplications where atomic structures are often unknown or difficult to obtain.\nWe propose a scalable multimodal framework that learns directly from elemental\ncomposition and X-ray diffraction (XRD) -- two of the more available modalities\nin experimental workflows without requiring crystal structure input. Our\narchitecture integrates modality-specific encoders with a cross-attention\nfusion module and is trained on the 5-million-sample Alexandria dataset. We\npresent masked XRD modeling (MXM), and apply MXM and contrastive alignment as\nself-supervised pretraining strategies. Pretraining yields faster convergence\n(up to 4.2x speedup) and improves both accuracy and representation quality. We\nfurther demonstrate that multimodal performance scales more favorably with\ndataset size than unimodal baselines, with gains compounding at larger data\nregimes. Our results establish a path toward structure-free, experimentally\ngrounded foundation models for materials science.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5143\u7d20\u7ec4\u6210\u548cXRD\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u65e0\u9700\u6676\u4f53\u7ed3\u6784\u8f93\u5165\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u7b56\u7565\u63d0\u5347\u6750\u6599\u53d1\u73b0\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u57fa\u4e8e\u6676\u4f53\u7ed3\u6784\u7684\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u56e0\u7ed3\u6784\u6570\u636e\u96be\u4ee5\u83b7\u53d6\u800c\u4e0d\u5b9e\u7528\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u591a\u6a21\u6001\u6846\u67b6\uff0c\u7ed3\u5408\u5143\u7d20\u7ec4\u6210\u548cXRD\u6570\u636e\uff0c\u4f7f\u7528\u63a9\u7801XRD\u5efa\u6a21\u548c\u5bf9\u6bd4\u5bf9\u9f50\u4f5c\u4e3a\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u9884\u8bad\u7ec3\u663e\u8457\u52a0\u901f\u6536\u655b\uff08\u6700\u9ad84.2\u500d\uff09\uff0c\u63d0\u5347\u51c6\u786e\u6027\u548c\u8868\u793a\u8d28\u91cf\uff0c\u591a\u6a21\u6001\u6027\u80fd\u968f\u6570\u636e\u89c4\u6a21\u6269\u5c55\u66f4\u4f18\u3002", "conclusion": "\u4e3a\u6750\u6599\u79d1\u5b66\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u7ed3\u6784\u8f93\u5165\u3001\u57fa\u4e8e\u5b9e\u9a8c\u6570\u636e\u7684\u901a\u7528\u6a21\u578b\u8def\u5f84\u3002"}}
{"id": "2507.01056", "pdf": "https://arxiv.org/pdf/2507.01056", "abs": "https://arxiv.org/abs/2507.01056", "authors": ["Lidan Peng", "Lu Gao", "Feng Hong", "Jingran Sun"], "title": "Evaluating Pavement Deterioration Rates Due to Flooding Events Using Explainable AI", "categories": ["cs.LG"], "comment": null, "summary": "Flooding can damage pavement infrastructure significantly, causing both\nimmediate and long-term structural and functional issues. This research\ninvestigates how flooding events affect pavement deterioration, specifically\nfocusing on measuring pavement roughness by the International Roughness Index\n(IRI). To quantify these effects, we utilized 20 years of pavement condition\ndata from TxDOT's PMIS database, which is integrated with flood event data,\nincluding duration and spatial extent. Statistical analyses were performed to\ncompare IRI values before and after flooding and to calculate the deterioration\nrates influenced by flood exposure. Moreover, we applied Explainable Artificial\nIntelligence (XAI) techniques, such as SHapley Additive exPlanations (SHAP) and\nLocal Interpretable Model-Agnostic Explanations (LIME), to assess the impact of\nflooding on pavement performance. The results demonstrate that flood-affected\npavements experience a more rapid increase in roughness compared to non-flooded\nsections. These findings emphasize the need for proactive flood mitigation\nstrategies, including improved drainage systems, flood-resistant materials, and\npreventative maintenance, to enhance pavement resilience in vulnerable regions.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u6d2a\u6c34\u5bf9\u8def\u9762\u7c97\u7cd9\u5ea6\u7684\u5f71\u54cd\uff0c\u5229\u752820\u5e74\u6570\u636e\u548cXAI\u6280\u672f\u5206\u6790\u6d2a\u6c34\u5bf9\u8def\u9762\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6d2a\u6c34\u52a0\u901f\u8def\u9762\u7c97\u7cd9\u5ea6\u589e\u52a0\uff0c\u5efa\u8bae\u91c7\u53d6\u9632\u6d2a\u63aa\u65bd\u3002", "motivation": "\u6d2a\u6c34\u5bf9\u8def\u9762\u57fa\u7840\u8bbe\u65bd\u9020\u6210\u4e25\u91cd\u635f\u5bb3\uff0c\u7814\u7a76\u65e8\u5728\u91cf\u5316\u6d2a\u6c34\u5bf9\u8def\u9762\u7c97\u7cd9\u5ea6\u7684\u5f71\u54cd\u3002", "method": "\u6574\u540820\u5e74\u8def\u9762\u6570\u636e\u548c\u6d2a\u6c34\u4e8b\u4ef6\u6570\u636e\uff0c\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\uff0c\u5e76\u5e94\u7528XAI\u6280\u672f\uff08\u5982SHAP\u548cLIME\uff09\u8bc4\u4f30\u5f71\u54cd\u3002", "result": "\u6d2a\u6c34\u8def\u6bb5\u7684\u8def\u9762\u7c97\u7cd9\u5ea6\u589e\u52a0\u901f\u5ea6\u663e\u8457\u5feb\u4e8e\u975e\u6d2a\u6c34\u8def\u6bb5\u3002", "conclusion": "\u9700\u91c7\u53d6\u9632\u6d2a\u63aa\u65bd\uff08\u5982\u6539\u8fdb\u6392\u6c34\u7cfb\u7edf\u548c\u4f7f\u7528\u6297\u6d2a\u6750\u6599\uff09\u4ee5\u63d0\u9ad8\u8def\u9762\u5728\u6613\u53d7\u707e\u533a\u57df\u7684\u97e7\u6027\u3002"}}
{"id": "2507.01057", "pdf": "https://arxiv.org/pdf/2507.01057", "abs": "https://arxiv.org/abs/2507.01057", "authors": ["Lushun Fan", "Yuqin Xia", "Jun Li", "Karl Jenkins"], "title": "Loop2Net: Data-Driven Generation and Optimization of Airfoil CFD Meshes from Sparse Boundary Coordinates", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "In this study, an innovative intelligent optimization system for mesh quality\nis proposed, which is based on a deep convolutional neural network\narchitecture, to achieve mesh generation and optimization. The core of the\nstudy is the Loop2Net generator and loss function, it predicts the mesh based\non the given wing coordinates. And the model's performance is continuously\noptimised by two key loss functions during the training. Then discipline by\nadding penalties, the goal of mesh generation was finally reached.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u667a\u80fd\u4f18\u5316\u7cfb\u7edf\uff0c\u7528\u4e8e\u7f51\u683c\u751f\u6210\u548c\u4f18\u5316\uff0c\u6838\u5fc3\u662fLoop2Net\u751f\u6210\u5668\u548c\u635f\u5931\u51fd\u6570\u3002", "motivation": "\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u5b9e\u73b0\u9ad8\u6548\u7684\u7f51\u683c\u751f\u6210\u548c\u4f18\u5316\uff0c\u63d0\u5347\u7f51\u683c\u8d28\u91cf\u3002", "method": "\u4f7f\u7528Loop2Net\u751f\u6210\u5668\u548c\u4e24\u4e2a\u5173\u952e\u635f\u5931\u51fd\u6570\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u901a\u8fc7\u60e9\u7f5a\u673a\u5236\u4f18\u5316\u6a21\u578b\u6027\u80fd\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u57fa\u4e8e\u7ed9\u5b9a\u7ffc\u5750\u6807\u7684\u7f51\u683c\u9884\u6d4b\u548c\u4f18\u5316\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u63d0\u5347\u7f51\u683c\u751f\u6210\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002"}}
{"id": "2507.01068", "pdf": "https://arxiv.org/pdf/2507.01068", "abs": "https://arxiv.org/abs/2507.01068", "authors": ["Biplov Paneru"], "title": "Prediction of Freezing of Gait in Parkinsons Disease using Explainable AI and Federated Deep Learning for Wearable Sensors", "categories": ["cs.LG"], "comment": null, "summary": "This study leverages an Inertial Measurement Unit (IMU) dataset to develop\nexplainable AI methods for the early detection and prediction of Freezing of\nGait (FOG), a common symptom in Parkinson's disease. Machine learning models,\nincluding CatBoost, XGBoost, and Extra Trees classifiers, are employed to\naccurately categorize FOG episodes based on relevant clinical features. A\nStacking Ensemble model achieves superior performance, surpassing a hybrid\nbidirectional GRU model and reaching nearly 99% classification accuracy. SHAP\ninterpretability analysis reveals that time (seconds) is the most influential\nfactor in distinguishing gait patterns. Additionally, the proposed FOG\nprediction framework incorporates federated learning, where models are trained\nlocally on individual devices and aggregated on a central server using a\nfederated averaging approach, utilizing a hybrid Conv1D + LSTM architecture for\nenhanced predictive capability.", "AI": {"tldr": "\u5229\u7528IMU\u6570\u636e\u548c\u53ef\u89e3\u91caAI\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u65e9\u671f\u68c0\u6d4b\u548c\u9884\u6d4b\u5e15\u91d1\u68ee\u75c5\u51bb\u7ed3\u6b65\u6001\uff08FOG\uff09\u7684\u6846\u67b6\uff0c\u96c6\u6210\u6a21\u578b\u8868\u73b0\u4f18\u5f02\uff0c\u51c6\u786e\u7387\u8fbe99%\u3002", "motivation": "\u89e3\u51b3\u5e15\u91d1\u68ee\u75c5\u60a3\u8005\u5e38\u89c1\u7684\u51bb\u7ed3\u6b65\u6001\uff08FOG\uff09\u65e9\u671f\u68c0\u6d4b\u548c\u9884\u6d4b\u95ee\u9898\uff0c\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u4f7f\u7528CatBoost\u3001XGBoost\u548cExtra Trees\u5206\u7c7b\u5668\uff0c\u7ed3\u5408Stacking Ensemble\u6a21\u578b\u548cSHAP\u5206\u6790\uff0c\u5e76\u5f15\u5165\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u3002", "result": "Stacking Ensemble\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u63a5\u8fd199%\uff0c\u65f6\u95f4\u56e0\u7d20\u5bf9\u6b65\u6001\u6a21\u5f0f\u533a\u5206\u5f71\u54cd\u6700\u5927\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u5728FOG\u68c0\u6d4b\u548c\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u5b9e\u7528\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2507.01073", "pdf": "https://arxiv.org/pdf/2507.01073", "abs": "https://arxiv.org/abs/2507.01073", "authors": ["Dian Jin"], "title": "Rotational Sampling: A Plug-and-Play Encoder for Rotation-Invariant 3D Molecular GNNs", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Graph neural networks (GNNs) have achieved remarkable success in molecular\nproperty prediction. However, traditional graph representations struggle to\neffectively encode the inherent 3D spatial structures of molecules, as\nmolecular orientations in 3D space introduce significant variability, severely\nlimiting model generalization and robustness. Existing approaches primarily\nfocus on rotation-invariant and rotation-equivariant methods. Invariant methods\noften rely heavily on prior knowledge and lack sufficient generalizability,\nwhile equivariant methods suffer from high computational costs. To address\nthese limitations, this paper proposes a novel plug-and-play 3D encoding module\nleveraging rotational sampling. By computing the expectation over the SO(3)\nrotational group, the method naturally achieves approximate rotational\ninvariance. Furthermore, by introducing a carefully designed post-alignment\nstrategy, strict invariance can be achieved without compromising performance.\nExperimental evaluations on the QM9 and C10 Datasets demonstrate superior\npredictive accuracy, robustness, and generalization performance compared to\nexisting methods. Moreover, the proposed approach maintains low computational\ncomplexity and enhanced interpretability, providing a promising direction for\nefficient and effective handling of 3D molecular information in drug discovery\nand material design.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u76843D\u7f16\u7801\u6a21\u5757\uff0c\u901a\u8fc7\u65cb\u8f6c\u91c7\u6837\u5b9e\u73b0\u8fd1\u4f3c\u65cb\u8f6c\u4e0d\u53d8\u6027\uff0c\u5e76\u901a\u8fc7\u540e\u5bf9\u9f50\u7b56\u7565\u4e25\u683c\u5b9e\u73b0\u4e0d\u53d8\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u5b50\u5c5e\u6027\u9884\u6d4b\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u56fe\u8868\u793a\u96be\u4ee5\u6709\u6548\u7f16\u7801\u5206\u5b50\u76843D\u7a7a\u95f4\u7ed3\u6784\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u5148\u9a8c\u77e5\u8bc6\uff0c\u8981\u4e48\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSO(3)\u65cb\u8f6c\u7fa4\u671f\u671b\u8ba1\u7b97\u76843D\u7f16\u7801\u6a21\u5757\uff0c\u7ed3\u5408\u540e\u5bf9\u9f50\u7b56\u7565\u5b9e\u73b0\u4e25\u683c\u65cb\u8f6c\u4e0d\u53d8\u6027\u3002", "result": "\u5728QM9\u548cC10\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u836f\u7269\u53d1\u73b0\u548c\u6750\u6599\u8bbe\u8ba1\u4e2d\u76843D\u5206\u5b50\u4fe1\u606f\u5904\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01077", "pdf": "https://arxiv.org/pdf/2507.01077", "abs": "https://arxiv.org/abs/2507.01077", "authors": ["Bogdan Bogdan", "Arina Cazacu", "Laura Vasilie"], "title": "Good Enough to Learn: LLM-based Anomaly Detection in ECU Logs without Reliable Labels", "categories": ["cs.LG"], "comment": "6 pages, 7 figures, 4 tables, accepted to IEEE Intelligent Vehicles\n  Symposium (IV) 2025", "summary": "Anomaly detection often relies on supervised or clustering approaches, with\nlimited success in specialized domains like automotive communication systems\nwhere scalable solutions are essential. We propose a novel decoder-only Large\nLanguage Model (LLM) to detect anomalies in Electronic Control Unit (ECU)\ncommunication logs. Our approach addresses two key challenges: the lack of LLMs\ntailored for ECU communication and the complexity of inconsistent ground truth\ndata. By learning from UDP communication logs, we formulate anomaly detection\nsimply as identifying deviations in time from normal behavior. We introduce an\nentropy regularization technique that increases model's uncertainty in known\nanomalies while maintaining consistency in similar scenarios. Our solution\noffers three novelties: a decoder-only anomaly detection architecture, a way to\nhandle inconsistent labeling, and an adaptable LLM for different ECU\ncommunication use cases. By leveraging the generative capabilities of\ndecoder-only models, we present a new technique that addresses the high cost\nand error-prone nature of manual labeling through a more scalable system that\nis able to learn from a minimal set of examples, while improving detection\naccuracy in complex communication environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89e3\u7801\u5668\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u7528\u4e8e\u68c0\u6d4b\u7535\u5b50\u63a7\u5236\u5355\u5143\uff08ECU\uff09\u901a\u4fe1\u65e5\u5fd7\u4e2d\u7684\u5f02\u5e38\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u4e13\u4e1a\u9886\u57df\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5728\u6c7d\u8f66\u901a\u4fe1\u7cfb\u7edf\u7b49\u4e13\u4e1a\u9886\u57df\u4e2d\u6548\u679c\u6709\u9650\uff0c\u4e14\u7f3a\u4e4f\u9488\u5bf9ECU\u901a\u4fe1\u7684LLM\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u89e3\u7801\u5668LLM\u5b66\u4e60UDP\u901a\u4fe1\u65e5\u5fd7\uff0c\u901a\u8fc7\u65f6\u95f4\u504f\u5dee\u68c0\u6d4b\u5f02\u5e38\uff0c\u5e76\u5f15\u5165\u71b5\u6b63\u5219\u5316\u6280\u672f\u5904\u7406\u4e0d\u4e00\u81f4\u7684\u6807\u6ce8\u6570\u636e\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u7801\u5668\u5f02\u5e38\u68c0\u6d4b\u67b6\u6784\uff0c\u80fd\u591f\u5904\u7406\u4e0d\u4e00\u81f4\u6807\u6ce8\uff0c\u5e76\u9002\u5e94\u4e0d\u540cECU\u901a\u4fe1\u573a\u666f\uff0c\u63d0\u9ad8\u4e86\u68c0\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u751f\u6210\u80fd\u529b\u51cf\u5c11\u4e86\u624b\u52a8\u6807\u6ce8\u7684\u9ad8\u6210\u672c\u548c\u9519\u8bef\uff0c\u4e3a\u590d\u6742\u901a\u4fe1\u73af\u5883\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01080", "pdf": "https://arxiv.org/pdf/2507.01080", "abs": "https://arxiv.org/abs/2507.01080", "authors": ["Edouard Lansiaux", "Ramy Azzouz", "Emmanuel Chazard", "Am\u00e9lie Vromant", "Eric Wiel"], "title": "Development and Comparative Evaluation of Three Artificial Intelligence Models (NLP, LLM, JEPA) for Predicting Triage in Emergency Departments: A 7-Month Retrospective Proof-of-Concept", "categories": ["cs.LG", "cs.PF"], "comment": "15 pages, 6 figures", "summary": "Triage errors, including undertriage and overtriage, are persistent\nchallenges in emergency departments (EDs). With increasing patient influx and\nstaff shortages, the integration of artificial intelligence (AI) into triage\nprotocols has gained attention. This study compares the performance of three AI\nmodels [Natural Language Processing (NLP), Large Language Models (LLM), and\nJoint Embedding Predictive Architecture (JEPA)] in predicting triage outcomes\nagainst the FRENCH scale and clinical practice.We conducted a retrospective\nanalysis of a prospectively recruited cohort gathering adult patient triage\ndata over a 7-month period at the Roger Salengro Hospital ED (Lille, France).\nThree AI models were trained and validated : (1) TRIAGEMASTER (NLP), (2)\nURGENTIAPARSE (LLM), and (3) EMERGINET (JEPA). Data included demographic\ndetails, verbatim chief complaints, vital signs, and triage outcomes based on\nthe FRENCH scale and GEMSA coding. The primary outcome was the concordance of\nAI-predicted triage level with the FRENCH gold-standard. It was assessed thanks\nto various indicators : F1-Score, Weighted Kappa, Spearman, MAE, RMSE. The LLM\nmodel (URGENTIAPARSE) showed higher accuracy (composite score: 2.514) compared\nto JEPA (EMERGINET, 0.438) and NLP (TRIAGEMASTER, -3.511), outperforming nurse\ntriage (-4.343). Secondary analyses highlighted the effectiveness of\nURGENTIAPARSE in predicting hospitalization needs (GEMSA) and its robustness\nwith structured data versus raw transcripts (either for GEMSA prediction or for\nFRENCH prediction). LLM architecture, through abstraction of patient\nrepresentations, offers the most accurate triage predictions among tested\nmodels. Integrating AI into ED workflows could enhance patient safety and\noperational efficiency, though integration into clinical workflows requires\naddressing model limitations and ensuring ethical transparency.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4e09\u79cdAI\u6a21\u578b\uff08NLP\u3001LLM\u3001JEPA\uff09\u5728\u6025\u8bca\u5206\u8bca\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0LLM\u6a21\u578b\uff08URGENTIAPARSE\uff09\u51c6\u786e\u6027\u6700\u9ad8\uff0c\u4f18\u4e8e\u62a4\u58eb\u5206\u8bca\u548c\u5176\u4ed6AI\u6a21\u578b\u3002", "motivation": "\u6025\u8bca\u5206\u8bca\u4e2d\u7684\u9519\u8bef\uff08\u5982\u8fc7\u5ea6\u6216\u4e0d\u8db3\u5206\u8bca\uff09\u662f\u6301\u7eed\u6311\u6218\uff0cAI\u7684\u6574\u5408\u53ef\u80fd\u63d0\u5347\u5206\u8bca\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "method": "\u56de\u987e\u6027\u5206\u67907\u4e2a\u6708\u7684\u60a3\u8005\u6570\u636e\uff0c\u8bad\u7ec3\u5e76\u9a8c\u8bc1\u4e09\u79cdAI\u6a21\u578b\uff0c\u8bc4\u4f30\u5176\u4e0eFRENCH\u6807\u51c6\u7684\u543b\u5408\u5ea6\u3002", "result": "LLM\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u5c24\u5176\u5728\u9884\u6d4b\u4f4f\u9662\u9700\u6c42\u548c\u7ed3\u6784\u5316\u6570\u636e\u5904\u7406\u4e0a\u3002", "conclusion": "AI\uff08\u5c24\u5176\u662fLLM\uff09\u53ef\u63d0\u5347\u6025\u8bca\u5206\u8bca\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u4f46\u9700\u89e3\u51b3\u6a21\u578b\u5c40\u9650\u6027\u548c\u4f26\u7406\u95ee\u9898\u3002"}}
{"id": "2507.01098", "pdf": "https://arxiv.org/pdf/2507.01098", "abs": "https://arxiv.org/abs/2507.01098", "authors": ["Liu Ziyin", "Isaac Chuang"], "title": "Proof of a perfect platonic representation hypothesis", "categories": ["cs.LG", "cond-mat.dis-nn", "q-bio.NC", "stat.ML"], "comment": null, "summary": "In this note, we elaborate on and explain in detail the proof given by Ziyin\net al. (2025) of the \"perfect\" Platonic Representation Hypothesis (PRH) for the\nembedded deep linear network model (EDLN). We show that if trained with SGD,\ntwo EDLNs with different widths and depths and trained on different data will\nbecome Perfectly Platonic, meaning that every possible pair of layers will\nlearn the same representation up to a rotation. Because most of the global\nminima of the loss function are not Platonic, that SGD only finds the perfectly\nPlatonic solution is rather extraordinary. The proof also suggests at least six\nways the PRH can be broken. We also show that in the EDLN model, the emergence\nof the Platonic representations is due to the same reason as the emergence of\nprogressive sharpening. This implies that these two seemingly unrelated\nphenomena in deep learning can, surprisingly, have a common cause. Overall, the\ntheory and proof highlight the importance of understanding emergent \"entropic\nforces\" due to the irreversibility of SGD training and their role in\nrepresentation learning. The goal of this note is to be instructive and avoid\nlengthy technical details.", "AI": {"tldr": "\u672c\u6587\u8be6\u7ec6\u89e3\u91ca\u4e86Ziyin\u7b49\u4eba\uff082025\uff09\u5173\u4e8e\u5d4c\u5165\u5f0f\u6df1\u5ea6\u7ebf\u6027\u7f51\u7edc\u6a21\u578b\uff08EDLN\uff09\u7684\u201c\u5b8c\u7f8e\u201d\u67cf\u62c9\u56fe\u8868\u793a\u5047\u8bbe\uff08PRH\uff09\u7684\u8bc1\u660e\uff0c\u5e76\u5c55\u793a\u4e86SGD\u8bad\u7ec3\u4e0bEDLN\u7684\u67cf\u62c9\u56fe\u7279\u6027\u53ca\u5176\u4e0e\u6e10\u8fdb\u9510\u5316\u7684\u5171\u540c\u539f\u56e0\u3002", "motivation": "\u63a2\u8ba8SGD\u8bad\u7ec3\u4e0bEDLN\u6a21\u578b\u7684\u67cf\u62c9\u56fe\u8868\u793a\u73b0\u8c61\u53ca\u5176\u4e0e\u6e10\u8fdb\u9510\u5316\u7684\u8054\u7cfb\uff0c\u63ed\u793a\u6df1\u5ea6\u5b66\u4e60\u4e2d\u4e0d\u53ef\u9006\u6027\u5bfc\u81f4\u7684\u201c\u71b5\u529b\u201d\u5bf9\u8868\u793a\u5b66\u4e60\u7684\u91cd\u8981\u6027\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u8bc1\u660e\uff0c\u5c55\u793aSGD\u8bad\u7ec3\u4e0bEDLN\u6a21\u578b\u7684\u67cf\u62c9\u56fe\u8868\u793a\u7279\u6027\uff0c\u5e76\u63a2\u8ba8\u5176\u4e0e\u6e10\u8fdb\u9510\u5316\u7684\u5171\u540c\u539f\u56e0\u3002", "result": "\u53d1\u73b0SGD\u8bad\u7ec3\u4e0bEDLN\u6a21\u578b\u4f1a\u5b66\u4e60\u5230\u5b8c\u7f8e\u7684\u67cf\u62c9\u56fe\u8868\u793a\uff0c\u4e14\u8fd9\u4e00\u73b0\u8c61\u4e0e\u6e10\u8fdb\u9510\u5316\u6709\u5171\u540c\u539f\u56e0\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u7406\u89e3SGD\u8bad\u7ec3\u4e2d\u4e0d\u53ef\u9006\u6027\u5bfc\u81f4\u7684\u201c\u71b5\u529b\u201d\u5bf9\u8868\u793a\u5b66\u4e60\u7684\u5173\u952e\u4f5c\u7528\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7684\u7406\u8bba\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2507.01117", "pdf": "https://arxiv.org/pdf/2507.01117", "abs": "https://arxiv.org/abs/2507.01117", "authors": ["Nikita Sakovich", "Dmitry Aksenov", "Ekaterina Pleshakova", "Sergey Gataullin"], "title": "A Neural Operator based on Dynamic Mode Decomposition", "categories": ["cs.LG", "68T07, 35A99"], "comment": "30 pages, 10 figures", "summary": "The scientific computation methods development in conjunction with artificial\nintelligence technologies remains a hot research topic. Finding a balance\nbetween lightweight and accurate computations is a solid foundation for this\ndirection. The study presents a neural operator based on the dynamic mode\ndecomposition algorithm (DMD), mapping functional spaces, which combines DMD\nand deep learning (DL) for spatiotemporal processes efficient modeling. Solving\nPDEs for various initial and boundary conditions requires significant\ncomputational resources. The method suggested automatically extracts key modes\nand system dynamics using them to construct predictions, reducing computational\ncosts compared to traditional numerical methods. The approach has demonstrated\nits efficiency through comparative analysis of performance with closest\nanalogues DeepONet and FNO in the heat equation, Laplaces equation, and Burgers\nequation solutions approximation, where it achieves high reconstruction\naccuracy.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a8\u6001\u6a21\u5f0f\u5206\u89e3\uff08DMD\uff09\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u795e\u7ecf\u7b97\u5b50\uff0c\u7528\u4e8e\u9ad8\u6548\u5efa\u6a21\u65f6\u7a7a\u8fc7\u7a0b\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u79d1\u5b66\u8ba1\u7b97\u4e0e\u4eba\u5de5\u667a\u80fd\u7ed3\u5408\u662f\u7814\u7a76\u70ed\u70b9\uff0c\u4f46\u9700\u5e73\u8861\u8f7b\u91cf\u5316\u548c\u51c6\u786e\u6027\u3002\u4f20\u7edfPDE\u6c42\u89e3\u65b9\u6cd5\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u9700\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408DMD\u548c\u6df1\u5ea6\u5b66\u4e60\uff0c\u81ea\u52a8\u63d0\u53d6\u5173\u952e\u6a21\u5f0f\u548c\u7cfb\u7edf\u52a8\u6001\uff0c\u7528\u4e8e\u9884\u6d4b\u3002", "result": "\u5728\u70ed\u65b9\u7a0b\u3001\u62c9\u666e\u62c9\u65af\u65b9\u7a0b\u548cBurgers\u65b9\u7a0b\u8fd1\u4f3c\u89e3\u4e2d\uff0c\u4e0eDeepONet\u548cFNO\u76f8\u6bd4\uff0c\u8868\u73b0\u51fa\u9ad8\u91cd\u6784\u7cbe\u5ea6\u548c\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9ad8\u6548\u5efa\u6a21\u65f6\u7a7a\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u3002"}}
{"id": "2507.01129", "pdf": "https://arxiv.org/pdf/2507.01129", "abs": "https://arxiv.org/abs/2507.01129", "authors": ["Arun Ganesh", "Brendan McMahan", "Abhradeep Thakurta"], "title": "On Design Principles for Private Adaptive Optimizers", "categories": ["cs.LG", "cs.CR"], "comment": "PPML 2025", "summary": "The spherical noise added to gradients in differentially private (DP)\ntraining undermines the performance of adaptive optimizers like AdaGrad and\nAdam, and hence many recent works have proposed algorithms to address this\nchallenge. However, the empirical results in these works focus on simple tasks\nand models and the conclusions may not generalize to model training in\npractice. In this paper we survey several of these variants, and develop better\ntheoretical intuition for them as well as perform empirical studies comparing\nthem. We find that a common intuition of aiming for unbiased estimates of\nsecond moments of gradients in adaptive optimizers is misguided, and instead\nthat a simple technique called scale-then-privatize (which does not achieve\nunbiased second moments) has more desirable theoretical behaviors and\noutperforms all other variants we study on a small-scale language model\ntraining task. We additionally argue that scale-then-privatize causes the noise\naddition to better match the application of correlated noise mechanisms which\nare more desirable to use in practice.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5dee\u5206\u9690\u79c1\u8bad\u7ec3\u4e2d\u81ea\u9002\u5e94\u4f18\u5316\u5668\u7684\u6027\u80fd\u95ee\u9898\uff0c\u53d1\u73b0\u5e38\u89c1\u7684\u65e0\u504f\u4e8c\u9636\u77e9\u4f30\u8ba1\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\uff0c\u800c\u7b80\u5355\u7684\u201cscale-then-privatize\u201d\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u5dee\u5206\u9690\u79c1\u8bad\u7ec3\u4e2d\u7403\u5f62\u566a\u58f0\u5bf9\u81ea\u9002\u5e94\u4f18\u5316\u5668\uff08\u5982AdaGrad\u548cAdam\uff09\u7684\u6027\u80fd\u6709\u8d1f\u9762\u5f71\u54cd\uff0c\u73b0\u6709\u7814\u7a76\u7ed3\u8bba\u53ef\u80fd\u65e0\u6cd5\u63a8\u5e7f\u5230\u5b9e\u9645\u6a21\u578b\u8bad\u7ec3\u4e2d\u3002", "method": "\u8c03\u67e5\u4e86\u591a\u79cd\u6539\u8fdb\u7b97\u6cd5\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7814\u7a76\u6bd4\u8f83\u5176\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u201cscale-then-privatize\u201d\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u5747\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u5c0f\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4efb\u52a1\u4e2d\u3002", "conclusion": "\u201cscale-then-privatize\u201d\u65b9\u6cd5\u66f4\u5339\u914d\u5b9e\u9645\u9700\u6c42\uff0c\u566a\u58f0\u6dfb\u52a0\u65b9\u5f0f\u66f4\u4f18\u3002"}}
{"id": "2507.01131", "pdf": "https://arxiv.org/pdf/2507.01131", "abs": "https://arxiv.org/abs/2507.01131", "authors": ["Yuchao Lin", "Cong Fu", "Zachary Krueger", "Haiyang Yu", "Maho Nakata", "Jianwen Xie", "Emine Kucukbenli", "Xiaofeng Qian", "Shuiwang Ji"], "title": "Tensor Decomposition Networks for Fast Machine Learning Interatomic Potential Computations", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "$\\rm{SO}(3)$-equivariant networks are the dominant models for machine\nlearning interatomic potentials (MLIPs). The key operation of such networks is\nthe Clebsch-Gordan (CG) tensor product, which is computationally expensive. To\naccelerate the computation, we develop tensor decomposition networks (TDNs) as\na class of approximately equivariant networks whose CG tensor products are\nreplaced by low-rank tensor decompositions, such as the CANDECOMP/PARAFAC (CP)\ndecomposition. With the CP decomposition, we prove (i) a uniform bound on the\ninduced error of $\\rm{SO}(3)$-equivariance, and (ii) the universality of\napproximating any equivariant bilinear map. To further reduce the number of\nparameters, we propose path-weight sharing that ties all multiplicity-space\nweights across the $O(L^3)$ CG paths into a single path without compromising\nequivariance, where $L$ is the maximum angular degree. The resulting layer acts\nas a plug-and-play replacement for tensor products in existing networks, and\nthe computational complexity of tensor products is reduced from $O(L^6)$ to\n$O(L^4)$. We evaluate TDNs on PubChemQCR, a newly curated molecular relaxation\ndataset containing 105 million DFT-calculated snapshots. We also use existing\ndatasets, including OC20, and OC22. Results show that TDNs achieve competitive\nperformance with dramatic speedup in computations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8fd1\u4f3c\u7b49\u53d8\u7684\u5f20\u91cf\u5206\u89e3\u7f51\u7edc\uff08TDNs\uff09\uff0c\u901a\u8fc7\u4f4e\u79e9\u5f20\u91cf\u5206\u89e3\uff08\u5982CP\u5206\u89e3\uff09\u66ff\u4ee3\u8ba1\u7b97\u6602\u8d35\u7684Clebsch-Gordan\uff08CG\uff09\u5f20\u91cf\u79ef\uff0c\u663e\u8457\u52a0\u901f\u8ba1\u7b97\u3002", "motivation": "\u73b0\u6709\u7684SO(3)-\u7b49\u53d8\u7f51\u7edc\u5728\u673a\u5668\u5b66\u4e60\u539f\u5b50\u95f4\u52bf\u80fd\uff08MLIPs\uff09\u4e2d\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u4f46\u5176\u5173\u952e\u64cd\u4f5cCG\u5f20\u91cf\u79ef\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u4e9f\u9700\u4f18\u5316\u3002", "method": "\u91c7\u7528CP\u5206\u89e3\u8fd1\u4f3cCG\u5f20\u91cf\u79ef\uff0c\u63d0\u51fa\u8def\u5f84\u6743\u91cd\u5171\u4eab\u4ee5\u51cf\u5c11\u53c2\u6570\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u7b49\u53d8\u6027\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO(L^6)\u964d\u81f3O(L^4)\u3002", "result": "\u5728PubChemQCR\u3001OC20\u548cOC22\u7b49\u6570\u636e\u96c6\u4e0a\uff0cTDNs\u8868\u73b0\u51fa\u4e0e\u73b0\u6709\u65b9\u6cd5\u7ade\u4e89\u7684\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u901f\u5ea6\u3002", "conclusion": "TDNs\u4f5c\u4e3a\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u6709\u6548\u5e73\u8861\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u5206\u5b50\u6a21\u62df\u4efb\u52a1\u3002"}}
{"id": "2507.01132", "pdf": "https://arxiv.org/pdf/2507.01132", "abs": "https://arxiv.org/abs/2507.01132", "authors": ["Brenda Nogueira", "Gabe Gomes", "Meng Jiang", "Nitesh V. Chawla", "Nuno Moniz"], "title": "Spectral Manifold Harmonization for Graph Imbalanced Regression", "categories": ["cs.LG", "q-bio.MN"], "comment": null, "summary": "Graph-structured data is ubiquitous in scientific domains, where models often\nface imbalanced learning settings. In imbalanced regression, domain preferences\nfocus on specific target value ranges representing the most scientifically\nvaluable cases; we observe a significant lack of research. In this paper, we\npresent Spectral Manifold Harmonization (SMH), a novel approach for addressing\nthis imbalanced regression challenge on graph-structured data by generating\nsynthetic graph samples that preserve topological properties while focusing on\noften underrepresented target distribution regions. Conventional methods fail\nin this context because they either ignore graph topology in case generation or\ndo not target specific domain ranges, resulting in models biased toward average\ntarget values. Experimental results demonstrate the potential of SMH on\nchemistry and drug discovery benchmark datasets, showing consistent\nimprovements in predictive performance for target domain ranges.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSpectral Manifold Harmonization\uff08SMH\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u56fe\u7ed3\u6784\u6570\u636e\u4e2d\u7684\u4e0d\u5e73\u8861\u56de\u5f52\u95ee\u9898\uff0c\u901a\u8fc7\u751f\u6210\u5408\u6210\u6837\u672c\u4ee5\u5173\u6ce8\u76ee\u6807\u5206\u5e03\u4e2d\u5e38\u88ab\u5ffd\u89c6\u7684\u533a\u57df\u3002", "motivation": "\u56fe\u7ed3\u6784\u6570\u636e\u5728\u79d1\u5b66\u9886\u57df\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5728\u76ee\u6807\u503c\u8303\u56f4\u4e0d\u5e73\u8861\u7684\u60c5\u51b5\u4e0b\u7f3a\u4e4f\u5173\u6ce8\uff0c\u5c24\u5176\u662f\u5bf9\u79d1\u5b66\u4ef7\u503c\u9ad8\u7684\u533a\u57df\u3002", "method": "SMH\u65b9\u6cd5\u901a\u8fc7\u751f\u6210\u5408\u6210\u56fe\u6837\u672c\uff0c\u4fdd\u7559\u62d3\u6251\u7279\u6027\uff0c\u540c\u65f6\u805a\u7126\u4e8e\u76ee\u6807\u5206\u5e03\u4e2d\u5e38\u88ab\u5ffd\u89c6\u7684\u533a\u57df\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSMH\u5728\u5316\u5b66\u548c\u836f\u7269\u53d1\u73b0\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u76ee\u6807\u57df\u8303\u56f4\u7684\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "SMH\u4e3a\u89e3\u51b3\u56fe\u7ed3\u6784\u6570\u636e\u4e2d\u7684\u4e0d\u5e73\u8861\u56de\u5f52\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u79d1\u5b66\u4ef7\u503c\u9ad8\u7684\u76ee\u6807\u8303\u56f4\u3002"}}
{"id": "2507.01154", "pdf": "https://arxiv.org/pdf/2507.01154", "abs": "https://arxiv.org/abs/2507.01154", "authors": ["Liangyu Wang", "Junxiao Wang", "Jie Ren", "Zihang Xiang", "David E. Keyes", "Di Wang"], "title": "FlashDP: Private Training Large Language Models with Efficient DP-SGD", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "As large language models (LLMs) increasingly underpin technological\nadvancements, the privacy of their training data emerges as a critical concern.\nDifferential Privacy (DP) serves as a rigorous mechanism to protect this data,\nyet its integration via Differentially Private Stochastic Gradient Descent\n(DP-SGD) introduces substantial challenges, primarily due to the complexities\nof per-sample gradient clipping. Current explicit methods, such as Opacus,\nnecessitate extensive storage for per-sample gradients, significantly inflating\nmemory requirements. Conversely, implicit methods like GhostClip reduce storage\nneeds by recalculating gradients multiple times, which leads to inefficiencies\ndue to redundant computations. This paper introduces FlashDP, an innovative\ncache-friendly per-layer DP-SGD that consolidates necessary operations into a\nsingle task, calculating gradients only once in a fused manner. This approach\nnot only diminishes memory movement by up to \\textbf{50\\%} but also cuts down\nredundant computations by \\textbf{20\\%}, compared to previous methods.\nConsequently, FlashDP does not increase memory demands and achieves a\n\\textbf{90\\%} throughput compared to the Non-DP method on a four-A100 system\nduring the pre-training of the Llama-13B model, while maintaining parity with\nstandard per-layer clipped DP-SGD in terms of accuracy. These advancements\nestablish FlashDP as a pivotal development for efficient and privacy-preserving\ntraining of LLMs. FlashDP's code has been open-sourced in\nhttps://github.com/kaustpradalab/flashdp.", "AI": {"tldr": "FlashDP\u662f\u4e00\u79cd\u521b\u65b0\u7684\u7f13\u5b58\u53cb\u597d\u578bDP-SGD\u65b9\u6cd5\uff0c\u901a\u8fc7\u5355\u6b21\u878d\u5408\u8ba1\u7b97\u68af\u5ea6\uff0c\u663e\u8457\u51cf\u5c11\u5185\u5b58\u9700\u6c42\u548c\u5197\u4f59\u8ba1\u7b97\uff0c\u540c\u65f6\u4fdd\u6301\u9690\u79c1\u4fdd\u62a4\u6548\u679c\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u8bad\u7ec3\u6570\u636e\u7684\u9690\u79c1\u4fdd\u62a4\u6210\u4e3a\u5173\u952e\u95ee\u9898\u3002\u73b0\u6709DP-SGD\u65b9\u6cd5\u5728\u5185\u5b58\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002", "method": "FlashDP\u901a\u8fc7\u5355\u6b21\u4efb\u52a1\u878d\u5408\u8ba1\u7b97\u68af\u5ea6\uff0c\u51cf\u5c11\u5185\u5b58\u79fb\u52a8\u548c\u5197\u4f59\u8ba1\u7b97\uff0c\u4f18\u5316\u4e86DP-SGD\u7684\u5b9e\u73b0\u3002", "result": "FlashDP\u5728Llama-13B\u6a21\u578b\u9884\u8bad\u7ec3\u4e2d\uff0c\u5185\u5b58\u9700\u6c42\u964d\u4f4e50%\uff0c\u5197\u4f59\u8ba1\u7b97\u51cf\u5c1120%\uff0c\u541e\u5410\u91cf\u8fbe\u5230\u975eDP\u65b9\u6cd5\u768490%\u3002", "conclusion": "FlashDP\u4e3a\u9ad8\u6548\u4e14\u9690\u79c1\u4fdd\u62a4\u7684LLMs\u8bad\u7ec3\u63d0\u4f9b\u4e86\u91cd\u8981\u8fdb\u5c55\uff0c\u5176\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.01178", "pdf": "https://arxiv.org/pdf/2507.01178", "abs": "https://arxiv.org/abs/2507.01178", "authors": ["Alec Helbling", "Duen Horng Chau"], "title": "Diffusion Explorer: Interactive Exploration of Diffusion Models", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion models have been central to the development of recent image, video,\nand even text generation systems. They posses striking geometric properties\nthat can be faithfully portrayed in low-dimensional settings. However, existing\nresources for explaining diffusion either require an advanced theoretical\nfoundation or focus on their neural network architectures rather than their\nrich geometric properties. We introduce Diffusion Explorer, an interactive tool\nto explain the geometric properties of diffusion models. Users can train 2D\ndiffusion models in the browser and observe the temporal dynamics of their\nsampling process. Diffusion Explorer leverages interactive animation, which has\nbeen shown to be a powerful tool for making engaging visualizations of dynamic\nsystems, making it well suited to explaining diffusion models which represent\nstochastic processes that evolve over time. Diffusion Explorer is open source\nand a live demo is available at alechelbling.com/Diffusion-Explorer.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aDiffusion Explorer\u7684\u4ea4\u4e92\u5f0f\u5de5\u5177\uff0c\u7528\u4e8e\u76f4\u89c2\u5c55\u793a\u6269\u6563\u6a21\u578b\u7684\u51e0\u4f55\u7279\u6027\u3002", "motivation": "\u73b0\u6709\u89e3\u91ca\u6269\u6563\u6a21\u578b\u7684\u8d44\u6e90\u8981\u4e48\u9700\u8981\u9ad8\u6df1\u7406\u8bba\u57fa\u7840\uff0c\u8981\u4e48\u8fc7\u4e8e\u5173\u6ce8\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5ffd\u7565\u4e86\u5176\u51e0\u4f55\u7279\u6027\u3002", "method": "\u5f00\u53d1\u4e86Diffusion Explorer\u5de5\u5177\uff0c\u7528\u6237\u53ef\u5728\u6d4f\u89c8\u5668\u4e2d\u8bad\u7ec32D\u6269\u6563\u6a21\u578b\u5e76\u89c2\u5bdf\u91c7\u6837\u8fc7\u7a0b\u7684\u52a8\u6001\u53d8\u5316\u3002", "result": "\u901a\u8fc7\u4ea4\u4e92\u5f0f\u52a8\u753b\u76f4\u89c2\u5c55\u793a\u4e86\u6269\u6563\u6a21\u578b\u7684\u51e0\u4f55\u7279\u6027\u548c\u65f6\u95f4\u52a8\u6001\u3002", "conclusion": "Diffusion Explorer\u4e3a\u7406\u89e3\u548c\u6559\u5b66\u6269\u6563\u6a21\u578b\u63d0\u4f9b\u4e86\u76f4\u89c2\u4e14\u6613\u7528\u7684\u5de5\u5177\u3002"}}
{"id": "2507.01196", "pdf": "https://arxiv.org/pdf/2507.01196", "abs": "https://arxiv.org/abs/2507.01196", "authors": ["Na Lee", "Konstantinos Barmpas", "Yannis Panagakis", "Dimitrios Adamos", "Nikolaos Laskaris", "Stefanos Zafeiriou"], "title": "Are Large Brainwave Foundation Models Capable Yet? Insights from Fine-tuning", "categories": ["cs.LG", "cs.AI", "cs.HC"], "comment": null, "summary": "Foundation Models have demonstrated significant success across various\ndomains in Artificial Intelligence (AI), yet their capabilities for brainwave\nmodeling remain unclear. In this paper, we comprehensively evaluate current\nLarge Brainwave Foundation Models (LBMs) through systematic fine-tuning\nexperiments across multiple Brain-Computer Interface (BCI) benchmark tasks,\nincluding memory tasks and sleep stage classification. Our extensive analysis\nshows that state-of-the-art LBMs achieve only marginal improvements (0.9%-1.2%)\nover traditional deep architectures while requiring significantly more\nparameters (millions vs thousands), raising important questions about their\nefficiency and applicability in BCI contexts. Moreover, through detailed\nablation studies and Low-Rank Adaptation (LoRA), we significantly reduce\ntrainable parameters without performance degradation, while demonstrating that\narchitectural and training inefficiencies limit LBMs' current capabilities. Our\nexperiments span both full model fine-tuning and parameter-efficient adaptation\ntechniques, providing insights into optimal training strategies for BCI\napplications. We pioneer the application of LoRA to LBMs, revealing that\nperformance benefits generally emerge when adapting multiple neural network\ncomponents simultaneously. These findings highlight the critical need for\ndomain-specific development strategies to advance LBMs, suggesting that current\narchitectures may require redesign to fully leverage the potential of\nfoundation models in brainwave analysis.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8111\u6ce2\u57fa\u7840\u6a21\u578b\uff08LBMs\uff09\u5728\u8111\u673a\u63a5\u53e3\uff08BCI\uff09\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u6027\u80fd\u63d0\u5347\u6709\u9650\u4e14\u53c2\u6570\u9700\u6c42\u9ad8\uff0c\u63d0\u51fa\u4e86\u901a\u8fc7LoRA\u7b49\u6280\u672f\u4f18\u5316\u53c2\u6570\u6548\u7387\u7684\u65b9\u6cd5\u3002", "motivation": "\u63a2\u7d22\u57fa\u7840\u6a21\u578b\u5728\u8111\u6ce2\u5efa\u6a21\u4e2d\u7684\u6f5c\u529b\uff0c\u8bc4\u4f30\u5176\u5728BCI\u4efb\u52a1\u4e2d\u7684\u9002\u7528\u6027\u548c\u6548\u7387\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5fae\u8c03\u5b9e\u9a8c\u548cLoRA\u6280\u672f\uff0c\u5bf9\u6bd4LBMs\u4e0e\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u7684\u6027\u80fd\u548c\u53c2\u6570\u6548\u7387\u3002", "result": "LBMs\u6027\u80fd\u63d0\u5347\u6709\u9650\uff080.9%-1.2%\uff09\uff0c\u53c2\u6570\u9700\u6c42\u9ad8\uff0c\u4f46LoRA\u80fd\u663e\u8457\u51cf\u5c11\u53c2\u6570\u4e14\u4e0d\u964d\u4f4e\u6027\u80fd\u3002", "conclusion": "\u5f53\u524dLBMs\u5728\u8111\u6ce2\u5206\u6790\u4e2d\u6548\u7387\u4e0d\u8db3\uff0c\u9700\u9886\u57df\u7279\u5b9a\u7684\u4f18\u5316\u7b56\u7565\u548c\u67b6\u6784\u6539\u8fdb\u3002"}}
{"id": "2507.01201", "pdf": "https://arxiv.org/pdf/2507.01201", "abs": "https://arxiv.org/abs/2507.01201", "authors": ["Hyoseo", "Yoon", "Yisong Yue", "Been Kim"], "title": "Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Independently trained vision and language models inhabit disjoint\nrepresentational spaces, shaped by their respective modalities, objectives, and\narchitectures. Yet an emerging hypothesis - the Platonic Representation\nHypothesis - suggests that such models may nonetheless converge toward a shared\nstatistical model of reality. This compatibility, if it exists, raises a\nfundamental question: can we move beyond post-hoc statistical detection of\nalignment and explicitly optimize for it between such disjoint representations?\nWe cast this Platonic alignment problem as a multi-objective optimization task\n- preserve each modality's native structure while aligning for mutual\ncoherence. We introduce the Joint Autoencoder Modulator (JAM) framework that\njointly trains modality-specific autoencoders on the latent representations of\npre-trained single modality models, encouraging alignment through both\nreconstruction and cross-modal objectives. By analogy, this framework serves as\na method to escape Plato's Cave, enabling the emergence of shared structure\nfrom disjoint inputs. We evaluate this framework across three critical design\naxes: (i) the alignment objective - comparing contrastive loss (Con), its\nhard-negative variant (NegCon), and our Spread loss, (ii) the layer depth at\nwhich alignment is most effective, and (iii) the impact of foundation model\nscale on representational convergence. Our findings show that our lightweight\nPareto-efficient framework reliably induces alignment, even across frozen,\nindependently trained representations, offering both theoretical insight and\npractical pathways for transforming generalist unimodal foundations into\nspecialist multimodal models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aJAM\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u4efb\u52a1\u5b9e\u73b0\u89c6\u89c9\u548c\u8bed\u8a00\u6a21\u578b\u7684\u8868\u793a\u5bf9\u9f50\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u63a2\u7d22\u89c6\u89c9\u548c\u8bed\u8a00\u6a21\u578b\u5728\u72ec\u7acb\u8bad\u7ec3\u540e\u662f\u5426\u80fd\u901a\u8fc7\u4f18\u5316\u5b9e\u73b0\u8868\u793a\u5bf9\u9f50\uff0c\u9a8c\u8bc1\u67cf\u62c9\u56fe\u8868\u793a\u5047\u8bbe\u3002", "method": "\u5f15\u5165JAM\u6846\u67b6\uff0c\u8054\u5408\u8bad\u7ec3\u6a21\u6001\u7279\u5b9a\u7684\u81ea\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u91cd\u5efa\u548c\u8de8\u6a21\u6001\u76ee\u6807\u4fc3\u8fdb\u5bf9\u9f50\u3002", "result": "JAM\u6846\u67b6\u5728\u591a\u79cd\u8bbe\u8ba1\u8f74\uff08\u5982\u5bf9\u9f50\u76ee\u6807\u3001\u5c42\u6df1\u5ea6\u548c\u6a21\u578b\u89c4\u6a21\uff09\u4e0b\u5747\u80fd\u6709\u6548\u8bf1\u5bfc\u5bf9\u9f50\u3002", "conclusion": "JAM\u6846\u67b6\u4e3a\u5c06\u901a\u7528\u5355\u6a21\u6001\u6a21\u578b\u8f6c\u5316\u4e3a\u4e13\u4e1a\u591a\u6a21\u6001\u6a21\u578b\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u8def\u5f84\u3002"}}
{"id": "2507.01208", "pdf": "https://arxiv.org/pdf/2507.01208", "abs": "https://arxiv.org/abs/2507.01208", "authors": ["Pedro R. X. Carmo", "Igor de Moura", "Assis T. de Oliveira Filho", "Djamel Sadok", "Cleber Zanchettin"], "title": "Deep Learning-Based Intrusion Detection for Automotive Ethernet: Evaluating & Optimizing Fast Inference Techniques for Deployment on Low-Cost Platform", "categories": ["cs.LG", "cs.CR", "C.2.0; I.2.0"], "comment": null, "summary": "Modern vehicles are increasingly connected, and in this context, automotive\nEthernet is one of the technologies that promise to provide the necessary\ninfrastructure for intra-vehicle communication. However, these systems are\nsubject to attacks that can compromise safety, including flow injection\nattacks. Deep Learning-based Intrusion Detection Systems (IDS) are often\ndesigned to combat this problem, but they require expensive hardware to run in\nreal time. In this work, we propose to evaluate and apply fast neural network\ninference techniques like Distilling and Prunning for deploying IDS models on\nlow-cost platforms in real time. The results show that these techniques can\nachieve intrusion detection times of up to 727 {\\mu}s using a Raspberry Pi 4,\nwith AUCROC values of 0.9890.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u84b8\u998f\u548c\u526a\u679d\u7684\u5feb\u901f\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\u6280\u672f\uff0c\u7528\u4e8e\u5728\u4f4e\u6210\u672c\u5e73\u53f0\u4e0a\u5b9e\u65f6\u90e8\u7f72\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff08IDS\uff09\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u786c\u4ef6\u9700\u6c42\u5e76\u4fdd\u6301\u4e86\u9ad8\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u73b0\u4ee3\u8f66\u8f86\u7684\u4e92\u8054\u6027\u589e\u5f3a\uff0c\u8f66\u8f7d\u4ee5\u592a\u7f51\u6210\u4e3a\u5173\u952e\u6280\u672f\uff0c\u4f46\u5176\u6613\u53d7\u653b\u51fb\uff0c\u5982\u6d41\u91cf\u6ce8\u5165\u653b\u51fb\u3002\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60IDS\u9700\u8981\u6602\u8d35\u786c\u4ef6\u652f\u6301\u5b9e\u65f6\u8fd0\u884c\uff0c\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u91c7\u7528\u84b8\u998f\u548c\u526a\u679d\u6280\u672f\u4f18\u5316IDS\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u5728\u4f4e\u6210\u672c\u5e73\u53f0\uff08\u5982\u6811\u8393\u6d3e4\uff09\u4e0a\u5b9e\u65f6\u8fd0\u884c\u3002", "result": "\u4f18\u5316\u540e\u7684IDS\u5728\u6811\u8393\u6d3e4\u4e0a\u5b9e\u73b0\u4e86727\u5fae\u79d2\u7684\u68c0\u6d4b\u65f6\u95f4\uff0cAUCROC\u503c\u8fbe\u52300.9890\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u84b8\u998f\u548c\u526a\u679d\u6280\u672f\u80fd\u6709\u6548\u964d\u4f4eIDS\u7684\u786c\u4ef6\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\uff0c\u4e3a\u4f4e\u6210\u672c\u5b9e\u65f6\u5165\u4fb5\u68c0\u6d4b\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2507.01216", "pdf": "https://arxiv.org/pdf/2507.01216", "abs": "https://arxiv.org/abs/2507.01216", "authors": ["Xingke Yang", "Liang Li", "Zhiyi Wan", "Sicong Li", "Hao Wang", "Xiaoqi Qi", "Jiang Liu", "Tomoaki Ohtsuki", "Xin Fu", "Miao Pan"], "title": "PAE MobiLLM: Privacy-Aware and Efficient LLM Fine-Tuning on the Mobile Device via Additive Side-Tuning", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "There is a huge gap between numerous intriguing applications fostered by\non-device large language model (LLM) fine-tuning (FT) from fresh mobile data\nand the limited resources of a mobile device. While existing server-assisted\nmethods (e.g., split learning or side-tuning) may enable LLM FT on the local\nmobile device, they suffer from heavy communication burdens of activation\ntransmissions, and may disclose data, labels or fine-tuned models to the\nserver. To address those issues, we develop PAE MobiLLM, a privacy-aware and\nefficient LLM FT method which can be deployed on the mobile device via\nserver-assisted additive side-tuning. To further accelerate FT convergence and\nimprove computing efficiency, PAE MobiLLM integrates activation caching on the\nserver side, which allows the server to reuse historical activations and saves\nthe mobile device from repeatedly computing forward passes for the recurring\ndata samples. Besides, to reduce communication cost, PAE MobiLLM develops a\none-token (i.e., ``pivot'' token) activation shortcut that transmits only a\nsingle activation dimension instead of full activation matrices to guide the\nside network tuning. Last but not least, PAE MobiLLM introduces the additive\nadapter side-network design which makes the server train the adapter modules\nbased on device-defined prediction differences rather than raw ground-truth\nlabels. In this way, the server can only assist device-defined side-network\ncomputing, and learn nothing about data, labels or fine-tuned models.", "AI": {"tldr": "PAE MobiLLM\u662f\u4e00\u79cd\u9690\u79c1\u4fdd\u62a4\u4e14\u9ad8\u6548\u7684\u79fb\u52a8\u8bbe\u5907\u7aef\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u670d\u52a1\u5668\u8f85\u52a9\u7684\u4fa7\u8c03\u4f18\u548c\u6fc0\u6d3b\u7f13\u5b58\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u901a\u4fe1\u8d1f\u62c5\u548c\u6570\u636e\u6cc4\u9732\u95ee\u9898\u3002", "motivation": "\u79fb\u52a8\u8bbe\u5907\u8d44\u6e90\u6709\u9650\uff0c\u73b0\u6709\u670d\u52a1\u5668\u8f85\u52a9\u65b9\u6cd5\u5b58\u5728\u901a\u4fe1\u8d1f\u62c5\u91cd\u548c\u6570\u636e\u6cc4\u9732\u98ce\u9669\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u5fae\u8c03\u65b9\u6cd5\u3002", "method": "PAE MobiLLM\u7ed3\u5408\u670d\u52a1\u5668\u7aef\u6fc0\u6d3b\u7f13\u5b58\u3001\u5355\u4ee4\u724c\u6fc0\u6d3b\u5feb\u6377\u65b9\u5f0f\u548c\u52a0\u6cd5\u9002\u914d\u5668\u4fa7\u7f51\u7edc\u8bbe\u8ba1\uff0c\u51cf\u5c11\u901a\u4fe1\u6210\u672c\u5e76\u4fdd\u62a4\u9690\u79c1\u3002", "result": "PAE MobiLLM\u663e\u8457\u964d\u4f4e\u4e86\u901a\u4fe1\u8d1f\u62c5\uff0c\u52a0\u901f\u4e86\u5fae\u8c03\u6536\u655b\uff0c\u540c\u65f6\u4fdd\u62a4\u4e86\u6570\u636e\u548c\u6a21\u578b\u9690\u79c1\u3002", "conclusion": "PAE MobiLLM\u4e3a\u79fb\u52a8\u8bbe\u5907\u4e0a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01235", "pdf": "https://arxiv.org/pdf/2507.01235", "abs": "https://arxiv.org/abs/2507.01235", "authors": ["Bara Rababa", "Bilal Farooq"], "title": "Quantum Machine Learning in Transportation: A Case Study of Pedestrian Stress Modelling", "categories": ["cs.LG", "quant-ph"], "comment": "Proceedings of IEEE Intelligent Transportation Systems Conference,\n  2025", "summary": "Quantum computing has opened new opportunities to tackle complex machine\nlearning tasks, for instance, high-dimensional data representations commonly\nrequired in intelligent transportation systems. We explore quantum machine\nlearning to model complex skin conductance response (SCR) events that reflect\npedestrian stress in a virtual reality road crossing experiment. For this\npurpose, Quantum Support Vector Machine (QSVM) with an eight-qubit ZZ feature\nmap and a Quantum Neural Network (QNN) using a Tree Tensor Network ansatz and\nan eight-qubit ZZ feature map, were developed on Pennylane. The dataset\nconsists of SCR measurements along with features such as the response amplitude\nand elapsed time, which have been categorized into amplitude-based classes. The\nQSVM achieved good training accuracy, but had an overfitting problem, showing a\nlow test accuracy of 45% and therefore impacting the reliability of the\nclassification model. The QNN model reached a higher test accuracy of 55%,\nmaking it a better classification model than the QSVM and the classic versions.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5728\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u5efa\u6a21\u76ae\u80a4\u7535\u5bfc\u53cd\u5e94\uff08SCR\uff09\u4e8b\u4ef6\u7684\u5e94\u7528\uff0c\u6bd4\u8f83\u4e86\u91cf\u5b50\u652f\u6301\u5411\u91cf\u673a\uff08QSVM\uff09\u548c\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\uff08QNN\uff09\u7684\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u8ba1\u7b97\u5728\u590d\u6742\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u5206\u6790\u884c\u4eba\u538b\u529b\u76f8\u5173\u7684SCR\u4e8b\u4ef6\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8ePennylane\u7684QSVM\uff08\u4f7f\u7528\u516b\u91cf\u5b50\u4f4dZZ\u7279\u5f81\u56fe\uff09\u548cQNN\uff08\u4f7f\u7528\u6811\u5f20\u91cf\u7f51\u7edc\u7ed3\u6784\u548c\u516b\u91cf\u5b50\u4f4dZZ\u7279\u5f81\u56fe\uff09\uff0c\u5e76\u5bf9SCR\u6570\u636e\u8fdb\u884c\u4e86\u5206\u7c7b\u3002", "result": "QSVM\u8bad\u7ec3\u51c6\u786e\u7387\u9ad8\u4f46\u6d4b\u8bd5\u51c6\u786e\u7387\u4f4e\uff0845%\uff09\uff0c\u5b58\u5728\u8fc7\u62df\u5408\u95ee\u9898\uff1bQNN\u6d4b\u8bd5\u51c6\u786e\u7387\u66f4\u9ad8\uff0855%\uff09\uff0c\u4f18\u4e8eQSVM\u548c\u7ecf\u5178\u65b9\u6cd5\u3002", "conclusion": "QNN\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u5c55\u793a\u4e86\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5728\u590d\u6742\u6570\u636e\u5206\u6790\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.01241", "pdf": "https://arxiv.org/pdf/2507.01241", "abs": "https://arxiv.org/abs/2507.01241", "authors": ["Di Zhang", "Yihang Zhang"], "title": "Beyond First-Order: Training LLMs with Stochastic Conjugate Subgradients and AdamW", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Stochastic gradient-based descent (SGD), have long been central to training\nlarge language models (LLMs). However, their effectiveness is increasingly\nbeing questioned, particularly in large-scale applications where empirical\nevidence suggests potential performance limitations. In response, this paper\nproposes a stochastic conjugate subgradient method together with adaptive\nsampling tailored specifically for training LLMs. The method not only achieves\nfaster convergence per iteration but also demonstrates improved scalability\ncompared to traditional SGD techniques. It leverages sample complexity analysis\nto adaptively choose the sample size, employs a stochastic conjugate\nsubgradient approach to determine search directions and utilizing an AdamW-like\nalgorithm to adaptively adjust step sizes. This approach preserves the key\nadvantages of first-order methods while effectively addressing the nonconvexity\nand non-smoothness inherent in LLMs training. Additionally, we provide a\ndetailed analysis of the advantage of the algorithm. Experimental results show\nthat the proposed method not only maintains, but in many cases surpasses, the\nscalability of traditional SGD techniques, significantly enhancing both the\nspeed and accuracy of the optimization process.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8bad\u7ec3\u7684\u968f\u673a\u5171\u8f6d\u6b21\u68af\u5ea6\u65b9\u6cd5\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u91c7\u6837\uff0c\u76f8\u6bd4\u4f20\u7edfSGD\u65b9\u6cd5\u5177\u6709\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u597d\u7684\u6269\u5c55\u6027\u3002", "motivation": "\u4f20\u7edf\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u5728\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\u5b58\u5728\u6027\u80fd\u9650\u5236\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u968f\u673a\u5171\u8f6d\u6b21\u68af\u5ea6\u65b9\u6cd5\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u91c7\u6837\u548cAdamW-like\u7b97\u6cd5\u8c03\u6574\u6b65\u957f\uff0c\u89e3\u51b3LLMs\u8bad\u7ec3\u4e2d\u7684\u975e\u51f8\u6027\u548c\u975e\u5149\u6ed1\u6027\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edfSGD\uff0c\u4e14\u6269\u5c55\u6027\u66f4\u5f3a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aLLMs\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2507.01271", "pdf": "https://arxiv.org/pdf/2507.01271", "abs": "https://arxiv.org/abs/2507.01271", "authors": ["Tatsuki Kawakami", "Kazuki Egashira", "Atsuyuki Miyai", "Go Irie", "Kiyoharu Aizawa"], "title": "PULSE: Practical Evaluation Scenarios for Large Multimodal Model Unlearning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In recent years, unlearning techniques, which are methods for inducing a\nmodel to \"forget\" previously learned information, have attracted attention as a\nway to address privacy and copyright concerns in large language models (LLMs)\nand large multimodal models (LMMs). While several unlearning benchmarks have\nbeen established for LLMs, a practical evaluation framework for unlearning in\nLMMs has been less explored. Specifically, existing unlearning benchmark for\nLMMs considers only scenarios in which the model is required to unlearn\nfine-tuned knowledge through a single unlearning operation. In this study, we\nintroduce PULSE protocol for realistic unlearning scenarios for LMMs by\nintroducing two critical perspectives: (i) Pre-trained knowledge Unlearning for\nanalyzing the effect across different knowledge acquisition phases and (ii)\nLong-term Sustainability Evaluation to address sequential requests. We then\nevaluate existing unlearning methods along these dimensions. Our results reveal\nthat, although some techniques can successfully unlearn knowledge acquired\nthrough fine-tuning, they struggle to eliminate information learned during\npre-training. Moreover, methods that effectively unlearn a batch of target data\nin a single operation exhibit substantial performance degradation when the same\ndata are split and unlearned sequentially.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86PULSE\u534f\u8bae\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u7684\u9057\u5fd8\u6280\u672f\uff0c\u91cd\u70b9\u5173\u6ce8\u9884\u8bad\u7ec3\u77e5\u8bc6\u9057\u5fd8\u548c\u957f\u671f\u53ef\u6301\u7eed\u6027\u8bc4\u4f30\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u9057\u5fd8\u57fa\u51c6\u4ec5\u5173\u6ce8\u5355\u6b21\u9057\u5fd8\u64cd\u4f5c\u7684\u95ee\u9898\uff0c\u4e3aLMMs\u63d0\u4f9b\u66f4\u73b0\u5b9e\u7684\u9057\u5fd8\u573a\u666f\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5f15\u5165PULSE\u534f\u8bae\uff0c\u4ece\u9884\u8bad\u7ec3\u77e5\u8bc6\u9057\u5fd8\u548c\u957f\u671f\u53ef\u6301\u7eed\u6027\u8bc4\u4f30\u4e24\u4e2a\u7ef4\u5ea6\u5206\u6790\u73b0\u6709\u9057\u5fd8\u65b9\u6cd5\u3002", "result": "\u73b0\u6709\u6280\u672f\u80fd\u6709\u6548\u9057\u5fd8\u5fae\u8c03\u77e5\u8bc6\uff0c\u4f46\u96be\u4ee5\u6d88\u9664\u9884\u8bad\u7ec3\u4fe1\u606f\uff1b\u5355\u6b21\u6279\u91cf\u9057\u5fd8\u65b9\u6cd5\u5728\u591a\u6b21\u64cd\u4f5c\u4e2d\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "PULSE\u534f\u8bae\u63ed\u793a\u4e86\u73b0\u6709\u9057\u5fd8\u6280\u672f\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2507.01313", "pdf": "https://arxiv.org/pdf/2507.01313", "abs": "https://arxiv.org/abs/2507.01313", "authors": ["Qian Qi"], "title": "Neural Hamiltonian Operator", "categories": ["cs.LG", "cs.AI", "math.DS", "math.OC"], "comment": null, "summary": "Stochastic control problems in high dimensions are notoriously difficult to\nsolve due to the curse of dimensionality. An alternative to traditional dynamic\nprogramming is Pontryagin's Maximum Principle (PMP), which recasts the problem\nas a system of Forward-Backward Stochastic Differential Equations (FBSDEs). In\nthis paper, we introduce a formal framework for solving such problems with deep\nlearning by defining a \\textbf{Neural Hamiltonian Operator (NHO)}. This\noperator parameterizes the coupled FBSDE dynamics via neural networks that\nrepresent the feedback control and an ansatz for the value function's spatial\ngradient. We show how the optimal NHO can be found by training the underlying\nnetworks to enforce the consistency conditions dictated by the PMP. By adopting\nthis operator-theoretic view, we situate the deep FBSDE method within the\nrigorous language of statistical inference, framing it as a problem of learning\nan unknown operator from simulated data. This perspective allows us to prove\nthe universal approximation capabilities of NHOs under general martingale\ndrivers and provides a clear lens for analyzing the significant optimization\nchallenges inherent to this class of models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u795e\u7ecf\u54c8\u5bc6\u987f\u7b97\u5b50\uff08NHO\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u9ad8\u7ef4\u968f\u673a\u63a7\u5236\u95ee\u9898\uff0c\u907f\u514d\u4e86\u7ef4\u5ea6\u707e\u96be\u3002", "motivation": "\u9ad8\u7ef4\u968f\u673a\u63a7\u5236\u95ee\u9898\u56e0\u7ef4\u5ea6\u707e\u96be\u96be\u4ee5\u89e3\u51b3\uff0c\u4f20\u7edf\u52a8\u6001\u89c4\u5212\u65b9\u6cd5\u6548\u7387\u4f4e\uff0c\u9700\u8981\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u795e\u7ecf\u54c8\u5bc6\u987f\u7b97\u5b50\uff08NHO\uff09\uff0c\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u524d\u5411-\u540e\u5411\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff08FBSDEs\uff09\uff0c\u5e76\u7528\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316\u63a7\u5236\u4e0e\u503c\u51fd\u6570\u7684\u68af\u5ea6\u3002", "result": "\u8bc1\u660e\u4e86NHO\u5728\u4e00\u822c\u9785\u9a71\u52a8\u4e0b\u7684\u901a\u7528\u903c\u8fd1\u80fd\u529b\uff0c\u5e76\u5206\u6790\u4e86\u4f18\u5316\u6311\u6218\u3002", "conclusion": "NHO\u4e3a\u9ad8\u7ef4\u968f\u673a\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5177\u6709\u7406\u8bba\u652f\u6301\u548c\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.01321", "pdf": "https://arxiv.org/pdf/2507.01321", "abs": "https://arxiv.org/abs/2507.01321", "authors": ["Zhiyao Ren", "Siyuan Liang", "Aishan Liu", "Dacheng Tao"], "title": "ICLShield: Exploring and Mitigating In-Context Learning Backdoor Attacks", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "ICML 2025", "summary": "In-context learning (ICL) has demonstrated remarkable success in large\nlanguage models (LLMs) due to its adaptability and parameter-free nature.\nHowever, it also introduces a critical vulnerability to backdoor attacks, where\nadversaries can manipulate LLM behaviors by simply poisoning a few ICL\ndemonstrations. In this paper, we propose, for the first time, the\ndual-learning hypothesis, which posits that LLMs simultaneously learn both the\ntask-relevant latent concepts and backdoor latent concepts within poisoned\ndemonstrations, jointly influencing the probability of model outputs. Through\ntheoretical analysis, we derive an upper bound for ICL backdoor effects,\nrevealing that the vulnerability is dominated by the concept preference ratio\nbetween the task and the backdoor. Motivated by these findings, we propose\nICLShield, a defense mechanism that dynamically adjusts the concept preference\nratio. Our method encourages LLMs to select clean demonstrations during the ICL\nphase by leveraging confidence and similarity scores, effectively mitigating\nsusceptibility to backdoor attacks. Extensive experiments across multiple LLMs\nand tasks demonstrate that our method achieves state-of-the-art defense\neffectiveness, significantly outperforming existing approaches (+26.02% on\naverage). Furthermore, our method exhibits exceptional adaptability and\ndefensive performance even for closed-source models (e.g., GPT-4).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u540e\u95e8\u653b\u51fb\u7684\u9632\u5fa1\u673a\u5236ICLShield\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u6982\u5ff5\u504f\u597d\u6bd4\u4f8b\uff0c\u6709\u6548\u51cf\u5c11\u653b\u51fb\u5f71\u54cd\u3002", "motivation": "ICL\u56e0\u5176\u9002\u5e94\u6027\u548c\u65e0\u9700\u53c2\u6570\u7684\u7279\u6027\u5728LLMs\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u4e5f\u6613\u53d7\u540e\u95e8\u653b\u51fb\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u5b89\u5168\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u53cc\u5b66\u4e60\u5047\u8bbe\uff0c\u5206\u6790ICL\u540e\u95e8\u6548\u5e94\u7684\u4e0a\u754c\uff0c\u5e76\u8bbe\u8ba1ICLShield\u673a\u5236\uff0c\u5229\u7528\u7f6e\u4fe1\u5ea6\u548c\u76f8\u4f3c\u5ea6\u5206\u6570\u52a8\u6001\u8c03\u6574\u6982\u5ff5\u504f\u597d\u6bd4\u4f8b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eICLShield\u5728\u591a\u79cdLLMs\u548c\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u5747\u9632\u5fa1\u6548\u679c\u63d0\u534726.02%\uff0c\u4e14\u5bf9\u95ed\u6e90\u6a21\u578b\uff08\u5982GPT-4\uff09\u4e5f\u6709\u6548\u3002", "conclusion": "ICLShield\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u6982\u5ff5\u504f\u597d\u6bd4\u4f8b\uff0c\u663e\u8457\u63d0\u5347\u4e86ICL\u7684\u5b89\u5168\u6027\uff0c\u4e3aLLMs\u7684\u9632\u5fa1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.01327", "pdf": "https://arxiv.org/pdf/2507.01327", "abs": "https://arxiv.org/abs/2507.01327", "authors": ["Xiaoyun Zhang", "Jingqing Ruan", "Xing Ma", "Yawen Zhu", "Jiansong Chen", "Ke Zeng", "Xunliang Cai"], "title": "Reasoner for Real-World Event Detection: Scaling Reinforcement Learning via Adaptive Perplexity-Aware Sampling Strategy", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages, 6 figures, submitted to EMNLP", "summary": "Detecting abnormal events in real-world customer service dialogues is highly\nchallenging due to the complexity of business data and the dynamic nature of\ncustomer interactions. Moreover, models must demonstrate strong out-of-domain\n(OOD) generalization to enable rapid adaptation across different business\nscenarios and maximize commercial value. In this work, we propose a novel\nAdaptive Perplexity-Aware Reinforcement Learning (APARL) framework that\nleverages the advanced reasoning capabilities of large language models for\nabnormal event detection. APARL introduces a dual-loop dynamic curriculum\nlearning architecture, enabling the model to progressively focus on more\nchallenging samples as its proficiency increases. This design effectively\naddresses performance bottlenecks and significantly enhances OOD\ntransferability. Extensive evaluations on food delivery dialogue tasks show\nthat our model achieves significantly enhanced adaptability and robustness,\nattaining the highest F1 score with an average improvement of 17.19\\%, and an\naverage improvement of 9.59\\% in OOD transfer tests. This method provides a\nsuperior solution for industrial deployment of anomaly detection models,\ncontributing to improved operational efficiency and commercial benefits.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u9002\u5e94\u56f0\u60d1\u5ea6\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\uff08APARL\uff09\u7684\u5f02\u5e38\u4e8b\u4ef6\u68c0\u6d4b\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3\u5ba2\u6237\u670d\u52a1\u5bf9\u8bdd\u4e2d\u5f02\u5e38\u4e8b\u4ef6\u68c0\u6d4b\u7684\u590d\u6742\u6027\u548c\u52a8\u6001\u6027\uff0c\u4ee5\u53ca\u6a21\u578b\u5728\u8de8\u4e1a\u52a1\u573a\u666f\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u91c7\u7528\u53cc\u73af\u52a8\u6001\u8bfe\u7a0b\u5b66\u4e60\u67b6\u6784\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\uff0c\u9010\u6b65\u805a\u7126\u66f4\u5177\u6311\u6218\u6027\u7684\u6837\u672c\u3002", "result": "\u5728\u98df\u54c1\u914d\u9001\u5bf9\u8bdd\u4efb\u52a1\u4e2d\uff0cF1\u5206\u6570\u5e73\u5747\u63d0\u534717.19%\uff0cOOD\u8fc1\u79fb\u6d4b\u8bd5\u5e73\u5747\u63d0\u53479.59%\u3002", "conclusion": "APARL\u4e3a\u5de5\u4e1a\u90e8\u7f72\u63d0\u4f9b\u4e86\u4f18\u8d8a\u7684\u5f02\u5e38\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\uff0c\u63d0\u5347\u4e86\u8fd0\u8425\u6548\u7387\u548c\u5546\u4e1a\u6548\u76ca\u3002"}}
{"id": "2507.01354", "pdf": "https://arxiv.org/pdf/2507.01354", "abs": "https://arxiv.org/abs/2507.01354", "authors": ["Chugang Yi", "Minghan Yu", "Weikang Qian", "Yixin Wen", "Haizhao Yang"], "title": "Efficient Kilometer-Scale Precipitation Downscaling with Conditional Wavelet Diffusion", "categories": ["cs.LG", "physics.ao-ph", "86A10 (Primary) 86A22, 68U10 (Secondary)", "J.2; I.4.4"], "comment": null, "summary": "Effective hydrological modeling and extreme weather analysis demand\nprecipitation data at a kilometer-scale resolution, which is significantly\nfiner than the 10 km scale offered by standard global products like IMERG. To\naddress this, we propose the Wavelet Diffusion Model (WDM), a generative\nframework that achieves 10x spatial super-resolution (downscaling to 1 km) and\ndelivers a 9x inference speedup over pixel-based diffusion models. WDM is a\nconditional diffusion model that learns the learns the complex structure of\nprecipitation from MRMS radar data directly in the wavelet domain. By focusing\non high-frequency wavelet coefficients, it generates exceptionally realistic\nand detailed 1-km precipitation fields. This wavelet-based approach produces\nvisually superior results with fewer artifacts than pixel-space models, and\ndelivers a significant gains in sampling efficiency. Our results demonstrate\nthat WDM provides a robust solution to the dual challenges of accuracy and\nspeed in geoscience super-resolution, paving the way for more reliable\nhydrological forecasts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c0f\u6ce2\u57df\u7684\u751f\u6210\u6a21\u578b\uff08WDM\uff09\uff0c\u7528\u4e8e\u5c06\u964d\u6c34\u6570\u636e\u4ece10 km\u5206\u8fa8\u7387\u964d\u5c3a\u5ea6\u52301 km\uff0c\u540c\u65f6\u663e\u8457\u63d0\u5347\u63a8\u7406\u901f\u5ea6\u548c\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u5168\u7403\u964d\u6c34\u6570\u636e\uff08\u5982IMERG\uff09\u5206\u8fa8\u7387\u8f83\u4f4e\uff0810 km\uff09\uff0c\u65e0\u6cd5\u6ee1\u8db3\u6c34\u6587\u5efa\u6a21\u548c\u6781\u7aef\u5929\u6c14\u5206\u6790\u7684\u9700\u6c42\u3002", "method": "WDM\u662f\u4e00\u79cd\u6761\u4ef6\u6269\u6563\u6a21\u578b\uff0c\u76f4\u63a5\u5728\u5c0f\u6ce2\u57df\u4e2d\u5b66\u4e60\u964d\u6c34\u6570\u636e\u7684\u590d\u6742\u7ed3\u6784\uff0c\u4e13\u6ce8\u4e8e\u9ad8\u9891\u5c0f\u6ce2\u7cfb\u6570\u4ee5\u751f\u6210\u9ad8\u5206\u8fa8\u7387\u964d\u6c34\u573a\u3002", "result": "WDM\u5b9e\u73b0\u4e8610\u500d\u7a7a\u95f4\u8d85\u5206\u8fa8\u7387\uff081 km\uff09\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u53479\u500d\uff0c\u4e14\u751f\u6210\u7ed3\u679c\u66f4\u771f\u5b9e\u3001\u7ec6\u8282\u66f4\u4e30\u5bcc\uff0c\u51cf\u5c11\u4e86\u4f2a\u5f71\u3002", "conclusion": "WDM\u4e3a\u5730\u7403\u79d1\u5b66\u8d85\u5206\u8fa8\u7387\u95ee\u9898\u63d0\u4f9b\u4e86\u51c6\u786e\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u6c34\u6587\u9884\u62a5\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2507.01381", "pdf": "https://arxiv.org/pdf/2507.01381", "abs": "https://arxiv.org/abs/2507.01381", "authors": ["Tong Liu", "Yinuo Wang", "Xujie Song", "Wenjun Zou", "Liangfa Chen", "Likun Wang", "Bin Shuai", "Jingliang Duan", "Shengbo Eben Li"], "title": "Distributional Soft Actor-Critic with Diffusion Policy", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted IEEE ITSC 2025", "summary": "Reinforcement learning has been proven to be highly effective in handling\ncomplex control tasks. Traditional methods typically use unimodal\ndistributions, such as Gaussian distributions, to model the output of value\ndistributions. However, unimodal distribution often and easily causes bias in\nvalue function estimation, leading to poor algorithm performance. This paper\nproposes a distributional reinforcement learning algorithm called DSAC-D\n(Distributed Soft Actor Critic with Diffusion Policy) to address the challenges\nof estimating bias in value functions and obtaining multimodal policy\nrepresentations. A multimodal distributional policy iteration framework that\ncan converge to the optimal policy was established by introducing policy\nentropy and value distribution function. A diffusion value network that can\naccurately characterize the distribution of multi peaks was constructed by\ngenerating a set of reward samples through reverse sampling using a diffusion\nmodel. Based on this, a distributional reinforcement learning algorithm with\ndual diffusion of the value network and the policy network was derived. MuJoCo\ntesting tasks demonstrate that the proposed algorithm not only learns\nmultimodal policy, but also achieves state-of-the-art (SOTA) performance in all\n9 control tasks, with significant suppression of estimation bias and total\naverage return improvement of over 10\\% compared to existing mainstream\nalgorithms. The results of real vehicle testing show that DSAC-D can accurately\ncharacterize the multimodal distribution of different driving styles, and the\ndiffusion policy network can characterize multimodal trajectories.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDSAC-D\u7b97\u6cd5\uff0c\u901a\u8fc7\u6269\u6563\u6a21\u578b\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u503c\u51fd\u6570\u4f30\u8ba1\u504f\u5dee\u95ee\u9898\uff0c\u5b9e\u73b0\u591a\u6a21\u6001\u7b56\u7565\u8868\u793a\uff0c\u5e76\u5728\u63a7\u5236\u4efb\u52a1\u4e2d\u53d6\u5f97SOTA\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f7f\u7528\u5355\u6a21\u6001\u5206\u5e03\uff08\u5982\u9ad8\u65af\u5206\u5e03\uff09\u5efa\u6a21\u503c\u5206\u5e03\uff0c\u5bb9\u6613\u5bfc\u81f4\u4f30\u8ba1\u504f\u5dee\u548c\u7b97\u6cd5\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u5f15\u5165\u7b56\u7565\u71b5\u548c\u503c\u5206\u5e03\u51fd\u6570\u6784\u5efa\u591a\u6a21\u6001\u5206\u5e03\u7b56\u7565\u8fed\u4ee3\u6846\u67b6\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u53cd\u5411\u91c7\u6837\u6784\u5efa\u6269\u6563\u503c\u7f51\u7edc\uff0c\u6700\u7ec8\u63d0\u51faDSAC-D\u7b97\u6cd5\u3002", "result": "\u57289\u4e2a\u63a7\u5236\u4efb\u52a1\u4e2d\u5b9e\u73b0SOTA\u6027\u80fd\uff0c\u4f30\u8ba1\u504f\u5dee\u663e\u8457\u6291\u5236\uff0c\u603b\u5e73\u5747\u56de\u62a5\u63d0\u5347\u8d8510%\u3002\u5b9e\u8f66\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u591a\u6a21\u6001\u9a7e\u9a76\u98ce\u683c\u8868\u5f81\u80fd\u529b\u3002", "conclusion": "DSAC-D\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u503c\u51fd\u6570\u4f30\u8ba1\u504f\u5dee\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u591a\u6a21\u6001\u7b56\u7565\u8868\u793a\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.01389", "pdf": "https://arxiv.org/pdf/2507.01389", "abs": "https://arxiv.org/abs/2507.01389", "authors": ["Anbang Wang", "Dunbo Cai", "Yu Zhang", "Yangqing Huang", "Xiangyang Feng", "Zhihong Zhang"], "title": "Surrogate Modeling via Factorization Machine and Ising Model with Enhanced Higher-Order Interaction Learning", "categories": ["cs.LG", "quant-ph"], "comment": null, "summary": "Recently, a surrogate model was proposed that employs a factorization machine\nto approximate the underlying input-output mapping of the original system, with\nquantum annealing used to optimize the resulting surrogate function. Inspired\nby this approach, we propose an enhanced surrogate model that incorporates\nadditional slack variables into both the factorization machine and its\nassociated Ising representation thereby unifying what was by design a two-step\nprocess into a single, integrated step. During the training phase, the slack\nvariables are iteratively updated, enabling the model to account for\nhigher-order feature interactions. We apply the proposed method to the task of\npredicting drug combination effects. Experimental results indicate that the\nintroduction of slack variables leads to a notable improvement of performance.\nOur algorithm offers a promising approach for building efficient surrogate\nmodels that exploit potential quantum advantages.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5165\u677e\u5f1b\u53d8\u91cf\u5c06\u4e24\u6b65\u8fc7\u7a0b\u7edf\u4e00\u4e3a\u4e00\u6b65\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u53d7\u73b0\u6709\u91cf\u5b50\u9000\u706b\u4f18\u5316\u4ee3\u7406\u6a21\u578b\u7684\u542f\u53d1\uff0c\u65e8\u5728\u901a\u8fc7\u677e\u5f1b\u53d8\u91cf\u6539\u8fdb\u6a21\u578b\u6027\u80fd\u3002", "method": "\u5728\u56e0\u5b50\u5206\u89e3\u673a\u53ca\u5176Ising\u8868\u793a\u4e2d\u5f15\u5165\u677e\u5f1b\u53d8\u91cf\uff0c\u8fed\u4ee3\u66f4\u65b0\u4ee5\u6355\u6349\u9ad8\u9636\u7279\u5f81\u4ea4\u4e92\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u677e\u5f1b\u53d8\u91cf\u7684\u5f15\u5165\u663e\u8457\u63d0\u5347\u4e86\u836f\u7269\u7ec4\u5408\u6548\u5e94\u9884\u6d4b\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5229\u7528\u91cf\u5b50\u4f18\u52bf\u6784\u5efa\u9ad8\u6548\u4ee3\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2507.01414", "pdf": "https://arxiv.org/pdf/2507.01414", "abs": "https://arxiv.org/abs/2507.01414", "authors": ["Sultan Daniels", "Dylan Davis", "Dhruv Gautam", "Wentinn Liao", "Gireeja Ranade", "Anant Sahai"], "title": "Decomposing Prediction Mechanisms for In-Context Recall", "categories": ["cs.LG"], "comment": "44 pages, 47 figures, 2 tables", "summary": "We introduce a new family of toy problems that combine features of\nlinear-regression-style continuous in-context learning (ICL) with discrete\nassociative recall. We pretrain transformer models on sample traces from this\ntoy, specifically symbolically-labeled interleaved state observations from\nrandomly drawn linear deterministic dynamical systems. We study if the\ntransformer models can recall the state of a sequence previously seen in its\ncontext when prompted to do so with the corresponding in-context label. Taking\na closer look at this task, it becomes clear that the model must perform two\nfunctions: (1) identify which system's state should be recalled and apply that\nsystem to its last seen state, and (2) continuing to apply the correct system\nto predict the subsequent states. Training dynamics reveal that the first\ncapability emerges well into a model's training. Surprisingly, the second\ncapability, of continuing the prediction of a resumed sequence, develops much\nearlier.\n  Via out-of-distribution experiments, and a mechanistic analysis on model\nweights via edge pruning, we find that next-token prediction for this toy\nproblem involves at least two separate mechanisms. One mechanism uses the\ndiscrete symbolic labels to do the associative recall required to predict the\nstart of a resumption of a previously seen sequence. The second mechanism,\nwhich is largely agnostic to the discrete symbolic labels, performs a\n\"Bayesian-style\" prediction based on the previous token and the context. These\ntwo mechanisms have different learning dynamics.\n  To confirm that this multi-mechanism (manifesting as separate phase\ntransitions) phenomenon is not just an artifact of our toy setting, we used\nOLMo training checkpoints on an ICL translation task to see a similar\nphenomenon: a decisive gap in the emergence of first-task-token performance vs\nsecond-task-token performance.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7ed3\u5408\u7ebf\u6027\u56de\u5f52\u5f0f\u8fde\u7eed\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u548c\u79bb\u6563\u5173\u8054\u53ec\u56de\u7684\u65b0\u73a9\u5177\u95ee\u9898\uff0c\u7814\u7a76\u4e86Transformer\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u9700\u8981\u4e24\u79cd\u673a\u5236\uff1a\u57fa\u4e8e\u6807\u7b7e\u7684\u5173\u8054\u53ec\u56de\u548c\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u8d1d\u53f6\u65af\u9884\u6d4b\u3002", "motivation": "\u63a2\u7d22Transformer\u6a21\u578b\u5728\u5904\u7406\u7ed3\u5408\u8fde\u7eed\u548c\u79bb\u6563\u7279\u5f81\u7684\u73a9\u5177\u95ee\u9898\u65f6\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5176\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u9884\u8bad\u7ec3Transformer\u6a21\u578b\u4e8e\u7b26\u53f7\u6807\u8bb0\u7684\u968f\u673a\u7ebf\u6027\u786e\u5b9a\u6027\u52a8\u6001\u7cfb\u7edf\u6837\u672c\uff0c\u5206\u6790\u5176\u5728\u5173\u8054\u53ec\u56de\u548c\u72b6\u6001\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u901a\u8fc7\u6743\u91cd\u4fee\u526a\u8fdb\u884c\u673a\u5236\u5206\u6790\u3002", "result": "\u6a21\u578b\u9700\u8981\u4e24\u79cd\u673a\u5236\uff1a\u57fa\u4e8e\u6807\u7b7e\u7684\u5173\u8054\u53ec\u56de\u548c\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u8d1d\u53f6\u65af\u9884\u6d4b\uff0c\u4e14\u8fd9\u4e24\u79cd\u673a\u5236\u7684\u5b66\u4e60\u52a8\u6001\u4e0d\u540c\u3002", "conclusion": "\u591a\u673a\u5236\u73b0\u8c61\u4e0d\u4ec5\u9650\u4e8e\u73a9\u5177\u95ee\u9898\uff0c\u5728\u771f\u5b9e\u4efb\u52a1\uff08\u5982ICL\u7ffb\u8bd1\uff09\u4e2d\u4e5f\u89c2\u5bdf\u5230\u7c7b\u4f3c\u73b0\u8c61\u3002"}}
{"id": "2507.01469", "pdf": "https://arxiv.org/pdf/2507.01469", "abs": "https://arxiv.org/abs/2507.01469", "authors": ["Alessio Ferrato", "Fabio Gasparetti", "Carla Limongelli", "Stefano Mastandrea", "Giuseppe Sansonetti", "Joaqu\u00edn Torres-Sospedra"], "title": "Cross-platform Smartphone Positioning at Museums", "categories": ["cs.LG", "eess.SP"], "comment": "Accepted at the 2025 International Conference on Indoor Positioning\n  and Indoor Navigation (IPIN), Tampere, Finland, September 15-18, 2025", "summary": "Indoor Positioning Systems (IPSs) hold significant potential for enhancing\nvisitor experiences in cultural heritage institutions. By enabling personalized\nnavigation, efficient artifact organization, and better interaction with\nexhibits, IPSs can transform the modalities of how individuals engage with\nmuseums, galleries and libraries. However, these institutions face several\nchallenges in implementing IPSs, including environmental constraints, technical\nlimits, and limited experimentation. In other contexts, Received Signal\nStrength (RSS)-based approaches using Bluetooth Low Energy (BLE) and WiFi have\nemerged as preferred solutions due to their non-invasive nature and minimal\ninfrastructure requirements. Nevertheless, the lack of publicly available RSS\ndatasets that specifically reflect museum environments presents a substantial\nbarrier to developing and evaluating positioning algorithms designed for the\nintricate spatial characteristics typical of cultural heritage sites. To\naddress this limitation, we present BAR, a novel RSS dataset collected in front\nof 90 artworks across 13 museum rooms using two different platforms, i.e.,\nAndroid and iOS. Additionally, we provide an advanced position classification\nbaseline taking advantage of a proximity-based method and $k$-NN algorithms. In\nour analysis, we discuss the results and offer suggestions for potential\nresearch directions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBAR\u7684\u65b0\u578bRSS\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u89e3\u51b3\u6587\u5316\u9057\u5740\u4e2d\u5ba4\u5185\u5b9a\u4f4d\u7cfb\u7edf\uff08IPS\uff09\u5f00\u53d1\u7684\u6570\u636e\u4e0d\u8db3\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e86\u57fa\u4e8e\u90bb\u8fd1\u6027\u548ck-NN\u7b97\u6cd5\u7684\u5206\u7c7b\u57fa\u7ebf\u3002", "motivation": "\u6587\u5316\u9057\u5740\u4e2d\u7684IPS\u53ef\u4ee5\u63d0\u5347\u8bbf\u5ba2\u4f53\u9a8c\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u535a\u7269\u9986\u73af\u5883\u7684\u516c\u5f00RSS\u6570\u636e\u96c6\u963b\u788d\u4e86\u76f8\u5173\u7b97\u6cd5\u7684\u5f00\u53d1\u4e0e\u8bc4\u4f30\u3002", "method": "\u6536\u96c6\u4e8690\u4ef6\u827a\u672f\u54c1\u524d\u7684RSS\u6570\u636e\uff08\u4f7f\u7528Android\u548ciOS\u5e73\u53f0\uff09\uff0c\u5e76\u91c7\u7528\u90bb\u8fd1\u6027\u65b9\u6cd5\u548ck-NN\u7b97\u6cd5\u5efa\u7acb\u5206\u7c7b\u57fa\u7ebf\u3002", "result": "\u63d0\u4f9b\u4e86BAR\u6570\u636e\u96c6\uff0c\u5e76\u5c55\u793a\u4e86\u57fa\u4e8e\u90bb\u8fd1\u6027\u548ck-NN\u7b97\u6cd5\u7684\u5206\u7c7b\u7ed3\u679c\u3002", "conclusion": "BAR\u6570\u636e\u96c6\u586b\u8865\u4e86\u535a\u7269\u9986\u73af\u5883RSS\u6570\u636e\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5e76\u63d0\u51fa\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.01470", "pdf": "https://arxiv.org/pdf/2507.01470", "abs": "https://arxiv.org/abs/2507.01470", "authors": ["Yannick Molinghen", "Tom Lenaerts"], "title": "Zero-Incentive Dynamics: a look at reward sparsity through the lens of unrewarded subgoals", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at \"Finding the Frame 2025\", workshop at RLC", "summary": "This work re-examines the commonly held assumption that the frequency of\nrewards is a reliable measure of task difficulty in reinforcement learning. We\nidentify and formalize a structural challenge that undermines the effectiveness\nof current policy learning methods: when essential subgoals do not directly\nyield rewards. We characterize such settings as exhibiting zero-incentive\ndynamics, where transitions critical to success remain unrewarded. We show that\nstate-of-the-art deep subgoal-based algorithms fail to leverage these dynamics\nand that learning performance is highly sensitive to the temporal proximity\nbetween subgoal completion and eventual reward. These findings reveal a\nfundamental limitation in current approaches and point to the need for\nmechanisms that can infer latent task structure without relying on immediate\nincentives.", "AI": {"tldr": "\u8bba\u6587\u6311\u6218\u4e86\u5956\u52b1\u9891\u7387\u4f5c\u4e3a\u4efb\u52a1\u96be\u5ea6\u8861\u91cf\u6807\u51c6\u7684\u5047\u8bbe\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u5173\u952e\u5b50\u76ee\u6807\u65e0\u76f4\u63a5\u5956\u52b1\u65f6\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u91cd\u65b0\u5ba1\u89c6\u5956\u52b1\u9891\u7387\u4e0e\u4efb\u52a1\u96be\u5ea6\u7684\u5173\u7cfb\uff0c\u89e3\u51b3\u5173\u952e\u5b50\u76ee\u6807\u65e0\u76f4\u63a5\u5956\u52b1\u65f6\u7684\u5b66\u4e60\u95ee\u9898\u3002", "method": "\u5f62\u5f0f\u5316\u96f6\u6fc0\u52b1\u52a8\u6001\u95ee\u9898\uff0c\u5206\u6790\u73b0\u6709\u5b50\u76ee\u6807\u7b97\u6cd5\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u7b97\u6cd5\u65e0\u6cd5\u6709\u6548\u5229\u7528\u96f6\u6fc0\u52b1\u52a8\u6001\uff0c\u5b66\u4e60\u6027\u80fd\u53d7\u5b50\u76ee\u6807\u4e0e\u5956\u52b1\u65f6\u95f4\u63a5\u8fd1\u5ea6\u5f71\u54cd\u3002", "conclusion": "\u6307\u51fa\u5f53\u524d\u65b9\u6cd5\u9700\u6539\u8fdb\uff0c\u9700\u5f00\u53d1\u80fd\u63a8\u65ad\u6f5c\u5728\u4efb\u52a1\u7ed3\u6784\u7684\u673a\u5236\u3002"}}
{"id": "2507.01516", "pdf": "https://arxiv.org/pdf/2507.01516", "abs": "https://arxiv.org/abs/2507.01516", "authors": ["Dibyanshu Kumar", "Philipp Vaeth", "Magda Gregorov\u00e1"], "title": "Loss Functions in Diffusion Models: A Comparative Study", "categories": ["cs.LG"], "comment": "Accepted to ECML 2025", "summary": "Diffusion models have emerged as powerful generative models, inspiring\nextensive research into their underlying mechanisms. One of the key questions\nin this area is the loss functions these models shall train with. Multiple\nformulations have been introduced in the literature over the past several years\nwith some links and some critical differences stemming from various initial\nconsiderations. In this paper, we explore the different target objectives and\ncorresponding loss functions in detail. We present a systematic overview of\ntheir relationships, unifying them under the framework of the variational lower\nbound objective. We complement this theoretical analysis with an empirical\nstudy providing insights into the conditions under which these objectives\ndiverge in performance and the underlying factors contributing to such\ndeviations. Additionally, we evaluate how the choice of objective impacts the\nmodel ability to achieve specific goals, such as generating high-quality\nsamples or accurately estimating likelihoods. This study offers a unified\nunderstanding of loss functions in diffusion models, contributing to more\nefficient and goal-oriented model designs in future research.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u6269\u6563\u6a21\u578b\u4e2d\u4e0d\u540c\u76ee\u6807\u51fd\u6570\u53ca\u5176\u5bf9\u5e94\u7684\u635f\u5931\u51fd\u6570\uff0c\u7edf\u4e00\u4e86\u5b83\u4eec\u5728\u53d8\u5206\u4e0b\u754c\u76ee\u6807\u6846\u67b6\u4e0b\u7684\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u63ed\u793a\u4e86\u8fd9\u4e9b\u76ee\u6807\u5728\u6027\u80fd\u4e0a\u7684\u5dee\u5f02\u53ca\u5176\u539f\u56e0\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u5f3a\u5927\u7684\u751f\u6210\u6a21\u578b\uff0c\u5176\u635f\u5931\u51fd\u6570\u7684\u9009\u62e9\u662f\u5173\u952e\u95ee\u9898\u3002\u5df2\u6709\u591a\u79cd\u635f\u5931\u51fd\u6570\u88ab\u63d0\u51fa\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u89c6\u89d2\u548c\u5b9e\u8bc1\u6bd4\u8f83\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u5c06\u4e0d\u540c\u635f\u5931\u51fd\u6570\u7edf\u4e00\u5230\u53d8\u5206\u4e0b\u754c\u76ee\u6807\u6846\u67b6\u4e0b\uff0c\u5e76\u8f85\u4ee5\u5b9e\u8bc1\u7814\u7a76\uff0c\u6bd4\u8f83\u4e0d\u540c\u76ee\u6807\u5728\u751f\u6210\u8d28\u91cf\u548c\u4f3c\u7136\u4f30\u8ba1\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u635f\u5931\u51fd\u6570\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u6027\u80fd\u5b58\u5728\u5dee\u5f02\uff0c\u5e76\u63ed\u793a\u4e86\u5f71\u54cd\u8fd9\u4e9b\u5dee\u5f02\u7684\u56e0\u7d20\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u6269\u6563\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\u63d0\u4f9b\u4e86\u7edf\u4e00\u7406\u89e3\uff0c\u6709\u52a9\u4e8e\u672a\u6765\u66f4\u9ad8\u6548\u548c\u9488\u5bf9\u6027\u7684\u6a21\u578b\u8bbe\u8ba1\u3002"}}
{"id": "2507.01522", "pdf": "https://arxiv.org/pdf/2507.01522", "abs": "https://arxiv.org/abs/2507.01522", "authors": ["Koen Ponse", "Jan Felix Kleuker", "Aske Plaat", "Thomas Moerland"], "title": "Chargax: A JAX Accelerated EV Charging Simulator", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": "Accepted at RLC 2025", "summary": "Deep Reinforcement Learning can play a key role in addressing sustainable\nenergy challenges. For instance, many grid systems are heavily congested,\nhighlighting the urgent need to enhance operational efficiency. However,\nreinforcement learning approaches have traditionally been slow due to the high\nsample complexity and expensive simulation requirements. While recent works\nhave effectively used GPUs to accelerate data generation by converting\nenvironments to JAX, these works have largely focussed on classical toy\nproblems. This paper introduces Chargax, a JAX-based environment for realistic\nsimulation of electric vehicle charging stations designed for accelerated\ntraining of RL agents. We validate our environment in a variety of scenarios\nbased on real data, comparing reinforcement learning agents against baselines.\nChargax delivers substantial computational performance improvements of over\n100x-1000x over existing environments. Additionally, Chargax' modular\narchitecture enables the representation of diverse real-world charging station\nconfigurations.", "AI": {"tldr": "Chargax\u662f\u4e00\u4e2a\u57fa\u4e8eJAX\u7684\u7535\u52a8\u8f66\u5145\u7535\u7ad9\u4eff\u771f\u73af\u5883\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6548\u7387\uff0c\u6027\u80fd\u63d0\u5347100x-1000x\u3002", "motivation": "\u7535\u7f51\u7cfb\u7edf\u62e5\u5835\u95ee\u9898\u6025\u9700\u63d0\u5347\u8fd0\u884c\u6548\u7387\uff0c\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u56e0\u9ad8\u6837\u672c\u590d\u6742\u5ea6\u548c\u4eff\u771f\u6210\u672c\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u5f00\u53d1\u4e86Chargax\uff0c\u4e00\u4e2a\u57fa\u4e8eJAX\u7684\u7535\u52a8\u8f66\u5145\u7535\u7ad9\u4eff\u771f\u73af\u5883\uff0c\u652f\u6301\u6a21\u5757\u5316\u914d\u7f6e\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u573a\u666f\u4e2d\u9a8c\u8bc1\uff0c\u6027\u80fd\u63d0\u5347100x-1000x\uff0c\u5e76\u80fd\u7075\u6d3b\u6a21\u62df\u591a\u79cd\u5145\u7535\u7ad9\u914d\u7f6e\u3002", "conclusion": "Chargax\u4e3a\u53ef\u6301\u7eed\u80fd\u6e90\u6311\u6218\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01544", "pdf": "https://arxiv.org/pdf/2507.01544", "abs": "https://arxiv.org/abs/2507.01544", "authors": ["Benjamin Feuer", "Lennart Purucker", "Oussama Elachqar", "Chinmay Hegde"], "title": "MARVIS: Modality Adaptive Reasoning over VISualizations", "categories": ["cs.LG"], "comment": null, "summary": "Scientific applications of machine learning often rely on small, specialized\nmodels tuned to particular domains. Such models often achieve excellent\nperformance, but lack flexibility. Foundation models offer versatility, but\ntypically underperform specialized approaches, especially on non-traditional\nmodalities and long-tail domains. We propose MARVIS (Modality Adaptive\nReasoning over VISualizations), a training-free method that enables even small\nvision-language models to predict any data modality with high accuracy. MARVIS\ntransforms latent embedding spaces into visual representations and then\nleverages the spatial and fine-grained reasoning skills of VLMs to successfully\ninterpret and utilize them. MARVIS achieves competitive performance on vision,\naudio, biological, and tabular domains using a single 3B parameter model,\nachieving results that beat Gemini by 16\\% on average and approach specialized\nmethods, without exposing personally identifiable information (P.I.I.) or\nrequiring any domain-specific training. We open source our code and datasets at\nhttps://github.com/penfever/marvis", "AI": {"tldr": "MARVIS\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6f5c\u5728\u5d4c\u5165\u7a7a\u95f4\u8f6c\u6362\u4e3a\u89c6\u89c9\u8868\u793a\uff0c\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u548c\u7ec6\u7c92\u5ea6\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u73b0\u591a\u6a21\u6001\u6570\u636e\u7684\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u3002", "motivation": "\u89e3\u51b3\u5c0f\u89c4\u6a21\u4e13\u7528\u6a21\u578b\u7f3a\u4e4f\u7075\u6d3b\u6027\u548c\u57fa\u7840\u6a21\u578b\u5728\u975e\u4f20\u7edf\u6a21\u6001\u548c\u957f\u5c3e\u9886\u57df\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u5c06\u6f5c\u5728\u5d4c\u5165\u7a7a\u95f4\u8f6c\u6362\u4e3a\u89c6\u89c9\u8868\u793a\uff0c\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u548c\u7ec6\u7c92\u5ea6\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u5728\u89c6\u89c9\u3001\u97f3\u9891\u3001\u751f\u7269\u548c\u8868\u683c\u9886\u57df\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u5747\u6027\u80fd\u8d85\u8fc7Gemini 16%\uff0c\u63a5\u8fd1\u4e13\u7528\u65b9\u6cd5\u3002", "conclusion": "MARVIS\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u4fdd\u62a4\u9690\u79c1\u7684\u591a\u6a21\u6001\u9884\u6d4b\u65b9\u6cd5\uff0c\u6027\u80fd\u63a5\u8fd1\u4e13\u7528\u6a21\u578b\u3002"}}
{"id": "2507.01551", "pdf": "https://arxiv.org/pdf/2507.01551", "abs": "https://arxiv.org/abs/2507.01551", "authors": ["Wu Fei", "Hao Kong", "Shuxian Liang", "Yang Lin", "Yibo Yang", "Jing Tang", "Lei Chen", "Xiansheng Hua"], "title": "Self-Guided Process Reward Optimization with Masked Step Advantage for Process Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Process Reinforcement Learning~(PRL) has demonstrated considerable potential\nin enhancing the reasoning capabilities of Large Language Models~(LLMs).\nHowever, introducing additional process reward models incurs substantial\ncomputational overhead, and there is no unified theoretical framework for\nprocess-level advantage estimation. To bridge this gap, we propose\n\\textbf{S}elf-Guided \\textbf{P}rocess \\textbf{R}eward\n\\textbf{O}ptimization~(\\textbf{SPRO}), a novel framework that enables\nprocess-aware RL through two key innovations: (1) we first theoretically\ndemonstrate that process rewards can be derived intrinsically from the policy\nmodel itself, and (2) we introduce well-defined cumulative process rewards and\n\\textbf{M}asked \\textbf{S}tep \\textbf{A}dvantage (\\textbf{MSA}), which\nfacilitates rigorous step-wise action advantage estimation within shared-prompt\nsampling groups. Our experimental results demonstrate that SPRO outperforms\nvaniila GRPO with 3.4x higher training efficiency and a 17.5\\% test accuracy\nimprovement. Furthermore, SPRO maintains a stable and elevated policy entropy\nthroughout training while reducing the average response length by approximately\n$1/3$, evidencing sufficient exploration and prevention of reward hacking.\nNotably, SPRO incurs no additional computational overhead compared to\noutcome-supervised RL methods such as GRPO, which benefit industrial\nimplementation.", "AI": {"tldr": "SPRO\u662f\u4e00\u79cd\u81ea\u5f15\u5bfc\u8fc7\u7a0b\u5956\u52b1\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5185\u5728\u5956\u52b1\u548c\u63a9\u7801\u6b65\u9aa4\u4f18\u52bf\u4f30\u8ba1\u63d0\u5347LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u663e\u8457\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u6d4b\u8bd5\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u8fc7\u7a0b\u5f3a\u5316\u5b66\u4e60\u4e2d\u8ba1\u7b97\u5f00\u9500\u5927\u548c\u7f3a\u4e4f\u7edf\u4e00\u7406\u8bba\u6846\u67b6\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faSPRO\u6846\u67b6\uff0c\u5305\u62ec\u5185\u5728\u8fc7\u7a0b\u5956\u52b1\u548c\u63a9\u7801\u6b65\u9aa4\u4f18\u52bf\u4f30\u8ba1\uff08MSA\uff09\u3002", "result": "SPRO\u8bad\u7ec3\u6548\u7387\u63d0\u9ad83.4\u500d\uff0c\u6d4b\u8bd5\u51c6\u786e\u7387\u63d0\u534717.5%\uff0c\u4e14\u65e0\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "SPRO\u5728\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u4e86\u9ad8\u6548\u548c\u7a33\u5b9a\uff0c\u9002\u7528\u4e8e\u5de5\u4e1a\u5b9e\u73b0\u3002"}}
{"id": "2507.01559", "pdf": "https://arxiv.org/pdf/2507.01559", "abs": "https://arxiv.org/abs/2507.01559", "authors": ["Lapo Frati", "Neil Traft", "Jeff Clune", "Nick Cheney"], "title": "How Weight Resampling and Optimizers Shape the Dynamics of Continual Learning and Forgetting in Neural Networks", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Recent work in continual learning has highlighted the beneficial effect of\nresampling weights in the last layer of a neural network (``zapping\"). Although\nempirical results demonstrate the effectiveness of this approach, the\nunderlying mechanisms that drive these improvements remain unclear. In this\nwork, we investigate in detail the pattern of learning and forgetting that take\nplace inside a convolutional neural network when trained in challenging\nsettings such as continual learning and few-shot transfer learning, with\nhandwritten characters and natural images. Our experiments show that models\nthat have undergone zapping during training more quickly recover from the shock\nof transferring to a new domain. Furthermore, to better observe the effect of\ncontinual learning in a multi-task setting we measure how each individual task\nis affected. This shows that, not only zapping, but the choice of optimizer can\nalso deeply affect the dynamics of learning and forgetting, causing complex\npatterns of synergy/interference between tasks to emerge when the model learns\nsequentially at transfer time.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u795e\u7ecf\u7f51\u7edc\u6700\u540e\u4e00\u5c42\u6743\u91cd\u91cd\u91c7\u6837\uff08\u201czapping\u201d\uff09\u5728\u6301\u7eed\u5b66\u4e60\u548c\u5c11\u6837\u672c\u8fc1\u79fb\u5b66\u4e60\u4e2d\u7684\u4f5c\u7528\uff0c\u53d1\u73b0\u5176\u80fd\u52a0\u901f\u6a21\u578b\u5728\u65b0\u9886\u57df\u7684\u6062\u590d\uff0c\u5e76\u63ed\u793a\u4e86\u4f18\u5316\u5668\u9009\u62e9\u5bf9\u5b66\u4e60\u52a8\u6001\u7684\u590d\u6742\u5f71\u54cd\u3002", "motivation": "\u7406\u89e3zapping\u5728\u6301\u7eed\u5b66\u4e60\u548c\u5c11\u6837\u672c\u8fc1\u79fb\u5b66\u4e60\u4e2d\u7684\u673a\u5236\u53ca\u5176\u5bf9\u6a21\u578b\u6062\u590d\u901f\u5ea6\u7684\u5f71\u54cd\u3002", "method": "\u5728\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u901a\u8fc7\u624b\u5199\u5b57\u7b26\u548c\u81ea\u7136\u56fe\u50cf\u7684\u5b9e\u9a8c\uff0c\u5206\u6790zapping\u548c\u4f18\u5316\u5668\u9009\u62e9\u5bf9\u5b66\u4e60\u52a8\u6001\u7684\u5f71\u54cd\u3002", "result": "zapping\u80fd\u52a0\u901f\u6a21\u578b\u5728\u65b0\u9886\u57df\u7684\u6062\u590d\uff0c\u4f18\u5316\u5668\u9009\u62e9\u4f1a\u5f71\u54cd\u4efb\u52a1\u95f4\u7684\u534f\u540c/\u5e72\u6270\u6a21\u5f0f\u3002", "conclusion": "zapping\u548c\u4f18\u5316\u5668\u9009\u62e9\u5bf9\u6301\u7eed\u5b66\u4e60\u548c\u8fc1\u79fb\u5b66\u4e60\u7684\u52a8\u6001\u6709\u663e\u8457\u5f71\u54cd\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u673a\u5236\u3002"}}
{"id": "2507.01581", "pdf": "https://arxiv.org/pdf/2507.01581", "abs": "https://arxiv.org/abs/2507.01581", "authors": ["Masood Jan", "Wafa Njima", "Xun Zhang"], "title": "A Privacy-Preserving Indoor Localization System based on Hierarchical Federated Learning", "categories": ["cs.LG", "cs.CR", "eess.SP"], "comment": null, "summary": "Location information serves as the fundamental element for numerous Internet\nof Things (IoT) applications. Traditional indoor localization techniques often\nproduce significant errors and raise privacy concerns due to centralized data\ncollection. In response, Machine Learning (ML) techniques offer promising\nsolutions by capturing indoor environment variations. However, they typically\nrequire central data aggregation, leading to privacy, bandwidth, and server\nreliability issues. To overcome these challenges, in this paper, we propose a\nFederated Learning (FL)-based approach for dynamic indoor localization using a\nDeep Neural Network (DNN) model. Experimental results show that FL has the\nnearby performance to Centralized Model (CL) while keeping the data privacy,\nbandwidth efficiency and server reliability. This research demonstrates that\nour proposed FL approach provides a viable solution for privacy-enhanced indoor\nlocalization, paving the way for advancements in secure and efficient indoor\nlocalization systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u7684\u52a8\u6001\u5ba4\u5185\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u7684\u9690\u79c1\u3001\u5e26\u5bbd\u548c\u670d\u52a1\u5668\u53ef\u9760\u6027\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u5ba4\u5185\u5b9a\u4f4d\u6280\u672f\u8bef\u5dee\u5927\u4e14\u5b58\u5728\u9690\u79c1\u95ee\u9898\uff0c\u96c6\u4e2d\u5f0f\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u867d\u6709\u6548\u4f46\u4ecd\u6709\u9690\u79c1\u548c\u5e26\u5bbd\u7b49\u6311\u6218\u3002", "method": "\u91c7\u7528\u8054\u90a6\u5b66\u4e60\u7ed3\u5408\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u6a21\u578b\u8fdb\u884c\u52a8\u6001\u5ba4\u5185\u5b9a\u4f4d\u3002", "result": "\u5b9e\u9a8c\u8868\u660eFL\u6027\u80fd\u63a5\u8fd1\u96c6\u4e2d\u5f0f\u6a21\u578b\uff08CL\uff09\uff0c\u540c\u65f6\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u3001\u63d0\u9ad8\u5e26\u5bbd\u6548\u7387\u548c\u670d\u52a1\u5668\u53ef\u9760\u6027\u3002", "conclusion": "FL\u4e3a\u9690\u79c1\u589e\u5f3a\u7684\u5ba4\u5185\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u5b89\u5168\u9ad8\u6548\u5b9a\u4f4d\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.01598", "pdf": "https://arxiv.org/pdf/2507.01598", "abs": "https://arxiv.org/abs/2507.01598", "authors": ["Naoki Sato", "Hiroki Naganuma", "Hideaki Iiduka"], "title": "Analysis of Muon's Convergence and Critical Batch Size", "categories": ["cs.LG"], "comment": null, "summary": "This paper presents a theoretical analysis of Muon, a new optimizer that\nleverages the inherent matrix structure of neural network parameters. We\nprovide convergence proofs for four practical variants of Muon: with and\nwithout Nesterov momentum, and with and without weight decay. We then show that\nadding weight decay leads to strictly tighter bounds on both the parameter and\ngradient norms, and we clarify the relationship between the weight decay\ncoefficient and the learning rate. Finally, we derive Muon's critical batch\nsize minimizing the stochastic first-order oracle (SFO) complexity, which is\nthe stochastic computational cost, and validate our theoretical findings with\nexperiments.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86Muon\u4f18\u5316\u5668\u7684\u7406\u8bba\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u56db\u79cd\u53d8\u4f53\u7684\u6536\u655b\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u6743\u91cd\u8870\u51cf\u5bf9\u53c2\u6570\u548c\u68af\u5ea6\u8303\u6570\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u63a8\u5bfc\u4e86\u6700\u5c0f\u5316\u8ba1\u7b97\u6210\u672c\u7684\u4e34\u754c\u6279\u91cf\u5927\u5c0f\u3002", "motivation": "\u7814\u7a76Muon\u4f18\u5316\u5668\u7684\u7406\u8bba\u6027\u80fd\u53ca\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u6743\u91cd\u8870\u51cf\u548c\u5b66\u4e60\u7387\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u56db\u79cdMuon\u53d8\u4f53\u7684\u6536\u655b\u6027\uff0c\u5e76\u63a8\u5bfc\u4e86\u4e34\u754c\u6279\u91cf\u5927\u5c0f\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002", "result": "\u6743\u91cd\u8870\u51cf\u80fd\u66f4\u4e25\u683c\u5730\u9650\u5236\u53c2\u6570\u548c\u68af\u5ea6\u8303\u6570\uff0c\u4e34\u754c\u6279\u91cf\u5927\u5c0f\u53ef\u6700\u5c0f\u5316\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "Muon\u4f18\u5316\u5668\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u6743\u91cd\u8870\u51cf\u548c\u4e34\u754c\u6279\u91cf\u5927\u5c0f\u7684\u5206\u6790\u4e3a\u5176\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2507.01636", "pdf": "https://arxiv.org/pdf/2507.01636", "abs": "https://arxiv.org/abs/2507.01636", "authors": ["Ghasem Alipoor", "Karl Skretting"], "title": "Kernel Recursive Least Squares Dictionary Learning Algorithm", "categories": ["cs.LG", "eess.SP"], "comment": "Published in Digital Signal Processing, Volume 141, 2023. DOI:\n  https://doi.org/10.1016/j.dsp.2023.104159 12 pages, 8 figures. Code and data\n  available at: https://github.com/G-Alipoor/kernel-rls-dictionary-learning", "summary": "We propose an efficient online dictionary learning algorithm for kernel-based\nsparse representations. In this framework, input signals are nonlinearly mapped\nto a high-dimensional feature space and represented sparsely using a virtual\ndictionary. At each step, the dictionary is updated recursively using a novel\nalgorithm based on the recursive least squares (RLS) method. This update\nmechanism works with single samples or mini-batches and maintains low\ncomputational complexity. Experiments on four datasets across different domains\nshow that our method not only outperforms existing online kernel dictionary\nlearning approaches but also achieves classification accuracy close to that of\nbatch-trained models, while remaining significantly more efficient.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5728\u7ebf\u6838\u7a00\u758f\u8868\u793a\u5b57\u5178\u5b66\u4e60\u7b97\u6cd5\uff0c\u57fa\u4e8eRLS\u65b9\u6cd5\u9012\u5f52\u66f4\u65b0\u5b57\u5178\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u5728\u7ebf\u65b9\u6cd5\uff0c\u63a5\u8fd1\u6279\u91cf\u8bad\u7ec3\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u5728\u7ebf\u6838\u7a00\u758f\u8868\u793a\u5b57\u5178\u5b66\u4e60\u7684\u9ad8\u6548\u6027\u95ee\u9898\uff0c\u63d0\u5347\u5206\u7c7b\u51c6\u786e\u7387\u5e76\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "method": "\u91c7\u7528\u9012\u5f52\u6700\u5c0f\u4e8c\u4e58\u6cd5\uff08RLS\uff09\u9012\u5f52\u66f4\u65b0\u5b57\u5178\uff0c\u652f\u6301\u5355\u6837\u672c\u6216\u5c0f\u6279\u91cf\u5904\u7406\u3002", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u5728\u7ebf\u65b9\u6cd5\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u63a5\u8fd1\u6279\u91cf\u8bad\u7ec3\u6a21\u578b\uff0c\u4e14\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\uff0c\u9002\u7528\u4e8e\u5728\u7ebf\u6838\u7a00\u758f\u8868\u793a\u5b66\u4e60\u3002"}}
{"id": "2507.01644", "pdf": "https://arxiv.org/pdf/2507.01644", "abs": "https://arxiv.org/abs/2507.01644", "authors": ["Miguel O'Malley"], "title": "Dance Dance ConvLSTM", "categories": ["cs.LG"], "comment": "15 pages, 9 figures, 4 tables", "summary": "\\textit{Dance Dance Revolution} is a rhythm game consisting of songs and\naccompanying choreography, referred to as charts. Players press arrows on a\ndevice referred to as a dance pad in time with steps determined by the song's\nchart. In 2017, the authors of Dance Dance Convolution (DDC) developed an\nalgorithm for the automatic generation of \\textit{Dance Dance Revolution}\ncharts, utilizing a CNN-LSTM architecture. We introduce Dance Dance ConvLSTM\n(DDCL), a new method for the automatic generation of DDR charts using a\nConvLSTM based model, which improves upon the DDC methodology and substantially\nincreases the accuracy of chart generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eConvLSTM\u7684\u65b0\u65b9\u6cd5DDCL\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u300aDance Dance Revolution\u300b\u6e38\u620f\u4e2d\u7684\u821e\u8e48\u56fe\u8868\uff0c\u6539\u8fdb\u4e86\u4e4b\u524d\u7684DDC\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u51c6\u786e\u6027\u3002", "motivation": "\u6539\u8fdb\u73b0\u6709\u7684Dance Dance Convolution (DDC)\u65b9\u6cd5\uff0c\u901a\u8fc7\u66f4\u5148\u8fdb\u7684\u6a21\u578b\u63d0\u9ad8\u821e\u8e48\u56fe\u8868\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u8d28\u91cf\u3002", "method": "\u4f7f\u7528ConvLSTM\u67b6\u6784\u66ff\u4ee3DDC\u4e2d\u7684CNN-LSTM\uff0c\u4f18\u5316\u6a21\u578b\u4ee5\u66f4\u597d\u5730\u6355\u6349\u97f3\u4e50\u8282\u594f\u4e0e\u821e\u8e48\u52a8\u4f5c\u7684\u5173\u7cfb\u3002", "result": "DDCL\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u821e\u8e48\u56fe\u8868\u751f\u6210\u7684\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u4e4b\u524d\u7684DDC\u65b9\u6cd5\u3002", "conclusion": "ConvLSTM\u67b6\u6784\u5728\u81ea\u52a8\u751f\u6210\u821e\u8e48\u56fe\u8868\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u4e3a\u6e38\u620f\u5185\u5bb9\u751f\u6210\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u5de5\u5177\u3002"}}
{"id": "2507.01649", "pdf": "https://arxiv.org/pdf/2507.01649", "abs": "https://arxiv.org/abs/2507.01649", "authors": ["Yoav Gelberg", "Yam Eitan", "Aviv Navon", "Aviv Shamsian", "Theo", "Putterman", "Michael Bronstein", "Haggai Maron"], "title": "GradMetaNet: An Equivariant Architecture for Learning on Gradients", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Gradients of neural networks encode valuable information for optimization,\nediting, and analysis of models. Therefore, practitioners often treat gradients\nas inputs to task-specific algorithms, e.g. for pruning or optimization. Recent\nworks explore learning algorithms that operate directly on gradients but use\narchitectures that are not specifically designed for gradient processing,\nlimiting their applicability. In this paper, we present a principled approach\nfor designing architectures that process gradients. Our approach is guided by\nthree principles: (1) equivariant design that preserves neuron permutation\nsymmetries, (2) processing sets of gradients across multiple data points to\ncapture curvature information, and (3) efficient gradient representation\nthrough rank-1 decomposition. Based on these principles, we introduce\nGradMetaNet, a novel architecture for learning on gradients, constructed from\nsimple equivariant blocks. We prove universality results for GradMetaNet, and\nshow that previous approaches cannot approximate natural gradient-based\nfunctions that GradMetaNet can. We then demonstrate GradMetaNet's effectiveness\non a diverse set of gradient-based tasks on MLPs and transformers, such as\nlearned optimization, INR editing, and estimating loss landscape curvature.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGradMetaNet\u7684\u65b0\u67b6\u6784\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u5904\u7406\u795e\u7ecf\u7f51\u7edc\u68af\u5ea6\uff0c\u57fa\u4e8e\u4e09\u4e2a\u539f\u5219\uff1a\u7b49\u53d8\u6027\u8bbe\u8ba1\u3001\u591a\u6570\u636e\u70b9\u68af\u5ea6\u96c6\u5904\u7406\u548c\u9ad8\u6548\u68af\u5ea6\u8868\u793a\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u68af\u5ea6\u65f6\u672a\u9488\u5bf9\u68af\u5ea6\u5904\u7406\u8bbe\u8ba1\u4e13\u95e8\u67b6\u6784\uff0c\u9650\u5236\u4e86\u5176\u9002\u7528\u6027\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51faGradMetaNet\u67b6\u6784\uff0c\u57fa\u4e8e\u7b49\u53d8\u6027\u8bbe\u8ba1\u3001\u591a\u6570\u636e\u70b9\u68af\u5ea6\u96c6\u5904\u7406\u548c\u79e91\u5206\u89e3\u7684\u9ad8\u6548\u8868\u793a\u3002", "result": "GradMetaNet\u5728\u591a\u79cd\u68af\u5ea6\u4efb\u52a1\uff08\u5982\u4f18\u5316\u3001\u7f16\u8f91\u548c\u66f2\u7387\u4f30\u8ba1\uff09\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "GradMetaNet\u4e3a\u68af\u5ea6\u5904\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u4efb\u52a1\u3002"}}
{"id": "2507.01663", "pdf": "https://arxiv.org/pdf/2507.01663", "abs": "https://arxiv.org/abs/2507.01663", "authors": ["Zhenyu Han", "Ansheng You", "Haibo Wang", "Kui Luo", "Guang Yang", "Wenqi Shi", "Menglong Chen", "Sicheng Zhang", "Zeshun Lan", "Chunshi Deng", "Huazhong Ji", "Wenjie Liu", "Yu Huang", "Yixiang Zhang", "Chenyi Pan", "Jing Wang", "Xin Huang", "Chunsheng Li", "Jianping Wu"], "title": "AsyncFlow: An Asynchronous Streaming RL Framework for Efficient LLM Post-Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has become a pivotal technology in the\npost-training phase of large language models (LLMs). Traditional task-colocated\nRL frameworks suffer from significant scalability bottlenecks, while\ntask-separated RL frameworks face challenges in complex dataflows and the\ncorresponding resource idling and workload imbalance. Moreover, most existing\nframeworks are tightly coupled with LLM training or inference engines, making\nit difficult to support custom-designed engines. To address these challenges,\nwe propose AsyncFlow, an asynchronous streaming RL framework for efficient\npost-training. Specifically, we introduce a distributed data storage and\ntransfer module that provides a unified data management and fine-grained\nscheduling capability in a fully streamed manner. This architecture inherently\nfacilitates automated pipeline overlapping among RL tasks and dynamic load\nbalancing. Moreover, we propose a producer-consumer-based asynchronous workflow\nengineered to minimize computational idleness by strategically deferring\nparameter update process within staleness thresholds. Finally, the core\ncapability of AsynFlow is architecturally decoupled from underlying training\nand inference engines and encapsulated by service-oriented user interfaces,\noffering a modular and customizable user experience. Extensive experiments\ndemonstrate an average of 1.59 throughput improvement compared with\nstate-of-the-art baseline. The presented architecture in this work provides\nactionable insights for next-generation RL training system designs.", "AI": {"tldr": "AsyncFlow\u662f\u4e00\u4e2a\u5f02\u6b65\u6d41\u5f0f\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u540e\u8bad\u7ec3\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfRL\u6846\u67b6\u7684\u53ef\u6269\u5c55\u6027\u548c\u8d44\u6e90\u5229\u7528\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfRL\u6846\u67b6\u5728\u6269\u5c55\u6027\u548c\u8d44\u6e90\u5229\u7528\u4e0a\u5b58\u5728\u74f6\u9888\uff0c\u4e14\u4e0eLLM\u8bad\u7ec3\u6216\u63a8\u7406\u5f15\u64ce\u7d27\u5bc6\u8026\u5408\uff0c\u96be\u4ee5\u652f\u6301\u81ea\u5b9a\u4e49\u5f15\u64ce\u3002", "method": "\u63d0\u51fa\u5206\u5e03\u5f0f\u6570\u636e\u5b58\u50a8\u548c\u4f20\u8f93\u6a21\u5757\uff0c\u652f\u6301\u6d41\u5f0f\u6570\u636e\u7ba1\u7406\u548c\u7ec6\u7c92\u5ea6\u8c03\u5ea6\uff1b\u91c7\u7528\u751f\u4ea7\u8005-\u6d88\u8d39\u8005\u5f02\u6b65\u5de5\u4f5c\u6d41\uff0c\u51cf\u5c11\u8ba1\u7b97\u95f2\u7f6e\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u541e\u5410\u91cf\u5e73\u5747\u63d0\u53471.59\u500d\u3002", "conclusion": "AsyncFlow\u4e3a\u4e0b\u4e00\u4ee3RL\u8bad\u7ec3\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u548c\u53ef\u5b9a\u5236\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01679", "pdf": "https://arxiv.org/pdf/2507.01679", "abs": "https://arxiv.org/abs/2507.01679", "authors": ["Zeyu Huang", "Tianhao Cheng", "Zihan Qiu", "Zili Wang", "Yinghui Xu", "Edoardo M. Ponti", "Ivan Titov"], "title": "Blending Supervised and Reinforcement Fine-Tuning with Prefix Sampling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Work in progress", "summary": "Existing post-training techniques for large language models are broadly\ncategorized into Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning\n(RFT). Each paradigm presents a distinct trade-off: SFT excels at mimicking\ndemonstration data but can lead to problematic generalization as a form of\nbehavior cloning. Conversely, RFT can significantly enhance a model's\nperformance but is prone to learn unexpected behaviors, and its performance is\nhighly sensitive to the initial policy. In this paper, we propose a unified\nview of these methods and introduce Prefix-RFT, a hybrid approach that\nsynergizes learning from both demonstration and exploration. Using mathematical\nreasoning problems as a testbed, we empirically demonstrate that Prefix-RFT is\nboth simple and effective. It not only surpasses the performance of standalone\nSFT and RFT but also outperforms parallel mixed-policy RFT methods. A key\nadvantage is its seamless integration into existing open-source frameworks,\nrequiring only minimal modifications to the standard RFT pipeline. Our analysis\nhighlights the complementary nature of SFT and RFT, and validates that\nPrefix-RFT effectively harmonizes these two learning paradigms. Furthermore,\nablation studies confirm the method's robustness to variations in the quality\nand quantity of demonstration data. We hope this work offers a new perspective\non LLM post-training, suggesting that a unified paradigm that judiciously\nintegrates demonstration and exploration could be a promising direction for\nfuture research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPrefix-RFT\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548c\u5f3a\u5316\u5fae\u8c03\uff08RFT\uff09\u7684\u4f18\u52bf\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709SFT\u548cRFT\u65b9\u6cd5\u5404\u6709\u4f18\u7f3a\u70b9\uff0cSFT\u6613\u5bfc\u81f4\u884c\u4e3a\u514b\u9686\u95ee\u9898\uff0cRFT\u5219\u5bf9\u521d\u59cb\u7b56\u7565\u654f\u611f\u4e14\u53ef\u80fd\u5b66\u4e60\u5230\u610f\u5916\u884c\u4e3a\u3002", "method": "\u63d0\u51faPrefix-RFT\uff0c\u7ed3\u5408\u6f14\u793a\u548c\u63a2\u7d22\u5b66\u4e60\uff0c\u901a\u8fc7\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "Prefix-RFT\u6027\u80fd\u4f18\u4e8e\u5355\u72ecSFT\u548cRFT\uff0c\u4e14\u4f18\u4e8e\u5e76\u884c\u6df7\u5408\u7b56\u7565RFT\u65b9\u6cd5\uff0c\u5bf9\u6f14\u793a\u6570\u636e\u8d28\u91cf\u4e0e\u6570\u91cf\u53d8\u5316\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "Prefix-RFT\u4e3aLLM\u540e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u672a\u6765\u7814\u7a76\u53ef\u63a2\u7d22\u7edf\u4e00\u6f14\u793a\u4e0e\u63a2\u7d22\u7684\u8303\u5f0f\u3002"}}
{"id": "2507.01693", "pdf": "https://arxiv.org/pdf/2507.01693", "abs": "https://arxiv.org/abs/2507.01693", "authors": ["Adrians Skapars", "Edoardo Manino", "Youcheng Sun", "Lucas C. Cordeiro"], "title": "GPT, But Backwards: Exactly Inverting Language Model Outputs", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, ICML 2025 Workshop on Reliable and Responsible Foundation\n  Models", "summary": "While existing auditing techniques attempt to identify potential unwanted\nbehaviours in large language models (LLMs), we address the complementary\nforensic problem of reconstructing the exact input that led to an existing LLM\noutput - enabling post-incident analysis and potentially the detection of fake\noutput reports. We formalize exact input reconstruction as a discrete\noptimisation problem with a unique global minimum and introduce SODA, an\nefficient gradient-based algorithm that operates on a continuous relaxation of\nthe input search space with periodic restarts and parameter decay. Through\ncomprehensive experiments on LLMs ranging in size from 33M to 3B parameters, we\ndemonstrate that SODA significantly outperforms existing approaches. We succeed\nin fully recovering 79.5% of shorter out-of-distribution inputs from next-token\nlogits, without a single false positive, but struggle to extract private\ninformation from the outputs of longer (15+ token) input sequences. This\nsuggests that standard deployment practices may currently provide adequate\nprotection against malicious use of our method. Our code is available at\nhttps://doi.org/10.5281/zenodo.15539879.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSODA\u7b97\u6cd5\uff0c\u7528\u4e8e\u4eceLLM\u8f93\u51fa\u4e2d\u7cbe\u786e\u91cd\u5efa\u8f93\u5165\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4f46\u957f\u8f93\u5165\u5e8f\u5217\u7684\u9690\u79c1\u4fe1\u606f\u63d0\u53d6\u4ecd\u6709\u56f0\u96be\u3002", "motivation": "\u73b0\u6709\u5ba1\u8ba1\u6280\u672f\u5173\u6ce8\u8bc6\u522bLLM\u7684\u4e0d\u826f\u884c\u4e3a\uff0c\u800c\u672c\u6587\u89e3\u51b3\u7684\u662f\u4ece\u5df2\u6709\u8f93\u51fa\u4e2d\u91cd\u5efa\u8f93\u5165\u7684\u53d6\u8bc1\u95ee\u9898\uff0c\u4ee5\u652f\u6301\u4e8b\u540e\u5206\u6790\u548c\u68c0\u6d4b\u865a\u5047\u62a5\u544a\u3002", "method": "\u5c06\u8f93\u5165\u91cd\u5efa\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u79bb\u6563\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51faSODA\u7b97\u6cd5\uff0c\u57fa\u4e8e\u8fde\u7eed\u677e\u5f1b\u7684\u8f93\u5165\u641c\u7d22\u7a7a\u95f4\uff0c\u7ed3\u5408\u5468\u671f\u6027\u91cd\u542f\u548c\u53c2\u6570\u8870\u51cf\u3002", "result": "\u572833M\u52303B\u53c2\u6570\u7684LLM\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cSODA\u80fd\u5b8c\u5168\u6062\u590d79.5%\u7684\u77ed\u5206\u5e03\u5916\u8f93\u5165\uff0c\u4f46\u5bf9\u957f\u5e8f\u5217\uff0815+ token\uff09\u7684\u9690\u79c1\u4fe1\u606f\u63d0\u53d6\u6548\u679c\u4e0d\u4f73\u3002", "conclusion": "\u6807\u51c6\u90e8\u7f72\u5b9e\u8df5\u53ef\u80fd\u5df2\u8db3\u591f\u9632\u8303\u6076\u610f\u4f7f\u7528SODA\u65b9\u6cd5\uff0c\u4f46\u957f\u5e8f\u5217\u7684\u9690\u79c1\u4fdd\u62a4\u4ecd\u9700\u6539\u8fdb\u3002"}}
{"id": "2507.01695", "pdf": "https://arxiv.org/pdf/2507.01695", "abs": "https://arxiv.org/abs/2507.01695", "authors": ["Omkar Shende", "Gayathri Ananthanarayanan", "Marcello Traiola"], "title": "PERTINENCE: Input-based Opportunistic Neural Network Dynamic Execution", "categories": ["cs.LG"], "comment": null, "summary": "Deep neural networks (DNNs) have become ubiquitous thanks to their remarkable\nability to model complex patterns across various domains such as computer\nvision, speech recognition, robotics, etc. While large DNN models are often\nmore accurate than simpler, lightweight models, they are also resource- and\nenergy-hungry. Hence, it is imperative to design methods to reduce reliance on\nsuch large models without significant degradation in output accuracy. The high\ncomputational cost of these models is often necessary only for a reduced set of\nchallenging inputs, while lighter models can handle most simple ones. Thus,\ncarefully combining properties of existing DNN models in a dynamic, input-based\nway opens opportunities to improve efficiency without impacting accuracy.\n  In this work, we introduce PERTINENCE, a novel online method designed to\nanalyze the complexity of input features and dynamically select the most\nsuitable model from a pre-trained set to process a given input effectively. To\nachieve this, we employ a genetic algorithm to explore the training space of an\nML-based input dispatcher, enabling convergence towards the Pareto front in the\nsolution space that balances overall accuracy and computational efficiency.\n  We showcase our approach on state-of-the-art Convolutional Neural Networks\n(CNNs) trained on the CIFAR-10 and CIFAR-100, as well as Vision Transformers\n(ViTs) trained on TinyImageNet dataset. We report results showing PERTINENCE's\nability to provide alternative solutions to existing state-of-the-art models in\nterms of trade-offs between accuracy and number of operations. By\nopportunistically selecting among models trained for the same task, PERTINENCE\nachieves better or comparable accuracy with up to 36% fewer operations.", "AI": {"tldr": "PERTINENCE\u662f\u4e00\u79cd\u52a8\u6001\u9009\u62e9\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u8f93\u5165\u7279\u5f81\u590d\u6742\u5ea6\uff0c\u5e73\u8861\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u5927\u578bDNN\u6a21\u578b\u867d\u7136\u51c6\u786e\u4f46\u8d44\u6e90\u6d88\u8017\u9ad8\uff0c\u9700\u8981\u5728\u4e0d\u663e\u8457\u964d\u4f4e\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u51cf\u5c11\u5bf9\u5b83\u4eec\u7684\u4f9d\u8d56\u3002", "method": "\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u8bad\u7ec3\u8f93\u5165\u8c03\u5ea6\u5668\uff0c\u52a8\u6001\u9009\u62e9\u6700\u9002\u5408\u7684\u6a21\u578b\u5904\u7406\u8f93\u5165\u3002", "result": "\u5728CIFAR-10\u3001CIFAR-100\u548cTinyImageNet\u6570\u636e\u96c6\u4e0a\uff0cPERTINENCE\u5728\u51cf\u5c1136%\u64cd\u4f5c\u7684\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "PERTINENCE\u901a\u8fc7\u52a8\u6001\u6a21\u578b\u9009\u62e9\uff0c\u6709\u6548\u5e73\u8861\u4e86\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2507.01699", "pdf": "https://arxiv.org/pdf/2507.01699", "abs": "https://arxiv.org/abs/2507.01699", "authors": ["Illia Oleksiienko", "Juho Kanniainen", "Alexandros Iosifidis"], "title": "Variational Graph Convolutional Neural Networks", "categories": ["cs.LG"], "comment": "This work has been submitted to the IEEE for possible publication. 9\n  pages, 6 figures", "summary": "Estimation of model uncertainty can help improve the explainability of Graph\nConvolutional Networks and the accuracy of the models at the same time.\nUncertainty can also be used in critical applications to verify the results of\nthe model by an expert or additional models. In this paper, we propose\nVariational Neural Network versions of spatial and spatio-temporal Graph\nConvolutional Networks. We estimate uncertainty in both outputs and layer-wise\nattentions of the models, which has the potential for improving model\nexplainability. We showcase the benefits of these models in the social trading\nanalysis and the skeleton-based human action recognition tasks on the Finnish\nboard membership, NTU-60, NTU-120 and Kinetics datasets, where we show\nimprovement in model accuracy in addition to estimated model uncertainties.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53d8\u5206\u795e\u7ecf\u7f51\u7edc\u7248\u672c\u7684\u56fe\u5377\u79ef\u7f51\u7edc\uff0c\u7528\u4e8e\u4f30\u8ba1\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u5347\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u901a\u8fc7\u4f30\u8ba1\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u5347\u56fe\u5377\u79ef\u7f51\u7edc\u7684\u53ef\u89e3\u91ca\u6027\u548c\u51c6\u786e\u6027\uff0c\u5e76\u652f\u6301\u5173\u952e\u5e94\u7528\u4e2d\u7684\u7ed3\u679c\u9a8c\u8bc1\u3002", "method": "\u63d0\u51fa\u7a7a\u95f4\u548c\u65f6\u7a7a\u56fe\u5377\u79ef\u7f51\u7edc\u7684\u53d8\u5206\u795e\u7ecf\u7f51\u7edc\u7248\u672c\uff0c\u4f30\u8ba1\u6a21\u578b\u8f93\u51fa\u548c\u5c42\u6ce8\u610f\u529b\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5728\u793e\u4ea4\u4ea4\u6613\u5206\u6790\u548c\u57fa\u4e8e\u9aa8\u67b6\u7684\u4eba\u4f53\u52a8\u4f5c\u8bc6\u522b\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u51c6\u786e\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u5747\u6709\u6240\u63d0\u5347\u3002", "conclusion": "\u53d8\u5206\u795e\u7ecf\u7f51\u7edc\u7248\u672c\u7684\u56fe\u5377\u79ef\u7f51\u7edc\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.01700", "pdf": "https://arxiv.org/pdf/2507.01700", "abs": "https://arxiv.org/abs/2507.01700", "authors": ["Andrea Piras", "Matteo Negro", "Ragib Ahsan", "David Arbour", "Elena Zheleva"], "title": "Relational Causal Discovery with Latent Confounders", "categories": ["cs.LG", "cs.AI"], "comment": "30 pages, 19 figures. Accepted for publication at the 41st Conference\n  on Uncertainty in Artificial Intelligence (UAI 2025). Andrea Piras and Matteo\n  Negro contributed equally to this work", "summary": "Estimating causal effects from real-world relational data can be challenging\nwhen the underlying causal model and potential confounders are unknown. While\nseveral causal discovery algorithms exist for learning causal models with\nlatent confounders from data, they assume that the data is independent and\nidentically distributed (i.i.d.) and are not well-suited for learning from\nrelational data. Similarly, existing relational causal discovery algorithms\nassume causal sufficiency, which is unrealistic for many real-world datasets.\nTo address this gap, we propose RelFCI, a sound and complete causal discovery\nalgorithm for relational data with latent confounders. Our work builds upon the\nFast Causal Inference (FCI) and Relational Causal Discovery (RCD) algorithms\nand it defines new graphical models, necessary to support causal discovery in\nrelational domains. We also establish soundness and completeness guarantees for\nrelational d-separation with latent confounders. We present experimental\nresults demonstrating the effectiveness of RelFCI in identifying the correct\ncausal structure in relational causal models with latent confounders.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRelFCI\u7684\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u5177\u6709\u6f5c\u5728\u6df7\u6742\u56e0\u7d20\u7684\u5173\u7cfb\u6570\u636e\uff0c\u586b\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\u5728\u5904\u7406\u5173\u7cfb\u6570\u636e\u548c\u6f5c\u5728\u6df7\u6742\u56e0\u7d20\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u9645\u9700\u6c42\u3002", "method": "\u57fa\u4e8eFast Causal Inference (FCI)\u548cRelational Causal Discovery (RCD)\u7b97\u6cd5\uff0c\u5b9a\u4e49\u4e86\u65b0\u7684\u56fe\u6a21\u578b\uff0c\u652f\u6301\u5173\u7cfb\u9886\u57df\u4e2d\u7684\u56e0\u679c\u53d1\u73b0\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eRelFCI\u80fd\u6709\u6548\u8bc6\u522b\u5177\u6709\u6f5c\u5728\u6df7\u6742\u56e0\u7d20\u7684\u5173\u7cfb\u56e0\u679c\u6a21\u578b\u4e2d\u7684\u6b63\u786e\u56e0\u679c\u7ed3\u6784\u3002", "conclusion": "RelFCI\u662f\u4e00\u79cd\u53ef\u9760\u4e14\u5b8c\u6574\u7684\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u5173\u7cfb\u6570\u636e\u4e2d\u7684\u56e0\u679c\u53d1\u73b0\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2507.01714", "pdf": "https://arxiv.org/pdf/2507.01714", "abs": "https://arxiv.org/abs/2507.01714", "authors": ["Kevin Innerebner", "Franz M. Rohrhofer", "Bernhard C. Geiger"], "title": "B-PL-PINN: Stabilizing PINN Training with Bayesian Pseudo Labeling", "categories": ["cs.LG"], "comment": null, "summary": "Training physics-informed neural networks (PINNs) for forward problems often\nsuffers from severe convergence issues, hindering the propagation of\ninformation from regions where the desired solution is well-defined.\nHaitsiukevich and Ilin (2023) proposed an ensemble approach that extends the\nactive training domain of each PINN based on i) ensemble consensus and ii)\nvicinity to (pseudo-)labeled points, thus ensuring that the information from\nthe initial condition successfully propagates to the interior of the\ncomputational domain.\n  In this work, we suggest replacing the ensemble by a Bayesian PINN, and\nconsensus by an evaluation of the PINN's posterior variance. Our experiments\nshow that this mathematically principled approach outperforms the ensemble on a\nset of benchmark problems and is competitive with PINN ensembles trained with\ncombinations of Adam and LBFGS.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7528\u8d1d\u53f6\u65afPINN\u66ff\u4ee3\u96c6\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc4\u4f30\u540e\u9a8c\u65b9\u5dee\u63d0\u5347\u4fe1\u606f\u4f20\u64ad\u6548\u679c\uff0c\u6027\u80fd\u4f18\u4e8e\u96c6\u6210\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3PINN\u5728\u524d\u5411\u95ee\u9898\u4e2d\u4fe1\u606f\u4f20\u64ad\u4e0d\u8db3\u7684\u6536\u655b\u95ee\u9898\u3002", "method": "\u7528\u8d1d\u53f6\u65afPINN\u66ff\u4ee3\u96c6\u6210\u65b9\u6cd5\uff0c\u8bc4\u4f30\u540e\u9a8c\u65b9\u5dee\u786e\u4fdd\u4fe1\u606f\u4f20\u64ad\u3002", "result": "\u5728\u57fa\u51c6\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u4e8e\u96c6\u6210\u65b9\u6cd5\uff0c\u4e0eAdam\u548cLBFGS\u7ed3\u5408\u7684PINN\u96c6\u6210\u7ade\u4e89\u3002", "conclusion": "\u8d1d\u53f6\u65afPINN\u662f\u4e00\u79cd\u6570\u5b66\u4e0a\u66f4\u4e25\u8c28\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u6709\u6548\u63d0\u5347PINN\u6027\u80fd\u3002"}}
{"id": "2507.01724", "pdf": "https://arxiv.org/pdf/2507.01724", "abs": "https://arxiv.org/abs/2507.01724", "authors": ["Micha Henheik", "Theresa Eimer", "Marius Lindauer"], "title": "Revisiting Learning Rate Control", "categories": ["cs.LG"], "comment": null, "summary": "The learning rate is one of the most important hyperparameters in deep\nlearning, and how to control it is an active area within both AutoML and deep\nlearning research. Approaches for learning rate control span from classic\noptimization to online scheduling based on gradient statistics. This paper\ncompares paradigms to assess the current state of learning rate control. We\nfind that methods from multi-fidelity hyperparameter optimization,\nfixed-hyperparameter schedules, and hyperparameter-free learning often perform\nvery well on selected deep learning tasks but are not reliable across settings.\nThis highlights the need for algorithm selection methods in learning rate\ncontrol, which have been neglected so far by both the AutoML and deep learning\ncommunities. We also observe a trend of hyperparameter optimization approaches\nbecoming less effective as models and tasks grow in complexity, even when\ncombined with multi-fidelity approaches for more expensive model trainings. A\nfocus on more relevant test tasks and new promising directions like finetunable\nmethods and meta-learning will enable the AutoML community to significantly\nstrengthen its impact on this crucial factor in deep learning.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86\u5b66\u4e60\u7387\u63a7\u5236\u7684\u4e0d\u540c\u65b9\u6cd5\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\u4f46\u7f3a\u4e4f\u666e\u9002\u6027\uff0c\u9700\u5173\u6ce8\u7b97\u6cd5\u9009\u62e9\u548c\u65b0\u5174\u65b9\u5411\u5982\u5143\u5b66\u4e60\u3002", "motivation": "\u63a2\u8ba8\u5b66\u4e60\u7387\u63a7\u5236\u5728\u6df1\u5ea6\u5b66\u4e60\u548cAutoML\u4e2d\u7684\u91cd\u8981\u6027\u53ca\u73b0\u72b6\u3002", "method": "\u6bd4\u8f83\u591a\u4fdd\u771f\u8d85\u53c2\u6570\u4f18\u5316\u3001\u56fa\u5b9a\u8d85\u53c2\u6570\u8c03\u5ea6\u548c\u65e0\u8d85\u53c2\u6570\u5b66\u4e60\u7b49\u65b9\u6cd5\u3002", "result": "\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u6a21\u578b\u548c\u4efb\u52a1\u4e2d\u6548\u679c\u4e0b\u964d\uff0c\u9700\u7b97\u6cd5\u9009\u62e9\u548c\u65b0\u5174\u65b9\u6cd5\u3002", "conclusion": "\u672a\u6765\u5e94\u5173\u6ce8\u66f4\u76f8\u5173\u7684\u6d4b\u8bd5\u4efb\u52a1\u548c\u5143\u5b66\u4e60\u7b49\u65b9\u5411\uff0c\u4ee5\u63d0\u5347\u5b66\u4e60\u7387\u63a7\u5236\u7684\u6548\u679c\u3002"}}
{"id": "2507.01740", "pdf": "https://arxiv.org/pdf/2507.01740", "abs": "https://arxiv.org/abs/2507.01740", "authors": ["Trung-Dung Hoang", "Alceu Bissoto", "Vihangkumar V. Naik", "Tim Fl\u00fchmann", "Artemii Shlychkov", "Jos\u00e9 Garcia-Tirado", "Lisa M. Koch"], "title": "A Real-Time Digital Twin for Type 1 Diabetes using Simulation-Based Inference", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Accurately estimating parameters of physiological models is essential to\nachieving reliable digital twins. For Type 1 Diabetes, this is particularly\nchallenging due to the complexity of glucose-insulin interactions. Traditional\nmethods based on Markov Chain Monte Carlo struggle with high-dimensional\nparameter spaces and fit parameters from scratch at inference time, making them\nslow and computationally expensive. In this study, we propose a\nSimulation-Based Inference approach based on Neural Posterior Estimation to\nefficiently capture the complex relationships between meal intake, insulin, and\nglucose level, providing faster, amortized inference. Our experiments\ndemonstrate that SBI not only outperforms traditional methods in parameter\nestimation but also generalizes better to unseen conditions, offering real-time\nposterior inference with reliable uncertainty quantification.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u540e\u9a8c\u4f30\u8ba1\u7684\u6a21\u62df\u63a8\u7406\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u4f30\u8ba11\u578b\u7cd6\u5c3f\u75c5\u7684\u751f\u7406\u6a21\u578b\u53c2\u6570\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u9ad8\u7ef4\u53c2\u6570\u7a7a\u95f4\u4e2d\u6548\u7387\u4f4e\u4e0b\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u4f30\u8ba1\u590d\u6742\u7684\u8461\u8404\u7cd6-\u80f0\u5c9b\u7d20\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u795e\u7ecf\u540e\u9a8c\u4f30\u8ba1\u7684\u6a21\u62df\u63a8\u7406\u65b9\u6cd5\uff0c\u6355\u6349\u996e\u98df\u3001\u80f0\u5c9b\u7d20\u548c\u8840\u7cd6\u6c34\u5e73\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u53c2\u6570\u4f30\u8ba1\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4e14\u80fd\u66f4\u597d\u5730\u6cdb\u5316\u5230\u672a\u89c1\u6761\u4ef6\uff0c\u63d0\u4f9b\u5b9e\u65f6\u540e\u9a8c\u63a8\u65ad\u548c\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a1\u578b\u7cd6\u5c3f\u75c5\u7684\u6570\u5b57\u5b6a\u751f\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u53ef\u9760\u7684\u53c2\u6570\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01752", "pdf": "https://arxiv.org/pdf/2507.01752", "abs": "https://arxiv.org/abs/2507.01752", "authors": ["Ismail Labiad", "Mathurin Videau", "Matthieu Kowalski", "Marc Schoenauer", "Alessandro Leite", "Julia Kempe", "Olivier Teytaud"], "title": "Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "comment": null, "summary": "Gradient-based optimization is the workhorse of deep learning, offering\nefficient and scalable training via backpropagation. However, its reliance on\nlarge volumes of labeled data raises privacy and security concerns such as\nsusceptibility to data poisoning attacks and the risk of overfitting. In\ncontrast, black box optimization methods, which treat the model as an opaque\nfunction, relying solely on function evaluations to guide optimization, offer a\npromising alternative in scenarios where data access is restricted, adversarial\nrisks are high, or overfitting is a concern. However, black box methods also\npose significant challenges, including poor scalability to high-dimensional\nparameter spaces, as prevalent in large language models (LLMs), and high\ncomputational costs due to reliance on numerous model evaluations. This paper\nintroduces BBoxER, an evolutionary black-box method for LLM post-training that\ninduces an information bottleneck via implicit compression of the training\ndata. Leveraging the tractability of information flow, we provide strong\ntheoretical bounds on generalization, differential privacy, susceptibility to\ndata poisoning attacks, and robustness to extraction attacks. BBoxER operates\non top of pre-trained LLMs, offering a lightweight and modular enhancement\nsuitable for deployment in restricted or privacy-sensitive environments, in\naddition to non-vacuous generalization guarantees. In experiments with LLMs, we\ndemonstrate empirically that Retrofitting methods are able to learn, showing\nhow a few iterations of BBoxER improve performance and generalize well on a\nbenchmark of reasoning datasets. This positions BBoxER as an attractive add-on\non top of gradient-based optimization.", "AI": {"tldr": "BBoxER\u662f\u4e00\u79cd\u57fa\u4e8e\u9ed1\u76d2\u4f18\u5316\u7684\u8fdb\u5316\u65b9\u6cd5\uff0c\u7528\u4e8eLLM\u540e\u8bad\u7ec3\uff0c\u901a\u8fc7\u9690\u5f0f\u538b\u7f29\u8bad\u7ec3\u6570\u636e\u5f15\u5165\u4fe1\u606f\u74f6\u9888\uff0c\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u68af\u5ea6\u4f18\u5316\u5728\u9690\u79c1\u3001\u5b89\u5168\u548c\u8fc7\u62df\u5408\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u540c\u65f6\u514b\u670d\u9ed1\u76d2\u65b9\u6cd5\u5728\u9ad8\u7ef4\u53c2\u6570\u7a7a\u95f4\u548c\u8ba1\u7b97\u6210\u672c\u4e0a\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faBBoxER\u65b9\u6cd5\uff0c\u5229\u7528\u4fe1\u606f\u6d41\u53ef\u8ffd\u8e2a\u6027\uff0c\u901a\u8fc7\u9690\u5f0f\u538b\u7f29\u8bad\u7ec3\u6570\u636e\u5b9e\u73b0\u4fe1\u606f\u74f6\u9888\uff0c\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eBBoxER\u5728LLM\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u63d0\u5347\u6027\u80fd\u5e76\u6cdb\u5316\u826f\u597d\u3002", "conclusion": "BBoxER\u662f\u68af\u5ea6\u4f18\u5316\u7684\u8f7b\u91cf\u7ea7\u6a21\u5757\u5316\u8865\u5145\uff0c\u9002\u7528\u4e8e\u9690\u79c1\u654f\u611f\u73af\u5883\u3002"}}
{"id": "2507.01761", "pdf": "https://arxiv.org/pdf/2507.01761", "abs": "https://arxiv.org/abs/2507.01761", "authors": ["Nicolas Salvy", "Hugues Talbot", "Bertrand Thirion"], "title": "Enhanced Generative Model Evaluation with Clipped Density and Coverage", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Although generative models have made remarkable progress in recent years,\ntheir use in critical applications has been hindered by their incapacity to\nreliably evaluate sample quality. Quality refers to at least two complementary\nconcepts: fidelity and coverage. Current quality metrics often lack reliable,\ninterpretable values due to an absence of calibration or insufficient\nrobustness to outliers. To address these shortcomings, we introduce two novel\nmetrics, Clipped Density and Clipped Coverage. By clipping individual sample\ncontributions and, for fidelity, the radii of nearest neighbor balls, our\nmetrics prevent out-of-distribution samples from biasing the aggregated values.\nThrough analytical and empirical calibration, these metrics exhibit linear\nscore degradation as the proportion of poor samples increases. Thus, they can\nbe straightforwardly interpreted as equivalent proportions of good samples.\nExtensive experiments on synthetic and real-world datasets demonstrate that\nClipped Density and Clipped Coverage outperform existing methods in terms of\nrobustness, sensitivity, and interpretability for evaluating generative models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u6307\u6807\uff08Clipped Density\u548cClipped Coverage\uff09\uff0c\u7528\u4e8e\u66f4\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u5730\u8bc4\u4f30\u751f\u6210\u6a21\u578b\u7684\u6837\u672c\u8d28\u91cf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6307\u6807\u5728\u9c81\u68d2\u6027\u548c\u6821\u51c6\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u751f\u6210\u6a21\u578b\u5728\u5173\u952e\u5e94\u7528\u4e2d\u7684\u4f7f\u7528\u53d7\u5230\u6837\u672c\u8d28\u91cf\u8bc4\u4f30\u4e0d\u53ef\u9760\u7684\u9650\u5236\uff0c\u73b0\u6709\u6307\u6807\u7f3a\u4e4f\u6821\u51c6\u6216\u5bf9\u5f02\u5e38\u503c\u7684\u9c81\u68d2\u6027\u3002", "method": "\u901a\u8fc7\u526a\u88c1\u5355\u4e2a\u6837\u672c\u8d21\u732e\u548c\u6700\u8fd1\u90bb\u7403\u7684\u534a\u5f84\uff0c\u63d0\u51faClipped Density\u548cClipped Coverage\u6307\u6807\uff0c\u9632\u6b62\u5206\u5e03\u5916\u6837\u672c\u5f71\u54cd\u805a\u5408\u503c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u6307\u6807\u5728\u9c81\u68d2\u6027\u3001\u654f\u611f\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5206\u6570\u968f\u52a3\u8d28\u6837\u672c\u6bd4\u4f8b\u7ebf\u6027\u4e0b\u964d\u3002", "conclusion": "Clipped Density\u548cClipped Coverage\u4e3a\u751f\u6210\u6a21\u578b\u7684\u8d28\u91cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u548c\u53ef\u89e3\u91ca\u7684\u5de5\u5177\u3002"}}
{"id": "2507.01781", "pdf": "https://arxiv.org/pdf/2507.01781", "abs": "https://arxiv.org/abs/2507.01781", "authors": ["Dalia Rodr\u00edguez-Salas", "Christian Riess"], "title": "BranchNet: A Neuro-Symbolic Learning Framework for Structured Multi-Class Classification", "categories": ["cs.LG", "cs.AI", "68T07 (Primary) 62H30, 68T05 (Secondary)"], "comment": "18 pages, 3 figures (with two images each)", "summary": "We introduce BranchNet, a neuro-symbolic learning framework that transforms\ndecision tree ensembles into sparse, partially connected neural networks. Each\nbranch, defined as a decision path from root to a parent of leaves, is mapped\nto a hidden neuron, preserving symbolic structure while enabling gradient-based\noptimization. The resulting models are compact, interpretable, and require no\nmanual architecture tuning. Evaluated on a suite of structured multi-class\nclassification benchmarks, BranchNet consistently outperforms XGBoost in\naccuracy, with statistically significant gains. We detail the architecture,\ntraining procedure, and sparsity dynamics, and discuss the model's strengths in\nsymbolic interpretability as well as its current limitations, particularly on\nbinary tasks where further adaptive calibration may be beneficial.", "AI": {"tldr": "BranchNet\u5c06\u51b3\u7b56\u6811\u96c6\u6210\u8f6c\u6362\u4e3a\u7a00\u758f\u3001\u90e8\u5206\u8fde\u63a5\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u4fdd\u7559\u7b26\u53f7\u7ed3\u6784\u5e76\u652f\u6301\u68af\u5ea6\u4f18\u5316\uff0c\u6027\u80fd\u4f18\u4e8eXGBoost\u3002", "motivation": "\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u7684\u68af\u5ea6\u4f18\u5316\u80fd\u529b\u4e0e\u51b3\u7b56\u6811\u7684\u7b26\u53f7\u53ef\u89e3\u91ca\u6027\uff0c\u6784\u5efa\u7d27\u51d1\u4e14\u65e0\u9700\u624b\u52a8\u8c03\u53c2\u7684\u6a21\u578b\u3002", "method": "\u5c06\u51b3\u7b56\u6811\u7684\u6bcf\u6761\u5206\u652f\u6620\u5c04\u4e3a\u9690\u85cf\u795e\u7ecf\u5143\uff0c\u5f62\u6210\u7a00\u758f\u795e\u7ecf\u7f51\u7edc\uff0c\u4fdd\u7559\u7b26\u53f7\u7ed3\u6784\u3002", "result": "\u5728\u591a\u7c7b\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cBranchNet\u5728\u51c6\u786e\u6027\u4e0a\u663e\u8457\u4f18\u4e8eXGBoost\u3002", "conclusion": "BranchNet\u5728\u7b26\u53f7\u53ef\u89e3\u91ca\u6027\u548c\u6027\u80fd\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u4e8c\u5143\u4efb\u52a1\u4e2d\u53ef\u80fd\u9700\u8981\u8fdb\u4e00\u6b65\u6821\u51c6\u3002"}}
{"id": "2507.01803", "pdf": "https://arxiv.org/pdf/2507.01803", "abs": "https://arxiv.org/abs/2507.01803", "authors": ["Leyang Xue", "Meghana Madhyastha", "Randal Burns", "Myungjin Lee", "Mahesh K. Marina"], "title": "Towards Decentralized and Sustainable Foundation Model Training with the Edge", "categories": ["cs.LG"], "comment": null, "summary": "Foundation models are at the forefront of AI research, appealing for their\nability to learn from vast datasets and cater to diverse tasks. Yet, their\nsignificant computational demands raise issues of environmental impact and the\nrisk of centralized control in their development. We put forward a vision\ntowards decentralized and sustainable foundation model training that leverages\nthe collective compute of sparingly used connected edge AI devices. We present\nthe rationale behind our vision, particularly in support of its sustainability\nbenefit. We further outline a set of challenges that need to be addressed to\nturn this vision into reality.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u3001\u53ef\u6301\u7eed\u7684\u57fa\u7840\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5229\u7528\u8fb9\u7f18AI\u8bbe\u5907\u7684\u95f2\u7f6e\u7b97\u529b\uff0c\u4ee5\u51cf\u5c11\u73af\u5883\u5f71\u54cd\u548c\u96c6\u4e2d\u63a7\u5236\u98ce\u9669\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u7684\u8ba1\u7b97\u9700\u6c42\u9ad8\uff0c\u5bfc\u81f4\u73af\u5883\u95ee\u9898\u548c\u96c6\u4e2d\u63a7\u5236\u98ce\u9669\uff0c\u9700\u8981\u66f4\u53ef\u6301\u7eed\u548c\u53bb\u4e2d\u5fc3\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528\u8fde\u63a5\u8fb9\u7f18AI\u8bbe\u5907\u7684\u95f2\u7f6e\u7b97\u529b\u8fdb\u884c\u5206\u5e03\u5f0f\u8bad\u7ec3\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6301\u7eed\u4e14\u53bb\u4e2d\u5fc3\u5316\u7684\u8bad\u7ec3\u613f\u666f\uff0c\u5e76\u5206\u6790\u4e86\u5176\u4f18\u52bf\u3002", "conclusion": "\u9700\u89e3\u51b3\u4e00\u7cfb\u5217\u6311\u6218\u4ee5\u5b9e\u73b0\u8fd9\u4e00\u613f\u666f\uff0c\u4f46\u5176\u53ef\u6301\u7eed\u6027\u548c\u53bb\u4e2d\u5fc3\u5316\u6f5c\u529b\u503c\u5f97\u63a2\u7d22\u3002"}}
{"id": "2507.01806", "pdf": "https://arxiv.org/pdf/2507.01806", "abs": "https://arxiv.org/abs/2507.01806", "authors": ["Reza Arabpour", "Haitz S\u00e1ez de Oc\u00e1riz Borde", "Anastasis Kratsios"], "title": "LoRA Fine-Tuning Without GPUs: A CPU-Efficient Meta-Generation Framework for LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": "5-page main paper (excluding references) + 11-page appendix, 3\n  tables, 1 figure. Accepted to ICML 2025 Workshop on Efficient Systems for\n  Foundation Models", "summary": "Low-Rank Adapters (LoRAs) have transformed the fine-tuning of Large Language\nModels (LLMs) by enabling parameter-efficient updates. However, their\nwidespread adoption remains limited by the reliance on GPU-based training. In\nthis work, we propose a theoretically grounded approach to LoRA fine-tuning\ndesigned specifically for users with limited computational resources,\nparticularly those restricted to standard laptop CPUs. Our method learns a\nmeta-operator that maps any input dataset, represented as a probability\ndistribution, to a set of LoRA weights by leveraging a large bank of\npre-trained adapters for the Mistral-7B-Instruct-v0.2 model. Instead of\nperforming new gradient-based updates, our pipeline constructs adapters via\nlightweight combinations of existing LoRAs directly on CPU. While the resulting\nadapters do not match the performance of GPU-trained counterparts, they\nconsistently outperform the base Mistral model on downstream tasks, offering a\npractical and accessible alternative to traditional GPU-based fine-tuning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCPU\u7684\u4f4e\u79e9\u9002\u914d\u5668\uff08LoRA\uff09\u5fae\u8c03\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u7684\u7528\u6237\uff0c\u901a\u8fc7\u7ec4\u5408\u9884\u8bad\u7ec3\u9002\u914d\u5668\u751f\u6210\u65b0\u9002\u914d\u5668\uff0c\u6027\u80fd\u867d\u4e0d\u53caGPU\u8bad\u7ec3\u4f46\u4f18\u4e8e\u57fa\u7840\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3LoRA\u5fae\u8c03\u5bf9GPU\u7684\u4f9d\u8d56\u95ee\u9898\uff0c\u4e3a\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u7684\u7528\u6237\u63d0\u4f9b\u53ef\u884c\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u5229\u7528\u9884\u8bad\u7ec3\u9002\u914d\u5668\u5e93\uff0c\u5b66\u4e60\u4e00\u4e2a\u5143\u64cd\u4f5c\u7b26\uff0c\u5c06\u8f93\u5165\u6570\u636e\u96c6\u6620\u5c04\u5230LoRA\u6743\u91cd\uff0c\u76f4\u63a5\u5728CPU\u4e0a\u7ec4\u5408\u751f\u6210\u9002\u914d\u5668\u3002", "result": "\u751f\u6210\u7684\u9002\u914d\u5668\u6027\u80fd\u4f18\u4e8e\u57fa\u7840Mistral\u6a21\u578b\uff0c\u4f46\u4e0d\u53caGPU\u8bad\u7ec3\u7684\u9002\u914d\u5668\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8d44\u6e90\u53d7\u9650\u7528\u6237\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684LoRA\u5fae\u8c03\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.01823", "pdf": "https://arxiv.org/pdf/2507.01823", "abs": "https://arxiv.org/abs/2507.01823", "authors": ["Dmytro Kuzmenko", "Nadiya Shvai"], "title": "TD-MPC-Opt: Distilling Model-Based Multi-Task Reinforcement Learning Agents", "categories": ["cs.LG", "cs.RO"], "comment": "Preprint of a manuscript submitted for peer review", "summary": "We present a novel approach to knowledge transfer in model-based\nreinforcement learning, addressing the critical challenge of deploying large\nworld models in resource-constrained environments. Our method efficiently\ndistills a high-capacity multi-task agent (317M parameters) into a compact\nmodel (1M parameters) on the MT30 benchmark, significantly improving\nperformance across diverse tasks. Our distilled model achieves a\nstate-of-the-art normalized score of 28.45, surpassing the original 1M\nparameter model score of 18.93. This improvement demonstrates the ability of\nour distillation technique to capture and consolidate complex multi-task\nknowledge. We further optimize the distilled model through FP16 post-training\nquantization, reducing its size by $\\sim$50\\%. Our approach addresses practical\ndeployment limitations and offers insights into knowledge representation in\nlarge world models, paving the way for more efficient and accessible multi-task\nreinforcement learning systems in robotics and other resource-constrained\napplications. Code available at https://github.com/dmytro-kuzmenko/td-mpc-opt.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7684\u77e5\u8bc6\u8f6c\u79fb\u65b0\u65b9\u6cd5\uff0c\u5c06\u9ad8\u5bb9\u91cf\u591a\u4efb\u52a1\u4ee3\u7406\uff08317M\u53c2\u6570\uff09\u9ad8\u6548\u84b8\u998f\u4e3a\u7d27\u51d1\u6a21\u578b\uff081M\u53c2\u6570\uff09\uff0c\u5728MT30\u57fa\u51c6\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u90e8\u7f72\u5927\u578b\u4e16\u754c\u6a21\u578b\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u901a\u8fc7\u84b8\u998f\u6280\u672f\u5c06\u9ad8\u5bb9\u91cf\u591a\u4efb\u52a1\u4ee3\u7406\u538b\u7f29\u4e3a\u7d27\u51d1\u6a21\u578b\uff0c\u5e76\u8fdb\u4e00\u6b65\u901a\u8fc7FP16\u540e\u8bad\u7ec3\u91cf\u5316\u4f18\u5316\u6a21\u578b\u5927\u5c0f\u3002", "result": "\u84b8\u998f\u6a21\u578b\u5728MT30\u57fa\u51c6\u4e0a\u8fbe\u523028.45\u7684\u5f52\u4e00\u5316\u5206\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u539f\u59cb1M\u53c2\u6570\u6a21\u578b\u768418.93\u3002\u6a21\u578b\u5927\u5c0f\u51cf\u5c11\u7ea650%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u5b9e\u9645\u90e8\u7f72\u9650\u5236\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u5e94\u7528\u4e2d\u7684\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01825", "pdf": "https://arxiv.org/pdf/2507.01825", "abs": "https://arxiv.org/abs/2507.01825", "authors": ["Franco Alberto Cardillo", "Hamza Khyari", "Umberto Straccia"], "title": "MILP-SAT-GNN: Yet Another Neural SAT Solver", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We proposes a novel method that enables Graph Neural Networks (GNNs) to solve\nSAT problems by leveraging a technique developed for applying GNNs to Mixed\nInteger Linear Programming (MILP). Specifically, k-CNF formulae are mapped into\nMILP problems, which are then encoded as weighted bipartite graphs and\nsubsequently fed into a GNN for training and testing. From a theoretical\nperspective: (i) we establish permutation and equivalence invariance results,\ndemonstrating that the method produces outputs that are stable under reordering\nof clauses and variables; (ii) we identify a theoretical limitation, showing\nthat for a class of formulae called foldable formulae, standard GNNs cannot\nalways distinguish satisfiable from unsatisfiable instances; (iii) we prove a\nuniversal approximation theorem, establishing that with Random Node\nInitialization (RNI), the method can approximate SAT solving to arbitrary\nprecision on finite datasets, that is, the GNN becomes approximately sound and\ncomplete on such datasets. Furthermore, we show that for unfoldable formulae,\nthe same approximation guarantee can be achieved without the need for RNI.\nFinally, we conduct an experimental evaluation of our approach, which show\nthat, despite the simplicity of the neural architecture, the method achieves\npromising results.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u89e3\u51b3SAT\u95ee\u9898\uff0c\u901a\u8fc7\u5c06k-CNF\u516c\u5f0f\u6620\u5c04\u4e3aMILP\u95ee\u9898\uff0c\u518d\u7f16\u7801\u4e3a\u52a0\u6743\u4e8c\u5206\u56fe\u8f93\u5165GNN\u3002\u7406\u8bba\u8bc1\u660e\u65b9\u6cd5\u7684\u7a33\u5b9a\u6027\u548c\u5c40\u9650\u6027\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5176\u6709\u6548\u6027\u3002", "motivation": "\u63a2\u7d22GNN\u5728\u89e3\u51b3SAT\u95ee\u9898\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u7ed3\u5408MILP\u6280\u672f\uff0c\u63d0\u5347GNN\u5728\u903b\u8f91\u95ee\u9898\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u5c06k-CNF\u516c\u5f0f\u8f6c\u5316\u4e3aMILP\u95ee\u9898\uff0c\u7f16\u7801\u4e3a\u52a0\u6743\u4e8c\u5206\u56fe\uff0c\u8f93\u5165GNN\u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002\u7406\u8bba\u5206\u6790\u4e86\u65b9\u6cd5\u7684\u7a33\u5b9a\u6027\u548c\u5c40\u9650\u6027\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u65b9\u6cd5\u5177\u6709\u7a33\u5b9a\u6027\u548c\u8fd1\u4f3c\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u5b9e\u9645\u95ee\u9898\u4e2d\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aGNN\u5728SAT\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5177\u6709\u7406\u8bba\u548c\u5b9e\u8df5\u4ef7\u503c\u3002"}}
{"id": "2507.01829", "pdf": "https://arxiv.org/pdf/2507.01829", "abs": "https://arxiv.org/abs/2507.01829", "authors": ["Tristan Torchet", "Christian Metzner", "Laura Kriener", "Melika Payvand"], "title": "mGRADE: Minimal Recurrent Gating Meets Delay Convolutions for Lightweight Sequence Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Edge devices for temporal processing demand models that capture both short-\nand long- range dynamics under tight memory constraints. While Transformers\nexcel at sequence modeling, their quadratic memory scaling with sequence length\nmakes them impractical for such settings. Recurrent Neural Networks (RNNs)\noffer constant memory but train sequentially, and Temporal Convolutional\nNetworks (TCNs), though efficient, scale memory with kernel size. To address\nthis, we propose mGRADE (mininally Gated Recurrent Architecture with Delay\nEmbedding), a hybrid-memory system that integrates a temporal 1D-convolution\nwith learnable spacings followed by a minimal gated recurrent unit (minGRU).\nThis design allows the convolutional layer to realize a flexible delay\nembedding that captures rapid temporal variations, while the recurrent module\nefficiently maintains global context with minimal memory overhead. We validate\nour approach on two synthetic tasks, demonstrating that mGRADE effectively\nseparates and preserves multi-scale temporal features. Furthermore, on\nchallenging pixel-by-pixel image classification benchmarks, mGRADE consistently\noutperforms both pure convolutional and pure recurrent counterparts using\napproximately 20% less memory footprint, highlighting its suitability for\nmemory-constrained temporal processing at the edge. This highlights mGRADE's\npromise as an efficient solution for memory-constrained multi-scale temporal\nprocessing at the edge.", "AI": {"tldr": "mGRADE\u662f\u4e00\u79cd\u6df7\u5408\u5185\u5b58\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e861D\u5377\u79ef\u548c\u6700\u5c0f\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff0c\u9002\u7528\u4e8e\u5185\u5b58\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u591a\u5c3a\u5ea6\u65f6\u95f4\u5904\u7406\u3002", "motivation": "\u89e3\u51b3\u8fb9\u7f18\u8bbe\u5907\u5728\u5185\u5b58\u9650\u5236\u4e0b\u540c\u65f6\u6355\u6349\u77ed\u65f6\u548c\u957f\u65f6\u52a8\u6001\u7684\u9700\u6c42\uff0c\u907f\u514dTransformer\u7684\u9ad8\u5185\u5b58\u6d88\u8017\u548cRNN\u3001TCN\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51famGRADE\uff0c\u7ed3\u5408\u53ef\u5b66\u4e60\u95f4\u9694\u76841D\u5377\u79ef\u548cminGRU\uff0c\u5377\u79ef\u5c42\u6355\u6349\u5feb\u901f\u53d8\u5316\uff0c\u5faa\u73af\u6a21\u5757\u7ef4\u62a4\u5168\u5c40\u4e0a\u4e0b\u6587\u3002", "result": "\u5728\u5408\u6210\u4efb\u52a1\u548c\u50cf\u7d20\u7ea7\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cmGRADE\u8868\u73b0\u4f18\u4e8e\u7eaf\u5377\u79ef\u548c\u7eaf\u5faa\u73af\u6a21\u578b\uff0c\u5185\u5b58\u5360\u7528\u51cf\u5c1120%\u3002", "conclusion": "mGRADE\u662f\u5185\u5b58\u53d7\u9650\u8fb9\u7f18\u8bbe\u5907\u591a\u5c3a\u5ea6\u65f6\u95f4\u5904\u7406\u7684\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01831", "pdf": "https://arxiv.org/pdf/2507.01831", "abs": "https://arxiv.org/abs/2507.01831", "authors": ["Yucen Lily Li", "Daohan Lu", "Polina Kirichenko", "Shikai Qiu", "Tim G. J. Rudner", "C. Bayan Bruss", "Andrew Gordon Wilson"], "title": "Out-of-Distribution Detection Methods Answer the Wrong Questions", "categories": ["cs.LG", "stat.ML"], "comment": "Extended version of ICML 2025 paper", "summary": "To detect distribution shifts and improve model safety, many\nout-of-distribution (OOD) detection methods rely on the predictive uncertainty\nor features of supervised models trained on in-distribution data. In this\npaper, we critically re-examine this popular family of OOD detection\nprocedures, and we argue that these methods are fundamentally answering the\nwrong questions for OOD detection. There is no simple fix to this misalignment,\nsince a classifier trained only on in-distribution classes cannot be expected\nto identify OOD points; for instance, a cat-dog classifier may confidently\nmisclassify an airplane if it contains features that distinguish cats from\ndogs, despite generally appearing nothing alike. We find that uncertainty-based\nmethods incorrectly conflate high uncertainty with being OOD, while\nfeature-based methods incorrectly conflate far feature-space distance with\nbeing OOD. We show how these pathologies manifest as irreducible errors in OOD\ndetection and identify common settings where these methods are ineffective.\nAdditionally, interventions to improve OOD detection such as feature-logit\nhybrid methods, scaling of model and data size, epistemic uncertainty\nrepresentation, and outlier exposure also fail to address this fundamental\nmisalignment in objectives. We additionally consider unsupervised density\nestimation and generative models for OOD detection, which we show have their\nown fundamental limitations.", "AI": {"tldr": "\u8bba\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86\u6d41\u884c\u7684OOD\u68c0\u6d4b\u65b9\u6cd5\uff0c\u6307\u51fa\u5176\u6839\u672c\u95ee\u9898\u5728\u4e8e\u76ee\u6807\u9519\u4f4d\uff0c\u65e0\u6cd5\u6709\u6548\u8bc6\u522bOOD\u6837\u672c\uff0c\u5e76\u63d0\u51fa\u8fd9\u4e9b\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u548c\u7279\u5f81\u7684OOD\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u76ee\u6807\u9519\u4f4d\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u8bc6\u522bOOD\u6837\u672c\uff0c\u9700\u91cd\u65b0\u5ba1\u89c6\u5176\u6709\u6548\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4e0d\u786e\u5b9a\u6027\u65b9\u6cd5\u548c\u7279\u5f81\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63a2\u8ba8\u4e86\u5bc6\u5ea6\u4f30\u8ba1\u548c\u751f\u6210\u6a21\u578b\u7684OOD\u68c0\u6d4b\u80fd\u529b\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5728OOD\u68c0\u6d4b\u4e2d\u5b58\u5728\u4e0d\u53ef\u51cf\u5c11\u7684\u9519\u8bef\uff0c\u4e14\u5e38\u89c1\u5e72\u9884\u63aa\u65bd\u65e0\u6cd5\u89e3\u51b3\u76ee\u6807\u9519\u4f4d\u95ee\u9898\u3002", "conclusion": "\u73b0\u6709OOD\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u6027\u7f3a\u9677\uff0c\u9700\u91cd\u65b0\u8bbe\u8ba1\u76ee\u6807\u548c\u65b9\u6cd5\u4ee5\u6709\u6548\u8bc6\u522bOOD\u6837\u672c\u3002"}}
{"id": "2507.01841", "pdf": "https://arxiv.org/pdf/2507.01841", "abs": "https://arxiv.org/abs/2507.01841", "authors": ["Yihang Gao", "Vincent Y. F. Tan"], "title": "Automatic Rank Determination for Low-Rank Adaptation via Submodular Function Maximization", "categories": ["cs.LG", "cs.IT", "eess.SP", "math.IT", "math.OC"], "comment": null, "summary": "In this paper, we propose SubLoRA, a rank determination method for Low-Rank\nAdaptation (LoRA) based on submodular function maximization. In contrast to\nprior approaches, such as AdaLoRA, that rely on first-order (linearized)\napproximations of the loss function, SubLoRA utilizes second-order information\nto capture the potentially complex loss landscape by incorporating the Hessian\nmatrix. We show that the linearization becomes inaccurate and ill-conditioned\nwhen the LoRA parameters have been well optimized, motivating the need for a\nmore reliable and nuanced second-order formulation. To this end, we reformulate\nthe rank determination problem as a combinatorial optimization problem with a\nquadratic objective. However, solving this problem exactly is NP-hard in\ngeneral. To overcome the computational challenge, we introduce a submodular\nfunction maximization framework and devise a greedy algorithm with\napproximation guarantees. We derive a sufficient and necessary condition under\nwhich the rank-determination objective becomes submodular, and construct a\nclosed-form projection of the Hessian matrix that satisfies this condition\nwhile maintaining computational efficiency. Our method combines solid\ntheoretical foundations, second-order accuracy, and practical computational\nefficiency. We further extend SubLoRA to a joint optimization setting,\nalternating between LoRA parameter updates and rank determination under a rank\nbudget constraint. Extensive experiments on fine-tuning physics-informed neural\nnetworks (PINNs) for solving partial differential equations (PDEs) demonstrate\nthe effectiveness of our approach. Results show that SubLoRA outperforms\nexisting methods in both rank determination and joint training performance.", "AI": {"tldr": "SubLoRA\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b50\u6a21\u51fd\u6570\u6700\u5927\u5316\u7684LoRA\u79e9\u786e\u5b9a\u65b9\u6cd5\uff0c\u5229\u7528\u4e8c\u9636\u4fe1\u606f\uff08Hessian\u77e9\u9635\uff09\u6539\u8fdb\u4f20\u7edf\u7ebf\u6027\u5316\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u5e76\u901a\u8fc7\u8d2a\u5fc3\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\uff08\u5982AdaLoRA\uff09\u4f9d\u8d56\u635f\u5931\u51fd\u6570\u7684\u4e00\u9636\u8fd1\u4f3c\uff0c\u5728LoRA\u53c2\u6570\u4f18\u5316\u826f\u597d\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u66f4\u53ef\u9760\u4e14\u7cbe\u7ec6\u7684\u4e8c\u9636\u65b9\u6cd5\u3002", "method": "\u5c06\u79e9\u786e\u5b9a\u95ee\u9898\u8f6c\u5316\u4e3a\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u5f15\u5165\u5b50\u6a21\u51fd\u6570\u6700\u5927\u5316\u6846\u67b6\u548c\u8d2a\u5fc3\u7b97\u6cd5\uff0c\u5e76\u7ed3\u5408Hessian\u77e9\u9635\u7684\u95ed\u5f0f\u6295\u5f71\u4fdd\u8bc1\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSubLoRA\u5728\u79e9\u786e\u5b9a\u548c\u8054\u5408\u8bad\u7ec3\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SubLoRA\u7ed3\u5408\u4e86\u7406\u8bba\u4e25\u8c28\u6027\u3001\u4e8c\u9636\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u7528\u4e8e\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINN\uff09\u7684\u5fae\u8c03\u4efb\u52a1\u3002"}}
{"id": "2507.01875", "pdf": "https://arxiv.org/pdf/2507.01875", "abs": "https://arxiv.org/abs/2507.01875", "authors": ["Gast\u00f3n Garc\u00eda Gonz\u00e1lez", "Pedro Casas", "Emilio Mart\u00ednez", "Alicia Fern\u00e1ndez"], "title": "Towards Foundation Auto-Encoders for Time-Series Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": "Presented at ACM KDD 2024, MiLeTS 2024 Workshop, August 25, 2024,\n  Barcelona, Spain", "summary": "We investigate a novel approach to time-series modeling, inspired by the\nsuccesses of large pretrained foundation models. We introduce FAE (Foundation\nAuto-Encoders), a foundation generative-AI model for anomaly detection in\ntime-series data, based on Variational Auto-Encoders (VAEs). By foundation, we\nmean a model pretrained on massive amounts of time-series data which can learn\ncomplex temporal patterns useful for accurate modeling, forecasting, and\ndetection of anomalies on previously unseen datasets. FAE leverages VAEs and\nDilated Convolutional Neural Networks (DCNNs) to build a generic model for\nunivariate time-series modeling, which could eventually perform properly in\nout-of-the-box, zero-shot anomaly detection applications. We introduce the main\nconcepts of FAE, and present preliminary results in different multi-dimensional\ntime-series datasets from various domains, including a real dataset from an\noperational mobile ISP, and the well known KDD 2021 Anomaly Detection dataset.", "AI": {"tldr": "FAE\u662f\u4e00\u79cd\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\u548c\u6269\u5f20\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u5b66\u4e60\u590d\u6742\u65f6\u95f4\u6a21\u5f0f\uff0c\u5b9e\u73b0\u96f6\u6837\u672c\u5f02\u5e38\u68c0\u6d4b\u3002", "motivation": "\u53d7\u5927\u578b\u9884\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u6210\u529f\u7684\u542f\u53d1\uff0c\u7814\u7a76\u4e00\u79cd\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u5f02\u5e38\u68c0\u6d4b\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAEs\uff09\u548c\u6269\u5f20\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08DCNNs\uff09\uff0c\u6784\u5efa\u901a\u7528\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\uff0c\u652f\u6301\u96f6\u6837\u672c\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u5728\u591a\u7ef4\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\uff08\u5305\u62ec\u79fb\u52a8ISP\u6570\u636e\u548cKDD 2021\u6570\u636e\u96c6\uff09\u4e0a\u5c55\u793a\u4e86\u521d\u6b65\u7ed3\u679c\u3002", "conclusion": "FAE\u4f5c\u4e3a\u4e00\u79cd\u57fa\u7840\u6a21\u578b\uff0c\u5c55\u73b0\u51fa\u5728\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5728\u96f6\u6837\u672c\u573a\u666f\u4e0b\u3002"}}
{"id": "2507.01924", "pdf": "https://arxiv.org/pdf/2507.01924", "abs": "https://arxiv.org/abs/2507.01924", "authors": ["Samirah Bakker", "Yao Ma", "Seyed Sahand Mohammadi Ziabari"], "title": "Exploring a Hybrid Deep Learning Approach for Anomaly Detection in Mental Healthcare Provider Billing: Addressing Label Scarcity through Semi-Supervised Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The complexity of mental healthcare billing enables anomalies, including\nfraud. While machine learning methods have been applied to anomaly detection,\nthey often struggle with class imbalance, label scarcity, and complex\nsequential patterns. This study explores a hybrid deep learning approach\ncombining Long Short-Term Memory (LSTM) networks and Transformers, with\npseudo-labeling via Isolation Forests (iForest) and Autoencoders (AE). Prior\nwork has not evaluated such hybrid models trained on pseudo-labeled data in the\ncontext of healthcare billing. The approach is evaluated on two real-world\nbilling datasets related to mental healthcare. The iForest LSTM baseline\nachieves the highest recall (0.963) on declaration-level data. On the\noperation-level data, the hybrid iForest-based model achieves the highest\nrecall (0.744), though at the cost of lower precision. These findings highlight\nthe potential of combining pseudo-labeling with hybrid deep learning in\ncomplex, imbalanced anomaly detection settings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LSTM\u548cTransformer\u7684\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5229\u7528iForest\u548cAE\u8fdb\u884c\u4f2a\u6807\u8bb0\uff0c\u7528\u4e8e\u5fc3\u7406\u5065\u5eb7\u8d26\u5355\u5f02\u5e38\u68c0\u6d4b\uff0c\u89e3\u51b3\u4e86\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u6807\u7b7e\u7a00\u7f3a\u95ee\u9898\u3002", "motivation": "\u5fc3\u7406\u5065\u5eb7\u8d26\u5355\u7684\u590d\u6742\u6027\u5bfc\u81f4\u5f02\u5e38\uff08\u5982\u6b3a\u8bc8\uff09\u9891\u53d1\uff0c\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u3001\u6807\u7b7e\u7a00\u7f3a\u548c\u590d\u6742\u5e8f\u5217\u6a21\u5f0f\u5904\u7406\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u5408LSTM\u548cTransformer\uff0c\u5229\u7528iForest\u548cAE\u751f\u6210\u4f2a\u6807\u7b7e\uff0c\u5e76\u5728\u4e24\u4e2a\u771f\u5b9e\u5fc3\u7406\u5065\u5eb7\u8d26\u5355\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u3002", "result": "iForest LSTM\u57fa\u7ebf\u5728\u58f0\u660e\u7ea7\u6570\u636e\u4e0a\u53ec\u56de\u7387\u6700\u9ad8\uff080.963\uff09\uff1b\u5728\u64cd\u4f5c\u7ea7\u6570\u636e\u4e0a\uff0c\u6df7\u5408iForest\u6a21\u578b\u53ec\u56de\u7387\u6700\u9ad8\uff080.744\uff09\uff0c\u4f46\u7cbe\u5ea6\u8f83\u4f4e\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u4f2a\u6807\u8bb0\u4e0e\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u7ed3\u5408\u5728\u590d\u6742\u3001\u4e0d\u5e73\u8861\u7684\u5f02\u5e38\u68c0\u6d4b\u573a\u666f\u4e2d\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2507.01951", "pdf": "https://arxiv.org/pdf/2507.01951", "abs": "https://arxiv.org/abs/2507.01951", "authors": ["Zixiao Wang", "Yuxin Wang", "Xiaorui Wang", "Mengting Xing", "Jie Gao", "Jianjun Xu", "Guangcan Liu", "Chenhui Jin", "Zhuo Wang", "Shengzhuo Zhang", "Hongtao Xie"], "title": "Test-Time Scaling with Reflective Generative Model", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "We introduce our first reflective generative model MetaStone-S1, which\nobtains OpenAI o3's performance via the self-supervised process reward model\n(SPRM). Through sharing the backbone network and using task-specific heads for\nnext token prediction and process scoring respectively, SPRM successfully\nintegrates the policy model and process reward model(PRM) into a unified\ninterface without extra process annotation, reducing over 99% PRM parameters\nfor efficient reasoning. Equipped with SPRM, MetaStone-S1 is naturally suitable\nfor test time scaling (TTS), and we provide three reasoning effort modes (low,\nmedium, and high), based on the controllable thinking length. Moreover, we\nempirically establish a scaling law that reveals the relationship between total\nthinking computation and TTS performance. Experiments demonstrate that our\nMetaStone-S1 achieves comparable performance to OpenAI-o3-mini's series with\nonly 32B parameter size. To support the research community, we have\nopen-sourced MetaStone-S1 at https://github.com/MetaStone-AI/MetaStone-S1.", "AI": {"tldr": "MetaStone-S1\u662f\u4e00\u4e2a\u53cd\u5c04\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08SPRM\uff09\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\uff0c\u6027\u80fd\u5ab2\u7f8eOpenAI o3\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u7edf\u4e00\u63a5\u53e3\u6574\u5408\u7b56\u7565\u6a21\u578b\u548c\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u51cf\u5c11\u53c2\u6570\u5e76\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002", "method": "\u4f7f\u7528\u5171\u4eab\u4e3b\u5e72\u7f51\u7edc\u548c\u4efb\u52a1\u7279\u5b9a\u5934\uff0c\u7ed3\u5408SPRM\u5b9e\u73b0\u81ea\u76d1\u7763\u8bad\u7ec3\uff0c\u652f\u6301\u53ef\u63a7\u601d\u8003\u957f\u5ea6\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "result": "MetaStone-S1\u4ee532B\u53c2\u6570\u89c4\u6a21\u8fbe\u5230\u4e0eOpenAI-o3-mini\u7cfb\u5217\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5e76\u5f00\u6e90\u6a21\u578b\u3002", "conclusion": "MetaStone-S1\u5c55\u793a\u4e86\u9ad8\u6548\u63a8\u7406\u7684\u6f5c\u529b\uff0c\u5e76\u901a\u8fc7\u5f00\u6e90\u63a8\u52a8\u7814\u7a76\u793e\u533a\u53d1\u5c55\u3002"}}
{"id": "2506.23121", "pdf": "https://arxiv.org/pdf/2506.23121", "abs": "https://arxiv.org/abs/2506.23121", "authors": ["Xinlei Yu", "Chanmiao Wang", "Hui Jin", "Ahmed Elazab", "Gangyong Jia", "Xiang Wan", "Changqing Zou", "Ruiquan Ge"], "title": "CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for Multi-Organ Segmentation", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": "19 pages, 9 figures, 10 tables", "summary": "Multi-organ medical segmentation is a crucial component of medical image\nprocessing, essential for doctors to make accurate diagnoses and develop\neffective treatment plans. Despite significant progress in this field, current\nmulti-organ segmentation models often suffer from inaccurate details,\ndependence on geometric prompts and loss of spatial information. Addressing\nthese challenges, we introduce a novel model named CRISP-SAM2 with CRoss-modal\nInteraction and Semantic Prompting based on SAM2. This model represents a\npromising approach to multi-organ medical segmentation guided by textual\ndescriptions of organs. Our method begins by converting visual and textual\ninputs into cross-modal contextualized semantics using a progressive\ncross-attention interaction mechanism. These semantics are then injected into\nthe image encoder to enhance the detailed understanding of visual information.\nTo eliminate reliance on geometric prompts, we use a semantic prompting\nstrategy, replacing the original prompt encoder to sharpen the perception of\nchallenging targets. In addition, a similarity-sorting self-updating strategy\nfor memory and a mask-refining process is applied to further adapt to medical\nimaging and enhance localized details. Comparative experiments conducted on\nseven public datasets indicate that CRISP-SAM2 outperforms existing models.\nExtensive analysis also demonstrates the effectiveness of our method, thereby\nconfirming its superior performance, especially in addressing the limitations\nmentioned earlier. Our code is available at:\nhttps://github.com/YU-deep/CRISP\\_SAM2.git.", "AI": {"tldr": "CRISP-SAM2\u662f\u4e00\u79cd\u57fa\u4e8eSAM2\u7684\u591a\u5668\u5b98\u533b\u5b66\u5206\u5272\u6a21\u578b\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u4ea4\u4e92\u548c\u8bed\u4e49\u63d0\u793a\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u7684\u7ec6\u8282\u4e0d\u51c6\u786e\u3001\u4f9d\u8d56\u51e0\u4f55\u63d0\u793a\u548c\u7a7a\u95f4\u4fe1\u606f\u4e22\u5931\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u591a\u5668\u5b98\u5206\u5272\u6a21\u578b\u5b58\u5728\u7ec6\u8282\u4e0d\u51c6\u786e\u3001\u4f9d\u8d56\u51e0\u4f55\u63d0\u793a\u548c\u7a7a\u95f4\u4fe1\u606f\u4e22\u5931\u7684\u5c40\u9650\u6027\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u91c7\u7528\u8de8\u6a21\u6001\u4ea4\u4e92\u673a\u5236\u5c06\u89c6\u89c9\u548c\u6587\u672c\u8f93\u5165\u8f6c\u5316\u4e3a\u8bed\u4e49\u4fe1\u606f\uff0c\u7ed3\u5408\u8bed\u4e49\u63d0\u793a\u7b56\u7565\u548c\u8bb0\u5fc6\u81ea\u66f4\u65b0\u7b56\u7565\uff0c\u589e\u5f3a\u7ec6\u8282\u611f\u77e5\u3002", "result": "\u5728\u4e03\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCRISP-SAM2\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "CRISP-SAM2\u5728\u89e3\u51b3\u73b0\u6709\u95ee\u9898\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2507.01020", "pdf": "https://arxiv.org/pdf/2507.01020", "abs": "https://arxiv.org/abs/2507.01020", "authors": ["Aashray Reddy", "Andrew Zagula", "Nicholas Saban"], "title": "AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models", "categories": ["cs.CR", "cs.LG"], "comment": "16 pages, 4 figures, submitted to LLMSEC", "summary": "Large Language Models (LLMs) continue to exhibit vulnerabilities to\njailbreaking attacks: carefully crafted malicious inputs intended to circumvent\nsafety guardrails and elicit harmful responses. As such, we present AutoAdv, a\nnovel framework that automates adversarial prompt generation to systematically\nevaluate and expose vulnerabilities in LLM safety mechanisms. Our approach\nleverages a parametric attacker LLM to produce semantically disguised malicious\nprompts through strategic rewriting techniques, specialized system prompts, and\noptimized hyperparameter configurations. The primary contribution of our work\nis a dynamic, multi-turn attack methodology that analyzes failed jailbreak\nattempts and iteratively generates refined follow-up prompts, leveraging\ntechniques such as roleplaying, misdirection, and contextual manipulation. We\nquantitatively evaluate attack success rate (ASR) using the StrongREJECT\n(arXiv:2402.10260 [cs.CL]) framework across sequential interaction turns.\nThrough extensive empirical evaluation of state-of-the-art models--including\nChatGPT, Llama, and DeepSeek--we reveal significant vulnerabilities, with our\nautomated attacks achieving jailbreak success rates of up to 86% for harmful\ncontent generation. Our findings reveal that current safety mechanisms remain\nsusceptible to sophisticated multi-turn attacks, emphasizing the urgent need\nfor more robust defense strategies.", "AI": {"tldr": "AutoAdv\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u5bf9\u6297\u6027\u63d0\u793a\u751f\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u66b4\u9732\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u901a\u8fc7\u591a\u8f6e\u653b\u51fb\u65b9\u6cd5\u5b9e\u73b0\u9ad8\u8fbe86%\u7684\u8d8a\u72f1\u6210\u529f\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6613\u53d7\u8d8a\u72f1\u653b\u51fb\uff0c\u73b0\u6709\u5b89\u5168\u673a\u5236\u5b58\u5728\u6f0f\u6d1e\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u8bc4\u4f30\u548c\u66b4\u9732\u8fd9\u4e9b\u6f0f\u6d1e\u3002", "method": "\u5229\u7528\u53c2\u6570\u5316\u653b\u51fb\u8005LLM\u751f\u6210\u8bed\u4e49\u4f2a\u88c5\u7684\u6076\u610f\u63d0\u793a\uff0c\u7ed3\u5408\u89d2\u8272\u626e\u6f14\u3001\u8bef\u5bfc\u548c\u4e0a\u4e0b\u6587\u64cd\u7eb5\u7b49\u6280\u672f\uff0c\u52a8\u6001\u591a\u8f6e\u653b\u51fb\u3002", "result": "\u5728ChatGPT\u3001Llama\u548cDeepSeek\u7b49\u5148\u8fdb\u6a21\u578b\u4e0a\uff0cAutoAdv\u5b9e\u73b0\u4e86\u9ad8\u8fbe86%\u7684\u8d8a\u72f1\u6210\u529f\u7387\u3002", "conclusion": "\u5f53\u524d\u5b89\u5168\u673a\u5236\u5bf9\u590d\u6742\u591a\u8f6e\u653b\u51fb\u4ecd\u8106\u5f31\uff0c\u4e9f\u9700\u66f4\u5f3a\u5927\u7684\u9632\u5fa1\u7b56\u7565\u3002"}}
{"id": "2507.01022", "pdf": "https://arxiv.org/pdf/2507.01022", "abs": "https://arxiv.org/abs/2507.01022", "authors": ["Shayan Dadman", "Bernt Arild Bremdal", "Andreas Bergsland"], "title": "Workflow-Based Evaluation of Music Generation Systems", "categories": ["eess.AS", "cs.HC", "cs.LG", "cs.MM", "cs.SD"], "comment": "54 pages, 3 figures, 6 tables, 5 appendices", "summary": "This study presents an exploratory evaluation of Music Generation Systems\n(MGS) within contemporary music production workflows by examining eight\nopen-source systems. The evaluation framework combines technical insights with\npractical experimentation through criteria specifically designed to investigate\nthe practical and creative affordances of the systems within the iterative,\nnon-linear nature of music production. Employing a single-evaluator methodology\nas a preliminary phase, this research adopts a mixed approach utilizing\nqualitative methods to form hypotheses subsequently assessed through\nquantitative metrics. The selected systems represent architectural diversity\nacross both symbolic and audio-based music generation approaches, spanning\ncomposition, arrangement, and sound design tasks. The investigation addresses\nlimitations of current MGS in music production, challenges and opportunities\nfor workflow integration, and development potential as collaborative tools\nwhile maintaining artistic authenticity. Findings reveal these systems function\nprimarily as complementary tools enhancing rather than replacing human\nexpertise. They exhibit limitations in maintaining thematic and structural\ncoherence that emphasize the indispensable role of human creativity in tasks\ndemanding emotional depth and complex decision-making. This study contributes a\nstructured evaluation framework that considers the iterative nature of music\ncreation. It identifies methodological refinements necessary for subsequent\ncomprehensive evaluations and determines viable areas for AI integration as\ncollaborative tools in creative workflows. The research provides\nempirically-grounded insights to guide future development in the field.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u516b\u79cd\u5f00\u6e90\u97f3\u4e50\u751f\u6210\u7cfb\u7edf\uff08MGS\uff09\u5728\u5f53\u4ee3\u97f3\u4e50\u5236\u4f5c\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6280\u672f\u548c\u5b9e\u8df5\u7684\u8bc4\u4ef7\u6846\u67b6\uff0c\u53d1\u73b0MGS\u4e3b\u8981\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\uff0c\u5f3a\u8c03\u4eba\u7c7b\u521b\u9020\u529b\u7684\u4e0d\u53ef\u66ff\u4ee3\u6027\u3002", "motivation": "\u63a2\u8ba8MGS\u5728\u97f3\u4e50\u5236\u4f5c\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0c\u586b\u8865\u73b0\u6709\u7cfb\u7edf\u5728\u4e3b\u9898\u548c\u7ed3\u6784\u8fde\u8d2f\u6027\u4e0a\u7684\u4e0d\u8db3\uff0c\u63a8\u52a8AI\u4f5c\u4e3a\u534f\u4f5c\u5de5\u5177\u7684\u53d1\u5c55\u3002", "method": "\u91c7\u7528\u5355\u8bc4\u4f30\u8005\u65b9\u6cd5\uff0c\u7ed3\u5408\u5b9a\u6027\u548c\u5b9a\u91cf\u5206\u6790\uff0c\u8bc4\u4f30\u516b\u79cd\u5177\u6709\u67b6\u6784\u591a\u6837\u6027\u7684MGS\u3002", "result": "MGS\u5728\u589e\u5f3a\u4eba\u7c7b\u521b\u9020\u529b\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u60c5\u611f\u6df1\u5ea6\u548c\u590d\u6742\u51b3\u7b56\u4efb\u52a1\u4e2d\u4ecd\u9700\u4eba\u7c7b\u4e3b\u5bfc\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u8bc4\u4ef7\u6846\u67b6\uff0c\u4e3a\u672a\u6765MGS\u7684\u5f00\u53d1\u548c\u96c6\u6210\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u6307\u5bfc\u3002"}}
{"id": "2507.01038", "pdf": "https://arxiv.org/pdf/2507.01038", "abs": "https://arxiv.org/abs/2507.01038", "authors": ["Seong-Joon Park", "Hee-Youl Kwak", "Sang-Hyo Kim", "Yongjune Kim", "Jong-Seon No"], "title": "Cross-Attention Message-Passing Transformers for Code-Agnostic Decoding in 6G Networks", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "comment": null, "summary": "Channel coding for 6G networks is expected to support a wide range of\nrequirements arising from heterogeneous communication scenarios. These demands\nchallenge traditional code-specific decoders, which lack the flexibility and\nscalability required for next-generation systems. To tackle this problem, we\npropose an AI-native foundation model for unified and code-agnostic decoding\nbased on the transformer architecture. We first introduce a cross-attention\nmessage-passing transformer (CrossMPT). CrossMPT employs two masked\ncross-attention blocks that iteratively update two distinct input\nrepresentations-magnitude and syndrome vectors-allowing the model to\neffectively learn the decoding problem. Notably, our CrossMPT has achieved\nstate-of-the-art decoding performance among single neural decoders. Building on\nthis, we develop foundation CrossMPT (FCrossMPT) by making the architecture\ninvariant to code length, rate, and class, allowing a single trained model to\ndecode a broad range of codes without retraining. To further enhance decoding\nperformance, particularly for short blocklength codes, we propose CrossMPT\nensemble decoder (CrossED), an ensemble decoder composed of multiple parallel\nCrossMPT blocks employing different parity-check matrices. This architecture\ncan also serve as a foundation model, showing strong generalization across\ndiverse code types. Overall, the proposed AI-native code-agnostic decoder\noffers flexibility, scalability, and high performance, presenting a promising\ndirection to channel coding for 6G networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u67b6\u6784\u7684AI\u539f\u751f\u57fa\u7840\u6a21\u578b\uff0c\u7528\u4e8e\u7edf\u4e00\u4e14\u4e0e\u7f16\u7801\u65e0\u5173\u7684\u89e3\u7801\uff0c\u89e3\u51b3\u4e866G\u7f51\u7edc\u4e2d\u4f20\u7edf\u89e3\u7801\u5668\u7f3a\u4e4f\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u95ee\u9898\u3002", "motivation": "6G\u7f51\u7edc\u7684\u5f02\u6784\u901a\u4fe1\u573a\u666f\u5bf9\u4f20\u7edf\u89e3\u7801\u5668\u63d0\u51fa\u4e86\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u578b\u89e3\u7801\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86CrossMPT\uff08\u8de8\u6ce8\u610f\u529b\u6d88\u606f\u4f20\u9012Transformer\uff09\uff0c\u901a\u8fc7\u4e24\u4e2a\u63a9\u7801\u8de8\u6ce8\u610f\u529b\u5757\u8fed\u4ee3\u66f4\u65b0\u8f93\u5165\u8868\u793a\uff08\u5e45\u5ea6\u548c\u6821\u9a8c\u5411\u91cf\uff09\uff0c\u5e76\u8fdb\u4e00\u6b65\u5f00\u53d1\u4e86FCrossMPT\u548cCrossED\uff08\u96c6\u6210\u89e3\u7801\u5668\uff09\u3002", "result": "CrossMPT\u5728\u5355\u795e\u7ecf\u89e3\u7801\u5668\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u89e3\u7801\u6027\u80fd\uff0cFCrossMPT\u548cCrossED\u5c55\u793a\u4e86\u5e7f\u6cdb\u7684\u89e3\u7801\u80fd\u529b\u548c\u5f3a\u6cdb\u5316\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684AI\u539f\u751f\u89e3\u7801\u5668\u5177\u6709\u7075\u6d3b\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u9ad8\u6027\u80fd\uff0c\u4e3a6G\u7f51\u7edc\u7684\u4fe1\u9053\u7f16\u7801\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2507.01044", "pdf": "https://arxiv.org/pdf/2507.01044", "abs": "https://arxiv.org/abs/2507.01044", "authors": ["Vivek Borkar", "Parthe Pandit"], "title": "Asymptotic convexity of wide and shallow neural networks", "categories": ["stat.ML", "cs.LG", "math.PR", "68T07"], "comment": "5 pages", "summary": "For a simple model of shallow and wide neural networks, we show that the\nepigraph of its input-output map as a function of the network parameters\napproximates epigraph of a. convex function in a precise sense. This leads to a\nplausible explanation of their observed good performance.", "AI": {"tldr": "\u6d45\u5c42\u5bbd\u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u5165\u8f93\u51fa\u6620\u5c04\u7684epigraph\u8fd1\u4f3c\u4e8e\u51f8\u51fd\u6570\u7684epigraph\uff0c\u89e3\u91ca\u4e86\u5176\u826f\u597d\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u6d45\u5c42\u5bbd\u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u5165\u8f93\u51fa\u6620\u5c04\u7279\u6027\uff0c\u4ee5\u89e3\u91ca\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u826f\u597d\u8868\u73b0\u3002", "method": "\u5206\u6790\u6d45\u5c42\u5bbd\u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u5165\u8f93\u51fa\u6620\u5c04\u7684epigraph\uff0c\u5e76\u4e0e\u51f8\u51fd\u6570\u7684epigraph\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u53d1\u73b0\u8f93\u5165\u8f93\u51fa\u6620\u5c04\u7684epigraph\u5728\u53c2\u6570\u7a7a\u95f4\u4e2d\u8fd1\u4f3c\u4e8e\u51f8\u51fd\u6570\u7684epigraph\u3002", "conclusion": "\u8fd9\u79cd\u8fd1\u4f3c\u6027\u4e3a\u6d45\u5c42\u5bbd\u795e\u7ecf\u7f51\u7edc\u7684\u826f\u597d\u6027\u80fd\u63d0\u4f9b\u4e86\u5408\u7406\u89e3\u91ca\u3002"}}
{"id": "2507.01058", "pdf": "https://arxiv.org/pdf/2507.01058", "abs": "https://arxiv.org/abs/2507.01058", "authors": ["Puspendu Banerjee", "Aritra Mazumdar", "Wazib Ansar", "Saptarsi Goswami", "Amlan Chakrabarti"], "title": "A Data Science Approach to Calcutta High Court Judgments: An Efficient LLM and RAG-powered Framework for Summarization and Similar Cases Retrieval", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "12 pages, 6 figures", "summary": "The judiciary, as one of democracy's three pillars, is dealing with a rising\namount of legal issues, needing careful use of judicial resources. This\nresearch presents a complex framework that leverages Data Science\nmethodologies, notably Large Language Models (LLM) and Retrieval-Augmented\nGeneration (RAG) techniques, to improve the efficiency of analyzing Calcutta\nHigh Court verdicts. Our framework focuses on two key aspects: first, the\ncreation of a robust summarization mechanism that distills complex legal texts\ninto concise and coherent summaries; and second, the development of an\nintelligent system for retrieving similar cases, which will assist legal\nprofessionals in research and decision making. By fine-tuning the Pegasus model\nusing case head note summaries, we achieve significant improvements in the\nsummarization of legal cases. Our two-step summarizing technique preserves\ncrucial legal contexts, allowing for the production of a comprehensive vector\ndatabase for RAG. The RAG-powered framework efficiently retrieves similar cases\nin response to user queries, offering thorough overviews and summaries. This\ntechnique not only improves legal research efficiency, but it also helps legal\nprofessionals and students easily acquire and grasp key legal information,\nbenefiting the overall legal scenario.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u5206\u6790\u52a0\u5c14\u5404\u7b54\u9ad8\u7b49\u6cd5\u9662\u7684\u5224\u51b3\uff0c\u5305\u62ec\u6587\u672c\u6458\u8981\u548c\u7c7b\u4f3c\u6848\u4f8b\u68c0\u7d22\u3002", "motivation": "\u53f8\u6cd5\u8d44\u6e90\u9700\u8981\u9ad8\u6548\u5229\u7528\uff0c\u6cd5\u5f8b\u4e13\u4e1a\u4eba\u58eb\u548c\u5b66\u751f\u5728\u5904\u7406\u590d\u6742\u6cd5\u5f8b\u6587\u672c\u65f6\u9762\u4e34\u6311\u6218\u3002", "method": "\u4f7f\u7528Pegasus\u6a21\u578b\u8fdb\u884c\u6cd5\u5f8b\u6587\u672c\u6458\u8981\uff0c\u5e76\u6784\u5efaRAG\u6846\u67b6\u4ee5\u68c0\u7d22\u7c7b\u4f3c\u6848\u4f8b\u3002", "result": "\u663e\u8457\u63d0\u5347\u4e86\u6cd5\u5f8b\u6848\u4f8b\u6458\u8981\u7684\u8d28\u91cf\uff0c\u5e76\u6784\u5efa\u4e86\u5168\u9762\u7684\u5411\u91cf\u6570\u636e\u5e93\u4ee5\u652f\u6301\u9ad8\u6548\u68c0\u7d22\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86\u6cd5\u5f8b\u7814\u7a76\u6548\u7387\uff0c\u5e2e\u52a9\u7528\u6237\u5feb\u901f\u83b7\u53d6\u5173\u952e\u6cd5\u5f8b\u4fe1\u606f\u3002"}}
{"id": "2507.01060", "pdf": "https://arxiv.org/pdf/2507.01060", "abs": "https://arxiv.org/abs/2507.01060", "authors": ["Kang Liu"], "title": "Optimizing Conversational Product Recommendation via Reinforcement Learning", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "We propose a reinforcement learning-based approach to optimize conversational\nstrategies for product recommendation across diverse industries. As\norganizations increasingly adopt intelligent agents to support sales and\nservice operations, the effectiveness of a conversation hinges not only on what\nis recommended but how and when recommendations are delivered. We explore a\nmethodology where agentic systems learn optimal dialogue policies through\nfeedback-driven reinforcement learning. By mining aggregate behavioral patterns\nand conversion outcomes, our approach enables agents to refine talk tracks that\ndrive higher engagement and product uptake, while adhering to contextual and\nregulatory constraints. We outline the conceptual framework, highlight key\ninnovations, and discuss the implications for scalable, personalized\nrecommendation in enterprise environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u4f18\u5316\u8de8\u884c\u4e1a\u4ea7\u54c1\u63a8\u8350\u7684\u5bf9\u8bdd\u7b56\u7565\uff0c\u901a\u8fc7\u53cd\u9988\u9a71\u52a8\u7684\u5b66\u4e60\u63d0\u5347\u5bf9\u8bdd\u6548\u679c\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u4ee3\u7406\u5728\u9500\u552e\u548c\u670d\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5bf9\u8bdd\u7684\u63a8\u8350\u65b9\u5f0f\u548c\u65f6\u673a\u5bf9\u6548\u679c\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u4ece\u884c\u4e3a\u6a21\u5f0f\u548c\u8f6c\u5316\u7ed3\u679c\u4e2d\u5b66\u4e60\u6700\u4f18\u5bf9\u8bdd\u7b56\u7565\u3002", "result": "\u65b9\u6cd5\u80fd\u591f\u63d0\u5347\u7528\u6237\u53c2\u4e0e\u5ea6\u548c\u4ea7\u54c1\u91c7\u7eb3\u7387\uff0c\u540c\u65f6\u6ee1\u8db3\u4e0a\u4e0b\u6587\u548c\u6cd5\u89c4\u7ea6\u675f\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4f01\u4e1a\u5728\u4e2a\u6027\u5316\u63a8\u8350\u4e2d\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01066", "pdf": "https://arxiv.org/pdf/2507.01066", "abs": "https://arxiv.org/abs/2507.01066", "authors": ["Hanzhong Liang", "Jinghao Shi", "Xiang Shen", "Zixuan Wang", "Vera Wen", "Ardalan Mehrani", "Zhiqian Chen", "Yifan Wu", "Zhixin Zhang"], "title": "Embedding-based Retrieval in Multimodal Content Moderation", "categories": ["cs.IR", "cs.CV", "cs.LG"], "comment": "Camera ready for SIGIR 2025", "summary": "Video understanding plays a fundamental role for content moderation on short\nvideo platforms, enabling the detection of inappropriate content. While\nclassification remains the dominant approach for content moderation, it often\nstruggles in scenarios requiring rapid and cost-efficient responses, such as\ntrend adaptation and urgent escalations. To address this issue, we introduce an\nEmbedding-Based Retrieval (EBR) method designed to complement traditional\nclassification approaches. We first leverage a Supervised Contrastive Learning\n(SCL) framework to train a suite of foundation embedding models, including both\nsingle-modal and multi-modal architectures. Our models demonstrate superior\nperformance over established contrastive learning methods such as CLIP and\nMoCo. Building on these embedding models, we design and implement the\nembedding-based retrieval system that integrates embedding generation and video\nretrieval to enable efficient and effective trend handling. Comprehensive\noffline experiments on 25 diverse emerging trends show that EBR improves\nROC-AUC from 0.85 to 0.99 and PR-AUC from 0.35 to 0.95. Further online\nexperiments reveal that EBR increases action rates by 10.32% and reduces\noperational costs by over 80%, while also enhancing interpretability and\nflexibility compared to classification-based solutions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u7d22\uff08EBR\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u8865\u5145\u4f20\u7edf\u5206\u7c7b\u65b9\u6cd5\u5728\u89c6\u9891\u5185\u5bb9\u5ba1\u6838\u4e2d\u7684\u4e0d\u8db3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u5206\u7c7b\u65b9\u6cd5\u5728\u5feb\u901f\u54cd\u5e94\u548c\u6210\u672c\u6548\u76ca\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u5c24\u5176\u662f\u5728\u8d8b\u52bf\u9002\u5e94\u548c\u7d27\u6025\u5347\u7ea7\u573a\u666f\u4e2d\u3002", "method": "\u91c7\u7528\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\uff08SCL\uff09\u6846\u67b6\u8bad\u7ec3\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u57fa\u7840\u5d4c\u5165\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5d4c\u5165\u751f\u6210\u4e0e\u89c6\u9891\u68c0\u7d22\u7ed3\u5408\u7684EBR\u7cfb\u7edf\u3002", "result": "\u79bb\u7ebf\u5b9e\u9a8c\u663e\u793aEBR\u5c06ROC-AUC\u4ece0.85\u63d0\u5347\u81f30.99\uff0cPR-AUC\u4ece0.35\u63d0\u5347\u81f30.95\uff1b\u5728\u7ebf\u5b9e\u9a8c\u8868\u660eEBR\u63d0\u9ad8\u4e8610.32%\u7684\u884c\u52a8\u7387\u5e76\u964d\u4f4e80%\u4ee5\u4e0a\u7684\u8fd0\u8425\u6210\u672c\u3002", "conclusion": "EBR\u65b9\u6cd5\u5728\u6027\u80fd\u3001\u6548\u7387\u548c\u7075\u6d3b\u6027\u4e0a\u4f18\u4e8e\u4f20\u7edf\u5206\u7c7b\u65b9\u6cd5\uff0c\u9002\u5408\u89c6\u9891\u5185\u5bb9\u5ba1\u6838\u7684\u5b9e\u9645\u9700\u6c42\u3002"}}
{"id": "2507.01099", "pdf": "https://arxiv.org/pdf/2507.01099", "abs": "https://arxiv.org/abs/2507.01099", "authors": ["Zeyi Liu", "Shuang Li", "Eric Cousineau", "Siyuan Feng", "Benjamin Burchfiel", "Shuran Song"], "title": "Geometry-aware 4D Video Generation for Robot Manipulation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "Project website: https://robot4dgen.github.io", "summary": "Understanding and predicting the dynamics of the physical world can enhance a\nrobot's ability to plan and interact effectively in complex environments. While\nrecent video generation models have shown strong potential in modeling dynamic\nscenes, generating videos that are both temporally coherent and geometrically\nconsistent across camera views remains a significant challenge. To address\nthis, we propose a 4D video generation model that enforces multi-view 3D\nconsistency of videos by supervising the model with cross-view pointmap\nalignment during training. This geometric supervision enables the model to\nlearn a shared 3D representation of the scene, allowing it to predict future\nvideo sequences from novel viewpoints based solely on the given RGB-D\nobservations, without requiring camera poses as inputs. Compared to existing\nbaselines, our method produces more visually stable and spatially aligned\npredictions across multiple simulated and real-world robotic datasets. We\nfurther show that the predicted 4D videos can be used to recover robot\nend-effector trajectories using an off-the-shelf 6DoF pose tracker, supporting\nrobust robot manipulation and generalization to novel camera viewpoints.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd4D\u89c6\u9891\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u8de8\u89c6\u89d2\u70b9\u56fe\u5bf9\u9f50\u76d1\u7763\u8bad\u7ec3\uff0c\u5b9e\u73b0\u591a\u89c6\u89d23D\u4e00\u81f4\u6027\uff0c\u63d0\u5347\u673a\u5668\u4eba\u52a8\u6001\u73af\u5883\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u589e\u5f3a\u673a\u5668\u4eba\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u89c4\u5212\u548c\u4ea4\u4e92\u80fd\u529b\uff0c\u89e3\u51b3\u89c6\u9891\u751f\u6210\u4e2d\u65f6\u95f4\u8fde\u8d2f\u6027\u548c\u51e0\u4f55\u4e00\u81f4\u6027\u7684\u6311\u6218\u3002", "method": "\u5229\u7528RGB-D\u89c2\u6d4b\u6570\u636e\uff0c\u901a\u8fc7\u8de8\u89c6\u89d2\u70b9\u56fe\u5bf9\u9f50\u76d1\u7763\u8bad\u7ec3\u6a21\u578b\uff0c\u5b66\u4e60\u5171\u4eab3D\u573a\u666f\u8868\u793a\uff0c\u65e0\u9700\u76f8\u673a\u59ff\u6001\u8f93\u5165\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u673a\u5668\u4eba\u6570\u636e\u96c6\u4e2d\u751f\u6210\u66f4\u7a33\u5b9a\u3001\u7a7a\u95f4\u5bf9\u9f50\u7684\u89c6\u9891\u9884\u6d4b\uff0c\u652f\u6301\u673a\u5668\u4eba\u64cd\u4f5c\u548c\u65b0\u89c6\u89d2\u6cdb\u5316\u3002", "conclusion": "4D\u89c6\u9891\u751f\u6210\u6a21\u578b\u6709\u6548\u63d0\u5347\u673a\u5668\u4eba\u52a8\u6001\u73af\u5883\u9884\u6d4b\u548c\u64cd\u4f5c\u80fd\u529b\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.01110", "pdf": "https://arxiv.org/pdf/2507.01110", "abs": "https://arxiv.org/abs/2507.01110", "authors": ["Felix Windisch", "Lukas Radl", "Thomas K\u00f6hler", "Michael Steiner", "Dieter Schmalstieg", "Markus Steinberger"], "title": "A LoD of Gaussians: Unified Training and Rendering for Ultra-Large Scale Reconstruction with External Memory", "categories": ["cs.GR", "cs.LG"], "comment": null, "summary": "Gaussian Splatting has emerged as a high-performance technique for novel view\nsynthesis, enabling real-time rendering and high-quality reconstruction of\nsmall scenes. However, scaling to larger environments has so far relied on\npartitioning the scene into chunks -- a strategy that introduces artifacts at\nchunk boundaries, complicates training across varying scales, and is poorly\nsuited to unstructured scenarios such as city-scale flyovers combined with\nstreet-level views. Moreover, rendering remains fundamentally limited by GPU\nmemory, as all visible chunks must reside in VRAM simultaneously. We introduce\nA LoD of Gaussians, a framework for training and rendering ultra-large-scale\nGaussian scenes on a single consumer-grade GPU -- without partitioning. Our\nmethod stores the full scene out-of-core (e.g., in CPU memory) and trains a\nLevel-of-Detail (LoD) representation directly, dynamically streaming only the\nrelevant Gaussians. A hybrid data structure combining Gaussian hierarchies with\nSequential Point Trees enables efficient, view-dependent LoD selection, while a\nlightweight caching and view scheduling system exploits temporal coherence to\nsupport real-time streaming and rendering. Together, these innovations enable\nseamless multi-scale reconstruction and interactive visualization of complex\nscenes -- from broad aerial views to fine-grained ground-level details.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aA LoD of Gaussians\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5355\u4e2a\u6d88\u8d39\u7ea7GPU\u4e0a\u8bad\u7ec3\u548c\u6e32\u67d3\u8d85\u5927\u89c4\u6a21\u9ad8\u65af\u573a\u666f\uff0c\u65e0\u9700\u5206\u533a\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u9ad8\u65af\u6e85\u5c04\u6280\u672f\u5728\u6269\u5c55\u5230\u5927\u573a\u666f\u65f6\u56e0\u5206\u533a\u7b56\u7565\u5bfc\u81f4\u7684\u8fb9\u754c\u4f2a\u5f71\u3001\u8bad\u7ec3\u590d\u6742\u6027\u548cGPU\u5185\u5b58\u9650\u5236\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6570\u636e\u7ed3\u6784\uff08\u9ad8\u65af\u5c42\u6b21\u7ed3\u6784\u4e0e\u987a\u5e8f\u70b9\u6811\uff09\u548c\u8f7b\u91cf\u7ea7\u7f13\u5b58\u4e0e\u89c6\u56fe\u8c03\u5ea6\u7cfb\u7edf\uff0c\u52a8\u6001\u6d41\u5f0f\u4f20\u8f93\u76f8\u5173\u9ad8\u65af\u6570\u636e\u3002", "result": "\u5b9e\u73b0\u4e86\u65e0\u7f1d\u591a\u5c3a\u5ea6\u91cd\u5efa\u548c\u590d\u6742\u573a\u666f\u7684\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\uff0c\u652f\u6301\u4ece\u9ad8\u7a7a\u4fef\u77b0\u5230\u5730\u9762\u7ec6\u8282\u7684\u591a\u5c3a\u5ea6\u6e32\u67d3\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5355\u4e2aGPU\u4e0a\u5b9e\u73b0\u4e86\u8d85\u5927\u89c4\u6a21\u573a\u666f\u7684\u9ad8\u6548\u8bad\u7ec3\u548c\u5b9e\u65f6\u6e32\u67d3\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6280\u672f\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2507.01123", "pdf": "https://arxiv.org/pdf/2507.01123", "abs": "https://arxiv.org/abs/2507.01123", "authors": ["Rahul A. Burange", "Harsh K. Shinde", "Omkar Mutyalwar"], "title": "Landslide Detection and Mapping Using Deep Learning Across Multi-Source Satellite Data and Geographic Regions", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": "20 pages, 24 figures", "summary": "Landslides pose severe threats to infrastructure, economies, and human lives,\nnecessitating accurate detection and predictive mapping across diverse\ngeographic regions. With advancements in deep learning and remote sensing,\nautomated landslide detection has become increasingly effective. This study\npresents a comprehensive approach integrating multi-source satellite imagery\nand deep learning models to enhance landslide identification and prediction. We\nleverage Sentinel-2 multispectral data and ALOS PALSAR-derived slope and\nDigital Elevation Model (DEM) layers to capture critical environmental features\ninfluencing landslide occurrences. Various geospatial analysis techniques are\nemployed to assess the impact of terra in characteristics, vegetation cover,\nand rainfall on detection accuracy. Additionally, we evaluate the performance\nof multiple stateof-the-art deep learning segmentation models, including U-Net,\nDeepLabV3+, and Res-Net, to determine their effectiveness in landslide\ndetection. The proposed framework contributes to the development of reliable\nearly warning systems, improved disaster risk management, and sustainable\nland-use planning. Our findings provide valuable insights into the potential of\ndeep learning and multi-source remote sensing in creating robust, scalable, and\ntransferable landslide prediction models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7ed3\u5408\u591a\u6e90\u536b\u661f\u5f71\u50cf\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u63d0\u5347\u6ed1\u5761\u8bc6\u522b\u548c\u9884\u6d4b\u80fd\u529b\uff0c\u4e3a\u707e\u5bb3\u98ce\u9669\u7ba1\u7406\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u6ed1\u5761\u5bf9\u57fa\u7840\u8bbe\u65bd\u3001\u7ecf\u6d4e\u548c\u4eba\u7c7b\u751f\u547d\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u9700\u8981\u51c6\u786e\u68c0\u6d4b\u548c\u9884\u6d4b\u3002", "method": "\u5229\u7528Sentinel-2\u591a\u5149\u8c31\u6570\u636e\u548cALOS PALSAR\u884d\u751f\u7684\u5761\u5ea6\u53caDEM\u5c42\uff0c\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u5982U-Net\u3001DeepLabV3+\u548cRes-Net\uff09\u8fdb\u884c\u6ed1\u5761\u68c0\u6d4b\u3002", "result": "\u7814\u7a76\u4e3a\u53ef\u9760\u7684\u65e9\u671f\u9884\u8b66\u7cfb\u7edf\u3001\u707e\u5bb3\u98ce\u9669\u7ba1\u7406\u548c\u53ef\u6301\u7eed\u571f\u5730\u5229\u7528\u89c4\u5212\u63d0\u4f9b\u4e86\u652f\u6301\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u548c\u591a\u6e90\u9065\u611f\u5728\u6784\u5efa\u7a33\u5065\u3001\u53ef\u6269\u5c55\u548c\u53ef\u8fc1\u79fb\u7684\u6ed1\u5761\u9884\u6d4b\u6a21\u578b\u4e2d\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2507.01143", "pdf": "https://arxiv.org/pdf/2507.01143", "abs": "https://arxiv.org/abs/2507.01143", "authors": ["Reza Jalayer", "Masoud Jalayer", "Amirali Baniasadi"], "title": "A Review on Sound Source Localization in Robotics: Focusing on Deep Learning Methods", "categories": ["cs.RO", "cs.LG", "cs.SD", "eess.AS"], "comment": "35 pages", "summary": "Sound source localization (SSL) adds a spatial dimension to auditory\nperception, allowing a system to pinpoint the origin of speech, machinery\nnoise, warning tones, or other acoustic events, capabilities that facilitate\nrobot navigation, human-machine dialogue, and condition monitoring. While\nexisting surveys provide valuable historical context, they typically address\ngeneral audio applications and do not fully account for robotic constraints or\nthe latest advancements in deep learning. This review addresses these gaps by\noffering a robotics-focused synthesis, emphasizing recent progress in deep\nlearning methodologies. We start by reviewing classical methods such as Time\nDifference of Arrival (TDOA), beamforming, Steered-Response Power (SRP), and\nsubspace analysis. Subsequently, we delve into modern machine learning (ML) and\ndeep learning (DL) approaches, discussing traditional ML and neural networks\n(NNs), convolutional neural networks (CNNs), convolutional recurrent neural\nnetworks (CRNNs), and emerging attention-based architectures. The data and\ntraining strategy that are the two cornerstones of DL-based SSL are explored.\nStudies are further categorized by robot types and application domains to\nfacilitate researchers in identifying relevant work for their specific\ncontexts. Finally, we highlight the current challenges in SSL works in general,\nregarding environmental robustness, sound source multiplicity, and specific\nimplementation constraints in robotics, as well as data and learning strategies\nin DL-based SSL. Also, we sketch promising directions to offer an actionable\nroadmap toward robust, adaptable, efficient, and explainable DL-based SSL for\nnext-generation robots.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u673a\u5668\u4eba\u9886\u57df\u4e2d\u7684\u58f0\u6e90\u5b9a\u4f4d\uff08SSL\uff09\u6280\u672f\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5e76\u63a2\u8ba8\u4e86\u5f53\u524d\u6311\u6218\u4e0e\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u7efc\u8ff0\u591a\u5173\u6ce8\u901a\u7528\u97f3\u9891\u5e94\u7528\uff0c\u672a\u5145\u5206\u8003\u8651\u673a\u5668\u4eba\u9886\u57df\u7684\u9650\u5236\u53ca\u6df1\u5ea6\u5b66\u4e60\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u56de\u987e\u4e86\u7ecf\u5178\u65b9\u6cd5\uff08\u5982TDOA\u3001\u6ce2\u675f\u6210\u5f62\u7b49\uff09\u548c\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff08\u5982CNN\u3001CRNN\u7b49\uff09\uff0c\u5e76\u5206\u6790\u4e86\u6570\u636e\u4e0e\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u603b\u7ed3\u4e86\u4e0d\u540c\u673a\u5668\u4eba\u7c7b\u578b\u548c\u5e94\u7528\u9886\u57df\u7684\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u5f53\u524dSSL\u9762\u4e34\u7684\u6311\u6218\uff08\u5982\u73af\u5883\u9c81\u68d2\u6027\u3001\u591a\u58f0\u6e90\u95ee\u9898\u7b49\uff09\u3002", "conclusion": "\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u65e8\u5728\u5b9e\u73b0\u66f4\u9c81\u68d2\u3001\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u6df1\u5ea6\u5b66\u4e60SSL\u6280\u672f\u3002"}}
{"id": "2507.01243", "pdf": "https://arxiv.org/pdf/2507.01243", "abs": "https://arxiv.org/abs/2507.01243", "authors": ["Ziang Zheng", "Guojian Zhan", "Shiqi Liu", "Yao Lyu", "Tao Zhang", "Shengbo Eben Li"], "title": "Jump-Start Reinforcement Learning with Self-Evolving Priors for Extreme Monopedal Locomotion", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) has shown great potential in enabling quadruped\nrobots to perform agile locomotion. However, directly training policies to\nsimultaneously handle dual extreme challenges, i.e., extreme underactuation and\nextreme terrains, as in monopedal hopping tasks, remains highly challenging due\nto unstable early-stage interactions and unreliable reward feedback. To address\nthis, we propose JumpER (jump-start reinforcement learning via self-evolving\npriors), an RL training framework that structures policy learning into multiple\nstages of increasing complexity. By dynamically generating self-evolving priors\nthrough iterative bootstrapping of previously learned policies, JumpER\nprogressively refines and enhances guidance, thereby stabilizing exploration\nand policy optimization without relying on external expert priors or\nhandcrafted reward shaping. Specifically, when integrated with a structured\nthree-stage curriculum that incrementally evolves action modality, observation\nspace, and task objective, JumpER enables quadruped robots to achieve robust\nmonopedal hopping on unpredictable terrains for the first time. Remarkably, the\nresulting policy effectively handles challenging scenarios that traditional\nmethods struggle to conquer, including wide gaps up to 60 cm, irregularly\nspaced stairs, and stepping stones with distances varying from 15 cm to 35 cm.\nJumpER thus provides a principled and scalable approach for addressing\nlocomotion tasks under the dual challenges of extreme underactuation and\nextreme terrains.", "AI": {"tldr": "JumpER\u662f\u4e00\u79cd\u901a\u8fc7\u81ea\u6f14\u5316\u5148\u9a8c\u5206\u9636\u6bb5\u8bad\u7ec3\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u56db\u8db3\u673a\u5668\u4eba\u5728\u6781\u7aef\u6b20\u9a71\u52a8\u548c\u6781\u7aef\u5730\u5f62\u4e0b\u7684\u5355\u8db3\u8df3\u8dc3\u4efb\u52a1\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u540c\u65f6\u5e94\u5bf9\u6781\u7aef\u6b20\u9a71\u52a8\u548c\u6781\u7aef\u5730\u5f62\u65f6\uff0c\u7531\u4e8e\u65e9\u671f\u4ea4\u4e92\u4e0d\u7a33\u5b9a\u548c\u5956\u52b1\u53cd\u9988\u4e0d\u53ef\u9760\uff0c\u96be\u4ee5\u76f4\u63a5\u8bad\u7ec3\u6709\u6548\u7684\u7b56\u7565\u3002", "method": "JumpER\u901a\u8fc7\u591a\u9636\u6bb5\u9010\u6b65\u589e\u52a0\u590d\u6742\u6027\u7684\u7b56\u7565\u5b66\u4e60\uff0c\u52a8\u6001\u751f\u6210\u81ea\u6f14\u5316\u5148\u9a8c\uff0c\u65e0\u9700\u5916\u90e8\u4e13\u5bb6\u5148\u9a8c\u6216\u624b\u5de5\u5956\u52b1\u8bbe\u8ba1\u3002", "result": "\u56db\u8db3\u673a\u5668\u4eba\u9996\u6b21\u5b9e\u73b0\u4e86\u5728\u4e0d\u53ef\u9884\u6d4b\u5730\u5f62\u4e0a\u7684\u7a33\u5065\u5355\u8db3\u8df3\u8dc3\uff0c\u80fd\u5e94\u5bf960\u5398\u7c73\u5bbd\u95f4\u9699\u3001\u4e0d\u89c4\u5219\u697c\u68af\u548c15-35\u5398\u7c73\u95f4\u8ddd\u7684\u8e0f\u811a\u77f3\u7b49\u6311\u6218\u3002", "conclusion": "JumpER\u4e3a\u6781\u7aef\u6b20\u9a71\u52a8\u548c\u6781\u7aef\u5730\u5f62\u4e0b\u7684\u8fd0\u52a8\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u539f\u5219\u6027\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01260", "pdf": "https://arxiv.org/pdf/2507.01260", "abs": "https://arxiv.org/abs/2507.01260", "authors": ["Y. Suzuki", "Y. Yukutake", "T. Ohminato", "M. Yamasaki", "Ahyi Kim"], "title": "Automated Classification of Volcanic Earthquakes Using Transformer Encoders: Insights into Data Quality and Model Interpretability", "categories": ["physics.geo-ph", "cs.LG"], "comment": "submitted to Seismological Research Letters", "summary": "Precisely classifying earthquake types is crucial for elucidating the\nrelationship between volcanic earthquakes and volcanic activity. However,\ntraditional methods rely on subjective human judgment, which requires\nconsiderable time and effort. To address this issue, we developed a deep\nlearning model using a transformer encoder for a more objective and efficient\nclassification. Tested on Mount Asama's diverse seismic activity, our model\nachieved high F1 scores (0.930 for volcano tectonic, 0.931 for low-frequency\nearthquakes, and 0.980 for noise), superior to a conventional CNN-based method.\nTo enhance interpretability, attention weight visualizations were analyzed,\nrevealing that the model focuses on key waveform features similarly to human\nexperts. However, inconsistencies in training data, such as ambiguously labeled\nB-type events with S-waves, were found to influence classification accuracy and\nattention weight distributions. Experiments addressing data selection and\naugmentation demonstrated the importance of balancing data quality and\ndiversity. In addition, stations within 3 km of the crater played an important\nrole in improving model performance and interpretability. These findings\nhighlight the potential of Transformer-based models for automated volcanic\nearthquake classification, particularly in improving efficiency and\ninterpretability. By addressing challenges such as data imbalance and\nsubjective labeling, our approach provides a robust framework for understanding\nseismic activity at Mount Asama. Moreover, this framework offers opportunities\nfor transfer learning to other volcanic regions, paving the way for enhanced\nvolcanic hazard assessments and disaster mitigation strategies.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u7f16\u7801\u5668\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u9ad8\u6548\u3001\u5ba2\u89c2\u5730\u5206\u7c7b\u706b\u5c71\u5730\u9707\u7c7b\u578b\uff0c\u4f18\u4e8e\u4f20\u7edfCNN\u65b9\u6cd5\uff0c\u5e76\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u706b\u5c71\u5730\u9707\u5206\u7c7b\u4f9d\u8d56\u4e3b\u89c2\u4eba\u5de5\u5224\u65ad\uff0c\u8017\u65f6\u8017\u529b\uff0c\u9700\u66f4\u9ad8\u6548\u3001\u5ba2\u89c2\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528Transformer\u7f16\u7801\u5668\u6784\u5efa\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5206\u6790\u5173\u952e\u6ce2\u5f62\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u6ce8\u610f\u529b\u6743\u91cd\u53ef\u89c6\u5316\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u6a21\u578b\u5728Mount Asama\u7684\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff08F1\u5206\u6570\uff1a\u706b\u5c71\u6784\u9020\u5730\u97070.930\uff0c\u4f4e\u9891\u5730\u97070.931\uff0c\u566a\u58f00.980\uff09\uff0c\u4e14\u6570\u636e\u8d28\u91cf\u548c\u591a\u6837\u6027\u5bf9\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "Transformer\u6a21\u578b\u4e3a\u706b\u5c71\u5730\u9707\u5206\u7c7b\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u53ef\u63a8\u5e7f\u81f3\u5176\u4ed6\u706b\u5c71\u533a\u57df\uff0c\u52a9\u529b\u707e\u5bb3\u8bc4\u4f30\u4e0e\u51cf\u707e\u3002"}}
{"id": "2507.01284", "pdf": "https://arxiv.org/pdf/2507.01284", "abs": "https://arxiv.org/abs/2507.01284", "authors": ["Cristian Gariboldi", "Hayato Tokida", "Ken Kinjo", "Yuki Asada", "Alexander Carballo"], "title": "VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.ET", "cs.LG"], "comment": "2025 IEEE 28th International Conference on Intelligent Transportation\n  Systems (ITSC)", "summary": "Recent advancements in open-source Visual Language Models (VLMs) such as\nLLaVA, Qwen-VL, and Llama have catalyzed extensive research on their\nintegration with diverse systems. The internet-scale general knowledge\nencapsulated within these models presents significant opportunities for\nenhancing autonomous driving perception, prediction, and planning capabilities.\nIn this paper we propose VLAD, a vision-language autonomous driving model,\nwhich integrates a fine-tuned VLM with VAD, a state-of-the-art end-to-end\nsystem. We implement a specialized fine-tuning approach using custom\nquestion-answer datasets designed specifically to improve the spatial reasoning\ncapabilities of the model. The enhanced VLM generates high-level navigational\ncommands that VAD subsequently processes to guide vehicle operation.\nAdditionally, our system produces interpretable natural language explanations\nof driving decisions, thereby increasing transparency and trustworthiness of\nthe traditionally black-box end-to-end architecture. Comprehensive evaluation\non the real-world nuScenes dataset demonstrates that our integrated system\nreduces average collision rates by 31.82% compared to baseline methodologies,\nestablishing a new benchmark for VLM-augmented autonomous driving systems.", "AI": {"tldr": "VLAD\u6a21\u578b\u901a\u8fc7\u5fae\u8c03\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u4e0e\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff08VAD\uff09\u7ed3\u5408\uff0c\u63d0\u5347\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u51cf\u5c11\u78b0\u649e\u738731.82%\u3002", "motivation": "\u5229\u7528\u5f00\u6e90\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08\u5982LLaVA\u3001Qwen-VL\uff09\u7684\u901a\u7528\u77e5\u8bc6\uff0c\u589e\u5f3a\u81ea\u52a8\u9a7e\u9a76\u7684\u611f\u77e5\u3001\u9884\u6d4b\u548c\u89c4\u5212\u80fd\u529b\u3002", "method": "\u63d0\u51faVLAD\u6a21\u578b\uff0c\u901a\u8fc7\u5b9a\u5236\u95ee\u7b54\u6570\u636e\u96c6\u5fae\u8c03VLM\uff0c\u751f\u6210\u9ad8\u7ea7\u5bfc\u822a\u6307\u4ee4\uff0c\u5e76\u7531VAD\u5904\u7406\u4ee5\u6307\u5bfc\u8f66\u8f86\u64cd\u4f5c\u3002", "result": "\u5728nuScenes\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u78b0\u649e\u7387\u5e73\u5747\u964d\u4f4e31.82%\u3002", "conclusion": "VLAD\u4e3aVLM\u589e\u5f3a\u7684\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u8bbe\u7acb\u4e86\u65b0\u57fa\u51c6\uff0c\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2507.01305", "pdf": "https://arxiv.org/pdf/2507.01305", "abs": "https://arxiv.org/abs/2507.01305", "authors": ["Worameth Chinchuthakun", "Pakkapon Phongthawee", "Amit Raj", "Varun Jampani", "Pramook Khungurn", "Supasorn Suwajanakorn"], "title": "DiffusionLight-Turbo: Accelerated Light Probes for Free via Single-Pass Chrome Ball Inpainting", "categories": ["cs.CV", "cs.GR", "cs.LG", "I.3.3; I.4.8"], "comment": "arXiv admin note: substantial text overlap with arXiv:2312.09168", "summary": "We introduce a simple yet effective technique for estimating lighting from a\nsingle low-dynamic-range (LDR) image by reframing the task as a chrome ball\ninpainting problem. This approach leverages a pre-trained diffusion model,\nStable Diffusion XL, to overcome the generalization failures of existing\nmethods that rely on limited HDR panorama datasets. While conceptually simple,\nthe task remains challenging because diffusion models often insert incorrect or\ninconsistent content and cannot readily generate chrome balls in HDR format.\nOur analysis reveals that the inpainting process is highly sensitive to the\ninitial noise in the diffusion process, occasionally resulting in unrealistic\noutputs. To address this, we first introduce DiffusionLight, which uses\niterative inpainting to compute a median chrome ball from multiple outputs to\nserve as a stable, low-frequency lighting prior that guides the generation of a\nhigh-quality final result. To generate high-dynamic-range (HDR) light probes,\nan Exposure LoRA is fine-tuned to create LDR images at multiple exposure\nvalues, which are then merged. While effective, DiffusionLight is\ntime-intensive, requiring approximately 30 minutes per estimation. To reduce\nthis overhead, we introduce DiffusionLight-Turbo, which reduces the runtime to\nabout 30 seconds with minimal quality loss. This 60x speedup is achieved by\ntraining a Turbo LoRA to directly predict the averaged chrome balls from the\niterative process. Inference is further streamlined into a single denoising\npass using a LoRA swapping technique. Experimental results that show our method\nproduces convincing light estimates across diverse settings and demonstrates\nsuperior generalization to in-the-wild scenarios. Our code is available at\nhttps://diffusionlight.github.io/turbo", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5c06\u4efb\u52a1\u91cd\u65b0\u5b9a\u4e49\u4e3a\u9540\u94ec\u7403\u4fee\u590d\u95ee\u9898\uff0c\u4ece\u5355\u5f20\u4f4e\u52a8\u6001\u8303\u56f4\uff08LDR\uff09\u56fe\u50cf\u4f30\u8ba1\u5149\u7167\u7684\u7b80\u5355\u6709\u6548\u6280\u672f\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u9884\u8bad\u7ec3\u7684\u6269\u6563\u6a21\u578bStable Diffusion XL\uff0c\u514b\u670d\u4e86\u4f9d\u8d56\u6709\u9650HDR\u5168\u666f\u6570\u636e\u96c6\u7684\u73b0\u6709\u65b9\u6cd5\u7684\u6cdb\u5316\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u6709\u9650\u7684HDR\u5168\u666f\u6570\u636e\u96c6\uff0c\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6269\u6563\u6a21\u578b\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51faDiffusionLight\uff0c\u901a\u8fc7\u8fed\u4ee3\u4fee\u590d\u8ba1\u7b97\u4e2d\u4f4d\u9540\u94ec\u7403\u4f5c\u4e3a\u7a33\u5b9a\u7684\u4f4e\u9891\u5149\u7167\u5148\u9a8c\uff0c\u5e76\u5f15\u5165Exposure LoRA\u751f\u6210HDR\u5149\u63a2\u9488\u3002\u8fdb\u4e00\u6b65\u63d0\u51faDiffusionLight-Turbo\uff0c\u901a\u8fc7\u8bad\u7ec3Turbo LoRA\u76f4\u63a5\u9884\u6d4b\u8fed\u4ee3\u8fc7\u7a0b\u7ed3\u679c\uff0c\u663e\u8457\u63d0\u5347\u901f\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u6837\u5316\u573a\u666f\u4e2d\u751f\u6210\u903c\u771f\u7684\u5149\u7167\u4f30\u8ba1\uff0c\u5e76\u5728\u91ce\u5916\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "DiffusionLight\u53ca\u5176\u52a0\u901f\u7248\u672cDiffusionLight-Turbo\u5728\u5149\u7167\u4f30\u8ba1\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u540c\u65f6\u517c\u987e\u8d28\u91cf\u548c\u6548\u7387\u3002"}}
{"id": "2507.01323", "pdf": "https://arxiv.org/pdf/2507.01323", "abs": "https://arxiv.org/abs/2507.01323", "authors": ["Rongchang Zhao", "Huanchi Liu", "Jian Zhang"], "title": "SWinMamba: Serpentine Window State Space Model for Vascular Segmentation", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Vascular segmentation in medical images is crucial for disease diagnosis and\nsurgical navigation. However, the segmented vascular structure is often\ndiscontinuous due to its slender nature and inadequate prior modeling. In this\npaper, we propose a novel Serpentine Window Mamba (SWinMamba) to achieve\naccurate vascular segmentation. The proposed SWinMamba innovatively models the\ncontinuity of slender vascular structures by incorporating serpentine window\nsequences into bidirectional state space models. The serpentine window\nsequences enable efficient feature capturing by adaptively guiding global\nvisual context modeling to the vascular structure. Specifically, the Serpentine\nWindow Tokenizer (SWToken) adaptively splits the input image using overlapping\nserpentine window sequences, enabling flexible receptive fields (RFs) for\nvascular structure modeling. The Bidirectional Aggregation Module (BAM)\nintegrates coherent local features in the RFs for vascular continuity\nrepresentation. In addition, dual-domain learning with Spatial-Frequency Fusion\nUnit (SFFU) is designed to enhance the feature representation of vascular\nstructure. Extensive experiments on three challenging datasets demonstrate that\nthe proposed SWinMamba achieves superior performance with complete and\nconnected vessels.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSWinMamba\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u86c7\u5f62\u7a97\u53e3\u5e8f\u5217\u548c\u53cc\u5411\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u8840\u7ba1\u7ed3\u6784\u7684\u8fde\u7eed\u6027\u548c\u7cbe\u786e\u5206\u5272\u3002", "motivation": "\u8840\u7ba1\u5206\u5272\u5728\u533b\u5b66\u56fe\u50cf\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5e38\u56e0\u8840\u7ba1\u7ec6\u957f\u548c\u5148\u9a8c\u5efa\u6a21\u4e0d\u8db3\u5bfc\u81f4\u5206\u5272\u4e0d\u8fde\u7eed\u3002", "method": "SWinMamba\u7ed3\u5408\u86c7\u5f62\u7a97\u53e3\u5e8f\u5217\uff08SWToken\uff09\u548c\u53cc\u5411\u805a\u5408\u6a21\u5757\uff08BAM\uff09\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5206\u5272\u548c\u7279\u5f81\u6574\u5408\u5b9e\u73b0\u8840\u7ba1\u8fde\u7eed\u6027\u5efa\u6a21\uff0c\u5e76\u5229\u7528\u7a7a\u95f4-\u9891\u7387\u878d\u5408\u5355\u5143\uff08SFFU\uff09\u589e\u5f3a\u7279\u5f81\u8868\u793a\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSWinMamba\u80fd\u591f\u751f\u6210\u5b8c\u6574\u4e14\u8fde\u63a5\u7684\u8840\u7ba1\u5206\u5272\u7ed3\u679c\uff0c\u6027\u80fd\u4f18\u8d8a\u3002", "conclusion": "SWinMamba\u901a\u8fc7\u521b\u65b0\u7684\u86c7\u5f62\u7a97\u53e3\u5e8f\u5217\u548c\u53cc\u5411\u5efa\u6a21\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8840\u7ba1\u5206\u5272\u4e2d\u7684\u4e0d\u8fde\u7eed\u6027\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.01352", "pdf": "https://arxiv.org/pdf/2507.01352", "abs": "https://arxiv.org/abs/2507.01352", "authors": ["Chris Yuhao Liu", "Liang Zeng", "Yuzhen Xiao", "Jujie He", "Jiacai Liu", "Chaojie Wang", "Rui Yan", "Wei Shen", "Fuxiang Zhang", "Jiacheng Xu", "Yang Liu", "Yahui Zhou"], "title": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Despite the critical role of reward models (RMs) in reinforcement learning\nfrom human feedback (RLHF), current state-of-the-art open RMs perform poorly on\nmost existing evaluation benchmarks, failing to capture the spectrum of nuanced\nand sophisticated human preferences. Even approaches that incorporate advanced\ntraining techniques have not yielded meaningful performance improvements. We\nhypothesize that this brittleness stems primarily from limitations in\npreference datasets, which are often narrowly scoped, synthetically labeled, or\nlack rigorous quality control. To address these challenges, we present a\nlarge-scale preference dataset comprising 40 million preference pairs, named\nSynPref-40M. To enable data curation at scale, we design a human-AI synergistic\ntwo-stage pipeline that leverages the complementary strengths of human\nannotation quality and AI scalability. In this pipeline, humans provide\nverified annotations, while large language models perform automatic curation\nbased on human guidance. Training on this preference mixture, we introduce\nSkywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B\nparameters, trained on a carefully curated subset of 26 million preference\npairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile\nacross a wide range of capabilities, including alignment with human\npreferences, objective correctness, safety, resistance to stylistic biases, and\nbest-of-N scaling, achieving state-of-the-art performance across seven major\nreward model benchmarks. Ablation studies confirm that the effectiveness of our\napproach stems not only from data scale but also from high-quality curation.\nThe Skywork-Reward-V2 series represents substantial progress in open reward\nmodels, highlighting the untapped potential of existing preference datasets and\ndemonstrating how human-AI curation synergy can unlock significantly higher\ndata quality.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86SynPref-40M\u5927\u89c4\u6a21\u504f\u597d\u6570\u636e\u96c6\u548cSkywork-Reward-V2\u5956\u52b1\u6a21\u578b\u7cfb\u5217\uff0c\u901a\u8fc7\u4eba\u673a\u534f\u540c\u7684\u6570\u636e\u6807\u6ce8\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5956\u52b1\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5956\u52b1\u6a21\u578b\u5728\u6355\u6349\u4eba\u7c7b\u504f\u597d\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u6e90\u4e8e\u504f\u597d\u6570\u636e\u96c6\u7684\u5c40\u9650\u6027\uff0c\u5982\u8303\u56f4\u72ed\u7a84\u3001\u6807\u6ce8\u8d28\u91cf\u4f4e\u7b49\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4eba\u673a\u534f\u540c\u7684\u4e24\u9636\u6bb5\u6570\u636e\u6807\u6ce8\u6d41\u7a0b\uff0c\u7ed3\u5408\u4eba\u7c7b\u6807\u6ce8\u8d28\u91cf\u548cAI\u7684\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u8bad\u7ec3\u4e86\u4ece0.6B\u52308B\u53c2\u6570\u7684\u5956\u52b1\u6a21\u578b\u3002", "result": "Skywork-Reward-V2\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u4f18\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u6570\u636e\u89c4\u6a21\u548c\u9ad8\u8d28\u6807\u6ce8\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u4eba\u673a\u534f\u540c\u7684\u6570\u636e\u6807\u6ce8\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u5956\u52b1\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.01368", "pdf": "https://arxiv.org/pdf/2507.01368", "abs": "https://arxiv.org/abs/2507.01368", "authors": ["Tianning Chai", "Chancharik Mitra", "Brandon Huang", "Gautam Rajendrakumar Gare", "Zhiqiu Lin", "Assaf Arbelle", "Leonid Karlinsky", "Rogerio Feris", "Trevor Darrell", "Deva Ramanan", "Roei Herzig"], "title": "Activation Reward Models for Few-Shot Model Alignment", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Aligning Large Language Models (LLMs) and Large Multimodal Models (LMMs) to\nhuman preferences is a central challenge in improving the quality of the\nmodels' generative outputs for real-world applications. A common approach is to\nuse reward modeling to encode preferences, enabling alignment via post-training\nusing reinforcement learning. However, traditional reward modeling is not\neasily adaptable to new preferences because it requires a separate reward\nmodel, commonly trained on large preference datasets. To address this, we\nintroduce Activation Reward Models (Activation RMs) -- a novel few-shot reward\nmodeling method that leverages activation steering to construct well-aligned\nreward signals using minimal supervision and no additional model finetuning.\nActivation RMs outperform existing few-shot reward modeling approaches such as\nLLM-as-a-judge with in-context learning, voting-based scoring, and token\nprobability scoring on standard reward modeling benchmarks. Furthermore, we\ndemonstrate the effectiveness of Activation RMs in mitigating reward hacking\nbehaviors, highlighting their utility for safety-critical applications. Toward\nthis end, we propose PreferenceHack, a novel few-shot setting benchmark, the\nfirst to test reward models on reward hacking in a paired preference format.\nFinally, we show that Activation RM achieves state-of-the-art performance on\nthis benchmark, surpassing even GPT-4o.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u5c11\u6837\u672c\u5956\u52b1\u5efa\u6a21\u65b9\u6cd5\u2014\u2014\u6fc0\u6d3b\u5956\u52b1\u6a21\u578b\uff08Activation RMs\uff09\uff0c\u901a\u8fc7\u6fc0\u6d3b\u5bfc\u5411\u6784\u5efa\u5bf9\u9f50\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u65e0\u9700\u989d\u5916\u5fae\u8c03\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u65b0\u57fa\u51c6PreferenceHack\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5bf9\u9f50\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6a21\u6001\u6a21\u578b\u7684\u4eba\u7c7b\u504f\u597d\u662f\u63d0\u5347\u751f\u6210\u8d28\u91cf\u7684\u5173\u952e\uff0c\u4f20\u7edf\u5956\u52b1\u5efa\u6a21\u96be\u4ee5\u9002\u5e94\u65b0\u504f\u597d\u3002", "method": "\u5229\u7528\u6fc0\u6d3b\u5bfc\u5411\u6280\u672f\u6784\u5efa\u5956\u52b1\u4fe1\u53f7\uff0c\u4ec5\u9700\u5c11\u91cf\u76d1\u7763\u6570\u636e\uff0c\u65e0\u9700\u989d\u5916\u6a21\u578b\u5fae\u8c03\u3002", "result": "Activation RMs\u5728\u6807\u51c6\u5956\u52b1\u5efa\u6a21\u57fa\u51c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u65b0\u57fa\u51c6PreferenceHack\u4e0a\u8d85\u8d8aGPT-4o\u3002", "conclusion": "Activation RMs\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u5b89\u5168\u7684\u5c11\u6837\u672c\u5956\u52b1\u5efa\u6a21\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5b89\u5168\u5173\u952e\u5e94\u7528\u3002"}}
{"id": "2507.01372", "pdf": "https://arxiv.org/pdf/2507.01372", "abs": "https://arxiv.org/abs/2507.01372", "authors": ["Max Hamilton", "Jinlin Lai", "Wenlong Zhao", "Subhransu Maji", "Daniel Sheldon"], "title": "Active Measurement: Efficient Estimation at Scale", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "AI has the potential to transform scientific discovery by analyzing vast\ndatasets with little human effort. However, current workflows often do not\nprovide the accuracy or statistical guarantees that are needed. We introduce\nactive measurement, a human-in-the-loop AI framework for scientific\nmeasurement. An AI model is used to predict measurements for individual units,\nwhich are then sampled for human labeling using importance sampling. With each\nnew set of human labels, the AI model is improved and an unbiased Monte Carlo\nestimate of the total measurement is refined. Active measurement can provide\nprecise estimates even with an imperfect AI model, and requires little human\neffort when the AI model is very accurate. We derive novel estimators,\nweighting schemes, and confidence intervals, and show that active measurement\nreduces estimation error compared to alternatives in several measurement tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u4e3b\u52a8\u6d4b\u91cf\u201d\u7684\u4eba\u673a\u534f\u4f5cAI\u6846\u67b6\uff0c\u901a\u8fc7\u91cd\u8981\u6027\u91c7\u6837\u548c\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u63d0\u5347\u79d1\u5b66\u6d4b\u91cf\u7684\u7cbe\u5ea6\u548c\u6548\u7387\u3002", "motivation": "\u5f53\u524dAI\u5728\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u5e94\u7528\u7f3a\u4e4f\u51c6\u786e\u6027\u548c\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408AI\u9884\u6d4b\u548c\u4eba\u5de5\u6807\u6ce8\uff0c\u91c7\u7528\u91cd\u8981\u6027\u91c7\u6837\u4f18\u5316\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u63d0\u4f9b\u65e0\u504f\u6d4b\u91cf\u3002", "result": "\u4e3b\u52a8\u6d4b\u91cf\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u663e\u8457\u964d\u4f4e\u4e86\u4f30\u8ba1\u8bef\u5dee\uff0c\u4e14\u5bf9AI\u6a21\u578b\u7684\u5bb9\u9519\u6027\u8f83\u5f3a\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u79d1\u5b66\u6d4b\u91cf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u7cbe\u786e\u4e14\u7edf\u8ba1\u53ef\u9760\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2507.01397", "pdf": "https://arxiv.org/pdf/2507.01397", "abs": "https://arxiv.org/abs/2507.01397", "authors": ["Khanh Son Pham", "Christian Witte", "Jens Behley", "Johannes Betz", "Cyrill Stachniss"], "title": "Coherent Online Road Topology Estimation and Reasoning with Standard-Definition Maps", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at IROS 2025", "summary": "Most autonomous cars rely on the availability of high-definition (HD) maps.\nCurrent research aims to address this constraint by directly predicting HD map\nelements from onboard sensors and reasoning about the relationships between the\npredicted map and traffic elements. Despite recent advancements, the coherent\nonline construction of HD maps remains a challenging endeavor, as it\nnecessitates modeling the high complexity of road topologies in a unified and\nconsistent manner. To address this challenge, we propose a coherent approach to\npredict lane segments and their corresponding topology, as well as road\nboundaries, all by leveraging prior map information represented by commonly\navailable standard-definition (SD) maps. We propose a network architecture,\nwhich leverages hybrid lane segment encodings comprising prior information and\ndenoising techniques to enhance training stability and performance.\nFurthermore, we facilitate past frames for temporal consistency. Our\nexperimental evaluation demonstrates that our approach outperforms previous\nmethods by a large margin, highlighting the benefits of our modeling scheme.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6807\u51c6\u5730\u56fe\u4fe1\u606f\u9884\u6d4b\u8f66\u9053\u6bb5\u53ca\u5176\u62d3\u6251\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u4f9d\u8d56\u9ad8\u7cbe\u5730\u56fe\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u8f66\u8f7d\u4f20\u611f\u5668\u76f4\u63a5\u9884\u6d4b\u5730\u56fe\u5143\u7d20\u53ca\u5176\u5173\u7cfb\u3002", "method": "\u5229\u7528\u6807\u51c6\u5730\u56fe\u4fe1\u606f\uff0c\u7ed3\u5408\u6df7\u5408\u8f66\u9053\u6bb5\u7f16\u7801\u548c\u53bb\u566a\u6280\u672f\uff0c\u63d0\u5347\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6027\u80fd\uff0c\u5e76\u5f15\u5165\u65f6\u95f4\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5927\u5e45\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u5efa\u6a21\u65b9\u6848\u6709\u6548\u89e3\u51b3\u4e86\u9ad8\u7cbe\u5730\u56fe\u5728\u7ebf\u6784\u5efa\u7684\u590d\u6742\u6027\u95ee\u9898\u3002"}}
{"id": "2507.01413", "pdf": "https://arxiv.org/pdf/2507.01413", "abs": "https://arxiv.org/abs/2507.01413", "authors": ["Kushal Agrawal", "Verona Teo", "Juan J. Vazquez", "Sudarsh Kunnavakkam", "Vishak Srikanth", "Andy Liu"], "title": "Evaluating LLM Agent Collusion in Double Auctions", "categories": ["cs.GT", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive capabilities as\nautonomous agents with rapidly expanding applications in various domains. As\nthese agents increasingly engage in socioeconomic interactions, identifying\ntheir potential for undesirable behavior becomes essential. In this work, we\nexamine scenarios where they can choose to collude, defined as secretive\ncooperation that harms another party. To systematically study this, we\ninvestigate the behavior of LLM agents acting as sellers in simulated\ncontinuous double auction markets. Through a series of controlled experiments,\nwe analyze how parameters such as the ability to communicate, choice of model,\nand presence of environmental pressures affect the stability and emergence of\nseller collusion. We find that direct seller communication increases collusive\ntendencies, the propensity to collude varies across models, and environmental\npressures, such as oversight and urgency from authority figures, influence\ncollusive behavior. Our findings highlight important economic and ethical\nconsiderations for the deployment of LLM-based market agents.", "AI": {"tldr": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u5e02\u573a\u4ee3\u7406\u65f6\u53ef\u80fd\u51fa\u73b0\u7684\u5408\u8c0b\u884c\u4e3a\uff0c\u5206\u6790\u4e86\u6c9f\u901a\u80fd\u529b\u3001\u6a21\u578b\u9009\u62e9\u548c\u73af\u5883\u538b\u529b\u5bf9\u5408\u8c0b\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "motivation": "\u968f\u7740LLMs\u5728\u793e\u4f1a\u7ecf\u6d4e\u4e92\u52a8\u4e2d\u7684\u5e94\u7528\u589e\u52a0\uff0c\u8bc6\u522b\u5176\u6f5c\u5728\u7684\u4e0d\u826f\u884c\u4e3a\uff08\u5982\u5408\u8c0b\uff09\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u6a21\u62df\u8fde\u7eed\u53cc\u5411\u62cd\u5356\u5e02\u573a\uff0c\u63a7\u5236\u5b9e\u9a8c\u5206\u6790LLM\u4ee3\u7406\u4f5c\u4e3a\u5356\u5bb6\u7684\u884c\u4e3a\uff0c\u8003\u5bdf\u6c9f\u901a\u3001\u6a21\u578b\u9009\u62e9\u548c\u73af\u5883\u538b\u529b\u5bf9\u5408\u8c0b\u7684\u5f71\u54cd\u3002", "result": "\u76f4\u63a5\u6c9f\u901a\u589e\u52a0\u5408\u8c0b\u503e\u5411\uff0c\u4e0d\u540c\u6a21\u578b\u7684\u5408\u8c0b\u503e\u5411\u4e0d\u540c\uff0c\u73af\u5883\u538b\u529b\uff08\u5982\u76d1\u7ba1\u548c\u7d27\u8feb\u611f\uff09\u5f71\u54cd\u5408\u8c0b\u884c\u4e3a\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u90e8\u7f72\u57fa\u4e8eLLM\u7684\u5e02\u573a\u4ee3\u7406\u65f6\u9700\u8003\u8651\u7684\u7ecf\u6d4e\u548c\u4f26\u7406\u95ee\u9898\u3002"}}
{"id": "2507.01417", "pdf": "https://arxiv.org/pdf/2507.01417", "abs": "https://arxiv.org/abs/2507.01417", "authors": ["Jiawei Gu", "Ziyue Qiao", "Zechao Li"], "title": "Gradient Short-Circuit: Efficient Out-of-Distribution Detection via Feature Intervention", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted to ICCV 2025", "summary": "Out-of-Distribution (OOD) detection is critical for safely deploying deep\nmodels in open-world environments, where inputs may lie outside the training\ndistribution. During inference on a model trained exclusively with\nIn-Distribution (ID) data, we observe a salient gradient phenomenon: around an\nID sample, the local gradient directions for \"enhancing\" that sample's\npredicted class remain relatively consistent, whereas OOD samples--unseen in\ntraining--exhibit disorganized or conflicting gradient directions in the same\nneighborhood. Motivated by this observation, we propose an inference-stage\ntechnique to short-circuit those feature coordinates that spurious gradients\nexploit to inflate OOD confidence, while leaving ID classification largely\nintact. To circumvent the expense of recomputing the logits after this gradient\nshort-circuit, we further introduce a local first-order approximation that\naccurately captures the post-modification outputs without a second forward\npass. Experiments on standard OOD benchmarks show our approach yields\nsubstantial improvements. Moreover, the method is lightweight and requires\nminimal changes to the standard inference pipeline, offering a practical path\ntoward robust OOD detection in real-world applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u68af\u5ea6\u65b9\u5411\u4e00\u81f4\u6027\u7684OOD\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u77ed\u8def\u5f02\u5e38\u68af\u5ea6\u63d0\u5347\u68c0\u6d4b\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301ID\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u5728\u5f00\u653e\u73af\u5883\u4e2d\uff0cOOD\u68c0\u6d4b\u5bf9\u6a21\u578b\u5b89\u5168\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002\u4f5c\u8005\u89c2\u5bdf\u5230ID\u6837\u672c\u7684\u68af\u5ea6\u65b9\u5411\u4e00\u81f4\uff0c\u800cOOD\u6837\u672c\u68af\u5ea6\u6df7\u4e71\uff0c\u4ece\u800c\u63d0\u51fa\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u63a8\u7406\u9636\u6bb5\u6280\u672f\uff0c\u77ed\u8def\u5f02\u5e38\u68af\u5ea6\uff0c\u5e76\u901a\u8fc7\u4e00\u9636\u8fd1\u4f3c\u907f\u514d\u91cd\u590d\u8ba1\u7b97\u3002", "result": "\u5728\u6807\u51c6OOD\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u663e\u8457\u63d0\u5347\uff0c\u65b9\u6cd5\u8f7b\u91cf\u4e14\u6613\u4e8e\u5b9e\u73b0\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684OOD\u68c0\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01431", "pdf": "https://arxiv.org/pdf/2507.01431", "abs": "https://arxiv.org/abs/2507.01431", "authors": ["Yoonseok Yang", "Minjune Kim", "Marlon Rondinelli", "Keren Shao"], "title": "Pensieve Grader: An AI-Powered, Ready-to-Use Platform for Effortless Handwritten STEM Grading", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "comment": "7 pages, 5 figues, 1 table", "summary": "Grading handwritten, open-ended responses remains a major bottleneck in large\nuniversity STEM courses. We introduce Pensieve (https://www.pensieve.co), an\nAI-assisted grading platform that leverages large language models (LLMs) to\ntranscribe and evaluate student work, providing instructors with rubric-aligned\nscores, transcriptions, and confidence ratings. Unlike prior tools that focus\nnarrowly on specific tasks like transcription or rubric generation, Pensieve\nsupports the entire grading pipeline-from scanned student submissions to final\nfeedback-within a human-in-the-loop interface.\n  Pensieve has been deployed in real-world courses at over 20 institutions and\nhas graded more than 300,000 student responses. We present system details and\nempirical results across four core STEM disciplines: Computer Science,\nMathematics, Physics, and Chemistry. Our findings show that Pensieve reduces\ngrading time by an average of 65%, while maintaining a 95.4% agreement rate\nwith instructor-assigned grades for high-confidence predictions.", "AI": {"tldr": "Pensieve\u662f\u4e00\u4e2aAI\u8f85\u52a9\u8bc4\u5206\u5e73\u53f0\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8f6c\u5f55\u548c\u8bc4\u4f30\u5b66\u751f\u4f5c\u4e1a\uff0c\u663e\u8457\u51cf\u5c11\u8bc4\u5206\u65f6\u95f4\u5e76\u4fdd\u6301\u9ad8\u8bc4\u5206\u4e00\u81f4\u6027\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21STEM\u8bfe\u7a0b\u4e2d\u624b\u5199\u5f00\u653e\u6027\u7b54\u6848\u8bc4\u5206\u7684\u74f6\u9888\u95ee\u9898\u3002", "method": "\u5f00\u53d1Pensieve\u5e73\u53f0\uff0c\u6574\u5408LLMs\u8fdb\u884c\u8f6c\u5f55\u548c\u8bc4\u5206\uff0c\u652f\u6301\u4ece\u626b\u63cf\u4f5c\u4e1a\u5230\u6700\u7ec8\u53cd\u9988\u7684\u5168\u6d41\u7a0b\u3002", "result": "\u572820\u591a\u6240\u673a\u6784\u7684\u8bfe\u7a0b\u4e2d\u90e8\u7f72\uff0c\u8bc4\u520630\u4e07\u4efd\u7b54\u6848\uff0c\u8bc4\u5206\u65f6\u95f4\u51cf\u5c1165%\uff0c\u9ad8\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u4e0e\u6559\u5e08\u8bc4\u5206\u4e00\u81f4\u7387\u8fbe95.4%\u3002", "conclusion": "Pensieve\u6709\u6548\u63d0\u5347\u8bc4\u5206\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u8bc4\u5206\u8d28\u91cf\uff0c\u9002\u7528\u4e8e\u591a\u5b66\u79d1STEM\u8bfe\u7a0b\u3002"}}
{"id": "2507.01466", "pdf": "https://arxiv.org/pdf/2507.01466", "abs": "https://arxiv.org/abs/2507.01466", "authors": ["Tianyi Chen", "Hao Yang", "Wenjun Ma", "Jun Zhang"], "title": "Symbolic identification of tensor equations in multidimensional physical fields", "categories": ["math-ph", "cs.LG", "math.MP"], "comment": null, "summary": "Recently, data-driven methods have shown great promise for discovering\ngoverning equations from simulation or experimental data. However, most\nexisting approaches are limited to scalar equations, with few capable of\nidentifying tensor relationships. In this work, we propose a general\ndata-driven framework for identifying tensor equations, referred to as Symbolic\nIdentification of Tensor Equations (SITE). The core idea of SITE--representing\ntensor equations using a host-plasmid structure--is inspired by the\nmultidimensional gene expression programming (M-GEP) approach. To improve the\nrobustness of the evolutionary process, SITE adopts a genetic information\nretention strategy. Moreover, SITE introduces two key innovations beyond\nconventional evolutionary algorithms. First, it incorporates a dimensional\nhomogeneity check to restrict the search space and eliminate physically invalid\nexpressions. Second, it replaces traditional linear scaling with a tensor\nlinear regression technique, greatly enhancing the efficiency of numerical\ncoefficient optimization. We validate SITE using two benchmark scenarios, where\nit accurately recovers target equations from synthetic data, showing robustness\nto noise and small sample sizes. Furthermore, SITE is applied to identify\nconstitutive relations directly from molecular simulation data, which are\ngenerated without reliance on macroscopic constitutive models. It adapts to\nboth compressible and incompressible flow conditions and successfully\nidentifies the corresponding macroscopic forms, highlighting its potential for\ndata-driven discovery of tensor equation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSITE\u7684\u6570\u636e\u9a71\u52a8\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u6570\u636e\u4e2d\u8bc6\u522b\u5f20\u91cf\u65b9\u7a0b\uff0c\u901a\u8fc7\u5bbf\u4e3b-\u8d28\u7c92\u7ed3\u6784\u548c\u9057\u4f20\u4fe1\u606f\u4fdd\u7559\u7b56\u7565\u63d0\u9ad8\u9c81\u68d2\u6027\uff0c\u5e76\u5f15\u5165\u7ef4\u5ea6\u4e00\u81f4\u6027\u68c0\u67e5\u548c\u5f20\u91cf\u7ebf\u6027\u56de\u5f52\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u591a\u9650\u4e8e\u6807\u91cf\u65b9\u7a0b\uff0c\u96be\u4ee5\u8bc6\u522b\u5f20\u91cf\u5173\u7cfb\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u901a\u7528\u7684\u6570\u636e\u9a71\u52a8\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "SITE\u91c7\u7528\u5bbf\u4e3b-\u8d28\u7c92\u7ed3\u6784\u8868\u793a\u5f20\u91cf\u65b9\u7a0b\uff0c\u7ed3\u5408\u9057\u4f20\u4fe1\u606f\u4fdd\u7559\u7b56\u7565\u3001\u7ef4\u5ea6\u4e00\u81f4\u6027\u68c0\u67e5\u548c\u5f20\u91cf\u7ebf\u6027\u56de\u5f52\u6280\u672f\u3002", "result": "SITE\u5728\u5408\u6210\u6570\u636e\u4e2d\u51c6\u786e\u6062\u590d\u76ee\u6807\u65b9\u7a0b\uff0c\u5bf9\u566a\u58f0\u548c\u5c0f\u6837\u672c\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5e76\u6210\u529f\u4ece\u5206\u5b50\u6a21\u62df\u6570\u636e\u4e2d\u8bc6\u522b\u672c\u6784\u5173\u7cfb\u3002", "conclusion": "SITE\u5c55\u793a\u4e86\u6570\u636e\u9a71\u52a8\u53d1\u73b0\u5f20\u91cf\u65b9\u7a0b\u7684\u6f5c\u529b\uff0c\u9002\u7528\u4e8e\u53ef\u538b\u7f29\u548c\u4e0d\u53ef\u538b\u7f29\u6d41\u52a8\u6761\u4ef6\u3002"}}
{"id": "2507.01472", "pdf": "https://arxiv.org/pdf/2507.01472", "abs": "https://arxiv.org/abs/2507.01472", "authors": ["Jon\u00e1\u0161 Herec", "V\u00edt R\u016f\u017ei\u010dka", "Rado Pito\u0148\u00e1k"], "title": "Optimizing Methane Detection On Board Satellites: Speed, Accuracy, and Low-Power Solutions for Resource-Constrained Hardware", "categories": ["cs.CV", "cs.LG", "cs.PF"], "comment": "This is a preprint of a paper accepted for the EDHPC 2025 Conference", "summary": "Methane is a potent greenhouse gas, and detecting its leaks early via\nhyperspectral satellite imagery can help mitigate climate change. Meanwhile,\nmany existing missions operate in manual tasking regimes only, thus missing\npotential events of interest. To overcome slow downlink rates cost-effectively,\nonboard detection is a viable solution. However, traditional methane\nenhancement methods are too computationally demanding for resource-limited\nonboard hardware. This work accelerates methane detection by focusing on\nefficient, low-power algorithms. We test fast target detection methods (ACE,\nCEM) that have not been previously used for methane detection and propose a\nMag1c-SAS - a significantly faster variant of the current state-of-the-art\nalgorithm for methane detection: Mag1c. To explore their true detection\npotential, we integrate them with a machine learning model (U-Net, LinkNet).\nOur results identify two promising candidates (Mag1c-SAS and CEM), both\nacceptably accurate for the detection of strong plumes and computationally\nefficient enough for onboard deployment: one optimized more for accuracy, the\nother more for speed, achieving up to ~100x and ~230x faster computation than\noriginal Mag1c on resource-limited hardware. Additionally, we propose and\nevaluate three band selection strategies. One of them can outperform the method\ntraditionally used in the field while using fewer channels, leading to even\nfaster processing without compromising accuracy. This research lays the\nfoundation for future advancements in onboard methane detection with minimal\nhardware requirements, improving timely data delivery. The produced code, data,\nand models are open-sourced and can be accessed from\nhttps://github.com/zaitra/methane-filters-benchmark.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u4f4e\u529f\u8017\u7684\u7532\u70f7\u6cc4\u6f0f\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6539\u8fdb\u7b97\u6cd5\uff08Mag1c-SAS\u548cCEM\uff09\u548c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u901f\u5ea6\u548c\u786c\u4ef6\u9002\u5e94\u6027\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u4f18\u5316\u7684\u6ce2\u6bb5\u9009\u62e9\u7b56\u7565\u3002", "motivation": "\u7532\u70f7\u662f\u4e00\u79cd\u5f3a\u6548\u6e29\u5ba4\u6c14\u4f53\uff0c\u901a\u8fc7\u9ad8\u5149\u8c31\u536b\u661f\u56fe\u50cf\u65e9\u671f\u68c0\u6d4b\u5176\u6cc4\u6f0f\u6709\u52a9\u4e8e\u7f13\u89e3\u6c14\u5019\u53d8\u5316\u3002\u73b0\u6709\u4efb\u52a1\u591a\u4e3a\u624b\u52a8\u64cd\u4f5c\uff0c\u6548\u7387\u4f4e\u4e14\u6613\u9057\u6f0f\u4e8b\u4ef6\uff0c\u4e9f\u9700\u4e00\u79cd\u9002\u7528\u4e8e\u8d44\u6e90\u6709\u9650\u786c\u4ef6\u7684\u5feb\u901f\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u6d4b\u8bd5\u4e86\u5feb\u901f\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\uff08ACE\u3001CEM\uff09\uff0c\u5e76\u63d0\u51faMag1c-SAS\u7b97\u6cd5\uff08Mag1c\u7684\u5feb\u901f\u53d8\u4f53\uff09\u3002\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08U-Net\u3001LinkNet\uff09\u8bc4\u4f30\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e09\u79cd\u6ce2\u6bb5\u9009\u62e9\u7b56\u7565\u3002", "result": "Mag1c-SAS\u548cCEM\u8868\u73b0\u4f18\u5f02\uff0c\u5206\u522b\u4f18\u5316\u4e86\u7cbe\u5ea6\u548c\u901f\u5ea6\uff0c\u8ba1\u7b97\u901f\u5ea6\u6bd4\u539f\u59cbMag1c\u5feb100\u500d\u548c230\u500d\u3002\u5176\u4e2d\u4e00\u79cd\u6ce2\u6bb5\u9009\u62e9\u7b56\u7565\u5728\u51cf\u5c11\u901a\u9053\u6570\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u7cbe\u5ea6\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8d44\u6e90\u6709\u9650\u7684\u786c\u4ef6\u4e0a\u5b9e\u73b0\u9ad8\u6548\u7532\u70f7\u68c0\u6d4b\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63d0\u5347\u4e86\u6570\u636e\u4ea4\u4ed8\u7684\u53ca\u65f6\u6027\u3002\u4ee3\u7801\u3001\u6570\u636e\u548c\u6a21\u578b\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.01487", "pdf": "https://arxiv.org/pdf/2507.01487", "abs": "https://arxiv.org/abs/2507.01487", "authors": ["Marc Damie", "Florian Hahn", "Andreas Peter", "Jan Ramon"], "title": "How to Securely Shuffle? A survey about Secure Shufflers for privacy-preserving computations", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Ishai et al. (FOCS'06) introduced secure shuffling as an efficient building\nblock for private data aggregation. Recently, the field of differential privacy\nhas revived interest in secure shufflers by highlighting the privacy\namplification they can provide in various computations. Although several works\nargue for the utility of secure shufflers, they often treat them as black\nboxes; overlooking the practical vulnerabilities and performance trade-offs of\nexisting implementations. This leaves a central question open: what makes a\ngood secure shuffler?\n  This survey addresses that question by identifying, categorizing, and\ncomparing 26 secure protocols that realize the necessary shuffling\nfunctionality. To enable a meaningful comparison, we adapt and unify existing\nsecurity definitions into a consistent set of properties. We also present an\noverview of privacy-preserving technologies that rely on secure shufflers,\noffer practical guidelines for selecting appropriate protocols, and outline\npromising directions for future work.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5b89\u5168\u6df7\u6d17\u5668\u7684\u5b9a\u4e49\u3001\u5b9e\u73b0\u53ca\u5176\u5728\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u6bd4\u8f83\u4e8626\u79cd\u534f\u8bae\u3002", "motivation": "\u5b89\u5168\u6df7\u6d17\u5668\u5728\u9690\u79c1\u6570\u636e\u805a\u5408\u548c\u5dee\u5206\u9690\u79c1\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5e38\u5c06\u5176\u89c6\u4e3a\u9ed1\u7bb1\uff0c\u5ffd\u7565\u4e86\u5b9e\u9645\u6f0f\u6d1e\u548c\u6027\u80fd\u6743\u8861\u3002", "method": "\u901a\u8fc7\u8bc6\u522b\u3001\u5206\u7c7b\u548c\u6bd4\u8f8326\u79cd\u5b89\u5168\u534f\u8bae\uff0c\u7edf\u4e00\u5b89\u5168\u5b9a\u4e49\uff0c\u5e76\u63d0\u4f9b\u9009\u62e9\u6307\u5357\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u8bc4\u4f30\u5b89\u5168\u6df7\u6d17\u5668\uff0c\u5e76\u603b\u7ed3\u4e86\u5176\u5728\u4e0d\u540c\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "\u5b89\u5168\u6df7\u6d17\u5668\u7684\u8bbe\u8ba1\u548c\u9009\u62e9\u9700\u7efc\u5408\u8003\u8651\u5b89\u5168\u6027\u548c\u6027\u80fd\uff0c\u672a\u6765\u7814\u7a76\u5e94\u5173\u6ce8\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4f18\u5316\u3002"}}
{"id": "2507.01501", "pdf": "https://arxiv.org/pdf/2507.01501", "abs": "https://arxiv.org/abs/2507.01501", "authors": ["Eloy Pe\u00f1a-Asensio", "Fabio Ferrari"], "title": "Meteoroid stream identification with HDBSCAN unsupervised clustering algorithm", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.LG"], "comment": "Accepted in The Astronomical Journal", "summary": "Accurate identification of meteoroid streams is central to understanding\ntheir origins and evolution. However, overlapping clusters and background noise\nhinder classification, an issue amplified for missions such as ESA's LUMIO that\nrely on meteor shower observations to infer lunar meteoroid impact parameters.\nThis study evaluates the performance of the Hierarchical Density-Based Spatial\nClustering of Applications with Noise (HDBSCAN) algorithm for unsupervised\nmeteoroid stream identification, comparing its outcomes with the established\nCameras for All-Sky Meteor Surveillance (CAMS) look-up table method. We analyze\nthe CAMS Meteoroid Orbit Database v3.0 using three feature vectors: LUTAB (CAMS\ngeocentric parameters), ORBIT (heliocentric orbital elements), and GEO (adapted\ngeocentric parameters). HDBSCAN is applied with varying minimum cluster sizes\nand two cluster selection methods (eom and leaf). To align HDBSCAN clusters\nwith CAMS classifications, the Hungarian algorithm determines the optimal\nmapping. Clustering performance is assessed via the Silhouette score,\nNormalized Mutual Information, and F1 score, with Principal Component Analysis\nfurther supporting the analysis. With the GEO vector, HDBSCAN confirms 39\nmeteoroid streams, 21 strongly aligning with CAMS. The ORBIT vector identifies\n30 streams, 13 with high matching scores. Less active showers pose\nidentification challenges. The eom method consistently yields superior\nperformance and agreement with CAMS. Although HDBSCAN requires careful\nselection of the minimum cluster size, it delivers robust, internally\nconsistent clusters and outperforms the look-up table method in statistical\ncoherence. These results underscore HDBSCAN's potential as a mathematically\nconsistent alternative for meteoroid stream identification, although further\nvalidation is needed to assess physical validity.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86HDBSCAN\u7b97\u6cd5\u5728\u65e0\u76d1\u7763\u6d41\u661f\u7fa4\u8bc6\u522b\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u4e0eCAMS\u65b9\u6cd5\u5bf9\u6bd4\uff0c\u53d1\u73b0HDBSCAN\u5728\u7edf\u8ba1\u4e00\u81f4\u6027\u4e0a\u66f4\u4f18\u3002", "motivation": "\u51c6\u786e\u8bc6\u522b\u6d41\u661f\u7fa4\u5bf9\u7406\u89e3\u5176\u8d77\u6e90\u548c\u6f14\u5316\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u91cd\u53e0\u7c07\u548c\u80cc\u666f\u566a\u58f0\u589e\u52a0\u4e86\u5206\u7c7b\u96be\u5ea6\uff0c\u5c24\u5176\u662f\u5bf9\u4f9d\u8d56\u6d41\u661f\u96e8\u89c2\u6d4b\u7684\u4efb\u52a1\uff08\u5982ESA\u7684LUMIO\uff09\u3002", "method": "\u4f7f\u7528HDBSCAN\u7b97\u6cd5\u5206\u6790CAMS\u6d41\u661f\u8f68\u9053\u6570\u636e\u5e93\uff0c\u6bd4\u8f83\u4e09\u79cd\u7279\u5f81\u5411\u91cf\uff08LUTAB\u3001ORBIT\u3001GEO\uff09\uff0c\u5e76\u901a\u8fc7\u5308\u7259\u5229\u7b97\u6cd5\u4e0eCAMS\u5206\u7c7b\u5bf9\u9f50\uff0c\u8bc4\u4f30\u805a\u7c7b\u6027\u80fd\u3002", "result": "HDBSCAN\u786e\u8ba439\u4e2a\u6d41\u661f\u7fa4\uff0821\u4e2a\u4e0eCAMS\u9ad8\u5ea6\u4e00\u81f4\uff09\uff0cORBIT\u5411\u91cf\u8bc6\u522b30\u4e2a\uff0813\u4e2a\u5339\u914d\u5ea6\u9ad8\uff09\u3002eom\u65b9\u6cd5\u8868\u73b0\u6700\u4f18\u3002", "conclusion": "HDBSCAN\u5728\u7edf\u8ba1\u4e00\u81f4\u6027\u4e0a\u4f18\u4e8eCAMS\u65b9\u6cd5\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u7269\u7406\u6709\u6548\u6027\u3002"}}
{"id": "2507.01509", "pdf": "https://arxiv.org/pdf/2507.01509", "abs": "https://arxiv.org/abs/2507.01509", "authors": ["Tapas K. Dutta", "Snehashis Majhi", "Deepak Ranjan Nayak", "Debesh Jha"], "title": "Mamba Guided Boundary Prior Matters: A New Perspective for Generalized Polyp Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "11 pages, 2 figures, MICCAI-2025", "summary": "Polyp segmentation in colonoscopy images is crucial for early detection and\ndiagnosis of colorectal cancer. However, this task remains a significant\nchallenge due to the substantial variations in polyp shape, size, and color, as\nwell as the high similarity between polyps and surrounding tissues, often\ncompounded by indistinct boundaries. While existing encoder-decoder CNN and\ntransformer-based approaches have shown promising results, they struggle with\nstable segmentation performance on polyps with weak or blurry boundaries. These\nmethods exhibit limited abilities to distinguish between polyps and non-polyps\nand capture essential boundary cues. Moreover, their generalizability still\nfalls short of meeting the demands of real-time clinical applications. To\naddress these limitations, we propose SAM-MaGuP, a groundbreaking approach for\nrobust polyp segmentation. By incorporating a boundary distillation module and\na 1D-2D Mamba adapter within the Segment Anything Model (SAM), SAM-MaGuP excels\nat resolving weak boundary challenges and amplifies feature learning through\nenriched global contextual interactions. Extensive evaluations across five\ndiverse datasets reveal that SAM-MaGuP outperforms state-of-the-art methods,\nachieving unmatched segmentation accuracy and robustness. Our key innovations,\na Mamba-guided boundary prior and a 1D-2D Mamba block, set a new benchmark in\nthe field, pushing the boundaries of polyp segmentation to new heights.", "AI": {"tldr": "SAM-MaGuP\u662f\u4e00\u79cd\u521b\u65b0\u7684\u606f\u8089\u5206\u5272\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fb9\u754c\u84b8\u998f\u6a21\u5757\u548c1D-2D Mamba\u9002\u914d\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f31\u8fb9\u754c\u5206\u5272\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u606f\u8089\u5f62\u72b6\u3001\u5927\u5c0f\u548c\u989c\u8272\u53d8\u5316\u5927\u4e14\u8fb9\u754c\u6a21\u7cca\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u96be\u4ee5\u6ee1\u8db3\u5b9e\u65f6\u4e34\u5e8a\u9700\u6c42\u3002", "method": "\u7ed3\u5408\u8fb9\u754c\u84b8\u998f\u6a21\u5757\u548c1D-2D Mamba\u9002\u914d\u5668\uff0c\u589e\u5f3a\u5168\u5c40\u4e0a\u4e0b\u6587\u4ea4\u4e92\u548c\u8fb9\u754c\u7279\u5f81\u5b66\u4e60\u3002", "result": "\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5206\u5272\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "SAM-MaGuP\u4e3a\u606f\u8089\u5206\u5272\u9886\u57df\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\uff0c\u89e3\u51b3\u4e86\u5f31\u8fb9\u754c\u6311\u6218\u3002"}}
{"id": "2507.01533", "pdf": "https://arxiv.org/pdf/2507.01533", "abs": "https://arxiv.org/abs/2507.01533", "authors": ["Hanno Gottschalk", "Emil Partow", "Tobias J. Riedlinger"], "title": "Consistency of Learned Sparse Grid Quadrature Rules using NeuralODEs", "categories": ["math.NA", "cs.LG", "cs.NA", "math.PR"], "comment": null, "summary": "This paper provides a proof of the consistency of sparse grid quadrature for\nnumerical integration of high dimensional distributions. In a first step, a\ntransport map is learned that normalizes the distribution to a noise\ndistribution on the unit cube. This step is built on the statistical learning\ntheory of neural ordinary differential equations, which has been established\nrecently. Secondly, the composition of the generative map with the quantity of\ninterest is integrated numerically using the Clenshaw-Curtis sparse grid\nquadrature. A decomposition of the total numerical error in quadrature error\nand statistical error is provided. As main result it is proven in the framework\nof empirical risk minimization that all error terms can be controlled in the\nsense of PAC (probably approximately correct) learning and with high\nprobability the numerical integral approximates the theoretical value up to an\narbitrary small error in the limit where the data set size is growing and the\nnetwork capacity is increased adaptively.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u4e86\u7a00\u758f\u7f51\u683c\u6c42\u79ef\u5728\u9ad8\u7ef4\u5206\u5e03\u6570\u503c\u79ef\u5206\u4e2d\u7684\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u8fd0\u8f93\u6620\u5c04\u548c\u7a00\u758f\u7f51\u683c\u6c42\u79ef\u65b9\u6cd5\u63a7\u5236\u8bef\u5dee\u3002", "motivation": "\u9ad8\u7ef4\u5206\u5e03\u7684\u6570\u503c\u79ef\u5206\u662f\u4e00\u4e2a\u590d\u6742\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u4fdd\u8bc1\u8ba1\u7b97\u7684\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "1. \u5b66\u4e60\u8fd0\u8f93\u6620\u5c04\u5c06\u5206\u5e03\u5f52\u4e00\u5316\u5230\u5355\u4f4d\u7acb\u65b9\u4f53\u4e0a\u7684\u566a\u58f0\u5206\u5e03\uff1b2. \u4f7f\u7528Clenshaw-Curtis\u7a00\u758f\u7f51\u683c\u6c42\u79ef\u5bf9\u751f\u6210\u6620\u5c04\u4e0e\u76ee\u6807\u91cf\u7684\u7ec4\u5408\u8fdb\u884c\u6570\u503c\u79ef\u5206\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u6846\u67b6\u4e0b\uff0c\u6240\u6709\u8bef\u5dee\u9879\u5747\u53ef\u63a7\u5236\uff0c\u6570\u503c\u79ef\u5206\u80fd\u4ee5\u9ad8\u6982\u7387\u903c\u8fd1\u7406\u8bba\u503c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u9ad8\u7ef4\u6570\u503c\u79ef\u5206\u4e2d\u5177\u6709\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\uff0c\u9002\u7528\u4e8e\u5927\u6570\u636e\u96c6\u548c\u81ea\u9002\u5e94\u7f51\u7edc\u5bb9\u91cf\u589e\u957f\u7684\u60c5\u51b5\u3002"}}
{"id": "2507.01542", "pdf": "https://arxiv.org/pdf/2507.01542", "abs": "https://arxiv.org/abs/2507.01542", "authors": ["Tom Szwagier", "Pierre-Alexandre Mattei", "Charles Bouveyron", "Xavier Pennec"], "title": "Parsimonious Gaussian mixture models with piecewise-constant eigenvalue profiles", "categories": ["stat.ML", "cs.LG", "stat.AP", "stat.CO", "stat.ME"], "comment": null, "summary": "Gaussian mixture models (GMMs) are ubiquitous in statistical learning,\nparticularly for unsupervised problems. While full GMMs suffer from the\noverparameterization of their covariance matrices in high-dimensional spaces,\nspherical GMMs (with isotropic covariance matrices) certainly lack flexibility\nto fit certain anisotropic distributions. Connecting these two extremes, we\nintroduce a new family of parsimonious GMMs with piecewise-constant covariance\neigenvalue profiles. These extend several low-rank models like the celebrated\nmixtures of probabilistic principal component analyzers (MPPCA), by enabling\nany possible sequence of eigenvalue multiplicities. If the latter are\nprespecified, then we can naturally derive an expectation-maximization (EM)\nalgorithm to learn the mixture parameters. Otherwise, to address the\nnotoriously-challenging issue of jointly learning the mixture parameters and\nhyperparameters, we propose a componentwise penalized EM algorithm, whose\nmonotonicity is proven. We show the superior likelihood-parsimony tradeoffs\nachieved by our models on a variety of unsupervised experiments: density\nfitting, clustering and single-image denoising.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMM\uff09\u5bb6\u65cf\uff0c\u5177\u6709\u5206\u6bb5\u5e38\u6570\u534f\u65b9\u5dee\u7279\u5f81\u503c\uff0c\u5e73\u8861\u4e86\u5168GMM\u548c\u7403\u5f62GMM\u7684\u7075\u6d3b\u6027\u3002", "motivation": "\u89e3\u51b3\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u5168GMM\u8fc7\u53c2\u6570\u5316\u548c\u7403\u5f62GMM\u7075\u6d3b\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u5206\u6bb5\u5e38\u6570\u534f\u65b9\u5dee\u7279\u5f81\u503c\u7684GMM\uff0c\u5e76\u5f00\u53d1\u4e86EM\u7b97\u6cd5\u5b66\u4e60\u53c2\u6570\uff0c\u63d0\u51fa\u7ec4\u4ef6\u60e9\u7f5aEM\u7b97\u6cd5\u8054\u5408\u5b66\u4e60\u8d85\u53c2\u6570\u3002", "result": "\u5728\u5bc6\u5ea6\u62df\u5408\u3001\u805a\u7c7b\u548c\u56fe\u50cf\u53bb\u566a\u7b49\u65e0\u76d1\u7763\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u4f3c\u7136\u6027\u4e0e\u7b80\u6d01\u6027\u6743\u8861\u3002", "conclusion": "\u65b0\u6a21\u578b\u5728\u7075\u6d3b\u6027\u548c\u53c2\u6570\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u5e73\u8861\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u65e0\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\u3002"}}
{"id": "2507.01547", "pdf": "https://arxiv.org/pdf/2507.01547", "abs": "https://arxiv.org/abs/2507.01547", "authors": ["Ubada El Joulani", "Tatiana Kalganova", "Stergios-Aristoteles Mitoulis", "Sotirios Argyroudis"], "title": "AI and Remote Sensing for Resilient and Sustainable Built Environments: A Review of Current Methods, Open Data and Future Directions", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": null, "summary": "Critical infrastructure, such as transport networks, underpins economic\ngrowth by enabling mobility and trade. However, ageing assets, climate change\nimpacts (e.g., extreme weather, rising sea levels), and hybrid threats ranging\nfrom natural disasters to cyber attacks and conflicts pose growing risks to\ntheir resilience and functionality. This review paper explores how emerging\ndigital technologies, specifically Artificial Intelligence (AI), can enhance\ndamage assessment and monitoring of transport infrastructure. A systematic\nliterature review examines existing AI models and datasets for assessing damage\nin roads, bridges, and other critical infrastructure impacted by natural\ndisasters. Special focus is given to the unique challenges and opportunities\nassociated with bridge damage detection due to their structural complexity and\ncritical role in connectivity. The integration of SAR (Synthetic Aperture\nRadar) data with AI models is also discussed, with the review revealing a\ncritical research gap: a scarcity of studies applying AI models to SAR data for\ncomprehensive bridge damage assessment. Therefore, this review aims to identify\nthe research gaps and provide foundations for AI-driven solutions for assessing\nand monitoring critical transport infrastructures.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u5982\u4f55\u901a\u8fc7\u6570\u5b57\u6280\u672f\u63d0\u5347\u4ea4\u901a\u57fa\u7840\u8bbe\u65bd\u7684\u635f\u5bb3\u8bc4\u4f30\u4e0e\u76d1\u6d4b\u80fd\u529b\uff0c\u7279\u522b\u5173\u6ce8\u6865\u6881\u635f\u5bb3\u68c0\u6d4b\u7684\u6311\u6218\u4e0e\u673a\u9047\uff0c\u5e76\u6307\u51faSAR\u6570\u636e\u4e0eAI\u6a21\u578b\u7ed3\u5408\u7684\u7814\u7a76\u7f3a\u53e3\u3002", "motivation": "\u4ea4\u901a\u57fa\u7840\u8bbe\u65bd\u5bf9\u7ecf\u6d4e\u589e\u957f\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9762\u4e34\u8001\u5316\u3001\u6c14\u5019\u53d8\u5316\u548c\u6df7\u5408\u5a01\u80c1\uff08\u5982\u81ea\u7136\u707e\u5bb3\u3001\u7f51\u7edc\u653b\u51fb\uff09\u7684\u98ce\u9669\uff0c\u9700\u8981\u65b0\u6280\u672f\u63d0\u5347\u5176\u97e7\u6027\u548c\u529f\u80fd\u6027\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u6790\u4e86\u73b0\u6709AI\u6a21\u578b\u548c\u6570\u636e\u96c6\u5728\u9053\u8def\u3001\u6865\u6881\u7b49\u57fa\u7840\u8bbe\u65bd\u635f\u5bb3\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u5173\u6ce8SAR\u6570\u636e\u4e0eAI\u6a21\u578b\u7684\u6574\u5408\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u76ee\u524d\u7f3a\u4e4f\u5c06AI\u6a21\u578b\u5e94\u7528\u4e8eSAR\u6570\u636e\u8fdb\u884c\u6865\u6881\u635f\u5bb3\u5168\u9762\u8bc4\u4f30\u7684\u7814\u7a76\uff0c\u5b58\u5728\u660e\u663e\u7684\u7814\u7a76\u7f3a\u53e3\u3002", "conclusion": "\u672c\u6587\u65e8\u5728\u586b\u8865\u7814\u7a76\u7f3a\u53e3\uff0c\u4e3aAI\u9a71\u52a8\u7684\u4ea4\u901a\u57fa\u7840\u8bbe\u65bd\u635f\u5bb3\u8bc4\u4f30\u4e0e\u76d1\u6d4b\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2507.01575", "pdf": "https://arxiv.org/pdf/2507.01575", "abs": "https://arxiv.org/abs/2507.01575", "authors": ["Masood Jan", "Wafa Njima", "Xun Zhang", "Alexander Artemenko"], "title": "Transfer Learning for VLC-based indoor Localization: Addressing Environmental Variability", "categories": ["eess.SP", "cs.LG"], "comment": "Accepted for publication in the IEEE VTC2025-Spring Conference, 7\n  pages", "summary": "Accurate indoor localization is crucial in industrial environments. Visible\nLight Communication (VLC) has emerged as a promising solution, offering high\naccuracy, energy efficiency, and minimal electromagnetic interference. However,\nVLC-based indoor localization faces challenges due to environmental\nvariability, such as lighting fluctuations and obstacles. To address these\nchallenges, we propose a Transfer Learning (TL)-based approach for VLC-based\nindoor localization. Using real-world data collected at a BOSCH factory, the TL\nframework integrates a deep neural network (DNN) to improve localization\naccuracy by 47\\%, reduce energy consumption by 32\\%, and decrease computational\ntime by 40\\% compared to the conventional models. The proposed solution is\nhighly adaptable under varying environmental conditions and achieves similar\naccuracy with only 30\\% of the dataset, making it a cost-efficient and scalable\noption for industrial applications in Industry 4.0.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fc1\u79fb\u5b66\u4e60\uff08TL\uff09\u7684\u53ef\u89c1\u5149\u901a\u4fe1\uff08VLC\uff09\u5ba4\u5185\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5b9a\u4f4d\u7cbe\u5ea6\u3001\u964d\u4f4e\u4e86\u80fd\u8017\u548c\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u5de5\u4e1a\u73af\u5883\u4e2d\u9ad8\u7cbe\u5ea6\u5ba4\u5185\u5b9a\u4f4d\u9700\u6c42\u8feb\u5207\uff0c\u4f46VLC\u6280\u672f\u53d7\u73af\u5883\u53d8\u5316\u5f71\u54cd\u8f83\u5927\u3002", "method": "\u91c7\u7528\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6\u7ed3\u5408\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\uff0c\u5229\u7528\u771f\u5b9e\u5de5\u5382\u6570\u636e\u4f18\u5316\u5b9a\u4f4d\u6027\u80fd\u3002", "result": "\u5b9a\u4f4d\u7cbe\u5ea6\u63d0\u534747%\uff0c\u80fd\u8017\u964d\u4f4e32%\uff0c\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c1140%\uff0c\u4e14\u4ec5\u970030%\u6570\u636e\u96c6\u5373\u53ef\u8fbe\u5230\u76f8\u4f3c\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u5e94\u6027\u5f3a\uff0c\u6210\u672c\u6548\u76ca\u9ad8\uff0c\u9002\u5408\u5de5\u4e1a4.0\u5e94\u7528\u3002"}}
{"id": "2507.01590", "pdf": "https://arxiv.org/pdf/2507.01590", "abs": "https://arxiv.org/abs/2507.01590", "authors": ["Ameer Hamza", "Zuhaib Hussain But", "Umar Arif", "Samiya", "M. Abdullah Asad", "Muhammad Naeem"], "title": "Autonomous AI Surveillance: Multimodal Deep Learning for Cognitive and Behavioral Monitoring", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "This study presents a novel classroom surveillance system that integrates\nmultiple modalities, including drowsiness, tracking of mobile phone usage, and\nface recognition,to assess student attentiveness with enhanced precision.The\nsystem leverages the YOLOv8 model to detect both mobile phone and sleep\nusage,(Ghatge et al., 2024) while facial recognition is achieved through\nLResNet Occ FC body tracking using YOLO and MTCNN.(Durai et al., 2024) These\nmodels work in synergy to provide comprehensive, real-time monitoring, offering\ninsights into student engagement and behavior.(S et al., 2023) The framework is\ntrained on specialized datasets, such as the RMFD dataset for face recognition\nand a Roboflow dataset for mobile phone detection. The extensive evaluation of\nthe system shows promising results. Sleep detection achieves 97. 42% mAP@50,\nface recognition achieves 86. 45% validation accuracy and mobile phone\ndetection reach 85. 89% mAP@50. The system is implemented within a core PHP web\napplication and utilizes ESP32-CAM hardware for seamless data capture.(Neto et\nal., 2024) This integrated approach not only enhances classroom monitoring, but\nalso ensures automatic attendance recording via face recognition as students\nremain seated in the classroom, offering scalability for diverse educational\nenvironments.(Banada,2025)", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u8bfe\u5802\u76d1\u63a7\u7cfb\u7edf\uff0c\u7ed3\u5408\u7761\u610f\u68c0\u6d4b\u3001\u624b\u673a\u4f7f\u7528\u8ffd\u8e2a\u548c\u4eba\u8138\u8bc6\u522b\uff0c\u63d0\u5347\u5b66\u751f\u6ce8\u610f\u529b\u8bc4\u4f30\u7684\u7cbe\u786e\u5ea6\u3002", "motivation": "\u901a\u8fc7\u6574\u5408\u591a\u79cd\u6280\u672f\u624b\u6bb5\uff0c\u5b9e\u65f6\u76d1\u63a7\u5b66\u751f\u884c\u4e3a\uff0c\u63d0\u9ad8\u8bfe\u5802\u53c2\u4e0e\u5ea6\u548c\u81ea\u52a8\u5316\u8003\u52e4\u6548\u7387\u3002", "method": "\u5229\u7528YOLOv8\u68c0\u6d4b\u624b\u673a\u548c\u7761\u7720\u884c\u4e3a\uff0cLResNet Occ FC\u548cMTCNN\u5b9e\u73b0\u4eba\u8138\u8bc6\u522b\uff0c\u7cfb\u7edf\u57fa\u4e8ePHP\u548cESP32-CAM\u786c\u4ef6\u5b9e\u73b0\u3002", "result": "\u7761\u7720\u68c0\u6d4bmAP@50\u8fbe97.42%\uff0c\u4eba\u8138\u8bc6\u522b\u9a8c\u8bc1\u51c6\u786e\u738786.45%\uff0c\u624b\u673a\u68c0\u6d4bmAP@50\u8fbe85.89%\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u6559\u80b2\u73af\u5883\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u76d1\u63a7\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u8003\u52e4\u3002"}}
{"id": "2507.01607", "pdf": "https://arxiv.org/pdf/2507.01607", "abs": "https://arxiv.org/abs/2507.01607", "authors": ["Quentin Le Roux", "Yannick Teglia", "Teddy Furon", "Philippe Loubet-Moundi", "Eric Bourbao"], "title": "Survivability of Backdoor Attacks on Unconstrained Face Recognition Systems", "categories": ["cs.CV", "cs.AI", "cs.CR", "cs.LG"], "comment": null, "summary": "The widespread use of deep learning face recognition raises several security\nconcerns. Although prior works point at existing vulnerabilities, DNN backdoor\nattacks against real-life, unconstrained systems dealing with images captured\nin the wild remain a blind spot of the literature. This paper conducts the\nfirst system-level study of backdoors in deep learning-based face recognition\nsystems. This paper yields four contributions by exploring the feasibility of\nDNN backdoors on these pipelines in a holistic fashion. We demonstrate for the\nfirst time two backdoor attacks on the face detection task: face generation and\nface landmark shift attacks. We then show that face feature extractors trained\nwith large margin losses also fall victim to backdoor attacks. Combining our\nmodels, we then show using 20 possible pipeline configurations and 15 attack\ncases that a single backdoor enables an attacker to bypass the entire function\nof a system. Finally, we provide stakeholders with several best practices and\ncountermeasures.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u6df1\u5ea6\u5b66\u4e60\u4eba\u8138\u8bc6\u522b\u7cfb\u7edf\u4e2d\u7684\u540e\u95e8\u653b\u51fb\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u578b\u653b\u51fb\u65b9\u5f0f\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u79cd\u914d\u7f6e\u4e0b\u7684\u6709\u6548\u6027\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u9632\u5fa1\u5efa\u8bae\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u4eba\u8138\u8bc6\u522b\u7cfb\u7edf\u7684\u5e7f\u6cdb\u5e94\u7528\u5f15\u53d1\u4e86\u5b89\u5168\u9690\u60a3\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5bf9\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u540e\u95e8\u653b\u51fb\u5173\u6ce8\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u63a2\u7d22\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u540e\u95e8\u653b\u51fb\u7684\u53ef\u884c\u6027\uff0c\u63d0\u51fa\u4e86\u4eba\u8138\u751f\u6210\u548c\u4eba\u8138\u5173\u952e\u70b9\u504f\u79fb\u4e24\u79cd\u653b\u51fb\u65b9\u5f0f\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u572820\u79cd\u7cfb\u7edf\u914d\u7f6e\u548c15\u79cd\u653b\u51fb\u6848\u4f8b\u4e2d\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5355\u4e00\u540e\u95e8\u653b\u51fb\u53ef\u7ed5\u8fc7\u6574\u4e2a\u7cfb\u7edf\u529f\u80fd\uff0c\u540c\u65f6\u53d1\u73b0\u5927\u95f4\u9694\u635f\u5931\u8bad\u7ec3\u7684\u7279\u5f81\u63d0\u53d6\u5668\u4e5f\u6613\u53d7\u653b\u51fb\u3002", "conclusion": "\u7814\u7a76\u586b\u8865\u4e86\u540e\u95e8\u653b\u51fb\u5728\u771f\u5b9e\u4eba\u8138\u8bc6\u522b\u7cfb\u7edf\u4e2d\u7684\u7a7a\u767d\uff0c\u4e3a\u76f8\u5173\u65b9\u63d0\u4f9b\u4e86\u9632\u5fa1\u63aa\u65bd\u548c\u6700\u4f73\u5b9e\u8df5\u3002"}}
{"id": "2507.01613", "pdf": "https://arxiv.org/pdf/2507.01613", "abs": "https://arxiv.org/abs/2507.01613", "authors": ["Shirong Xu", "Jingnan Zhang", "Junhui Wang"], "title": "When Less Is More: Binary Feedback Can Outperform Ordinal Comparisons in Ranking Recovery", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Paired comparison data, where users evaluate items in pairs, play a central\nrole in ranking and preference learning tasks. While ordinal comparison data\nintuitively offer richer information than binary comparisons, this paper\nchallenges that conventional wisdom. We propose a general parametric framework\nfor modeling ordinal paired comparisons without ties. The model adopts a\ngeneralized additive structure, featuring a link function that quantifies the\npreference difference between two items and a pattern function that governs the\ndistribution over ordinal response levels. This framework encompasses classical\nbinary comparison models as special cases, by treating binary responses as\nbinarized versions of ordinal data. Within this framework, we show that\nbinarizing ordinal data can significantly improve the accuracy of ranking\nrecovery. Specifically, we prove that under the counting algorithm, the ranking\nerror associated with binary comparisons exhibits a faster exponential\nconvergence rate than that of ordinal data. Furthermore, we characterize a\nsubstantial performance gap between binary and ordinal data in terms of a\nsignal-to-noise ratio (SNR) determined by the pattern function. We identify the\npattern function that minimizes the SNR and maximizes the benefit of\nbinarization. Extensive simulations and a real application on the MovieLens\ndataset further corroborate our theoretical findings.", "AI": {"tldr": "\u8bba\u6587\u6311\u6218\u4e86\u5e8f\u6570\u914d\u5bf9\u6bd4\u8f83\u6570\u636e\u6bd4\u4e8c\u5143\u6bd4\u8f83\u6570\u636e\u4fe1\u606f\u66f4\u4e30\u5bcc\u7684\u4f20\u7edf\u89c2\u70b9\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u5e73\u5c40\u7684\u5e8f\u6570\u914d\u5bf9\u6bd4\u8f83\u5efa\u6a21\u6846\u67b6\uff0c\u5e76\u8bc1\u660e\u4e8c\u5143\u5316\u5e8f\u6570\u6570\u636e\u53ef\u663e\u8457\u63d0\u9ad8\u6392\u540d\u6062\u590d\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u63a2\u8ba8\u5e8f\u6570\u914d\u5bf9\u6bd4\u8f83\u6570\u636e\u662f\u5426\u771f\u7684\u6bd4\u4e8c\u5143\u6bd4\u8f83\u6570\u636e\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u4fe1\u606f\uff0c\u5e76\u7814\u7a76\u4e8c\u5143\u5316\u5e8f\u6570\u6570\u636e\u5bf9\u6392\u540d\u6062\u590d\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5e7f\u4e49\u52a0\u6027\u7ed3\u6784\u7684\u53c2\u6570\u5316\u6846\u67b6\uff0c\u5305\u542b\u91cf\u5316\u504f\u597d\u5dee\u5f02\u7684\u94fe\u63a5\u51fd\u6570\u548c\u63a7\u5236\u5e8f\u6570\u54cd\u5e94\u5206\u5e03\u7684\u6a21\u5f0f\u51fd\u6570\u3002", "result": "\u8bc1\u660e\u5728\u8ba1\u6570\u7b97\u6cd5\u4e0b\uff0c\u4e8c\u5143\u6bd4\u8f83\u7684\u6392\u540d\u8bef\u5dee\u6536\u655b\u901f\u5ea6\u6bd4\u5e8f\u6570\u6570\u636e\u66f4\u5feb\uff0c\u5e76\u901a\u8fc7\u4fe1\u53f7\u566a\u58f0\u6bd4\uff08SNR\uff09\u91cf\u5316\u4e86\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "\u4e8c\u5143\u5316\u5e8f\u6570\u6570\u636e\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u80fd\u663e\u8457\u63d0\u5347\u6392\u540d\u6062\u590d\u7684\u51c6\u786e\u6027\uff0c\u5e76\u786e\u5b9a\u4e86\u6700\u5927\u5316\u4e8c\u5143\u5316\u6548\u679c\u7684\u6a21\u5f0f\u51fd\u6570\u3002"}}
{"id": "2507.01631", "pdf": "https://arxiv.org/pdf/2507.01631", "abs": "https://arxiv.org/abs/2507.01631", "authors": ["Camille Billouard", "Dawa Derksen", "Alexandre Constantin", "Bruno Vallet"], "title": "Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG"], "comment": "Accepted at ICCV 2025 Workshop 3D-VAST (From street to space: 3D\n  Vision Across Altitudes). Version before camera ready. Our code will be made\n  public after the conference", "summary": "Neural Radiance Fields (NeRF) have recently emerged as a paradigm for 3D\nreconstruction from multiview satellite imagery. However, state-of-the-art NeRF\nmethods are typically constrained to small scenes due to the memory footprint\nduring training, which we study in this paper. Previous work on large-scale\nNeRFs palliate this by dividing the scene into NeRFs. This paper introduces\nSnake-NeRF, a framework that scales to large scenes. Our out-of-core method\neliminates the need to load all images and networks simultaneously, and\noperates on a single device. We achieve this by dividing the region of interest\ninto NeRFs that 3D tile without overlap. Importantly, we crop the images with\noverlap to ensure each NeRFs is trained with all the necessary pixels. We\nintroduce a novel $2\\times 2$ 3D tile progression strategy and segmented\nsampler, which together prevent 3D reconstruction errors along the tile edges.\nOur experiments conclude that large satellite images can effectively be\nprocessed with linear time complexity, on a single GPU, and without compromise\nin quality.", "AI": {"tldr": "Snake-NeRF\u662f\u4e00\u79cd\u7528\u4e8e\u5927\u89c4\u6a21\u573a\u666f3D\u91cd\u5efa\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5757\u5904\u7406\u548c\u4f18\u5316\u91c7\u6837\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfNeRF\u65b9\u6cd5\u7684\u5185\u5b58\u9650\u5236\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfNeRF\u65b9\u6cd5\u56e0\u5185\u5b58\u9650\u5236\u96be\u4ee5\u5904\u7406\u5927\u89c4\u6a21\u573a\u666f\uff0c\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u4e14\u4e0d\u635f\u5931\u8d28\u91cf\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5206\u5757\u7b56\u7565\uff0c\u5c06\u573a\u666f\u5212\u5206\u4e3a\u65e0\u91cd\u53e0\u76843D\u5757\uff0c\u5e76\u4f18\u5316\u91c7\u6837\u7b56\u7565\u4ee5\u907f\u514d\u8fb9\u7f18\u8bef\u5dee\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u5728\u7ebf\u6027\u65f6\u95f4\u5185\u5904\u7406\u5927\u89c4\u6a21\u536b\u661f\u56fe\u50cf\uff0c\u4e14\u65e0\u9700\u591a\u8bbe\u5907\u652f\u6301\u3002", "conclusion": "Snake-NeRF\u4e3a\u5927\u89c4\u6a213D\u91cd\u5efa\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01654", "pdf": "https://arxiv.org/pdf/2507.01654", "abs": "https://arxiv.org/abs/2507.01654", "authors": ["Martine Hjelkrem-Tan", "Marius Aasan", "Gabriel Y. Arteaga", "Ad\u00edn Ram\u00edrez Rivera"], "title": "SPoT: Subpixel Placement of Tokens in Vision Transformers", "categories": ["cs.CV", "cs.LG"], "comment": "To appear in Workshop on Efficient Computing under Limited Resources:\n  Visual Computing (ICCV 2025). Code available at\n  https://github.com/dsb-ifi/SPoT", "summary": "Vision Transformers naturally accommodate sparsity, yet standard tokenization\nmethods confine features to discrete patch grids. This constraint prevents\nmodels from fully exploiting sparse regimes, forcing awkward compromises. We\npropose Subpixel Placement of Tokens (SPoT), a novel tokenization strategy that\npositions tokens continuously within images, effectively sidestepping\ngrid-based limitations. With our proposed oracle-guided search, we uncover\nsubstantial performance gains achievable with ideal subpixel token positioning,\ndrastically reducing the number of tokens necessary for accurate predictions\nduring inference. SPoT provides a new direction for flexible, efficient, and\ninterpretable ViT architectures, redefining sparsity as a strategic advantage\nrather than an imposed limitation.", "AI": {"tldr": "SPoT\u662f\u4e00\u79cd\u65b0\u7684tokenization\u7b56\u7565\uff0c\u901a\u8fc7\u8fde\u7eed\u5b9a\u4f4dtoken\u6765\u907f\u514d\u7f51\u683c\u9650\u5236\uff0c\u663e\u8457\u51cf\u5c11\u63a8\u7406\u6240\u9700\u7684token\u6570\u91cf\u3002", "motivation": "\u6807\u51c6tokenization\u65b9\u6cd5\u5c06\u7279\u5f81\u9650\u5236\u5728\u79bb\u6563\u7684patch\u7f51\u683c\u4e2d\uff0c\u963b\u788d\u4e86\u6a21\u578b\u5728\u7a00\u758f\u573a\u666f\u4e0b\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51faSubpixel Placement of Tokens (SPoT)\uff0c\u901a\u8fc7\u8fde\u7eed\u5b9a\u4f4dtoken\uff0c\u5e76\u7ed3\u5408oracle-guided\u641c\u7d22\u4f18\u5316\u6027\u80fd\u3002", "result": "SPoT\u663e\u8457\u51cf\u5c11\u4e86\u63a8\u7406\u6240\u9700\u7684token\u6570\u91cf\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "SPoT\u4e3aViT\u67b6\u6784\u63d0\u4f9b\u4e86\u7075\u6d3b\u3001\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u65b0\u65b9\u5411\uff0c\u5c06\u7a00\u758f\u6027\u8f6c\u5316\u4e3a\u6218\u7565\u4f18\u52bf\u3002"}}
{"id": "2507.01687", "pdf": "https://arxiv.org/pdf/2507.01687", "abs": "https://arxiv.org/abs/2507.01687", "authors": ["Georgios Arampatzis", "Stylianos Katsarakis", "Charalambos Makridakis"], "title": "A generative modeling / Physics-Informed Neural Network approach to random differential equations", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "The integration of Scientific Machine Learning (SciML) techniques with\nuncertainty quantification (UQ) represents a rapidly evolving frontier in\ncomputational science. This work advances Physics-Informed Neural Networks\n(PINNs) by incorporating probabilistic frameworks to effectively model\nuncertainty in complex systems. Our approach enhances the representation of\nuncertainty in forward problems by combining generative modeling techniques\nwith PINNs. This integration enables in a systematic fashion uncertainty\ncontrol while maintaining the predictive accuracy of the model. We demonstrate\nthe utility of this method through applications to random differential\nequations and random partial differential equations (PDEs).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6982\u7387\u6846\u67b6\u7684\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\uff0c\u7528\u4e8e\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\uff0c\u5e76\u901a\u8fc7\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u548c\u968f\u673a\u504f\u5fae\u5206\u65b9\u7a0b\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u79d1\u5b66\u673a\u5668\u5b66\u4e60\uff08SciML\uff09\u4e0e\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08UQ\uff09\u7684\u7ed3\u5408\u662f\u8ba1\u7b97\u79d1\u5b66\u7684\u524d\u6cbf\u9886\u57df\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u80fd\u529b\u6709\u9650\u3002", "method": "\u901a\u8fc7\u5c06\u751f\u6210\u5efa\u6a21\u6280\u672f\u4e0ePINNs\u7ed3\u5408\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u4ee5\u7cfb\u7edf\u5316\u65b9\u5f0f\u63a7\u5236\u4e0d\u786e\u5b9a\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u548c\u968f\u673a\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u4e3a\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u5de5\u5177\uff0c\u5c55\u793a\u4e86SciML\u4e0eUQ\u7ed3\u5408\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.01717", "pdf": "https://arxiv.org/pdf/2507.01717", "abs": "https://arxiv.org/abs/2507.01717", "authors": ["Gopichand Kanumolu", "Ashok Urlana", "Charaka Vinayak Kumar", "Bala Mallikarjunarao Garlapati"], "title": "Agent Ideate: A Framework for Product Idea Generation from Patents Using Agentic AI", "categories": ["cs.AI", "cs.IR", "cs.LG", "cs.MA"], "comment": "AgentScen Workshop, IJCAI 2025", "summary": "Patents contain rich technical knowledge that can inspire innovative product\nideas, yet accessing and interpreting this information remains a challenge.\nThis work explores the use of Large Language Models (LLMs) and autonomous\nagents to mine and generate product concepts from a given patent. In this work,\nwe design Agent Ideate, a framework for automatically generating product-based\nbusiness ideas from patents. We experimented with open-source LLMs and\nagent-based architectures across three domains: Computer Science, Natural\nLanguage Processing, and Material Chemistry. Evaluation results show that the\nagentic approach consistently outperformed standalone LLMs in terms of idea\nquality, relevance, and novelty. These findings suggest that combining LLMs\nwith agentic workflows can significantly enhance the innovation pipeline by\nunlocking the untapped potential of business idea generation from patent data.", "AI": {"tldr": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u81ea\u4e3b\u4ee3\u7406\u4ece\u4e13\u5229\u4e2d\u6316\u6398\u5e76\u751f\u6210\u4ea7\u54c1\u6982\u5ff5\uff0c\u63d0\u51faAgent Ideate\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u4ee3\u7406\u65b9\u6cd5\u5728\u521b\u610f\u8d28\u91cf\u3001\u76f8\u5173\u6027\u548c\u65b0\u9896\u6027\u4e0a\u4f18\u4e8e\u72ec\u7acbLLMs\u3002", "motivation": "\u4e13\u5229\u8574\u542b\u4e30\u5bcc\u7684\u6280\u672f\u77e5\u8bc6\uff0c\u4f46\u8bbf\u95ee\u548c\u89e3\u8bfb\u8fd9\u4e9b\u4fe1\u606f\u4ecd\u5177\u6311\u6218\u6027\uff0c\u5e0c\u671b\u901a\u8fc7LLMs\u548c\u4ee3\u7406\u6280\u672f\u6316\u6398\u5176\u521b\u65b0\u6f5c\u529b\u3002", "method": "\u8bbe\u8ba1Agent Ideate\u6846\u67b6\uff0c\u7ed3\u5408\u5f00\u6e90LLMs\u548c\u4ee3\u7406\u67b6\u6784\uff0c\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u6750\u6599\u5316\u5b66\u9886\u57df\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u4ee3\u7406\u65b9\u6cd5\u5728\u521b\u610f\u8d28\u91cf\u3001\u76f8\u5173\u6027\u548c\u65b0\u9896\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u72ec\u7acbLLMs\u3002", "conclusion": "\u7ed3\u5408LLMs\u4e0e\u4ee3\u7406\u5de5\u4f5c\u6d41\u53ef\u663e\u8457\u63d0\u5347\u4ece\u4e13\u5229\u6570\u636e\u751f\u6210\u5546\u4e1a\u521b\u610f\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.01728", "pdf": "https://arxiv.org/pdf/2507.01728", "abs": "https://arxiv.org/abs/2507.01728", "authors": ["Hao Wei", "Wanli Ni", "Wen Wang", "Wenjun Xu", "Dusit Niyato", "Ping Zhang"], "title": "Token Communication in the Era of Large Models: An Information Bottleneck-Based Approach", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "This letter proposes UniToCom, a unified token communication paradigm that\ntreats tokens as the fundamental units for both processing and wireless\ntransmission. Specifically, to enable efficient token representations, we\npropose a generative information bottleneck (GenIB) principle, which\nfacilitates the learning of tokens that preserve essential information while\nsupporting reliable generation across multiple modalities. By doing this,\nGenIB-based tokenization is conducive to improving the communication efficiency\nand reducing computational complexity. Additionally, we develop $\\sigma$-GenIB\nto address the challenges of variance collapse in autoregressive modeling,\nmaintaining representational diversity and stability. Moreover, we employ a\ncausal Transformer-based multimodal large language model (MLLM) at the receiver\nto unify the processing of both discrete and continuous tokens under the\nnext-token prediction paradigm. Simulation results validate the effectiveness\nand superiority of the proposed UniToCom compared to baselines under dynamic\nchannel conditions. By integrating token processing with MLLMs, UniToCom\nenables scalable and generalizable communication in favor of multimodal\nunderstanding and generation, providing a potential solution for\nnext-generation intelligent communications.", "AI": {"tldr": "UniToCom\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u4ee4\u724c\u901a\u4fe1\u8303\u5f0f\uff0c\u5c06\u4ee4\u724c\u4f5c\u4e3a\u5904\u7406\u548c\u65e0\u7ebf\u4f20\u8f93\u7684\u57fa\u672c\u5355\u4f4d\uff0c\u901a\u8fc7\u751f\u6210\u4fe1\u606f\u74f6\u9888\uff08GenIB\uff09\u539f\u5219\u63d0\u9ad8\u901a\u4fe1\u6548\u7387\u5e76\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u901a\u4fe1\u4e2d\u4ee4\u724c\u8868\u793a\u7684\u9ad8\u6548\u6027\u548c\u53ef\u9760\u6027\u95ee\u9898\uff0c\u540c\u65f6\u652f\u6301\u79bb\u6563\u548c\u8fde\u7eed\u4ee4\u724c\u7684\u7edf\u4e00\u5904\u7406\u3002", "method": "\u63d0\u51faGenIB\u539f\u5219\u4f18\u5316\u4ee4\u724c\u8868\u793a\uff0c\u5f00\u53d1\u03c3-GenIB\u9632\u6b62\u65b9\u5dee\u5d29\u6e83\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u56e0\u679cTransformer\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u5904\u7406\u4ee4\u724c\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660eUniToCom\u5728\u52a8\u6001\u4fe1\u9053\u6761\u4ef6\u4e0b\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "UniToCom\u901a\u8fc7\u7ed3\u5408\u4ee4\u724c\u5904\u7406\u548cMLLM\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u667a\u80fd\u901a\u4fe1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u548c\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01735", "pdf": "https://arxiv.org/pdf/2507.01735", "abs": "https://arxiv.org/abs/2507.01735", "authors": ["Kai Chen", "Ruiyuan Gao", "Lanqing Hong", "Hang Xu", "Xu Jia", "Holger Caesar", "Dengxin Dai", "Bingbing Liu", "Dzmitry Tsishkou", "Songcen Xu", "Chunjing Xu", "Qiang Xu", "Huchuan Lu", "Dit-Yan Yeung"], "title": "ECCV 2024 W-CODA: 1st Workshop on Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "ECCV 2024. Workshop page: https://coda-dataset.github.io/w-coda2024/", "summary": "In this paper, we present details of the 1st W-CODA workshop, held in\nconjunction with the ECCV 2024. W-CODA aims to explore next-generation\nsolutions for autonomous driving corner cases, empowered by state-of-the-art\nmultimodal perception and comprehension techniques. 5 Speakers from both\nacademia and industry are invited to share their latest progress and opinions.\nWe collect research papers and hold a dual-track challenge, including both\ncorner case scene understanding and generation. As the pioneering effort, we\nwill continuously bridge the gap between frontier autonomous driving techniques\nand fully intelligent, reliable self-driving agents robust towards corner\ncases.", "AI": {"tldr": "\u9996\u5c4aW-CODA\u7814\u8ba8\u4f1a\u6982\u8ff0\uff0c\u805a\u7126\u81ea\u52a8\u9a7e\u9a76\u6781\u7aef\u573a\u666f\u7684\u591a\u6a21\u6001\u611f\u77e5\u4e0e\u7406\u89e3\u6280\u672f\u3002", "motivation": "\u63a2\u7d22\u4e0b\u4e00\u4ee3\u81ea\u52a8\u9a7e\u9a76\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u6781\u7aef\u573a\u666f\u4e0b\u7684\u6311\u6218\u3002", "method": "\u9080\u8bf75\u4f4d\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u4e13\u5bb6\u5206\u4eab\u6700\u65b0\u8fdb\u5c55\uff0c\u5e76\u4e3e\u529e\u53cc\u8f68\u6311\u6218\u8d5b\uff08\u6781\u7aef\u573a\u666f\u7406\u89e3\u4e0e\u751f\u6210\uff09\u3002", "result": "\u7814\u8ba8\u4f1a\u6c47\u96c6\u4e86\u524d\u6cbf\u7814\u7a76\uff0c\u63a8\u52a8\u81ea\u52a8\u9a7e\u9a76\u6280\u672f\u5728\u6781\u7aef\u573a\u666f\u4e0b\u7684\u53ef\u9760\u6027\u3002", "conclusion": "W-CODA\u5c06\u6301\u7eed\u5f25\u5408\u524d\u6cbf\u6280\u672f\u4e0e\u5b8c\u5168\u667a\u80fd\u3001\u53ef\u9760\u7684\u81ea\u52a8\u9a7e\u9a76\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2507.01785", "pdf": "https://arxiv.org/pdf/2507.01785", "abs": "https://arxiv.org/abs/2507.01785", "authors": ["Zhixun Chen", "Ping Guo", "Wenhan Han", "Yifan Zhang", "Binbin Liu", "Haobin Lin", "Fengze Liu", "Yan Zhao", "Bingni Zhang", "Taifeng Wang", "Yin Zheng", "Meng Fang"], "title": "MuRating: A High Quality Data Selecting Approach to Multilingual Large Language Model Pretraining", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Data quality is a critical driver of large language model performance, yet\nexisting model-based selection methods focus almost exclusively on English. We\nintroduce MuRating, a scalable framework that transfers high-quality English\ndata-quality signals into a single rater for 17 target languages. MuRating\naggregates multiple English \"raters\" via pairwise comparisons to learn unified\ndocument-quality scores,then projects these judgments through translation to\ntrain a multilingual evaluator on monolingual, cross-lingual, and parallel text\npairs. Applied to web data, MuRating selects balanced subsets of English and\nmultilingual content to pretrain a 1.2 B-parameter LLaMA model. Compared to\nstrong baselines, including QuRater, AskLLM, DCLM and so on, our approach\nboosts average accuracy on both English benchmarks and multilingual\nevaluations, with especially large gains on knowledge-intensive tasks. We\nfurther analyze translation fidelity, selection biases, and underrepresentation\nof narrative material, outlining directions for future work.", "AI": {"tldr": "MuRating\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u82f1\u8bed\u6570\u636e\u8d28\u91cf\u4fe1\u53f7\u8f6c\u79fb\u523017\u79cd\u76ee\u6807\u8bed\u8a00\uff0c\u8bad\u7ec3\u591a\u8bed\u8a00\u8bc4\u4f30\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6a21\u578b\u7684\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u82f1\u8bed\uff0c\u800c\u6570\u636e\u8d28\u91cf\u5bf9\u591a\u8bed\u8a00\u5927\u6a21\u578b\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "method": "MuRating\u901a\u8fc7\u805a\u5408\u591a\u4e2a\u82f1\u8bed\u8bc4\u5206\u5668\u7684\u4fe1\u53f7\uff0c\u5b66\u4e60\u7edf\u4e00\u7684\u6587\u6863\u8d28\u91cf\u8bc4\u5206\uff0c\u5e76\u901a\u8fc7\u7ffb\u8bd1\u5c06\u8fd9\u4e9b\u8bc4\u5206\u6295\u5c04\u5230\u76ee\u6807\u8bed\u8a00\uff0c\u8bad\u7ec3\u591a\u8bed\u8a00\u8bc4\u4f30\u5668\u3002", "result": "MuRating\u5728\u82f1\u8bed\u548c\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u5c24\u5176\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "MuRating\u4e3a\u591a\u8bed\u8a00\u6570\u636e\u8d28\u91cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u5728\u7ffb\u8bd1\u4fdd\u771f\u5ea6\u548c\u53d9\u4e8b\u6750\u6599\u4ee3\u8868\u6027\u65b9\u9762\u7684\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2507.01790", "pdf": "https://arxiv.org/pdf/2507.01790", "abs": "https://arxiv.org/abs/2507.01790", "authors": ["Tianze Hua", "Tian Yun", "Ellie Pavlick"], "title": "How Do Vision-Language Models Process Conflicting Information Across Modalities?", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": "All code and resources are available at:\n  https://github.com/ethahtz/vlm_conflicting_info_processing", "summary": "AI models are increasingly required to be multimodal, integrating disparate\ninput streams into a coherent state representation on which subsequent\nbehaviors and actions can be based. This paper seeks to understand how such\nmodels behave when input streams present conflicting information. Focusing\nspecifically on vision-language models, we provide inconsistent inputs (e.g.,\nan image of a dog paired with the caption \"A photo of a cat\") and ask the model\nto report the information present in one of the specific modalities (e.g.,\n\"What does the caption say / What is in the image?\"). We find that models often\nfavor one modality over the other, e.g., reporting the image regardless of what\nthe caption says, but that different models differ in which modality they\nfavor. We find evidence that the behaviorally preferred modality is evident in\nthe internal representational structure of the model, and that specific\nattention heads can restructure the representations to favor one modality over\nthe other. Moreover, we find modality-agnostic \"router heads\" which appear to\npromote answers about the modality requested in the instruction, and which can\nbe manipulated or transferred in order to improve performance across datasets\nand modalities. Together, the work provides essential steps towards identifying\nand controlling if and how models detect and resolve conflicting signals within\ncomplex multimodal environments.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u591a\u6a21\u6001AI\u6a21\u578b\u5728\u8f93\u5165\u4fe1\u606f\u51b2\u7a81\u65f6\u7684\u884c\u4e3a\uff0c\u53d1\u73b0\u6a21\u578b\u503e\u5411\u4e8e\u4f18\u5148\u5904\u7406\u67d0\u4e00\u6a21\u6001\uff0c\u5e76\u63ed\u793a\u4e86\u5185\u90e8\u8868\u5f81\u7ed3\u6784\u548c\u6ce8\u610f\u529b\u673a\u5236\u7684\u4f5c\u7528\u3002", "motivation": "\u7406\u89e3\u591a\u6a21\u6001\u6a21\u578b\u5728\u8f93\u5165\u4fe1\u606f\u51b2\u7a81\u65f6\u7684\u884c\u4e3a\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u5411\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e0d\u4e00\u81f4\u7684\u8f93\u5165\uff08\u5982\u56fe\u50cf\u4e0e\u6807\u9898\u4e0d\u7b26\uff09\uff0c\u89c2\u5bdf\u6a21\u578b\u5bf9\u4e0d\u540c\u6a21\u6001\u7684\u504f\u597d\uff0c\u5e76\u5206\u6790\u5185\u90e8\u8868\u5f81\u548c\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u6a21\u578b\u901a\u5e38\u4f18\u5148\u5904\u7406\u67d0\u4e00\u6a21\u6001\uff0c\u4e14\u4e0d\u540c\u6a21\u578b\u504f\u597d\u4e0d\u540c\uff1b\u5185\u90e8\u8868\u5f81\u7ed3\u6784\u548c\u7279\u5b9a\u6ce8\u610f\u529b\u5934\u53ef\u8c03\u6574\u6a21\u6001\u504f\u597d\uff1b\u53d1\u73b0\u6a21\u6001\u65e0\u5173\u7684\u201c\u8def\u7531\u5934\u201d\u53ef\u4f18\u5316\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8bc6\u522b\u548c\u63a7\u5236\u591a\u6a21\u6001\u6a21\u578b\u5728\u51b2\u7a81\u4fe1\u53f7\u4e2d\u7684\u884c\u4e3a\u63d0\u4f9b\u4e86\u5173\u952e\u6b65\u9aa4\u3002"}}
{"id": "2507.01795", "pdf": "https://arxiv.org/pdf/2507.01795", "abs": "https://arxiv.org/abs/2507.01795", "authors": ["Lizuo Liu", "Lu Zhang", "Anne Gelb"], "title": "Neural Entropy-stable conservative flux form neural networks for learning hyperbolic conservation laws", "categories": ["math.NA", "cs.LG", "cs.NA", "math-ph", "math.MP", "65M08, 68T07, 65M22, 65M32, 65D25"], "comment": null, "summary": "We propose a neural entropy-stable conservative flux form neural network\n(NESCFN) for learning hyperbolic conservation laws and their associated entropy\nfunctions directly from solution trajectories, without requiring any predefined\nnumerical discretization. While recent neural network architectures have\nsuccessfully integrated classical numerical principles into learned models,\nmost rely on prior knowledge of the governing equations or assume a fixed\ndiscretization. Our approach removes this dependency by embedding\nentropy-stable design principles into the learning process itself, enabling the\ndiscovery of physically consistent dynamics in a fully data-driven setting. By\njointly learning both the numerical flux function and a corresponding entropy,\nthe proposed method ensures conservation and entropy dissipation, critical for\nlong-term stability and fidelity in the system of hyperbolic conservation laws.\nNumerical results demonstrate that the method achieves stability and\nconservation over extended time horizons and accurately captures shock\npropagation speeds, even without oracle access to future-time solution profiles\nin the training data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u71b5\u7a33\u5b9a\u4fdd\u5b88\u901a\u91cf\u5f62\u5f0f\u795e\u7ecf\u7f51\u7edc\uff08NESCFN\uff09\uff0c\u76f4\u63a5\u4ece\u89e3\u8f68\u8ff9\u5b66\u4e60\u53cc\u66f2\u5b88\u6052\u5f8b\u53ca\u5176\u71b5\u51fd\u6570\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u6570\u503c\u79bb\u6563\u5316\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5927\u591a\u4f9d\u8d56\u9884\u5148\u5df2\u77e5\u7684\u63a7\u5236\u65b9\u7a0b\u6216\u56fa\u5b9a\u79bb\u6563\u5316\uff0c\u800c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5d4c\u5165\u71b5\u7a33\u5b9a\u8bbe\u8ba1\u539f\u5219\uff0c\u5b9e\u73b0\u4e86\u5b8c\u5168\u6570\u636e\u9a71\u52a8\u7684\u7269\u7406\u4e00\u81f4\u6027\u52a8\u6001\u53d1\u73b0\u3002", "method": "\u901a\u8fc7\u8054\u5408\u5b66\u4e60\u6570\u503c\u901a\u91cf\u51fd\u6570\u548c\u5bf9\u5e94\u71b5\uff0c\u786e\u4fdd\u5b88\u6052\u548c\u71b5\u8017\u6563\uff0c\u9002\u7528\u4e8e\u53cc\u66f2\u5b88\u6052\u5f8b\u7cfb\u7edf\u7684\u957f\u671f\u7a33\u5b9a\u6027\u548c\u4fdd\u771f\u5ea6\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u957f\u65f6\u95f4\u8303\u56f4\u5185\u4fdd\u6301\u7a33\u5b9a\u548c\u5b88\u6052\uff0c\u5e76\u80fd\u51c6\u786e\u6355\u6349\u6fc0\u6ce2\u4f20\u64ad\u901f\u5ea6\uff0c\u5373\u4f7f\u8bad\u7ec3\u6570\u636e\u4e2d\u672a\u5305\u542b\u672a\u6765\u65f6\u95f4\u89e3\u5256\u9762\u3002", "conclusion": "NESCFN\u65b9\u6cd5\u5728\u65e0\u9700\u9884\u5b9a\u4e49\u79bb\u6563\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u53cc\u66f2\u5b88\u6052\u5f8b\u7684\u7269\u7406\u4e00\u81f4\u6027\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2507.01802", "pdf": "https://arxiv.org/pdf/2507.01802", "abs": "https://arxiv.org/abs/2507.01802", "authors": ["Katharina Beckh", "Elisa Studeny", "Sujan Sai Gannamaneni", "Dario Antweiler", "Stefan R\u00fcping"], "title": "The Anatomy of Evidence: An Investigation Into Explainable ICD Coding", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to ACL 2025 Findings", "summary": "Automatic medical coding has the potential to ease documentation and billing\nprocesses. For this task, transparency plays an important role for medical\ncoders and regulatory bodies, which can be achieved using explainability\nmethods. However, the evaluation of these approaches has been mostly limited to\nshort text and binary settings due to a scarcity of annotated data. Recent\nefforts by Cheng et al. (2023) have introduced the MDACE dataset, which\nprovides a valuable resource containing code evidence in clinical records. In\nthis work, we conduct an in-depth analysis of the MDACE dataset and perform\nplausibility evaluation of current explainable medical coding systems from an\napplied perspective. With this, we contribute to a deeper understanding of\nautomatic medical coding and evidence extraction. Our findings reveal that\nground truth evidence aligns with code descriptions to a certain degree. An\ninvestigation into state-of-the-art approaches shows a high overlap with ground\ntruth evidence. We propose match measures and highlight success and failure\ncases. Based on our findings, we provide recommendations for developing and\nevaluating explainable medical coding systems.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86MDACE\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e86\u53ef\u89e3\u91ca\u533b\u7597\u7f16\u7801\u7cfb\u7edf\u7684\u5408\u7406\u6027\uff0c\u53d1\u73b0\u771f\u5b9e\u8bc1\u636e\u4e0e\u4ee3\u7801\u63cf\u8ff0\u90e8\u5206\u4e00\u81f4\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u81ea\u52a8\u533b\u7597\u7f16\u7801\u53ef\u7b80\u5316\u6587\u6863\u548c\u8ba1\u8d39\u6d41\u7a0b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u56e0\u6570\u636e\u7a00\u7f3a\u591a\u9650\u4e8e\u77ed\u6587\u672c\u548c\u4e8c\u5143\u8bbe\u7f6e\uff0cMDACE\u6570\u636e\u96c6\u4e3a\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u8d44\u6e90\u3002", "method": "\u5bf9MDACE\u6570\u636e\u96c6\u8fdb\u884c\u6df1\u5165\u5206\u6790\uff0c\u8bc4\u4f30\u5f53\u524d\u53ef\u89e3\u91ca\u533b\u7597\u7f16\u7801\u7cfb\u7edf\u7684\u5408\u7406\u6027\uff0c\u5e76\u63d0\u51fa\u5339\u914d\u5ea6\u91cf\u65b9\u6cd5\u3002", "result": "\u771f\u5b9e\u8bc1\u636e\u4e0e\u4ee3\u7801\u63cf\u8ff0\u90e8\u5206\u4e00\u81f4\uff0c\u5148\u8fdb\u65b9\u6cd5\u4e0e\u771f\u5b9e\u8bc1\u636e\u9ad8\u5ea6\u91cd\u53e0\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u4e0e\u8bc4\u4f30\u53ef\u89e3\u91ca\u533b\u7597\u7f16\u7801\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5efa\u8bae\uff0c\u52a0\u6df1\u4e86\u5bf9\u81ea\u52a8\u533b\u7597\u7f16\u7801\u7684\u7406\u89e3\u3002"}}
{"id": "2507.01844", "pdf": "https://arxiv.org/pdf/2507.01844", "abs": "https://arxiv.org/abs/2507.01844", "authors": ["Arthur Wuhrmann", "Anastasiia Kucherenko", "Andrei Kucharavy"], "title": "Low-Perplexity LLM-Generated Sequences and Where To Find Them", "categories": ["cs.CL", "cs.LG"], "comment": "Camera-ready version. Accepted to ACL 2025. 10 pages, 4 figures, 6\n  tables", "summary": "As Large Language Models (LLMs) become increasingly widespread, understanding\nhow specific training data shapes their outputs is crucial for transparency,\naccountability, privacy, and fairness. To explore how LLMs leverage and\nreplicate their training data, we introduce a systematic approach centered on\nanalyzing low-perplexity sequences - high-probability text spans generated by\nthe model. Our pipeline reliably extracts such long sequences across diverse\ntopics while avoiding degeneration, then traces them back to their sources in\nthe training data. Surprisingly, we find that a substantial portion of these\nlow-perplexity spans cannot be mapped to the corpus. For those that do match,\nwe quantify the distribution of occurrences across source documents,\nhighlighting the scope and nature of verbatim recall and paving a way toward\nbetter understanding of how LLMs training data impacts their behavior.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u4f4e\u56f0\u60d1\u5ea6\u5e8f\u5217\u6765\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5982\u4f55\u5229\u7528\u548c\u590d\u5236\u8bad\u7ec3\u6570\u636e\uff0c\u53d1\u73b0\u90e8\u5206\u5e8f\u5217\u65e0\u6cd5\u8ffd\u6eaf\u5230\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u5bf9\u5339\u914d\u5e8f\u5217\u7684\u5206\u5e03\u8fdb\u884c\u4e86\u91cf\u5316\u3002", "motivation": "\u7406\u89e3\u8bad\u7ec3\u6570\u636e\u5982\u4f55\u5f71\u54cdLLMs\u7684\u8f93\u51fa\uff0c\u4ee5\u63d0\u9ad8\u900f\u660e\u5ea6\u3001\u95ee\u8d23\u6027\u3001\u9690\u79c1\u548c\u516c\u5e73\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4f4e\u56f0\u60d1\u5ea6\u5e8f\u5217\uff08\u9ad8\u6982\u7387\u6587\u672c\u7247\u6bb5\uff09\u5e76\u8ffd\u8e2a\u5176\u8bad\u7ec3\u6570\u636e\u6765\u6e90\u3002", "result": "\u53d1\u73b0\u5927\u91cf\u4f4e\u56f0\u60d1\u5ea6\u5e8f\u5217\u65e0\u6cd5\u6620\u5c04\u5230\u8bad\u7ec3\u6570\u636e\uff0c\u5bf9\u5339\u914d\u5e8f\u5217\u7684\u5206\u5e03\u8fdb\u884c\u4e86\u91cf\u5316\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3LLMs\u8bad\u7ec3\u6570\u636e\u5bf9\u5176\u884c\u4e3a\u7684\u5f71\u54cd\u3002"}}
{"id": "2507.01881", "pdf": "https://arxiv.org/pdf/2507.01881", "abs": "https://arxiv.org/abs/2507.01881", "authors": ["Niccol\u00f2 McConnell", "Pardeep Vasudev", "Daisuke Yamada", "Daryl Cheng", "Mehran Azimbagirad", "John McCabe", "Shahab Aslani", "Ahmed H. Shahin", "Yukun Zhou", "The SUMMIT Consortium", "Andre Altmann", "Yipeng Hu", "Paul Taylor", "Sam M. Janes", "Daniel C. Alexander", "Joseph Jacob"], "title": "A computationally frugal open-source foundation model for thoracic disease detection in lung cancer screening programs", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Low-dose computed tomography (LDCT) imaging employed in lung cancer screening\n(LCS) programs is increasing in uptake worldwide. LCS programs herald a\ngenerational opportunity to simultaneously detect cancer and non-cancer-related\nearly-stage lung disease. Yet these efforts are hampered by a shortage of\nradiologists to interpret scans at scale. Here, we present TANGERINE, a\ncomputationally frugal, open-source vision foundation model for volumetric LDCT\nanalysis. Designed for broad accessibility and rapid adaptation, TANGERINE can\nbe fine-tuned off the shelf for a wide range of disease-specific tasks with\nlimited computational resources and training data. Relative to models trained\nfrom scratch, TANGERINE demonstrates fast convergence during fine-tuning,\nthereby requiring significantly fewer GPU hours, and displays strong label\nefficiency, achieving comparable or superior performance with a fraction of\nfine-tuning data. Pretrained using self-supervised learning on over 98,000\nthoracic LDCTs, including the UK's largest LCS initiative to date and 27 public\ndatasets, TANGERINE achieves state-of-the-art performance across 14 disease\nclassification tasks, including lung cancer and multiple respiratory diseases,\nwhile generalising robustly across diverse clinical centres. By extending a\nmasked autoencoder framework to 3D imaging, TANGERINE offers a scalable\nsolution for LDCT analysis, departing from recent closed, resource-intensive\nmodels by combining architectural simplicity, public availability, and modest\ncomputational requirements. Its accessible, open-source lightweight design lays\nthe foundation for rapid integration into next-generation medical imaging tools\nthat could transform LCS initiatives, allowing them to pivot from a singular\nfocus on lung cancer detection to comprehensive respiratory disease management\nin high-risk populations.", "AI": {"tldr": "TANGERINE\u662f\u4e00\u4e2a\u5f00\u6e90\u3001\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u4f4e\u76843D\u89c6\u89c9\u57fa\u7840\u6a21\u578b\uff0c\u7528\u4e8e\u4f4e\u5242\u91cfCT\u626b\u63cf\u5206\u6790\uff0c\u80fd\u5feb\u901f\u9002\u5e94\u591a\u79cd\u75be\u75c5\u68c0\u6d4b\u4efb\u52a1\uff0c\u5e76\u572814\u79cd\u75be\u75c5\u5206\u7c7b\u4e2d\u8fbe\u5230\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u4f4e\u5242\u91cfCT\u626b\u63cf\u5206\u6790\u4e2d\u653e\u5c04\u79d1\u533b\u751f\u77ed\u7f3a\u7684\u95ee\u9898\uff0c\u540c\u65f6\u6269\u5c55\u80ba\u764c\u7b5b\u67e5\u9879\u76ee\u4ee5\u6db5\u76d6\u66f4\u591a\u547c\u5438\u7cfb\u7edf\u75be\u75c5\u3002", "method": "\u91c7\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u57fa\u4e8e\u8d85\u8fc798,000\u4f8b\u80f8\u90e8LDCT\u6570\u636e\uff0c\u7ed3\u5408\u63a9\u7801\u81ea\u7f16\u7801\u5668\u6846\u67b6\u6269\u5c55\u52303D\u6210\u50cf\u3002", "result": "\u572814\u79cd\u75be\u75c5\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u4f4e\u4e14\u6807\u7b7e\u6548\u7387\u9ad8\u3002", "conclusion": "TANGERINE\u4e3a\u4e0b\u4e00\u4ee3\u533b\u5b66\u5f71\u50cf\u5de5\u5177\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u5f00\u653e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u63a8\u52a8\u80ba\u764c\u7b5b\u67e5\u5411\u5168\u9762\u547c\u5438\u7cfb\u7edf\u75be\u75c5\u7ba1\u7406\u8f6c\u53d8\u3002"}}
{"id": "2507.01889", "pdf": "https://arxiv.org/pdf/2507.01889", "abs": "https://arxiv.org/abs/2507.01889", "authors": ["Sebastian Wissel", "Jonas Scheunert", "Aaron Dextre", "Shamail Ahmed", "Andreas Bayer", "Kerstin Volz", "Bai-Xiang Xu"], "title": "STEM Diffraction Pattern Analysis with Deep Learning Networks", "categories": ["cond-mat.dis-nn", "cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Accurate grain orientation mapping is essential for understanding and\noptimizing the performance of polycrystalline materials, particularly in\nenergy-related applications. Lithium nickel oxide (LiNiO$_{2}$) is a promising\ncathode material for next-generation lithium-ion batteries, and its\nelectrochemical behaviour is closely linked to microstructural features such as\ngrain size and crystallographic orientations. Traditional orientation mapping\nmethods--such as manual indexing, template matching (TM), or Hough\ntransform-based techniques--are often slow and noise-sensitive when handling\ncomplex or overlapping patterns, creating a bottleneck in large-scale\nmicrostructural analysis. This work presents a machine learning-based approach\nfor predicting Euler angles directly from scanning transmission electron\nmicroscopy (STEM) diffraction patterns (DPs). This enables the automated\ngeneration of high-resolution crystal orientation maps, facilitating the\nanalysis of internal microstructures at the nanoscale. Three deep learning\narchitectures--convolutional neural networks (CNNs), Dense Convolutional\nNetworks (DenseNets), and Shifted Windows (Swin) Transformers--are evaluated,\nusing an experimentally acquired dataset labelled via a commercial TM\nalgorithm. While the CNN model serves as a baseline, both DenseNets and Swin\nTransformers demonstrate superior performance, with the Swin Transformer\nachieving the highest evaluation scores and the most consistent microstructural\npredictions. The resulting crystal maps exhibit clear grain boundary\ndelineation and coherent intra-grain orientation distributions, underscoring\nthe potential of attention-based architectures for analyzing diffraction-based\nimage data. These findings highlight the promise of combining advanced machine\nlearning models with STEM data for robust, high-throughput microstructural\ncharacterization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u626b\u63cf\u900f\u5c04\u7535\u5b50\u663e\u5fae\u955c\u884d\u5c04\u56fe\u6848\u5206\u6790\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u9884\u6d4b\u6676\u4f53\u53d6\u5411\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e09\u79cd\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u7684\u6027\u80fd\u3002", "motivation": "\u9502\u954d\u6c27\u5316\u7269\u4f5c\u4e3a\u4e0b\u4e00\u4ee3\u9502\u79bb\u5b50\u7535\u6c60\u7684\u9634\u6781\u6750\u6599\uff0c\u5176\u7535\u5316\u5b66\u884c\u4e3a\u4e0e\u5fae\u89c2\u7ed3\u6784\u7279\u5f81\u5bc6\u5207\u76f8\u5173\uff0c\u4f20\u7edf\u53d6\u5411\u6620\u5c04\u65b9\u6cd5\u6548\u7387\u4f4e\u4e14\u566a\u58f0\u654f\u611f\u3002", "method": "\u91c7\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u3001\u5bc6\u96c6\u5377\u79ef\u7f51\u7edc\uff08DenseNets\uff09\u548cShifted Windows\uff08Swin\uff09Transformer\u4e09\u79cd\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u76f4\u63a5\u4ece\u884d\u5c04\u56fe\u6848\u9884\u6d4b\u6b27\u62c9\u89d2\u3002", "result": "Swin Transformer\u8868\u73b0\u6700\u4f73\uff0c\u751f\u6210\u7684\u6676\u4f53\u53d6\u5411\u56fe\u6e05\u6670\u5c55\u793a\u4e86\u6676\u754c\u548c\u6676\u5185\u53d6\u5411\u5206\u5e03\u3002", "conclusion": "\u7ed3\u5408\u5148\u8fdb\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e0eSTEM\u6570\u636e\uff0c\u53ef\u5b9e\u73b0\u9ad8\u6548\u3001\u9ad8\u7cbe\u5ea6\u7684\u5fae\u89c2\u7ed3\u6784\u8868\u5f81\u3002"}}
{"id": "2507.01900", "pdf": "https://arxiv.org/pdf/2507.01900", "abs": "https://arxiv.org/abs/2507.01900", "authors": ["Songtao Liu", "Peng Liu"], "title": "High-Layer Attention Pruning with Rescaling", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Pruning is a highly effective approach for compressing large language models\n(LLMs), significantly reducing inference latency. However, conventional\ntraining-free structured pruning methods often employ a heuristic metric that\nindiscriminately removes some attention heads across all pruning layers,\nwithout considering their positions within the network architecture. In this\nwork, we propose a novel pruning algorithm that strategically prunes attention\nheads in the model's higher layers. Since the removal of attention heads can\nalter the magnitude of token representations, we introduce an adaptive\nrescaling parameter that calibrates the representation scale post-pruning to\ncounteract this effect. We conduct comprehensive experiments on a wide range of\nLLMs, including LLaMA3.1-8B, Mistral-7B-v0.3, Qwen2-7B, and Gemma2-9B. Our\nevaluation includes both generation and discriminative tasks across 27\ndatasets. The results consistently demonstrate that our method outperforms\nexisting structured pruning methods. This improvement is particularly notable\nin generation tasks, where our approach significantly outperforms existing\nbaselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u526a\u679d\u7b97\u6cd5\uff0c\u4e13\u6ce8\u4e8e\u9ad8\u5c42\u6ce8\u610f\u529b\u5934\u7684\u526a\u679d\uff0c\u5e76\u901a\u8fc7\u81ea\u9002\u5e94\u91cd\u7f29\u653e\u53c2\u6570\u6821\u51c6\u8868\u793a\u5c3a\u5ea6\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u526a\u679d\u65b9\u6cd5\u4e0d\u8003\u8651\u6ce8\u610f\u529b\u5934\u5728\u7f51\u7edc\u4e2d\u7684\u4f4d\u7f6e\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u526a\u679d\u9ad8\u5c42\u6ce8\u610f\u529b\u5934\u7684\u7b56\u7565\uff0c\u5e76\u5f15\u5165\u81ea\u9002\u5e94\u91cd\u7f29\u653e\u53c2\u6570\u4ee5\u6821\u51c6\u526a\u679d\u540e\u7684\u8868\u793a\u5c3a\u5ea6\u3002", "result": "\u5728\u591a\u79cdLLM\u548c27\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u751f\u6210\u4efb\u52a1\u8868\u73b0\u5c24\u5176\u7a81\u51fa\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u5728\u538b\u7f29\u6a21\u578b\u548c\u63d0\u5347\u63a8\u7406\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2507.01913", "pdf": "https://arxiv.org/pdf/2507.01913", "abs": "https://arxiv.org/abs/2507.01913", "authors": ["Apoorv Verma", "Junaid Jami", "Amrita Bhattacharya"], "title": "Advancing Magnetic Materials Discovery -- A structure-based machine learning approach for magnetic ordering and magnetic moment prediction", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Accurately predicting magnetic behavior across diverse materials systems\nremains a longstanding challenge due to the complex interplay of structural and\nelectronic factors and is pivotal for the accelerated discovery and design of\nnext-generation magnetic materials. In this work, a refined descriptor is\nproposed that significantly improves the prediction of two critical magnetic\nproperties -- magnetic ordering (Ferromagnetic vs. Ferrimagnetic) and magnetic\nmoment per atom -- using only the structural information of materials. Unlike\nprevious models limited to Mn-based or lanthanide-transition metal compounds,\nthe present approach generalizes across a diverse dataset of 5741 stable,\nbinary and ternary, ferromagnetic and ferrimagnetic compounds sourced from the\nMaterials Project. Leveraging an enriched elemental vector representation and\nadvanced feature engineering, including nonlinear terms and reduced matrix\nsparsity, the LightGBM-based model achieves an accuracy of 82.4% for magnetic\nordering classification and balanced recall across FM and FiM classes,\naddressing a key limitation in prior studies. The model predicts magnetic\nmoment per atom with a correlation coefficient of 0.93, surpassing the Hund's\nmatrix and orbital field matrix descriptors. Additionally, it accurately\nestimates formation energy per atom, enabling assessment of both magnetic\nbehavior and material stability. This generalized and computationally efficient\nframework offers a robust tool for high-throughput screening of magnetic\nmaterials with tailored properties.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u63cf\u8ff0\u7b26\uff0c\u5229\u7528\u6750\u6599\u7684\u7ed3\u6784\u4fe1\u606f\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u78c1\u6027\u6392\u5e8f\u548c\u539f\u5b50\u78c1\u77e9\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u6750\u6599\u7cfb\u7edf\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u78c1\u6027\u884c\u4e3a\u5bf9\u52a0\u901f\u53d1\u73b0\u548c\u8bbe\u8ba1\u4e0b\u4e00\u4ee3\u78c1\u6027\u6750\u6599\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u5c40\u9650\u4e8e\u7279\u5b9a\u6750\u6599\u7cfb\u7edf\u3002", "method": "\u91c7\u7528LightGBM\u6a21\u578b\uff0c\u7ed3\u5408\u4e30\u5bcc\u7684\u5143\u7d20\u5411\u91cf\u8868\u793a\u548c\u9ad8\u7ea7\u7279\u5f81\u5de5\u7a0b\uff0c\u5305\u62ec\u975e\u7ebf\u6027\u9879\u548c\u51cf\u5c11\u77e9\u9635\u7a00\u758f\u6027\u3002", "result": "\u6a21\u578b\u5728\u78c1\u6027\u6392\u5e8f\u5206\u7c7b\u4e2d\u8fbe\u523082.4%\u7684\u51c6\u786e\u7387\uff0c\u539f\u5b50\u78c1\u77e9\u9884\u6d4b\u7684\u76f8\u5173\u7cfb\u6570\u4e3a0.93\uff0c\u4f18\u4e8e\u73b0\u6709\u63cf\u8ff0\u7b26\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u9ad8\u901a\u91cf\u7b5b\u9009\u5177\u6709\u5b9a\u5236\u7279\u6027\u7684\u78c1\u6027\u6750\u6599\u63d0\u4f9b\u4e86\u5f3a\u5927\u5de5\u5177\u3002"}}
{"id": "2507.01915", "pdf": "https://arxiv.org/pdf/2507.01915", "abs": "https://arxiv.org/abs/2507.01915", "authors": ["Chengao Li", "Hanyu Zhang", "Yunkun Xu", "Hongyan Xue", "Xiang Ao", "Qing He"], "title": "Gradient-Adaptive Policy Optimization: Towards Multi-Objective Alignment of Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "19 pages, 3 figures. Accepted by ACL 2025 (main)", "summary": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a powerful\ntechnique for aligning large language models (LLMs) with human preferences.\nHowever, effectively aligning LLMs with diverse human preferences remains a\nsignificant challenge, particularly when they are conflict. To address this\nissue, we frame human value alignment as a multi-objective optimization\nproblem, aiming to maximize a set of potentially conflicting objectives. We\nintroduce Gradient-Adaptive Policy Optimization (GAPO), a novel fine-tuning\nparadigm that employs multiple-gradient descent to align LLMs with diverse\npreference distributions. GAPO adaptively rescales the gradients for each\nobjective to determine an update direction that optimally balances the\ntrade-offs between objectives. Additionally, we introduce P-GAPO, which\nincorporates user preferences across different objectives and achieves Pareto\nsolutions that better align with the user's specific needs. Our theoretical\nanalysis demonstrates that GAPO converges towards a Pareto optimal solution for\nmultiple objectives. Empirical results on Mistral-7B show that GAPO outperforms\ncurrent state-of-the-art methods, achieving superior performance in both\nhelpfulness and harmlessness.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGAPO\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u4f18\u5316\u89e3\u51b3LLM\u4e0e\u591a\u6837\u5316\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u5e76\u5f15\u5165P-GAPO\u8fdb\u4e00\u6b65\u7ed3\u5408\u7528\u6237\u504f\u597d\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5bf9\u9f50\u591a\u6837\u5316\u4e14\u53ef\u80fd\u51b2\u7a81\u7684\u4eba\u7c7b\u504f\u597d\u3002", "method": "\u63d0\u51faGradient-Adaptive Policy Optimization (GAPO)\uff0c\u5229\u7528\u591a\u68af\u5ea6\u4e0b\u964d\u6cd5\u5e73\u8861\u76ee\u6807\u95f4\u7684\u6743\u8861\uff0c\u5e76\u5f15\u5165P-GAPO\u7ed3\u5408\u7528\u6237\u504f\u597d\u3002", "result": "\u7406\u8bba\u8bc1\u660eGAPO\u6536\u655b\u4e8ePareto\u6700\u4f18\u89e3\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728Mistral-7B\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "GAPO\u548cP-GAPO\u4e3aLLM\u4e0e\u591a\u6837\u5316\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.01932", "pdf": "https://arxiv.org/pdf/2507.01932", "abs": "https://arxiv.org/abs/2507.01932", "authors": ["Zhaosong Lu", "Xiangyuan Wang"], "title": "A first-order method for nonconvex-nonconcave minimax problems under a local Kurdyka-\u0141ojasiewicz condition", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA", "stat.ML", "90C26, 90C30, 90C47, 90C99, 65K05"], "comment": "26 pages", "summary": "We study a class of nonconvex-nonconcave minimax problems in which the inner\nmaximization problem satisfies a local Kurdyka-{\\L}ojasiewicz (KL) condition\nthat may vary with the outer minimization variable. In contrast to the global\nKL or Polyak-{\\L}ojasiewicz (PL) conditions commonly assumed in the literature\n-- which are significantly stronger and often too restrictive in practice --\nthis local KL condition accommodates a broader range of practical scenarios.\nHowever, it also introduces new analytical challenges. In particular, as an\noptimization algorithm progresses toward a stationary point of the problem, the\nregion over which the KL condition holds may shrink, resulting in a more\nintricate and potentially ill-conditioned landscape. To address this challenge,\nwe show that the associated maximal function is locally H\\\"older smooth.\nLeveraging this key property, we develop an inexact proximal gradient method\nfor solving the minimax problem, where the inexact gradient of the maximal\nfunction is computed by applying a proximal gradient method to a KL-structured\nsubproblem. Under mild assumptions, we establish complexity guarantees for\ncomputing an approximate stationary point of the minimax problem.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4e00\u7c7b\u975e\u51f8\u975e\u51f9\u7684\u6781\u5c0f\u6781\u5927\u95ee\u9898\uff0c\u5176\u4e2d\u5185\u90e8\u6700\u5927\u5316\u95ee\u9898\u6ee1\u8db3\u5c40\u90e8KL\u6761\u4ef6\u3002\u901a\u8fc7\u8bc1\u660e\u76f8\u5173\u6781\u5927\u51fd\u6570\u7684\u5c40\u90e8H\u00f6lder\u5149\u6ed1\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u7cbe\u786e\u8fd1\u7aef\u68af\u5ea6\u6cd5\uff0c\u5e76\u7ed9\u51fa\u4e86\u8ba1\u7b97\u8fd1\u4f3c\u7a33\u5b9a\u70b9\u7684\u590d\u6742\u5ea6\u4fdd\u8bc1\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5168\u5c40KL\u6216PL\u6761\u4ef6\u8fc7\u4e8e\u4e25\u683c\u7684\u95ee\u9898\uff0c\u9002\u5e94\u66f4\u5e7f\u6cdb\u7684\u5b9e\u8df5\u573a\u666f\uff0c\u540c\u65f6\u5e94\u5bf9\u5c40\u90e8KL\u6761\u4ef6\u5e26\u6765\u7684\u65b0\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u4e0d\u7cbe\u786e\u8fd1\u7aef\u68af\u5ea6\u6cd5\uff0c\u901a\u8fc7\u8fd1\u7aef\u68af\u5ea6\u6cd5\u8ba1\u7b97\u6781\u5927\u51fd\u6570\u7684\u4e0d\u7cbe\u786e\u68af\u5ea6\uff0c\u5904\u7406KL\u7ed3\u6784\u7684\u5b50\u95ee\u9898\u3002", "result": "\u8bc1\u660e\u4e86\u6781\u5927\u51fd\u6570\u7684\u5c40\u90e8H\u00f6lder\u5149\u6ed1\u6027\uff0c\u5e76\u7ed9\u51fa\u4e86\u8ba1\u7b97\u8fd1\u4f3c\u7a33\u5b9a\u70b9\u7684\u590d\u6742\u5ea6\u4fdd\u8bc1\u3002", "conclusion": "\u5c40\u90e8KL\u6761\u4ef6\u66f4\u7075\u6d3b\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u7531\u6b64\u5e26\u6765\u7684\u590d\u6742\u6027\u548c\u75c5\u6001\u6027\u3002"}}
{"id": "2507.01939", "pdf": "https://arxiv.org/pdf/2507.01939", "abs": "https://arxiv.org/abs/2507.01939", "authors": ["Xiaosheng Zhao", "Yang Huang", "Guirong Xue", "Xiao Kong", "Jifeng Liu", "Xiaoyu Tang", "Timothy C. Beers", "Yuan-Sen Ting", "A-Li Luo"], "title": "SpecCLIP: Aligning and Translating Spectroscopic Measurements for Stars", "categories": ["astro-ph.IM", "astro-ph.SR", "cs.AI", "cs.LG"], "comment": "26 pages, 6 figures, 5 tables. To be submitted to AAS Journals.\n  Comments welcome", "summary": "In recent years, large language models (LLMs) have transformed natural\nlanguage understanding through vast datasets and large-scale parameterization.\nInspired by this success, we present SpecCLIP, a foundation model framework\nthat extends LLM-inspired methodologies to stellar spectral analysis. Stellar\nspectra, akin to structured language, encode rich physical and chemical\ninformation about stars. By training foundation models on large-scale spectral\ndatasets, our goal is to learn robust and informative embeddings that support\ndiverse downstream applications. As a proof of concept, SpecCLIP involves\npre-training on two spectral types--LAMOST low-resolution and Gaia XP--followed\nby contrastive alignment using the CLIP (Contrastive Language-Image\nPre-training) framework, adapted to associate spectra from different\ninstruments. This alignment is complemented by auxiliary decoders that preserve\nspectrum-specific information and enable translation (prediction) between\nspectral types, with the former achieved by maximizing mutual information\nbetween embeddings and input spectra. The result is a cross-spectrum framework\nenabling intrinsic calibration and flexible applications across instruments. We\ndemonstrate that fine-tuning these models on moderate-sized labeled datasets\nimproves adaptability to tasks such as stellar-parameter estimation and\nchemical-abundance determination. SpecCLIP also enhances the accuracy and\nprecision of parameter estimates benchmarked against external survey data.\nAdditionally, its similarity search and cross-spectrum prediction capabilities\noffer potential for anomaly detection. Our results suggest that contrastively\ntrained foundation models enriched with spectrum-aware decoders can advance\nprecision stellar spectroscopy.", "AI": {"tldr": "SpecCLIP\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u542f\u53d1\u7684\u6052\u661f\u5149\u8c31\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u548c\u8f85\u52a9\u89e3\u7801\u5668\u5b9e\u73b0\u8de8\u5149\u8c31\u6821\u51c6\u548c\u7075\u6d3b\u5e94\u7528\u3002", "motivation": "\u5c06LLM\u7684\u6210\u529f\u65b9\u6cd5\u6269\u5c55\u5230\u6052\u661f\u5149\u8c31\u5206\u6790\uff0c\u4ee5\u5b66\u4e60\u9c81\u68d2\u4e14\u4fe1\u606f\u4e30\u5bcc\u7684\u5d4c\u5165\uff0c\u652f\u6301\u591a\u6837\u5316\u7684\u4e0b\u6e38\u5e94\u7528\u3002", "method": "\u4f7f\u7528LAMOST\u4f4e\u5206\u8fa8\u7387\u548cGaia XP\u5149\u8c31\u6570\u636e\u96c6\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7ed3\u5408CLIP\u6846\u67b6\u8fdb\u884c\u5bf9\u6bd4\u5bf9\u9f50\uff0c\u5e76\u901a\u8fc7\u8f85\u52a9\u89e3\u7801\u5668\u4fdd\u7559\u5149\u8c31\u7279\u5b9a\u4fe1\u606f\u3002", "result": "SpecCLIP\u5728\u6052\u661f\u53c2\u6570\u4f30\u8ba1\u548c\u5316\u5b66\u4e30\u5ea6\u6d4b\u5b9a\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u7cbe\u5ea6\uff0c\u5e76\u5177\u5907\u5f02\u5e38\u68c0\u6d4b\u6f5c\u529b\u3002", "conclusion": "\u5bf9\u6bd4\u8bad\u7ec3\u7684\u57fa\u7840\u6a21\u578b\u7ed3\u5408\u5149\u8c31\u611f\u77e5\u89e3\u7801\u5668\u53ef\u4ee5\u63a8\u52a8\u7cbe\u5bc6\u6052\u661f\u5149\u8c31\u5b66\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.01946", "pdf": "https://arxiv.org/pdf/2507.01946", "abs": "https://arxiv.org/abs/2507.01946", "authors": ["Adam J. Eisen", "Mitchell Ostrow", "Sarthak Chandra", "Leo Kozachkov", "Earl K. Miller", "Ila R. Fiete"], "title": "Characterizing control between interacting subsystems with deep Jacobian estimation", "categories": ["q-bio.QM", "cs.LG", "math.DS", "q-bio.NC"], "comment": "10 pages, 6 figures", "summary": "Biological function arises through the dynamical interactions of multiple\nsubsystems, including those between brain areas, within gene regulatory\nnetworks, and more. A common approach to understanding these systems is to\nmodel the dynamics of each subsystem and characterize communication between\nthem. An alternative approach is through the lens of control theory: how the\nsubsystems control one another. This approach involves inferring the\ndirectionality, strength, and contextual modulation of control between\nsubsystems. However, methods for understanding subsystem control are typically\nlinear and cannot adequately describe the rich contextual effects enabled by\nnonlinear complex systems. To bridge this gap, we devise a data-driven\nnonlinear control-theoretic framework to characterize subsystem interactions\nvia the Jacobian of the dynamics. We address the challenge of learning\nJacobians from time-series data by proposing the JacobianODE, a deep learning\nmethod that leverages properties of the Jacobian to directly estimate it for\narbitrary dynamical systems from data alone. We show that JacobianODEs\noutperform existing Jacobian estimation methods on challenging systems,\nincluding high-dimensional chaos. Applying our approach to a multi-area\nrecurrent neural network (RNN) trained on a working memory selection task, we\nshow that the \"sensory\" area gains greater control over the \"cognitive\" area\nover learning. Furthermore, we leverage the JacobianODE to directly control the\ntrained RNN, enabling precise manipulation of its behavior. Our work lays the\nfoundation for a theoretically grounded and data-driven understanding of\ninteractions among biological subsystems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u7ebf\u6027\u63a7\u5236\u7406\u8bba\u6846\u67b6JacobianODE\uff0c\u7528\u4e8e\u4ece\u6570\u636e\u4e2d\u76f4\u63a5\u4f30\u8ba1\u5b50\u7cfb\u7edf\u4ea4\u4e92\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\uff0c\u5e76\u5728\u9ad8\u7ef4\u6df7\u6c8c\u7cfb\u7edf\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u901a\u5e38\u4e3a\u7ebf\u6027\uff0c\u65e0\u6cd5\u5145\u5206\u63cf\u8ff0\u975e\u7ebf\u6027\u590d\u6742\u7cfb\u7edf\u7684\u4e30\u5bcc\u4e0a\u4e0b\u6587\u6548\u5e94\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u975e\u7ebf\u6027\u63a7\u5236\u7406\u8bba\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86JacobianODE\uff0c\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u96c5\u53ef\u6bd4\u77e9\u9635\u7684\u7279\u6027\u76f4\u63a5\u4ece\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u4f30\u8ba1\u4efb\u610f\u52a8\u6001\u7cfb\u7edf\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\u3002", "result": "JacobianODE\u5728\u9ad8\u7ef4\u6df7\u6c8c\u7cfb\u7edf\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u5728\u591a\u533a\u57df\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\uff08RNN\uff09\u4e2d\u5c55\u793a\u4e86\u611f\u5b98\u533a\u57df\u5bf9\u8ba4\u77e5\u533a\u57df\u7684\u63a7\u5236\u589e\u5f3a\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u751f\u7269\u5b50\u7cfb\u7edf\u4ea4\u4e92\u7684\u7406\u8bba\u548c\u6570\u636e\u9a71\u52a8\u7406\u89e3\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.01955", "pdf": "https://arxiv.org/pdf/2507.01955", "abs": "https://arxiv.org/abs/2507.01955", "authors": ["Rahul Ramachandran", "Ali Garjani", "Roman Bachmann", "Andrei Atanov", "O\u011fuzhan Fatih Kar", "Amir Zamir"], "title": "How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Project page at https://fm-vision-evals.epfl.ch/", "summary": "Multimodal foundation models, such as GPT-4o, have recently made remarkable\nprogress, but it is not clear where exactly these models stand in terms of\nunderstanding vision. In this paper, we benchmark the performance of popular\nmultimodal foundation models (GPT-4o, o4-mini, Gemini 1.5 Pro and Gemini 2.0\nFlash, Claude 3.5 Sonnet, Qwen2-VL, Llama 3.2) on standard computer vision\ntasks (semantic segmentation, object detection, image classification, depth and\nsurface normal prediction) using established datasets (e.g., COCO, ImageNet and\nits variants, etc).\n  The main challenges to performing this are: 1) most models are trained to\noutput text and cannot natively express versatile domains, such as segments or\n3D geometry, and 2) many leading models are proprietary and accessible only at\nan API level, i.e., there is no weight access to adapt them. We address these\nchallenges by translating standard vision tasks into equivalent text-promptable\nand API-compatible tasks via prompt chaining to create a standardized\nbenchmarking framework.\n  We observe that 1) the models are not close to the state-of-the-art\nspecialist models at any task. However, 2) they are respectable generalists;\nthis is remarkable as they are presumably trained on primarily image-text-based\ntasks. 3) They perform semantic tasks notably better than geometric ones. 4)\nWhile the prompt-chaining techniques affect performance, better models exhibit\nless sensitivity to prompt variations. 5) GPT-4o performs the best among\nnon-reasoning models, securing the top position in 4 out of 6 tasks, 6)\nreasoning models, e.g. o3, show improvements in geometric tasks, and 7) a\npreliminary analysis of models with native image generation, like the latest\nGPT-4o, shows they exhibit quirks like hallucinations and spatial\nmisalignments.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u6807\u51c6\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5b83\u4eec\u867d\u4e0d\u53ca\u4e13\u4e1a\u6a21\u578b\uff0c\u4f46\u4f5c\u4e3a\u901a\u7528\u6a21\u578b\u8868\u73b0\u5c1a\u53ef\uff0c\u4e14\u8bed\u4e49\u4efb\u52a1\u4f18\u4e8e\u51e0\u4f55\u4efb\u52a1\u3002GPT-4o\u5728\u975e\u63a8\u7406\u6a21\u578b\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u7814\u7a76\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u89c6\u89c9\u7406\u89e3\u65b9\u9762\u7684\u5b9e\u9645\u80fd\u529b\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u63d0\u793a\u94fe\u5c06\u6807\u51c6\u89c6\u89c9\u4efb\u52a1\u8f6c\u5316\u4e3a\u6587\u672c\u53ef\u63d0\u793a\u548cAPI\u517c\u5bb9\u7684\u4efb\u52a1\uff0c\u5efa\u7acb\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u6a21\u578b\u5728\u8bed\u4e49\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u51e0\u4f55\u4efb\u52a1\uff0cGPT-4o\u5728\u975e\u63a8\u7406\u6a21\u578b\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u63a8\u7406\u6a21\u578b\u5728\u51e0\u4f55\u4efb\u52a1\u4e2d\u6709\u6539\u8fdb\u3002", "conclusion": "\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u89c6\u89c9\u4efb\u52a1\u4e2d\u8868\u73b0\u5c1a\u53ef\uff0c\u4f46\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u5c24\u5176\u662f\u5728\u51e0\u4f55\u4efb\u52a1\u548c\u63d0\u793a\u654f\u611f\u6027\u65b9\u9762\u3002"}}
